{
  "total_instances": 680,
  "valid_instances": 393,
  "invalid_instances": 287,
  "duration_seconds": 1354.2560482025146,
  "duration_minutes": 22.570934136708576,
  "instances_per_second": 0.502120703763926,
  "by_repository": {
    "django/django": {
      "total": 274,
      "valid": 221,
      "errors": [
        "django__django-11138",
        "django__django-11149",
        "django__django-11299",
        "django__django-11740",
        "django__django-11790",
        "django__django-11815",
        "django__django-11848",
        "django__django-12143",
        "django__django-12193",
        "django__django-12209",
        "django__django-12262",
        "django__django-12308",
        "django__django-12325",
        "django__django-12419",
        "django__django-12741",
        "django__django-12754",
        "django__django-12858",
        "django__django-12965",
        "django__django-13012",
        "django__django-13023",
        "django__django-13028",
        "django__django-13089",
        "django__django-13112",
        "django__django-13121",
        "django__django-13128",
        "django__django-13195",
        "django__django-13279",
        "django__django-13297",
        "django__django-13315",
        "django__django-13343",
        "django__django-13344",
        "django__django-13346",
        "django__django-13363",
        "django__django-13401",
        "django__django-13410",
        "django__django-13417",
        "django__django-13449",
        "django__django-13512",
        "django__django-13513",
        "django__django-13516",
        "django__django-13551",
        "django__django-13658",
        "django__django-15037",
        "django__django-11138",
        "django__django-11740",
        "django__django-12143",
        "django__django-12325",
        "django__django-13012",
        "django__django-13112",
        "django__django-15037",
        "django__django-13297",
        "django__django-13512",
        "django__django-13551"
      ]
    },
    "sympy/sympy": {
      "total": 102,
      "valid": 50,
      "errors": [
        "sympy__sympy-12096",
        "sympy__sympy-13091",
        "sympy__sympy-13372",
        "sympy__sympy-13615",
        "sympy__sympy-13647",
        "sympy__sympy-13757",
        "sympy__sympy-13798",
        "sympy__sympy-13877",
        "sympy__sympy-13878",
        "sympy__sympy-14248",
        "sympy__sympy-14531",
        "sympy__sympy-14976",
        "sympy__sympy-15599",
        "sympy__sympy-15809",
        "sympy__sympy-15875",
        "sympy__sympy-16450",
        "sympy__sympy-16597",
        "sympy__sympy-17139",
        "sympy__sympy-17318",
        "sympy__sympy-17630",
        "sympy__sympy-18189",
        "sympy__sympy-18199",
        "sympy__sympy-18211",
        "sympy__sympy-18763",
        "sympy__sympy-19346",
        "sympy__sympy-19637",
        "sympy__sympy-21930",
        "sympy__sympy-12096",
        "sympy__sympy-13091",
        "sympy__sympy-13372",
        "sympy__sympy-13615",
        "sympy__sympy-13647",
        "sympy__sympy-13798",
        "sympy__sympy-13757",
        "sympy__sympy-14531",
        "sympy__sympy-14248",
        "sympy__sympy-15599",
        "sympy__sympy-15809",
        "sympy__sympy-15875",
        "sympy__sympy-16597",
        "sympy__sympy-16450",
        "sympy__sympy-17630",
        "sympy__sympy-17139",
        "sympy__sympy-13877",
        "sympy__sympy-18211",
        "sympy__sympy-14976",
        "sympy__sympy-19346",
        "sympy__sympy-18763",
        "sympy__sympy-19637",
        "sympy__sympy-18189",
        "sympy__sympy-13878",
        "sympy__sympy-17318"
      ]
    },
    "matplotlib/matplotlib": {
      "total": 58,
      "valid": 15,
      "errors": [
        "matplotlib__matplotlib-13989",
        "matplotlib__matplotlib-14623",
        "matplotlib__matplotlib-20488",
        "matplotlib__matplotlib-20676",
        "matplotlib__matplotlib-20826",
        "matplotlib__matplotlib-20859",
        "matplotlib__matplotlib-22865",
        "matplotlib__matplotlib-23299",
        "matplotlib__matplotlib-23314",
        "matplotlib__matplotlib-23476",
        "matplotlib__matplotlib-24026",
        "matplotlib__matplotlib-24149",
        "matplotlib__matplotlib-24177",
        "matplotlib__matplotlib-24627",
        "matplotlib__matplotlib-24970",
        "matplotlib__matplotlib-25122",
        "matplotlib__matplotlib-25287",
        "matplotlib__matplotlib-25311",
        "matplotlib__matplotlib-25332",
        "matplotlib__matplotlib-25479",
        "matplotlib__matplotlib-25960",
        "matplotlib__matplotlib-26113",
        "matplotlib__matplotlib-26208",
        "matplotlib__matplotlib-26342",
        "matplotlib__matplotlib-20488",
        "matplotlib__matplotlib-20676",
        "matplotlib__matplotlib-13989",
        "matplotlib__matplotlib-23299",
        "matplotlib__matplotlib-23476",
        "matplotlib__matplotlib-22865",
        "matplotlib__matplotlib-14623",
        "matplotlib__matplotlib-24970",
        "matplotlib__matplotlib-25311",
        "matplotlib__matplotlib-20826",
        "matplotlib__matplotlib-25332",
        "matplotlib__matplotlib-25479",
        "matplotlib__matplotlib-23314",
        "matplotlib__matplotlib-24177",
        "matplotlib__matplotlib-26342",
        "matplotlib__matplotlib-24627",
        "matplotlib__matplotlib-26113",
        "matplotlib__matplotlib-25287",
        "matplotlib__matplotlib-26208"
      ]
    },
    "sphinx-doc/sphinx": {
      "total": 49,
      "valid": 39,
      "errors": [
        "sphinx-doc__sphinx-7440",
        "sphinx-doc__sphinx-8056",
        "sphinx-doc__sphinx-8120",
        "sphinx-doc__sphinx-8621",
        "sphinx-doc__sphinx-8721",
        "sphinx-doc__sphinx-7440",
        "sphinx-doc__sphinx-8056",
        "sphinx-doc__sphinx-8621",
        "sphinx-doc__sphinx-8120",
        "sphinx-doc__sphinx-8721"
      ]
    },
    "scikit-learn/scikit-learn": {
      "total": 64,
      "valid": 29,
      "errors": [
        "scikit-learn__scikit-learn-10297",
        "scikit-learn__scikit-learn-10844",
        "scikit-learn__scikit-learn-10908",
        "scikit-learn__scikit-learn-11310",
        "scikit-learn__scikit-learn-11578",
        "scikit-learn__scikit-learn-12585",
        "scikit-learn__scikit-learn-12682",
        "scikit-learn__scikit-learn-12973",
        "scikit-learn__scikit-learn-13124",
        "scikit-learn__scikit-learn-13135",
        "scikit-learn__scikit-learn-13142",
        "scikit-learn__scikit-learn-13328",
        "scikit-learn__scikit-learn-13439",
        "scikit-learn__scikit-learn-13496",
        "scikit-learn__scikit-learn-13779",
        "scikit-learn__scikit-learn-14053",
        "scikit-learn__scikit-learn-14087",
        "scikit-learn__scikit-learn-14141",
        "scikit-learn__scikit-learn-14496",
        "scikit-learn__scikit-learn-14629",
        "scikit-learn__scikit-learn-14710",
        "scikit-learn__scikit-learn-14894",
        "scikit-learn__scikit-learn-14983",
        "scikit-learn__scikit-learn-15100",
        "scikit-learn__scikit-learn-25102",
        "scikit-learn__scikit-learn-25232",
        "scikit-learn__scikit-learn-25747",
        "scikit-learn__scikit-learn-25931",
        "scikit-learn__scikit-learn-25973",
        "scikit-learn__scikit-learn-26194",
        "scikit-learn__scikit-learn-26323",
        "scikit-learn__scikit-learn-9288",
        "scikit-learn__scikit-learn-11310",
        "scikit-learn__scikit-learn-13124",
        "scikit-learn__scikit-learn-14053"
      ]
    },
    "astropy/astropy": {
      "total": 33,
      "valid": 11,
      "errors": [
        "astropy__astropy-13033",
        "astropy__astropy-13236",
        "astropy__astropy-13398",
        "astropy__astropy-13579",
        "astropy__astropy-14096",
        "astropy__astropy-7166",
        "astropy__astropy-7336",
        "astropy__astropy-7606",
        "astropy__astropy-7671",
        "astropy__astropy-8707",
        "astropy__astropy-8872",
        "astropy__astropy-13033",
        "astropy__astropy-13579",
        "astropy__astropy-13398",
        "astropy__astropy-7166",
        "astropy__astropy-13236",
        "astropy__astropy-7606",
        "astropy__astropy-14096",
        "astropy__astropy-7671",
        "astropy__astropy-8707",
        "astropy__astropy-7336",
        "astropy__astropy-8872"
      ]
    },
    "pydata/xarray": {
      "total": 30,
      "valid": 18,
      "errors": [
        "pydata__xarray-2905",
        "pydata__xarray-3993",
        "pydata__xarray-4094",
        "pydata__xarray-4687",
        "pydata__xarray-4695",
        "pydata__xarray-6721",
        "pydata__xarray-6744",
        "pydata__xarray-6992",
        "pydata__xarray-4094",
        "pydata__xarray-4695",
        "pydata__xarray-4687",
        "pydata__xarray-3993"
      ]
    },
    "psf/requests": {
      "total": 16,
      "valid": 0,
      "errors": [
        "psf__requests-1142",
        "psf__requests-1724",
        "psf__requests-1766",
        "psf__requests-1921",
        "psf__requests-2317",
        "psf__requests-2931",
        "psf__requests-5414",
        "psf__requests-6028",
        "psf__requests-1142",
        "psf__requests-1766",
        "psf__requests-2931",
        "psf__requests-1921",
        "psf__requests-5414",
        "psf__requests-6028",
        "psf__requests-1724",
        "psf__requests-2317"
      ]
    },
    "mwaskom/seaborn": {
      "total": 4,
      "valid": 0,
      "errors": [
        "mwaskom__seaborn-3069",
        "mwaskom__seaborn-3187",
        "mwaskom__seaborn-3069",
        "mwaskom__seaborn-3187"
      ]
    },
    "pytest-dev/pytest": {
      "total": 34,
      "valid": 4,
      "errors": [
        "pytest-dev__pytest-10081",
        "pytest-dev__pytest-5262",
        "pytest-dev__pytest-5631",
        "pytest-dev__pytest-5787",
        "pytest-dev__pytest-5809",
        "pytest-dev__pytest-5840",
        "pytest-dev__pytest-6197",
        "pytest-dev__pytest-6202",
        "pytest-dev__pytest-7205",
        "pytest-dev__pytest-7236",
        "pytest-dev__pytest-7324",
        "pytest-dev__pytest-7432",
        "pytest-dev__pytest-7521",
        "pytest-dev__pytest-7982",
        "pytest-dev__pytest-8399",
        "pytest-dev__pytest-5631",
        "pytest-dev__pytest-5787",
        "pytest-dev__pytest-5809",
        "pytest-dev__pytest-5840",
        "pytest-dev__pytest-6197",
        "pytest-dev__pytest-6202",
        "pytest-dev__pytest-7205",
        "pytest-dev__pytest-7324",
        "pytest-dev__pytest-7432",
        "pytest-dev__pytest-7521",
        "pytest-dev__pytest-7982",
        "pytest-dev__pytest-10081",
        "pytest-dev__pytest-5262",
        "pytest-dev__pytest-8399",
        "pytest-dev__pytest-7236"
      ]
    },
    "pylint-dev/pylint": {
      "total": 15,
      "valid": 5,
      "errors": [
        "pylint-dev__pylint-4661",
        "pylint-dev__pylint-6528",
        "pylint-dev__pylint-7080",
        "pylint-dev__pylint-7277",
        "pylint-dev__pylint-8898",
        "pylint-dev__pylint-4661",
        "pylint-dev__pylint-8898",
        "pylint-dev__pylint-7080",
        "pylint-dev__pylint-7277",
        "pylint-dev__pylint-6528"
      ]
    },
    "pallets/flask": {
      "total": 1,
      "valid": 1,
      "errors": []
    }
  },
  "by_worker": {
    "http://34.44.234.143:8080": 252,
    "http://35.239.238.137:8080": 90,
    "http://34.41.233.120:8080": 56,
    "http://34.44.241.183:8080": 78,
    "http://34.171.248.213:8080": 53,
    "http://34.59.30.169:8080": 37,
    "http://34.123.9.23:8080": 57,
    "http://34.70.1.155:8080": 57
  },
  "validation_rate": 57.79411764705882,
  "results": [
    {
      "instance_id": "django__django-10097",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 21.400625944137573,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 365,
          "failed": 6,
          "errors": 0,
          "duration": 6.68,
          "log_tail": "AssertionError: ValidationError not raised when validating 'http://foo:bar:baz@example.com'\n\n======================================================================\nFAIL: test_URLValidator_raises_error_355 (validators.tests.TestSimpleValidators)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.5/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.5/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/validators/tests.py\", line 322, in test_func\n    expected.__name__, value))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.5/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: ValidationError not raised when validating 'http://foo:bar@baz@example.com'\n\n======================================================================\nFAIL: test_URLValidator_raises_error_356 (validators.tests.TestSimpleValidators)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.5/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.5/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/validators/tests.py\", line 322, in test_func\n    expected.__name__, value))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.5/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: ValidationError not raised when validating 'http://foo:bar/baz@example.com'\n\n======================================================================\nFAIL: test_URLValidator_raises_error_357 (validators.tests.TestSimpleValidators)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.5/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.5/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/validators/tests.py\", line 322, in test_func\n    expected.__name__, value))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.5/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: ValidationError not raised when validating 'http://invalid-.com/?m=foo@example.com'\n\n----------------------------------------------------------------------\nRan 371 tests in 0.317s\n\nFAILED (failures=6)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 validators` failed. (See above for error)",
          "test_files_run": [
            "tests/validators"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 371,
          "failed": 0,
          "errors": 0,
          "duration": 6.35,
          "log_tail": "test_message_list (validators.tests.TestSimpleValidators) ... ok\ntest_regex_validator_flags (validators.tests.TestSimpleValidators) ... ok\ntest_single_message (validators.tests.TestSimpleValidators) ... ok\ntest_validate_image_file_extension_212 (validators.tests.TestSimpleValidators) ... ok\ntest_validate_image_file_extension_213 (validators.tests.TestSimpleValidators) ... ok\ntest_validate_image_file_extension_214 (validators.tests.TestSimpleValidators) ... ok\ntest_validate_image_file_extension_raises_error_215 (validators.tests.TestSimpleValidators) ... ok\ntest_validate_image_file_extension_raises_error_216 (validators.tests.TestSimpleValidators) ... ok\ntest_validate_integer_0 (validators.tests.TestSimpleValidators) ... ok\ntest_validate_integer_1 (validators.tests.TestSimpleValidators) ... ok\ntest_validate_integer_2 (validators.tests.TestSimpleValidators) ... ok\ntest_validate_integer_raises_error_3 (validators.tests.TestSimpleValidators) ... ok\ntest_validate_integer_raises_error_4 (validators.tests.TestSimpleValidators) ... ok\ntest_validate_integer_raises_error_5 (validators.tests.TestSimpleValidators) ... ok\ntest_validate_integer_raises_error_6 (validators.tests.TestSimpleValidators) ... ok\ntest_validate_integer_raises_error_7 (validators.tests.TestSimpleValidators) ... ok\ntest_validate_ipv46_address_100 (validators.tests.TestSimpleValidators) ... ok\ntest_validate_ipv46_address_101 (validators.tests.TestSimpleValidators) ... ok\ntest_validate_ipv46_address_102 (validators.tests.TestSimpleValidators) ... ok\ntest_validate_ipv46_address_103 (validators.tests.TestSimpleValidators) ... ok\ntest_validate_ipv46_address_98 (validators.tests.TestSimpleValidators) ... ok\ntest_validate_ipv46_address_99 (validators.tests.TestSimpleValidators) ... ok\ntest_validate_ipv46_address_raises_error_104 (validators.tests.TestSimpleValidators) ... ok\ntest_validate_ipv46_address_raises_error_105 (validators.tests.TestSimpleValidators) ... ok\ntest_validate_ipv46_address_raises_error_106 (validators.tests.TestSimpleValidators) ... ok\ntest_validate_ipv46_address_raises_error_107 (validators.tests.TestSimpleValidators) ... ok\ntest_validate_ipv46_address_raises_error_108 (validators.tests.TestSimpleValidators) ... ok\ntest_validate_ipv46_address_raises_error_109 (validators.tests.TestSimpleValidators) ... ok\ntest_validate_ipv46_address_raises_error_110 (validators.tests.TestSimpleValidators) ... ok\ntest_validate_ipv4_address_83 (validators.tests.TestSimpleValidators) ... ok\ntest_validate_ipv4_address_84 (validators.tests.TestSimpleValidators) ... ok\ntest_validate_ipv4_address_85 (validators.tests.TestSimpleValidators) ... ok\ntest_validate_ipv4_address_raises_error_86 (validators.tests.TestSimpleValidators) ... ok\ntest_validate_ipv4_address_raises_error_87 (validators.tests.TestSimpleValidators) ... ok\ntest_validate_ipv4_address_raises_error_88 (validators.tests.TestSimpleValidators) ... ok\ntest_validate_ipv4_address_raises_error_89 (validators.tests.TestSimpleValidators) ... ok\ntest_validate_ipv4_address_raises_error_90 (validators.tests.TestSimpleValidators) ... ok\ntest_validate_ipv4_address_raises_error_91 (validators.tests.TestSimpleValidators) ... ok\ntest_validate_ipv6_address_92 (validators.tests.TestSimpleValidators) ... ok\ntest_validate_ipv6_address_93 (validators.tests.TestSimpleValidators) ... ok\ntest_validate_ipv6_address_94 (validators.tests.TestSimpleValidators) ... ok\ntest_validate_ipv6_address_raises_error_95 (validators.tests.TestSimpleValidators) ... ok\ntest_validate_ipv6_address_raises_error_96 (validators.tests.TestSimpleValidators) ... ok\ntest_validate_ipv6_address_raises_error_97 (validators.tests.TestSimpleValidators) ... ok\n\n----------------------------------------------------------------------\nRan 371 tests in 0.407s\n\nOK\n",
          "test_files_run": [
            "tests/validators"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-10554",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 29.282819747924805,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 8.93,
          "log_tail": "test_union_with_values_list_and_order (queries.test_qs_combinators.QuerySetSetOperationTests) ... test_union_with_values_list_on_annotated_and_unannotated (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_unsupported_intersection_raises_db_error (queries.test_qs_combinators.QuerySetSetOperationTests) ... skipped 'Database has feature(s) supports_select_intersection'\ntest_unsupported_ordering_slicing_raises_db_error (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\n\n======================================================================\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nTraceback (most recent call last):\n  File \"runtests.py\", line 564, in <module>\n    options.start_at, options.start_after,\n  File \"runtests.py\", line 310, in django_tests\n    extra_tests=extra_tests,\n  File \"/testbed/django/test/runner.py\", line 652, in run_tests\n    result = self.run_suite(suite)\n  File \"/testbed/django/test/runner.py\", line 594, in run_suite\n    return runner.run(suite)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/runner.py\", line 183, in run\n    result.printErrors()\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/runner.py\", line 109, in printErrors\n    self.printErrorList('ERROR', self.errors)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/runner.py\", line 115, in printErrorList\n    self.stream.writeln(\"%s: %s\" % (flavour,self.getDescription(test)))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/runner.py\", line 49, in getDescription\n    return str(test)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1429, in __str__\n    return \"{} {}\".format(self.test_case, self._subDescription())\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1415, in _subDescription\n    for (k, v) in sorted(self.params.items()))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1415, in <genexpr>\n    for (k, v) in sorted(self.params.items()))\n  File \"/testbed/django/db/models/query.py\", line 252, in __repr__\n    data = list(self[:REPR_OUTPUT_SIZE + 1])\n  File \"/testbed/django/db/models/query.py\", line 276, in __iter__\n    self._fetch_all()\n  File \"/testbed/django/db/models/query.py\", line 1240, in _fetch_all\n    self._result_cache = list(self._iterable_class(self))\n  File \"/testbed/django/db/models/query.py\", line 184, in __iter__\n    for row in compiler.results_iter(chunked_fetch=self.chunked_fetch, chunk_size=self.chunk_size):\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1042, in results_iter\n    results = self.execute_sql(MULTI, chunked_fetch=chunked_fetch, chunk_size=chunk_size)\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1077, in execute_sql\n    sql, params = self.as_sql()\n  File \"/testbed/django/db/models/sql/compiler.py\", line 475, in as_sql\n    extra_select, order_by, group_by = self.pre_sql_setup()\n  File \"/testbed/django/db/models/sql/compiler.py\", line 53, in pre_sql_setup\n    order_by = self.get_order_by()\n  File \"/testbed/django/db/models/sql/compiler.py\", line 359, in get_order_by\n    raise DatabaseError('ORDER BY term does not match any column in the result set.')\ndjango.db.utils.DatabaseError: ORDER BY term does not match any column in the result set.\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 queries.test_qs_combinators` failed. (See above for error)",
          "test_files_run": [
            "tests/queries/test_qs_combinators.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 27,
          "failed": 0,
          "errors": 0,
          "duration": 8.84,
          "log_tail": "    Creating table queries_ticket23605b\n    Creating table queries_ticket23605c\n    Creating table Individual\n    Creating table RelatedIndividual\n    Creating table queries_customdbcolumn\n    Running deferred SQL...\nRunning migrations:\n  Applying admin.0001_initial... OK\n  Applying admin.0002_logentry_remove_auto_add... OK\n  Applying admin.0003_logentry_add_action_flag_choices... OK\n  Applying sites.0001_initial... OK\n  Applying sites.0002_alter_domain_unique... OK\nSystem check identified no issues (1 silenced).\n\n\nCreating test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\ntest_combining_multiple_models (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_count_difference (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_count_intersection (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_count_union (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_count_union_empty_result (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_difference_with_empty_qs (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_difference_with_values (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_intersection_with_empty_qs (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_intersection_with_values (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_limits (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_order_raises_on_non_selected_column (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_ordering (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_ordering_by_f_expression (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_ordering_subqueries (queries.test_qs_combinators.QuerySetSetOperationTests) ... skipped \"Database doesn't support feature(s): supports_slicing_ordering_in_compound\"\ntest_qs_with_subcompound_qs (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_simple_difference (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_simple_intersection (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_simple_union (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_union_distinct (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_union_with_empty_qs (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_union_with_extra_and_values_list (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_union_with_two_annotated_values_list (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_union_with_values (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_union_with_values_list_and_order (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_union_with_values_list_on_annotated_and_unannotated (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_unsupported_intersection_raises_db_error (queries.test_qs_combinators.QuerySetSetOperationTests) ... skipped 'Database has feature(s) supports_select_intersection'\ntest_unsupported_ordering_slicing_raises_db_error (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\n\n----------------------------------------------------------------------\nRan 27 tests in 0.072s\n\nOK (skipped=2)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/queries/test_qs_combinators.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-10880",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 28.636974096298218,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 55,
          "failed": 0,
          "errors": 1,
          "duration": 8.42,
          "log_tail": "test_ticket11881 (aggregation.tests.AggregateTestCase) ... ok\ntest_ticket12886 (aggregation.tests.AggregateTestCase) ... ok\ntest_ticket17424 (aggregation.tests.AggregateTestCase) ... ok\ntest_values_aggregation (aggregation.tests.AggregateTestCase) ... ok\ntest_values_annotation_with_expression (aggregation.tests.AggregateTestCase) ... ok\n\n======================================================================\nERROR: test_count_distinct_expression (aggregation.tests.AggregateTestCase)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/django/db/backends/utils.py\", line 84, in _execute\n    return self.cursor.execute(sql, params)\n  File \"/testbed/django/db/backends/sqlite3/base.py\", line 376, in execute\n    return Database.Cursor.execute(self, query, params)\nsqlite3.OperationalError: near \"WHEN\": syntax error\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/testbed/tests/aggregation/tests.py\", line 401, in test_count_distinct_expression\n    distinct_ratings=Count(Case(When(pages__gt=300, then='rating')), distinct=True),\n  File \"/testbed/django/db/models/manager.py\", line 82, in manager_method\n    return getattr(self.get_queryset(), name)(*args, **kwargs)\n  File \"/testbed/django/db/models/query.py\", line 378, in aggregate\n    return query.get_aggregation(self.db, kwargs)\n  File \"/testbed/django/db/models/sql/query.py\", line 489, in get_aggregation\n    result = compiler.execute_sql(SINGLE)\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1080, in execute_sql\n    cursor.execute(sql, params)\n  File \"/testbed/django/db/backends/utils.py\", line 67, in execute\n    return self._execute_with_wrappers(sql, params, many=False, executor=self._execute)\n  File \"/testbed/django/db/backends/utils.py\", line 76, in _execute_with_wrappers\n    return executor(sql, params, many, context)\n  File \"/testbed/django/db/backends/utils.py\", line 84, in _execute\n    return self.cursor.execute(sql, params)\n  File \"/testbed/django/db/utils.py\", line 89, in __exit__\n    raise dj_exc_value.with_traceback(traceback) from exc_value\n  File \"/testbed/django/db/backends/utils.py\", line 84, in _execute\n    return self.cursor.execute(sql, params)\n  File \"/testbed/django/db/backends/sqlite3/base.py\", line 376, in execute\n    return Database.Cursor.execute(self, query, params)\ndjango.db.utils.OperationalError: near \"WHEN\": syntax error\n\n----------------------------------------------------------------------\nRan 56 tests in 0.129s\n\nFAILED (errors=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 aggregation.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/aggregation/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 56,
          "failed": 0,
          "errors": 0,
          "duration": 8.82,
          "log_tail": "test_annotate_values (aggregation.tests.AggregateTestCase) ... ok\ntest_annotate_values_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_annotate_values_list (aggregation.tests.AggregateTestCase) ... ok\ntest_annotated_aggregate_over_annotated_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_annotation (aggregation.tests.AggregateTestCase) ... ok\ntest_annotation_expressions (aggregation.tests.AggregateTestCase) ... ok\ntest_arguments_must_be_expressions (aggregation.tests.AggregateTestCase) ... ok\ntest_avg_decimal_field (aggregation.tests.AggregateTestCase) ... ok\ntest_avg_duration_field (aggregation.tests.AggregateTestCase) ... ok\ntest_backwards_m2m_annotate (aggregation.tests.AggregateTestCase) ... ok\ntest_combine_different_types (aggregation.tests.AggregateTestCase) ... ok\ntest_complex_aggregations_require_kwarg (aggregation.tests.AggregateTestCase) ... ok\ntest_complex_values_aggregation (aggregation.tests.AggregateTestCase) ... ok\ntest_count (aggregation.tests.AggregateTestCase) ... ok\ntest_count_distinct_expression (aggregation.tests.AggregateTestCase) ... ok\ntest_count_star (aggregation.tests.AggregateTestCase) ... ok\ntest_dates_with_aggregation (aggregation.tests.AggregateTestCase) ... ok\ntest_decimal_max_digits_has_no_effect (aggregation.tests.AggregateTestCase) ... ok\ntest_empty_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_even_more_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_expression_on_aggregation (aggregation.tests.AggregateTestCase) ... ok\ntest_filter_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_filtering (aggregation.tests.AggregateTestCase) ... ok\ntest_fkey_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_grouped_annotation_in_group_by (aggregation.tests.AggregateTestCase) ... ok\ntest_missing_output_field_raises_error (aggregation.tests.AggregateTestCase) ... ok\ntest_more_aggregation (aggregation.tests.AggregateTestCase) ... ok\ntest_multi_arg_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_multiple_aggregates (aggregation.tests.AggregateTestCase) ... ok\ntest_non_grouped_annotation_not_in_group_by (aggregation.tests.AggregateTestCase) ... ok\ntest_nonaggregate_aggregation_throws (aggregation.tests.AggregateTestCase) ... ok\ntest_nonfield_annotation (aggregation.tests.AggregateTestCase) ... ok\ntest_order_of_precedence (aggregation.tests.AggregateTestCase) ... ok\ntest_related_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_reverse_fkey_annotate (aggregation.tests.AggregateTestCase) ... ok\ntest_single_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_sum_distinct_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_sum_duration_field (aggregation.tests.AggregateTestCase) ... ok\ntest_ticket11881 (aggregation.tests.AggregateTestCase) ... ok\ntest_ticket12886 (aggregation.tests.AggregateTestCase) ... ok\ntest_ticket17424 (aggregation.tests.AggregateTestCase) ... ok\ntest_values_aggregation (aggregation.tests.AggregateTestCase) ... ok\ntest_values_annotation_with_expression (aggregation.tests.AggregateTestCase) ... ok\n\n----------------------------------------------------------------------\nRan 56 tests in 0.116s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\n",
          "test_files_run": [
            "tests/aggregation/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-10914",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 29.65796184539795,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 99,
          "failed": 1,
          "errors": 0,
          "duration": 9.47,
          "log_tail": "test_not_used (test_utils.tests.AssertTemplateUsedContextManagerTests) ... ok\ntest_usage (test_utils.tests.AssertTemplateUsedContextManagerTests) ... ok\n\n======================================================================\nFAIL: test_override_file_upload_permissions (test_utils.tests.OverrideSettingsTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/test_utils/tests.py\", line 1102, in test_override_file_upload_permissions\n    self.assertEqual(default_storage.file_permissions_mode, 0o644)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 822, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: None != 420\n\n----------------------------------------------------------------------\nRan 100 tests in 0.291s\n\nFAILED (failures=1, skipped=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 test_utils.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/test_utils/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 100,
          "failed": 0,
          "errors": 0,
          "duration": 8.29,
          "log_tail": "test_urlconf_cache (test_utils.tests.OverrideSettingsTests) ... ok\ntest_urlconf_first (test_utils.tests.OverrideSettingsTests) ... ok\ntest_urlconf_second (test_utils.tests.OverrideSettingsTests) ... ok\ntest_assert_num_queries (test_utils.tests.AssertNumQueriesTests) ... ok\ntest_assert_num_queries_with_client (test_utils.tests.AssertNumQueriesTests) ... ok\ntest_failure (test_utils.tests.AssertNumQueriesContextManagerTests) ... ok\ntest_simple (test_utils.tests.AssertNumQueriesContextManagerTests) ... ok\ntest_with_client (test_utils.tests.AssertNumQueriesContextManagerTests) ... ok\ntest_assert_used_on_http_response (test_utils.tests.AssertTemplateUsedContextManagerTests) ... ok\ntest_error_message (test_utils.tests.AssertTemplateUsedContextManagerTests) ... ok\ntest_failure (test_utils.tests.AssertTemplateUsedContextManagerTests) ... ok\ntest_nested_usage (test_utils.tests.AssertTemplateUsedContextManagerTests) ... ok\ntest_not_used (test_utils.tests.AssertTemplateUsedContextManagerTests) ... ok\ntest_usage (test_utils.tests.AssertTemplateUsedContextManagerTests) ... ok\ntest_failure (test_utils.tests.CaptureQueriesContextManagerTests) ... ok\ntest_nested (test_utils.tests.CaptureQueriesContextManagerTests) ... ok\ntest_simple (test_utils.tests.CaptureQueriesContextManagerTests) ... ok\ntest_with_client (test_utils.tests.CaptureQueriesContextManagerTests) ... ok\ntest_within (test_utils.tests.CaptureQueriesContextManagerTests) ... ok\n\n----------------------------------------------------------------------\nRan 100 tests in 0.300s\n\nOK (skipped=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')\u2026\n",
          "test_files_run": [
            "tests/test_utils/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-10973",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 22.361262798309326,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 5,
          "duration": 7.77,
          "log_tail": "    restore_signals, start_new_session)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/subprocess.py\", line 1364, in _execute_child\n    raise child_exception_type(errno_num, err_msg, err_filename)\nFileNotFoundError: [Errno 2] No such file or directory: 'psql': 'psql'\n\n======================================================================\nERROR: test_nopass (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/dbshell/test_postgresql.py\", line 47, in test_nopass\n    'port': '444',\n  File \"/testbed/tests/dbshell/test_postgresql.py\", line 24, in _run_it\n    DatabaseClient.runshell_db(dbinfo)\n  File \"/testbed/django/db/backends/postgresql/client.py\", line 61, in runshell_db\n    subprocess.check_call(args)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/subprocess.py\", line 306, in check_call\n    retcode = call(*popenargs, **kwargs)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/subprocess.py\", line 287, in call\n    with Popen(*popenargs, **kwargs) as p:\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/subprocess.py\", line 729, in __init__\n    restore_signals, start_new_session)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/subprocess.py\", line 1364, in _execute_child\n    raise child_exception_type(errno_num, err_msg, err_filename)\nFileNotFoundError: [Errno 2] No such file or directory: 'psql': 'psql'\n\n======================================================================\nERROR: test_sigint_handler (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase)\nSIGINT is ignored in Python and passed to psql to abort quries.\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/dbshell/test_postgresql.py\", line 94, in test_sigint_handler\n    DatabaseClient.runshell_db({})\n  File \"/testbed/django/db/backends/postgresql/client.py\", line 61, in runshell_db\n    subprocess.check_call(args)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/subprocess.py\", line 306, in check_call\n    retcode = call(*popenargs, **kwargs)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/subprocess.py\", line 287, in call\n    with Popen(*popenargs, **kwargs) as p:\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/subprocess.py\", line 729, in __init__\n    restore_signals, start_new_session)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/subprocess.py\", line 1364, in _execute_child\n    raise child_exception_type(errno_num, err_msg, err_filename)\nFileNotFoundError: [Errno 2] No such file or directory: 'psql': 'psql'\n\n----------------------------------------------------------------------\nRan 5 tests in 0.027s\n\nFAILED (errors=5)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 dbshell.test_postgresql` failed. (See above for error)",
          "test_files_run": [
            "tests/dbshell/test_postgresql.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 5,
          "failed": 0,
          "errors": 0,
          "duration": 6.32,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application dbshell\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_accent (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase) ... ok\ntest_basic (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase) ... ok\ntest_column (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase) ... ok\ntest_nopass (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase) ... ok\ntest_sigint_handler (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase)\nSIGINT is ignored in Python and passed to psql to abort quries. ... ok\n\n----------------------------------------------------------------------\nRan 5 tests in 0.003s\n\nOK\n",
          "test_files_run": [
            "tests/dbshell/test_postgresql.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-10999",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 28.479103088378906,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 7,
          "failed": 5,
          "errors": 0,
          "duration": 9.46,
          "log_tail": "  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 523, in subTest\n    yield\n  File \"/testbed/tests/utils_tests/test_dateparse.py\", line 125, in test_negative\n    self.assertEqual(parse_duration(source), expected)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 822, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: datetime.timedelta(0, 61) != datetime.timedelta(-1, 86339)\n\n======================================================================\nFAIL: test_negative (utils_tests.test_dateparse.DurationParseTests) [<object object at 0x709514b4ca50>] (source='-01:01')\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 523, in subTest\n    yield\n  File \"/testbed/tests/utils_tests/test_dateparse.py\", line 125, in test_negative\n    self.assertEqual(parse_duration(source), expected)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 822, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: datetime.timedelta(-1, 86341) != datetime.timedelta(-1, 86339)\n\n======================================================================\nFAIL: test_negative (utils_tests.test_dateparse.DurationParseTests) [<object object at 0x709514b4ca50>] (source='-01:-01')\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 523, in subTest\n    yield\n  File \"/testbed/tests/utils_tests/test_dateparse.py\", line 125, in test_negative\n    self.assertEqual(parse_duration(source), expected)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 822, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: datetime.timedelta(-1, 86339) != None\n\n----------------------------------------------------------------------\nRan 12 tests in 0.297s\n\nFAILED (failures=5)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 utils_tests.test_dateparse` failed. (See above for error)",
          "test_files_run": [
            "tests/utils_tests/test_dateparse.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 12,
          "failed": 0,
          "errors": 0,
          "duration": 7.41,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application utils_tests\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_days (utils_tests.test_dateparse.DurationParseTests) ... ok\ntest_fractions_of_seconds (utils_tests.test_dateparse.DurationParseTests) ... ok\ntest_hours_minutes_seconds (utils_tests.test_dateparse.DurationParseTests) ... ok\ntest_iso_8601 (utils_tests.test_dateparse.DurationParseTests) ... ok\ntest_minutes_seconds (utils_tests.test_dateparse.DurationParseTests) ... ok\ntest_negative (utils_tests.test_dateparse.DurationParseTests) ... ok\ntest_parse_postgresql_format (utils_tests.test_dateparse.DurationParseTests) ... ok\ntest_parse_python_format (utils_tests.test_dateparse.DurationParseTests) ... ok\ntest_seconds (utils_tests.test_dateparse.DurationParseTests) ... ok\ntest_parse_date (utils_tests.test_dateparse.DateParseTests) ... ok\ntest_parse_datetime (utils_tests.test_dateparse.DateParseTests) ... ok\ntest_parse_time (utils_tests.test_dateparse.DateParseTests) ... ok\n\n----------------------------------------------------------------------\nRan 12 tests in 0.244s\n\nOK\n",
          "test_files_run": [
            "tests/utils_tests/test_dateparse.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-11066",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 30.3261079788208,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 3,
          "failed": 1,
          "errors": 0,
          "duration": 9.41,
          "log_tail": "    Creating table auth_user\n    Creating table django_session\n    Creating table contenttypes_tests_site\n    Creating table contenttypes_tests_author\n    Creating table contenttypes_tests_article\n    Creating table contenttypes_tests_schemeincludedurl\n    Creating table contenttypes_tests_concretemodel\n    Creating table contenttypes_tests_foowithouturl\n    Creating table contenttypes_tests_foowithurl\n    Creating table contenttypes_tests_foowithbrokenabsoluteurl\n    Creating table contenttypes_tests_question\n    Creating table contenttypes_tests_answer\n    Creating table contenttypes_tests_post\n    Creating table contenttypes_tests_modelwithnullfktosite\n    Creating table contenttypes_tests_modelwithm2mtosite\n    Running deferred SQL...\nRunning migrations:\n  Applying admin.0001_initial... OK\n  Applying admin.0002_logentry_remove_auto_add... OK\n  Applying admin.0003_logentry_add_action_flag_choices... OK\n  Applying sites.0001_initial... OK\n  Applying sites.0002_alter_domain_unique... OK\nSystem check identified no issues (0 silenced).\n\n\nCreating test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCreating test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\ntest_content_type_rename_conflict (contenttypes_tests.test_operations.ContentTypeOperationsTests) ... ok\ntest_existing_content_type_rename (contenttypes_tests.test_operations.ContentTypeOperationsTests) ... ok\ntest_existing_content_type_rename_other_database (contenttypes_tests.test_operations.ContentTypeOperationsTests) ... FAIL\ntest_missing_content_type_rename_ignore (contenttypes_tests.test_operations.ContentTypeOperationsTests) ... ok\n\n======================================================================\nFAIL: test_existing_content_type_rename_other_database (contenttypes_tests.test_operations.ContentTypeOperationsTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/django/test/utils.py\", line 370, in inner\n    return func(*args, **kwargs)\n  File \"/testbed/tests/contenttypes_tests/test_operations.py\", line 60, in test_existing_content_type_rename_other_database\n    self.assertFalse(other_content_types.filter(model='foo').exists())\nAssertionError: True is not false\n\n----------------------------------------------------------------------\nRan 4 tests in 0.206s\n\nFAILED (failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 contenttypes_tests.test_operations` failed. (See above for error)",
          "test_files_run": [
            "tests/contenttypes_tests/test_operations.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 4,
          "failed": 0,
          "errors": 0,
          "duration": 8.93,
          "log_tail": "  Applying admin.0003_logentry_add_action_flag_choices... OK\n  Applying sites.0001_initial... OK\n  Applying sites.0002_alter_domain_unique... OK\nOperations to perform:\n  Synchronize unmigrated apps: auth, contenttypes, contenttypes_tests, messages, sessions, staticfiles\n  Apply all migrations: admin, sites\nSynchronizing apps without migrations:\n  Creating tables...\n    Creating table django_content_type\n    Creating table auth_permission\n    Creating table auth_group\n    Creating table auth_user\n    Creating table django_session\n    Creating table contenttypes_tests_site\n    Creating table contenttypes_tests_author\n    Creating table contenttypes_tests_article\n    Creating table contenttypes_tests_schemeincludedurl\n    Creating table contenttypes_tests_concretemodel\n    Creating table contenttypes_tests_foowithouturl\n    Creating table contenttypes_tests_foowithurl\n    Creating table contenttypes_tests_foowithbrokenabsoluteurl\n    Creating table contenttypes_tests_question\n    Creating table contenttypes_tests_answer\n    Creating table contenttypes_tests_post\n    Creating table contenttypes_tests_modelwithnullfktosite\n    Creating table contenttypes_tests_modelwithm2mtosite\n    Running deferred SQL...\nRunning migrations:\n  Applying admin.0001_initial... OK\n  Applying admin.0002_logentry_remove_auto_add... OK\n  Applying admin.0003_logentry_add_action_flag_choices... OK\n  Applying sites.0001_initial... OK\n  Applying sites.0002_alter_domain_unique... OK\nSystem check identified no issues (0 silenced).\n\n\nCreating test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCreating test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\ntest_content_type_rename_conflict (contenttypes_tests.test_operations.ContentTypeOperationsTests) ... ok\ntest_existing_content_type_rename (contenttypes_tests.test_operations.ContentTypeOperationsTests) ... ok\ntest_existing_content_type_rename_other_database (contenttypes_tests.test_operations.ContentTypeOperationsTests) ... ok\ntest_missing_content_type_rename_ignore (contenttypes_tests.test_operations.ContentTypeOperationsTests) ... ok\n\n----------------------------------------------------------------------\nRan 4 tests in 0.250s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/contenttypes_tests/test_operations.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-11087",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 30.482924938201904,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 42,
          "failed": 1,
          "errors": 0,
          "duration": 9.36,
          "log_tail": "test_bulk (delete.tests.DeletionTests) ... ok\ntest_can_defer_constraint_checks (delete.tests.DeletionTests) ... ok\ntest_cannot_defer_constraint_checks (delete.tests.DeletionTests) ... skipped 'Database has feature(s) can_defer_constraint_checks'\ntest_delete_with_keeping_parents (delete.tests.DeletionTests) ... ok\ntest_delete_with_keeping_parents_relationships (delete.tests.DeletionTests) ... ok\ntest_deletion_order (delete.tests.DeletionTests) ... ok\ntest_hidden_related (delete.tests.DeletionTests) ... ok\ntest_instance_update (delete.tests.DeletionTests) ... ok\ntest_large_delete (delete.tests.DeletionTests) ... ok\ntest_large_delete_related (delete.tests.DeletionTests) ... ok\ntest_m2m (delete.tests.DeletionTests) ... ok\ntest_model_delete_returns_num_rows (delete.tests.DeletionTests) ... ok\ntest_only_referenced_fields_selected (delete.tests.DeletionTests) ... FAIL\ntest_proxied_model_duplicate_queries (delete.tests.DeletionTests) ... ok\ntest_queryset_delete_returns_num_rows (delete.tests.DeletionTests) ... ok\ntest_relational_post_delete_signals_happen_before_parent_object (delete.tests.DeletionTests) ... ok\n\n======================================================================\nFAIL: test_only_referenced_fields_selected (delete.tests.DeletionTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/delete/tests.py\", line 455, in test_only_referenced_fields_selected\n    self.assertEqual(ctx.captured_queries[0]['sql'], expected_sql)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1203, in assertMultiLineEqual\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: 'SELE[41 chars]er\".\"origin_id\", \"delete_referrer\".\"unique_fie[98 chars] (1)' != 'SELE[41 chars]er\".\"unique_field\" FROM \"delete_referrer\" WHER[34 chars] (1)'\n- SELECT \"delete_referrer\".\"id\", \"delete_referrer\".\"origin_id\", \"delete_referrer\".\"unique_field\", \"delete_referrer\".\"large_field\" FROM \"delete_referrer\" WHERE \"delete_referrer\".\"origin_id\" IN (1)\n?                               -------------------------------                                 ^                  -------------------------------------\n+ SELECT \"delete_referrer\".\"id\", \"delete_referrer\".\"unique_field\" FROM \"delete_referrer\" WHERE \"delete_referrer\".\"origin_id\" IN (1)\n?                                                                ^^^^^\n\n\n----------------------------------------------------------------------\nRan 43 tests in 0.870s\n\nFAILED (failures=1, skipped=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 delete.models delete.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/delete/models.py",
            "tests/delete/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 43,
          "failed": 0,
          "errors": 0,
          "duration": 9.01,
          "log_tail": "test_fast_delete_instance_set_pk_none (delete.tests.FastDeleteTests) ... ok\ntest_fast_delete_joined_qs (delete.tests.FastDeleteTests) ... ok\ntest_fast_delete_large_batch (delete.tests.FastDeleteTests) ... ok\ntest_fast_delete_m2m (delete.tests.FastDeleteTests) ... ok\ntest_fast_delete_qs (delete.tests.FastDeleteTests) ... ok\ntest_fast_delete_revm2m (delete.tests.FastDeleteTests) ... ok\ntest_auto (delete.tests.OnDeleteTests) ... ok\ntest_auto_nullable (delete.tests.OnDeleteTests) ... ok\ntest_cascade (delete.tests.OnDeleteTests) ... ok\ntest_cascade_from_child (delete.tests.OnDeleteTests) ... ok\ntest_cascade_from_parent (delete.tests.OnDeleteTests) ... ok\ntest_cascade_nullable (delete.tests.OnDeleteTests) ... ok\ntest_do_nothing (delete.tests.OnDeleteTests) ... ok\ntest_do_nothing_qscount (delete.tests.OnDeleteTests) ... ok\ntest_inheritance_cascade_down (delete.tests.OnDeleteTests) ... ok\ntest_inheritance_cascade_up (delete.tests.OnDeleteTests) ... ok\ntest_o2o_setnull (delete.tests.OnDeleteTests) ... ok\ntest_protect (delete.tests.OnDeleteTests) ... ok\ntest_setdefault (delete.tests.OnDeleteTests) ... ok\ntest_setdefault_none (delete.tests.OnDeleteTests) ... ok\ntest_setnull (delete.tests.OnDeleteTests) ... ok\ntest_setnull_from_child (delete.tests.OnDeleteTests) ... ok\ntest_setnull_from_parent (delete.tests.OnDeleteTests) ... ok\ntest_setvalue (delete.tests.OnDeleteTests) ... ok\ntest_bulk (delete.tests.DeletionTests) ... ok\ntest_can_defer_constraint_checks (delete.tests.DeletionTests) ... ok\ntest_cannot_defer_constraint_checks (delete.tests.DeletionTests) ... skipped 'Database has feature(s) can_defer_constraint_checks'\ntest_delete_with_keeping_parents (delete.tests.DeletionTests) ... ok\ntest_delete_with_keeping_parents_relationships (delete.tests.DeletionTests) ... ok\ntest_deletion_order (delete.tests.DeletionTests) ... ok\ntest_hidden_related (delete.tests.DeletionTests) ... ok\ntest_instance_update (delete.tests.DeletionTests) ... ok\ntest_large_delete (delete.tests.DeletionTests) ... ok\ntest_large_delete_related (delete.tests.DeletionTests) ... ok\ntest_m2m (delete.tests.DeletionTests) ... ok\ntest_model_delete_returns_num_rows (delete.tests.DeletionTests) ... ok\ntest_only_referenced_fields_selected (delete.tests.DeletionTests) ... ok\ntest_proxied_model_duplicate_queries (delete.tests.DeletionTests) ... ok\ntest_queryset_delete_returns_num_rows (delete.tests.DeletionTests) ... ok\ntest_relational_post_delete_signals_happen_before_parent_object (delete.tests.DeletionTests) ... ok\n\n----------------------------------------------------------------------\nRan 43 tests in 0.963s\n\nOK (skipped=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/delete/models.py",
            "tests/delete/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-11095",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 30.442397117614746,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 19,
          "failed": 1,
          "errors": 0,
          "duration": 9.28,
          "log_tail": "test_max_num_param (generic_inline_admin.tests.GenericInlineAdminParametersTest) ... ok\ntest_min_num_param (generic_inline_admin.tests.GenericInlineAdminParametersTest) ... ok\ntest_no_param (generic_inline_admin.tests.GenericInlineAdminParametersTest) ... ok\ntest_add (generic_inline_admin.tests.GenericInlineAdminWithUniqueTogetherTest) ... ok\ntest_delete (generic_inline_admin.tests.GenericInlineAdminWithUniqueTogetherTest) ... ok\ntest_basic_add_GET (generic_inline_admin.tests.GenericAdminViewTest) ... ok\ntest_basic_add_POST (generic_inline_admin.tests.GenericAdminViewTest) ... ok\ntest_basic_edit_GET (generic_inline_admin.tests.GenericAdminViewTest) ... ok\ntest_basic_edit_POST (generic_inline_admin.tests.GenericAdminViewTest) ... ok\n\n======================================================================\nFAIL: test_get_inline_instances_override_get_inlines (generic_inline_admin.tests.GenericInlineModelAdminTest)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/generic_inline_admin/tests.py\", line 453, in test_get_inline_instances_override_get_inlines\n    self.assertEqual(ma.get_inline_instances(request), [])\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1028, in assertListEqual\n    self.assertSequenceEqual(list1, list2, msg, seq_type=list)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1010, in assertSequenceEqual\n    self.fail(msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: Lists differ: [<generic_inline_admin.tests.GenericInline[259 chars]d30>] != []\n\nFirst list contains 2 additional elements.\nFirst extra element 0:\n<generic_inline_admin.tests.GenericInlineModelAdminTest.test_get_inline_instances_override_get_inlines.<locals>.AlternateInline object at 0x75ece0129cf8>\n\n+ []\n- [<generic_inline_admin.tests.GenericInlineModelAdminTest.test_get_inline_instances_override_get_inlines.<locals>.AlternateInline object at 0x75ece0129cf8>,\n-  <generic_inline_admin.tests.GenericInlineModelAdminTest.test_get_inline_instances_override_get_inlines.<locals>.MediaInline object at 0x75ece0129d30>]\n\n----------------------------------------------------------------------\nRan 20 tests in 0.580s\n\nFAILED (failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 generic_inline_admin.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/generic_inline_admin/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 20,
          "failed": 0,
          "errors": 0,
          "duration": 9.12,
          "log_tail": "    Creating table generic_inline_admin_contact\n    Creating table generic_inline_admin_episodepermanent\n    Running deferred SQL...\nRunning migrations:\n  Applying admin.0001_initial... OK\n  Applying admin.0002_logentry_remove_auto_add... OK\n  Applying admin.0003_logentry_add_action_flag_choices... OK\n  Applying sites.0001_initial... OK\n  Applying sites.0002_alter_domain_unique... OK\nSystem check identified no issues (0 silenced).\n\n\nCreating test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\ntest_no_deletion (generic_inline_admin.tests.NoInlineDeletionTest) ... ok\ntest_custom_form_meta_exclude (generic_inline_admin.tests.GenericInlineModelAdminTest) ... ok\ntest_custom_form_meta_exclude_with_readonly (generic_inline_admin.tests.GenericInlineModelAdminTest) ... ok\ntest_get_fieldsets (generic_inline_admin.tests.GenericInlineModelAdminTest) ... ok\ntest_get_formset_kwargs (generic_inline_admin.tests.GenericInlineModelAdminTest) ... ok\ntest_get_formsets_with_inlines_returns_tuples (generic_inline_admin.tests.GenericInlineModelAdminTest) ... ok\ntest_get_inline_instances_override_get_inlines (generic_inline_admin.tests.GenericInlineModelAdminTest) ... ok\ntest_add (generic_inline_admin.tests.GenericInlineAdminWithUniqueTogetherTest) ... ok\ntest_delete (generic_inline_admin.tests.GenericInlineAdminWithUniqueTogetherTest) ... ok\ntest_extra_param (generic_inline_admin.tests.GenericInlineAdminParametersTest) ... ok\ntest_get_extra (generic_inline_admin.tests.GenericInlineAdminParametersTest) ... ok\ntest_get_max_num (generic_inline_admin.tests.GenericInlineAdminParametersTest) ... ok\ntest_get_min_num (generic_inline_admin.tests.GenericInlineAdminParametersTest) ... ok\ntest_max_num_param (generic_inline_admin.tests.GenericInlineAdminParametersTest) ... ok\ntest_min_num_param (generic_inline_admin.tests.GenericInlineAdminParametersTest) ... ok\ntest_no_param (generic_inline_admin.tests.GenericInlineAdminParametersTest) ... ok\ntest_basic_add_GET (generic_inline_admin.tests.GenericAdminViewTest) ... ok\ntest_basic_add_POST (generic_inline_admin.tests.GenericAdminViewTest) ... ok\ntest_basic_edit_GET (generic_inline_admin.tests.GenericAdminViewTest) ... ok\ntest_basic_edit_POST (generic_inline_admin.tests.GenericAdminViewTest) ... ok\n\n----------------------------------------------------------------------\nRan 20 tests in 0.596s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/generic_inline_admin/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-11099",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 28.709994077682495,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 20,
          "failed": 2,
          "errors": 0,
          "duration": 8.76,
          "log_tail": "test_help_text (auth_tests.test_validators.CommonPasswordValidatorTest) ... ok\ntest_validate (auth_tests.test_validators.CommonPasswordValidatorTest) ... ok\ntest_validate_custom_list (auth_tests.test_validators.CommonPasswordValidatorTest) ... ok\ntest_validate_django_supplied_file (auth_tests.test_validators.CommonPasswordValidatorTest) ... ok\n\n======================================================================\nFAIL: test_ascii_validator (auth_tests.test_validators.UsernameValidatorsTests) [<object object at 0x7fbf459c0b50>] (invalid='trailingnewline\\n')\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 523, in subTest\n    yield\n  File \"/testbed/tests/auth_tests/test_validators.py\", line 261, in test_ascii_validator\n    v(invalid)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 203, in __exit__\n    self._raiseFailure(\"{} not raised\".format(exc_name))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 135, in _raiseFailure\n    raise self.test_case.failureException(msg)\nAssertionError: ValidationError not raised\n\n======================================================================\nFAIL: test_unicode_validator (auth_tests.test_validators.UsernameValidatorsTests) [<object object at 0x7fbf459c0b50>] (invalid='trailingnewline\\n')\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 523, in subTest\n    yield\n  File \"/testbed/tests/auth_tests/test_validators.py\", line 249, in test_unicode_validator\n    v(invalid)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 203, in __exit__\n    self._raiseFailure(\"{} not raised\".format(exc_name))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 135, in _raiseFailure\n    raise self.test_case.failureException(msg)\nAssertionError: ValidationError not raised\n\n----------------------------------------------------------------------\nRan 22 tests in 0.253s\n\nFAILED (failures=2)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 auth_tests.test_validators` failed. (See above for error)",
          "test_files_run": [
            "tests/auth_tests/test_validators.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 22,
          "failed": 0,
          "errors": 0,
          "duration": 8.22,
          "log_tail": "  Applying admin.0001_initial... OK\n  Applying admin.0002_logentry_remove_auto_add... OK\n  Applying admin.0003_logentry_add_action_flag_choices... OK\n  Applying sites.0001_initial... OK\n  Applying sites.0002_alter_domain_unique... OK\nSystem check identified no issues (0 silenced).\n\n\nCreating test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\ntest_help_text (auth_tests.test_validators.NumericPasswordValidatorTest) ... ok\ntest_validate (auth_tests.test_validators.NumericPasswordValidatorTest) ... ok\ntest_help_text (auth_tests.test_validators.MinimumLengthValidatorTest) ... ok\ntest_validate (auth_tests.test_validators.MinimumLengthValidatorTest) ... ok\ntest_ascii_validator (auth_tests.test_validators.UsernameValidatorsTests) ... ok\ntest_unicode_validator (auth_tests.test_validators.UsernameValidatorsTests) ... ok\ntest_help_text (auth_tests.test_validators.UserAttributeSimilarityValidatorTest) ... ok\ntest_validate (auth_tests.test_validators.UserAttributeSimilarityValidatorTest) ... ok\ntest_validate_property (auth_tests.test_validators.UserAttributeSimilarityValidatorTest) ... ok\ntest_empty_password_validator_help_text_html (auth_tests.test_validators.PasswordValidationTest) ... ok\ntest_get_default_password_validators (auth_tests.test_validators.PasswordValidationTest) ... ok\ntest_get_password_validators_custom (auth_tests.test_validators.PasswordValidationTest) ... ok\ntest_password_changed (auth_tests.test_validators.PasswordValidationTest) ... ok\ntest_password_changed_with_custom_validator (auth_tests.test_validators.PasswordValidationTest) ... ok\ntest_password_validators_help_text_html (auth_tests.test_validators.PasswordValidationTest) ... ok\ntest_password_validators_help_text_html_escaping (auth_tests.test_validators.PasswordValidationTest) ... ok\ntest_password_validators_help_texts (auth_tests.test_validators.PasswordValidationTest) ... ok\ntest_validate_password (auth_tests.test_validators.PasswordValidationTest) ... ok\ntest_help_text (auth_tests.test_validators.CommonPasswordValidatorTest) ... ok\ntest_validate (auth_tests.test_validators.CommonPasswordValidatorTest) ... ok\ntest_validate_custom_list (auth_tests.test_validators.CommonPasswordValidatorTest) ... ok\ntest_validate_django_supplied_file (auth_tests.test_validators.CommonPasswordValidatorTest) ... ok\n\n----------------------------------------------------------------------\nRan 22 tests in 0.243s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/auth_tests/test_validators.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-11119",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 29.057082891464233,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 7,
          "failed": 1,
          "errors": 0,
          "duration": 8.98,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application template_tests\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_cached_loader_priority (template_tests.test_engine.LoaderTests) ... ok\ntest_loader_priority (template_tests.test_engine.LoaderTests) ... ok\ntest_origin (template_tests.test_engine.LoaderTests) ... ok\ntest_autoescape_off (template_tests.test_engine.RenderToStringTest) ... FAIL\ntest_basic_context (template_tests.test_engine.RenderToStringTest) ... ok\ntest_multiple_engines_configured (template_tests.test_engine.GetDefaultTests) ... ok\ntest_no_engines_configured (template_tests.test_engine.GetDefaultTests) ... ok\ntest_single_engine_configured (template_tests.test_engine.GetDefaultTests) ... ok\n\n======================================================================\nFAIL: test_autoescape_off (template_tests.test_engine.RenderToStringTest)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/template_tests/test_engine.py\", line 28, in test_autoescape_off\n    'obj:<script>\\n',\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 822, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: 'obj:&lt;script&gt;\\n' != 'obj:<script>\\n'\n\n----------------------------------------------------------------------\nRan 8 tests in 0.276s\n\nFAILED (failures=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 template_tests.test_engine` failed. (See above for error)",
          "test_files_run": [
            "tests/template_tests/test_engine.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 8,
          "failed": 0,
          "errors": 0,
          "duration": 8.52,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application template_tests\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_autoescape_off (template_tests.test_engine.RenderToStringTest) ... ok\ntest_basic_context (template_tests.test_engine.RenderToStringTest) ... ok\ntest_cached_loader_priority (template_tests.test_engine.LoaderTests) ... ok\ntest_loader_priority (template_tests.test_engine.LoaderTests) ... ok\ntest_origin (template_tests.test_engine.LoaderTests) ... ok\ntest_multiple_engines_configured (template_tests.test_engine.GetDefaultTests) ... ok\ntest_no_engines_configured (template_tests.test_engine.GetDefaultTests) ... ok\ntest_single_engine_configured (template_tests.test_engine.GetDefaultTests) ... ok\n\n----------------------------------------------------------------------\nRan 8 tests in 0.239s\n\nOK\n",
          "test_files_run": [
            "tests/template_tests/test_engine.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-11133",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 22.277318000793457,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 64,
          "failed": 1,
          "errors": 0,
          "duration": 7.04,
          "log_tail": "test_multiple_keys (httpwrappers.tests.QueryDictTests)\nTest QueryDict with two key/value pairs with same keys. ... ok\ntest_mutable_copy (httpwrappers.tests.QueryDictTests)\nA copy of a QueryDict is mutable. ... ok\ntest_mutable_delete (httpwrappers.tests.QueryDictTests) ... ok\ntest_non_default_encoding (httpwrappers.tests.QueryDictTests)\n#13572 - QueryDict with a non-default encoding ... ok\ntest_pickle (httpwrappers.tests.QueryDictTests) ... ok\ntest_querydict_fromkeys (httpwrappers.tests.QueryDictTests) ... ok\ntest_single_key_value (httpwrappers.tests.QueryDictTests)\nTest QueryDict with one key/value pair ... ok\ntest_update_from_querydict (httpwrappers.tests.QueryDictTests)\nRegression test for #8278: QueryDict.update(QueryDict) ... ok\ntest_urlencode (httpwrappers.tests.QueryDictTests) ... ok\ntest_urlencode_int (httpwrappers.tests.QueryDictTests) ... ok\ntest_dict_behavior (httpwrappers.tests.HttpResponseTests) ... ok\ntest_file_interface (httpwrappers.tests.HttpResponseTests) ... ok\ntest_headers_type (httpwrappers.tests.HttpResponseTests) ... ok\ntest_iter_content (httpwrappers.tests.HttpResponseTests) ... ok\ntest_iterator_isnt_rewound (httpwrappers.tests.HttpResponseTests) ... ok\ntest_lazy_content (httpwrappers.tests.HttpResponseTests) ... ok\ntest_long_line (httpwrappers.tests.HttpResponseTests) ... ok\ntest_memoryview_content (httpwrappers.tests.HttpResponseTests) ... FAIL\ntest_newlines_in_headers (httpwrappers.tests.HttpResponseTests) ... ok\ntest_non_string_content (httpwrappers.tests.HttpResponseTests) ... ok\ntest_stream_interface (httpwrappers.tests.HttpResponseTests) ... ok\ntest_unsafe_redirect (httpwrappers.tests.HttpResponseTests) ... ok\n\n======================================================================\nFAIL: test_memoryview_content (httpwrappers.tests.HttpResponseTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/httpwrappers/tests.py\", line 371, in test_memoryview_content\n    self.assertEqual(r.content, b'memoryview')\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 822, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: b'<memory at 0x792960fd5c48>' != b'memoryview'\n\n----------------------------------------------------------------------\nRan 65 tests in 0.214s\n\nFAILED (failures=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 httpwrappers.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/httpwrappers/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 65,
          "failed": 0,
          "errors": 0,
          "duration": 6.46,
          "log_tail": "test_json_response_passing_arguments_to_json_dumps (httpwrappers.tests.JsonResponseTests) ... ok\ntest_json_response_raises_type_error_with_default_setting (httpwrappers.tests.JsonResponseTests) ... ok\ntest_json_response_text (httpwrappers.tests.JsonResponseTests) ... ok\ntest_json_response_uuid (httpwrappers.tests.JsonResponseTests) ... ok\ntest_dict_behavior (httpwrappers.tests.HttpResponseTests) ... ok\ntest_file_interface (httpwrappers.tests.HttpResponseTests) ... ok\ntest_headers_type (httpwrappers.tests.HttpResponseTests) ... ok\ntest_iter_content (httpwrappers.tests.HttpResponseTests) ... ok\ntest_iterator_isnt_rewound (httpwrappers.tests.HttpResponseTests) ... ok\ntest_lazy_content (httpwrappers.tests.HttpResponseTests) ... ok\ntest_long_line (httpwrappers.tests.HttpResponseTests) ... ok\ntest_memoryview_content (httpwrappers.tests.HttpResponseTests) ... ok\ntest_newlines_in_headers (httpwrappers.tests.HttpResponseTests) ... ok\ntest_non_string_content (httpwrappers.tests.HttpResponseTests) ... ok\ntest_stream_interface (httpwrappers.tests.HttpResponseTests) ... ok\ntest_unsafe_redirect (httpwrappers.tests.HttpResponseTests) ... ok\ntest_basic_mutable_operations (httpwrappers.tests.QueryDictTests) ... ok\ntest_create_with_no_args (httpwrappers.tests.QueryDictTests) ... ok\ntest_duplicates_in_fromkeys_iterable (httpwrappers.tests.QueryDictTests) ... ok\ntest_fromkeys_empty_iterable (httpwrappers.tests.QueryDictTests) ... ok\ntest_fromkeys_is_immutable_by_default (httpwrappers.tests.QueryDictTests) ... ok\ntest_fromkeys_mutable_override (httpwrappers.tests.QueryDictTests) ... ok\ntest_fromkeys_noniterable (httpwrappers.tests.QueryDictTests) ... ok\ntest_fromkeys_with_nondefault_encoding (httpwrappers.tests.QueryDictTests) ... ok\ntest_fromkeys_with_nonempty_value (httpwrappers.tests.QueryDictTests) ... ok\ntest_immutability (httpwrappers.tests.QueryDictTests) ... ok\ntest_immutable_basic_operations (httpwrappers.tests.QueryDictTests) ... ok\ntest_immutable_get_with_default (httpwrappers.tests.QueryDictTests) ... ok\ntest_missing_key (httpwrappers.tests.QueryDictTests) ... ok\ntest_multiple_keys (httpwrappers.tests.QueryDictTests)\nTest QueryDict with two key/value pairs with same keys. ... ok\ntest_mutable_copy (httpwrappers.tests.QueryDictTests)\nA copy of a QueryDict is mutable. ... ok\ntest_mutable_delete (httpwrappers.tests.QueryDictTests) ... ok\ntest_non_default_encoding (httpwrappers.tests.QueryDictTests)\n#13572 - QueryDict with a non-default encoding ... ok\ntest_pickle (httpwrappers.tests.QueryDictTests) ... ok\ntest_querydict_fromkeys (httpwrappers.tests.QueryDictTests) ... ok\ntest_single_key_value (httpwrappers.tests.QueryDictTests)\nTest QueryDict with one key/value pair ... ok\ntest_update_from_querydict (httpwrappers.tests.QueryDictTests)\nRegression test for #8278: QueryDict.update(QueryDict) ... ok\ntest_urlencode (httpwrappers.tests.QueryDictTests) ... ok\ntest_urlencode_int (httpwrappers.tests.QueryDictTests) ... ok\n\n----------------------------------------------------------------------\nRan 65 tests in 0.247s\n\nOK\n",
          "test_files_run": [
            "tests/httpwrappers/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-11138",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "duration": 30.234858989715576,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 80,
          "failed": 4,
          "errors": 0,
          "duration": 9.36,
          "log_tail": "AssertionError: datet[38 chars]zinfo=<UTC>) != datet[38 chars]zinfo=datetime.timezone(datetime.timedelta(0, 25200), '+0700'))\n\n======================================================================\nFAIL: test_aware_datetime_with_microsecond (timezones.tests.SerializationTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/timezones/tests.py\", line 710, in test_aware_datetime_with_microsecond\n    self.assertEqual(obj.dt.replace(tzinfo=UTC), dt)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 822, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: datet[46 chars]zinfo=<UTC>) != datet[46 chars]zinfo=datetime.timezone(datetime.timedelta(0, 25200), '+0700'))\n\n======================================================================\nFAIL: test_query_convert_timezones (timezones.tests.NewDatabaseTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/timezones/tests.py\", line 340, in test_query_convert_timezones\n    self.assertEqual(Event.objects.filter(dt__date=event_datetime.date()).first(), event)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 822, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: None != <Event: Event object (1)>\n\n----------------------------------------------------------------------\nRan 84 tests in 0.446s\n\nFAILED (failures=4, skipped=8)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 timezones.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/timezones/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 81,
          "failed": 3,
          "errors": 0,
          "duration": 9.01,
          "log_tail": "AssertionError: datet[38 chars]zinfo=<UTC>) != datet[38 chars]zinfo=datetime.timezone(datetime.timedelta(0, 10800), '+0300'))\n\n======================================================================\nFAIL: test_aware_datetime_in_other_timezone (timezones.tests.SerializationTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/timezones/tests.py\", line 782, in test_aware_datetime_in_other_timezone\n    self.assertEqual(obj.dt.replace(tzinfo=UTC), dt)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 822, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: datet[38 chars]zinfo=<UTC>) != datet[38 chars]zinfo=datetime.timezone(datetime.timedelta(0, 25200), '+0700'))\n\n======================================================================\nFAIL: test_aware_datetime_with_microsecond (timezones.tests.SerializationTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/timezones/tests.py\", line 710, in test_aware_datetime_with_microsecond\n    self.assertEqual(obj.dt.replace(tzinfo=UTC), dt)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 822, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: datet[46 chars]zinfo=<UTC>) != datet[46 chars]zinfo=datetime.timezone(datetime.timedelta(0, 25200), '+0700'))\n\n----------------------------------------------------------------------\nRan 84 tests in 0.504s\n\nFAILED (failures=3, skipped=8)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 timezones.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/timezones/tests.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "django__django-11141",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 30.74007511138916,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 24,
          "failed": 0,
          "errors": 1,
          "duration": 10.1,
          "log_tail": "test_loading_namespace_package (migrations.test_loader.LoaderTests)\nMigration directories without an __init__.py file are loaded. ... ERROR\ntest_loading_squashed (migrations.test_loader.LoaderTests)\nTests loading a squashed migration ... ok\ntest_loading_squashed_complex (migrations.test_loader.LoaderTests)\nTests loading a complex set of squashed migrations ... ok\ntest_loading_squashed_complex_multi_apps (migrations.test_loader.LoaderTests) ... ok\ntest_loading_squashed_complex_multi_apps_partially_applied (migrations.test_loader.LoaderTests) ... ok\ntest_loading_squashed_erroneous (migrations.test_loader.LoaderTests)\nTests loading a complex but erroneous set of squashed migrations ... ok\ntest_loading_squashed_ref_squashed (migrations.test_loader.LoaderTests)\nTests loading a squashed migration with a new migration referencing it ... ok\ntest_marked_as_migrated (migrations.test_loader.LoaderTests) ... ok\ntest_marked_as_unmigrated (migrations.test_loader.LoaderTests) ... ok\ntest_name_match (migrations.test_loader.LoaderTests)\nTests prefix name matching ... ok\ntest_plan_handles_repeated_migrations (migrations.test_loader.LoaderTests) ... ok\ntest_run_before (migrations.test_loader.LoaderTests) ... ok\n\n======================================================================\nERROR: test_loading_namespace_package (migrations.test_loader.LoaderTests)\nMigration directories without an __init__.py file are loaded.\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/django/test/utils.py\", line 370, in inner\n    return func(*args, **kwargs)\n  File \"/testbed/tests/migrations/test_loader.py\", line 518, in test_loading_namespace_package\n    migration_loader.graph.forwards_plan(('migrations', '0001_initial')),\n  File \"/testbed/django/db/migrations/graph.py\", line 204, in forwards_plan\n    raise NodeNotFoundError(\"Node %r not a valid node\" % (target,), target)\ndjango.db.migrations.exceptions.NodeNotFoundError: Node ('migrations', '0001_initial') not a valid node\n\n----------------------------------------------------------------------\nRan 25 tests in 0.735s\n\nFAILED (errors=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 migrations.test_loader migrations.test_migrations_namespace_package.0001_initial` failed. (See above for error)",
          "test_files_run": [
            "tests/migrations/test_loader.py",
            "tests/migrations/test_migrations_namespace_package/0001_initial.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 25,
          "failed": 0,
          "errors": 0,
          "duration": 8.17,
          "log_tail": "Creating test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nCloning test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nCloning test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nCloning test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\ntest_apply (migrations.test_loader.RecorderTests) ... ok\ntest_invalid (migrations.test_loader.PycLoaderTests) ... ok\ntest_valid (migrations.test_loader.PycLoaderTests) ... ok\ntest_check_consistent_history (migrations.test_loader.LoaderTests) ... ok\ntest_check_consistent_history_squashed (migrations.test_loader.LoaderTests) ... ok\ntest_explicit_missing_module (migrations.test_loader.LoaderTests) ... ok\ntest_first (migrations.test_loader.LoaderTests) ... ok\ntest_ignore_files (migrations.test_loader.LoaderTests)\nFiles prefixed with underscore, tilde, or dot aren't loaded. ... ok\ntest_load (migrations.test_loader.LoaderTests) ... ok\ntest_load_empty_dir (migrations.test_loader.LoaderTests) ... ok\ntest_load_import_error (migrations.test_loader.LoaderTests) ... ok\ntest_load_module_file (migrations.test_loader.LoaderTests) ... ok\ntest_load_unmigrated_dependency (migrations.test_loader.LoaderTests) ... ok\ntest_loading_namespace_package (migrations.test_loader.LoaderTests)\nMigration directories without an __init__.py file are loaded. ... ok\ntest_loading_squashed (migrations.test_loader.LoaderTests)\nTests loading a squashed migration ... ok\ntest_loading_squashed_complex (migrations.test_loader.LoaderTests)\nTests loading a complex set of squashed migrations ... ok\ntest_loading_squashed_complex_multi_apps (migrations.test_loader.LoaderTests) ... ok\ntest_loading_squashed_complex_multi_apps_partially_applied (migrations.test_loader.LoaderTests) ... ok\ntest_loading_squashed_erroneous (migrations.test_loader.LoaderTests)\nTests loading a complex but erroneous set of squashed migrations ... ok\ntest_loading_squashed_ref_squashed (migrations.test_loader.LoaderTests)\nTests loading a squashed migration with a new migration referencing it ... ok\ntest_marked_as_migrated (migrations.test_loader.LoaderTests) ... ok\ntest_marked_as_unmigrated (migrations.test_loader.LoaderTests) ... ok\ntest_name_match (migrations.test_loader.LoaderTests)\nTests prefix name matching ... ok\ntest_plan_handles_repeated_migrations (migrations.test_loader.LoaderTests) ... ok\ntest_run_before (migrations.test_loader.LoaderTests) ... ok\n\n----------------------------------------------------------------------\nRan 25 tests in 0.784s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/migrations/test_loader.py",
            "tests/migrations/test_migrations_namespace_package/0001_initial.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-11149",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "django__django-11163",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 29.399966955184937,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 142,
          "failed": 1,
          "errors": 0,
          "duration": 8.17,
          "log_tail": "Traceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/model_forms/tests.py\", line 1817, in test_modelform_subclassed_model\n    self.assertEqual(sorted(model_to_dict(bw, fields=[])), [])\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1028, in assertListEqual\n    self.assertSequenceEqual(list1, list2, msg, seq_type=list)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1010, in assertSequenceEqual\n    self.fail(msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: Lists differ: ['id', 'name', 'score', 'writer_ptr'] != []\n\nFirst list contains 4 additional elements.\nFirst extra element 0:\n'id'\n\n- ['id', 'name', 'score', 'writer_ptr']\n+ []\n\n----------------------------------------------------------------------\nRan 143 tests in 0.439s\n\nFAILED (failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 model_forms.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/model_forms/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 143,
          "failed": 0,
          "errors": 0,
          "duration": 9.53,
          "log_tail": "test_clean_false_required (model_forms.tests.FileAndImageFieldTests) ... ok\ntest_clear_and_file_contradiction (model_forms.tests.FileAndImageFieldTests) ... ok\ntest_custom_file_field_save (model_forms.tests.FileAndImageFieldTests) ... ok\ntest_file_field_data (model_forms.tests.FileAndImageFieldTests) ... ok\ntest_file_field_multiple_save (model_forms.tests.FileAndImageFieldTests) ... ok\ntest_file_path_field_blank (model_forms.tests.FileAndImageFieldTests)\nFilePathField(blank=True) includes the empty option. ... ok\ntest_filefield_required_false (model_forms.tests.FileAndImageFieldTests) ... ok\ntest_full_clear (model_forms.tests.FileAndImageFieldTests) ... ok\ntest_image_field (model_forms.tests.FileAndImageFieldTests) ... ok\ntest_render_empty_file_field (model_forms.tests.FileAndImageFieldTests) ... ok\ntest_auto_id (model_forms.tests.ModelFormBasicTests) ... ok\ntest_base_form (model_forms.tests.ModelFormBasicTests) ... ok\ntest_basic_creation (model_forms.tests.ModelFormBasicTests) ... ok\ntest_custom_form_fields (model_forms.tests.ModelFormBasicTests) ... ok\ntest_initial_values (model_forms.tests.ModelFormBasicTests) ... ok\ntest_m2m_editing (model_forms.tests.ModelFormBasicTests) ... ok\ntest_m2m_initial_callable (model_forms.tests.ModelFormBasicTests) ... ok\ntest_multi_fields (model_forms.tests.ModelFormBasicTests) ... ok\ntest_recleaning_model_form_instance (model_forms.tests.ModelFormBasicTests) ... ok\ntest_runtime_choicefield_populated (model_forms.tests.ModelFormBasicTests) ... ok\ntest_save_commit_false (model_forms.tests.ModelFormBasicTests) ... ok\ntest_save_with_data_errors (model_forms.tests.ModelFormBasicTests) ... ok\ntest_subset_fields (model_forms.tests.ModelFormBasicTests) ... ok\n\n----------------------------------------------------------------------\nRan 143 tests in 0.523s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/model_forms/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-11179",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 31.051527738571167,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 41,
          "failed": 1,
          "errors": 0,
          "duration": 10.26,
          "log_tail": "test_o2o_setnull (delete.tests.OnDeleteTests) ... ok\ntest_protect (delete.tests.OnDeleteTests) ... ok\ntest_setdefault (delete.tests.OnDeleteTests) ... ok\ntest_setdefault_none (delete.tests.OnDeleteTests) ... ok\ntest_setnull (delete.tests.OnDeleteTests) ... ok\ntest_setnull_from_child (delete.tests.OnDeleteTests) ... ok\ntest_setnull_from_parent (delete.tests.OnDeleteTests) ... ok\ntest_setvalue (delete.tests.OnDeleteTests) ... ok\ntest_bulk (delete.tests.DeletionTests) ... ok\ntest_can_defer_constraint_checks (delete.tests.DeletionTests) ... ok\ntest_cannot_defer_constraint_checks (delete.tests.DeletionTests) ... skipped 'Database has feature(s) can_defer_constraint_checks'\ntest_delete_with_keeping_parents (delete.tests.DeletionTests) ... ok\ntest_delete_with_keeping_parents_relationships (delete.tests.DeletionTests) ... ok\ntest_deletion_order (delete.tests.DeletionTests) ... ok\ntest_hidden_related (delete.tests.DeletionTests) ... ok\ntest_instance_update (delete.tests.DeletionTests) ... ok\ntest_large_delete (delete.tests.DeletionTests) ... ok\ntest_large_delete_related (delete.tests.DeletionTests) ... ok\ntest_m2m (delete.tests.DeletionTests) ... ok\ntest_model_delete_returns_num_rows (delete.tests.DeletionTests) ... ok\ntest_proxied_model_duplicate_queries (delete.tests.DeletionTests) ... ok\ntest_queryset_delete_returns_num_rows (delete.tests.DeletionTests) ... ok\ntest_relational_post_delete_signals_happen_before_parent_object (delete.tests.DeletionTests) ... ok\n\n======================================================================\nFAIL: test_fast_delete_instance_set_pk_none (delete.tests.FastDeleteTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/delete/tests.py\", line 481, in test_fast_delete_instance_set_pk_none\n    self.assertIsNone(u.pk)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1233, in assertIsNone\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: 1 is not None\n\n----------------------------------------------------------------------\nRan 42 tests in 0.898s\n\nFAILED (failures=1, skipped=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 delete.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/delete/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 42,
          "failed": 0,
          "errors": 0,
          "duration": 7.11,
          "log_tail": "test_fast_delete_inheritance (delete.tests.FastDeleteTests) ... ok\ntest_fast_delete_instance_set_pk_none (delete.tests.FastDeleteTests) ... ok\ntest_fast_delete_joined_qs (delete.tests.FastDeleteTests) ... ok\ntest_fast_delete_large_batch (delete.tests.FastDeleteTests) ... ok\ntest_fast_delete_m2m (delete.tests.FastDeleteTests) ... ok\ntest_fast_delete_qs (delete.tests.FastDeleteTests) ... ok\ntest_fast_delete_revm2m (delete.tests.FastDeleteTests) ... ok\ntest_auto (delete.tests.OnDeleteTests) ... ok\ntest_auto_nullable (delete.tests.OnDeleteTests) ... ok\ntest_cascade (delete.tests.OnDeleteTests) ... ok\ntest_cascade_from_child (delete.tests.OnDeleteTests) ... ok\ntest_cascade_from_parent (delete.tests.OnDeleteTests) ... ok\ntest_cascade_nullable (delete.tests.OnDeleteTests) ... ok\ntest_do_nothing (delete.tests.OnDeleteTests) ... ok\ntest_do_nothing_qscount (delete.tests.OnDeleteTests) ... ok\ntest_inheritance_cascade_down (delete.tests.OnDeleteTests) ... ok\ntest_inheritance_cascade_up (delete.tests.OnDeleteTests) ... ok\ntest_o2o_setnull (delete.tests.OnDeleteTests) ... ok\ntest_protect (delete.tests.OnDeleteTests) ... ok\ntest_setdefault (delete.tests.OnDeleteTests) ... ok\ntest_setdefault_none (delete.tests.OnDeleteTests) ... ok\ntest_setnull (delete.tests.OnDeleteTests) ... ok\ntest_setnull_from_child (delete.tests.OnDeleteTests) ... ok\ntest_setnull_from_parent (delete.tests.OnDeleteTests) ... ok\ntest_setvalue (delete.tests.OnDeleteTests) ... ok\ntest_bulk (delete.tests.DeletionTests) ... ok\ntest_can_defer_constraint_checks (delete.tests.DeletionTests) ... ok\ntest_cannot_defer_constraint_checks (delete.tests.DeletionTests) ... skipped 'Database has feature(s) can_defer_constraint_checks'\ntest_delete_with_keeping_parents (delete.tests.DeletionTests) ... ok\ntest_delete_with_keeping_parents_relationships (delete.tests.DeletionTests) ... ok\ntest_deletion_order (delete.tests.DeletionTests) ... ok\ntest_hidden_related (delete.tests.DeletionTests) ... ok\ntest_instance_update (delete.tests.DeletionTests) ... ok\ntest_large_delete (delete.tests.DeletionTests) ... ok\ntest_large_delete_related (delete.tests.DeletionTests) ... ok\ntest_m2m (delete.tests.DeletionTests) ... ok\ntest_model_delete_returns_num_rows (delete.tests.DeletionTests) ... ok\ntest_proxied_model_duplicate_queries (delete.tests.DeletionTests) ... ok\ntest_queryset_delete_returns_num_rows (delete.tests.DeletionTests) ... ok\ntest_relational_post_delete_signals_happen_before_parent_object (delete.tests.DeletionTests) ... ok\n\n----------------------------------------------------------------------\nRan 42 tests in 0.726s\n\nOK (skipped=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/delete/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-11206",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 37.92629289627075,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 5,
          "failed": 1,
          "errors": 0,
          "duration": 7.98,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application utils_tests\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_decimal_numbers (utils_tests.test_numberformat.TestNumberFormat) ... test_decimal_subclass (utils_tests.test_numberformat.TestNumberFormat) ... ok\ntest_float_numbers (utils_tests.test_numberformat.TestNumberFormat) ... ok\ntest_format_number (utils_tests.test_numberformat.TestNumberFormat) ... ok\ntest_format_string (utils_tests.test_numberformat.TestNumberFormat) ... ok\ntest_large_number (utils_tests.test_numberformat.TestNumberFormat) ... ok\n\n======================================================================\nFAIL: test_decimal_numbers (utils_tests.test_numberformat.TestNumberFormat) (value='0.000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001234')\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/utils_tests/test_numberformat.py\", line 101, in test_decimal_numbers\n    self.assertEqual(nformat(Decimal(value), '.', decimal_pos), expected_value)\nAssertionError: '1.234e-300' != '0.000'\n- 1.234e-300\n+ 0.000\n\n\n----------------------------------------------------------------------\nRan 6 tests in 0.004s\n\nFAILED (failures=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 utils_tests.test_numberformat` failed. (See above for error)",
          "test_files_run": [
            "tests/utils_tests/test_numberformat.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 6,
          "failed": 0,
          "errors": 0,
          "duration": 7.52,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application utils_tests\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_decimal_numbers (utils_tests.test_numberformat.TestNumberFormat) ... ok\ntest_decimal_subclass (utils_tests.test_numberformat.TestNumberFormat) ... ok\ntest_float_numbers (utils_tests.test_numberformat.TestNumberFormat) ... ok\ntest_format_number (utils_tests.test_numberformat.TestNumberFormat) ... ok\ntest_format_string (utils_tests.test_numberformat.TestNumberFormat) ... ok\ntest_large_number (utils_tests.test_numberformat.TestNumberFormat) ... ok\n\n----------------------------------------------------------------------\nRan 6 tests in 0.004s\n\nOK\n",
          "test_files_run": [
            "tests/utils_tests/test_numberformat.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-11211",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 30.13223099708557,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 76,
          "failed": 1,
          "errors": 0,
          "duration": 8.57,
          "log_tail": "    self.fail(msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: Lists differ: [None] != [<Article: Article object (16f33579-0952-4e8d-83b4-b1a4a40948ec)>]\n\nFirst differing element 0:\nNone\n<Article: Article object (16f33579-0952-4e8d-83b4-b1a4a40948ec)>\n\n- [None]\n+ [<Article: Article object (16f33579-0952-4e8d-83b4-b1a4a40948ec)>]\n\n----------------------------------------------------------------------\nRan 77 tests in 0.343s\n\nFAILED (failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 prefetch_related.models prefetch_related.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/prefetch_related/models.py",
            "tests/prefetch_related/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 77,
          "failed": 0,
          "errors": 0,
          "duration": 9.58,
          "log_tail": "test_m2m_through_fk (prefetch_related.tests.CustomPrefetchTests) ... ok\ntest_m2m_through_gfk (prefetch_related.tests.CustomPrefetchTests) ... ok\ntest_nested_prefetch_related_are_not_overwritten (prefetch_related.tests.CustomPrefetchTests) ... ok\ntest_nested_prefetch_related_with_duplicate_prefetcher (prefetch_related.tests.CustomPrefetchTests) ... ok\ntest_o2m_through_m2m (prefetch_related.tests.CustomPrefetchTests) ... ok\ntest_reverse_m2m (prefetch_related.tests.CustomPrefetchTests) ... ok\ntest_to_attr_cached_property (prefetch_related.tests.CustomPrefetchTests) ... ok\ntest_to_attr_doesnt_cache_through_attr_as_list (prefetch_related.tests.CustomPrefetchTests) ... ok\ntest_traverse_multiple_items_property (prefetch_related.tests.CustomPrefetchTests) ... ok\ntest_traverse_qs (prefetch_related.tests.CustomPrefetchTests) ... ok\ntest_traverse_single_item_property (prefetch_related.tests.CustomPrefetchTests) ... ok\ntest_values_queryset (prefetch_related.tests.CustomPrefetchTests) ... ok\n\n----------------------------------------------------------------------\nRan 77 tests in 0.432s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/prefetch_related/models.py",
            "tests/prefetch_related/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-11239",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 20.99153423309326,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 5,
          "failed": 1,
          "errors": 0,
          "duration": 6.64,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application dbshell\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_accent (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase) ... ok\ntest_basic (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase) ... ok\ntest_column (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase) ... ok\ntest_nopass (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase) ... ok\ntest_sigint_handler (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase)\nSIGINT is ignored in Python and passed to psql to abort quries. ... ok\ntest_ssl_certificate (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase) ... FAIL\n\n======================================================================\nFAIL: test_ssl_certificate (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/dbshell/test_postgresql.py\", line 72, in test_ssl_certificate\n    'PGSSLROOTCERT': 'root.crt',\nAssertionError: Tuples differ: (['ps[61 chars]'], {}) != (['ps[61 chars]'], {'PGSSLCERT': 'client.crt', 'PGSSLKEY': 'c[62 chars]rt'})\n\nFirst differing element 1:\n{}\n{'PGSSLCERT': 'client.crt', 'PGSSLKEY': 'c[61 chars]crt'}\n\n- (['psql', '-U', 'someuser', '-h', 'somehost', '-p', '444', 'dbname'], {})\n?                                                                      ----\n\n+ (['psql', '-U', 'someuser', '-h', 'somehost', '-p', '444', 'dbname'],\n+  {'PGSSLCERT': 'client.crt',\n+   'PGSSLKEY': 'client.key',\n+   'PGSSLMODE': 'verify-ca',\n+   'PGSSLROOTCERT': 'root.crt'})\n\n----------------------------------------------------------------------\nRan 6 tests in 0.003s\n\nFAILED (failures=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 dbshell.test_postgresql` failed. (See above for error)",
          "test_files_run": [
            "tests/dbshell/test_postgresql.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 6,
          "failed": 0,
          "errors": 0,
          "duration": 6.16,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application dbshell\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_accent (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase) ... ok\ntest_basic (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase) ... ok\ntest_column (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase) ... ok\ntest_nopass (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase) ... ok\ntest_sigint_handler (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase)\nSIGINT is ignored in Python and passed to psql to abort quries. ... ok\ntest_ssl_certificate (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase) ... ok\n\n----------------------------------------------------------------------\nRan 6 tests in 0.001s\n\nOK\n",
          "test_files_run": [
            "tests/dbshell/test_postgresql.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-11265",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 28.054676055908203,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 31,
          "failed": 0,
          "errors": 1,
          "duration": 8.23,
          "log_tail": "test_with_m2m_multijoin (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_with_multiple_filter (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_with_prefetch_related (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_without_join (filtered_relation.tests.FilteredRelationTests) ... ok\n\n======================================================================\nERROR: test_with_exclude (filtered_relation.tests.FilteredRelationTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/filtered_relation/tests.py\", line 105, in test_with_exclude\n    ).exclude(book_alice__isnull=False),\n  File \"/testbed/django/db/models/query.py\", line 888, in exclude\n    return self._filter_or_exclude(True, *args, **kwargs)\n  File \"/testbed/django/db/models/query.py\", line 897, in _filter_or_exclude\n    clone.query.add_q(~Q(*args, **kwargs))\n  File \"/testbed/django/db/models/sql/query.py\", line 1319, in add_q\n    clause, _ = self._add_q(q_object, self.used_aliases)\n  File \"/testbed/django/db/models/sql/query.py\", line 1347, in _add_q\n    split_subq=split_subq, simple_col=simple_col,\n  File \"/testbed/django/db/models/sql/query.py\", line 1259, in build_filter\n    return self.split_exclude(filter_expr, can_reuse, e.names_with_path)\n  File \"/testbed/django/db/models/sql/query.py\", line 1669, in split_exclude\n    query.add_filter(filter_expr)\n  File \"/testbed/django/db/models/sql/query.py\", line 1305, in add_filter\n    self.add_q(Q(**{filter_clause[0]: filter_clause[1]}))\n  File \"/testbed/django/db/models/sql/query.py\", line 1319, in add_q\n    clause, _ = self._add_q(q_object, self.used_aliases)\n  File \"/testbed/django/db/models/sql/query.py\", line 1347, in _add_q\n    split_subq=split_subq, simple_col=simple_col,\n  File \"/testbed/django/db/models/sql/query.py\", line 1219, in build_filter\n    lookups, parts, reffed_expression = self.solve_lookup_type(arg)\n  File \"/testbed/django/db/models/sql/query.py\", line 1078, in solve_lookup_type\n    _, field, _, lookup_parts = self.names_to_path(lookup_splitted, self.get_meta())\n  File \"/testbed/django/db/models/sql/query.py\", line 1449, in names_to_path\n    \"Choices are: %s\" % (name, \", \".join(available)))\ndjango.core.exceptions.FieldError: Cannot resolve keyword 'book_alice' into field. Choices are: book, content_object, content_type, content_type_id, favorite_books, id, name, object_id\n\n----------------------------------------------------------------------\nRan 32 tests in 0.230s\n\nFAILED (errors=1, skipped=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 filtered_relation.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/filtered_relation/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 32,
          "failed": 0,
          "errors": 0,
          "duration": 8.05,
          "log_tail": "  Applying admin.0003_logentry_add_action_flag_choices... OK\n  Applying sites.0001_initial... OK\n  Applying sites.0002_alter_domain_unique... OK\nSystem check identified no issues (0 silenced).\n\n\nCreating test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\ntest_aggregate (filtered_relation.tests.FilteredRelationAggregationTests) ... ok\ntest_as_subquery (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_defer (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_difference (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_exclude_relation_with_join (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_extra (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_internal_queryset_alias_mapping (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_intersection (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_multiple_times (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_only_not_supported (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_select_for_update (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_select_related (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_select_related_foreign_key (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_select_related_foreign_key_for_update_of (filtered_relation.tests.FilteredRelationTests) ... skipped \"Database doesn't support feature(s): has_select_for_update, has_select_for_update_of\"\ntest_select_related_with_empty_relation (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_union (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_values (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_values_list (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_with_condition_as_expression_error (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_with_empty_relation_name_error (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_with_exclude (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_with_foreign_key_error (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_with_foreign_key_on_condition_error (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_with_generic_foreign_key (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_with_join (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_with_join_and_complex_condition (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_with_m2m (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_with_m2m_deep (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_with_m2m_multijoin (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_with_multiple_filter (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_with_prefetch_related (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_without_join (filtered_relation.tests.FilteredRelationTests) ... ok\n\n----------------------------------------------------------------------\nRan 32 tests in 0.228s\n\nOK (skipped=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/filtered_relation/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-11276",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 42.71685218811035,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 552,
          "failed": 28,
          "errors": 0,
          "duration": 11.33,
          "log_tail": "Destroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 admin_docs.test_views auth_tests.test_forms forms_tests.tests.test_forms forms_tests.widget_tests.base forms_tests.widget_tests.test_clearablefileinput model_forms.tests template_tests.filter_tests.test_addslashes template_tests.filter_tests.test_make_list template_tests.filter_tests.test_title template_tests.filter_tests.test_urlize template_tests.syntax_tests.test_url utils_tests.test_html view_tests.tests.test_csrf view_tests.tests.test_debug` failed. (See above for error)",
          "test_files_run": [
            "tests/admin_docs/test_views.py",
            "tests/auth_tests/test_forms.py",
            "tests/forms_tests/tests/test_forms.py",
            "tests/forms_tests/widget_tests/base.py",
            "tests/forms_tests/widget_tests/test_clearablefileinput.py",
            "tests/model_forms/tests.py",
            "tests/template_tests/filter_tests/test_addslashes.py",
            "tests/template_tests/filter_tests/test_make_list.py",
            "tests/template_tests/filter_tests/test_title.py",
            "tests/template_tests/filter_tests/test_urlize.py",
            "tests/template_tests/syntax_tests/test_url.py",
            "tests/utils_tests/test_html.py",
            "tests/view_tests/tests/test_csrf.py",
            "tests/view_tests/tests/test_debug.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 580,
          "failed": 0,
          "errors": 0,
          "duration": 10.43,
          "log_tail": "Destroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/admin_docs/test_views.py",
            "tests/auth_tests/test_forms.py",
            "tests/forms_tests/tests/test_forms.py",
            "tests/forms_tests/widget_tests/base.py",
            "tests/forms_tests/widget_tests/test_clearablefileinput.py",
            "tests/model_forms/tests.py",
            "tests/template_tests/filter_tests/test_addslashes.py",
            "tests/template_tests/filter_tests/test_make_list.py",
            "tests/template_tests/filter_tests/test_title.py",
            "tests/template_tests/filter_tests/test_urlize.py",
            "tests/template_tests/syntax_tests/test_url.py",
            "tests/utils_tests/test_html.py",
            "tests/view_tests/tests/test_csrf.py",
            "tests/view_tests/tests/test_debug.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-11292",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 30.38503885269165,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 31,
          "failed": 1,
          "errors": 0,
          "duration": 8.92,
          "log_tail": "test_calling_command_with_parameters_and_app_labels_at_the_end_should_be_ok (user_commands.tests.CommandTests) ... ok\ntest_check_migrations (user_commands.tests.CommandTests) ... ok\ntest_command (user_commands.tests.CommandTests) ... ok\ntest_command_add_arguments_after_common_arguments (user_commands.tests.CommandTests) ... ok\ntest_command_style (user_commands.tests.CommandTests) ... ok\ntest_create_parser_kwargs (user_commands.tests.CommandTests)\nBaseCommand.create_parser() passes kwargs to CommandParser. ... ok\ntest_discover_commands_in_eggs (user_commands.tests.CommandTests) ... ok\ntest_explode (user_commands.tests.CommandTests)\nAn unknown command raises CommandError ... ok\ntest_find_command_without_PATH (user_commands.tests.CommandTests) ... ok\ntest_language_preserved (user_commands.tests.CommandTests) ... ok\ntest_no_translations_deactivate_translations (user_commands.tests.CommandTests) ... ok\ntest_output_transaction (user_commands.tests.CommandTests) ... ok\ntest_subparser (user_commands.tests.CommandTests) ... ok\ntest_subparser_invalid_option (user_commands.tests.CommandTests) ... ok\ntest_system_exit (user_commands.tests.CommandTests)\nException raised in a command should raise CommandError with ... ok\ntest_disallowed_abbreviated_options (user_commands.tests.CommandRunTests) ... ok\ntest_script_prefix_set_in_commands (user_commands.tests.CommandRunTests) ... ok\ntest_skip_checks (user_commands.tests.CommandRunTests) ... FAIL\n\n======================================================================\nFAIL: test_skip_checks (user_commands.tests.CommandRunTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/user_commands/tests.py\", line 263, in test_skip_checks\n    self.assertNoOutput(err)\n  File \"/testbed/tests/admin_scripts/tests.py\", line 152, in assertNoOutput\n    self.assertEqual(len(stream), 0, \"Stream should be empty: actually contains '%s'\" % stream)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 822, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: 286 != 0 : Stream should be empty: actually contains 'usage: manage.py set_option [-h] [--set SET] [--version] [-v {0,1,2,3}]\n                            [--settings SETTINGS] [--pythonpath PYTHONPATH]\n                            [--traceback] [--no-color] [--force-color]\nmanage.py set_option: error: unrecognized arguments: --skip-checks\n'\n\n----------------------------------------------------------------------\nRan 32 tests in 1.131s\n\nFAILED (failures=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 user_commands.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/user_commands/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 32,
          "failed": 0,
          "errors": 0,
          "duration": 9.46,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application user_commands\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_get_random_secret_key (user_commands.tests.UtilsTests) ... ok\ntest_is_ignored_path_false (user_commands.tests.UtilsTests) ... ok\ntest_is_ignored_path_true (user_commands.tests.UtilsTests) ... ok\ntest_no_existent_external_program (user_commands.tests.UtilsTests) ... ok\ntest_normalize_path_patterns_truncates_wildcard_base (user_commands.tests.UtilsTests) ... ok\ntest_call_command_no_checks (user_commands.tests.CommandTests) ... ok\ntest_call_command_option_parsing (user_commands.tests.CommandTests) ... ok\ntest_call_command_option_parsing_non_string_arg (user_commands.tests.CommandTests) ... ok\ntest_call_command_unrecognized_option (user_commands.tests.CommandTests) ... ok\ntest_call_command_with_required_parameters_in_mixed_options (user_commands.tests.CommandTests) ... ok\ntest_call_command_with_required_parameters_in_options (user_commands.tests.CommandTests) ... ok\ntest_calling_a_command_with_no_app_labels_and_parameters_should_raise_a_command_error (user_commands.tests.CommandTests) ... ok\ntest_calling_a_command_with_only_empty_parameter_should_ends_gracefully (user_commands.tests.CommandTests) ... ok\ntest_calling_command_with_app_labels_and_parameters_should_be_ok (user_commands.tests.CommandTests) ... ok\ntest_calling_command_with_parameters_and_app_labels_at_the_end_should_be_ok (user_commands.tests.CommandTests) ... ok\ntest_check_migrations (user_commands.tests.CommandTests) ... ok\ntest_command (user_commands.tests.CommandTests) ... ok\ntest_command_add_arguments_after_common_arguments (user_commands.tests.CommandTests) ... ok\ntest_command_style (user_commands.tests.CommandTests) ... ok\ntest_create_parser_kwargs (user_commands.tests.CommandTests)\nBaseCommand.create_parser() passes kwargs to CommandParser. ... ok\ntest_discover_commands_in_eggs (user_commands.tests.CommandTests) ... ok\ntest_explode (user_commands.tests.CommandTests)\nAn unknown command raises CommandError ... ok\ntest_find_command_without_PATH (user_commands.tests.CommandTests) ... ok\ntest_language_preserved (user_commands.tests.CommandTests) ... ok\ntest_no_translations_deactivate_translations (user_commands.tests.CommandTests) ... ok\ntest_output_transaction (user_commands.tests.CommandTests) ... ok\ntest_subparser (user_commands.tests.CommandTests) ... ok\ntest_subparser_invalid_option (user_commands.tests.CommandTests) ... ok\ntest_system_exit (user_commands.tests.CommandTests)\nException raised in a command should raise CommandError with ... ok\ntest_disallowed_abbreviated_options (user_commands.tests.CommandRunTests) ... ok\ntest_script_prefix_set_in_commands (user_commands.tests.CommandRunTests) ... ok\ntest_skip_checks (user_commands.tests.CommandRunTests) ... ok\n\n----------------------------------------------------------------------\nRan 32 tests in 1.449s\n\nOK\n",
          "test_files_run": [
            "tests/user_commands/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-11299",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "django__django-11333",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 28.061175107955933,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 2,
          "failed": 1,
          "errors": 0,
          "duration": 7.86,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application urlpatterns\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_str (urlpatterns.test_resolvers.RegexPatternTests) ... ok\ntest_str (urlpatterns.test_resolvers.RoutePatternTests) ... ok\ntest_resolver_cache_default__root_urlconf (urlpatterns.test_resolvers.ResolverCacheTests) ... FAIL\n\n======================================================================\nFAIL: test_resolver_cache_default__root_urlconf (urlpatterns.test_resolvers.ResolverCacheTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/django/test/utils.py\", line 370, in inner\n    return func(*args, **kwargs)\n  File \"/testbed/tests/urlpatterns/test_resolvers.py\", line 24, in test_resolver_cache_default__root_urlconf\n    self.assertIs(get_resolver(), get_resolver('urlpatterns.path_urls'))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1103, in assertIs\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: <URLResolver 'urlpatterns.path_urls' (None:None) '^/'> is not <URLResolver 'urlpatterns.path_urls' (None:None) '^/'>\n\n----------------------------------------------------------------------\nRan 3 tests in 0.218s\n\nFAILED (failures=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 urlpatterns.test_resolvers` failed. (See above for error)",
          "test_files_run": [
            "tests/urlpatterns/test_resolvers.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 3,
          "failed": 0,
          "errors": 0,
          "duration": 8.35,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application urlpatterns\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_str (urlpatterns.test_resolvers.RegexPatternTests) ... ok\ntest_str (urlpatterns.test_resolvers.RoutePatternTests) ... ok\ntest_resolver_cache_default__root_urlconf (urlpatterns.test_resolvers.ResolverCacheTests) ... ok\n\n----------------------------------------------------------------------\nRan 3 tests in 0.240s\n\nOK\n",
          "test_files_run": [
            "tests/urlpatterns/test_resolvers.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-11400",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 32.303982973098755,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 58,
          "failed": 6,
          "errors": 0,
          "duration": 10.5,
          "log_tail": "AssertionError: Lists differ: [(2, 'Jack Red'), (3, 'Albert Green')] != [(3, 'Albert Green'), (2, 'Jack Red')]\n\nFirst differing element 0:\n(2, 'Jack Red')\n(3, 'Albert Green')\n\n- [(2, 'Jack Red'), (3, 'Albert Green')]\n+ [(3, 'Albert Green'), (2, 'Jack Red')]\n\n======================================================================\nFAIL: test_relatedonlyfieldlistfilter_foreignkey_ordering (admin_filters.tests.ListFiltersTests)\nRelatedOnlyFieldListFilter ordering respects ModelAdmin.ordering.\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/admin_filters/tests.py\", line 769, in test_relatedonlyfieldlistfilter_foreignkey_ordering\n    self.assertEqual(filterspec.lookup_choices, expected)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1028, in assertListEqual\n    self.assertSequenceEqual(list1, list2, msg, seq_type=list)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1010, in assertSequenceEqual\n    self.fail(msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: Lists differ: [(2, 'Jack Red'), (3, 'Albert Green')] != [(3, 'Albert Green'), (2, 'Jack Red')]\n\nFirst differing element 0:\n(2, 'Jack Red')\n(3, 'Albert Green')\n\n- [(2, 'Jack Red'), (3, 'Albert Green')]\n+ [(3, 'Albert Green'), (2, 'Jack Red')]\n\n----------------------------------------------------------------------\nRan 64 tests in 0.700s\n\nFAILED (failures=6)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 admin_filters.tests model_fields.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/admin_filters/tests.py",
            "tests/model_fields/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 64,
          "failed": 0,
          "errors": 0,
          "duration": 7.71,
          "log_tail": "test_booleanfieldlistfilter_tuple (admin_filters.tests.ListFiltersTests) ... ok\ntest_choicesfieldlistfilter_has_none_choice (admin_filters.tests.ListFiltersTests) ... ok\ntest_datefieldlistfilter (admin_filters.tests.ListFiltersTests) ... ok\ntest_datefieldlistfilter_with_time_zone_support (admin_filters.tests.ListFiltersTests) ... ok\ntest_fieldlistfilter_invalid_lookup_parameters (admin_filters.tests.ListFiltersTests)\nFiltering by an invalid value. ... ok\ntest_fieldlistfilter_underscorelookup_tuple (admin_filters.tests.ListFiltersTests) ... ok\ntest_filter_with_failing_queryset (admin_filters.tests.ListFiltersTests) ... ok\ntest_fk_with_to_field (admin_filters.tests.ListFiltersTests) ... ok\ntest_list_filter_queryset_filtered_by_default (admin_filters.tests.ListFiltersTests) ... ok\ntest_listfilter_genericrelation (admin_filters.tests.ListFiltersTests) ... ok\ntest_listfilter_without_title (admin_filters.tests.ListFiltersTests) ... ok\ntest_lookup_with_dynamic_value (admin_filters.tests.ListFiltersTests) ... ok\ntest_lookup_with_non_string_value (admin_filters.tests.ListFiltersTests) ... ok\ntest_lookup_with_non_string_value_underscored (admin_filters.tests.ListFiltersTests) ... ok\ntest_parameter_ends_with__in__or__isnull (admin_filters.tests.ListFiltersTests) ... ok\ntest_relatedfieldlistfilter_foreignkey (admin_filters.tests.ListFiltersTests) ... ok\ntest_relatedfieldlistfilter_foreignkey_default_ordering (admin_filters.tests.ListFiltersTests)\nRelatedFieldListFilter ordering respects Model.ordering. ... ok\ntest_relatedfieldlistfilter_foreignkey_ordering (admin_filters.tests.ListFiltersTests)\nRelatedFieldListFilter ordering respects ModelAdmin.ordering. ... ok\ntest_relatedfieldlistfilter_foreignkey_ordering_reverse (admin_filters.tests.ListFiltersTests) ... ok\ntest_relatedfieldlistfilter_manytomany (admin_filters.tests.ListFiltersTests) ... ok\ntest_relatedfieldlistfilter_reverse_relationships (admin_filters.tests.ListFiltersTests) ... ok\ntest_relatedfieldlistfilter_reverse_relationships_default_ordering (admin_filters.tests.ListFiltersTests) ... ok\ntest_relatedonlyfieldlistfilter_foreignkey (admin_filters.tests.ListFiltersTests) ... ok\ntest_relatedonlyfieldlistfilter_foreignkey_default_ordering (admin_filters.tests.ListFiltersTests)\nRelatedOnlyFieldListFilter ordering respects Meta.ordering. ... ok\ntest_relatedonlyfieldlistfilter_foreignkey_ordering (admin_filters.tests.ListFiltersTests)\nRelatedOnlyFieldListFilter ordering respects ModelAdmin.ordering. ... ok\ntest_relatedonlyfieldlistfilter_manytomany (admin_filters.tests.ListFiltersTests) ... ok\ntest_relatedonlyfieldlistfilter_underscorelookup_foreignkey (admin_filters.tests.ListFiltersTests) ... ok\ntest_simplelistfilter (admin_filters.tests.ListFiltersTests) ... ok\ntest_simplelistfilter_with_none_returning_lookups (admin_filters.tests.ListFiltersTests) ... ok\ntest_simplelistfilter_with_queryset_based_lookups (admin_filters.tests.ListFiltersTests) ... ok\ntest_simplelistfilter_without_parameter (admin_filters.tests.ListFiltersTests) ... ok\ntest_two_characters_long_field (admin_filters.tests.ListFiltersTests) ... ok\n\n----------------------------------------------------------------------\nRan 64 tests in 0.750s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/admin_filters/tests.py",
            "tests/model_fields/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-11433",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 30.58025074005127,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 143,
          "failed": 1,
          "errors": 0,
          "duration": 10.02,
          "log_tail": "test_label_overrides (model_forms.tests.TestFieldOverridesByFormMeta) ... ok\ntest_widget_overrides (model_forms.tests.TestFieldOverridesByFormMeta) ... ok\n\n======================================================================\nFAIL: test_default_not_populated_on_non_empty_value_in_cleaned_data (model_forms.tests.ModelFormBaseTest)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/model_forms/tests.py\", line 604, in test_default_not_populated_on_non_empty_value_in_cleaned_data\n    self.assertEqual(pub.mode, 'de')\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1203, in assertMultiLineEqual\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: 'di' != 'de'\n- di\n+ de\n\n\n----------------------------------------------------------------------\nRan 144 tests in 0.431s\n\nFAILED (failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 model_forms.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/model_forms/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 144,
          "failed": 0,
          "errors": 0,
          "duration": 8.1,
          "log_tail": "test_render_empty_file_field (model_forms.tests.FileAndImageFieldTests) ... ok\ntest_big_integer_field (model_forms.tests.ModelOtherFieldTests) ... ok\ntest_http_prefixing (model_forms.tests.ModelOtherFieldTests) ... ok\ntest_modelform_non_editable_field (model_forms.tests.ModelOtherFieldTests) ... ok\ntest_url_on_modelform (model_forms.tests.ModelOtherFieldTests)\nCheck basic URL field validation on model forms ... ok\ntest_error_messages_overrides (model_forms.tests.TestFieldOverridesByFormMeta) ... ok\ntest_field_type_overrides (model_forms.tests.TestFieldOverridesByFormMeta) ... ok\ntest_help_text_overrides (model_forms.tests.TestFieldOverridesByFormMeta) ... ok\ntest_label_overrides (model_forms.tests.TestFieldOverridesByFormMeta) ... ok\ntest_widget_overrides (model_forms.tests.TestFieldOverridesByFormMeta) ... ok\ntest_auto_id (model_forms.tests.ModelFormBasicTests) ... ok\ntest_base_form (model_forms.tests.ModelFormBasicTests) ... ok\ntest_basic_creation (model_forms.tests.ModelFormBasicTests) ... ok\ntest_custom_form_fields (model_forms.tests.ModelFormBasicTests) ... ok\ntest_initial_values (model_forms.tests.ModelFormBasicTests) ... ok\ntest_m2m_editing (model_forms.tests.ModelFormBasicTests) ... ok\ntest_m2m_initial_callable (model_forms.tests.ModelFormBasicTests) ... ok\ntest_multi_fields (model_forms.tests.ModelFormBasicTests) ... ok\ntest_recleaning_model_form_instance (model_forms.tests.ModelFormBasicTests) ... ok\ntest_runtime_choicefield_populated (model_forms.tests.ModelFormBasicTests) ... ok\ntest_save_commit_false (model_forms.tests.ModelFormBasicTests) ... ok\ntest_save_with_data_errors (model_forms.tests.ModelFormBasicTests) ... ok\ntest_subset_fields (model_forms.tests.ModelFormBasicTests) ... ok\n\n----------------------------------------------------------------------\nRan 144 tests in 0.381s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/model_forms/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-11451",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 28.33176279067993,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 48,
          "failed": 9,
          "errors": 0,
          "duration": 8.23,
          "log_tail": "  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 822, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: 1 != 0 : 1 queries executed, 0 expected\nCaptured queries were:\n1. SELECT \"auth_tests_extensionuser\".\"id\", \"auth_tests_extensionuser\".\"password\", \"auth_tests_extensionuser\".\"last_login\", \"auth_tests_extensionuser\".\"is_superuser\", \"auth_tests_extensionuser\".\"username\", \"auth_tests_extensionuser\".\"first_name\", \"auth_tests_extensionuser\".\"last_name\", \"auth_tests_extensionuser\".\"email\", \"auth_tests_extensionuser\".\"is_staff\", \"auth_tests_extensionuser\".\"is_active\", \"auth_tests_extensionuser\".\"date_joined\", \"auth_tests_extensionuser\".\"date_of_birth\" FROM \"auth_tests_extensionuser\" WHERE \"auth_tests_extensionuser\".\"username\" = 'test' LIMIT 21\n\n======================================================================\nFAIL: test_authentication_without_credentials (auth_tests.test_auth_backends.ExtensionUserModelBackendTest) [<object object at 0x7d399ee13b70>] (credentials={'password': 'test'})\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 523, in subTest\n    yield\n  File \"/testbed/tests/auth_tests/test_auth_backends.py\", line 239, in test_authentication_without_credentials\n    authenticate(**credentials)\n  File \"/testbed/django/test/testcases.py\", line 85, in __exit__\n    '%d. %s' % (i, query['sql']) for i, query in enumerate(self.captured_queries, start=1)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 822, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: 1 != 0 : 1 queries executed, 0 expected\nCaptured queries were:\n1. SELECT \"auth_tests_extensionuser\".\"id\", \"auth_tests_extensionuser\".\"password\", \"auth_tests_extensionuser\".\"last_login\", \"auth_tests_extensionuser\".\"is_superuser\", \"auth_tests_extensionuser\".\"username\", \"auth_tests_extensionuser\".\"first_name\", \"auth_tests_extensionuser\".\"last_name\", \"auth_tests_extensionuser\".\"email\", \"auth_tests_extensionuser\".\"is_staff\", \"auth_tests_extensionuser\".\"is_active\", \"auth_tests_extensionuser\".\"date_joined\", \"auth_tests_extensionuser\".\"date_of_birth\" FROM \"auth_tests_extensionuser\" WHERE \"auth_tests_extensionuser\".\"username\" IS NULL LIMIT 21\n\n----------------------------------------------------------------------\nRan 57 tests in 0.438s\n\nFAILED (failures=9)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 auth_tests.test_auth_backends` failed. (See above for error)",
          "test_files_run": [
            "tests/auth_tests/test_auth_backends.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 57,
          "failed": 0,
          "errors": 0,
          "duration": 8.5,
          "log_tail": "test_has_perm (auth_tests.test_auth_backends.ExtensionUserModelBackendTest) ... ok\ntest_inactive_has_no_permissions (auth_tests.test_auth_backends.ExtensionUserModelBackendTest) ... ok\ntest_anonymous_has_no_permissions (auth_tests.test_auth_backends.ModelBackendTest) ... ok\ntest_authenticate_inactive (auth_tests.test_auth_backends.ModelBackendTest) ... ok\ntest_authenticate_user_without_is_active_field (auth_tests.test_auth_backends.ModelBackendTest) ... ok\ntest_authentication_timing (auth_tests.test_auth_backends.ModelBackendTest)\nHasher is run once regardless of whether the user exists. Refs #20760. ... ok\ntest_authentication_without_credentials (auth_tests.test_auth_backends.ModelBackendTest) ... ok\ntest_custom_perms (auth_tests.test_auth_backends.ModelBackendTest) ... ok\ntest_get_all_superuser_permissions (auth_tests.test_auth_backends.ModelBackendTest)\nA superuser has all permissions. Refs #14795. ... ok\ntest_has_no_object_perm (auth_tests.test_auth_backends.ModelBackendTest)\nRegressiontest for #12462 ... ok\ntest_has_perm (auth_tests.test_auth_backends.ModelBackendTest) ... ok\ntest_inactive_has_no_permissions (auth_tests.test_auth_backends.ModelBackendTest) ... ok\ntest_anonymous_has_no_permissions (auth_tests.test_auth_backends.CustomPermissionsUserModelBackendTest) ... ok\ntest_authentication_timing (auth_tests.test_auth_backends.CustomPermissionsUserModelBackendTest)\nHasher is run once regardless of whether the user exists. Refs #20760. ... ok\ntest_authentication_without_credentials (auth_tests.test_auth_backends.CustomPermissionsUserModelBackendTest) ... ok\ntest_custom_perms (auth_tests.test_auth_backends.CustomPermissionsUserModelBackendTest) ... ok\ntest_get_all_superuser_permissions (auth_tests.test_auth_backends.CustomPermissionsUserModelBackendTest)\nA superuser has all permissions. Refs #14795. ... ok\ntest_has_no_object_perm (auth_tests.test_auth_backends.CustomPermissionsUserModelBackendTest)\nRegressiontest for #12462 ... ok\ntest_has_perm (auth_tests.test_auth_backends.CustomPermissionsUserModelBackendTest) ... ok\ntest_inactive_has_no_permissions (auth_tests.test_auth_backends.CustomPermissionsUserModelBackendTest) ... ok\n\n----------------------------------------------------------------------\nRan 57 tests in 0.366s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/auth_tests/test_auth_backends.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-11477",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 31.406847953796387,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 152,
          "failed": 2,
          "errors": 0,
          "duration": 10.23,
          "log_tail": "  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1203, in assertMultiLineEqual\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: '/nl/with-arguments/regular-argument/None.html' != '/nl/with-arguments/regular-argument/'\n- /nl/with-arguments/regular-argument/None.html\n?                                     ---------\n+ /nl/with-arguments/regular-argument/\n\n\n----------------------------------------------------------------------\nRan 154 tests in 0.780s\n\nFAILED (failures=2)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 i18n.patterns.tests i18n.patterns.urls.default urlpatterns.path_urls urlpatterns.tests urlpatterns_reverse.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/i18n/patterns/tests.py",
            "tests/i18n/patterns/urls/default.py",
            "tests/urlpatterns/path_urls.py",
            "tests/urlpatterns/tests.py",
            "tests/urlpatterns_reverse/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 154,
          "failed": 0,
          "errors": 0,
          "duration": 7.35,
          "log_tail": "test_nested_namespace_pattern (urlpatterns_reverse.tests.NamespaceTests)\nNamespaces can be nested. ... ok\ntest_non_existent_namespace (urlpatterns_reverse.tests.NamespaceTests)\nNonexistent namespaces raise errors. ... ok\ntest_normal_name (urlpatterns_reverse.tests.NamespaceTests)\nNormal lookups work as expected. ... ok\ntest_simple_included_name (urlpatterns_reverse.tests.NamespaceTests)\nNormal lookups work on names included from other patterns. ... ok\ntest_special_chars_namespace (urlpatterns_reverse.tests.NamespaceTests) ... ok\ntest_lazy_in_settings (urlpatterns_reverse.tests.ReverseLazySettingsTest) ... ok\n\n----------------------------------------------------------------------\nRan 154 tests in 0.639s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/i18n/patterns/tests.py",
            "tests/i18n/patterns/urls/default.py",
            "tests/urlpatterns/path_urls.py",
            "tests/urlpatterns/tests.py",
            "tests/urlpatterns_reverse/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-11490",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 30.628343105316162,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 25,
          "failed": 1,
          "errors": 0,
          "duration": 10.13,
          "log_tail": "test_count_union (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_count_union_empty_result (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_difference_with_empty_qs (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_difference_with_values (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_intersection_with_empty_qs (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_intersection_with_values (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_limits (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_order_raises_on_non_selected_column (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_ordering (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_ordering_by_f_expression (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_ordering_subqueries (queries.test_qs_combinators.QuerySetSetOperationTests) ... skipped \"Database doesn't support feature(s): supports_slicing_ordering_in_compound\"\ntest_qs_with_subcompound_qs (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_simple_difference (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_simple_intersection (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_simple_union (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_union_distinct (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_union_with_empty_qs (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_union_with_extra_and_values_list (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_union_with_two_annotated_values_list (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_union_with_values (queries.test_qs_combinators.QuerySetSetOperationTests) ... FAIL\ntest_union_with_values_list_on_annotated_and_unannotated (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_unsupported_intersection_raises_db_error (queries.test_qs_combinators.QuerySetSetOperationTests) ... skipped 'Database has feature(s) supports_select_intersection'\ntest_unsupported_ordering_slicing_raises_db_error (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\n\n======================================================================\nFAIL: test_union_with_values (queries.test_qs_combinators.QuerySetSetOperationTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/queries/test_qs_combinators.py\", line 128, in test_union_with_values\n    self.assertEqual(reserved_name, (2,))\nAssertionError: Tuples differ: ('a', 2, 1) != (2,)\n\nFirst differing element 0:\n'a'\n2\n\nFirst tuple contains 2 additional elements.\nFirst extra element 1:\n2\n\n- ('a', 2, 1)\n+ (2,)\n\n----------------------------------------------------------------------\nRan 26 tests in 0.039s\n\nFAILED (failures=1, skipped=2)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 queries.test_qs_combinators` failed. (See above for error)",
          "test_files_run": [
            "tests/queries/test_qs_combinators.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 26,
          "failed": 0,
          "errors": 0,
          "duration": 7.62,
          "log_tail": "    Creating table queries_ticket23605a\n    Creating table queries_ticket23605b\n    Creating table queries_ticket23605c\n    Creating table Individual\n    Creating table RelatedIndividual\n    Creating table queries_customdbcolumn\n    Running deferred SQL...\nRunning migrations:\n  Applying admin.0001_initial... OK\n  Applying admin.0002_logentry_remove_auto_add... OK\n  Applying admin.0003_logentry_add_action_flag_choices... OK\n  Applying sites.0001_initial... OK\n  Applying sites.0002_alter_domain_unique... OK\nSystem check identified no issues (1 silenced).\n\n\nCreating test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\ntest_combining_multiple_models (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_count_difference (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_count_intersection (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_count_union (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_count_union_empty_result (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_difference_with_empty_qs (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_difference_with_values (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_intersection_with_empty_qs (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_intersection_with_values (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_limits (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_order_raises_on_non_selected_column (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_ordering (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_ordering_by_f_expression (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_ordering_subqueries (queries.test_qs_combinators.QuerySetSetOperationTests) ... skipped \"Database doesn't support feature(s): supports_slicing_ordering_in_compound\"\ntest_qs_with_subcompound_qs (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_simple_difference (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_simple_intersection (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_simple_union (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_union_distinct (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_union_with_empty_qs (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_union_with_extra_and_values_list (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_union_with_two_annotated_values_list (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_union_with_values (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_union_with_values_list_on_annotated_and_unannotated (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_unsupported_intersection_raises_db_error (queries.test_qs_combinators.QuerySetSetOperationTests) ... skipped 'Database has feature(s) supports_select_intersection'\ntest_unsupported_ordering_slicing_raises_db_error (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\n\n----------------------------------------------------------------------\nRan 26 tests in 0.036s\n\nOK (skipped=2)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/queries/test_qs_combinators.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-11532",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 32.5494270324707,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 157,
          "failed": 0,
          "errors": 1,
          "duration": 10.76,
          "log_tail": "test_manager_and_admin_mail_prefix (mail.tests.SMTPBackendTests) ... ok\ntest_message_cc_header (mail.tests.SMTPBackendTests) ... ok\ntest_plaintext_send_mail (mail.tests.SMTPBackendTests) ... ok\ntest_recipient_without_domain (mail.tests.SMTPBackendTests) ... ok\ntest_reopen_connection (mail.tests.SMTPBackendTests) ... ok\ntest_send (mail.tests.SMTPBackendTests) ... ok\ntest_send_long_lines (mail.tests.SMTPBackendTests) ... ok\ntest_send_many (mail.tests.SMTPBackendTests) ... ok\ntest_send_messages_after_open_failed (mail.tests.SMTPBackendTests) ... ok\ntest_send_messages_empty_list (mail.tests.SMTPBackendTests) ... ok\ntest_send_messages_zero_sent (mail.tests.SMTPBackendTests)\nA message isn't sent if it doesn't have any recipients. ... ok\ntest_send_unicode (mail.tests.SMTPBackendTests) ... ok\ntest_send_verbose_name (mail.tests.SMTPBackendTests) ... ok\ntest_server_login (mail.tests.SMTPBackendTests) ... ok\ntest_server_open (mail.tests.SMTPBackendTests) ... ok\ntest_ssl_tls_mutually_exclusive (mail.tests.SMTPBackendTests) ... ok\ntest_use_as_contextmanager (mail.tests.SMTPBackendTests) ... ok\ntest_wrong_admins_managers (mail.tests.SMTPBackendTests) ... ok\n\n======================================================================\nERROR: test_non_ascii_dns_non_unicode_email (mail.tests.MailTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/mock.py\", line 1183, in patched\n    return func(*args, **keywargs)\n  File \"/testbed/tests/mail/tests.py\", line 374, in test_non_ascii_dns_non_unicode_email\n    self.assertIn('@xn--p8s937b>', email.message()['Message-ID'])\n  File \"/testbed/django/core/mail/message.py\", line 260, in message\n    msg['Message-ID'] = make_msgid(domain=DNS_NAME)\n  File \"/testbed/django/core/mail/message.py\", line 157, in __setitem__\n    name, val = forbid_multi_line_headers(name, val, self.encoding)\n  File \"/testbed/django/core/mail/message.py\", line 67, in forbid_multi_line_headers\n    val = Header(val, encoding).encode()\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/email/header.py\", line 217, in __init__\n    self.append(s, charset, errors)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/email/header.py\", line 301, in append\n    s.encode(output_charset, errors)\nUnicodeEncodeError: 'latin-1' codec can't encode characters in position 38-39: ordinal not in range(256)\n\n----------------------------------------------------------------------\nRan 158 tests in 1.386s\n\nFAILED (errors=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 mail.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/mail/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 158,
          "failed": 0,
          "errors": 0,
          "duration": 7.86,
          "log_tail": "#23063 -- RFC-compliant messages are sent over SMTP. ... ok\ntest_email_ssl_attempts_ssl_connection (mail.tests.SMTPBackendTests) ... ok\ntest_email_ssl_certfile_default_disabled (mail.tests.SMTPBackendTests) ... ok\ntest_email_ssl_certfile_override_settings (mail.tests.SMTPBackendTests) ... ok\ntest_email_ssl_certfile_use_settings (mail.tests.SMTPBackendTests) ... ok\ntest_email_ssl_default_disabled (mail.tests.SMTPBackendTests) ... ok\ntest_email_ssl_keyfile_default_disabled (mail.tests.SMTPBackendTests) ... ok\ntest_email_ssl_keyfile_override_settings (mail.tests.SMTPBackendTests) ... ok\ntest_email_ssl_keyfile_use_settings (mail.tests.SMTPBackendTests) ... ok\ntest_email_ssl_override_settings (mail.tests.SMTPBackendTests) ... ok\ntest_email_ssl_use_settings (mail.tests.SMTPBackendTests) ... ok\ntest_email_timeout_override_settings (mail.tests.SMTPBackendTests) ... ok\ntest_email_tls_attempts_starttls (mail.tests.SMTPBackendTests) ... ok\ntest_email_tls_default_disabled (mail.tests.SMTPBackendTests) ... ok\ntest_email_tls_override_settings (mail.tests.SMTPBackendTests) ... ok\ntest_email_tls_use_settings (mail.tests.SMTPBackendTests) ... ok\ntest_empty_admins (mail.tests.SMTPBackendTests) ... ok\ntest_html_mail_admins (mail.tests.SMTPBackendTests)\nTest html_message argument to mail_admins ... ok\ntest_html_mail_managers (mail.tests.SMTPBackendTests)\nTest html_message argument to mail_managers ... ok\ntest_html_send_mail (mail.tests.SMTPBackendTests)\nTest html_message argument to send_mail ... ok\ntest_idn_send (mail.tests.SMTPBackendTests) ... ok\ntest_lazy_addresses (mail.tests.SMTPBackendTests) ... ok\ntest_manager_and_admin_mail_prefix (mail.tests.SMTPBackendTests) ... ok\ntest_message_cc_header (mail.tests.SMTPBackendTests) ... ok\ntest_plaintext_send_mail (mail.tests.SMTPBackendTests) ... ok\ntest_recipient_without_domain (mail.tests.SMTPBackendTests) ... ok\ntest_reopen_connection (mail.tests.SMTPBackendTests) ... ok\ntest_send (mail.tests.SMTPBackendTests) ... ok\ntest_send_long_lines (mail.tests.SMTPBackendTests) ... ok\ntest_send_many (mail.tests.SMTPBackendTests) ... ok\ntest_send_messages_after_open_failed (mail.tests.SMTPBackendTests) ... ok\ntest_send_messages_empty_list (mail.tests.SMTPBackendTests) ... ok\ntest_send_messages_zero_sent (mail.tests.SMTPBackendTests)\nA message isn't sent if it doesn't have any recipients. ... ok\ntest_send_unicode (mail.tests.SMTPBackendTests) ... ok\ntest_send_verbose_name (mail.tests.SMTPBackendTests) ... ok\ntest_server_login (mail.tests.SMTPBackendTests) ... ok\ntest_server_open (mail.tests.SMTPBackendTests) ... ok\ntest_ssl_tls_mutually_exclusive (mail.tests.SMTPBackendTests) ... ok\ntest_use_as_contextmanager (mail.tests.SMTPBackendTests) ... ok\ntest_wrong_admins_managers (mail.tests.SMTPBackendTests) ... ok\n\n----------------------------------------------------------------------\nRan 158 tests in 1.361s\n\nOK\n",
          "test_files_run": [
            "tests/mail/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-11551",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 28.26633620262146,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 119,
          "failed": 1,
          "errors": 0,
          "duration": 8.85,
          "log_tail": "test_valid_case (modeladmin.test_checks.PrepopulatedFieldsCheckTests) ... ok\ntest_not_iterable (modeladmin.test_checks.SearchFieldsCheckTests) ... ok\ntest_invalid_expression (modeladmin.test_checks.OrderingCheckTests) ... ok\ntest_not_iterable (modeladmin.test_checks.OrderingCheckTests) ... ok\ntest_random_marker_not_alone (modeladmin.test_checks.OrderingCheckTests) ... ok\ntest_valid_case (modeladmin.test_checks.OrderingCheckTests) ... ok\ntest_valid_complex_case (modeladmin.test_checks.OrderingCheckTests) ... ok\ntest_valid_expression (modeladmin.test_checks.OrderingCheckTests) ... ok\ntest_valid_random_marker_case (modeladmin.test_checks.OrderingCheckTests) ... ok\ntest_invalid_field_type (modeladmin.test_checks.ListDisplayTests) ... ok\ntest_missing_field (modeladmin.test_checks.ListDisplayTests) ... ok\ntest_not_iterable (modeladmin.test_checks.ListDisplayTests) ... ok\ntest_valid_case (modeladmin.test_checks.ListDisplayTests) ... ok\ntest_valid_field_accessible_via_instance (modeladmin.test_checks.ListDisplayTests) ... FAIL\n\n======================================================================\nFAIL: test_valid_field_accessible_via_instance (modeladmin.test_checks.ListDisplayTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/modeladmin/test_checks.py\", line 529, in test_valid_field_accessible_via_instance\n    self.assertIsValid(TestModelAdmin, TestModel)\n  File \"/testbed/tests/modeladmin/test_checks.py\", line 43, in assertIsValid\n    self.assertEqual(admin_obj.check(), [])\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1028, in assertListEqual\n    self.assertSequenceEqual(list1, list2, msg, seq_type=list)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1010, in assertSequenceEqual\n    self.fail(msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: Lists differ: [<Error: level=40, msg=\"The value of 'list[289 chars]08'>] != []\n\nFirst list contains 1 additional elements.\nFirst extra element 0:\n<Error: level=40, msg=\"The value of 'list_display[0]' refers to 'field', which is not a callable, an attribute of 'TestModelAdmin', or an attribute or method on 'modeladmin.TestModel'.\", hint=None, obj=<class 'modeladmin.test_checks.ListDisplayTests.test_valid_field_accessible_via_instance.<locals>.TestModelAdmin'>, id='admin.E108'>\n\n- [<Error: level=40, msg=\"The value of 'list_display[0]' refers to 'field', which is not a callable, an attribute of 'TestModelAdmin', or an attribute or method on 'modeladmin.TestModel'.\", hint=None, obj=<class 'modeladmin.test_checks.ListDisplayTests.test_valid_field_accessible_via_instance.<locals>.TestModelAdmin'>, id='admin.E108'>]\n+ []\n\n----------------------------------------------------------------------\nRan 120 tests in 0.255s\n\nFAILED (failures=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 modeladmin.test_checks` failed. (See above for error)",
          "test_files_run": [
            "tests/modeladmin/test_checks.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 120,
          "failed": 0,
          "errors": 0,
          "duration": 7.87,
          "log_tail": "test_not_callable (modeladmin.test_checks.ListFilterTests) ... ok\ntest_not_filter (modeladmin.test_checks.ListFilterTests) ... ok\ntest_not_filter_again (modeladmin.test_checks.ListFilterTests) ... ok\ntest_not_filter_again_again (modeladmin.test_checks.ListFilterTests) ... ok\ntest_not_list_filter_class (modeladmin.test_checks.ListFilterTests) ... ok\ntest_valid_case (modeladmin.test_checks.ListFilterTests) ... ok\ntest_invalid_field_type (modeladmin.test_checks.RadioFieldsCheckTests) ... ok\ntest_invalid_value (modeladmin.test_checks.RadioFieldsCheckTests) ... ok\ntest_missing_field (modeladmin.test_checks.RadioFieldsCheckTests) ... ok\ntest_not_dictionary (modeladmin.test_checks.RadioFieldsCheckTests) ... ok\ntest_valid_case (modeladmin.test_checks.RadioFieldsCheckTests) ... ok\ntest_None_is_valid_case (modeladmin.test_checks.ListDisplayLinksCheckTests) ... ok\ntest_list_display_link_checked_for_list_tuple_if_get_list_display_overridden (modeladmin.test_checks.ListDisplayLinksCheckTests) ... ok\ntest_list_display_links_check_skipped_if_get_list_display_overridden (modeladmin.test_checks.ListDisplayLinksCheckTests) ... ok\ntest_missing_field (modeladmin.test_checks.ListDisplayLinksCheckTests) ... ok\ntest_missing_in_list_display (modeladmin.test_checks.ListDisplayLinksCheckTests) ... ok\ntest_not_iterable (modeladmin.test_checks.ListDisplayLinksCheckTests) ... ok\ntest_valid_case (modeladmin.test_checks.ListDisplayLinksCheckTests) ... ok\ntest_invalid_field_type (modeladmin.test_checks.RawIdCheckTests) ... ok\ntest_missing_field (modeladmin.test_checks.RawIdCheckTests) ... ok\ntest_not_iterable (modeladmin.test_checks.RawIdCheckTests) ... ok\ntest_valid_case (modeladmin.test_checks.RawIdCheckTests) ... ok\ntest_invalid_callable (modeladmin.test_checks.InlinesCheckTests) ... ok\ntest_invalid_model (modeladmin.test_checks.InlinesCheckTests) ... ok\ntest_invalid_model_type (modeladmin.test_checks.InlinesCheckTests) ... ok\ntest_missing_model_field (modeladmin.test_checks.InlinesCheckTests) ... ok\ntest_not_correct_inline_field (modeladmin.test_checks.InlinesCheckTests) ... ok\ntest_not_iterable (modeladmin.test_checks.InlinesCheckTests) ... ok\ntest_not_model_admin (modeladmin.test_checks.InlinesCheckTests) ... ok\ntest_valid_case (modeladmin.test_checks.InlinesCheckTests) ... ok\ntest_not_integer (modeladmin.test_checks.MinNumCheckTests) ... ok\ntest_valid_case (modeladmin.test_checks.MinNumCheckTests) ... ok\ntest_invalid_field_type (modeladmin.test_checks.ListDisplayTests) ... ok\ntest_missing_field (modeladmin.test_checks.ListDisplayTests) ... ok\ntest_not_iterable (modeladmin.test_checks.ListDisplayTests) ... ok\ntest_valid_case (modeladmin.test_checks.ListDisplayTests) ... ok\ntest_valid_field_accessible_via_instance (modeladmin.test_checks.ListDisplayTests) ... ok\ntest_invalid_expression (modeladmin.test_checks.OrderingCheckTests) ... ok\ntest_not_iterable (modeladmin.test_checks.OrderingCheckTests) ... ok\ntest_random_marker_not_alone (modeladmin.test_checks.OrderingCheckTests) ... ok\ntest_valid_case (modeladmin.test_checks.OrderingCheckTests) ... ok\ntest_valid_complex_case (modeladmin.test_checks.OrderingCheckTests) ... ok\ntest_valid_expression (modeladmin.test_checks.OrderingCheckTests) ... ok\ntest_valid_random_marker_case (modeladmin.test_checks.OrderingCheckTests) ... ok\n\n----------------------------------------------------------------------\nRan 120 tests in 0.256s\n\nOK\n",
          "test_files_run": [
            "tests/modeladmin/test_checks.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-11555",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 29.72299599647522,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 26,
          "failed": 0,
          "errors": 1,
          "duration": 9.71,
          "log_tail": "ERROR: test_order_by_ptr_field_with_default_ordering_by_expression (ordering.tests.OrderingTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/ordering/tests.py\", line 483, in test_order_by_ptr_field_with_default_ordering_by_expression\n    self.assertSequenceEqual(articles, [ca4, ca2, ca1, ca3])\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1005, in assertSequenceEqual\n    difflib.ndiff(pprint.pformat(seq1).splitlines(),\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/pprint.py\", line 58, in pformat\n    compact=compact).pformat(object)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/pprint.py\", line 144, in pformat\n    self._format(object, sio, 0, 0, {}, 0)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/pprint.py\", line 161, in _format\n    rep = self._repr(object, context, level)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/pprint.py\", line 393, in _repr\n    self._depth, level)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/pprint.py\", line 405, in format\n    return _safe_repr(object, context, maxlevels, level)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/pprint.py\", line 555, in _safe_repr\n    rep = repr(object)\n  File \"/testbed/django/db/models/query.py\", line 252, in __repr__\n    data = list(self[:REPR_OUTPUT_SIZE + 1])\n  File \"/testbed/django/db/models/query.py\", line 276, in __iter__\n    self._fetch_all()\n  File \"/testbed/django/db/models/query.py\", line 1240, in _fetch_all\n    self._result_cache = list(self._iterable_class(self))\n  File \"/testbed/django/db/models/query.py\", line 57, in __iter__\n    results = compiler.execute_sql(chunked_fetch=self.chunked_fetch, chunk_size=self.chunk_size)\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1082, in execute_sql\n    sql, params = self.as_sql()\n  File \"/testbed/django/db/models/sql/compiler.py\", line 480, in as_sql\n    extra_select, order_by, group_by = self.pre_sql_setup()\n  File \"/testbed/django/db/models/sql/compiler.py\", line 53, in pre_sql_setup\n    order_by = self.get_order_by()\n  File \"/testbed/django/db/models/sql/compiler.py\", line 330, in get_order_by\n    field, self.query.get_meta(), default_order=asc))\n  File \"/testbed/django/db/models/sql/compiler.py\", line 726, in find_ordering_name\n    order, already_seen))\n  File \"/testbed/django/db/models/sql/compiler.py\", line 707, in find_ordering_name\n    name, order = get_order_dir(name, default_order)\n  File \"/testbed/django/db/models/sql/query.py\", line 2221, in get_order_dir\n    if field[0] == '-':\nTypeError: 'OrderBy' object does not support indexing\n\n----------------------------------------------------------------------\nRan 27 tests in 0.093s\n\nFAILED (errors=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 ordering.models ordering.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/ordering/models.py",
            "tests/ordering/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 27,
          "failed": 0,
          "errors": 0,
          "duration": 8.1,
          "log_tail": "    Creating table ordering_author\n    Creating table ordering_article\n    Creating table ordering_childarticle\n    Creating table ordering_reference\n    Running deferred SQL...\nRunning migrations:\n  Applying admin.0001_initial... OK\n  Applying admin.0002_logentry_remove_auto_add... OK\n  Applying admin.0003_logentry_add_action_flag_choices... OK\n  Applying sites.0001_initial... OK\n  Applying sites.0002_alter_domain_unique... OK\nSystem check identified no issues (0 silenced).\n\n\nCreating test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\ntest_default_ordering (ordering.tests.OrderingTests) ... ok\ntest_default_ordering_by_f_expression (ordering.tests.OrderingTests)\nF expressions can be used in Meta.ordering. ... ok\ntest_default_ordering_override (ordering.tests.OrderingTests) ... ok\ntest_deprecated_values_annotate (ordering.tests.OrderingTests) ... ok\ntest_extra_ordering (ordering.tests.OrderingTests) ... ok\ntest_extra_ordering_quoting (ordering.tests.OrderingTests) ... ok\ntest_extra_ordering_with_table_name (ordering.tests.OrderingTests) ... ok\ntest_no_reordering_after_slicing (ordering.tests.OrderingTests) ... ok\ntest_order_by_constant_value (ordering.tests.OrderingTests) ... ok\ntest_order_by_constant_value_without_output_field (ordering.tests.OrderingTests) ... ok\ntest_order_by_f_expression (ordering.tests.OrderingTests) ... ok\ntest_order_by_f_expression_duplicates (ordering.tests.OrderingTests) ... ok\ntest_order_by_fk_attname (ordering.tests.OrderingTests) ... ok\ntest_order_by_nulls_first (ordering.tests.OrderingTests) ... ok\ntest_order_by_nulls_first_and_last (ordering.tests.OrderingTests) ... ok\ntest_order_by_nulls_last (ordering.tests.OrderingTests) ... ok\ntest_order_by_override (ordering.tests.OrderingTests) ... ok\ntest_order_by_pk (ordering.tests.OrderingTests) ... ok\ntest_order_by_ptr_field_with_default_ordering_by_expression (ordering.tests.OrderingTests) ... ok\ntest_orders_nulls_first_on_filtered_subquery (ordering.tests.OrderingTests) ... ok\ntest_random_ordering (ordering.tests.OrderingTests) ... ok\ntest_related_ordering_duplicate_table_reference (ordering.tests.OrderingTests) ... ok\ntest_reverse_meta_ordering_pure (ordering.tests.OrderingTests) ... ok\ntest_reverse_ordering_pure (ordering.tests.OrderingTests) ... ok\ntest_reversed_ordering (ordering.tests.OrderingTests) ... ok\ntest_stop_slicing (ordering.tests.OrderingTests) ... ok\ntest_stop_start_slicing (ordering.tests.OrderingTests) ... ok\n\n----------------------------------------------------------------------\nRan 27 tests in 0.085s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/ordering/models.py",
            "tests/ordering/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-11603",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 30.03420901298523,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 58,
          "failed": 0,
          "errors": 2,
          "duration": 9.84,
          "log_tail": "test_fkey_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_group_by_exists_annotation (aggregation.tests.AggregateTestCase) ... ok\ntest_group_by_subquery_annotation (aggregation.tests.AggregateTestCase) ... ok\ntest_grouped_annotation_in_group_by (aggregation.tests.AggregateTestCase) ... ok\ntest_missing_output_field_raises_error (aggregation.tests.AggregateTestCase) ... ok\ntest_more_aggregation (aggregation.tests.AggregateTestCase) ... ok\ntest_multi_arg_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_multiple_aggregates (aggregation.tests.AggregateTestCase) ... ok\ntest_non_grouped_annotation_not_in_group_by (aggregation.tests.AggregateTestCase) ... ok\ntest_nonaggregate_aggregation_throws (aggregation.tests.AggregateTestCase) ... ok\ntest_nonfield_annotation (aggregation.tests.AggregateTestCase) ... ok\ntest_order_of_precedence (aggregation.tests.AggregateTestCase) ... ok\ntest_related_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_reverse_fkey_annotate (aggregation.tests.AggregateTestCase) ... ok\ntest_single_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_sum_distinct_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_sum_duration_field (aggregation.tests.AggregateTestCase) ... ok\ntest_ticket11881 (aggregation.tests.AggregateTestCase) ... ok\ntest_ticket12886 (aggregation.tests.AggregateTestCase) ... ok\ntest_ticket17424 (aggregation.tests.AggregateTestCase) ... ok\ntest_values_aggregation (aggregation.tests.AggregateTestCase) ... ok\ntest_values_annotation_with_expression (aggregation.tests.AggregateTestCase) ... ok\n\n======================================================================\nERROR: test_distinct_on_aggregate (aggregation.tests.AggregateTestCase) (aggregate='Avg')\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/aggregation/tests.py\", line 410, in test_distinct_on_aggregate\n    books = Book.objects.aggregate(ratings=aggregate('rating', distinct=True))\n  File \"/testbed/django/db/models/aggregates.py\", line 26, in __init__\n    raise TypeError(\"%s does not allow distinct.\" % self.__class__.__name__)\nTypeError: Avg does not allow distinct.\n\n======================================================================\nERROR: test_distinct_on_aggregate (aggregation.tests.AggregateTestCase) (aggregate='Sum')\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/aggregation/tests.py\", line 410, in test_distinct_on_aggregate\n    books = Book.objects.aggregate(ratings=aggregate('rating', distinct=True))\n  File \"/testbed/django/db/models/aggregates.py\", line 26, in __init__\n    raise TypeError(\"%s does not allow distinct.\" % self.__class__.__name__)\nTypeError: Sum does not allow distinct.\n\n----------------------------------------------------------------------\nRan 60 tests in 0.181s\n\nFAILED (errors=2)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 aggregation.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/aggregation/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 60,
          "failed": 0,
          "errors": 0,
          "duration": 8.22,
          "log_tail": "test_annotated_aggregate_over_annotated_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_annotation (aggregation.tests.AggregateTestCase) ... ok\ntest_annotation_expressions (aggregation.tests.AggregateTestCase) ... ok\ntest_arguments_must_be_expressions (aggregation.tests.AggregateTestCase) ... ok\ntest_avg_decimal_field (aggregation.tests.AggregateTestCase) ... ok\ntest_avg_duration_field (aggregation.tests.AggregateTestCase) ... ok\ntest_backwards_m2m_annotate (aggregation.tests.AggregateTestCase) ... ok\ntest_combine_different_types (aggregation.tests.AggregateTestCase) ... ok\ntest_complex_aggregations_require_kwarg (aggregation.tests.AggregateTestCase) ... ok\ntest_complex_values_aggregation (aggregation.tests.AggregateTestCase) ... ok\ntest_count (aggregation.tests.AggregateTestCase) ... ok\ntest_count_distinct_expression (aggregation.tests.AggregateTestCase) ... ok\ntest_count_star (aggregation.tests.AggregateTestCase) ... ok\ntest_dates_with_aggregation (aggregation.tests.AggregateTestCase) ... ok\ntest_decimal_max_digits_has_no_effect (aggregation.tests.AggregateTestCase) ... ok\ntest_distinct_on_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_empty_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_even_more_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_expression_on_aggregation (aggregation.tests.AggregateTestCase) ... ok\ntest_filter_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_filtering (aggregation.tests.AggregateTestCase) ... ok\ntest_fkey_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_group_by_exists_annotation (aggregation.tests.AggregateTestCase) ... ok\ntest_group_by_subquery_annotation (aggregation.tests.AggregateTestCase) ... ok\ntest_grouped_annotation_in_group_by (aggregation.tests.AggregateTestCase) ... ok\ntest_missing_output_field_raises_error (aggregation.tests.AggregateTestCase) ... ok\ntest_more_aggregation (aggregation.tests.AggregateTestCase) ... ok\ntest_multi_arg_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_multiple_aggregates (aggregation.tests.AggregateTestCase) ... ok\ntest_non_grouped_annotation_not_in_group_by (aggregation.tests.AggregateTestCase) ... ok\ntest_nonaggregate_aggregation_throws (aggregation.tests.AggregateTestCase) ... ok\ntest_nonfield_annotation (aggregation.tests.AggregateTestCase) ... ok\ntest_order_of_precedence (aggregation.tests.AggregateTestCase) ... ok\ntest_related_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_reverse_fkey_annotate (aggregation.tests.AggregateTestCase) ... ok\ntest_single_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_sum_distinct_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_sum_duration_field (aggregation.tests.AggregateTestCase) ... ok\ntest_ticket11881 (aggregation.tests.AggregateTestCase) ... ok\ntest_ticket12886 (aggregation.tests.AggregateTestCase) ... ok\ntest_ticket17424 (aggregation.tests.AggregateTestCase) ... ok\ntest_values_aggregation (aggregation.tests.AggregateTestCase) ... ok\ntest_values_annotation_with_expression (aggregation.tests.AggregateTestCase) ... ok\n\n----------------------------------------------------------------------\nRan 60 tests in 0.192s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/aggregation/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-11728",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 33.37972092628479,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 42,
          "failed": 4,
          "errors": 0,
          "duration": 10.86,
          "log_tail": "  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 523, in subTest\n    yield\n  File \"/testbed/tests/admin_docs/test_views.py\", line 364, in test_simplify_regex\n    self.assertEqual(simplify_regex(pattern), output)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1203, in assertMultiLineEqual\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: '/<a>/b/(<var>\\\\w+)' != '/<a>/b/<var>'\n- /<a>/b/(<var>\\w+)\n?        -     ----\n+ /<a>/b/<var>\n\n\n======================================================================\nFAIL: test_simplify_regex (admin_docs.test_views.AdminDocViewFunctionsTests) [<object object at 0x77dc82077cf0>] (pattern='^(?P<a>(x|y))/b/(?P<c>\\\\w+)')\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 523, in subTest\n    yield\n  File \"/testbed/tests/admin_docs/test_views.py\", line 364, in test_simplify_regex\n    self.assertEqual(simplify_regex(pattern), output)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1203, in assertMultiLineEqual\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: '/<a>/b/(P<c>\\\\w+)' != '/<a>/b/<c>'\n- /<a>/b/(P<c>\\w+)\n?        --   ----\n+ /<a>/b/<c>\n\n\n----------------------------------------------------------------------\nRan 46 tests in 1.518s\n\nFAILED (failures=4)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 admin_docs.test_views` failed. (See above for error)",
          "test_files_run": [
            "tests/admin_docs/test_views.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 46,
          "failed": 0,
          "errors": 0,
          "duration": 8.43,
          "log_tail": "test_method_excludes (admin_docs.test_views.TestModelDetailView) ... ok\ntest_methods_with_arguments (admin_docs.test_views.TestModelDetailView) ... ok\ntest_methods_with_arguments_display_arguments (admin_docs.test_views.TestModelDetailView) ... ok\ntest_methods_with_arguments_display_arguments_default_value (admin_docs.test_views.TestModelDetailView) ... ok\ntest_methods_with_multiple_arguments_display_arguments (admin_docs.test_views.TestModelDetailView) ... ok\ntest_model_detail_title (admin_docs.test_views.TestModelDetailView) ... ok\ntest_model_docstring_renders_correctly (admin_docs.test_views.TestModelDetailView) ... ok\ntest_model_not_found (admin_docs.test_views.TestModelDetailView) ... ok\ntest_model_with_many_to_one (admin_docs.test_views.TestModelDetailView) ... ok\ntest_model_with_no_backward_relations_render_only_relevant_fields (admin_docs.test_views.TestModelDetailView) ... ok\ntest_bookmarklets (admin_docs.test_views.AdminDocViewTests) ... ok\ntest_index (admin_docs.test_views.AdminDocViewTests) ... ok\ntest_missing_docutils (admin_docs.test_views.AdminDocViewTests) ... ok\ntest_model_index (admin_docs.test_views.AdminDocViewTests) ... ok\ntest_namespaced_view_detail (admin_docs.test_views.AdminDocViewTests) ... ok\ntest_no_sites_framework (admin_docs.test_views.AdminDocViewTests) ... ok\ntest_template_detail (admin_docs.test_views.AdminDocViewTests) ... ok\ntest_templatefilter_index (admin_docs.test_views.AdminDocViewTests) ... ok\ntest_templatetag_index (admin_docs.test_views.AdminDocViewTests) ... ok\ntest_view_detail (admin_docs.test_views.AdminDocViewTests) ... ok\ntest_view_detail_as_method (admin_docs.test_views.AdminDocViewTests) ... ok\ntest_view_detail_illegal_import (admin_docs.test_views.AdminDocViewTests) ... ok\ntest_view_index (admin_docs.test_views.AdminDocViewTests) ... ok\ntest_view_index_with_method (admin_docs.test_views.AdminDocViewTests) ... ok\ntest_bookmarklets (admin_docs.test_views.AdminDocViewWithMultipleEngines) ... ok\ntest_index (admin_docs.test_views.AdminDocViewWithMultipleEngines) ... ok\ntest_missing_docutils (admin_docs.test_views.AdminDocViewWithMultipleEngines) ... ok\ntest_model_index (admin_docs.test_views.AdminDocViewWithMultipleEngines) ... ok\ntest_namespaced_view_detail (admin_docs.test_views.AdminDocViewWithMultipleEngines) ... ok\ntest_no_sites_framework (admin_docs.test_views.AdminDocViewWithMultipleEngines) ... ok\ntest_template_detail (admin_docs.test_views.AdminDocViewWithMultipleEngines) ... ok\ntest_templatefilter_index (admin_docs.test_views.AdminDocViewWithMultipleEngines) ... ok\ntest_templatetag_index (admin_docs.test_views.AdminDocViewWithMultipleEngines) ... ok\ntest_view_detail (admin_docs.test_views.AdminDocViewWithMultipleEngines) ... ok\ntest_view_detail_as_method (admin_docs.test_views.AdminDocViewWithMultipleEngines) ... ok\ntest_view_detail_illegal_import (admin_docs.test_views.AdminDocViewWithMultipleEngines) ... ok\ntest_view_index (admin_docs.test_views.AdminDocViewWithMultipleEngines) ... ok\ntest_view_index_with_method (admin_docs.test_views.AdminDocViewWithMultipleEngines) ... ok\n\n----------------------------------------------------------------------\nRan 46 tests in 1.923s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/admin_docs/test_views.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-11734",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 32.850841999053955,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 279,
          "failed": 2,
          "errors": 1,
          "duration": 10.25,
          "log_tail": "Destroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 queries.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/queries/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 282,
          "failed": 0,
          "errors": 0,
          "duration": 7.77,
          "log_tail": "Destroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/queries/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-11740",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "django__django-11749",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 39.88274908065796,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 34,
          "failed": 0,
          "errors": 1,
          "duration": 9.15,
          "log_tail": "test_create_parser_kwargs (user_commands.tests.CommandTests)\nBaseCommand.create_parser() passes kwargs to CommandParser. ... ok\ntest_discover_commands_in_eggs (user_commands.tests.CommandTests) ... ok\ntest_explode (user_commands.tests.CommandTests)\nAn unknown command raises CommandError ... ok\ntest_find_command_without_PATH (user_commands.tests.CommandTests) ... ok\ntest_language_preserved (user_commands.tests.CommandTests) ... ok\ntest_mutually_exclusive_group_required_options (user_commands.tests.CommandTests) ... ERROR\ntest_no_translations_deactivate_translations (user_commands.tests.CommandTests) ... ok\ntest_output_transaction (user_commands.tests.CommandTests) ... ok\ntest_subparser (user_commands.tests.CommandTests) ... ok\ntest_subparser_dest_args (user_commands.tests.CommandTests) ... ok\ntest_subparser_dest_required_args (user_commands.tests.CommandTests) ... ok\ntest_subparser_invalid_option (user_commands.tests.CommandTests) ... ok\ntest_system_exit (user_commands.tests.CommandTests)\nException raised in a command should raise CommandError with ... ok\ntest_disallowed_abbreviated_options (user_commands.tests.CommandRunTests) ... ok\ntest_script_prefix_set_in_commands (user_commands.tests.CommandRunTests) ... ok\ntest_skip_checks (user_commands.tests.CommandRunTests) ... ok\n\n======================================================================\nERROR: test_mutually_exclusive_group_required_options (user_commands.tests.CommandTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/user_commands/tests.py\", line 219, in test_mutually_exclusive_group_required_options\n    management.call_command('mutually_exclusive_required', foo_id=1, stdout=out)\n  File \"/testbed/django/core/management/__init__.py\", line 139, in call_command\n    defaults = parser.parse_args(args=parse_args)\n  File \"/testbed/django/core/management/base.py\", line 55, in parse_args\n    return super().parse_args(args, namespace)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/argparse.py\", line 1734, in parse_args\n    args, argv = self.parse_known_args(args, namespace)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/argparse.py\", line 1766, in parse_known_args\n    namespace, args = self._parse_known_args(args, namespace)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/argparse.py\", line 2016, in _parse_known_args\n    self.error(msg % ' '.join(names))\n  File \"/testbed/django/core/management/base.py\", line 61, in error\n    raise CommandError(\"Error: %s\" % message)\ndjango.core.management.base.CommandError: Error: one of the arguments --foo-id --foo-name is required\n\n----------------------------------------------------------------------\nRan 35 tests in 1.261s\n\nFAILED (errors=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 user_commands.management.commands.mutually_exclusive_required user_commands.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/user_commands/management/commands/mutually_exclusive_required.py",
            "tests/user_commands/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 35,
          "failed": 0,
          "errors": 0,
          "duration": 9.01,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application user_commands\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_get_random_secret_key (user_commands.tests.UtilsTests) ... ok\ntest_is_ignored_path_false (user_commands.tests.UtilsTests) ... ok\ntest_is_ignored_path_true (user_commands.tests.UtilsTests) ... ok\ntest_no_existent_external_program (user_commands.tests.UtilsTests) ... ok\ntest_normalize_path_patterns_truncates_wildcard_base (user_commands.tests.UtilsTests) ... ok\ntest_call_command_no_checks (user_commands.tests.CommandTests) ... ok\ntest_call_command_option_parsing (user_commands.tests.CommandTests) ... ok\ntest_call_command_option_parsing_non_string_arg (user_commands.tests.CommandTests) ... ok\ntest_call_command_unrecognized_option (user_commands.tests.CommandTests) ... ok\ntest_call_command_with_required_parameters_in_mixed_options (user_commands.tests.CommandTests) ... ok\ntest_call_command_with_required_parameters_in_options (user_commands.tests.CommandTests) ... ok\ntest_calling_a_command_with_no_app_labels_and_parameters_should_raise_a_command_error (user_commands.tests.CommandTests) ... ok\ntest_calling_a_command_with_only_empty_parameter_should_ends_gracefully (user_commands.tests.CommandTests) ... ok\ntest_calling_command_with_app_labels_and_parameters_should_be_ok (user_commands.tests.CommandTests) ... ok\ntest_calling_command_with_parameters_and_app_labels_at_the_end_should_be_ok (user_commands.tests.CommandTests) ... ok\ntest_check_migrations (user_commands.tests.CommandTests) ... ok\ntest_command (user_commands.tests.CommandTests) ... ok\ntest_command_add_arguments_after_common_arguments (user_commands.tests.CommandTests) ... ok\ntest_command_style (user_commands.tests.CommandTests) ... ok\ntest_create_parser_kwargs (user_commands.tests.CommandTests)\nBaseCommand.create_parser() passes kwargs to CommandParser. ... ok\ntest_discover_commands_in_eggs (user_commands.tests.CommandTests) ... ok\ntest_explode (user_commands.tests.CommandTests)\nAn unknown command raises CommandError ... ok\ntest_find_command_without_PATH (user_commands.tests.CommandTests) ... ok\ntest_language_preserved (user_commands.tests.CommandTests) ... ok\ntest_mutually_exclusive_group_required_options (user_commands.tests.CommandTests) ... ok\ntest_no_translations_deactivate_translations (user_commands.tests.CommandTests) ... ok\ntest_output_transaction (user_commands.tests.CommandTests) ... ok\ntest_subparser (user_commands.tests.CommandTests) ... ok\ntest_subparser_dest_args (user_commands.tests.CommandTests) ... ok\ntest_subparser_dest_required_args (user_commands.tests.CommandTests) ... ok\ntest_subparser_invalid_option (user_commands.tests.CommandTests) ... ok\ntest_system_exit (user_commands.tests.CommandTests)\nException raised in a command should raise CommandError with ... ok\ntest_disallowed_abbreviated_options (user_commands.tests.CommandRunTests) ... ok\ntest_script_prefix_set_in_commands (user_commands.tests.CommandRunTests) ... ok\ntest_skip_checks (user_commands.tests.CommandRunTests) ... ok\n\n----------------------------------------------------------------------\nRan 35 tests in 1.511s\n\nOK\n",
          "test_files_run": [
            "tests/user_commands/management/commands/mutually_exclusive_required.py",
            "tests/user_commands/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-11790",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "django__django-11815",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "django__django-11820",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 29.664904832839966,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 63,
          "failed": 2,
          "errors": 0,
          "duration": 9.56,
          "log_tail": "  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1028, in assertListEqual\n    self.assertSequenceEqual(list1, list2, msg, seq_type=list)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1010, in assertSequenceEqual\n    self.fail(msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: Lists differ: [] != [<Error: level=40, msg=\"'ordering' refers [236 chars]15'>]\n\nSecond list contains 1 additional elements.\nFirst extra element 0:\n<Error: level=40, msg=\"'ordering' refers to the nonexistent field, related field, or lookup 'parent__field1__field2'.\", hint=None, obj=<class 'invalid_models_tests.test_models.OtherModelTests.test_ordering_pointing_multiple_times_to_model_fields.<locals>.Child'>, id='models.E015'>\n\n- []\n+ [<Error: level=40, msg=\"'ordering' refers to the nonexistent field, related field, or lookup 'parent__field1__field2'.\", hint=None, obj=<class 'invalid_models_tests.test_models.OtherModelTests.test_ordering_pointing_multiple_times_to_model_fields.<locals>.Child'>, id='models.E015'>]\n\n======================================================================\nFAIL: test_ordering_pointing_to_related_model_pk (invalid_models_tests.test_models.OtherModelTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/invalid_models_tests/test_models.py\", line 857, in test_ordering_pointing_to_related_model_pk\n    self.assertEqual(Child.check(), [])\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1028, in assertListEqual\n    self.assertSequenceEqual(list1, list2, msg, seq_type=list)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1010, in assertSequenceEqual\n    self.fail(msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: Lists differ: [<Error: level=40, msg=\"'ordering' refers [213 chars]15'>] != []\n\nFirst list contains 1 additional elements.\nFirst extra element 0:\n<Error: level=40, msg=\"'ordering' refers to the nonexistent field, related field, or lookup 'parent__pk'.\", hint=None, obj=<class 'invalid_models_tests.test_models.OtherModelTests.test_ordering_pointing_to_related_model_pk.<locals>.Child'>, id='models.E015'>\n\n- [<Error: level=40, msg=\"'ordering' refers to the nonexistent field, related field, or lookup 'parent__pk'.\", hint=None, obj=<class 'invalid_models_tests.test_models.OtherModelTests.test_ordering_pointing_to_related_model_pk.<locals>.Child'>, id='models.E015'>]\n+ []\n\n----------------------------------------------------------------------\nRan 65 tests in 0.291s\n\nFAILED (failures=2, skipped=2)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 invalid_models_tests.test_models` failed. (See above for error)",
          "test_files_run": [
            "tests/invalid_models_tests/test_models.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 65,
          "failed": 0,
          "errors": 0,
          "duration": 8.23,
          "log_tail": "test_list_containing_non_iterable (invalid_models_tests.test_models.UniqueTogetherTests) ... ok\ntest_non_iterable (invalid_models_tests.test_models.UniqueTogetherTests) ... ok\ntest_non_list (invalid_models_tests.test_models.UniqueTogetherTests) ... ok\ntest_pointing_to_fk (invalid_models_tests.test_models.UniqueTogetherTests) ... ok\ntest_pointing_to_m2m (invalid_models_tests.test_models.UniqueTogetherTests) ... ok\ntest_pointing_to_missing_field (invalid_models_tests.test_models.UniqueTogetherTests) ... ok\ntest_valid_model (invalid_models_tests.test_models.UniqueTogetherTests) ... ok\ntest_field_name_clash_with_child_accessor (invalid_models_tests.test_models.ShadowingFieldsTests) ... ok\ntest_id_clash (invalid_models_tests.test_models.ShadowingFieldsTests) ... ok\ntest_inheritance_clash (invalid_models_tests.test_models.ShadowingFieldsTests) ... ok\ntest_multigeneration_inheritance (invalid_models_tests.test_models.ShadowingFieldsTests) ... ok\ntest_multiinheritance_clash (invalid_models_tests.test_models.ShadowingFieldsTests) ... ok\ntest_just_order_with_respect_to_no_errors (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_just_ordering_no_errors (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_lazy_reference_checks (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_m2m_autogenerated_table_name_clash (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_m2m_field_table_name_clash (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_m2m_table_name_clash (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_m2m_to_concrete_and_proxy_allowed (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_m2m_unmanaged_shadow_models_not_checked (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_missing_parent_link (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_name_beginning_with_underscore (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_name_contains_double_underscores (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_name_ending_with_underscore (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_non_valid (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_ordering_allows_registered_lookups (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_ordering_non_iterable (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_ordering_pointing_multiple_times_to_model_fields (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_ordering_pointing_to_foreignkey_field (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_ordering_pointing_to_missing_field (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_ordering_pointing_to_missing_foreignkey_field (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_ordering_pointing_to_missing_related_field (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_ordering_pointing_to_missing_related_model_field (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_ordering_pointing_to_non_related_field (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_ordering_pointing_to_related_model_pk (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_ordering_pointing_to_two_related_model_field (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_ordering_with_order_with_respect_to (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_property_and_related_field_accessor_clash (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_single_primary_key (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_swappable_missing_app (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_swappable_missing_app_name (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_two_m2m_through_same_model_with_different_through_fields (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_two_m2m_through_same_relationship (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_unique_primary_key (invalid_models_tests.test_models.OtherModelTests) ... ok\n\n----------------------------------------------------------------------\nRan 65 tests in 0.276s\n\nOK (skipped=2)\n",
          "test_files_run": [
            "tests/invalid_models_tests/test_models.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-11848",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "django__django-11880",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 32.19126605987549,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 114,
          "failed": 1,
          "errors": 0,
          "duration": 6.84,
          "log_tail": "test_iterable_boundfield_select (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_label_has_required_css_class (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_label_split_datetime_not_displayed (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_label_suffix (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_label_tag_override (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_multipart_encoded_form (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_multiple_choice_checkbox (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_multiple_choice_list_data (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_multiple_hidden (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_multivalue_deep_copy (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_multivalue_field_validation (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_multivalue_initial_data (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_multivalue_optional_subfields (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_only_hidden_fields (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_optional_data (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_specifying_labels (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_subclassing_forms (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_templates_with_forms (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_unbound_form (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_unicode_values (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_update_error_dict (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_use_required_attribute_false (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_use_required_attribute_true (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_validating_multiple_fields (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_validators_independence (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_various_boolean_values (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_widget_output (forms_tests.tests.test_forms.FormsTestCase) ... ok\n\n======================================================================\nFAIL: test_field_deep_copy_error_messages (forms_tests.tests.test_forms.FormsTestCase)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/forms_tests/tests/test_forms.py\", line 3697, in test_field_deep_copy_error_messages\n    self.assertIsNot(field_copy.error_messages, field.error_messages)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1109, in assertIsNot\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: unexpectedly identical: {'required': 'This field is required.', 'invalid': 'Form custom error message.'}\n\n----------------------------------------------------------------------\nRan 115 tests in 0.483s\n\nFAILED (failures=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 forms_tests.tests.test_forms` failed. (See above for error)",
          "test_files_run": [
            "tests/forms_tests/tests/test_forms.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 115,
          "failed": 0,
          "errors": 0,
          "duration": 6.89,
          "log_tail": "test_form_with_noniterable_boundfield (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_forms_with_choices (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_forms_with_file_fields (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_forms_with_multiple_choice (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_forms_with_null_boolean (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_forms_with_prefixes (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_forms_with_radio (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_get_initial_for_field (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_has_error (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_help_text (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_hidden_data (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_hidden_initial_gets_id (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_hidden_widget (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_html_safe (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_id_on_field (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_initial_data (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_initial_datetime_values (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_iterable_boundfield_select (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_label_has_required_css_class (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_label_split_datetime_not_displayed (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_label_suffix (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_label_tag_override (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_multipart_encoded_form (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_multiple_choice_checkbox (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_multiple_choice_list_data (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_multiple_hidden (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_multivalue_deep_copy (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_multivalue_field_validation (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_multivalue_initial_data (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_multivalue_optional_subfields (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_only_hidden_fields (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_optional_data (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_specifying_labels (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_subclassing_forms (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_templates_with_forms (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_unbound_form (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_unicode_values (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_update_error_dict (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_use_required_attribute_false (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_use_required_attribute_true (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_validating_multiple_fields (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_validators_independence (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_various_boolean_values (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_widget_output (forms_tests.tests.test_forms.FormsTestCase) ... ok\n\n----------------------------------------------------------------------\nRan 115 tests in 0.581s\n\nOK\n",
          "test_files_run": [
            "tests/forms_tests/tests/test_forms.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-11885",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 32.43890404701233,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 44,
          "failed": 1,
          "errors": 0,
          "duration": 10.32,
          "log_tail": "test_setvalue (delete.tests.OnDeleteTests) ... ok\ntest_bulk (delete.tests.DeletionTests) ... ok\ntest_can_defer_constraint_checks (delete.tests.DeletionTests) ... ok\ntest_cannot_defer_constraint_checks (delete.tests.DeletionTests) ... skipped 'Database has feature(s) can_defer_constraint_checks'\ntest_delete_with_keeping_parents (delete.tests.DeletionTests) ... ok\ntest_delete_with_keeping_parents_relationships (delete.tests.DeletionTests) ... ok\ntest_deletion_order (delete.tests.DeletionTests) ... ok\ntest_hidden_related (delete.tests.DeletionTests) ... ok\ntest_instance_update (delete.tests.DeletionTests) ... ok\ntest_large_delete (delete.tests.DeletionTests) ... ok\ntest_large_delete_related (delete.tests.DeletionTests) ... ok\ntest_m2m (delete.tests.DeletionTests) ... ok\ntest_model_delete_returns_num_rows (delete.tests.DeletionTests) ... ok\ntest_only_referenced_fields_selected (delete.tests.DeletionTests) ... ok\ntest_proxied_model_duplicate_queries (delete.tests.DeletionTests) ... ok\ntest_queryset_delete_returns_num_rows (delete.tests.DeletionTests) ... ok\ntest_relational_post_delete_signals_happen_before_parent_object (delete.tests.DeletionTests) ... ok\n\n======================================================================\nFAIL: test_fast_delete_combined_relationships (delete.tests.FastDeleteTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/delete/tests.py\", line 592, in test_fast_delete_combined_relationships\n    referer.delete()\n  File \"/testbed/django/test/testcases.py\", line 83, in __exit__\n    '%d. %s' % (i, query['sql']) for i, query in enumerate(self.captured_queries, start=1)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 822, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: 3 != 2 : 3 queries executed, 2 expected\nCaptured queries were:\n1. DELETE FROM \"delete_secondreferrer\" WHERE \"delete_secondreferrer\".\"referrer_id\" IN (1)\n2. DELETE FROM \"delete_secondreferrer\" WHERE \"delete_secondreferrer\".\"other_referrer_id\" IN (42)\n3. DELETE FROM \"delete_referrer\" WHERE \"delete_referrer\".\"id\" IN (1)\n\n----------------------------------------------------------------------\nRan 45 tests in 1.094s\n\nFAILED (failures=1, skipped=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 delete.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/delete/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 45,
          "failed": 0,
          "errors": 0,
          "duration": 8.03,
          "log_tail": "test_fast_delete_joined_qs (delete.tests.FastDeleteTests) ... ok\ntest_fast_delete_large_batch (delete.tests.FastDeleteTests) ... ok\ntest_fast_delete_m2m (delete.tests.FastDeleteTests) ... ok\ntest_fast_delete_qs (delete.tests.FastDeleteTests) ... ok\ntest_fast_delete_revm2m (delete.tests.FastDeleteTests) ... ok\ntest_auto (delete.tests.OnDeleteTests) ... ok\ntest_auto_nullable (delete.tests.OnDeleteTests) ... ok\ntest_cascade (delete.tests.OnDeleteTests) ... ok\ntest_cascade_from_child (delete.tests.OnDeleteTests) ... ok\ntest_cascade_from_parent (delete.tests.OnDeleteTests) ... ok\ntest_cascade_nullable (delete.tests.OnDeleteTests) ... ok\ntest_do_nothing (delete.tests.OnDeleteTests) ... ok\ntest_do_nothing_qscount (delete.tests.OnDeleteTests) ... ok\ntest_inheritance_cascade_down (delete.tests.OnDeleteTests) ... ok\ntest_inheritance_cascade_up (delete.tests.OnDeleteTests) ... ok\ntest_non_callable (delete.tests.OnDeleteTests) ... ok\ntest_o2o_setnull (delete.tests.OnDeleteTests) ... ok\ntest_protect (delete.tests.OnDeleteTests) ... ok\ntest_setdefault (delete.tests.OnDeleteTests) ... ok\ntest_setdefault_none (delete.tests.OnDeleteTests) ... ok\ntest_setnull (delete.tests.OnDeleteTests) ... ok\ntest_setnull_from_child (delete.tests.OnDeleteTests) ... ok\ntest_setnull_from_parent (delete.tests.OnDeleteTests) ... ok\ntest_setvalue (delete.tests.OnDeleteTests) ... ok\ntest_bulk (delete.tests.DeletionTests) ... ok\ntest_can_defer_constraint_checks (delete.tests.DeletionTests) ... ok\ntest_cannot_defer_constraint_checks (delete.tests.DeletionTests) ... skipped 'Database has feature(s) can_defer_constraint_checks'\ntest_delete_with_keeping_parents (delete.tests.DeletionTests) ... ok\ntest_delete_with_keeping_parents_relationships (delete.tests.DeletionTests) ... ok\ntest_deletion_order (delete.tests.DeletionTests) ... ok\ntest_hidden_related (delete.tests.DeletionTests) ... ok\ntest_instance_update (delete.tests.DeletionTests) ... ok\ntest_large_delete (delete.tests.DeletionTests) ... ok\ntest_large_delete_related (delete.tests.DeletionTests) ... ok\ntest_m2m (delete.tests.DeletionTests) ... ok\ntest_model_delete_returns_num_rows (delete.tests.DeletionTests) ... ok\ntest_only_referenced_fields_selected (delete.tests.DeletionTests) ... ok\ntest_proxied_model_duplicate_queries (delete.tests.DeletionTests) ... ok\ntest_queryset_delete_returns_num_rows (delete.tests.DeletionTests) ... ok\ntest_relational_post_delete_signals_happen_before_parent_object (delete.tests.DeletionTests) ... ok\n\n----------------------------------------------------------------------\nRan 45 tests in 1.187s\n\nOK (skipped=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/delete/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-11951",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 38.80949783325195,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 26,
          "failed": 1,
          "errors": 0,
          "duration": 8.11,
          "log_tail": "test_bulk_insert_expressions (bulk_create.tests.BulkCreateTests) ... ok\ntest_bulk_insert_nullable_fields (bulk_create.tests.BulkCreateTests) ... ok\ntest_efficiency (bulk_create.tests.BulkCreateTests) ... ok\ntest_empty_model (bulk_create.tests.BulkCreateTests) ... ok\ntest_explicit_batch_size (bulk_create.tests.BulkCreateTests) ... ok\ntest_explicit_batch_size_efficiency (bulk_create.tests.BulkCreateTests) ... ok\ntest_explicit_batch_size_respects_max_batch_size (bulk_create.tests.BulkCreateTests) ... FAIL\ntest_ignore_conflicts_ignore (bulk_create.tests.BulkCreateTests) ... ok\ntest_ignore_conflicts_value_error (bulk_create.tests.BulkCreateTests) ... skipped 'Database has feature(s) supports_ignore_conflicts'\ntest_large_batch (bulk_create.tests.BulkCreateTests) ... ok\ntest_large_batch_efficiency (bulk_create.tests.BulkCreateTests) ... ok\ntest_large_batch_mixed (bulk_create.tests.BulkCreateTests) ... ok\ntest_large_batch_mixed_efficiency (bulk_create.tests.BulkCreateTests) ... ok\ntest_large_single_field_batch (bulk_create.tests.BulkCreateTests) ... ok\ntest_long_and_short_text (bulk_create.tests.BulkCreateTests) ... ok\ntest_long_non_ascii_text (bulk_create.tests.BulkCreateTests) ... ok\ntest_multi_table_inheritance_unsupported (bulk_create.tests.BulkCreateTests) ... ok\ntest_non_auto_increment_pk (bulk_create.tests.BulkCreateTests) ... ok\ntest_non_auto_increment_pk_efficiency (bulk_create.tests.BulkCreateTests) ... ok\ntest_proxy_inheritance_supported (bulk_create.tests.BulkCreateTests) ... ok\ntest_set_pk_and_insert_single_item (bulk_create.tests.BulkCreateTests) ... skipped \"Database doesn't support feature(s): can_return_rows_from_bulk_insert\"\ntest_set_pk_and_query_efficiency (bulk_create.tests.BulkCreateTests) ... skipped \"Database doesn't support feature(s): can_return_rows_from_bulk_insert\"\ntest_set_state (bulk_create.tests.BulkCreateTests) ... skipped \"Database doesn't support feature(s): can_return_rows_from_bulk_insert\"\ntest_set_state_with_pk_specified (bulk_create.tests.BulkCreateTests) ... ok\ntest_simple (bulk_create.tests.BulkCreateTests) ... ok\ntest_zero_as_autoval (bulk_create.tests.BulkCreateTests) ... skipped 'Database has feature(s) allows_auto_pk_0'\n\n======================================================================\nFAIL: test_explicit_batch_size_respects_max_batch_size (bulk_create.tests.BulkCreateTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/django/test/testcases.py\", line 1206, in skip_wrapper\n    return test_func(*args, **kwargs)\n  File \"/testbed/tests/bulk_create/tests.py\", line 224, in test_explicit_batch_size_respects_max_batch_size\n    Country.objects.bulk_create(objs, batch_size=max_batch_size + 1)\n  File \"/testbed/django/test/testcases.py\", line 84, in __exit__\n    '%d. %s' % (i, query['sql']) for i, query in enumerate(self.captured_queries, start=1)\nAssertionError: 3 != 4 : 3 queries executed, 4 expected\nCaptured queries were:\n1. INSERT INTO \"bulk_create_country\" (\"name\", \"iso_two_letter\", \"description\") SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', ''\n2. INSERT INTO \"bulk_create_country\" (\"name\", \"iso_two_letter\", \"description\") SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', ''\n3. INSERT INTO \"bulk_create_country\" (\"name\", \"iso_two_letter\", \"description\") SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', '' UNION ALL SELECT '', '', ''\n\n----------------------------------------------------------------------\nRan 27 tests in 0.187s\n\nFAILED (failures=1, skipped=5)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 bulk_create.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/bulk_create/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 27,
          "failed": 0,
          "errors": 0,
          "duration": 8.12,
          "log_tail": "    Creating table bulk_create_pizzeria\n    Creating table bulk_create_state\n    Creating table bulk_create_twofields\n    Creating table bulk_create_nofields\n    Creating table bulk_create_nullablefields\n    Running deferred SQL...\nRunning migrations:\n  Applying admin.0001_initial... OK\n  Applying admin.0002_logentry_remove_auto_add... OK\n  Applying admin.0003_logentry_add_action_flag_choices... OK\n  Applying sites.0001_initial... OK\n  Applying sites.0002_alter_domain_unique... OK\nSystem check identified no issues (0 silenced).\n\n\nCreating test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\ntest_batch_same_vals (bulk_create.tests.BulkCreateTests) ... ok\ntest_bulk_insert_expressions (bulk_create.tests.BulkCreateTests) ... ok\ntest_bulk_insert_nullable_fields (bulk_create.tests.BulkCreateTests) ... ok\ntest_efficiency (bulk_create.tests.BulkCreateTests) ... ok\ntest_empty_model (bulk_create.tests.BulkCreateTests) ... ok\ntest_explicit_batch_size (bulk_create.tests.BulkCreateTests) ... ok\ntest_explicit_batch_size_efficiency (bulk_create.tests.BulkCreateTests) ... ok\ntest_explicit_batch_size_respects_max_batch_size (bulk_create.tests.BulkCreateTests) ... ok\ntest_ignore_conflicts_ignore (bulk_create.tests.BulkCreateTests) ... ok\ntest_ignore_conflicts_value_error (bulk_create.tests.BulkCreateTests) ... skipped 'Database has feature(s) supports_ignore_conflicts'\ntest_large_batch (bulk_create.tests.BulkCreateTests) ... ok\ntest_large_batch_efficiency (bulk_create.tests.BulkCreateTests) ... ok\ntest_large_batch_mixed (bulk_create.tests.BulkCreateTests) ... ok\ntest_large_batch_mixed_efficiency (bulk_create.tests.BulkCreateTests) ... ok\ntest_large_single_field_batch (bulk_create.tests.BulkCreateTests) ... ok\ntest_long_and_short_text (bulk_create.tests.BulkCreateTests) ... ok\ntest_long_non_ascii_text (bulk_create.tests.BulkCreateTests) ... ok\ntest_multi_table_inheritance_unsupported (bulk_create.tests.BulkCreateTests) ... ok\ntest_non_auto_increment_pk (bulk_create.tests.BulkCreateTests) ... ok\ntest_non_auto_increment_pk_efficiency (bulk_create.tests.BulkCreateTests) ... ok\ntest_proxy_inheritance_supported (bulk_create.tests.BulkCreateTests) ... ok\ntest_set_pk_and_insert_single_item (bulk_create.tests.BulkCreateTests) ... skipped \"Database doesn't support feature(s): can_return_rows_from_bulk_insert\"\ntest_set_pk_and_query_efficiency (bulk_create.tests.BulkCreateTests) ... skipped \"Database doesn't support feature(s): can_return_rows_from_bulk_insert\"\ntest_set_state (bulk_create.tests.BulkCreateTests) ... skipped \"Database doesn't support feature(s): can_return_rows_from_bulk_insert\"\ntest_set_state_with_pk_specified (bulk_create.tests.BulkCreateTests) ... ok\ntest_simple (bulk_create.tests.BulkCreateTests) ... ok\ntest_zero_as_autoval (bulk_create.tests.BulkCreateTests) ... skipped 'Database has feature(s) allows_auto_pk_0'\n\n----------------------------------------------------------------------\nRan 27 tests in 0.244s\n\nOK (skipped=5)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/bulk_create/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-11964",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 28.55695104598999,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 2,
          "failed": 15,
          "errors": 0,
          "duration": 8.44,
          "log_tail": "\n\n======================================================================\nFAIL: test_str (model_enums.tests.ChoicesTests) [<object object at 0x7429358aebc0>] (member=<Vehicle.TRUCK: 2>)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 523, in subTest\n    yield\n  File \"/testbed/tests/model_enums/tests.py\", line 150, in test_str\n    self.assertEqual(str(test[member.name]), str(member.value))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1203, in assertMultiLineEqual\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: 'Vehicle.TRUCK' != '2'\n- Vehicle.TRUCK\n+ 2\n\n\n======================================================================\nFAIL: test_str (model_enums.tests.ChoicesTests) [<object object at 0x7429358aebc0>] (member=<Vehicle.JET_SKI: 3>)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 523, in subTest\n    yield\n  File \"/testbed/tests/model_enums/tests.py\", line 150, in test_str\n    self.assertEqual(str(test[member.name]), str(member.value))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1203, in assertMultiLineEqual\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: 'Vehicle.JET_SKI' != '3'\n- Vehicle.JET_SKI\n+ 3\n\n\n----------------------------------------------------------------------\nRan 17 tests in 0.263s\n\nFAILED (failures=15)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 model_enums.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/model_enums/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 17,
          "failed": 0,
          "errors": 0,
          "duration": 8.41,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application model_enums\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_bool_unsupported (model_enums.tests.CustomChoicesTests) ... ok\ntest_labels_valid (model_enums.tests.CustomChoicesTests) ... ok\ntest_timezone_unsupported (model_enums.tests.CustomChoicesTests) ... ok\ntest_uuid_unsupported (model_enums.tests.CustomChoicesTests) ... ok\ntest_integerchoices (model_enums.tests.ChoicesTests) ... ok\ntest_integerchoices_auto_label (model_enums.tests.ChoicesTests) ... ok\ntest_integerchoices_containment (model_enums.tests.ChoicesTests) ... ok\ntest_integerchoices_empty_label (model_enums.tests.ChoicesTests) ... ok\ntest_integerchoices_functional_api (model_enums.tests.ChoicesTests) ... ok\ntest_invalid_definition (model_enums.tests.ChoicesTests) ... ok\ntest_str (model_enums.tests.ChoicesTests) ... ok\ntest_textchoices (model_enums.tests.ChoicesTests) ... ok\ntest_textchoices_auto_label (model_enums.tests.ChoicesTests) ... ok\ntest_textchoices_blank_value (model_enums.tests.ChoicesTests) ... ok\ntest_textchoices_containment (model_enums.tests.ChoicesTests) ... ok\ntest_textchoices_empty_label (model_enums.tests.ChoicesTests) ... ok\ntest_textchoices_functional_api (model_enums.tests.ChoicesTests) ... ok\n\n----------------------------------------------------------------------\nRan 17 tests in 0.279s\n\nOK\n",
          "test_files_run": [
            "tests/model_enums/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-11999",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 30.52454710006714,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 30,
          "failed": 1,
          "errors": 0,
          "duration": 9.95,
          "log_tail": "__repr__() uses __qualname__ for nested class support. ... ok\ntest_field_str (model_fields.tests.BasicFieldTests) ... ok\ntest_field_verbose_name (model_fields.tests.BasicFieldTests) ... ok\ntest_formfield_disabled (model_fields.tests.BasicFieldTests)\nField.formfield() sets disabled for fields with choices. ... ok\ntest_show_hidden_initial (model_fields.tests.BasicFieldTests) ... ok\ntest_check (model_fields.tests.ChoicesTests) ... ok\ntest_choices (model_fields.tests.ChoicesTests) ... ok\ntest_flatchoices (model_fields.tests.ChoicesTests) ... ok\ntest_formfield (model_fields.tests.ChoicesTests) ... ok\ntest_invalid_choice (model_fields.tests.ChoicesTests) ... ok\ntest_get_choices (model_fields.tests.GetChoicesOrderingTests) ... ok\ntest_get_choices_default_ordering (model_fields.tests.GetChoicesOrderingTests) ... ok\ntest_get_choices_reverse_related_field (model_fields.tests.GetChoicesOrderingTests) ... ok\ntest_get_choices_reverse_related_field_default_ordering (model_fields.tests.GetChoicesOrderingTests) ... ok\n\n======================================================================\nFAIL: test_overriding_FIELD_display (model_fields.tests.GetFieldDisplayTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/model_fields/tests.py\", line 179, in test_overriding_FIELD_display\n    self.assertEqual(f.get_foo_bar_display(), 'something')\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1203, in assertMultiLineEqual\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: 'foo' != 'something'\n- foo\n+ something\n\n\n----------------------------------------------------------------------\nRan 31 tests in 0.341s\n\nFAILED (failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 model_fields.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/model_fields/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 31,
          "failed": 0,
          "errors": 0,
          "duration": 8.24,
          "log_tail": "Can supply a custom choices form class to Field.formfield() ... ok\ntest_deconstruct_nested_field (model_fields.tests.BasicFieldTests)\ndeconstruct() uses __qualname__ for nested class support. ... ok\ntest_field_instance_is_picklable (model_fields.tests.BasicFieldTests)\nField instances can be pickled. ... ok\ntest_field_name (model_fields.tests.BasicFieldTests) ... ok\ntest_field_ordering (model_fields.tests.BasicFieldTests)\nFields are ordered based on their creation. ... ok\ntest_field_repr (model_fields.tests.BasicFieldTests) ... ok\ntest_field_repr_nested (model_fields.tests.BasicFieldTests)\n__repr__() uses __qualname__ for nested class support. ... ok\ntest_field_str (model_fields.tests.BasicFieldTests) ... ok\ntest_field_verbose_name (model_fields.tests.BasicFieldTests) ... ok\ntest_formfield_disabled (model_fields.tests.BasicFieldTests)\nField.formfield() sets disabled for fields with choices. ... ok\ntest_show_hidden_initial (model_fields.tests.BasicFieldTests) ... ok\ntest_blank_in_choices (model_fields.tests.GetChoicesTests) ... ok\ntest_blank_in_grouped_choices (model_fields.tests.GetChoicesTests) ... ok\ntest_empty_choices (model_fields.tests.GetChoicesTests) ... ok\ntest_lazy_strings_not_evaluated (model_fields.tests.GetChoicesTests) ... ok\ntest_check (model_fields.tests.ChoicesTests) ... ok\ntest_choices (model_fields.tests.ChoicesTests) ... ok\ntest_flatchoices (model_fields.tests.ChoicesTests) ... ok\ntest_formfield (model_fields.tests.ChoicesTests) ... ok\ntest_invalid_choice (model_fields.tests.ChoicesTests) ... ok\ntest_choices_and_field_display (model_fields.tests.GetFieldDisplayTests) ... ok\ntest_empty_iterator_choices (model_fields.tests.GetFieldDisplayTests) ... ok\ntest_get_FIELD_display_translated (model_fields.tests.GetFieldDisplayTests)\nA translated display value is coerced to str. ... ok\ntest_iterator_choices (model_fields.tests.GetFieldDisplayTests) ... ok\ntest_overriding_FIELD_display (model_fields.tests.GetFieldDisplayTests) ... ok\ntest_get_choices (model_fields.tests.GetChoicesLimitChoicesToTests) ... ok\ntest_get_choices_reverse_related_field (model_fields.tests.GetChoicesLimitChoicesToTests) ... ok\ntest_get_choices (model_fields.tests.GetChoicesOrderingTests) ... ok\ntest_get_choices_default_ordering (model_fields.tests.GetChoicesOrderingTests) ... ok\ntest_get_choices_reverse_related_field (model_fields.tests.GetChoicesOrderingTests) ... ok\ntest_get_choices_reverse_related_field_default_ordering (model_fields.tests.GetChoicesOrderingTests) ... ok\n\n----------------------------------------------------------------------\nRan 31 tests in 0.302s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/model_fields/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-12039",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 29.90926504135132,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 23,
          "failed": 1,
          "errors": 0,
          "duration": 9.74,
          "log_tail": "test_ops_class_multiple_columns (indexes.tests.SchemaIndexesPostgreSQLTests) ... skipped 'PostgreSQL tests'\ntest_ops_class_partial (indexes.tests.SchemaIndexesPostgreSQLTests) ... skipped 'PostgreSQL tests'\ntest_ops_class_partial_tablespace (indexes.tests.SchemaIndexesPostgreSQLTests) ... skipped 'PostgreSQL tests'\ntest_text_indexes (indexes.tests.SchemaIndexesPostgreSQLTests)\nTest creation of PostgreSQL-specific text indexes (#12234) ... skipped 'PostgreSQL tests'\ntest_virtual_relation_indexes (indexes.tests.SchemaIndexesPostgreSQLTests)\nTest indexes are not created for related objects ... skipped 'PostgreSQL tests'\ntest_no_index_for_foreignkey (indexes.tests.SchemaIndexesMySQLTests) ... skipped 'MySQL tests'\ntest_columns_list_sql (indexes.tests.SchemaIndexesTests) ... ok\ntest_descending_columns_list_sql (indexes.tests.SchemaIndexesTests) ... FAIL\ntest_index_name (indexes.tests.SchemaIndexesTests) ... ok\ntest_index_name_hash (indexes.tests.SchemaIndexesTests) ... ok\ntest_index_together (indexes.tests.SchemaIndexesTests) ... ok\ntest_index_together_single_list (indexes.tests.SchemaIndexesTests) ... ok\ntest_create_index_ignores_opclasses (indexes.tests.SchemaIndexesNotPostgreSQLTests) ... ok\ntest_boolean_restriction_partial (indexes.tests.PartialIndexTests) ... ok\ntest_integer_restriction_partial (indexes.tests.PartialIndexTests) ... ok\ntest_is_null_condition (indexes.tests.PartialIndexTests) ... ok\ntest_multiple_conditions (indexes.tests.PartialIndexTests) ... ok\ntest_partial_index (indexes.tests.PartialIndexTests) ... ok\n\n======================================================================\nFAIL: test_descending_columns_list_sql (indexes.tests.SchemaIndexesTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/indexes/tests.py\", line 91, in test_descending_columns_list_sql\n    str(index.create_sql(Article, editor)),\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1089, in assertIn\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: '(\"headline\" DESC)' not found in 'CREATE INDEX \"whitespace_idx\" ON \"indexes_article\" (\"headline\"DESC)'\n\n----------------------------------------------------------------------\nRan 24 tests in 0.353s\n\nFAILED (failures=1, skipped=12)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 indexes.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/indexes/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 24,
          "failed": 0,
          "errors": 0,
          "duration": 8.13,
          "log_tail": "  Applying sites.0002_alter_domain_unique... OK\nSystem check identified no issues (0 silenced).\n\n\nCreating test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\ntest_condition_ignored (indexes.tests.PartialIndexConditionIgnoredTests) ... skipped 'Database has feature(s) supports_partial_indexes'\ntest_no_index_for_foreignkey (indexes.tests.SchemaIndexesMySQLTests) ... skipped 'MySQL tests'\ntest_ops_class (indexes.tests.SchemaIndexesPostgreSQLTests) ... skipped 'PostgreSQL tests'\ntest_ops_class_columns_lists_sql (indexes.tests.SchemaIndexesPostgreSQLTests) ... skipped 'PostgreSQL tests'\ntest_ops_class_descending (indexes.tests.SchemaIndexesPostgreSQLTests) ... skipped 'PostgreSQL tests'\ntest_ops_class_descending_columns_list_sql (indexes.tests.SchemaIndexesPostgreSQLTests) ... skipped 'PostgreSQL tests'\ntest_ops_class_descending_partial (indexes.tests.SchemaIndexesPostgreSQLTests) ... skipped 'PostgreSQL tests'\ntest_ops_class_multiple_columns (indexes.tests.SchemaIndexesPostgreSQLTests) ... skipped 'PostgreSQL tests'\ntest_ops_class_partial (indexes.tests.SchemaIndexesPostgreSQLTests) ... skipped 'PostgreSQL tests'\ntest_ops_class_partial_tablespace (indexes.tests.SchemaIndexesPostgreSQLTests) ... skipped 'PostgreSQL tests'\ntest_text_indexes (indexes.tests.SchemaIndexesPostgreSQLTests)\nTest creation of PostgreSQL-specific text indexes (#12234) ... skipped 'PostgreSQL tests'\ntest_virtual_relation_indexes (indexes.tests.SchemaIndexesPostgreSQLTests)\nTest indexes are not created for related objects ... skipped 'PostgreSQL tests'\ntest_columns_list_sql (indexes.tests.SchemaIndexesTests) ... ok\ntest_descending_columns_list_sql (indexes.tests.SchemaIndexesTests) ... ok\ntest_index_name (indexes.tests.SchemaIndexesTests) ... ok\ntest_index_name_hash (indexes.tests.SchemaIndexesTests) ... ok\ntest_index_together (indexes.tests.SchemaIndexesTests) ... ok\ntest_index_together_single_list (indexes.tests.SchemaIndexesTests) ... ok\ntest_create_index_ignores_opclasses (indexes.tests.SchemaIndexesNotPostgreSQLTests) ... ok\ntest_boolean_restriction_partial (indexes.tests.PartialIndexTests) ... ok\ntest_integer_restriction_partial (indexes.tests.PartialIndexTests) ... ok\ntest_is_null_condition (indexes.tests.PartialIndexTests) ... ok\ntest_multiple_conditions (indexes.tests.PartialIndexTests) ... ok\ntest_partial_index (indexes.tests.PartialIndexTests) ... ok\n\n----------------------------------------------------------------------\nRan 24 tests in 0.323s\n\nOK (skipped=12)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/indexes/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-12050",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 29.076404809951782,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 10,
          "failed": 1,
          "errors": 0,
          "duration": 9.42,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application queries\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (1 silenced).\n\n\ntest_clone_select_related (queries.test_query.TestQuery) ... ok\ntest_complex_query (queries.test_query.TestQuery) ... ok\ntest_foreign_key (queries.test_query.TestQuery) ... ok\ntest_foreign_key_exclusive (queries.test_query.TestQuery) ... ok\ntest_foreign_key_f (queries.test_query.TestQuery) ... ok\ntest_iterable_lookup_value (queries.test_query.TestQuery) ... FAIL\ntest_multiple_fields (queries.test_query.TestQuery) ... ok\ntest_negated_nullable (queries.test_query.TestQuery) ... ok\ntest_simple_query (queries.test_query.TestQuery) ... ok\ntest_simplecol_query (queries.test_query.TestQuery) ... ok\ntest_transform (queries.test_query.TestQuery) ... ok\n\n======================================================================\nFAIL: test_iterable_lookup_value (queries.test_query.TestQuery)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/queries/test_query.py\", line 122, in test_iterable_lookup_value\n    self.assertEqual(name_exact.rhs, \"['a', 'b']\")\nAssertionError: \"('a', 'b')\" != \"['a', 'b']\"\n- ('a', 'b')\n? ^        ^\n+ ['a', 'b']\n? ^        ^\n\n\n----------------------------------------------------------------------\nRan 11 tests in 0.005s\n\nFAILED (failures=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 queries.test_query` failed. (See above for error)",
          "test_files_run": [
            "tests/queries/test_query.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 11,
          "failed": 0,
          "errors": 0,
          "duration": 8.01,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application queries\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (1 silenced).\n\n\ntest_clone_select_related (queries.test_query.TestQuery) ... ok\ntest_complex_query (queries.test_query.TestQuery) ... ok\ntest_foreign_key (queries.test_query.TestQuery) ... ok\ntest_foreign_key_exclusive (queries.test_query.TestQuery) ... ok\ntest_foreign_key_f (queries.test_query.TestQuery) ... ok\ntest_iterable_lookup_value (queries.test_query.TestQuery) ... ok\ntest_multiple_fields (queries.test_query.TestQuery) ... ok\ntest_negated_nullable (queries.test_query.TestQuery) ... ok\ntest_simple_query (queries.test_query.TestQuery) ... ok\ntest_simplecol_query (queries.test_query.TestQuery) ... ok\ntest_transform (queries.test_query.TestQuery) ... ok\n\n----------------------------------------------------------------------\nRan 11 tests in 0.007s\n\nOK\n",
          "test_files_run": [
            "tests/queries/test_query.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-12125",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 31.981273651123047,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 45,
          "failed": 2,
          "errors": 0,
          "duration": 6.77,
          "log_tail": "  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1010, in assertSequenceEqual\n    self.fail(msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: Tuples differ: ('mig[15 chars]iter.NestedEnum', {'import migrations.test_writer'}) != ('mig[15 chars]iter.WriterTests.NestedEnum', {'import migrati[13 chars]er'})\n\nFirst differing element 0:\n'migrations.test_writer.NestedEnum'\n'migrations.test_writer.WriterTests.NestedEnum'\n\n- ('migrations.test_writer.NestedEnum', {'import migrations.test_writer'})\n+ ('migrations.test_writer.WriterTests.NestedEnum',\n+  {'import migrations.test_writer'})\n\n======================================================================\nFAIL: test_serialize_nested_class (migrations.test_writer.WriterTests) [NestedChoices]\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 523, in subTest\n    yield\n  File \"/testbed/tests/migrations/test_writer.py\", line 403, in test_serialize_nested_class\n    {'import migrations.test_writer'},\n  File \"/testbed/tests/migrations/test_writer.py\", line 219, in assertSerializedResultEqual\n    self.assertEqual(MigrationWriter.serialize(value), target)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1039, in assertTupleEqual\n    self.assertSequenceEqual(tuple1, tuple2, msg, seq_type=tuple)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1010, in assertSequenceEqual\n    self.fail(msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: Tuples differ: ('mig[15 chars]iter.NestedChoices', {'import migrations.test_writer'}) != ('mig[15 chars]iter.WriterTests.NestedChoices', {'import migr[16 chars]er'})\n\nFirst differing element 0:\n'migrations.test_writer.NestedChoices'\n'migrations.test_writer.WriterTests.NestedChoices'\n\n- ('migrations.test_writer.NestedChoices', {'import migrations.test_writer'})\n+ ('migrations.test_writer.WriterTests.NestedChoices',\n+  {'import migrations.test_writer'})\n\n----------------------------------------------------------------------\nRan 47 tests in 0.292s\n\nFAILED (failures=2)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 migrations.test_writer` failed. (See above for error)",
          "test_files_run": [
            "tests/migrations/test_writer.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 47,
          "failed": 0,
          "errors": 0,
          "duration": 6.76,
          "log_tail": "test_multiline_args_signature (migrations.test_writer.OperationWriterTests) ... ok\ntest_nested_args_signature (migrations.test_writer.OperationWriterTests) ... ok\ntest_nested_operation_expand_args_signature (migrations.test_writer.OperationWriterTests) ... ok\ntest_custom_operation (migrations.test_writer.WriterTests) ... ok\ntest_deconstruct_class_arguments (migrations.test_writer.WriterTests) ... ok\ntest_migration_file_header_comments (migrations.test_writer.WriterTests) ... ok\ntest_migration_path (migrations.test_writer.WriterTests) ... ok\ntest_models_import_omitted (migrations.test_writer.WriterTests) ... ok\ntest_register_non_serializer (migrations.test_writer.WriterTests) ... ok\ntest_register_serializer (migrations.test_writer.WriterTests) ... ok\ntest_serialize_builtin_types (migrations.test_writer.WriterTests) ... ok\ntest_serialize_builtins (migrations.test_writer.WriterTests) ... ok\ntest_serialize_choices (migrations.test_writer.WriterTests) ... ok\ntest_serialize_class_based_validators (migrations.test_writer.WriterTests) ... ok\ntest_serialize_collections (migrations.test_writer.WriterTests) ... ok\ntest_serialize_compiled_regex (migrations.test_writer.WriterTests) ... ok\ntest_serialize_constants (migrations.test_writer.WriterTests) ... ok\ntest_serialize_datetime (migrations.test_writer.WriterTests) ... ok\ntest_serialize_empty_nonempty_tuple (migrations.test_writer.WriterTests) ... ok\ntest_serialize_enums (migrations.test_writer.WriterTests) ... ok\ntest_serialize_fields (migrations.test_writer.WriterTests) ... ok\ntest_serialize_frozensets (migrations.test_writer.WriterTests) ... ok\ntest_serialize_functions (migrations.test_writer.WriterTests) ... ok\ntest_serialize_functools_partial (migrations.test_writer.WriterTests) ... ok\ntest_serialize_functools_partialmethod (migrations.test_writer.WriterTests) ... ok\ntest_serialize_iterators (migrations.test_writer.WriterTests) ... ok\ntest_serialize_lazy_objects (migrations.test_writer.WriterTests) ... ok\ntest_serialize_local_function_reference (migrations.test_writer.WriterTests)\nA reference in a local scope can't be serialized. ... ok\ntest_serialize_managers (migrations.test_writer.WriterTests) ... ok\ntest_serialize_multiline_strings (migrations.test_writer.WriterTests) ... ok\ntest_serialize_nested_class (migrations.test_writer.WriterTests) ... ok\ntest_serialize_numbers (migrations.test_writer.WriterTests) ... ok\ntest_serialize_range (migrations.test_writer.WriterTests) ... ok\ntest_serialize_set (migrations.test_writer.WriterTests) ... ok\ntest_serialize_settings (migrations.test_writer.WriterTests) ... ok\ntest_serialize_strings (migrations.test_writer.WriterTests) ... ok\ntest_serialize_timedelta (migrations.test_writer.WriterTests) ... ok\ntest_serialize_type_none (migrations.test_writer.WriterTests) ... ok\ntest_serialize_unbound_method_reference (migrations.test_writer.WriterTests)\nAn unbound method used within a class body can be serialized. ... ok\ntest_serialize_uuid (migrations.test_writer.WriterTests) ... ok\ntest_simple_migration (migrations.test_writer.WriterTests) ... ok\ntest_sorted_imports (migrations.test_writer.WriterTests) ... ok\n\n----------------------------------------------------------------------\nRan 47 tests in 0.384s\n\nOK\n",
          "test_files_run": [
            "tests/migrations/test_writer.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-12143",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "django__django-12155",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 32.50092887878418,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 6,
          "failed": 1,
          "errors": 0,
          "duration": 6.89,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application admin_docs\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_description_output (admin_docs.test_utils.TestUtils) ... ok\ntest_initial_header_level (admin_docs.test_utils.TestUtils) ... ok\ntest_parse_docstring (admin_docs.test_utils.TestUtils) ... ok\ntest_parse_rst (admin_docs.test_utils.TestUtils) ... ok\ntest_parse_rst_with_docstring_no_leading_line_feed (admin_docs.test_utils.TestUtils) ... FAIL\ntest_publish_parts (admin_docs.test_utils.TestUtils) ... ok\ntest_title_output (admin_docs.test_utils.TestUtils) ... ok\n\n======================================================================\nFAIL: test_parse_rst_with_docstring_no_leading_line_feed (admin_docs.test_utils.TestUtils)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/admin_docs/test_utils.py\", line 101, in test_parse_rst_with_docstring_no_leading_line_feed\n    self.assertEqual(parse_rst(body, ''), '<p>second line</p>\\n')\nAssertionError: '<div class=\"system-message\">\\n<p class=\"sy[270 chars]v>\\n' != '<p>second line</p>\\n'\n\n----------------------------------------------------------------------\nRan 7 tests in 0.148s\n\nFAILED (failures=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 admin_docs.test_utils` failed. (See above for error)",
          "test_files_run": [
            "tests/admin_docs/test_utils.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 7,
          "failed": 0,
          "errors": 0,
          "duration": 6.7,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application admin_docs\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_description_output (admin_docs.test_utils.TestUtils) ... ok\ntest_initial_header_level (admin_docs.test_utils.TestUtils) ... ok\ntest_parse_docstring (admin_docs.test_utils.TestUtils) ... ok\ntest_parse_rst (admin_docs.test_utils.TestUtils) ... ok\ntest_parse_rst_with_docstring_no_leading_line_feed (admin_docs.test_utils.TestUtils) ... ok\ntest_publish_parts (admin_docs.test_utils.TestUtils) ... ok\ntest_title_output (admin_docs.test_utils.TestUtils) ... ok\n\n----------------------------------------------------------------------\nRan 7 tests in 0.134s\n\nOK\n",
          "test_files_run": [
            "tests/admin_docs/test_utils.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-12193",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "django__django-12209",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "django__django-12262",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "django__django-12273",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 37.96978211402893,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 27,
          "failed": 1,
          "errors": 2,
          "duration": 8.85,
          "log_tail": "======================================================================\nERROR: test_create_new_instance_with_pk_equals_none_multi_inheritance (model_inheritance_regress.tests.ModelInheritanceTest)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/django/db/backends/utils.py\", line 84, in _execute\n    return self.cursor.execute(sql, params)\n  File \"/testbed/django/db/backends/sqlite3/base.py\", line 401, in execute\n    return Database.Cursor.execute(self, query, params)\nsqlite3.IntegrityError: UNIQUE constraint failed: model_inheritance_regress_congressman.politician_ptr_id\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/testbed/tests/model_inheritance_regress/tests.py\", line 583, in test_create_new_instance_with_pk_equals_none_multi_inheritance\n    c2.save()\n  File \"/testbed/django/db/models/base.py\", line 747, in save\n    force_update=force_update, update_fields=update_fields)\n  File \"/testbed/django/db/models/base.py\", line 785, in save_base\n    force_update, using, update_fields,\n  File \"/testbed/django/db/models/base.py\", line 888, in _save_table\n    results = self._do_insert(cls._base_manager, using, fields, returning_fields, raw)\n  File \"/testbed/django/db/models/base.py\", line 927, in _do_insert\n    using=using, raw=raw,\n  File \"/testbed/django/db/models/manager.py\", line 82, in manager_method\n    return getattr(self.get_queryset(), name)(*args, **kwargs)\n  File \"/testbed/django/db/models/query.py\", line 1228, in _insert\n    return query.get_compiler(using=using).execute_sql(returning_fields)\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1374, in execute_sql\n    cursor.execute(sql, params)\n  File \"/testbed/django/db/backends/utils.py\", line 66, in execute\n    return self._execute_with_wrappers(sql, params, many=False, executor=self._execute)\n  File \"/testbed/django/db/backends/utils.py\", line 75, in _execute_with_wrappers\n    return executor(sql, params, many, context)\n  File \"/testbed/django/db/backends/utils.py\", line 84, in _execute\n    return self.cursor.execute(sql, params)\n  File \"/testbed/django/db/utils.py\", line 90, in __exit__\n    raise dj_exc_value.with_traceback(traceback) from exc_value\n  File \"/testbed/django/db/backends/utils.py\", line 84, in _execute\n    return self.cursor.execute(sql, params)\n  File \"/testbed/django/db/backends/sqlite3/base.py\", line 401, in execute\n    return Database.Cursor.execute(self, query, params)\ndjango.db.utils.IntegrityError: UNIQUE constraint failed: model_inheritance_regress_congressman.politician_ptr_id\n\n----------------------------------------------------------------------\nRan 30 tests in 0.140s\n\nFAILED (errors=2, expected failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 model_inheritance_regress.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/model_inheritance_regress/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 30,
          "failed": 0,
          "errors": 0,
          "duration": 8.86,
          "log_tail": "    Creating table model_inheritance_regress_congressman\n    Creating table model_inheritance_regress_senator\n    Running deferred SQL...\nRunning migrations:\n  Applying admin.0001_initial... OK\n  Applying admin.0002_logentry_remove_auto_add... OK\n  Applying admin.0003_logentry_add_action_flag_choices... OK\n  Applying sites.0001_initial... OK\n  Applying sites.0002_alter_domain_unique... OK\nSystem check identified no issues (0 silenced).\n\n\nCreating test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\ntest_abstract_base_class_m2m_relation_inheritance (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_abstract_verbose_name_plural_inheritance (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_all_fields_from_abstract_base_class (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_concrete_abstract_concrete_pk (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_create_new_instance_with_pk_equals_none (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_create_new_instance_with_pk_equals_none_multi_inheritance (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_filter_with_parent_fk (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_get_next_previous_by_date (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_id_field_update_on_ancestor_change (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_inheritance_joins (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_inheritance_resolve_columns (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_inheritance_select_related (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_inheritance_values_joins (model_inheritance_regress.tests.ModelInheritanceTest) ... expected failure\ntest_inherited_fields (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_inherited_nullable_exclude (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_inherited_unique_field_with_form (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_issue_11764 (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_issue_21554 (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_issue_6755 (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_issue_7105 (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_issue_7276 (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_issue_7488 (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_issue_7853 (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_model_inheritance (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_ptr_accessor_assigns_state (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_queries_on_parent_access (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_queryset_update_on_parent_model (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_related_filtering_query_efficiency_ticket_15844 (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_use_explicit_o2o_to_parent_as_pk (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_use_explicit_o2o_to_parent_from_abstract_model (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\n\n----------------------------------------------------------------------\nRan 30 tests in 0.107s\n\nOK (expected failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/model_inheritance_regress/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-12276",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 38.713099002838135,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 117,
          "failed": 2,
          "errors": 0,
          "duration": 8.91,
          "log_tail": "  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1103, in assertIs\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: True is not False\n\n======================================================================\nFAIL: test_filefield_with_fileinput_required (forms_tests.tests.test_forms.FormsTestCase)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/forms_tests/tests/test_forms.py\", line 2505, in test_filefield_with_fileinput_required\n    '<tr><th>File1:</th><td><input type=\"file\" name=\"file1\"></td></tr>',\n  File \"/testbed/django/test/testcases.py\", line 785, in assertHTMLEqual\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: <tr>\n<th>\nFile1:\n</th><td>\n<input name=\"file1\" required type=\"file\">\n</td>\n</tr> [truncated]... != <tr>\n<th>\nFile1:\n</th><td>\n<input name=\"file1\" type=\"file\">\n</td>\n</tr>\n  <tr>\n  <th>\n  File1:\n  </th><td>\n- <input name=\"file1\" required type=\"file\">\n?                     ---------\n\n+ <input name=\"file1\" type=\"file\">\n  </td>\n  </tr>\n\n----------------------------------------------------------------------\nRan 119 tests in 0.817s\n\nFAILED (failures=2)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 forms_tests.tests.test_forms forms_tests.widget_tests.test_fileinput` failed. (See above for error)",
          "test_files_run": [
            "tests/forms_tests/tests/test_forms.py",
            "tests/forms_tests/widget_tests/test_fileinput.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 119,
          "failed": 0,
          "errors": 0,
          "duration": 8.41,
          "log_tail": "test_form_with_noniterable_boundfield (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_forms_with_choices (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_forms_with_file_fields (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_forms_with_multiple_choice (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_forms_with_null_boolean (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_forms_with_prefixes (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_forms_with_radio (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_get_initial_for_field (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_has_error (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_help_text (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_hidden_data (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_hidden_initial_gets_id (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_hidden_widget (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_html_safe (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_id_on_field (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_initial_data (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_initial_datetime_values (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_iterable_boundfield_select (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_label_has_required_css_class (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_label_split_datetime_not_displayed (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_label_suffix (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_label_tag_override (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_multipart_encoded_form (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_multiple_choice_checkbox (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_multiple_choice_list_data (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_multiple_hidden (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_multivalue_deep_copy (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_multivalue_field_validation (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_multivalue_initial_data (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_multivalue_optional_subfields (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_only_hidden_fields (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_optional_data (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_specifying_labels (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_subclassing_forms (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_templates_with_forms (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_unbound_form (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_unicode_values (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_update_error_dict (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_use_required_attribute_false (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_use_required_attribute_true (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_validating_multiple_fields (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_validators_independence (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_various_boolean_values (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_widget_output (forms_tests.tests.test_forms.FormsTestCase) ... ok\n\n----------------------------------------------------------------------\nRan 119 tests in 0.558s\n\nOK\n",
          "test_files_run": [
            "tests/forms_tests/tests/test_forms.py",
            "tests/forms_tests/widget_tests/test_fileinput.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-12304",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 37.70942807197571,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 17,
          "failed": 1,
          "errors": 0,
          "duration": 8.15,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application model_enums\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_bool_unsupported (model_enums.tests.CustomChoicesTests) ... ok\ntest_labels_valid (model_enums.tests.CustomChoicesTests) ... ok\ntest_timezone_unsupported (model_enums.tests.CustomChoicesTests) ... ok\ntest_uuid_unsupported (model_enums.tests.CustomChoicesTests) ... ok\ntest_integerchoices (model_enums.tests.ChoicesTests) ... ok\ntest_integerchoices_auto_label (model_enums.tests.ChoicesTests) ... ok\ntest_integerchoices_containment (model_enums.tests.ChoicesTests) ... ok\ntest_integerchoices_empty_label (model_enums.tests.ChoicesTests) ... ok\ntest_integerchoices_functional_api (model_enums.tests.ChoicesTests) ... ok\ntest_invalid_definition (model_enums.tests.ChoicesTests) ... ok\ntest_str (model_enums.tests.ChoicesTests) ... ok\ntest_templates (model_enums.tests.ChoicesTests) ... FAIL\ntest_textchoices (model_enums.tests.ChoicesTests) ... ok\ntest_textchoices_auto_label (model_enums.tests.ChoicesTests) ... ok\ntest_textchoices_blank_value (model_enums.tests.ChoicesTests) ... ok\ntest_textchoices_containment (model_enums.tests.ChoicesTests) ... ok\ntest_textchoices_empty_label (model_enums.tests.ChoicesTests) ... ok\ntest_textchoices_functional_api (model_enums.tests.ChoicesTests) ... ok\n\n======================================================================\nFAIL: test_templates (model_enums.tests.ChoicesTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/model_enums/tests.py\", line 156, in test_templates\n    self.assertEqual(output, 'Diamond|1')\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 822, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: '|' != 'Diamond|1'\n\n----------------------------------------------------------------------\nRan 18 tests in 0.261s\n\nFAILED (failures=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 model_enums.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/model_enums/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 18,
          "failed": 0,
          "errors": 0,
          "duration": 8.53,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application model_enums\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_bool_unsupported (model_enums.tests.CustomChoicesTests) ... ok\ntest_labels_valid (model_enums.tests.CustomChoicesTests) ... ok\ntest_timezone_unsupported (model_enums.tests.CustomChoicesTests) ... ok\ntest_uuid_unsupported (model_enums.tests.CustomChoicesTests) ... ok\ntest_integerchoices (model_enums.tests.ChoicesTests) ... ok\ntest_integerchoices_auto_label (model_enums.tests.ChoicesTests) ... ok\ntest_integerchoices_containment (model_enums.tests.ChoicesTests) ... ok\ntest_integerchoices_empty_label (model_enums.tests.ChoicesTests) ... ok\ntest_integerchoices_functional_api (model_enums.tests.ChoicesTests) ... ok\ntest_invalid_definition (model_enums.tests.ChoicesTests) ... ok\ntest_str (model_enums.tests.ChoicesTests) ... ok\ntest_templates (model_enums.tests.ChoicesTests) ... ok\ntest_textchoices (model_enums.tests.ChoicesTests) ... ok\ntest_textchoices_auto_label (model_enums.tests.ChoicesTests) ... ok\ntest_textchoices_blank_value (model_enums.tests.ChoicesTests) ... ok\ntest_textchoices_containment (model_enums.tests.ChoicesTests) ... ok\ntest_textchoices_empty_label (model_enums.tests.ChoicesTests) ... ok\ntest_textchoices_functional_api (model_enums.tests.ChoicesTests) ... ok\n\n----------------------------------------------------------------------\nRan 18 tests in 0.258s\n\nOK\n",
          "test_files_run": [
            "tests/model_enums/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-12308",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "django__django-12325",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "django__django-12406",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 39.42272615432739,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 164,
          "failed": 1,
          "errors": 4,
          "duration": 8.98,
          "log_tail": "  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1010, in assertSequenceEqual\n    self.fail(msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: Lists differ: [('', '---------'), (<django.forms.models.M[54 chars]er')] != [(1, 'user')]\n\nFirst differing element 0:\n('', '---------')\n(1, 'user')\n\nFirst list contains 1 additional elements.\nFirst extra element 1:\n(<django.forms.models.ModelChoiceIteratorValue object at 0x735738dabcf8>, 'user')\n\n- [('', '---------'),\n-  (<django.forms.models.ModelChoiceIteratorValue object at 0x735738dabcf8>,\n-   'user')]\n? ^\n\n+ [(1, 'user')]\n? ^^^^\n\n\n----------------------------------------------------------------------\nRan 169 tests in 0.432s\n\nFAILED (failures=1, errors=4)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 model_forms.models model_forms.test_modelchoicefield model_forms.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/model_forms/models.py",
            "tests/model_forms/test_modelchoicefield.py",
            "tests/model_forms/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 169,
          "failed": 0,
          "errors": 0,
          "duration": 8.53,
          "log_tail": "test_clear_and_file_contradiction (model_forms.tests.FileAndImageFieldTests) ... ok\ntest_custom_file_field_save (model_forms.tests.FileAndImageFieldTests) ... ok\ntest_file_field_data (model_forms.tests.FileAndImageFieldTests) ... ok\ntest_file_field_multiple_save (model_forms.tests.FileAndImageFieldTests) ... ok\ntest_file_path_field_blank (model_forms.tests.FileAndImageFieldTests)\nFilePathField(blank=True) includes the empty option. ... ok\ntest_filefield_required_false (model_forms.tests.FileAndImageFieldTests) ... ok\ntest_full_clear (model_forms.tests.FileAndImageFieldTests) ... ok\ntest_image_field (model_forms.tests.FileAndImageFieldTests) ... ok\ntest_render_empty_file_field (model_forms.tests.FileAndImageFieldTests) ... ok\ntest_auto_id (model_forms.tests.ModelFormBasicTests) ... ok\ntest_base_form (model_forms.tests.ModelFormBasicTests) ... ok\ntest_basic_creation (model_forms.tests.ModelFormBasicTests) ... ok\ntest_custom_form_fields (model_forms.tests.ModelFormBasicTests) ... ok\ntest_initial_values (model_forms.tests.ModelFormBasicTests) ... ok\ntest_m2m_editing (model_forms.tests.ModelFormBasicTests) ... ok\ntest_m2m_initial_callable (model_forms.tests.ModelFormBasicTests) ... ok\ntest_multi_fields (model_forms.tests.ModelFormBasicTests) ... ok\ntest_recleaning_model_form_instance (model_forms.tests.ModelFormBasicTests) ... ok\ntest_runtime_choicefield_populated (model_forms.tests.ModelFormBasicTests) ... ok\ntest_save_commit_false (model_forms.tests.ModelFormBasicTests) ... ok\ntest_save_with_data_errors (model_forms.tests.ModelFormBasicTests) ... ok\ntest_subset_fields (model_forms.tests.ModelFormBasicTests) ... ok\n\n----------------------------------------------------------------------\nRan 169 tests in 0.415s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/model_forms/models.py",
            "tests/model_forms/test_modelchoicefield.py",
            "tests/model_forms/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-12419",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "django__django-12663",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 39.04203009605408,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 137,
          "failed": 0,
          "errors": 1,
          "duration": 9.92,
          "log_tail": "The above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/expressions/tests.py\", line 624, in test_subquery_filter_by_lazy\n    ).filter(ceo_manager=max_manager)\n  File \"/testbed/django/db/models/query.py\", line 928, in filter\n    return self._filter_or_exclude(False, *args, **kwargs)\n  File \"/testbed/django/db/models/query.py\", line 948, in _filter_or_exclude\n    clone._filter_or_exclude_inplace(negate, *args, **kwargs)\n  File \"/testbed/django/db/models/query.py\", line 955, in _filter_or_exclude_inplace\n    self._query.add_q(Q(*args, **kwargs))\n  File \"/testbed/django/db/models/sql/query.py\", line 1356, in add_q\n    clause, _ = self._add_q(q_object, self.used_aliases)\n  File \"/testbed/django/db/models/sql/query.py\", line 1378, in _add_q\n    split_subq=split_subq, check_filterable=check_filterable,\n  File \"/testbed/django/db/models/sql/query.py\", line 1273, in build_filter\n    condition = self.build_lookup(lookups, reffed_expression, value)\n  File \"/testbed/django/db/models/sql/query.py\", line 1163, in build_lookup\n    lookup = lookup_class(lhs, rhs)\n  File \"/testbed/django/db/models/lookups.py\", line 24, in __init__\n    self.rhs = self.get_prep_lookup()\n  File \"/testbed/django/db/models/lookups.py\", line 74, in get_prep_lookup\n    return self.lhs.output_field.get_prep_value(self.rhs)\n  File \"/testbed/django/db/models/fields/__init__.py\", line 1776, in get_prep_value\n    ) from e\nTypeError: Field 'id' expected a number but got <SimpleLazyObject: <Manager: Manager object (1)>>.\n\n----------------------------------------------------------------------\nRan 138 tests in 0.414s\n\nFAILED (errors=1, skipped=2)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 expressions.models expressions.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/expressions/models.py",
            "tests/expressions/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 138,
          "failed": 0,
          "errors": 0,
          "duration": 8.11,
          "log_tail": "test_new_object_create (expressions.tests.BasicExpressionsTests) ... ok\ntest_new_object_save (expressions.tests.BasicExpressionsTests) ... ok\ntest_object_create_with_aggregate (expressions.tests.BasicExpressionsTests) ... ok\ntest_object_update (expressions.tests.BasicExpressionsTests) ... ok\ntest_object_update_fk (expressions.tests.BasicExpressionsTests) ... ok\ntest_object_update_unsaved_objects (expressions.tests.BasicExpressionsTests) ... ok\ntest_order_by_exists (expressions.tests.BasicExpressionsTests) ... ok\ntest_order_by_multiline_sql (expressions.tests.BasicExpressionsTests) ... ok\ntest_order_of_operations (expressions.tests.BasicExpressionsTests) ... ok\ntest_outerref (expressions.tests.BasicExpressionsTests) ... ok\ntest_outerref_mixed_case_table_name (expressions.tests.BasicExpressionsTests) ... ok\ntest_outerref_with_operator (expressions.tests.BasicExpressionsTests) ... ok\ntest_parenthesis_priority (expressions.tests.BasicExpressionsTests) ... ok\ntest_pickle_expression (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_filter_by_aggregate (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_filter_by_lazy (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_group_by_outerref_in_filter (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_in_filter (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_references_joined_table_twice (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_11722_iexact_lookup (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_16731_startswith_lookup (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_18375_chained_filters (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_18375_join_reuse (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_18375_kwarg_ordering (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_18375_kwarg_ordering_2 (expressions.tests.BasicExpressionsTests) ... ok\ntest_update (expressions.tests.BasicExpressionsTests) ... ok\ntest_update_inherited_field_value (expressions.tests.BasicExpressionsTests) ... ok\ntest_update_with_fk (expressions.tests.BasicExpressionsTests) ... ok\ntest_update_with_none (expressions.tests.BasicExpressionsTests) ... ok\ntest_uuid_pk_subquery (expressions.tests.BasicExpressionsTests) ... ok\n\n----------------------------------------------------------------------\nRan 138 tests in 0.397s\n\nOK (skipped=2)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/expressions/models.py",
            "tests/expressions/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-12708",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 40.73222208023071,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 101,
          "failed": 0,
          "errors": 1,
          "duration": 11.27,
          "log_tail": "test_run_python_atomic (migrations.test_operations.OperationTests) ... ok\ntest_run_python_noop (migrations.test_operations.OperationTests) ... ok\ntest_run_python_related_assignment (migrations.test_operations.OperationTests) ... ok\ntest_run_sql (migrations.test_operations.OperationTests) ... ok\ntest_run_sql_noop (migrations.test_operations.OperationTests) ... ok\ntest_run_sql_params (migrations.test_operations.OperationTests) ... ok\ntest_run_sql_params_invalid (migrations.test_operations.OperationTests) ... ok\ntest_separate_database_and_state (migrations.test_operations.OperationTests) ... ok\ntest_separate_database_and_state2 (migrations.test_operations.OperationTests) ... ok\ntest_smallfield_autofield_foreignfield_growth (migrations.test_operations.OperationTests)\nA field may be migrated from SmallAutoField to AutoField. ... ok\ntest_smallfield_bigautofield_foreignfield_growth (migrations.test_operations.OperationTests)\nA field may be migrated from SmallAutoField to BigAutoField. ... ok\n\n======================================================================\nERROR: test_alter_index_together_remove_with_unique_together (migrations.test_operations.OperationTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/django/test/testcases.py\", line 1215, in skip_wrapper\n    return test_func(*args, **kwargs)\n  File \"/testbed/tests/migrations/test_operations.py\", line 1781, in test_alter_index_together_remove_with_unique_together\n    operation.database_forwards(app_label, editor, project_state, new_state)\n  File \"/testbed/django/db/migrations/operations/models.py\", line 511, in database_forwards\n    getattr(new_model._meta, self.option_name, set()),\n  File \"/testbed/django/db/backends/base/schema.py\", line 396, in alter_index_together\n    self._delete_composed_index(model, fields, {'index': True}, self.sql_delete_index)\n  File \"/testbed/django/db/backends/base/schema.py\", line 414, in _delete_composed_index\n    \", \".join(columns),\nValueError: Found wrong number (2) of constraints for test_alintoremove_wunto_pony(pink, weight)\n\n----------------------------------------------------------------------\nRan 102 tests in 1.749s\n\nFAILED (errors=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 migrations.test_base migrations.test_operations` failed. (See above for error)",
          "test_files_run": [
            "tests/migrations/test_base.py",
            "tests/migrations/test_operations.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 102,
          "failed": 0,
          "errors": 0,
          "duration": 9.81,
          "log_tail": "test_remove_field_m2m_with_through (migrations.test_operations.OperationTests) ... ok\ntest_remove_fk (migrations.test_operations.OperationTests) ... ok\ntest_remove_index (migrations.test_operations.OperationTests) ... ok\ntest_remove_index_state_forwards (migrations.test_operations.OperationTests) ... ok\ntest_remove_partial_unique_constraint (migrations.test_operations.OperationTests) ... ok\ntest_rename_field (migrations.test_operations.OperationTests) ... ok\ntest_rename_field_reloads_state_on_fk_target_changes (migrations.test_operations.OperationTests) ... ok\ntest_rename_m2m_model_after_rename_field (migrations.test_operations.OperationTests)\nRenameModel renames a many-to-many column after a RenameField. ... ok\ntest_rename_m2m_target_model (migrations.test_operations.OperationTests) ... ok\ntest_rename_m2m_through_model (migrations.test_operations.OperationTests) ... ok\ntest_rename_missing_field (migrations.test_operations.OperationTests) ... ok\ntest_rename_model (migrations.test_operations.OperationTests) ... ok\ntest_rename_model_state_forwards (migrations.test_operations.OperationTests) ... ok\ntest_rename_model_with_m2m (migrations.test_operations.OperationTests) ... ok\ntest_rename_model_with_self_referential_fk (migrations.test_operations.OperationTests) ... ok\ntest_rename_model_with_self_referential_m2m (migrations.test_operations.OperationTests) ... ok\ntest_rename_model_with_superclass_fk (migrations.test_operations.OperationTests) ... ok\ntest_rename_referenced_field_state_forward (migrations.test_operations.OperationTests) ... ok\ntest_repoint_field_m2m (migrations.test_operations.OperationTests) ... ok\ntest_run_python (migrations.test_operations.OperationTests) ... ok\ntest_run_python_atomic (migrations.test_operations.OperationTests) ... ok\ntest_run_python_noop (migrations.test_operations.OperationTests) ... ok\ntest_run_python_related_assignment (migrations.test_operations.OperationTests) ... ok\ntest_run_sql (migrations.test_operations.OperationTests) ... ok\ntest_run_sql_noop (migrations.test_operations.OperationTests) ... ok\ntest_run_sql_params (migrations.test_operations.OperationTests) ... ok\ntest_run_sql_params_invalid (migrations.test_operations.OperationTests) ... ok\ntest_separate_database_and_state (migrations.test_operations.OperationTests) ... ok\ntest_separate_database_and_state2 (migrations.test_operations.OperationTests) ... ok\ntest_smallfield_autofield_foreignfield_growth (migrations.test_operations.OperationTests)\nA field may be migrated from SmallAutoField to AutoField. ... ok\ntest_smallfield_bigautofield_foreignfield_growth (migrations.test_operations.OperationTests)\nA field may be migrated from SmallAutoField to BigAutoField. ... ok\n\n----------------------------------------------------------------------\nRan 102 tests in 1.828s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/migrations/test_base.py",
            "tests/migrations/test_operations.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-12713",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 38.72585916519165,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 72,
          "failed": 1,
          "errors": 0,
          "duration": 9.82,
          "log_tail": "test_render_required (admin_widgets.tests.AdminFileWidgetTests) ... ok\ntest_invalid_target_id (admin_widgets.tests.AdminForeignKeyRawIdWidget) ... ok\ntest_label_and_url_for_value_invalid_uuid (admin_widgets.tests.AdminForeignKeyRawIdWidget) ... ok\ntest_nonexistent_target_id (admin_widgets.tests.AdminForeignKeyRawIdWidget) ... ok\ntest_url_params_from_lookup_dict_any_iterable (admin_widgets.tests.AdminForeignKeyRawIdWidget) ... ok\ntest_url_params_from_lookup_dict_callable (admin_widgets.tests.AdminForeignKeyRawIdWidget) ... ok\n\n======================================================================\nFAIL: test_formfield_overrides_m2m_filter_widget (admin_widgets.tests.AdminFormfieldForDBFieldTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/admin_widgets/tests.py\", line 156, in test_formfield_overrides_m2m_filter_widget\n    self.assertIsInstance(field.widget.widget, forms.CheckboxSelectMultiple)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1246, in assertIsInstance\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: <django.contrib.admin.widgets.FilteredSelectMultiple object at 0x796f410eada0> is not an instance of <class 'django.forms.widgets.CheckboxSelectMultiple'>\n\n----------------------------------------------------------------------\nRan 73 tests in 0.738s\n\nFAILED (failures=1, skipped=14)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 admin_widgets.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/admin_widgets/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 73,
          "failed": 0,
          "errors": 0,
          "duration": 8.69,
          "log_tail": "test_select_multiple_widget_cant_change_delete_related (admin_widgets.tests.RelatedFieldWidgetWrapperTests) ... ok\ntest_widget_delegates_value_omitted_from_data (admin_widgets.tests.RelatedFieldWidgetWrapperTests) ... ok\ntest_widget_is_hidden (admin_widgets.tests.RelatedFieldWidgetWrapperTests) ... ok\ntest_widget_is_not_hidden (admin_widgets.tests.RelatedFieldWidgetWrapperTests) ... ok\ntest_fk_related_model_not_in_admin (admin_widgets.tests.ForeignKeyRawIdWidgetTest) ... ok\ntest_fk_to_self_model_not_in_admin (admin_widgets.tests.ForeignKeyRawIdWidgetTest) ... ok\ntest_proper_manager_for_label_lookup (admin_widgets.tests.ForeignKeyRawIdWidgetTest) ... ok\ntest_relations_to_non_primary_key (admin_widgets.tests.ForeignKeyRawIdWidgetTest) ... ok\ntest_render (admin_widgets.tests.ForeignKeyRawIdWidgetTest) ... ok\ntest_filter_choices_by_request_user (admin_widgets.tests.AdminFormfieldForDBFieldWithRequestTests) ... ok\ntest_get_context_validates_url (admin_widgets.tests.AdminURLWidgetTest) ... ok\ntest_render (admin_widgets.tests.AdminURLWidgetTest) ... ok\ntest_render_idn (admin_widgets.tests.AdminURLWidgetTest) ... ok\ntest_render_quoting (admin_widgets.tests.AdminURLWidgetTest) ... ok\ntest_changelist_ForeignKey (admin_widgets.tests.AdminForeignKeyWidgetChangeList) ... ok\ntest_readonly_fields (admin_widgets.tests.AdminFileWidgetTests) ... ok\ntest_render (admin_widgets.tests.AdminFileWidgetTests) ... ok\ntest_render_required (admin_widgets.tests.AdminFileWidgetTests) ... ok\ntest_invalid_target_id (admin_widgets.tests.AdminForeignKeyRawIdWidget) ... ok\ntest_label_and_url_for_value_invalid_uuid (admin_widgets.tests.AdminForeignKeyRawIdWidget) ... ok\ntest_nonexistent_target_id (admin_widgets.tests.AdminForeignKeyRawIdWidget) ... ok\ntest_url_params_from_lookup_dict_any_iterable (admin_widgets.tests.AdminForeignKeyRawIdWidget) ... ok\ntest_url_params_from_lookup_dict_callable (admin_widgets.tests.AdminForeignKeyRawIdWidget) ... ok\n\n----------------------------------------------------------------------\nRan 73 tests in 0.500s\n\nOK (skipped=14)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/admin_widgets/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-12741",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "django__django-12754",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "django__django-12774",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 38.64665198326111,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 41,
          "failed": 0,
          "errors": 1,
          "duration": 8.52,
          "log_tail": "test_exclude (lookup.tests.LookupTests) ... ok\ntest_exists (lookup.tests.LookupTests) ... ok\ntest_get_next_previous_by (lookup.tests.LookupTests) ... ok\ntest_in (lookup.tests.LookupTests) ... ok\ntest_in_bulk (lookup.tests.LookupTests) ... ok\ntest_in_bulk_lots_of_ids (lookup.tests.LookupTests) ... ok\ntest_in_bulk_meta_constraint (lookup.tests.LookupTests) ... ERROR\ntest_in_bulk_non_unique_field (lookup.tests.LookupTests) ... ok\ntest_in_bulk_non_unique_meta_constaint (lookup.tests.LookupTests) ... ok\ntest_in_bulk_with_field (lookup.tests.LookupTests) ... ok\ntest_in_different_database (lookup.tests.LookupTests) ... ok\ntest_in_keeps_value_ordering (lookup.tests.LookupTests) ... ok\ntest_isnull_non_boolean_value (lookup.tests.LookupTests) ... ok\ntest_iterator (lookup.tests.LookupTests) ... ok\ntest_lookup_collision (lookup.tests.LookupTests) ... ok\ntest_lookup_date_as_str (lookup.tests.LookupTests) ... ok\ntest_lookup_int_as_str (lookup.tests.LookupTests) ... ok\ntest_nested_outerref_lhs (lookup.tests.LookupTests) ... ok\ntest_none (lookup.tests.LookupTests) ... ok\ntest_nonfield_lookups (lookup.tests.LookupTests) ... ok\ntest_pattern_lookups_with_substr (lookup.tests.LookupTests) ... ok\ntest_regex (lookup.tests.LookupTests) ... ok\ntest_regex_backreferencing (lookup.tests.LookupTests) ... ok\ntest_regex_non_ascii (lookup.tests.LookupTests) ... ok\ntest_regex_non_string (lookup.tests.LookupTests) ... ok\ntest_regex_null (lookup.tests.LookupTests) ... ok\ntest_relation_nested_lookup_error (lookup.tests.LookupTests) ... ok\ntest_unsupported_lookups (lookup.tests.LookupTests) ... ok\ntest_values (lookup.tests.LookupTests) ... ok\ntest_values_list (lookup.tests.LookupTests) ... ok\n\n======================================================================\nERROR: test_in_bulk_meta_constraint (lookup.tests.LookupTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/lookup/tests.py\", line 200, in test_in_bulk_meta_constraint\n    field_name='year',\n  File \"/testbed/django/db/models/manager.py\", line 85, in manager_method\n    return getattr(self.get_queryset(), name)(*args, **kwargs)\n  File \"/testbed/django/db/models/query.py\", line 693, in in_bulk\n    raise ValueError(\"in_bulk()'s field_name must be a unique field but %r isn't.\" % field_name)\nValueError: in_bulk()'s field_name must be a unique field but 'year' isn't.\n\n----------------------------------------------------------------------\nRan 42 tests in 0.213s\n\nFAILED (errors=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 lookup.models lookup.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/lookup/models.py",
            "tests/lookup/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 42,
          "failed": 0,
          "errors": 0,
          "duration": 7.73,
          "log_tail": "test_count (lookup.tests.LookupTests) ... ok\ntest_custom_field_none_rhs (lookup.tests.LookupTests) ... ok\ntest_custom_lookup_none_rhs (lookup.tests.LookupTests)\nLookup.can_use_none_as_rhs=True allows None as a lookup value. ... ok\ntest_error_messages (lookup.tests.LookupTests) ... ok\ntest_escaping (lookup.tests.LookupTests) ... ok\ntest_exact_exists (lookup.tests.LookupTests) ... ok\ntest_exact_none_transform (lookup.tests.LookupTests)\nTransforms are used for __exact=None. ... ok\ntest_exact_query_rhs_with_selected_columns (lookup.tests.LookupTests) ... ok\ntest_exact_sliced_queryset_limit_one (lookup.tests.LookupTests) ... ok\ntest_exact_sliced_queryset_limit_one_offset (lookup.tests.LookupTests) ... ok\ntest_exact_sliced_queryset_not_limited_to_one (lookup.tests.LookupTests) ... ok\ntest_exclude (lookup.tests.LookupTests) ... ok\ntest_exists (lookup.tests.LookupTests) ... ok\ntest_get_next_previous_by (lookup.tests.LookupTests) ... ok\ntest_in (lookup.tests.LookupTests) ... ok\ntest_in_bulk (lookup.tests.LookupTests) ... ok\ntest_in_bulk_lots_of_ids (lookup.tests.LookupTests) ... ok\ntest_in_bulk_meta_constraint (lookup.tests.LookupTests) ... ok\ntest_in_bulk_non_unique_field (lookup.tests.LookupTests) ... ok\ntest_in_bulk_non_unique_meta_constaint (lookup.tests.LookupTests) ... ok\ntest_in_bulk_with_field (lookup.tests.LookupTests) ... ok\ntest_in_different_database (lookup.tests.LookupTests) ... ok\ntest_in_keeps_value_ordering (lookup.tests.LookupTests) ... ok\ntest_isnull_non_boolean_value (lookup.tests.LookupTests) ... ok\ntest_iterator (lookup.tests.LookupTests) ... ok\ntest_lookup_collision (lookup.tests.LookupTests) ... ok\ntest_lookup_date_as_str (lookup.tests.LookupTests) ... ok\ntest_lookup_int_as_str (lookup.tests.LookupTests) ... ok\ntest_nested_outerref_lhs (lookup.tests.LookupTests) ... ok\ntest_none (lookup.tests.LookupTests) ... ok\ntest_nonfield_lookups (lookup.tests.LookupTests) ... ok\ntest_pattern_lookups_with_substr (lookup.tests.LookupTests) ... ok\ntest_regex (lookup.tests.LookupTests) ... ok\ntest_regex_backreferencing (lookup.tests.LookupTests) ... ok\ntest_regex_non_ascii (lookup.tests.LookupTests) ... ok\ntest_regex_non_string (lookup.tests.LookupTests) ... ok\ntest_regex_null (lookup.tests.LookupTests) ... ok\ntest_relation_nested_lookup_error (lookup.tests.LookupTests) ... ok\ntest_unsupported_lookups (lookup.tests.LookupTests) ... ok\ntest_values (lookup.tests.LookupTests) ... ok\ntest_values_list (lookup.tests.LookupTests) ... ok\n\n----------------------------------------------------------------------\nRan 42 tests in 0.277s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/lookup/models.py",
            "tests/lookup/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-12858",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "django__django-12965",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "django__django-13012",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "django__django-13023",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "django__django-13028",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "django__django-13033",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 43.021703243255615,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 26,
          "failed": 1,
          "errors": 0,
          "duration": 12.3,
          "log_tail": "test_no_reordering_after_slicing (ordering.tests.OrderingTests) ... ok\ntest_order_by_constant_value (ordering.tests.OrderingTests) ... ok\ntest_order_by_constant_value_without_output_field (ordering.tests.OrderingTests) ... ok\ntest_order_by_f_expression (ordering.tests.OrderingTests) ... ok\ntest_order_by_f_expression_duplicates (ordering.tests.OrderingTests) ... ok\ntest_order_by_fk_attname (ordering.tests.OrderingTests) ... ok\ntest_order_by_nulls_first (ordering.tests.OrderingTests) ... ok\ntest_order_by_nulls_first_and_last (ordering.tests.OrderingTests) ... ok\ntest_order_by_nulls_last (ordering.tests.OrderingTests) ... ok\ntest_order_by_override (ordering.tests.OrderingTests) ... ok\ntest_order_by_pk (ordering.tests.OrderingTests) ... ok\ntest_order_by_ptr_field_with_default_ordering_by_expression (ordering.tests.OrderingTests) ... ok\ntest_order_by_self_referential_fk (ordering.tests.OrderingTests) ... FAIL\ntest_orders_nulls_first_on_filtered_subquery (ordering.tests.OrderingTests) ... ok\ntest_random_ordering (ordering.tests.OrderingTests) ... ok\ntest_related_ordering_duplicate_table_reference (ordering.tests.OrderingTests) ... ok\ntest_reverse_meta_ordering_pure (ordering.tests.OrderingTests) ... ok\ntest_reverse_ordering_pure (ordering.tests.OrderingTests) ... ok\ntest_reversed_ordering (ordering.tests.OrderingTests) ... ok\ntest_stop_slicing (ordering.tests.OrderingTests) ... ok\ntest_stop_start_slicing (ordering.tests.OrderingTests) ... ok\n\n======================================================================\nFAIL: test_order_by_self_referential_fk (ordering.tests.OrderingTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/ordering/tests.py\", line 359, in test_order_by_self_referential_fk\n    attrgetter('headline'),\n  File \"/testbed/django/test/testcases.py\", line 1054, in assertQuerysetEqual\n    return self.assertEqual(list(items), values, msg=msg)\nAssertionError: Lists differ: ['Article 2', 'Article 1'] != ['Article 1', 'Article 2']\n\nFirst differing element 0:\n'Article 2'\n'Article 1'\n\n- ['Article 2', 'Article 1']\n?           ^            ^\n\n+ ['Article 1', 'Article 2']\n?           ^            ^\n\n\n----------------------------------------------------------------------\nRan 27 tests in 0.085s\n\nFAILED (failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 ordering.models ordering.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/ordering/models.py",
            "tests/ordering/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 27,
          "failed": 0,
          "errors": 0,
          "duration": 10.44,
          "log_tail": "    Creating table ordering_author\n    Creating table ordering_article\n    Creating table ordering_childarticle\n    Creating table ordering_reference\n    Running deferred SQL...\nRunning migrations:\n  Applying admin.0001_initial... OK\n  Applying admin.0002_logentry_remove_auto_add... OK\n  Applying admin.0003_logentry_add_action_flag_choices... OK\n  Applying sites.0001_initial... OK\n  Applying sites.0002_alter_domain_unique... OK\nSystem check identified no issues (0 silenced).\n\n\nCreating test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\ntest_default_ordering (ordering.tests.OrderingTests) ... ok\ntest_default_ordering_by_f_expression (ordering.tests.OrderingTests)\nF expressions can be used in Meta.ordering. ... ok\ntest_default_ordering_override (ordering.tests.OrderingTests) ... ok\ntest_extra_ordering (ordering.tests.OrderingTests) ... ok\ntest_extra_ordering_quoting (ordering.tests.OrderingTests) ... ok\ntest_extra_ordering_with_table_name (ordering.tests.OrderingTests) ... ok\ntest_no_reordering_after_slicing (ordering.tests.OrderingTests) ... ok\ntest_order_by_constant_value (ordering.tests.OrderingTests) ... ok\ntest_order_by_constant_value_without_output_field (ordering.tests.OrderingTests) ... ok\ntest_order_by_f_expression (ordering.tests.OrderingTests) ... ok\ntest_order_by_f_expression_duplicates (ordering.tests.OrderingTests) ... ok\ntest_order_by_fk_attname (ordering.tests.OrderingTests) ... ok\ntest_order_by_nulls_first (ordering.tests.OrderingTests) ... ok\ntest_order_by_nulls_first_and_last (ordering.tests.OrderingTests) ... ok\ntest_order_by_nulls_last (ordering.tests.OrderingTests) ... ok\ntest_order_by_override (ordering.tests.OrderingTests) ... ok\ntest_order_by_pk (ordering.tests.OrderingTests) ... ok\ntest_order_by_ptr_field_with_default_ordering_by_expression (ordering.tests.OrderingTests) ... ok\ntest_order_by_self_referential_fk (ordering.tests.OrderingTests) ... ok\ntest_orders_nulls_first_on_filtered_subquery (ordering.tests.OrderingTests) ... ok\ntest_random_ordering (ordering.tests.OrderingTests) ... ok\ntest_related_ordering_duplicate_table_reference (ordering.tests.OrderingTests) ... ok\ntest_reverse_meta_ordering_pure (ordering.tests.OrderingTests) ... ok\ntest_reverse_ordering_pure (ordering.tests.OrderingTests) ... ok\ntest_reversed_ordering (ordering.tests.OrderingTests) ... ok\ntest_stop_slicing (ordering.tests.OrderingTests) ... ok\ntest_stop_start_slicing (ordering.tests.OrderingTests) ... ok\n\n----------------------------------------------------------------------\nRan 27 tests in 0.075s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/ordering/models.py",
            "tests/ordering/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-13089",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "django__django-13109",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 44.59507083892822,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 171,
          "failed": 1,
          "errors": 1,
          "duration": 12.98,
          "log_tail": "    self.assertIsNone(article.full_clean())\n  File \"/testbed/django/db/models/base.py\", line 1228, in full_clean\n    raise ValidationError(errors)\ndjango.core.exceptions.ValidationError: {'author': ['author instance with id 1 does not exist.']}\n\n======================================================================\nFAIL: test_validate_foreign_key_to_model_with_overridden_manager (model_forms.tests.ModelFormBasicTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/model_forms/tests.py\", line 1689, in test_validate_foreign_key_to_model_with_overridden_manager\n    self.assertIs(form.is_valid(), True)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1103, in assertIs\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: False is not True\n\n----------------------------------------------------------------------\nRan 173 tests in 0.578s\n\nFAILED (failures=1, errors=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 model_forms.models model_forms.tests validation.models validation.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/model_forms/models.py",
            "tests/model_forms/tests.py",
            "tests/validation/models.py",
            "tests/validation/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 173,
          "failed": 0,
          "errors": 0,
          "duration": 11.74,
          "log_tail": "test_unique_together_exclusion (model_forms.tests.UniqueTest) ... ok\ntest_auto_id (model_forms.tests.ModelFormBasicTests) ... ok\ntest_base_form (model_forms.tests.ModelFormBasicTests) ... ok\ntest_basic_creation (model_forms.tests.ModelFormBasicTests) ... ok\ntest_custom_form_fields (model_forms.tests.ModelFormBasicTests) ... ok\ntest_initial_values (model_forms.tests.ModelFormBasicTests) ... ok\ntest_m2m_editing (model_forms.tests.ModelFormBasicTests) ... ok\ntest_m2m_initial_callable (model_forms.tests.ModelFormBasicTests) ... ok\ntest_multi_fields (model_forms.tests.ModelFormBasicTests) ... ok\ntest_recleaning_model_form_instance (model_forms.tests.ModelFormBasicTests) ... ok\ntest_runtime_choicefield_populated (model_forms.tests.ModelFormBasicTests) ... ok\ntest_save_commit_false (model_forms.tests.ModelFormBasicTests) ... ok\ntest_save_with_data_errors (model_forms.tests.ModelFormBasicTests) ... ok\ntest_subset_fields (model_forms.tests.ModelFormBasicTests) ... ok\ntest_validate_foreign_key_to_model_with_overridden_manager (model_forms.tests.ModelFormBasicTests) ... ok\ntest_validate_foreign_key_uses_default_manager (model_forms.tests.ModelFormBasicTests) ... ok\ntest_error_messages_overrides (model_forms.tests.TestFieldOverridesByFormMeta) ... ok\ntest_field_type_overrides (model_forms.tests.TestFieldOverridesByFormMeta) ... ok\ntest_help_text_overrides (model_forms.tests.TestFieldOverridesByFormMeta) ... ok\ntest_label_overrides (model_forms.tests.TestFieldOverridesByFormMeta) ... ok\ntest_widget_overrides (model_forms.tests.TestFieldOverridesByFormMeta) ... ok\n\n----------------------------------------------------------------------\nRan 173 tests in 0.470s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/model_forms/models.py",
            "tests/model_forms/tests.py",
            "tests/validation/models.py",
            "tests/validation/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-13112",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "django__django-13121",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "django__django-13128",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "django__django-13158",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 45.02764105796814,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 31,
          "failed": 1,
          "errors": 0,
          "duration": 12.55,
          "log_tail": "test_difference_with_empty_qs (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_difference_with_values (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_intersection_with_empty_qs (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_intersection_with_values (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_limits (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_order_by_same_type (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_order_raises_on_non_selected_column (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_ordering (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_ordering_by_alias (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_ordering_by_f_expression (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_ordering_by_f_expression_and_alias (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_ordering_subqueries (queries.test_qs_combinators.QuerySetSetOperationTests) ... skipped \"Database doesn't support feature(s): supports_slicing_ordering_in_compound\"\ntest_qs_with_subcompound_qs (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_simple_difference (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_simple_intersection (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_simple_union (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_union_distinct (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_union_none (queries.test_qs_combinators.QuerySetSetOperationTests) ... FAIL\ntest_union_with_empty_qs (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_union_with_extra_and_values_list (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_union_with_two_annotated_values_list (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_union_with_values (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_union_with_values_list_and_order (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_union_with_values_list_on_annotated_and_unannotated (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_unsupported_intersection_raises_db_error (queries.test_qs_combinators.QuerySetSetOperationTests) ... skipped 'Database has feature(s) supports_select_intersection'\ntest_unsupported_operations_on_combined_qs (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_unsupported_ordering_slicing_raises_db_error (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\n\n======================================================================\nFAIL: test_union_none (queries.test_qs_combinators.QuerySetSetOperationTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/queries/test_qs_combinators.py\", line 58, in test_union_none\n    self.assertSequenceEqual(qs3.none(), [])\nAssertionError: Sequences differ: <QuerySet [<Number: 0>, <Number: 1>, <Number: 8>, <Number: 9>]> != []\n\nFirst sequence contains 4 additional elements.\nFirst extra element 0:\n<Number: 0>\n\n- <QuerySet [<Number: 0>, <Number: 1>, <Number: 8>, <Number: 9>]>\n+ []\n\n----------------------------------------------------------------------\nRan 32 tests in 0.091s\n\nFAILED (failures=1, skipped=2)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 queries.test_qs_combinators` failed. (See above for error)",
          "test_files_run": [
            "tests/queries/test_qs_combinators.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 32,
          "failed": 0,
          "errors": 0,
          "duration": 11.82,
          "log_tail": "    Running deferred SQL...\nRunning migrations:\n  Applying admin.0001_initial... OK\n  Applying admin.0002_logentry_remove_auto_add... OK\n  Applying admin.0003_logentry_add_action_flag_choices... OK\n  Applying sites.0001_initial... OK\n  Applying sites.0002_alter_domain_unique... OK\nSystem check identified no issues (1 silenced).\n\n\nCreating test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\ntest_combining_multiple_models (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_count_difference (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_count_intersection (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_count_union (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_count_union_empty_result (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_difference_with_empty_qs (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_difference_with_values (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_intersection_with_empty_qs (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_intersection_with_values (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_limits (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_order_by_same_type (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_order_raises_on_non_selected_column (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_ordering (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_ordering_by_alias (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_ordering_by_f_expression (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_ordering_by_f_expression_and_alias (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_ordering_subqueries (queries.test_qs_combinators.QuerySetSetOperationTests) ... skipped \"Database doesn't support feature(s): supports_slicing_ordering_in_compound\"\ntest_qs_with_subcompound_qs (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_simple_difference (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_simple_intersection (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_simple_union (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_union_distinct (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_union_none (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_union_with_empty_qs (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_union_with_extra_and_values_list (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_union_with_two_annotated_values_list (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_union_with_values (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_union_with_values_list_and_order (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_union_with_values_list_on_annotated_and_unannotated (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_unsupported_intersection_raises_db_error (queries.test_qs_combinators.QuerySetSetOperationTests) ... skipped 'Database has feature(s) supports_select_intersection'\ntest_unsupported_operations_on_combined_qs (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\ntest_unsupported_ordering_slicing_raises_db_error (queries.test_qs_combinators.QuerySetSetOperationTests) ... ok\n\n----------------------------------------------------------------------\nRan 32 tests in 0.153s\n\nOK (skipped=2)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/queries/test_qs_combinators.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-13195",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "django__django-13212",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 44.350768089294434,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": -16,
          "failed": 19,
          "errors": 4,
          "duration": 12.02,
          "log_tail": "  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 523, in subTest\n    yield\n  File \"/testbed/tests/forms_tests/tests/test_validators.py\", line 157, in test_value_placeholder_with_decimal_field\n    self.assertEqual(form.errors, {'field': [value]})\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 822, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: {'field': ['%(value)s']} != {'field': ['NaN']}\n\n======================================================================\nFAIL: test_value_placeholder_with_integer_field (forms_tests.tests.test_validators.ValidatorCustomMessageTests) [URLValidator] (value='1')\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 523, in subTest\n    yield\n  File \"/testbed/tests/forms_tests/tests/test_validators.py\", line 137, in test_value_placeholder_with_integer_field\n    self.assertEqual(form.errors, {'field': [str(value)]})\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 822, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: {'field': ['%(value)s']} != {'field': ['1']}\n\n======================================================================\nFAIL: test_value_placeholder_with_null_character (forms_tests.tests.test_validators.ValidatorCustomMessageTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/forms_tests/tests/test_validators.py\", line 119, in test_value_placeholder_with_null_character\n    self.assertEqual(form.errors, {'field': ['a\\x00b']})\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 822, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: {'field': ['%(value)s']} != {'field': ['a\\x00b']}\n\n----------------------------------------------------------------------\nRan 7 tests in 0.552s\n\nFAILED (failures=19, errors=4)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 forms_tests.tests.test_validators` failed. (See above for error)",
          "test_files_run": [
            "tests/forms_tests/tests/test_validators.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 7,
          "failed": 0,
          "errors": 0,
          "duration": 13.36,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application forms_tests\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_all_errors_get_reported (forms_tests.tests.test_validators.TestFieldWithValidators) ... ok\ntest_field_validators_can_be_any_iterable (forms_tests.tests.test_validators.TestFieldWithValidators) ... ok\ntest_value_placeholder_with_char_field (forms_tests.tests.test_validators.ValidatorCustomMessageTests) ... ok\ntest_value_placeholder_with_decimal_field (forms_tests.tests.test_validators.ValidatorCustomMessageTests) ... ok\ntest_value_placeholder_with_file_field (forms_tests.tests.test_validators.ValidatorCustomMessageTests) ... ok\ntest_value_placeholder_with_integer_field (forms_tests.tests.test_validators.ValidatorCustomMessageTests) ... ok\ntest_value_placeholder_with_null_character (forms_tests.tests.test_validators.ValidatorCustomMessageTests) ... ok\n\n----------------------------------------------------------------------\nRan 7 tests in 0.350s\n\nOK\n",
          "test_files_run": [
            "tests/forms_tests/tests/test_validators.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-13279",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "django__django-13297",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "django__django-13315",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "django__django-13343",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "django__django-13344",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "django__django-13346",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "django__django-13363",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "django__django-13401",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "django__django-13406",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 37.01794695854187,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 31,
          "failed": 4,
          "errors": 0,
          "duration": 13.05,
          "log_tail": "    yield\n  File \"/testbed/tests/queryset_pickle/tests.py\", line 247, in test_annotation_values_list\n    self.assertEqual(reloaded.get(), {'name': 'test'})\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 822, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: <queryset_pickle.models.Happening object at 0x7240ff66d048> != {'name': 'test'}\n\n======================================================================\nFAIL: test_annotation_values_list (queryset_pickle.tests.PickleabilityTestCase) [FlatValuesListIterable]\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 523, in subTest\n    yield\n  File \"/testbed/tests/queryset_pickle/tests.py\", line 247, in test_annotation_values_list\n    self.assertEqual(reloaded.get(), {'name': 'test'})\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 822, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: <queryset_pickle.models.Happening object at 0x7240ff66d198> != {'name': 'test'}\n\n======================================================================\nFAIL: test_annotation_values_list (queryset_pickle.tests.PickleabilityTestCase) [NamedValuesListIterable]\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 523, in subTest\n    yield\n  File \"/testbed/tests/queryset_pickle/tests.py\", line 247, in test_annotation_values_list\n    self.assertEqual(reloaded.get(), {'name': 'test'})\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 822, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: <queryset_pickle.models.Happening object at 0x7240ff66d2e8> != {'name': 'test'}\n\n----------------------------------------------------------------------\nRan 35 tests in 0.285s\n\nFAILED (failures=4)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 queryset_pickle.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/queryset_pickle/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 35,
          "failed": 0,
          "errors": 0,
          "duration": 12.81,
          "log_tail": "System check identified no issues (0 silenced).\n\n\nCreating test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\ntest_in_lookup_query_evaluation (queryset_pickle.tests.InLookupTests) ... ok\ntest_in_lookup_queryset_evaluation (queryset_pickle.tests.InLookupTests) ... ok\ntest_annotation_values (queryset_pickle.tests.PickleabilityTestCase) ... ok\ntest_annotation_values_list (queryset_pickle.tests.PickleabilityTestCase) ... ok\ntest_annotation_with_callable_default (queryset_pickle.tests.PickleabilityTestCase) ... ok\ntest_datetime_callable_default_all (queryset_pickle.tests.PickleabilityTestCase) ... ok\ntest_datetime_callable_default_filter (queryset_pickle.tests.PickleabilityTestCase) ... ok\ntest_doesnotexist_class (queryset_pickle.tests.PickleabilityTestCase) ... ok\ntest_doesnotexist_exception (queryset_pickle.tests.PickleabilityTestCase) ... ok\ntest_filter_deferred (queryset_pickle.tests.PickleabilityTestCase) ... ok\ntest_filter_reverse_fk (queryset_pickle.tests.PickleabilityTestCase) ... ok\ntest_forward_relatedobjectdoesnotexist_class (queryset_pickle.tests.PickleabilityTestCase) ... ok\ntest_manager_pickle (queryset_pickle.tests.PickleabilityTestCase) ... ok\ntest_missing_django_version_unpickling (queryset_pickle.tests.PickleabilityTestCase) ... ok\ntest_model_pickle (queryset_pickle.tests.PickleabilityTestCase) ... ok\ntest_model_pickle_dynamic (queryset_pickle.tests.PickleabilityTestCase) ... ok\ntest_model_pickle_m2m (queryset_pickle.tests.PickleabilityTestCase) ... ok\ntest_multipleobjectsreturned_class (queryset_pickle.tests.PickleabilityTestCase) ... ok\ntest_order_by_model_with_abstract_inheritance_and_meta_ordering (queryset_pickle.tests.PickleabilityTestCase) ... ok\ntest_pickle_exists_kwargs_queryset_not_evaluated (queryset_pickle.tests.PickleabilityTestCase) ... ok\ntest_pickle_exists_queryset_not_evaluated (queryset_pickle.tests.PickleabilityTestCase) ... ok\ntest_pickle_exists_queryset_still_usable (queryset_pickle.tests.PickleabilityTestCase) ... ok\ntest_pickle_prefetch_queryset_not_evaluated (queryset_pickle.tests.PickleabilityTestCase) ... ok\ntest_pickle_prefetch_queryset_still_usable (queryset_pickle.tests.PickleabilityTestCase) ... ok\ntest_pickle_prefetch_queryset_usable_outside_of_prefetch (queryset_pickle.tests.PickleabilityTestCase) ... ok\ntest_pickle_prefetch_related_idempotence (queryset_pickle.tests.PickleabilityTestCase) ... ok\ntest_pickle_prefetch_related_with_m2m_and_objects_deletion (queryset_pickle.tests.PickleabilityTestCase) ... ok\ntest_pickle_subquery_queryset_not_evaluated (queryset_pickle.tests.PickleabilityTestCase) ... ok\ntest_related_field (queryset_pickle.tests.PickleabilityTestCase) ... ok\ntest_reverse_one_to_one_relatedobjectdoesnotexist_class (queryset_pickle.tests.PickleabilityTestCase) ... ok\ntest_specialized_queryset (queryset_pickle.tests.PickleabilityTestCase) ... ok\ntest_standalone_method_as_default (queryset_pickle.tests.PickleabilityTestCase) ... ok\ntest_staticmethod_as_default (queryset_pickle.tests.PickleabilityTestCase) ... ok\ntest_string_as_default (queryset_pickle.tests.PickleabilityTestCase) ... ok\ntest_unsupported_unpickle (queryset_pickle.tests.PickleabilityTestCase) ... ok\n\n----------------------------------------------------------------------\nRan 35 tests in 0.419s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/queryset_pickle/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-13410",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "django__django-13417",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "django__django-13449",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "django__django-13512",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "django__django-13513",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "django__django-13516",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "django__django-13551",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "django__django-13568",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 36.548157930374146,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 13,
          "failed": 1,
          "errors": 0,
          "duration": 13.11,
          "log_tail": "test_custom_permission_codename_max_length (auth_tests.test_checks.ModelsPermissionsChecksTests) ... ok\ntest_custom_permission_name_max_length (auth_tests.test_checks.ModelsPermissionsChecksTests) ... ok\ntest_empty_default_permissions (auth_tests.test_checks.ModelsPermissionsChecksTests) ... ok\ntest_model_name_max_length (auth_tests.test_checks.ModelsPermissionsChecksTests) ... ok\ntest_non_clashing_custom_permissions (auth_tests.test_checks.ModelsPermissionsChecksTests) ... ok\ntest_verbose_name_max_length (auth_tests.test_checks.ModelsPermissionsChecksTests) ... ok\ntest_is_anonymous_authenticated_methods (auth_tests.test_checks.UserModelChecksTests) ... ok\ntest_required_fields_is_list (auth_tests.test_checks.UserModelChecksTests)\nREQUIRED_FIELDS should be a list. ... ok\ntest_username_non_unique (auth_tests.test_checks.UserModelChecksTests) ... ok\ntest_username_not_in_required_fields (auth_tests.test_checks.UserModelChecksTests)\nUSERNAME_FIELD should not appear in REQUIRED_FIELDS. ... ok\ntest_username_partially_unique (auth_tests.test_checks.UserModelChecksTests) ... ok\ntest_username_unique_with_model_constraint (auth_tests.test_checks.UserModelChecksTests) ... FAIL\n\n======================================================================\nFAIL: test_username_unique_with_model_constraint (auth_tests.test_checks.UserModelChecksTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/django/test/utils.py\", line 382, in inner\n    return func(*args, **kwargs)\n  File \"/testbed/tests/auth_tests/test_checks.py\", line 139, in test_username_unique_with_model_constraint\n    self.assertEqual(checks.run_checks(app_configs=self.apps.get_app_configs()), [])\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1028, in assertListEqual\n    self.assertSequenceEqual(list1, list2, msg, seq_type=list)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1010, in assertSequenceEqual\n    self.fail(msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: Lists differ: [<Error: level=40, msg=\"'CustomUserUniqueC[242 chars]03'>] != []\n\nFirst list contains 1 additional elements.\nFirst extra element 0:\n<Error: level=40, msg=\"'CustomUserUniqueConstraint.username' must be unique because it is named as the 'USERNAME_FIELD'.\", hint=None, obj=<class 'auth_tests.test_checks.UserModelChecksTests.test_username_unique_with_model_constraint.<locals>.CustomUserUniqueConstraint'>, id='auth.E003'>\n\n- [<Error: level=40, msg=\"'CustomUserUniqueConstraint.username' must be unique because it is named as the 'USERNAME_FIELD'.\", hint=None, obj=<class 'auth_tests.test_checks.UserModelChecksTests.test_username_unique_with_model_constraint.<locals>.CustomUserUniqueConstraint'>, id='auth.E003'>]\n+ []\n\n----------------------------------------------------------------------\nRan 14 tests in 0.296s\n\nFAILED (failures=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 auth_tests.test_checks` failed. (See above for error)",
          "test_files_run": [
            "tests/auth_tests/test_checks.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 14,
          "failed": 0,
          "errors": 0,
          "duration": 12.34,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application auth_tests\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_clashing_custom_permissions (auth_tests.test_checks.ModelsPermissionsChecksTests) ... ok\ntest_clashing_default_permissions (auth_tests.test_checks.ModelsPermissionsChecksTests) ... ok\ntest_custom_permission_codename_max_length (auth_tests.test_checks.ModelsPermissionsChecksTests) ... ok\ntest_custom_permission_name_max_length (auth_tests.test_checks.ModelsPermissionsChecksTests) ... ok\ntest_empty_default_permissions (auth_tests.test_checks.ModelsPermissionsChecksTests) ... ok\ntest_model_name_max_length (auth_tests.test_checks.ModelsPermissionsChecksTests) ... ok\ntest_non_clashing_custom_permissions (auth_tests.test_checks.ModelsPermissionsChecksTests) ... ok\ntest_verbose_name_max_length (auth_tests.test_checks.ModelsPermissionsChecksTests) ... ok\ntest_is_anonymous_authenticated_methods (auth_tests.test_checks.UserModelChecksTests) ... ok\ntest_required_fields_is_list (auth_tests.test_checks.UserModelChecksTests)\nREQUIRED_FIELDS should be a list. ... ok\ntest_username_non_unique (auth_tests.test_checks.UserModelChecksTests) ... ok\ntest_username_not_in_required_fields (auth_tests.test_checks.UserModelChecksTests)\nUSERNAME_FIELD should not appear in REQUIRED_FIELDS. ... ok\ntest_username_partially_unique (auth_tests.test_checks.UserModelChecksTests) ... ok\ntest_username_unique_with_model_constraint (auth_tests.test_checks.UserModelChecksTests) ... ok\n\n----------------------------------------------------------------------\nRan 14 tests in 0.246s\n\nOK\n",
          "test_files_run": [
            "tests/auth_tests/test_checks.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-13569",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 36.082890033721924,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 67,
          "failed": 1,
          "errors": 0,
          "duration": 13.33,
          "log_tail": "test_count_distinct_expression (aggregation.tests.AggregateTestCase) ... ok\ntest_count_star (aggregation.tests.AggregateTestCase) ... ok\ntest_dates_with_aggregation (aggregation.tests.AggregateTestCase) ... ok\ntest_decimal_max_digits_has_no_effect (aggregation.tests.AggregateTestCase) ... ok\ntest_distinct_on_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_empty_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_even_more_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_expression_on_aggregation (aggregation.tests.AggregateTestCase) ... ok\ntest_filter_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_filtering (aggregation.tests.AggregateTestCase) ... ok\ntest_fkey_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_group_by_exists_annotation (aggregation.tests.AggregateTestCase) ... ok\ntest_group_by_subquery_annotation (aggregation.tests.AggregateTestCase) ... ok\ntest_grouped_annotation_in_group_by (aggregation.tests.AggregateTestCase) ... ok\ntest_more_aggregation (aggregation.tests.AggregateTestCase) ... ok\ntest_multi_arg_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_multiple_aggregates (aggregation.tests.AggregateTestCase) ... ok\ntest_non_grouped_annotation_not_in_group_by (aggregation.tests.AggregateTestCase) ... ok\ntest_nonaggregate_aggregation_throws (aggregation.tests.AggregateTestCase) ... ok\ntest_nonfield_annotation (aggregation.tests.AggregateTestCase) ... ok\ntest_order_of_precedence (aggregation.tests.AggregateTestCase) ... ok\ntest_related_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_reverse_fkey_annotate (aggregation.tests.AggregateTestCase) ... ok\ntest_single_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_sum_distinct_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_sum_duration_field (aggregation.tests.AggregateTestCase) ... ok\ntest_ticket11881 (aggregation.tests.AggregateTestCase) ... ok\ntest_ticket12886 (aggregation.tests.AggregateTestCase) ... ok\ntest_ticket17424 (aggregation.tests.AggregateTestCase) ... ok\ntest_values_aggregation (aggregation.tests.AggregateTestCase) ... ok\ntest_values_annotation_with_expression (aggregation.tests.AggregateTestCase) ... ok\n\n======================================================================\nFAIL: test_aggregation_random_ordering (aggregation.tests.AggregateTestCase)\nRandom() is not included in the GROUP BY when used for ordering.\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/aggregation/tests.py\", line 1332, in test_aggregation_random_ordering\n    ], lambda a: (a.name, a.contact_count), ordered=False)\n  File \"/testbed/django/test/testcases.py\", line 1046, in assertQuerysetEqual\n    return self.assertEqual(Counter(items), Counter(values), msg=msg)\nAssertionError: Counter({('Peter Norvig', 1): 2, ('Jacob Kaplan-Moss[182 chars]: 1}) != Counter({('Adrian Holovaty', 1): 1, ('Jacob Kaplan-M[182 chars]: 1})\n\n----------------------------------------------------------------------\nRan 68 tests in 0.274s\n\nFAILED (failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 aggregation.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/aggregation/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 68,
          "failed": 0,
          "errors": 0,
          "duration": 12.64,
          "log_tail": "test_annotate_values_list (aggregation.tests.AggregateTestCase) ... ok\ntest_annotated_aggregate_over_annotated_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_annotation (aggregation.tests.AggregateTestCase) ... ok\ntest_annotation_expressions (aggregation.tests.AggregateTestCase) ... ok\ntest_arguments_must_be_expressions (aggregation.tests.AggregateTestCase) ... ok\ntest_avg_decimal_field (aggregation.tests.AggregateTestCase) ... ok\ntest_avg_duration_field (aggregation.tests.AggregateTestCase) ... ok\ntest_backwards_m2m_annotate (aggregation.tests.AggregateTestCase) ... ok\ntest_combine_different_types (aggregation.tests.AggregateTestCase) ... ok\ntest_complex_aggregations_require_kwarg (aggregation.tests.AggregateTestCase) ... ok\ntest_complex_values_aggregation (aggregation.tests.AggregateTestCase) ... ok\ntest_count (aggregation.tests.AggregateTestCase) ... ok\ntest_count_distinct_expression (aggregation.tests.AggregateTestCase) ... ok\ntest_count_star (aggregation.tests.AggregateTestCase) ... ok\ntest_dates_with_aggregation (aggregation.tests.AggregateTestCase) ... ok\ntest_decimal_max_digits_has_no_effect (aggregation.tests.AggregateTestCase) ... ok\ntest_distinct_on_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_empty_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_even_more_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_expression_on_aggregation (aggregation.tests.AggregateTestCase) ... ok\ntest_filter_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_filtering (aggregation.tests.AggregateTestCase) ... ok\ntest_fkey_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_group_by_exists_annotation (aggregation.tests.AggregateTestCase) ... ok\ntest_group_by_subquery_annotation (aggregation.tests.AggregateTestCase) ... ok\ntest_grouped_annotation_in_group_by (aggregation.tests.AggregateTestCase) ... ok\ntest_more_aggregation (aggregation.tests.AggregateTestCase) ... ok\ntest_multi_arg_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_multiple_aggregates (aggregation.tests.AggregateTestCase) ... ok\ntest_non_grouped_annotation_not_in_group_by (aggregation.tests.AggregateTestCase) ... ok\ntest_nonaggregate_aggregation_throws (aggregation.tests.AggregateTestCase) ... ok\ntest_nonfield_annotation (aggregation.tests.AggregateTestCase) ... ok\ntest_order_of_precedence (aggregation.tests.AggregateTestCase) ... ok\ntest_related_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_reverse_fkey_annotate (aggregation.tests.AggregateTestCase) ... ok\ntest_single_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_sum_distinct_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_sum_duration_field (aggregation.tests.AggregateTestCase) ... ok\ntest_ticket11881 (aggregation.tests.AggregateTestCase) ... ok\ntest_ticket12886 (aggregation.tests.AggregateTestCase) ... ok\ntest_ticket17424 (aggregation.tests.AggregateTestCase) ... ok\ntest_values_aggregation (aggregation.tests.AggregateTestCase) ... ok\ntest_values_annotation_with_expression (aggregation.tests.AggregateTestCase) ... ok\n\n----------------------------------------------------------------------\nRan 68 tests in 0.239s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/aggregation/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-13590",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 36.43314003944397,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 148,
          "failed": 0,
          "errors": 1,
          "duration": 13.54,
          "log_tail": "======================================================================\nERROR: test_range_lookup_namedtuple (expressions.tests.IterableLookupInnerExpressionsTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/expressions/tests.py\", line 891, in test_range_lookup_namedtuple\n    num_employees__range=EmployeeRange(minimum=51, maximum=100),\n  File \"/testbed/django/db/models/manager.py\", line 85, in manager_method\n    return getattr(self.get_queryset(), name)(*args, **kwargs)\n  File \"/testbed/django/db/models/query.py\", line 937, in filter\n    return self._filter_or_exclude(False, args, kwargs)\n  File \"/testbed/django/db/models/query.py\", line 957, in _filter_or_exclude\n    clone._filter_or_exclude_inplace(negate, args, kwargs)\n  File \"/testbed/django/db/models/query.py\", line 964, in _filter_or_exclude_inplace\n    self._query.add_q(Q(*args, **kwargs))\n  File \"/testbed/django/db/models/sql/query.py\", line 1376, in add_q\n    clause, _ = self._add_q(q_object, self.used_aliases)\n  File \"/testbed/django/db/models/sql/query.py\", line 1398, in _add_q\n    split_subq=split_subq, check_filterable=check_filterable,\n  File \"/testbed/django/db/models/sql/query.py\", line 1278, in build_filter\n    value = self.resolve_lookup_value(value, can_reuse, allow_joins)\n  File \"/testbed/django/db/models/sql/query.py\", line 1082, in resolve_lookup_value\n    for sub_value in value\nTypeError: __new__() missing 1 required positional argument: 'maximum'\n\n----------------------------------------------------------------------\nRan 149 tests in 0.529s\n\nFAILED (errors=1, skipped=2)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 expressions.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/expressions/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 149,
          "failed": 0,
          "errors": 0,
          "duration": 12.99,
          "log_tail": "test_object_update_fk (expressions.tests.BasicExpressionsTests) ... ok\ntest_object_update_unsaved_objects (expressions.tests.BasicExpressionsTests) ... ok\ntest_order_by_exists (expressions.tests.BasicExpressionsTests) ... ok\ntest_order_by_multiline_sql (expressions.tests.BasicExpressionsTests) ... ok\ntest_order_of_operations (expressions.tests.BasicExpressionsTests) ... ok\ntest_outerref (expressions.tests.BasicExpressionsTests) ... ok\ntest_outerref_mixed_case_table_name (expressions.tests.BasicExpressionsTests) ... ok\ntest_outerref_with_operator (expressions.tests.BasicExpressionsTests) ... ok\ntest_parenthesis_priority (expressions.tests.BasicExpressionsTests) ... ok\ntest_pickle_expression (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_eq (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_filter_by_aggregate (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_filter_by_lazy (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_group_by_outerref_in_filter (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_in_filter (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_references_joined_table_twice (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_11722_iexact_lookup (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_16731_startswith_lookup (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_18375_chained_filters (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_18375_join_reuse (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_18375_kwarg_ordering (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_18375_kwarg_ordering_2 (expressions.tests.BasicExpressionsTests) ... ok\ntest_update (expressions.tests.BasicExpressionsTests) ... ok\ntest_update_inherited_field_value (expressions.tests.BasicExpressionsTests) ... ok\ntest_update_with_fk (expressions.tests.BasicExpressionsTests) ... ok\ntest_update_with_none (expressions.tests.BasicExpressionsTests) ... ok\ntest_uuid_pk_subquery (expressions.tests.BasicExpressionsTests) ... ok\n\n----------------------------------------------------------------------\nRan 149 tests in 0.501s\n\nOK (skipped=2)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/expressions/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-13658",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "django__django-13670",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 35.135154247283936,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 15,
          "failed": 3,
          "errors": 0,
          "duration": 12.56,
          "log_tail": "test_datetime_with_local_tzinfo (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_datetime_with_tzinfo (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_day_of_year_leap (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_empty_format (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_epoch (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_futuredates (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_invalid_time_format_specifiers (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_microsecond (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_naive_ambiguous_datetime (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_naive_datetime (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_r_format_with_non_en_locale (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_time_formats (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_timezones (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_year_before_1000 (utils_tests.test_dateformat.DateFormatTests) ... \n======================================================================\nFAIL: test_year_before_1000 (utils_tests.test_dateformat.DateFormatTests) (year=476)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/utils_tests/test_dateformat.py\", line 179, in test_year_before_1000\n    expected_date,\nAssertionError: '6' != '76'\n- 6\n+ 76\n? +\n\n\n======================================================================\nFAIL: test_year_before_1000 (utils_tests.test_dateformat.DateFormatTests) (year=42)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/utils_tests/test_dateformat.py\", line 179, in test_year_before_1000\n    expected_date,\nAssertionError: '' != '42'\n+ 42\n\n======================================================================\nFAIL: test_year_before_1000 (utils_tests.test_dateformat.DateFormatTests) (year=4)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/utils_tests/test_dateformat.py\", line 179, in test_year_before_1000\n    expected_date,\nAssertionError: '' != '04'\n+ 04\n\n----------------------------------------------------------------------\nRan 18 tests in 0.031s\n\nFAILED (failures=3)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 utils_tests.test_dateformat` failed. (See above for error)",
          "test_files_run": [
            "tests/utils_tests/test_dateformat.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 18,
          "failed": 0,
          "errors": 0,
          "duration": 12.48,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application utils_tests\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_am_pm (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_date (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_date_formats (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_dateformat (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_datetime_with_local_tzinfo (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_datetime_with_tzinfo (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_day_of_year_leap (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_empty_format (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_epoch (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_futuredates (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_invalid_time_format_specifiers (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_microsecond (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_naive_ambiguous_datetime (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_naive_datetime (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_r_format_with_non_en_locale (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_time_formats (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_timezones (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_year_before_1000 (utils_tests.test_dateformat.DateFormatTests) ... ok\n\n----------------------------------------------------------------------\nRan 18 tests in 0.028s\n\nOK\n",
          "test_files_run": [
            "tests/utils_tests/test_dateformat.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-13741",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 35.69807529449463,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 82,
          "failed": 1,
          "errors": 0,
          "duration": 12.68,
          "log_tail": "test_save_plaintext_email (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_unusable_password (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_user_email_domain_unicode_collision (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_user_email_domain_unicode_collision_nonexistent (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_user_email_unicode_collision (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_user_email_unicode_collision_nonexistent (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_bug_14242 (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_bug_17944_empty_password (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_bug_17944_unknown_password_algorithm (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_bug_17944_unmanageable_password (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_bug_19133 (auth_tests.test_forms.UserChangeFormTest)\nThe change form does not return the password value ... ok\ntest_bug_19349_bound_password_field (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_custom_form (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_password_excluded (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_unusable_password (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_username_field_autocapitalize_none (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_username_validity (auth_tests.test_forms.UserChangeFormTest) ... ok\n\n======================================================================\nFAIL: test_readonly_field_has_changed (auth_tests.test_forms.ReadOnlyPasswordHashTest)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/auth_tests/test_forms.py\", line 1025, in test_readonly_field_has_changed\n    self.assertIs(field.disabled, True)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1103, in assertIs\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: False is not True\n\n----------------------------------------------------------------------\nRan 83 tests in 0.350s\n\nFAILED (failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 auth_tests.test_forms` failed. (See above for error)",
          "test_files_run": [
            "tests/auth_tests/test_forms.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 83,
          "failed": 0,
          "errors": 0,
          "duration": 13.0,
          "log_tail": "test_unicode_username (auth_tests.test_forms.AuthenticationFormTest) ... ok\ntest_username_field_autocapitalize_none (auth_tests.test_forms.AuthenticationFormTest) ... ok\ntest_username_field_label (auth_tests.test_forms.AuthenticationFormTest) ... ok\ntest_username_field_label_empty_string (auth_tests.test_forms.AuthenticationFormTest) ... ok\ntest_username_field_label_not_set (auth_tests.test_forms.AuthenticationFormTest) ... ok\ntest_username_field_max_length_defaults_to_254 (auth_tests.test_forms.AuthenticationFormTest) ... ok\ntest_username_field_max_length_matches_user_model (auth_tests.test_forms.AuthenticationFormTest) ... ok\ntest_cleaned_data (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_custom_email_constructor (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_custom_email_field (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_custom_email_subject (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_html_autocomplete_attributes (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_inactive_user (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_invalid_email (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_nonexistent_email (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_preserve_username_case (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_save_html_email_template_name (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_save_plaintext_email (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_unusable_password (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_user_email_domain_unicode_collision (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_user_email_domain_unicode_collision_nonexistent (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_user_email_unicode_collision (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_user_email_unicode_collision_nonexistent (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_bug_14242 (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_bug_17944_empty_password (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_bug_17944_unknown_password_algorithm (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_bug_17944_unmanageable_password (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_bug_19133 (auth_tests.test_forms.UserChangeFormTest)\nThe change form does not return the password value ... ok\ntest_bug_19349_bound_password_field (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_custom_form (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_password_excluded (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_unusable_password (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_username_field_autocapitalize_none (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_username_validity (auth_tests.test_forms.UserChangeFormTest) ... ok\n\n----------------------------------------------------------------------\nRan 83 tests in 0.410s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/auth_tests/test_forms.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-13786",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 34.857155084609985,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 33,
          "failed": 1,
          "errors": 0,
          "duration": 12.41,
          "log_tail": "test_create_alter_unique_field (migrations.test_optimizer.OptimizerTests) ... ok\ntest_create_delete_model (migrations.test_optimizer.OptimizerTests) ... ok\ntest_create_model_add_field (migrations.test_optimizer.OptimizerTests) ... ok\ntest_create_model_add_field_not_through_m2m_through (migrations.test_optimizer.OptimizerTests) ... ok\ntest_create_model_alter_field (migrations.test_optimizer.OptimizerTests) ... ok\ntest_create_model_and_remove_model_options (migrations.test_optimizer.OptimizerTests) ... FAIL\ntest_create_model_no_reordering_for_unrelated_fk (migrations.test_optimizer.OptimizerTests) ... ok\ntest_create_model_no_reordering_of_inherited_model (migrations.test_optimizer.OptimizerTests) ... ok\ntest_create_model_remove_field (migrations.test_optimizer.OptimizerTests) ... ok\ntest_create_model_rename_field (migrations.test_optimizer.OptimizerTests) ... ok\ntest_create_model_reordering (migrations.test_optimizer.OptimizerTests) ... ok\ntest_create_model_reordering_circular_fk (migrations.test_optimizer.OptimizerTests) ... ok\ntest_create_rename_model (migrations.test_optimizer.OptimizerTests) ... ok\ntest_none_app_label (migrations.test_optimizer.OptimizerTests) ... ok\ntest_optimize_elidable_operation (migrations.test_optimizer.OptimizerTests) ... ok\ntest_optimize_through_create (migrations.test_optimizer.OptimizerTests) ... ok\ntest_optimize_through_fields (migrations.test_optimizer.OptimizerTests) ... ok\ntest_rename_model_self (migrations.test_optimizer.OptimizerTests) ... ok\ntest_single (migrations.test_optimizer.OptimizerTests) ... ok\n\n======================================================================\nFAIL: test_create_model_and_remove_model_options (migrations.test_optimizer.OptimizerTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/migrations/test_optimizer.py\", line 132, in test_create_model_and_remove_model_options\n    [migrations.CreateModel('MyModel', fields=[])],\n  File \"/testbed/tests/migrations/test_optimizer.py\", line 29, in assertOptimizesTo\n    self.assertEqual(expected, result)\nAssertionError: Lists differ: [\"mig[60 chars] ],\\n)\"] != [\"mig[60 chars] ],\\n    options={\\n        'verbose_name': 'M[17 chars]\\n)\"]\n\nFirst differing element 0:\n\"migr[59 chars] ],\\n)\"\n\"migr[59 chars] ],\\n    options={\\n        'verbose_name': 'M[16 chars],\\n)\"\n\n- [\"migrations.CreateModel(\\n    name='MyModel',\\n    fields=[\\n    ],\\n)\"]\n+ ['migrations.CreateModel(\\n'\n+  \"    name='MyModel',\\n\"\n+  '    fields=[\\n'\n+  '    ],\\n'\n+  '    options={\\n'\n+  \"        'verbose_name': 'My Model',\\n\"\n+  '    },\\n'\n+  ')']\n\n----------------------------------------------------------------------\nRan 34 tests in 0.053s\n\nFAILED (failures=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 migrations.test_optimizer` failed. (See above for error)",
          "test_files_run": [
            "tests/migrations/test_optimizer.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 34,
          "failed": 0,
          "errors": 0,
          "duration": 12.11,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application migrations\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_add_field_alter_field (migrations.test_optimizer.OptimizerTests) ... ok\ntest_add_field_delete_field (migrations.test_optimizer.OptimizerTests) ... ok\ntest_add_field_rename_field (migrations.test_optimizer.OptimizerTests) ... ok\ntest_alter_alter_index_model (migrations.test_optimizer.OptimizerTests) ... ok\ntest_alter_alter_owrt_model (migrations.test_optimizer.OptimizerTests) ... ok\ntest_alter_alter_table_model (migrations.test_optimizer.OptimizerTests) ... ok\ntest_alter_alter_unique_model (migrations.test_optimizer.OptimizerTests) ... ok\ntest_alter_field_delete_field (migrations.test_optimizer.OptimizerTests) ... ok\ntest_alter_field_rename_field (migrations.test_optimizer.OptimizerTests) ... ok\ntest_create_alter_index_delete_model (migrations.test_optimizer.OptimizerTests) ... ok\ntest_create_alter_index_field (migrations.test_optimizer.OptimizerTests) ... ok\ntest_create_alter_model_options (migrations.test_optimizer.OptimizerTests) ... ok\ntest_create_alter_owrt_delete_model (migrations.test_optimizer.OptimizerTests) ... ok\ntest_create_alter_owrt_field (migrations.test_optimizer.OptimizerTests) ... ok\ntest_create_alter_unique_delete_model (migrations.test_optimizer.OptimizerTests) ... ok\ntest_create_alter_unique_field (migrations.test_optimizer.OptimizerTests) ... ok\ntest_create_delete_model (migrations.test_optimizer.OptimizerTests) ... ok\ntest_create_model_add_field (migrations.test_optimizer.OptimizerTests) ... ok\ntest_create_model_add_field_not_through_m2m_through (migrations.test_optimizer.OptimizerTests) ... ok\ntest_create_model_alter_field (migrations.test_optimizer.OptimizerTests) ... ok\ntest_create_model_and_remove_model_options (migrations.test_optimizer.OptimizerTests) ... ok\ntest_create_model_no_reordering_for_unrelated_fk (migrations.test_optimizer.OptimizerTests) ... ok\ntest_create_model_no_reordering_of_inherited_model (migrations.test_optimizer.OptimizerTests) ... ok\ntest_create_model_remove_field (migrations.test_optimizer.OptimizerTests) ... ok\ntest_create_model_rename_field (migrations.test_optimizer.OptimizerTests) ... ok\ntest_create_model_reordering (migrations.test_optimizer.OptimizerTests) ... ok\ntest_create_model_reordering_circular_fk (migrations.test_optimizer.OptimizerTests) ... ok\ntest_create_rename_model (migrations.test_optimizer.OptimizerTests) ... ok\ntest_none_app_label (migrations.test_optimizer.OptimizerTests) ... ok\ntest_optimize_elidable_operation (migrations.test_optimizer.OptimizerTests) ... ok\ntest_optimize_through_create (migrations.test_optimizer.OptimizerTests) ... ok\ntest_optimize_through_fields (migrations.test_optimizer.OptimizerTests) ... ok\ntest_rename_model_self (migrations.test_optimizer.OptimizerTests) ... ok\ntest_single (migrations.test_optimizer.OptimizerTests) ... ok\n\n----------------------------------------------------------------------\nRan 34 tests in 0.049s\n\nOK\n",
          "test_files_run": [
            "tests/migrations/test_optimizer.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-13794",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 36.41861581802368,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 24,
          "failed": 2,
          "errors": 1,
          "duration": 12.83,
          "log_tail": "  File \"/testbed/tests/utils_tests/test_functional.py\", line 190, in test_lazy_add\n    self.assertEqual(lazy_4() + lazy_5(), 9)\nTypeError: unsupported operand type(s) for +: '__proxy__' and '__proxy__'\n\n======================================================================\nFAIL: test_add08 (template_tests.filter_tests.test_add.AddTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/django/test/utils.py\", line 382, in inner\n    return func(*args, **kwargs)\n  File \"/testbed/tests/template_tests/utils.py\", line 55, in inner\n    func(self)\n  File \"/testbed/tests/template_tests/filter_tests/test_add.py\", line 56, in test_add08\n    self.assertEqual(output, 'stringlazy')\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 822, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: '' != 'stringlazy'\n\n======================================================================\nFAIL: test_add09 (template_tests.filter_tests.test_add.AddTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/django/test/utils.py\", line 382, in inner\n    return func(*args, **kwargs)\n  File \"/testbed/tests/template_tests/utils.py\", line 55, in inner\n    func(self)\n  File \"/testbed/tests/template_tests/filter_tests/test_add.py\", line 64, in test_add09\n    self.assertEqual(output, 'stringlazy')\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 822, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: '' != 'stringlazy'\n\n----------------------------------------------------------------------\nRan 27 tests in 0.352s\n\nFAILED (failures=2, errors=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 template_tests.filter_tests.test_add utils_tests.test_functional` failed. (See above for error)",
          "test_files_run": [
            "tests/template_tests/filter_tests/test_add.py",
            "tests/utils_tests/test_functional.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 27,
          "failed": 0,
          "errors": 0,
          "duration": 12.34,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application utils_tests\nImporting application template_tests\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_add (template_tests.filter_tests.test_add.FunctionTests) ... ok\ntest_cached_property (utils_tests.test_functional.FunctionalTests)\ncached_property caches its value and behaves like a property. ... ok\ntest_cached_property_auto_name (utils_tests.test_functional.FunctionalTests) ... ok\ntest_cached_property_reuse_different_names (utils_tests.test_functional.FunctionalTests)\nDisallow this case because the decorated function wouldn't be cached. ... ok\ntest_cached_property_reuse_same_name (utils_tests.test_functional.FunctionalTests) ... ok\ntest_cached_property_set_name_not_called (utils_tests.test_functional.FunctionalTests) ... ok\ntest_classproperty_getter (utils_tests.test_functional.FunctionalTests) ... ok\ntest_classproperty_override_getter (utils_tests.test_functional.FunctionalTests) ... ok\ntest_lazy (utils_tests.test_functional.FunctionalTests) ... ok\ntest_lazy_add (utils_tests.test_functional.FunctionalTests) ... ok\ntest_lazy_base_class (utils_tests.test_functional.FunctionalTests)\nlazy also finds base class methods in the proxy object ... ok\ntest_lazy_base_class_override (utils_tests.test_functional.FunctionalTests)\nlazy finds the correct (overridden) method implementation ... ok\ntest_lazy_class_preparation_caching (utils_tests.test_functional.FunctionalTests) ... ok\ntest_lazy_equality (utils_tests.test_functional.FunctionalTests) ... ok\ntest_lazy_object_to_string (utils_tests.test_functional.FunctionalTests) ... ok\ntest_lazy_repr_bytes (utils_tests.test_functional.FunctionalTests) ... ok\ntest_lazy_repr_int (utils_tests.test_functional.FunctionalTests) ... ok\ntest_lazy_repr_text (utils_tests.test_functional.FunctionalTests) ... ok\ntest_add01 (template_tests.filter_tests.test_add.AddTests) ... ok\ntest_add02 (template_tests.filter_tests.test_add.AddTests) ... ok\ntest_add03 (template_tests.filter_tests.test_add.AddTests) ... ok\ntest_add04 (template_tests.filter_tests.test_add.AddTests) ... ok\ntest_add05 (template_tests.filter_tests.test_add.AddTests) ... ok\ntest_add06 (template_tests.filter_tests.test_add.AddTests) ... ok\ntest_add07 (template_tests.filter_tests.test_add.AddTests) ... ok\ntest_add08 (template_tests.filter_tests.test_add.AddTests) ... ok\ntest_add09 (template_tests.filter_tests.test_add.AddTests) ... ok\n\n----------------------------------------------------------------------\nRan 27 tests in 0.315s\n\nOK\n",
          "test_files_run": [
            "tests/template_tests/filter_tests/test_add.py",
            "tests/utils_tests/test_functional.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-13807",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 36.032045125961304,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 49,
          "failed": 0,
          "errors": 1,
          "duration": 12.85,
          "log_tail": "    return Database.Cursor.execute(self, query)\nsqlite3.OperationalError: near \"order\": syntax error\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/backends/tests.py\", line 636, in test_check_constraints_sql_keywords\n    connection.check_constraints(table_names=['order'])\n  File \"/testbed/django/db/backends/sqlite3/base.py\", line 334, in check_constraints\n    for table_name, rowid, referenced_table_name, foreign_key_index in violations:\n  File \"/testbed/django/db/backends/sqlite3/base.py\", line 331, in <genexpr>\n    for table_name in table_names\n  File \"/testbed/django/db/backends/utils.py\", line 66, in execute\n    return self._execute_with_wrappers(sql, params, many=False, executor=self._execute)\n  File \"/testbed/django/db/backends/utils.py\", line 75, in _execute_with_wrappers\n    return executor(sql, params, many, context)\n  File \"/testbed/django/db/backends/utils.py\", line 84, in _execute\n    return self.cursor.execute(sql, params)\n  File \"/testbed/django/db/utils.py\", line 91, in __exit__\n    raise dj_exc_value.with_traceback(traceback) from exc_value\n  File \"/testbed/django/db/backends/utils.py\", line 82, in _execute\n    return self.cursor.execute(sql)\n  File \"/testbed/django/db/backends/sqlite3/base.py\", line 414, in execute\n    return Database.Cursor.execute(self, query)\ndjango.db.utils.OperationalError: near \"order\": syntax error\n\n----------------------------------------------------------------------\nRan 50 tests in 0.443s\n\nFAILED (errors=1, skipped=9)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 backends.models backends.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/backends/models.py",
            "tests/backends/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 50,
          "failed": 0,
          "errors": 0,
          "duration": 12.64,
          "log_tail": "test_closing_non_shared_connections (backends.tests.ThreadTests) ... ok\ntest_connections_thread_local (backends.tests.ThreadTests) ... ok\ntest_default_connection_thread_local (backends.tests.ThreadTests) ... ok\ntest_pass_connection_between_threads (backends.tests.ThreadTests) ... ok\ntest_thread_sharing_count (backends.tests.ThreadTests) ... ok\ntest_check_constraints (backends.tests.FkConstraintsTests) ... ok\ntest_check_constraints_sql_keywords (backends.tests.FkConstraintsTests) ... ok\ntest_disable_constraint_checks_context_manager (backends.tests.FkConstraintsTests) ... ok\ntest_disable_constraint_checks_manually (backends.tests.FkConstraintsTests) ... ok\ntest_integrity_checks_on_creation (backends.tests.FkConstraintsTests) ... ok\ntest_integrity_checks_on_update (backends.tests.FkConstraintsTests) ... ok\ntest_cached_db_features (backends.tests.BackendTestCase) ... ok\ntest_cursor_contextmanager (backends.tests.BackendTestCase) ... ok\ntest_cursor_contextmanager_closing (backends.tests.BackendTestCase) ... skipped 'Psycopg2 specific cursor.closed attribute needed'\ntest_cursor_execute_with_pyformat (backends.tests.BackendTestCase) ... skipped \"Database doesn't support feature(s): supports_paramstyle_pyformat\"\ntest_cursor_executemany (backends.tests.BackendTestCase) ... ok\ntest_cursor_executemany_with_empty_params_list (backends.tests.BackendTestCase) ... ok\ntest_cursor_executemany_with_iterator (backends.tests.BackendTestCase) ... ok\ntest_cursor_executemany_with_pyformat (backends.tests.BackendTestCase) ... skipped \"Database doesn't support feature(s): supports_paramstyle_pyformat\"\ntest_cursor_executemany_with_pyformat_iterator (backends.tests.BackendTestCase) ... skipped \"Database doesn't support feature(s): supports_paramstyle_pyformat\"\ntest_database_operations_helper_class (backends.tests.BackendTestCase) ... ok\ntest_database_operations_init (backends.tests.BackendTestCase) ... ok\ntest_duplicate_table_error (backends.tests.BackendTestCase)\nCreating an existing table returns a DatabaseError ... ok\ntest_is_usable_after_database_disconnects (backends.tests.BackendTestCase) ... skipped \"Database doesn't support feature(s): test_db_allows_multiple_connections\"\ntest_queries (backends.tests.BackendTestCase) ... ok\ntest_queries_limit (backends.tests.BackendTestCase) ... skipped \"Database doesn't support feature(s): test_db_allows_multiple_connections\"\ntest_timezone_none_use_tz_false (backends.tests.BackendTestCase) ... ok\ntest_unicode_fetches (backends.tests.BackendTestCase) ... ok\ntest_unicode_password (backends.tests.BackendTestCase) ... ok\n\n----------------------------------------------------------------------\nRan 50 tests in 0.354s\n\nOK (skipped=9)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/backends/models.py",
            "tests/backends/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-13809",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 53.23007297515869,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 275,
          "failed": 0,
          "errors": 1,
          "duration": 20.01,
          "log_tail": "Ran 276 tests in 13.412s\n\nFAILED (errors=1, skipped=20)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 admin_scripts.tests utils_tests.test_autoreload` failed. (See above for error)",
          "test_files_run": [
            "tests/admin_scripts/tests.py",
            "tests/utils_tests/test_autoreload.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 276,
          "failed": 0,
          "errors": 0,
          "duration": 21.75,
          "log_tail": "----------------------------------------------------------------------\nRan 276 tests in 14.534s\n\nOK (skipped=20)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/admin_scripts/tests.py",
            "tests/utils_tests/test_autoreload.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-13810",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 36.638052225112915,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 32,
          "failed": 0,
          "errors": 1,
          "duration": 12.13,
          "log_tail": "test_process_view_return_response (middleware_exceptions.tests.MiddlewareTests) ... ok\ntest_response_from_process_exception_short_circuits_remainder (middleware_exceptions.tests.MiddlewareTests) ... ok\ntest_response_from_process_exception_when_return_response (middleware_exceptions.tests.MiddlewareTests) ... ok\ntest_templateresponse_from_process_view_passed_to_process_template_response (middleware_exceptions.tests.MiddlewareTests) ... ok\ntest_templateresponse_from_process_view_rendered (middleware_exceptions.tests.MiddlewareTests) ... ok\ntest_view_exception_converted_before_middleware (middleware_exceptions.tests.MiddlewareTests) ... ok\ntest_view_exception_handled_by_process_exception (middleware_exceptions.tests.MiddlewareTests) ... ok\ntest_exception_in_async_render_passed_to_process_exception (middleware_exceptions.tests.AsyncMiddlewareTests) ... ok\ntest_exception_in_render_passed_to_process_exception (middleware_exceptions.tests.AsyncMiddlewareTests) ... ok\ntest_process_template_response (middleware_exceptions.tests.AsyncMiddlewareTests) ... ok\ntest_process_template_response_returns_none (middleware_exceptions.tests.AsyncMiddlewareTests) ... ok\ntest_process_view_return_response (middleware_exceptions.tests.AsyncMiddlewareTests) ... ok\ntest_view_exception_handled_by_process_exception (middleware_exceptions.tests.AsyncMiddlewareTests) ... /opt/miniconda3/envs/testbed/lib/python3.6/site-packages/asgiref/sync.py:125: UserWarning: async_to_sync was passed a non-async-marked callable\n  warnings.warn(\"async_to_sync was passed a non-async-marked callable\")\nok\n\n======================================================================\nERROR: test_async_and_sync_middleware_chain_async_call (middleware_exceptions.tests.MiddlewareNotUsedTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/site-packages/asgiref/sync.py\", line 223, in __call__\n    return call_result.result()\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/concurrent/futures/_base.py\", line 425, in result\n    return self.__get_result()\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/concurrent/futures/_base.py\", line 384, in __get_result\n    raise self._exception\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/site-packages/asgiref/sync.py\", line 292, in main_wrap\n    result = await self.awaitable(*args, **kwargs)\n  File \"/testbed/django/test/utils.py\", line 375, in inner\n    return await func(*args, **kwargs)\n  File \"/testbed/tests/middleware_exceptions/tests.py\", line 190, in test_async_and_sync_middleware_chain_async_call\n    response = await self.async_client.get('/middleware_exceptions/view/')\n  File \"/testbed/django/test/client.py\", line 903, in request\n    response = await self.handler(scope)\n  File \"/testbed/django/test/client.py\", line 192, in __call__\n    response = await self.get_response_async(request)\n  File \"/testbed/django/core/handlers/base.py\", line 148, in get_response_async\n    response = await self._middleware_chain(request)\nTypeError: object HttpResponse can't be used in 'await' expression\n\n----------------------------------------------------------------------\nRan 33 tests in 0.459s\n\nFAILED (errors=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 middleware_exceptions.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/middleware_exceptions/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 33,
          "failed": 0,
          "errors": 0,
          "duration": 11.54,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application middleware_exceptions\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_missing_root_urlconf (middleware_exceptions.tests.RootUrlconfTests) ... ok\ntest_async_and_sync_middleware_chain_async_call (middleware_exceptions.tests.MiddlewareNotUsedTests) ... ok\ntest_do_not_log_when_debug_is_false (middleware_exceptions.tests.MiddlewareNotUsedTests) ... ok\ntest_log (middleware_exceptions.tests.MiddlewareNotUsedTests) ... ok\ntest_log_custom_message (middleware_exceptions.tests.MiddlewareNotUsedTests) ... ok\ntest_raise_exception (middleware_exceptions.tests.MiddlewareNotUsedTests) ... ok\ntest_async_and_sync_middleware_async_call (middleware_exceptions.tests.MiddlewareSyncAsyncTests) ... ok\ntest_async_and_sync_middleware_sync_call (middleware_exceptions.tests.MiddlewareSyncAsyncTests) ... ok\ntest_async_middleware (middleware_exceptions.tests.MiddlewareSyncAsyncTests) ... ok\ntest_async_middleware_async (middleware_exceptions.tests.MiddlewareSyncAsyncTests) ... ok\ntest_async_process_template_response_returns_none_with_sync_client (middleware_exceptions.tests.MiddlewareSyncAsyncTests) ... ok\ntest_not_sync_or_async_middleware (middleware_exceptions.tests.MiddlewareSyncAsyncTests) ... ok\ntest_sync_decorated_middleware (middleware_exceptions.tests.MiddlewareSyncAsyncTests) ... ok\ntest_sync_middleware (middleware_exceptions.tests.MiddlewareSyncAsyncTests) ... ok\ntest_sync_middleware_async (middleware_exceptions.tests.MiddlewareSyncAsyncTests) ... ok\ntest_exception_in_async_render_passed_to_process_exception (middleware_exceptions.tests.AsyncMiddlewareTests) ... ok\ntest_exception_in_render_passed_to_process_exception (middleware_exceptions.tests.AsyncMiddlewareTests) ... ok\ntest_process_template_response (middleware_exceptions.tests.AsyncMiddlewareTests) ... ok\ntest_process_template_response_returns_none (middleware_exceptions.tests.AsyncMiddlewareTests) ... ok\ntest_process_view_return_response (middleware_exceptions.tests.AsyncMiddlewareTests) ... ok\ntest_view_exception_handled_by_process_exception (middleware_exceptions.tests.AsyncMiddlewareTests) ... ok\ntest_exception_in_middleware_converted_before_prior_middleware (middleware_exceptions.tests.MiddlewareTests) ... ok\ntest_exception_in_render_passed_to_process_exception (middleware_exceptions.tests.MiddlewareTests) ... ok\ntest_process_template_response (middleware_exceptions.tests.MiddlewareTests) ... ok\ntest_process_template_response_returns_none (middleware_exceptions.tests.MiddlewareTests) ... ok\ntest_process_view_return_none (middleware_exceptions.tests.MiddlewareTests) ... ok\ntest_process_view_return_response (middleware_exceptions.tests.MiddlewareTests) ... ok\ntest_response_from_process_exception_short_circuits_remainder (middleware_exceptions.tests.MiddlewareTests) ... ok\ntest_response_from_process_exception_when_return_response (middleware_exceptions.tests.MiddlewareTests) ... ok\ntest_templateresponse_from_process_view_passed_to_process_template_response (middleware_exceptions.tests.MiddlewareTests) ... ok\ntest_templateresponse_from_process_view_rendered (middleware_exceptions.tests.MiddlewareTests) ... ok\ntest_view_exception_converted_before_middleware (middleware_exceptions.tests.MiddlewareTests) ... ok\ntest_view_exception_handled_by_process_exception (middleware_exceptions.tests.MiddlewareTests) ... /opt/miniconda3/envs/testbed/lib/python3.6/site-packages/asgiref/sync.py:125: UserWarning: async_to_sync was passed a non-async-marked callable\n  warnings.warn(\"async_to_sync was passed a non-async-marked callable\")\nok\n\n----------------------------------------------------------------------\nRan 33 tests in 0.369s\n\nOK\n",
          "test_files_run": [
            "tests/middleware_exceptions/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-13820",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 41.16099309921265,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 25,
          "failed": 1,
          "errors": 0,
          "duration": 13.02,
          "log_tail": "Tests loading a squashed migration ... ok\ntest_loading_squashed_complex (migrations.test_loader.LoaderTests)\nTests loading a complex set of squashed migrations ... ok\ntest_loading_squashed_complex_multi_apps (migrations.test_loader.LoaderTests) ... ok\ntest_loading_squashed_complex_multi_apps_partially_applied (migrations.test_loader.LoaderTests) ... ok\ntest_loading_squashed_erroneous (migrations.test_loader.LoaderTests)\nTests loading a complex but erroneous set of squashed migrations ... ok\ntest_loading_squashed_ref_squashed (migrations.test_loader.LoaderTests)\nTests loading a squashed migration with a new migration referencing it ... ok\ntest_marked_as_migrated (migrations.test_loader.LoaderTests) ... ok\ntest_marked_as_unmigrated (migrations.test_loader.LoaderTests) ... ok\ntest_name_match (migrations.test_loader.LoaderTests)\nTests prefix name matching ... ok\ntest_plan_handles_repeated_migrations (migrations.test_loader.LoaderTests) ... ok\ntest_run_before (migrations.test_loader.LoaderTests) ... ok\n\n======================================================================\nFAIL: test_loading_package_without__file__ (migrations.test_loader.LoaderTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/django/test/utils.py\", line 382, in inner\n    return func(*args, **kwargs)\n  File \"/testbed/tests/migrations/test_loader.py\", line 539, in test_loading_package_without__file__\n    self.assertCountEqual(migrations, ['0001_initial', '0002_second'])\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1183, in assertCountEqual\n    self.fail(msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: Element counts were not equal:\nFirst has 0, Second has 1:  '0001_initial'\nFirst has 0, Second has 1:  '0002_second'\n\n----------------------------------------------------------------------\nRan 26 tests in 0.764s\n\nFAILED (failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 migrations.test_loader` failed. (See above for error)",
          "test_files_run": [
            "tests/migrations/test_loader.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 26,
          "failed": 0,
          "errors": 0,
          "duration": 13.27,
          "log_tail": "Cloning test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nCloning test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nCloning test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\ntest_apply (migrations.test_loader.RecorderTests) ... ok\ntest_invalid (migrations.test_loader.PycLoaderTests) ... ok\ntest_valid (migrations.test_loader.PycLoaderTests) ... ok\ntest_check_consistent_history (migrations.test_loader.LoaderTests) ... ok\ntest_check_consistent_history_squashed (migrations.test_loader.LoaderTests) ... ok\ntest_explicit_missing_module (migrations.test_loader.LoaderTests) ... ok\ntest_first (migrations.test_loader.LoaderTests) ... ok\ntest_ignore_files (migrations.test_loader.LoaderTests)\nFiles prefixed with underscore, tilde, or dot aren't loaded. ... ok\ntest_load (migrations.test_loader.LoaderTests) ... ok\ntest_load_empty_dir (migrations.test_loader.LoaderTests) ... ok\ntest_load_import_error (migrations.test_loader.LoaderTests) ... ok\ntest_load_module_file (migrations.test_loader.LoaderTests) ... ok\ntest_load_unmigrated_dependency (migrations.test_loader.LoaderTests) ... ok\ntest_loading_namespace_package (migrations.test_loader.LoaderTests)\nMigration directories without an __init__.py file are ignored. ... ok\ntest_loading_package_without__file__ (migrations.test_loader.LoaderTests) ... ok\ntest_loading_squashed (migrations.test_loader.LoaderTests)\nTests loading a squashed migration ... ok\ntest_loading_squashed_complex (migrations.test_loader.LoaderTests)\nTests loading a complex set of squashed migrations ... ok\ntest_loading_squashed_complex_multi_apps (migrations.test_loader.LoaderTests) ... ok\ntest_loading_squashed_complex_multi_apps_partially_applied (migrations.test_loader.LoaderTests) ... ok\ntest_loading_squashed_erroneous (migrations.test_loader.LoaderTests)\nTests loading a complex but erroneous set of squashed migrations ... ok\ntest_loading_squashed_ref_squashed (migrations.test_loader.LoaderTests)\nTests loading a squashed migration with a new migration referencing it ... ok\ntest_marked_as_migrated (migrations.test_loader.LoaderTests) ... ok\ntest_marked_as_unmigrated (migrations.test_loader.LoaderTests) ... ok\ntest_name_match (migrations.test_loader.LoaderTests)\nTests prefix name matching ... ok\ntest_plan_handles_repeated_migrations (migrations.test_loader.LoaderTests) ... ok\ntest_run_before (migrations.test_loader.LoaderTests) ... ok\n\n----------------------------------------------------------------------\nRan 26 tests in 0.769s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/migrations/test_loader.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-13821",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 37.19112181663513,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 17,
          "failed": 1,
          "errors": 0,
          "duration": 12.2,
          "log_tail": "test_parameter_quoting (backends.sqlite.tests.LastExecutedQueryTest) ... ok\ntest_aggregation (backends.sqlite.tests.Tests)\nRaise NotSupportedError when aggregating on date/time fields. ... ok\ntest_check_sqlite_version (backends.sqlite.tests.Tests) ... FAIL\ntest_distinct_aggregation (backends.sqlite.tests.Tests) ... ok\ntest_distinct_aggregation_multiple_args_no_distinct (backends.sqlite.tests.Tests) ... ok\ntest_memory_db_test_name (backends.sqlite.tests.Tests)\nA named in-memory db should be allowed where supported. ... ok\ntest_pathlib_name (backends.sqlite.tests.Tests) ... ok\ntest_regexp_function (backends.sqlite.tests.Tests) ... ok\ntest_database_sharing_in_threads (backends.sqlite.tests.ThreadSharing) ... ok\ntest_autoincrement (backends.sqlite.tests.SchemaTests) ... ok\ntest_constraint_checks_disabled_atomic_allowed (backends.sqlite.tests.SchemaTests) ... ok\ntest_disable_constraint_checking_failure_disallowed (backends.sqlite.tests.SchemaTests) ... ok\ntest_field_rename_inside_atomic_block (backends.sqlite.tests.SchemaTests) ... skipped 'Database has feature(s) supports_atomic_references_rename'\ntest_table_rename_inside_atomic_block (backends.sqlite.tests.SchemaTests) ... skipped 'Database has feature(s) supports_atomic_references_rename'\n\n======================================================================\nFAIL: test_check_sqlite_version (backends.sqlite.tests.Tests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/backends/sqlite/tests.py\", line 37, in test_check_sqlite_version\n    check_sqlite_version()\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/contextlib.py\", line 88, in __exit__\n    next(self.gen)\n  File \"/testbed/django/test/testcases.py\", line 692, in _assert_raises_or_warns_cm\n    yield cm\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 203, in __exit__\n    self._raiseFailure(\"{} not raised\".format(exc_name))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 135, in _raiseFailure\n    raise self.test_case.failureException(msg)\nAssertionError: ImproperlyConfigured not raised\n\n----------------------------------------------------------------------\nRan 18 tests in 0.345s\n\nFAILED (failures=1, skipped=2)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 backends.sqlite.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/backends/sqlite/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 18,
          "failed": 0,
          "errors": 0,
          "duration": 12.04,
          "log_tail": "    Running deferred SQL...\nRunning migrations:\n  Applying admin.0001_initial... OK\n  Applying admin.0002_logentry_remove_auto_add... OK\n  Applying admin.0003_logentry_add_action_flag_choices... OK\n  Applying sites.0001_initial... OK\n  Applying sites.0002_alter_domain_unique... OK\nSystem check identified no issues (0 silenced).\n\n\nCreating test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\ntest_parameter_escaping (backends.sqlite.tests.EscapingChecks) ... ok\ntest_parameter_escaping (backends.sqlite.tests.EscapingChecksDebug) ... ok\ntest_large_number_of_parameters (backends.sqlite.tests.LastExecutedQueryTest) ... ok\ntest_no_interpolation (backends.sqlite.tests.LastExecutedQueryTest) ... ok\ntest_parameter_quoting (backends.sqlite.tests.LastExecutedQueryTest) ... ok\ntest_aggregation (backends.sqlite.tests.Tests)\nRaise NotSupportedError when aggregating on date/time fields. ... ok\ntest_check_sqlite_version (backends.sqlite.tests.Tests) ... ok\ntest_distinct_aggregation (backends.sqlite.tests.Tests) ... ok\ntest_distinct_aggregation_multiple_args_no_distinct (backends.sqlite.tests.Tests) ... ok\ntest_memory_db_test_name (backends.sqlite.tests.Tests)\nA named in-memory db should be allowed where supported. ... ok\ntest_pathlib_name (backends.sqlite.tests.Tests) ... ok\ntest_regexp_function (backends.sqlite.tests.Tests) ... ok\ntest_database_sharing_in_threads (backends.sqlite.tests.ThreadSharing) ... ok\ntest_autoincrement (backends.sqlite.tests.SchemaTests) ... ok\ntest_constraint_checks_disabled_atomic_allowed (backends.sqlite.tests.SchemaTests) ... ok\ntest_disable_constraint_checking_failure_disallowed (backends.sqlite.tests.SchemaTests) ... ok\ntest_field_rename_inside_atomic_block (backends.sqlite.tests.SchemaTests) ... skipped 'Database has feature(s) supports_atomic_references_rename'\ntest_table_rename_inside_atomic_block (backends.sqlite.tests.SchemaTests) ... skipped 'Database has feature(s) supports_atomic_references_rename'\n\n----------------------------------------------------------------------\nRan 18 tests in 0.308s\n\nOK (skipped=2)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/backends/sqlite/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-13837",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 36.610934019088745,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 77,
          "failed": 1,
          "errors": 0,
          "duration": 12.27,
          "log_tail": "test_path_with_embedded_null_bytes (utils_tests.test_autoreload.TestIterModulesAndFiles) ... ok\ntest_paths_are_pathlib_instances (utils_tests.test_autoreload.TestIterModulesAndFiles) ... ok\ntest_weakref_in_sys_module (utils_tests.test_autoreload.TestIterModulesAndFiles)\niter_all_python_module_file() ignores weakref modules. ... ok\ntest_zip_reload (utils_tests.test_autoreload.TestIterModulesAndFiles) ... ok\n\n======================================================================\nFAIL: test_run_as_non_django_module (utils_tests.test_autoreload.TestChildArguments)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/mock.py\", line 1602, in _inner\n    return f(*args, **kw)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/mock.py\", line 1183, in patched\n    return func(*args, **keywargs)\n  File \"/testbed/tests/utils_tests/test_autoreload.py\", line 176, in test_run_as_non_django_module\n    [sys.executable, '-m', 'utils_tests.test_module', 'runserver'],\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1028, in assertListEqual\n    self.assertSequenceEqual(list1, list2, msg, seq_type=list)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1010, in assertSequenceEqual\n    self.fail(msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: Lists differ: ['/op[35 chars]n', '/testbed/tests/utils_tests/test_module/__[19 chars]ver'] != ['/op[35 chars]n', '-m', 'utils_tests.test_module', 'runserver']\n\nFirst differing element 1:\n'/testbed/tests/utils_tests/test_module/__main__.py'\n'-m'\n\nSecond list contains 1 additional elements.\nFirst extra element 3:\n'runserver'\n\n  ['/opt/miniconda3/envs/testbed/bin/python',\n-  '/testbed/tests/utils_tests/test_module/__main__.py',\n+  '-m',\n+  'utils_tests.test_module',\n   'runserver']\n\n----------------------------------------------------------------------\nRan 78 tests in 0.685s\n\nFAILED (failures=1, skipped=20)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 utils_tests.test_autoreload utils_tests.test_module.__main__` failed. (See above for error)",
          "test_files_run": [
            "tests/utils_tests/test_autoreload.py",
            "tests/utils_tests/test_module/__main__.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 78,
          "failed": 0,
          "errors": 0,
          "duration": 11.66,
          "log_tail": "test_exe_fallback (utils_tests.test_autoreload.TestChildArguments) ... ok\ntest_raises_runtimeerror (utils_tests.test_autoreload.TestChildArguments) ... ok\ntest_run_as_module (utils_tests.test_autoreload.TestChildArguments) ... ok\ntest_run_as_non_django_module (utils_tests.test_autoreload.TestChildArguments) ... ok\ntest_warnoptions (utils_tests.test_autoreload.TestChildArguments) ... ok\ntest_sys_paths_absolute (utils_tests.test_autoreload.TestSysPathDirectories) ... ok\ntest_sys_paths_directories (utils_tests.test_autoreload.TestSysPathDirectories) ... ok\ntest_sys_paths_non_existing (utils_tests.test_autoreload.TestSysPathDirectories) ... ok\ntest_sys_paths_with_directories (utils_tests.test_autoreload.TestSysPathDirectories) ... ok\ntest_run_loop_catches_stopiteration (utils_tests.test_autoreload.BaseReloaderTests) ... ok\ntest_run_loop_stop_and_return (utils_tests.test_autoreload.BaseReloaderTests) ... ok\ntest_wait_for_apps_ready_checks_for_exception (utils_tests.test_autoreload.BaseReloaderTests) ... ok\ntest_wait_for_apps_ready_without_exception (utils_tests.test_autoreload.BaseReloaderTests) ... ok\ntest_watch_dir_with_unresolvable_path (utils_tests.test_autoreload.BaseReloaderTests) ... ok\ntest_watch_files_with_recursive_glob (utils_tests.test_autoreload.BaseReloaderTests) ... ok\ntest_watch_with_glob (utils_tests.test_autoreload.BaseReloaderTests) ... ok\ntest_check_errors_called (utils_tests.test_autoreload.StartDjangoTests) ... ok\ntest_echo_on_called (utils_tests.test_autoreload.StartDjangoTests) ... ok\ntest_starts_thread_with_args (utils_tests.test_autoreload.StartDjangoTests) ... ok\ntest_watchman_becomes_unavailable (utils_tests.test_autoreload.StartDjangoTests) ... ok\ntest_glob (utils_tests.test_autoreload.StatReloaderTests) ... ok\ntest_glob_recursive (utils_tests.test_autoreload.StatReloaderTests) ... ok\ntest_multiple_globs (utils_tests.test_autoreload.StatReloaderTests) ... ok\ntest_multiple_recursive_globs (utils_tests.test_autoreload.StatReloaderTests) ... ok\ntest_nested_glob_recursive (utils_tests.test_autoreload.StatReloaderTests) ... ok\ntest_overlapping_glob_recursive (utils_tests.test_autoreload.StatReloaderTests) ... ok\ntest_overlapping_globs (utils_tests.test_autoreload.StatReloaderTests) ... ok\ntest_snapshot_files_ignores_missing_files (utils_tests.test_autoreload.StatReloaderTests) ... ok\ntest_snapshot_files_updates (utils_tests.test_autoreload.StatReloaderTests) ... ok\ntest_snapshot_files_with_duplicates (utils_tests.test_autoreload.StatReloaderTests) ... ok\ntest_tick_does_not_trigger_twice (utils_tests.test_autoreload.StatReloaderTests) ... ok\ntest_bytecode_conversion_to_source (utils_tests.test_autoreload.TestIterModulesAndFiles)\n.pyc and .pyo files are included in the files list. ... ok\ntest_check_errors (utils_tests.test_autoreload.TestIterModulesAndFiles) ... ok\ntest_check_errors_catches_all_exceptions (utils_tests.test_autoreload.TestIterModulesAndFiles) ... ok\ntest_file_added (utils_tests.test_autoreload.TestIterModulesAndFiles) ... ok\ntest_main_module_is_resolved (utils_tests.test_autoreload.TestIterModulesAndFiles) ... ok\ntest_main_module_without_file_is_not_resolved (utils_tests.test_autoreload.TestIterModulesAndFiles) ... ok\ntest_module_without_spec (utils_tests.test_autoreload.TestIterModulesAndFiles) ... ok\ntest_path_with_embedded_null_bytes (utils_tests.test_autoreload.TestIterModulesAndFiles) ... ok\ntest_paths_are_pathlib_instances (utils_tests.test_autoreload.TestIterModulesAndFiles) ... ok\ntest_weakref_in_sys_module (utils_tests.test_autoreload.TestIterModulesAndFiles)\niter_all_python_module_file() ignores weakref modules. ... ok\ntest_zip_reload (utils_tests.test_autoreload.TestIterModulesAndFiles) ... ok\n\n----------------------------------------------------------------------\nRan 78 tests in 0.628s\n\nOK (skipped=20)\n",
          "test_files_run": [
            "tests/utils_tests/test_autoreload.py",
            "tests/utils_tests/test_module/__main__.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-13925",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 30.372283935546875,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 24,
          "failed": 2,
          "errors": 0,
          "duration": 8.27,
          "log_tail": "AssertionError: Lists differ: [<War[448 chars]042'>, <Warning: level=30, msg=\"Auto-created p[413 chars]42'>] != [<War[448 chars]042'>]\n\nFirst list contains 1 additional elements.\nFirst extra element 1:\n<Warning: level=30, msg=\"Auto-created primary key used when not defining a primary key type, by default 'django.db.models.AutoField'.\", hint=\"Configure the DEFAULT_AUTO_FIELD setting or the CheckDefaultPKConfig.default_auto_field attribute to point to a subclass of AutoField, e.g. 'django.db.models.BigAutoField'.\", obj=<class 'check_framework.test_model_checks.ModelDefaultAutoFieldTests.test_auto_created_inherited_pk.<locals>.Child'>, id='models.W042'>\n\nDiff is 2311 characters long. Set self.maxDiff to None to see it.\n\n======================================================================\nFAIL: test_explicit_inherited_pk (check_framework.test_model_checks.ModelDefaultAutoFieldTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 60, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 676, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 633, in _callTestMethod\n    method()\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/mock.py\", line 1325, in patched\n    return func(*newargs, **newkeywargs)\n  File \"/testbed/tests/check_framework/test_model_checks.py\", line 404, in test_explicit_inherited_pk\n    self.assertEqual(checks.run_checks(app_configs=self.apps.get_app_configs()), [])\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 912, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 1118, in assertListEqual\n    self.assertSequenceEqual(list1, list2, msg, seq_type=list)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 1100, in assertSequenceEqual\n    self.fail(msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 753, in fail\n    raise self.failureException(msg)\nAssertionError: Lists differ: [<Warning: level=30, msg=\"Auto-created pri[407 chars]42'>] != []\n\nFirst list contains 1 additional elements.\nFirst extra element 0:\n<Warning: level=30, msg=\"Auto-created primary key used when not defining a primary key type, by default 'django.db.models.AutoField'.\", hint=\"Configure the DEFAULT_AUTO_FIELD setting or the CheckDefaultPKConfig.default_auto_field attribute to point to a subclass of AutoField, e.g. 'django.db.models.BigAutoField'.\", obj=<class 'check_framework.test_model_checks.ModelDefaultAutoFieldTests.test_explicit_inherited_pk.<locals>.Child'>, id='models.W042'>\n\n- [<Warning: level=30, msg=\"Auto-created primary key used when not defining a primary key type, by default 'django.db.models.AutoField'.\", hint=\"Configure the DEFAULT_AUTO_FIELD setting or the CheckDefaultPKConfig.default_auto_field attribute to point to a subclass of AutoField, e.g. 'django.db.models.BigAutoField'.\", obj=<class 'check_framework.test_model_checks.ModelDefaultAutoFieldTests.test_explicit_inherited_pk.<locals>.Child'>, id='models.W042'>]\n+ []\n\n----------------------------------------------------------------------\nRan 26 tests in 0.314s\n\nFAILED (failures=2)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 check_framework.test_model_checks` failed. (See above for error)",
          "test_files_run": [
            "tests/check_framework/test_model_checks.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 26,
          "failed": 0,
          "errors": 0,
          "duration": 8.31,
          "log_tail": "  Applying admin.0001_initial... OK\n  Applying admin.0002_logentry_remove_auto_add... OK\n  Applying admin.0003_logentry_add_action_flag_choices... OK\n  Applying sites.0001_initial... OK\n  Applying sites.0002_alter_domain_unique... OK\nSystem check identified no issues (0 silenced).\n\n\nCreating test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\ntest_app_default_auto_field (check_framework.test_model_checks.ModelDefaultAutoFieldTests) ... ok\ntest_auto_created_inherited_parent_link (check_framework.test_model_checks.ModelDefaultAutoFieldTests) ... ok\ntest_auto_created_inherited_pk (check_framework.test_model_checks.ModelDefaultAutoFieldTests) ... ok\ntest_auto_created_pk (check_framework.test_model_checks.ModelDefaultAutoFieldTests) ... ok\ntest_default_auto_field_setting (check_framework.test_model_checks.ModelDefaultAutoFieldTests) ... ok\ntest_explicit_inherited_parent_link (check_framework.test_model_checks.ModelDefaultAutoFieldTests) ... ok\ntest_explicit_inherited_pk (check_framework.test_model_checks.ModelDefaultAutoFieldTests) ... ok\ntest_explicit_pk (check_framework.test_model_checks.ModelDefaultAutoFieldTests) ... ok\ntest_collision_abstract_model (check_framework.test_model_checks.ConstraintNameTests) ... ok\ntest_collision_across_apps (check_framework.test_model_checks.ConstraintNameTests) ... ok\ntest_collision_in_different_models (check_framework.test_model_checks.ConstraintNameTests) ... ok\ntest_collision_in_same_model (check_framework.test_model_checks.ConstraintNameTests) ... ok\ntest_no_collision_abstract_model_interpolation (check_framework.test_model_checks.ConstraintNameTests) ... ok\ntest_no_collision_across_apps_interpolation (check_framework.test_model_checks.ConstraintNameTests) ... ok\ntest_collision_abstract_model (check_framework.test_model_checks.IndexNameTests) ... ok\ntest_collision_across_apps (check_framework.test_model_checks.IndexNameTests) ... ok\ntest_collision_in_different_models (check_framework.test_model_checks.IndexNameTests) ... ok\ntest_collision_in_same_model (check_framework.test_model_checks.IndexNameTests) ... ok\ntest_no_collision_abstract_model_interpolation (check_framework.test_model_checks.IndexNameTests) ... ok\ntest_no_collision_across_apps_interpolation (check_framework.test_model_checks.IndexNameTests) ... ok\ntest_collision_across_apps (check_framework.test_model_checks.DuplicateDBTableTests) ... ok\ntest_collision_across_apps_database_routers_installed (check_framework.test_model_checks.DuplicateDBTableTests) ... ok\ntest_collision_in_same_app (check_framework.test_model_checks.DuplicateDBTableTests) ... ok\ntest_collision_in_same_app_database_routers_installed (check_framework.test_model_checks.DuplicateDBTableTests) ... ok\ntest_no_collision_for_proxy_models (check_framework.test_model_checks.DuplicateDBTableTests) ... ok\ntest_no_collision_for_unmanaged_models (check_framework.test_model_checks.DuplicateDBTableTests) ... ok\n\n----------------------------------------------------------------------\nRan 26 tests in 0.567s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/check_framework/test_model_checks.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-13933",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 30.182903051376343,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 19,
          "failed": 1,
          "errors": 0,
          "duration": 8.55,
          "log_tail": "test_regexfield (forms_tests.tests.test_error_messages.FormsErrorMessagesTestCase) ... ok\ntest_splitdatetimefield (forms_tests.tests.test_error_messages.FormsErrorMessagesTestCase) ... ok\ntest_subclassing_errorlist (forms_tests.tests.test_error_messages.FormsErrorMessagesTestCase) ... ok\ntest_timefield (forms_tests.tests.test_error_messages.FormsErrorMessagesTestCase) ... ok\ntest_urlfield (forms_tests.tests.test_error_messages.FormsErrorMessagesTestCase) ... ok\n\n======================================================================\nFAIL: test_modelchoicefield_value_placeholder (forms_tests.tests.test_error_messages.ModelChoiceFieldErrorMessagesTestCase)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 60, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 676, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 633, in _callTestMethod\n    method()\n  File \"/testbed/tests/forms_tests/tests/test_error_messages.py\", line 319, in test_modelchoicefield_value_placeholder\n    self.assertFormErrors(\n  File \"/testbed/tests/forms_tests/tests/test_error_messages.py\", line 21, in assertFormErrors\n    self.assertEqual(cm.exception.messages, expected)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 912, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 1118, in assertListEqual\n    self.assertSequenceEqual(list1, list2, msg, seq_type=list)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 1100, in assertSequenceEqual\n    self.fail(msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 753, in fail\n    raise self.failureException(msg)\nAssertionError: Lists differ: ['\"%(value)s\" is not one of the available choices.'] != ['\"invalid\" is not one of the available choices.']\n\nFirst differing element 0:\n'\"%(value)s\" is not one of the available choices.'\n'\"invalid\" is not one of the available choices.'\n\n- ['\"%(value)s\" is not one of the available choices.']\n?    ^^   ^^^^\n\n+ ['\"invalid\" is not one of the available choices.']\n?    ^^   ^^\n\n\n----------------------------------------------------------------------\nRan 20 tests in 0.316s\n\nFAILED (failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 forms_tests.tests.test_error_messages` failed. (See above for error)",
          "test_files_run": [
            "tests/forms_tests/tests/test_error_messages.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 20,
          "failed": 0,
          "errors": 0,
          "duration": 8.48,
          "log_tail": "    Creating table forms_tests_boundarymodel\n    Creating table forms_tests_defaults\n    Creating table forms_tests_choicemodel\n    Creating table forms_tests_choiceoptionmodel\n    Creating table forms_tests_choicefieldmodel\n    Creating table forms_tests_optionalmultichoicemodel\n    Creating table forms_tests_filemodel\n    Creating table forms_tests_article\n    Running deferred SQL...\nRunning migrations:\n  Applying admin.0001_initial... OK\n  Applying admin.0002_logentry_remove_auto_add... OK\n  Applying admin.0003_logentry_add_action_flag_choices... OK\n  Applying sites.0001_initial... OK\n  Applying sites.0002_alter_domain_unique... OK\nSystem check identified no issues (0 silenced).\n\n\nCreating test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\ntest_modelchoicefield (forms_tests.tests.test_error_messages.ModelChoiceFieldErrorMessagesTestCase) ... ok\ntest_modelchoicefield_value_placeholder (forms_tests.tests.test_error_messages.ModelChoiceFieldErrorMessagesTestCase) ... ok\ntest_booleanfield (forms_tests.tests.test_error_messages.FormsErrorMessagesTestCase) ... ok\ntest_charfield (forms_tests.tests.test_error_messages.FormsErrorMessagesTestCase) ... ok\ntest_choicefield (forms_tests.tests.test_error_messages.FormsErrorMessagesTestCase) ... ok\ntest_datefield (forms_tests.tests.test_error_messages.FormsErrorMessagesTestCase) ... ok\ntest_datetimefield (forms_tests.tests.test_error_messages.FormsErrorMessagesTestCase) ... ok\ntest_decimalfield (forms_tests.tests.test_error_messages.FormsErrorMessagesTestCase) ... ok\ntest_emailfield (forms_tests.tests.test_error_messages.FormsErrorMessagesTestCase) ... ok\ntest_error_messages_escaping (forms_tests.tests.test_error_messages.FormsErrorMessagesTestCase) ... ok\ntest_filefield (forms_tests.tests.test_error_messages.FormsErrorMessagesTestCase) ... ok\ntest_floatfield (forms_tests.tests.test_error_messages.FormsErrorMessagesTestCase) ... ok\ntest_generic_ipaddressfield (forms_tests.tests.test_error_messages.FormsErrorMessagesTestCase) ... ok\ntest_integerfield (forms_tests.tests.test_error_messages.FormsErrorMessagesTestCase) ... ok\ntest_multiplechoicefield (forms_tests.tests.test_error_messages.FormsErrorMessagesTestCase) ... ok\ntest_regexfield (forms_tests.tests.test_error_messages.FormsErrorMessagesTestCase) ... ok\ntest_splitdatetimefield (forms_tests.tests.test_error_messages.FormsErrorMessagesTestCase) ... ok\ntest_subclassing_errorlist (forms_tests.tests.test_error_messages.FormsErrorMessagesTestCase) ... ok\ntest_timefield (forms_tests.tests.test_error_messages.FormsErrorMessagesTestCase) ... ok\ntest_urlfield (forms_tests.tests.test_error_messages.FormsErrorMessagesTestCase) ... ok\n\n----------------------------------------------------------------------\nRan 20 tests in 0.602s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/forms_tests/tests/test_error_messages.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-13964",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 30.15652108192444,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 35,
          "failed": 0,
          "errors": 2,
          "duration": 8.78,
          "log_tail": "test_select_related (many_to_one.tests.ManyToOneTests) ... ok\ntest_selects (many_to_one.tests.ManyToOneTests) ... ok\ntest_set (many_to_one.tests.ManyToOneTests) ... ok\ntest_set_after_prefetch (many_to_one.tests.ManyToOneTests) ... ok\ntest_values_list_exception (many_to_one.tests.ManyToOneTests) ... ok\n\n======================================================================\nERROR: test_save_fk_after_parent_with_non_numeric_pk_set_on_child (many_to_one.tests.ManyToOneTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/django/db/models/fields/related_descriptors.py\", line 173, in __get__\n    rel_obj = self.field.get_cached_value(instance)\n  File \"/testbed/django/db/models/fields/mixins.py\", line 15, in get_cached_value\n    return instance._state.fields_cache[cache_name]\nKeyError: 'parent'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/testbed/tests/many_to_one/tests.py\", line 559, in test_save_fk_after_parent_with_non_numeric_pk_set_on_child\n    self.assertEqual(child.parent, parent)\n  File \"/testbed/django/db/models/fields/related_descriptors.py\", line 187, in __get__\n    rel_obj = self.get_object(instance)\n  File \"/testbed/django/db/models/fields/related_descriptors.py\", line 154, in get_object\n    return qs.get(self.field.get_reverse_related_filter(instance))\n  File \"/testbed/django/db/models/query.py\", line 435, in get\n    raise self.model.DoesNotExist(\nmany_to_one.models.ParentStringPrimaryKey.DoesNotExist: ParentStringPrimaryKey matching query does not exist.\n\n======================================================================\nERROR: test_save_fk_after_parent_with_non_numeric_pk_set_on_child (many_to_one.tests.ManyToOneTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/django/test/testcases.py\", line 284, in _setup_and_call\n    self._post_teardown()\n  File \"/testbed/django/test/testcases.py\", line 1006, in _post_teardown\n    self._fixture_teardown()\n  File \"/testbed/django/test/testcases.py\", line 1247, in _fixture_teardown\n    connections[db_name].check_constraints()\n  File \"/testbed/django/db/backends/sqlite3/base.py\", line 352, in check_constraints\n    raise IntegrityError(\ndjango.db.utils.IntegrityError: The row in table 'many_to_one_childstringprimarykeyparent' with primary key '1' has an invalid foreign key: many_to_one_childstringprimarykeyparent.parent_id contains a value '' that does not have a corresponding value in many_to_one_parentstringprimarykey.name.\n\n----------------------------------------------------------------------\nRan 37 tests in 0.164s\n\nFAILED (errors=2)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 many_to_one.models many_to_one.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/many_to_one/models.py",
            "tests/many_to_one/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 37,
          "failed": 0,
          "errors": 0,
          "duration": 8.11,
          "log_tail": "  Applying sites.0002_alter_domain_unique... OK\nSystem check identified no issues (0 silenced).\n\n\nCreating test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\ntest_add (many_to_one.tests.ManyToOneTests) ... ok\ntest_add_after_prefetch (many_to_one.tests.ManyToOneTests) ... ok\ntest_add_remove_set_by_pk_raises (many_to_one.tests.ManyToOneTests) ... ok\ntest_add_then_remove_after_prefetch (many_to_one.tests.ManyToOneTests) ... ok\ntest_assign (many_to_one.tests.ManyToOneTests) ... ok\ntest_assign_fk_id_none (many_to_one.tests.ManyToOneTests) ... ok\ntest_assign_fk_id_value (many_to_one.tests.ManyToOneTests) ... ok\ntest_cached_foreign_key_with_to_field_not_cleared_by_save (many_to_one.tests.ManyToOneTests) ... ok\ntest_cached_relation_invalidated_on_save (many_to_one.tests.ManyToOneTests)\nModel.save() invalidates stale ForeignKey relations after a primary key ... ok\ntest_clear_after_prefetch (many_to_one.tests.ManyToOneTests) ... ok\ntest_create (many_to_one.tests.ManyToOneTests) ... ok\ntest_create_relation_with_gettext_lazy (many_to_one.tests.ManyToOneTests) ... ok\ntest_deepcopy_and_circular_references (many_to_one.tests.ManyToOneTests) ... ok\ntest_delete (many_to_one.tests.ManyToOneTests) ... ok\ntest_explicit_fk (many_to_one.tests.ManyToOneTests) ... ok\ntest_fk_assignment_and_related_object_cache (many_to_one.tests.ManyToOneTests) ... ok\ntest_fk_instantiation_outside_model (many_to_one.tests.ManyToOneTests) ... ok\ntest_fk_to_bigautofield (many_to_one.tests.ManyToOneTests) ... ok\ntest_fk_to_smallautofield (many_to_one.tests.ManyToOneTests) ... ok\ntest_get (many_to_one.tests.ManyToOneTests) ... ok\ntest_hasattr_related_object (many_to_one.tests.ManyToOneTests) ... ok\ntest_manager_class_caching (many_to_one.tests.ManyToOneTests) ... ok\ntest_multiple_foreignkeys (many_to_one.tests.ManyToOneTests) ... ok\ntest_related_object (many_to_one.tests.ManyToOneTests) ... ok\ntest_relation_unsaved (many_to_one.tests.ManyToOneTests) ... ok\ntest_remove_after_prefetch (many_to_one.tests.ManyToOneTests) ... ok\ntest_reverse_assignment_deprecation (many_to_one.tests.ManyToOneTests) ... ok\ntest_reverse_foreign_key_instance_to_field_caching (many_to_one.tests.ManyToOneTests) ... ok\ntest_reverse_selects (many_to_one.tests.ManyToOneTests) ... ok\ntest_save_fk_after_parent_with_non_numeric_pk_set_on_child (many_to_one.tests.ManyToOneTests) ... ok\ntest_save_nullable_fk_after_parent (many_to_one.tests.ManyToOneTests) ... ok\ntest_save_nullable_fk_after_parent_with_to_field (many_to_one.tests.ManyToOneTests) ... ok\ntest_select_related (many_to_one.tests.ManyToOneTests) ... ok\ntest_selects (many_to_one.tests.ManyToOneTests) ... ok\ntest_set (many_to_one.tests.ManyToOneTests) ... ok\ntest_set_after_prefetch (many_to_one.tests.ManyToOneTests) ... ok\ntest_values_list_exception (many_to_one.tests.ManyToOneTests) ... ok\n\n----------------------------------------------------------------------\nRan 37 tests in 0.191s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/many_to_one/models.py",
            "tests/many_to_one/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-14007",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 31.26418375968933,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 14,
          "failed": 1,
          "errors": 0,
          "duration": 8.72,
          "log_tail": "test_auto_field_subclass_create (custom_pk.tests.CustomPKTests) ... FAIL\ntest_custom_field_pk (custom_pk.tests.CustomPKTests) ... ok\ntest_custom_pk_create (custom_pk.tests.CustomPKTests)\nNew objects can be created both with pk and the custom name ... ok\ntest_required_pk (custom_pk.tests.CustomPKTests) ... skipped 'Database has feature(s) supports_unspecified_pk'\ntest_unicode_pk (custom_pk.tests.CustomPKTests) ... ok\ntest_unique_pk (custom_pk.tests.CustomPKTests) ... ok\ntest_zero_non_autoincrement_pk (custom_pk.tests.CustomPKTests) ... ok\ntest_get (custom_pk.tests.BasicCustomPKTests)\nGet can accept pk or the real attribute name ... ok\ntest_in_bulk (custom_pk.tests.BasicCustomPKTests)\nCustom pks work with in_bulk, both for integer and non-integer types ... ok\ntest_pk_attributes (custom_pk.tests.BasicCustomPKTests)\npk and attribute name are available on the model ... ok\ntest_querysets (custom_pk.tests.BasicCustomPKTests)\nBoth pk and custom attribute_name can be used in filter and friends ... ok\ntest_querysets_related_name (custom_pk.tests.BasicCustomPKTests)\nCustom pk doesn't affect related_name based lookups ... ok\ntest_querysets_relational (custom_pk.tests.BasicCustomPKTests)\nQueries across tables, involving primary key ... ok\ntest_save (custom_pk.tests.BasicCustomPKTests)\ncustom pks do not affect save ... ok\n\n======================================================================\nFAIL: test_auto_field_subclass_create (custom_pk.tests.CustomPKTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 60, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 676, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 633, in _callTestMethod\n    method()\n  File \"/testbed/tests/custom_pk/tests.py\", line 237, in test_auto_field_subclass_create\n    self.assertIsInstance(obj.id, MyWrapper)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 1335, in assertIsInstance\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 753, in fail\n    raise self.failureException(msg)\nAssertionError: 1 is not an instance of <class 'custom_pk.fields.MyWrapper'>\n\n----------------------------------------------------------------------\nRan 15 tests in 0.322s\n\nFAILED (failures=1, skipped=2)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 custom_pk.fields custom_pk.models custom_pk.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/custom_pk/fields.py",
            "tests/custom_pk/models.py",
            "tests/custom_pk/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 15,
          "failed": 0,
          "errors": 0,
          "duration": 8.14,
          "log_tail": "    Creating table custom_pk_employee\n    Creating table custom_pk_business\n    Creating table custom_pk_bar\n    Creating table custom_pk_foo\n    Creating table custom_pk_customautofieldmodel\n    Running deferred SQL...\nRunning migrations:\n  Applying admin.0001_initial... OK\n  Applying admin.0002_logentry_remove_auto_add... OK\n  Applying admin.0003_logentry_add_action_flag_choices... OK\n  Applying sites.0001_initial... OK\n  Applying sites.0002_alter_domain_unique... OK\nSystem check identified no issues (0 silenced).\n\n\nCreating test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\ntest_auto_field_subclass_bulk_create (custom_pk.tests.CustomPKTests) ... skipped \"Database doesn't support feature(s): can_return_rows_from_bulk_insert\"\ntest_auto_field_subclass_create (custom_pk.tests.CustomPKTests) ... ok\ntest_custom_field_pk (custom_pk.tests.CustomPKTests) ... ok\ntest_custom_pk_create (custom_pk.tests.CustomPKTests)\nNew objects can be created both with pk and the custom name ... ok\ntest_required_pk (custom_pk.tests.CustomPKTests) ... skipped 'Database has feature(s) supports_unspecified_pk'\ntest_unicode_pk (custom_pk.tests.CustomPKTests) ... ok\ntest_unique_pk (custom_pk.tests.CustomPKTests) ... ok\ntest_zero_non_autoincrement_pk (custom_pk.tests.CustomPKTests) ... ok\ntest_get (custom_pk.tests.BasicCustomPKTests)\nGet can accept pk or the real attribute name ... ok\ntest_in_bulk (custom_pk.tests.BasicCustomPKTests)\nCustom pks work with in_bulk, both for integer and non-integer types ... ok\ntest_pk_attributes (custom_pk.tests.BasicCustomPKTests)\npk and attribute name are available on the model ... ok\ntest_querysets (custom_pk.tests.BasicCustomPKTests)\nBoth pk and custom attribute_name can be used in filter and friends ... ok\ntest_querysets_related_name (custom_pk.tests.BasicCustomPKTests)\nCustom pk doesn't affect related_name based lookups ... ok\ntest_querysets_relational (custom_pk.tests.BasicCustomPKTests)\nQueries across tables, involving primary key ... ok\ntest_save (custom_pk.tests.BasicCustomPKTests)\ncustom pks do not affect save ... ok\n\n----------------------------------------------------------------------\nRan 15 tests in 0.296s\n\nOK (skipped=2)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/custom_pk/fields.py",
            "tests/custom_pk/models.py",
            "tests/custom_pk/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-14011",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 31.16825294494629,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": -4,
          "failed": 0,
          "errors": 6,
          "duration": 8.71,
          "log_tail": "======================================================================\nERROR: test_specified_port_bind (servers.tests.LiveServerPort)\nLiveServerTestCase.port customizes the server's port.\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/suite.py\", line 163, in _handleClassSetUp\n    setUpClass()\n  File \"/testbed/django/test/testcases.py\", line 1589, in setUpClass\n    raise cls.server_thread.error\n  File \"/testbed/django/test/testcases.py\", line 1503, in run\n    self.httpd = self._create_server()\n  File \"/testbed/django/test/testcases.py\", line 1517, in _create_server\n    return self.server_class(\n  File \"/testbed/django/core/servers/basehttp.py\", line 71, in __init__\n    super().__init__(*args, **kwargs)\nTypeError: __init__() got an unexpected keyword argument 'connections_override'\n\n======================================================================\nERROR: test_live_server_url_is_class_property (servers.tests.LiveServerAddress)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/suite.py\", line 163, in _handleClassSetUp\n    setUpClass()\n  File \"/testbed/tests/servers/tests.py\", line 150, in setUpClass\n    super().setUpClass()\n  File \"/testbed/django/test/testcases.py\", line 1589, in setUpClass\n    raise cls.server_thread.error\n  File \"/testbed/django/test/testcases.py\", line 1503, in run\n    self.httpd = self._create_server()\n  File \"/testbed/django/test/testcases.py\", line 1517, in _create_server\n    return self.server_class(\n  File \"/testbed/django/core/servers/basehttp.py\", line 71, in __init__\n    super().__init__(*args, **kwargs)\nTypeError: __init__() got an unexpected keyword argument 'connections_override'\n\n----------------------------------------------------------------------\nRan 2 tests in 0.941s\n\nFAILED (errors=6)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 django.test.testcases servers.tests` failed. (See above for error)",
          "test_files_run": [
            "django/test/testcases.py",
            "tests/servers/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 20,
          "failed": 0,
          "errors": 0,
          "duration": 9.33,
          "log_tail": "Cloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\ntest_set_up_class (servers.tests.LiveServerTestCaseSetupTest) ... ok\ntest_live_server_url_is_class_property (servers.tests.LiveServerAddress) ... ok\ntest_closes_connections (servers.tests.LiveServerTestCloseConnectionTest) ... skipped \"the sqlite backend's close() method is a no-op when using an in-memory database\"\ntest_closes_connection_with_content_length (servers.tests.SingleTreadLiveServerViews)\nContrast to ... ok\ntest_database_writes (servers.tests.LiveServerDatabase)\nData written to the database by a view can be read. ... ok\ntest_fixtures_loaded (servers.tests.LiveServerDatabase)\nFixtures are properly loaded and visible to the live server thread. ... ok\ntest_check_model_instance_from_subview (servers.tests.LiveServerThreadedTests) ... ok\ntest_view_calls_subview (servers.tests.LiveServerThreadedTests) ... ok\ntest_404 (servers.tests.LiveServerViews) ... ok\ntest_closes_connection_without_content_length (servers.tests.LiveServerViews)\nA HTTP 1.1 server is supposed to support keep-alive. Since our ... ok\ntest_environ (servers.tests.LiveServerViews) ... ok\ntest_keep_alive_connection_clears_previous_request_data (servers.tests.LiveServerViews) ... ok\ntest_keep_alive_on_connection_with_content_length (servers.tests.LiveServerViews)\nSee `test_closes_connection_without_content_length` for details. This ... ok\ntest_media_files (servers.tests.LiveServerViews) ... ok\ntest_no_collectstatic_emulation (servers.tests.LiveServerViews)\nLiveServerTestCase reports a 404 status code when HTTP client ... ok\ntest_protocol (servers.tests.LiveServerViews)\nLaunched server serves with HTTP 1.1. ... ok\ntest_static_files (servers.tests.LiveServerViews) ... ok\ntest_view (servers.tests.LiveServerViews) ... ok\ntest_port_bind (servers.tests.LiveServerPort)\nEach LiveServerTestCase binds to a unique port or fails to start a ... ok\ntest_specified_port_bind (servers.tests.LiveServerPort)\nLiveServerTestCase.port customizes the server's port. ... ok\n\n----------------------------------------------------------------------\nRan 20 tests in 2.026s\n\nOK (skipped=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "django/test/testcases.py",
            "tests/servers/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-14017",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 30.11988663673401,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 150,
          "failed": 0,
          "errors": 2,
          "duration": 8.53,
          "log_tail": "  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 633, in _callTestMethod\n    method()\n  File \"/testbed/tests/expressions/tests.py\", line 819, in test_boolean_expression_combined\n    Employee.objects.filter(Q(salary__gte=30) & Exists(is_ceo)),\n  File \"/testbed/django/db/models/query_utils.py\", line 65, in __and__\n    return self._combine(other, self.AND)\n  File \"/testbed/django/db/models/query_utils.py\", line 44, in _combine\n    raise TypeError(other)\nTypeError: <django.db.models.expressions.Exists object at 0x706ecb8a5ca0>\n\n======================================================================\nERROR: test_boolean_expression_combined_with_empty_Q (expressions.tests.BasicExpressionsTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 60, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 676, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 633, in _callTestMethod\n    method()\n  File \"/testbed/tests/expressions/tests.py\", line 833, in test_boolean_expression_combined_with_empty_Q\n    Q() & Exists(is_poc),\n  File \"/testbed/django/db/models/query_utils.py\", line 65, in __and__\n    return self._combine(other, self.AND)\n  File \"/testbed/django/db/models/query_utils.py\", line 44, in _combine\n    raise TypeError(other)\nTypeError: <django.db.models.expressions.Exists object at 0x706ecb8be730>\n\n----------------------------------------------------------------------\nRan 152 tests in 0.448s\n\nFAILED (errors=2, skipped=2)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 expressions.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/expressions/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 152,
          "failed": 0,
          "errors": 0,
          "duration": 8.3,
          "log_tail": "test_update_inherited_field_value (expressions.tests.BasicExpressionsTests) ... ok\ntest_update_with_fk (expressions.tests.BasicExpressionsTests) ... ok\ntest_update_with_none (expressions.tests.BasicExpressionsTests) ... ok\ntest_uuid_pk_subquery (expressions.tests.BasicExpressionsTests) ... ok\ntest_date_case_subtraction (expressions.tests.FTimeDeltaTests) ... ok\ntest_date_comparison (expressions.tests.FTimeDeltaTests) ... ok\ntest_date_minus_duration (expressions.tests.FTimeDeltaTests) ... ok\ntest_date_subquery_subtraction (expressions.tests.FTimeDeltaTests) ... ok\ntest_date_subtraction (expressions.tests.FTimeDeltaTests) ... ok\ntest_datetime_subquery_subtraction (expressions.tests.FTimeDeltaTests) ... ok\ntest_datetime_subtraction (expressions.tests.FTimeDeltaTests) ... ok\ntest_datetime_subtraction_microseconds (expressions.tests.FTimeDeltaTests) ... ok\ntest_delta_add (expressions.tests.FTimeDeltaTests) ... ok\ntest_delta_subtract (expressions.tests.FTimeDeltaTests) ... ok\ntest_delta_update (expressions.tests.FTimeDeltaTests) ... ok\ntest_duration_expressions (expressions.tests.FTimeDeltaTests) ... ok\ntest_duration_with_datetime (expressions.tests.FTimeDeltaTests) ... ok\ntest_duration_with_datetime_microseconds (expressions.tests.FTimeDeltaTests) ... ok\ntest_durationfield_add (expressions.tests.FTimeDeltaTests) ... ok\ntest_exclude (expressions.tests.FTimeDeltaTests) ... ok\ntest_invalid_operator (expressions.tests.FTimeDeltaTests) ... ok\ntest_mixed_comparisons1 (expressions.tests.FTimeDeltaTests) ... skipped \"Database doesn't support feature(s): supports_mixed_date_datetime_comparisons\"\ntest_mixed_comparisons2 (expressions.tests.FTimeDeltaTests) ... ok\ntest_multiple_query_compilation (expressions.tests.FTimeDeltaTests) ... ok\ntest_negative_timedelta_update (expressions.tests.FTimeDeltaTests) ... ok\ntest_query_clone (expressions.tests.FTimeDeltaTests) ... ok\ntest_time_subquery_subtraction (expressions.tests.FTimeDeltaTests) ... ok\ntest_time_subtraction (expressions.tests.FTimeDeltaTests) ... ok\n\n----------------------------------------------------------------------\nRan 152 tests in 0.606s\n\nOK (skipped=2)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/expressions/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-14034",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 28.83347201347351,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 12,
          "failed": 1,
          "errors": 0,
          "duration": 7.55,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application forms_tests\nFound 13 test(s).\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_bad_choice (forms_tests.field_tests.test_multivaluefield.MultiValueFieldTest) ... ok\ntest_clean (forms_tests.field_tests.test_multivaluefield.MultiValueFieldTest) ... ok\ntest_clean_disabled_multivalue (forms_tests.field_tests.test_multivaluefield.MultiValueFieldTest) ... ok\ntest_disabled_has_changed (forms_tests.field_tests.test_multivaluefield.MultiValueFieldTest) ... ok\ntest_form_as_table (forms_tests.field_tests.test_multivaluefield.MultiValueFieldTest) ... ok\ntest_form_as_table_data (forms_tests.field_tests.test_multivaluefield.MultiValueFieldTest) ... ok\ntest_form_cleaned_data (forms_tests.field_tests.test_multivaluefield.MultiValueFieldTest) ... ok\ntest_has_changed_first_widget (forms_tests.field_tests.test_multivaluefield.MultiValueFieldTest)\nTest when the first widget's data has changed. ... ok\ntest_has_changed_last_widget (forms_tests.field_tests.test_multivaluefield.MultiValueFieldTest)\nTest when the last widget's data has changed. This ensures that it is ... ok\ntest_has_changed_no_initial (forms_tests.field_tests.test_multivaluefield.MultiValueFieldTest) ... ok\ntest_has_changed_same (forms_tests.field_tests.test_multivaluefield.MultiValueFieldTest) ... ok\ntest_no_value (forms_tests.field_tests.test_multivaluefield.MultiValueFieldTest)\nIf insufficient data is provided, None is substituted. ... ok\ntest_render_required_attributes (forms_tests.field_tests.test_multivaluefield.MultiValueFieldTest) ... FAIL\n\n======================================================================\nFAIL: test_render_required_attributes (forms_tests.field_tests.test_multivaluefield.MultiValueFieldTest)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/forms_tests/field_tests/test_multivaluefield.py\", line 194, in test_render_required_attributes\n    self.assertInHTML('<input type=\"text\" name=\"f_1\" id=\"id_f_1\">', form.as_p())\n  File \"/testbed/django/test/testcases.py\", line 834, in assertInHTML\n    self.assertTrue(real_count != 0, msg_prefix + \"Couldn't find '%s' in response\" % needle)\nAssertionError: False is not true : Couldn't find '<input id=\"id_f_1\" name=\"f_1\" type=\"text\">' in response\n\n----------------------------------------------------------------------\nRan 13 tests in 0.035s\n\nFAILED (failures=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 forms_tests.field_tests.test_multivaluefield` failed. (See above for error)",
          "test_files_run": [
            "tests/forms_tests/field_tests/test_multivaluefield.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 13,
          "failed": 0,
          "errors": 0,
          "duration": 7.54,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application forms_tests\nFound 13 test(s).\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_bad_choice (forms_tests.field_tests.test_multivaluefield.MultiValueFieldTest) ... ok\ntest_clean (forms_tests.field_tests.test_multivaluefield.MultiValueFieldTest) ... ok\ntest_clean_disabled_multivalue (forms_tests.field_tests.test_multivaluefield.MultiValueFieldTest) ... ok\ntest_disabled_has_changed (forms_tests.field_tests.test_multivaluefield.MultiValueFieldTest) ... ok\ntest_form_as_table (forms_tests.field_tests.test_multivaluefield.MultiValueFieldTest) ... ok\ntest_form_as_table_data (forms_tests.field_tests.test_multivaluefield.MultiValueFieldTest) ... ok\ntest_form_cleaned_data (forms_tests.field_tests.test_multivaluefield.MultiValueFieldTest) ... ok\ntest_has_changed_first_widget (forms_tests.field_tests.test_multivaluefield.MultiValueFieldTest)\nTest when the first widget's data has changed. ... ok\ntest_has_changed_last_widget (forms_tests.field_tests.test_multivaluefield.MultiValueFieldTest)\nTest when the last widget's data has changed. This ensures that it is ... ok\ntest_has_changed_no_initial (forms_tests.field_tests.test_multivaluefield.MultiValueFieldTest) ... ok\ntest_has_changed_same (forms_tests.field_tests.test_multivaluefield.MultiValueFieldTest) ... ok\ntest_no_value (forms_tests.field_tests.test_multivaluefield.MultiValueFieldTest)\nIf insufficient data is provided, None is substituted. ... ok\ntest_render_required_attributes (forms_tests.field_tests.test_multivaluefield.MultiValueFieldTest) ... ok\n\n----------------------------------------------------------------------\nRan 13 tests in 0.031s\n\nOK\n",
          "test_files_run": [
            "tests/forms_tests/field_tests/test_multivaluefield.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-14053",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 32.65870690345764,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 31,
          "failed": 1,
          "errors": 0,
          "duration": 9.74,
          "log_tail": "test_loaded_cache (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_manifest_does_not_exist (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_manifest_does_not_ignore_permission_error (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_manifest_exists (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_missing_entry (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_parse_cache (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_path_ignored_completely (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_path_with_fragment (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_path_with_querystring (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_path_with_querystring_and_fragment (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_post_processing (staticfiles_tests.test_storage.TestCollectionManifestStorage)\npost_processing behaves correctly. ... FAIL\ntest_post_processing_failure (staticfiles_tests.test_storage.TestCollectionManifestStorage)\npost_processing indicates the origin of the error when it fails. ... ok\ntest_template_tag_absolute (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_template_tag_absolute_root (staticfiles_tests.test_storage.TestCollectionManifestStorage)\nLike test_template_tag_absolute, but for a file in STATIC_ROOT (#26249). ... ok\ntest_template_tag_deep_relative (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_template_tag_relative (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_template_tag_return (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_template_tag_simple_content (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_template_tag_url (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\n\n======================================================================\nFAIL: test_post_processing (staticfiles_tests.test_storage.TestCollectionManifestStorage)\npost_processing behaves correctly.\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 60, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 676, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 633, in _callTestMethod\n    method()\n  File \"/testbed/tests/staticfiles_tests/test_storage.py\", line 207, in test_post_processing\n    self.assertCountEqual(stats['post_processed'], set(stats['post_processed']))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 1272, in assertCountEqual\n    self.fail(msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 753, in fail\n    raise self.failureException(msg)\nAssertionError: Element counts were not equal:\n\nDiff is 699 characters long. Set self.maxDiff to None to see it.\n\n----------------------------------------------------------------------\nRan 32 tests in 2.082s\n\nFAILED (failures=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 staticfiles_tests.test_storage` failed. (See above for error)",
          "test_files_run": [
            "tests/staticfiles_tests/test_storage.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 32,
          "failed": 0,
          "errors": 0,
          "duration": 9.23,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application staticfiles_tests\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_hashed_name (staticfiles_tests.test_storage.TestCollectionNoneHashStorage) ... ok\ntest_multi_extension_patterns (staticfiles_tests.test_storage.TestExtraPatternsStorage)\nWith storage classes having several file extension patterns, only the ... ok\ntest_collect_static_files_default_permissions (staticfiles_tests.test_storage.TestStaticFilePermissions) ... ok\ntest_collect_static_files_permissions (staticfiles_tests.test_storage.TestStaticFilePermissions) ... ok\ntest_collect_static_files_subclass_of_static_storage (staticfiles_tests.test_storage.TestStaticFilePermissions) ... ok\ntest_template_tag_return (staticfiles_tests.test_storage.TestCollectionSimpleStorage) ... ok\ntest_template_tag_simple_content (staticfiles_tests.test_storage.TestCollectionSimpleStorage) ... ok\ntest_file_change_after_collectstatic (staticfiles_tests.test_storage.TestCollectionHashedFilesCache) ... ok\ntest_clear_empties_manifest (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_css_import_case_insensitive (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_import_loop (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_import_replacement (staticfiles_tests.test_storage.TestCollectionManifestStorage)\nSee #18050 ... ok\ntest_intermediate_files (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_loaded_cache (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_manifest_does_not_exist (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_manifest_does_not_ignore_permission_error (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_manifest_exists (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_missing_entry (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_parse_cache (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_path_ignored_completely (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_path_with_fragment (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_path_with_querystring (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_path_with_querystring_and_fragment (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_post_processing (staticfiles_tests.test_storage.TestCollectionManifestStorage)\npost_processing behaves correctly. ... ok\ntest_post_processing_failure (staticfiles_tests.test_storage.TestCollectionManifestStorage)\npost_processing indicates the origin of the error when it fails. ... ok\ntest_template_tag_absolute (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_template_tag_absolute_root (staticfiles_tests.test_storage.TestCollectionManifestStorage)\nLike test_template_tag_absolute, but for a file in STATIC_ROOT (#26249). ... ok\ntest_template_tag_deep_relative (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_template_tag_relative (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_template_tag_return (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_template_tag_simple_content (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_template_tag_url (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\n\n----------------------------------------------------------------------\nRan 32 tests in 1.933s\n\nOK\n",
          "test_files_run": [
            "tests/staticfiles_tests/test_storage.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-14089",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 28.413994073867798,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 43,
          "failed": 0,
          "errors": 1,
          "duration": 7.79,
          "log_tail": "test_getlist_doesnt_mutate (utils_tests.test_datastructures.MultiValueDictTests) ... ok\ntest_getlist_none_empty_values (utils_tests.test_datastructures.MultiValueDictTests) ... ok\ntest_internal_getlist_does_mutate (utils_tests.test_datastructures.MultiValueDictTests) ... ok\ntest_multivaluedict (utils_tests.test_datastructures.MultiValueDictTests) ... ok\ntest_pickle (utils_tests.test_datastructures.MultiValueDictTests) ... ok\ntest_repr (utils_tests.test_datastructures.MultiValueDictTests) ... ok\ntest_setdefault (utils_tests.test_datastructures.MultiValueDictTests) ... ok\ntest_setitem (utils_tests.test_datastructures.MultiValueDictTests) ... ok\ntest_update_dict_arg (utils_tests.test_datastructures.MultiValueDictTests) ... ok\ntest_update_kwargs (utils_tests.test_datastructures.MultiValueDictTests) ... ok\ntest_update_multivaluedict_arg (utils_tests.test_datastructures.MultiValueDictTests) ... ok\ntest_update_no_args (utils_tests.test_datastructures.MultiValueDictTests) ... ok\ntest_update_raises_correct_exceptions (utils_tests.test_datastructures.MultiValueDictTests) ... ok\ntest_update_too_many_args (utils_tests.test_datastructures.MultiValueDictTests) ... ok\ntest_update_with_empty_iterable (utils_tests.test_datastructures.MultiValueDictTests) ... ok\ntest_update_with_iterable_of_pairs (utils_tests.test_datastructures.MultiValueDictTests) ... ok\ntest_copy (utils_tests.test_datastructures.CaseInsensitiveMappingTests) ... ok\ntest_create_with_invalid_key (utils_tests.test_datastructures.CaseInsensitiveMappingTests) ... ok\ntest_create_with_invalid_values (utils_tests.test_datastructures.CaseInsensitiveMappingTests) ... ok\ntest_del (utils_tests.test_datastructures.CaseInsensitiveMappingTests) ... ok\ntest_dict (utils_tests.test_datastructures.CaseInsensitiveMappingTests) ... ok\ntest_equal (utils_tests.test_datastructures.CaseInsensitiveMappingTests) ... ok\ntest_getitem (utils_tests.test_datastructures.CaseInsensitiveMappingTests) ... ok\ntest_in (utils_tests.test_datastructures.CaseInsensitiveMappingTests) ... ok\ntest_items (utils_tests.test_datastructures.CaseInsensitiveMappingTests) ... ok\ntest_list (utils_tests.test_datastructures.CaseInsensitiveMappingTests) ... ok\ntest_repr (utils_tests.test_datastructures.CaseInsensitiveMappingTests) ... ok\ntest_set (utils_tests.test_datastructures.CaseInsensitiveMappingTests) ... ok\ntest_str (utils_tests.test_datastructures.CaseInsensitiveMappingTests) ... ok\n\n======================================================================\nERROR: test_reversed (utils_tests.test_datastructures.OrderedSetTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 60, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 676, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 633, in _callTestMethod\n    method()\n  File \"/testbed/tests/utils_tests/test_datastructures.py\", line 38, in test_reversed\n    s = reversed(OrderedSet([1, 2, 3]))\nTypeError: 'OrderedSet' object is not reversible\n\n----------------------------------------------------------------------\nRan 44 tests in 0.245s\n\nFAILED (errors=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 utils_tests.test_datastructures` failed. (See above for error)",
          "test_files_run": [
            "tests/utils_tests/test_datastructures.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 44,
          "failed": 0,
          "errors": 0,
          "duration": 7.56,
          "log_tail": "test_bool (utils_tests.test_datastructures.OrderedSetTests) ... ok\ntest_contains (utils_tests.test_datastructures.OrderedSetTests) ... ok\ntest_discard (utils_tests.test_datastructures.OrderedSetTests) ... ok\ntest_init_with_iterable (utils_tests.test_datastructures.OrderedSetTests) ... ok\ntest_len (utils_tests.test_datastructures.OrderedSetTests) ... ok\ntest_remove (utils_tests.test_datastructures.OrderedSetTests) ... ok\ntest_reversed (utils_tests.test_datastructures.OrderedSetTests) ... ok\ntest_custom_warning (utils_tests.test_datastructures.ImmutableListTests) ... ok\ntest_sort (utils_tests.test_datastructures.ImmutableListTests) ... ok\ntest_dictwrapper (utils_tests.test_datastructures.DictWrapperTests) ... ok\ntest_copy (utils_tests.test_datastructures.CaseInsensitiveMappingTests) ... ok\ntest_create_with_invalid_key (utils_tests.test_datastructures.CaseInsensitiveMappingTests) ... ok\ntest_create_with_invalid_values (utils_tests.test_datastructures.CaseInsensitiveMappingTests) ... ok\ntest_del (utils_tests.test_datastructures.CaseInsensitiveMappingTests) ... ok\ntest_dict (utils_tests.test_datastructures.CaseInsensitiveMappingTests) ... ok\ntest_equal (utils_tests.test_datastructures.CaseInsensitiveMappingTests) ... ok\ntest_getitem (utils_tests.test_datastructures.CaseInsensitiveMappingTests) ... ok\ntest_in (utils_tests.test_datastructures.CaseInsensitiveMappingTests) ... ok\ntest_items (utils_tests.test_datastructures.CaseInsensitiveMappingTests) ... ok\ntest_list (utils_tests.test_datastructures.CaseInsensitiveMappingTests) ... ok\ntest_repr (utils_tests.test_datastructures.CaseInsensitiveMappingTests) ... ok\ntest_set (utils_tests.test_datastructures.CaseInsensitiveMappingTests) ... ok\ntest_str (utils_tests.test_datastructures.CaseInsensitiveMappingTests) ... ok\ntest_appendlist (utils_tests.test_datastructures.MultiValueDictTests) ... ok\ntest_copy (utils_tests.test_datastructures.MultiValueDictTests) ... ok\ntest_deepcopy (utils_tests.test_datastructures.MultiValueDictTests) ... ok\ntest_dict_translation (utils_tests.test_datastructures.MultiValueDictTests) ... ok\ntest_getlist_default (utils_tests.test_datastructures.MultiValueDictTests) ... ok\ntest_getlist_doesnt_mutate (utils_tests.test_datastructures.MultiValueDictTests) ... ok\ntest_getlist_none_empty_values (utils_tests.test_datastructures.MultiValueDictTests) ... ok\ntest_internal_getlist_does_mutate (utils_tests.test_datastructures.MultiValueDictTests) ... ok\ntest_multivaluedict (utils_tests.test_datastructures.MultiValueDictTests) ... ok\ntest_pickle (utils_tests.test_datastructures.MultiValueDictTests) ... ok\ntest_repr (utils_tests.test_datastructures.MultiValueDictTests) ... ok\ntest_setdefault (utils_tests.test_datastructures.MultiValueDictTests) ... ok\ntest_setitem (utils_tests.test_datastructures.MultiValueDictTests) ... ok\ntest_update_dict_arg (utils_tests.test_datastructures.MultiValueDictTests) ... ok\ntest_update_kwargs (utils_tests.test_datastructures.MultiValueDictTests) ... ok\ntest_update_multivaluedict_arg (utils_tests.test_datastructures.MultiValueDictTests) ... ok\ntest_update_no_args (utils_tests.test_datastructures.MultiValueDictTests) ... ok\ntest_update_raises_correct_exceptions (utils_tests.test_datastructures.MultiValueDictTests) ... ok\ntest_update_too_many_args (utils_tests.test_datastructures.MultiValueDictTests) ... ok\ntest_update_with_empty_iterable (utils_tests.test_datastructures.MultiValueDictTests) ... ok\ntest_update_with_iterable_of_pairs (utils_tests.test_datastructures.MultiValueDictTests) ... ok\n\n----------------------------------------------------------------------\nRan 44 tests in 0.413s\n\nOK\n",
          "test_files_run": [
            "tests/utils_tests/test_datastructures.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-14122",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 24.97092294692993,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 26,
          "failed": 1,
          "errors": 0,
          "duration": 7.84,
          "log_tail": "test_extra_ordering_quoting (ordering.tests.OrderingTests)\nIf the extra clause uses an SQL keyword for a name, it will be ... ok\ntest_extra_ordering_with_table_name (ordering.tests.OrderingTests) ... ok\ntest_no_reordering_after_slicing (ordering.tests.OrderingTests) ... ok\ntest_order_by_constant_value (ordering.tests.OrderingTests) ... ok\ntest_order_by_f_expression (ordering.tests.OrderingTests) ... ok\ntest_order_by_f_expression_duplicates (ordering.tests.OrderingTests)\nA column may only be included once (the first occurrence) so we check ... ok\ntest_order_by_fk_attname (ordering.tests.OrderingTests)\nordering by a foreign key by its attribute name prevents the query ... ok\ntest_order_by_nulls_first (ordering.tests.OrderingTests) ... ok\ntest_order_by_nulls_first_and_last (ordering.tests.OrderingTests) ... ok\ntest_order_by_nulls_last (ordering.tests.OrderingTests) ... ok\ntest_order_by_override (ordering.tests.OrderingTests)\nOnly the last order_by has any effect (since they each override any ... ok\ntest_order_by_pk (ordering.tests.OrderingTests)\n'pk' works as an ordering option in Meta. ... ok\ntest_order_by_ptr_field_with_default_ordering_by_expression (ordering.tests.OrderingTests) ... ok\ntest_order_by_self_referential_fk (ordering.tests.OrderingTests) ... ok\ntest_orders_nulls_first_on_filtered_subquery (ordering.tests.OrderingTests) ... ok\ntest_random_ordering (ordering.tests.OrderingTests)\nUse '?' to order randomly. ... ok\ntest_related_ordering_duplicate_table_reference (ordering.tests.OrderingTests)\nAn ordering referencing a model with an ordering referencing a model ... ok\ntest_reverse_meta_ordering_pure (ordering.tests.OrderingTests) ... ok\ntest_reverse_ordering_pure (ordering.tests.OrderingTests) ... ok\ntest_reversed_ordering (ordering.tests.OrderingTests)\nOrdering can be reversed using the reverse() method on a queryset. ... ok\ntest_stop_slicing (ordering.tests.OrderingTests)\nUse the 'stop' part of slicing notation to limit the results. ... ok\ntest_stop_start_slicing (ordering.tests.OrderingTests)\nUse the 'stop' and 'start' parts of slicing notation to offset the ... ok\n\n======================================================================\nFAIL: test_default_ordering_does_not_affect_group_by (ordering.tests.OrderingTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/ordering/tests.py\", line 492, in test_default_ordering_does_not_affect_group_by\n    self.assertCountEqual(articles, [\nAssertionError: Element counts were not equal:\nFirst has 3, Second has 0:  {'author': 1, 'count': 1}\nFirst has 0, Second has 1:  {'author': 1, 'count': 3}\n\n----------------------------------------------------------------------\nRan 27 tests in 0.070s\n\nFAILED (failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 ordering.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/ordering/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 27,
          "failed": 0,
          "errors": 0,
          "duration": 7.56,
          "log_tail": "\nCreating test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\ntest_default_ordering (ordering.tests.OrderingTests)\nBy default, Article.objects.all() orders by pub_date descending, then ... ok\ntest_default_ordering_by_f_expression (ordering.tests.OrderingTests)\nF expressions can be used in Meta.ordering. ... ok\ntest_default_ordering_does_not_affect_group_by (ordering.tests.OrderingTests) ... ok\ntest_default_ordering_override (ordering.tests.OrderingTests)\nOverride ordering with order_by, which is in the same format as the ... ok\ntest_extra_ordering (ordering.tests.OrderingTests)\nOrdering can be based on fields included from an 'extra' clause ... ok\ntest_extra_ordering_quoting (ordering.tests.OrderingTests)\nIf the extra clause uses an SQL keyword for a name, it will be ... ok\ntest_extra_ordering_with_table_name (ordering.tests.OrderingTests) ... ok\ntest_no_reordering_after_slicing (ordering.tests.OrderingTests) ... ok\ntest_order_by_constant_value (ordering.tests.OrderingTests) ... ok\ntest_order_by_f_expression (ordering.tests.OrderingTests) ... ok\ntest_order_by_f_expression_duplicates (ordering.tests.OrderingTests)\nA column may only be included once (the first occurrence) so we check ... ok\ntest_order_by_fk_attname (ordering.tests.OrderingTests)\nordering by a foreign key by its attribute name prevents the query ... ok\ntest_order_by_nulls_first (ordering.tests.OrderingTests) ... ok\ntest_order_by_nulls_first_and_last (ordering.tests.OrderingTests) ... ok\ntest_order_by_nulls_last (ordering.tests.OrderingTests) ... ok\ntest_order_by_override (ordering.tests.OrderingTests)\nOnly the last order_by has any effect (since they each override any ... ok\ntest_order_by_pk (ordering.tests.OrderingTests)\n'pk' works as an ordering option in Meta. ... ok\ntest_order_by_ptr_field_with_default_ordering_by_expression (ordering.tests.OrderingTests) ... ok\ntest_order_by_self_referential_fk (ordering.tests.OrderingTests) ... ok\ntest_orders_nulls_first_on_filtered_subquery (ordering.tests.OrderingTests) ... ok\ntest_random_ordering (ordering.tests.OrderingTests)\nUse '?' to order randomly. ... ok\ntest_related_ordering_duplicate_table_reference (ordering.tests.OrderingTests)\nAn ordering referencing a model with an ordering referencing a model ... ok\ntest_reverse_meta_ordering_pure (ordering.tests.OrderingTests) ... ok\ntest_reverse_ordering_pure (ordering.tests.OrderingTests) ... ok\ntest_reversed_ordering (ordering.tests.OrderingTests)\nOrdering can be reversed using the reverse() method on a queryset. ... ok\ntest_stop_slicing (ordering.tests.OrderingTests)\nUse the 'stop' part of slicing notation to limit the results. ... ok\ntest_stop_start_slicing (ordering.tests.OrderingTests)\nUse the 'stop' and 'start' parts of slicing notation to offset the ... ok\n\n----------------------------------------------------------------------\nRan 27 tests in 0.093s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/ordering/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-14140",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 27.0699200630188,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 203,
          "failed": 2,
          "errors": 2,
          "duration": 9.25,
          "log_tail": "  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 60, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 676, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 633, in _callTestMethod\n    method()\n  File \"/testbed/tests/queries/test_q.py\", line 50, in test_deconstruct_negated\n    self.assertEqual(args, (('price__gt', F('discounted_price')),))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 912, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 1129, in assertTupleEqual\n    self.assertSequenceEqual(tuple1, tuple2, msg, seq_type=tuple)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 1100, in assertSequenceEqual\n    self.fail(msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 753, in fail\n    raise self.failureException(msg)\nAssertionError: Tuples differ: () != (('price__gt', F(discounted_price)),)\n\nSecond tuple contains 1 additional elements.\nFirst extra element 0:\n('price__gt', F(discounted_price))\n\n- ()\n+ (('price__gt', F(discounted_price)),)\n\n----------------------------------------------------------------------\nRan 207 tests in 0.492s\n\nFAILED (failures=2, errors=2, skipped=2)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 expressions.tests queries.test_q queryset_pickle.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/expressions/tests.py",
            "tests/queries/test_q.py",
            "tests/queryset_pickle/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 207,
          "failed": 0,
          "errors": 0,
          "duration": 8.62,
          "log_tail": "test_order_by_multiline_sql (expressions.tests.BasicExpressionsTests) ... ok\ntest_order_of_operations (expressions.tests.BasicExpressionsTests) ... ok\ntest_outerref (expressions.tests.BasicExpressionsTests) ... ok\ntest_outerref_mixed_case_table_name (expressions.tests.BasicExpressionsTests) ... ok\ntest_outerref_with_operator (expressions.tests.BasicExpressionsTests) ... ok\ntest_parenthesis_priority (expressions.tests.BasicExpressionsTests) ... ok\ntest_pickle_expression (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_eq (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_filter_by_aggregate (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_filter_by_lazy (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_group_by_outerref_in_filter (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_in_filter (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_references_joined_table_twice (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_11722_iexact_lookup (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_16731_startswith_lookup (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_18375_chained_filters (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_18375_join_reuse (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_18375_kwarg_ordering (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_18375_kwarg_ordering_2 (expressions.tests.BasicExpressionsTests) ... ok\ntest_update (expressions.tests.BasicExpressionsTests) ... ok\ntest_update_inherited_field_value (expressions.tests.BasicExpressionsTests) ... ok\ntest_update_with_fk (expressions.tests.BasicExpressionsTests) ... ok\ntest_update_with_none (expressions.tests.BasicExpressionsTests) ... ok\ntest_uuid_pk_subquery (expressions.tests.BasicExpressionsTests) ... ok\n\n----------------------------------------------------------------------\nRan 207 tests in 0.433s\n\nOK (skipped=2)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/expressions/tests.py",
            "tests/queries/test_q.py",
            "tests/queryset_pickle/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-14155",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 26.453276872634888,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 91,
          "failed": 4,
          "errors": 0,
          "duration": 8.35,
          "log_tail": "    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 753, in fail\n    raise self.failureException(msg)\nAssertionError: 'ResolverMatch(func=functools.partial, ar[90 chars]ed/)' != \"ResolverMatch(func=functools.partial(<fu[172 chars]d/')\"\nDiff is 660 characters long. Set self.maxDiff to None to see it.\n\n======================================================================\nFAIL: test_repr_functools_partial (urlpatterns_reverse.tests.ResolverMatchTests) [<object object at 0x742efbdb0eb0>] (name='partial_wrapped')\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 60, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 582, in subTest\n    yield\n  File \"/testbed/tests/urlpatterns_reverse/tests.py\", line 1161, in test_repr_functools_partial\n    self.assertEqual(\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 912, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 1292, in assertMultiLineEqual\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 753, in fail\n    raise self.failureException(msg)\nAssertionError: 'ResolverMatch(func=urlpatterns_reverse.v[111 chars]ed/)' != \"ResolverMatch(func=functools.partial(<fu[168 chars]d/')\"\n- ResolverMatch(func=urlpatterns_reverse.views.empty_view, args=(), kwargs={}, url_name=partial_wrapped, app_names=[], namespaces=[], route=partial_wrapped/)\n+ ResolverMatch(func=functools.partial(<function empty_view at 0x742efb554700>, template_name='template.html'), args=(), kwargs={}, url_name='partial_wrapped', app_names=[], namespaces=[], route='partial_wrapped/')\n\n\n----------------------------------------------------------------------\nRan 95 tests in 0.812s\n\nFAILED (failures=4)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 urlpatterns_reverse.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/urlpatterns_reverse/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 95,
          "failed": 0,
          "errors": 0,
          "duration": 7.98,
          "log_tail": "Namespace defaults to app_name when including a (pattern, app_name) ... ok\ntest_current_app_no_partial_match (urlpatterns_reverse.tests.NamespaceTests)\ncurrent_app shouldn't be used unless it matches the whole path. ... ok\ntest_embedded_namespace_object (urlpatterns_reverse.tests.NamespaceTests)\nNamespaces can be installed anywhere in the URL pattern tree. ... ok\ntest_multiple_namespace_pattern (urlpatterns_reverse.tests.NamespaceTests)\nNamespaces can be embedded. ... ok\ntest_namespace_object (urlpatterns_reverse.tests.NamespaceTests)\nDynamic URL objects can be found using a namespace. ... ok\ntest_namespace_pattern (urlpatterns_reverse.tests.NamespaceTests)\nNamespaces can be applied to include()'d urlpatterns. ... ok\ntest_namespace_pattern_with_variable_prefix (urlpatterns_reverse.tests.NamespaceTests)\nUsing include() with namespaces when there is a regex variable in front ... ok\ntest_namespaces_with_variables (urlpatterns_reverse.tests.NamespaceTests)\nNamespace prefixes can capture variables. ... ok\ntest_nested_app_lookup (urlpatterns_reverse.tests.NamespaceTests)\nA nested current_app should be split in individual namespaces (#24904). ... ok\ntest_nested_namespace_pattern (urlpatterns_reverse.tests.NamespaceTests)\nNamespaces can be nested. ... ok\ntest_non_existent_namespace (urlpatterns_reverse.tests.NamespaceTests)\nNonexistent namespaces raise errors. ... ok\ntest_normal_name (urlpatterns_reverse.tests.NamespaceTests)\nNormal lookups work as expected. ... ok\ntest_simple_included_name (urlpatterns_reverse.tests.NamespaceTests)\nNormal lookups work on names included from other patterns. ... ok\ntest_special_chars_namespace (urlpatterns_reverse.tests.NamespaceTests) ... ok\ntest_lazy_in_settings (urlpatterns_reverse.tests.ReverseLazySettingsTest) ... ok\n\n----------------------------------------------------------------------\nRan 95 tests in 0.718s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/urlpatterns_reverse/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-14170",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 30.834262132644653,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 79,
          "failed": 2,
          "errors": 0,
          "duration": 9.1,
          "log_tail": "\nFirst differing element 0:\n<DTModel: DTModel object (3)>\n<DTModel: DTModel object (2)>\n\nSecond sequence contains 1 additional elements.\nFirst extra element 1:\n<DTModel: DTModel object (3)>\n\n- <QuerySet [<DTModel: DTModel object (3)>]>\n+ [<DTModel: DTModel object (2)>, <DTModel: DTModel object (3)>]\n\n======================================================================\nFAIL: test_extract_iso_year_func_boundaries (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 60, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 676, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 633, in _callTestMethod\n    method()\n  File \"/testbed/tests/db_functions/datetime/test_extract_trunc.py\", line 377, in test_extract_iso_year_func_boundaries\n    self.assertSequenceEqual(qs, [obj_1_iso_2015, obj_2_iso_2015])\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 1100, in assertSequenceEqual\n    self.fail(msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 753, in fail\n    raise self.failureException(msg)\nAssertionError: Sequences differ: <QuerySet [<DTModel: DTModel object (3)>]> != [<DTModel: DTModel object (2)>, <DTModel: DTModel object (3)>]\n\nFirst differing element 0:\n<DTModel: DTModel object (3)>\n<DTModel: DTModel object (2)>\n\nSecond sequence contains 1 additional elements.\nFirst extra element 1:\n<DTModel: DTModel object (3)>\n\n- <QuerySet [<DTModel: DTModel object (3)>]>\n+ [<DTModel: DTModel object (2)>, <DTModel: DTModel object (3)>]\n\n----------------------------------------------------------------------\nRan 81 tests in 0.469s\n\nFAILED (failures=2, skipped=2)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 db_functions.datetime.test_extract_trunc` failed. (See above for error)",
          "test_files_run": [
            "tests/db_functions/datetime/test_extract_trunc.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 81,
          "failed": 0,
          "errors": 0,
          "duration": 8.18,
          "log_tail": "test_extract_func_explicit_timezone_priority (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_func_with_timezone (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_hour_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_invalid_field_with_timezone (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_iso_weekday_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_iso_year_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_iso_year_func_boundaries (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_minute_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_month_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_none (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_quarter_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_quarter_func_boundaries (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_second_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_week_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_week_func_boundaries (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_weekday_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_year_exact_lookup (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests)\nExtract year uses a BETWEEN filter to compare the year to allow indexes ... ok\ntest_extract_year_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_year_greaterthan_lookup (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_year_lessthan_lookup (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_ambiguous_and_invalid_times (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_date_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_date_none (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_day_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_func_with_timezone (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests)\nIf the truncated datetime transitions to a different offset (daylight ... ok\ntest_trunc_hour_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_invalid_field_with_timezone (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_minute_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_month_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_none (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_quarter_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_second_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_subquery_with_parameters (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_time_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_time_none (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_timezone_applied_before_truncation (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_week_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_year_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\n\n----------------------------------------------------------------------\nRan 81 tests in 0.603s\n\nOK (skipped=2)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/db_functions/datetime/test_extract_trunc.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-14238",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 30.008718013763428,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 58,
          "failed": 2,
          "errors": 1,
          "duration": 8.38,
          "log_tail": "    opts._prepare(cls)\n  File \"/testbed/django/db/models/options.py\", line 285, in _prepare\n    pk_class = self._get_default_pk_class()\n  File \"/testbed/django/db/models/options.py\", line 246, in _get_default_pk_class\n    raise ValueError(\nValueError: Primary key 'model_options.test_default_pk.MyBigAutoField' referred by DEFAULT_AUTO_FIELD must subclass AutoField.\n\n======================================================================\nFAIL: test_issubclass_of_autofield (model_fields.test_autofield.AutoFieldInheritanceTests) [MyBigAutoField]\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 60, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 582, in subTest\n    yield\n  File \"/testbed/tests/model_fields/test_autofield.py\", line 47, in test_issubclass_of_autofield\n    self.assertTrue(issubclass(field, models.AutoField))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 765, in assertTrue\n    raise self.failureException(msg)\nAssertionError: False is not true\n\n======================================================================\nFAIL: test_issubclass_of_autofield (model_fields.test_autofield.AutoFieldInheritanceTests) [MySmallAutoField]\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 60, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 582, in subTest\n    yield\n  File \"/testbed/tests/model_fields/test_autofield.py\", line 47, in test_issubclass_of_autofield\n    self.assertTrue(issubclass(field, models.AutoField))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 765, in assertTrue\n    raise self.failureException(msg)\nAssertionError: False is not true\n\n----------------------------------------------------------------------\nRan 61 tests in 0.285s\n\nFAILED (failures=2, errors=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 model_fields.test_autofield model_options.test_default_pk` failed. (See above for error)",
          "test_files_run": [
            "tests/model_fields/test_autofield.py",
            "tests/model_options/test_default_pk.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 61,
          "failed": 0,
          "errors": 0,
          "duration": 8.3,
          "log_tail": "Backend specific ranges can be saved without corruption. ... ok\ntest_backend_range_validation (model_fields.test_autofield.BigAutoFieldTests)\nBackend specific ranges are enforced at the model validation level ... ok\ntest_coercing (model_fields.test_autofield.BigAutoFieldTests) ... ok\ntest_documented_range (model_fields.test_autofield.BigAutoFieldTests)\nValues within the documented safe range pass validation, and can be ... ok\ntest_invalid_value (model_fields.test_autofield.BigAutoFieldTests) ... ok\ntest_redundant_backend_range_validators (model_fields.test_autofield.BigAutoFieldTests)\nIf there are stricter validators than the ones from the database ... ok\ntest_rel_db_type (model_fields.test_autofield.BigAutoFieldTests) ... ok\ntest_types (model_fields.test_autofield.BigAutoFieldTests) ... ok\ntest_backend_range_save (model_fields.test_integerfield.SmallIntegerFieldTests)\nBackend specific ranges can be saved without corruption. ... ok\ntest_backend_range_validation (model_fields.test_integerfield.SmallIntegerFieldTests)\nBackend specific ranges are enforced at the model validation level ... ok\ntest_coercing (model_fields.test_integerfield.SmallIntegerFieldTests) ... ok\ntest_documented_range (model_fields.test_integerfield.SmallIntegerFieldTests)\nValues within the documented safe range pass validation, and can be ... ok\ntest_invalid_value (model_fields.test_integerfield.SmallIntegerFieldTests) ... ok\ntest_redundant_backend_range_validators (model_fields.test_integerfield.SmallIntegerFieldTests)\nIf there are stricter validators than the ones from the database ... ok\ntest_rel_db_type (model_fields.test_integerfield.SmallIntegerFieldTests) ... ok\ntest_types (model_fields.test_integerfield.SmallIntegerFieldTests) ... ok\ntest_backend_range_save (model_fields.test_integerfield.BigIntegerFieldTests)\nBackend specific ranges can be saved without corruption. ... ok\ntest_backend_range_validation (model_fields.test_integerfield.BigIntegerFieldTests)\nBackend specific ranges are enforced at the model validation level ... ok\ntest_coercing (model_fields.test_integerfield.BigIntegerFieldTests) ... ok\ntest_documented_range (model_fields.test_integerfield.BigIntegerFieldTests)\nValues within the documented safe range pass validation, and can be ... ok\ntest_invalid_value (model_fields.test_integerfield.BigIntegerFieldTests) ... ok\ntest_redundant_backend_range_validators (model_fields.test_integerfield.BigIntegerFieldTests)\nIf there are stricter validators than the ones from the database ... ok\ntest_rel_db_type (model_fields.test_integerfield.BigIntegerFieldTests) ... ok\ntest_types (model_fields.test_integerfield.BigIntegerFieldTests) ... ok\n\n----------------------------------------------------------------------\nRan 61 tests in 0.324s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/model_fields/test_autofield.py",
            "tests/model_options/test_default_pk.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-14311",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 29.928385019302368,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 79,
          "failed": 1,
          "errors": 0,
          "duration": 8.96,
          "log_tail": "test_paths_are_pathlib_instances (utils_tests.test_autoreload.TestIterModulesAndFiles) ... ok\ntest_weakref_in_sys_module (utils_tests.test_autoreload.TestIterModulesAndFiles)\niter_all_python_module_file() ignores weakref modules. ... ok\ntest_zip_reload (utils_tests.test_autoreload.TestIterModulesAndFiles)\nModules imported from zipped files have their archive location included ... ok\n\n======================================================================\nFAIL: test_run_as_non_django_module_non_package (utils_tests.test_autoreload.TestChildArguments)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 60, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 676, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 633, in _callTestMethod\n    method()\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/mock.py\", line 1756, in _inner\n    return f(*args, **kw)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/mock.py\", line 1325, in patched\n    return func(*newargs, **newkeywargs)\n  File \"/testbed/tests/utils_tests/test_autoreload.py\", line 189, in test_run_as_non_django_module_non_package\n    self.assertEqual(\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 912, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 1118, in assertListEqual\n    self.assertSequenceEqual(list1, list2, msg, seq_type=list)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 1100, in assertSequenceEqual\n    self.fail(msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 753, in fail\n    raise self.failureException(msg)\nAssertionError: Lists differ: ['/op[33 chars]hon', '-m', 'utils_tests.test_module', 'runserver'] != ['/op[33 chars]hon', '-m', 'utils_tests.test_module.main_module', 'runserver']\n\nFirst differing element 2:\n'utils_tests.test_module'\n'utils_tests.test_module.main_module'\n\n  ['/opt/miniconda3/envs/testbed/bin/python',\n   '-m',\n-  'utils_tests.test_module',\n+  'utils_tests.test_module.main_module',\n?                          ++++++++++++\n\n   'runserver']\n\n----------------------------------------------------------------------\nRan 80 tests in 0.492s\n\nFAILED (failures=1, skipped=20)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 utils_tests.test_autoreload utils_tests.test_module.main_module` failed. (See above for error)",
          "test_files_run": [
            "tests/utils_tests/test_autoreload.py",
            "tests/utils_tests/test_module/main_module.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 80,
          "failed": 0,
          "errors": 0,
          "duration": 7.18,
          "log_tail": "test_warnoptions (utils_tests.test_autoreload.TestChildArguments) ... ok\ntest_sys_paths_absolute (utils_tests.test_autoreload.TestSysPathDirectories) ... ok\ntest_sys_paths_directories (utils_tests.test_autoreload.TestSysPathDirectories) ... ok\ntest_sys_paths_non_existing (utils_tests.test_autoreload.TestSysPathDirectories) ... ok\ntest_sys_paths_with_directories (utils_tests.test_autoreload.TestSysPathDirectories) ... ok\ntest_check_errors_called (utils_tests.test_autoreload.StartDjangoTests) ... ok\ntest_echo_on_called (utils_tests.test_autoreload.StartDjangoTests) ... ok\ntest_starts_thread_with_args (utils_tests.test_autoreload.StartDjangoTests) ... ok\ntest_watchman_becomes_unavailable (utils_tests.test_autoreload.StartDjangoTests) ... ok\ntest_run_loop_catches_stopiteration (utils_tests.test_autoreload.BaseReloaderTests) ... ok\ntest_run_loop_stop_and_return (utils_tests.test_autoreload.BaseReloaderTests) ... ok\ntest_wait_for_apps_ready_checks_for_exception (utils_tests.test_autoreload.BaseReloaderTests) ... ok\ntest_wait_for_apps_ready_without_exception (utils_tests.test_autoreload.BaseReloaderTests) ... ok\ntest_watch_dir_with_unresolvable_path (utils_tests.test_autoreload.BaseReloaderTests) ... ok\ntest_watch_files_with_recursive_glob (utils_tests.test_autoreload.BaseReloaderTests) ... ok\ntest_watch_with_glob (utils_tests.test_autoreload.BaseReloaderTests) ... ok\ntest_glob (utils_tests.test_autoreload.StatReloaderTests) ... ok\ntest_glob_recursive (utils_tests.test_autoreload.StatReloaderTests) ... ok\ntest_multiple_globs (utils_tests.test_autoreload.StatReloaderTests) ... ok\ntest_multiple_recursive_globs (utils_tests.test_autoreload.StatReloaderTests) ... ok\ntest_nested_glob_recursive (utils_tests.test_autoreload.StatReloaderTests) ... ok\ntest_overlapping_glob_recursive (utils_tests.test_autoreload.StatReloaderTests) ... ok\ntest_overlapping_globs (utils_tests.test_autoreload.StatReloaderTests) ... ok\ntest_snapshot_files_ignores_missing_files (utils_tests.test_autoreload.StatReloaderTests) ... ok\ntest_snapshot_files_updates (utils_tests.test_autoreload.StatReloaderTests) ... ok\ntest_snapshot_files_with_duplicates (utils_tests.test_autoreload.StatReloaderTests) ... ok\ntest_tick_does_not_trigger_twice (utils_tests.test_autoreload.StatReloaderTests) ... ok\ntest_bytecode_conversion_to_source (utils_tests.test_autoreload.TestIterModulesAndFiles)\n.pyc and .pyo files are included in the files list. ... ok\ntest_check_errors (utils_tests.test_autoreload.TestIterModulesAndFiles)\nWhen a file containing an error is imported in a function wrapped by ... ok\ntest_check_errors_catches_all_exceptions (utils_tests.test_autoreload.TestIterModulesAndFiles)\nSince Python may raise arbitrary exceptions when importing code, ... ok\ntest_file_added (utils_tests.test_autoreload.TestIterModulesAndFiles)\nWhen a file is added, it's returned by iter_all_python_module_files(). ... ok\ntest_main_module_is_resolved (utils_tests.test_autoreload.TestIterModulesAndFiles) ... ok\ntest_main_module_without_file_is_not_resolved (utils_tests.test_autoreload.TestIterModulesAndFiles) ... ok\ntest_module_without_spec (utils_tests.test_autoreload.TestIterModulesAndFiles) ... ok\ntest_path_with_embedded_null_bytes (utils_tests.test_autoreload.TestIterModulesAndFiles) ... ok\ntest_paths_are_pathlib_instances (utils_tests.test_autoreload.TestIterModulesAndFiles) ... ok\ntest_weakref_in_sys_module (utils_tests.test_autoreload.TestIterModulesAndFiles)\niter_all_python_module_file() ignores weakref modules. ... ok\ntest_zip_reload (utils_tests.test_autoreload.TestIterModulesAndFiles)\nModules imported from zipped files have their archive location included ... ok\n\n----------------------------------------------------------------------\nRan 80 tests in 0.455s\n\nOK (skipped=20)\n",
          "test_files_run": [
            "tests/utils_tests/test_autoreload.py",
            "tests/utils_tests/test_module/main_module.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-14315",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 28.560914039611816,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 7.73,
          "log_tail": "Traceback (most recent call last):\n  File \"runtests.py\", line 596, in <module>\n    failures = django_tests(\n  File \"runtests.py\", line 332, in django_tests\n    failures = test_runner.run_tests(test_labels or get_installed())\n  File \"/testbed/django/test/runner.py\", line 772, in run_tests\n    result = self.run_suite(suite)\n  File \"/testbed/django/test/runner.py\", line 705, in run_suite\n    return runner.run(suite)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/runner.py\", line 176, in run\n    test(result)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/suite.py\", line 84, in __call__\n    return self.run(*args, **kwds)\n  File \"/testbed/django/test/runner.py\", line 446, in run\n    subsuite_index, events = test_results.next(timeout=0.1)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/multiprocessing/pool.py\", line 868, in next\n    raise value\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/testbed/django/test/runner.py\", line 381, in _run_subsuite\n    result = runner.run(subsuite)\n  File \"/testbed/django/test/runner.py\", line 328, in run\n    test(result)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/suite.py\", line 84, in __call__\n    return self.run(*args, **kwds)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/suite.py\", line 122, in run\n    test(result)\n  File \"/testbed/django/test/testcases.py\", line 247, in __call__\n    self._setup_and_call(result)\n  File \"/testbed/django/test/testcases.py\", line 283, in _setup_and_call\n    super().__call__(result)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 736, in __call__\n    return self.run(*args, **kwds)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 684, in run\n    self._feedErrorsToResult(result, outcome.errors)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 597, in _feedErrorsToResult\n    result.addSubTest(test.test_case, test, exc_info)\n  File \"/testbed/django/test/runner.py\", line 269, in addSubTest\n    self.check_subtest_picklable(test, subtest)\n  File \"/testbed/django/test/runner.py\", line 231, in check_subtest_picklable\n    self._confirm_picklable(subtest)\n  File \"/testbed/django/test/runner.py\", line 164, in _confirm_picklable\n    pickle.loads(pickle.dumps(obj))\nTypeError: cannot pickle '_thread.RLock' object\nException ignored in: <function Pool.__del__ at 0x717ea9717f70>\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/multiprocessing/pool.py\", line 265, in __del__\nResourceWarning: unclosed running multiprocessing pool <multiprocessing.pool.Pool state=RUN pool_size=60>\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 backends.base.test_client dbshell.test_postgresql` failed. (See above for error)",
          "test_files_run": [
            "tests/backends/base/test_client.py",
            "tests/dbshell/test_postgresql.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 12,
          "failed": 0,
          "errors": 0,
          "duration": 7.74,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application dbshell\nImporting application backends\nFound 12 tests.\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_runshell_use_environ (backends.base.test_client.SimpleDatabaseClientTests) ... ok\ntest_settings_to_cmd_args_env (backends.base.test_client.SimpleDatabaseClientTests) ... ok\ntest_accent (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase) ... ok\ntest_basic (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase) ... ok\ntest_column (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase) ... ok\ntest_crash_password_does_not_leak (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase) ... ok\ntest_nopass (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase) ... ok\ntest_parameters (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase) ... ok\ntest_passfile (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase) ... ok\ntest_service (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase) ... ok\ntest_sigint_handler (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase)\nSIGINT is ignored in Python and passed to psql to abort queries. ... skipped 'Requires a PostgreSQL connection'\ntest_ssl_certificate (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase) ... ok\n\n----------------------------------------------------------------------\nRan 12 tests in 0.291s\n\nOK (skipped=1)\n",
          "test_files_run": [
            "tests/backends/base/test_client.py",
            "tests/dbshell/test_postgresql.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-14349",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 30.592429876327515,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 11,
          "failed": 8,
          "errors": 0,
          "duration": 8.73,
          "log_tail": "  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 60, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 582, in subTest\n    yield\n  File \"/testbed/tests/validators/tests.py\", line 334, in test_validators\n    validator(value)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 227, in __exit__\n    self._raiseFailure(\"{} not raised\".format(exc_name))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 164, in _raiseFailure\n    raise self.test_case.failureException(msg)\nAssertionError: ValidationError not raised\n\n======================================================================\nFAIL: test_validators (validators.tests.TestValidators) [URLValidator] (value='http://\\twww.djangoproject.com/')\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 60, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 582, in subTest\n    yield\n  File \"/testbed/tests/validators/tests.py\", line 334, in test_validators\n    validator(value)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 227, in __exit__\n    self._raiseFailure(\"{} not raised\".format(exc_name))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 164, in _raiseFailure\n    raise self.test_case.failureException(msg)\nAssertionError: ValidationError not raised\n\n======================================================================\nFAIL: test_validators (validators.tests.TestValidators) [URLValidator] (value='http://\\t[::ffff:192.9.5.5]')\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 60, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 582, in subTest\n    yield\n  File \"/testbed/tests/validators/tests.py\", line 334, in test_validators\n    validator(value)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 227, in __exit__\n    self._raiseFailure(\"{} not raised\".format(exc_name))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 164, in _raiseFailure\n    raise self.test_case.failureException(msg)\nAssertionError: ValidationError not raised\n\n----------------------------------------------------------------------\nRan 19 tests in 0.411s\n\nFAILED (failures=8)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 validators.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/validators/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 19,
          "failed": 0,
          "errors": 0,
          "duration": 7.28,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application validators\nFound 19 tests.\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_domain_whitelist (validators.tests.DeprecationTests) ... ok\ntest_domain_whitelist_access_warning (validators.tests.DeprecationTests) ... ok\ntest_domain_whitelist_set_warning (validators.tests.DeprecationTests) ... ok\ntest_whitelist (validators.tests.DeprecationTests) ... ok\ntest_whitelist_warning (validators.tests.DeprecationTests) ... ok\ntest_basic_equality (validators.tests.TestValidatorEquality) ... ok\ntest_decimal_equality (validators.tests.TestValidatorEquality) ... ok\ntest_email_equality (validators.tests.TestValidatorEquality) ... ok\ntest_file_extension_equality (validators.tests.TestValidatorEquality) ... ok\ntest_prohibit_null_characters_validator_equality (validators.tests.TestValidatorEquality) ... ok\ntest_regex_equality (validators.tests.TestValidatorEquality) ... ok\ntest_regex_equality_blank (validators.tests.TestValidatorEquality) ... ok\ntest_regex_equality_nocache (validators.tests.TestValidatorEquality) ... ok\ntest_max_length_validator_message (validators.tests.TestValidators) ... ok\ntest_message_dict (validators.tests.TestValidators) ... ok\ntest_message_list (validators.tests.TestValidators) ... ok\ntest_regex_validator_flags (validators.tests.TestValidators) ... ok\ntest_single_message (validators.tests.TestValidators) ... ok\ntest_validators (validators.tests.TestValidators) ... ok\n\n----------------------------------------------------------------------\nRan 19 tests in 0.458s\n\nOK\n",
          "test_files_run": [
            "tests/validators/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-14351",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 27.652796983718872,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 64,
          "failed": 0,
          "errors": 1,
          "duration": 8.14,
          "log_tail": "    return self.cursor.execute(sql, params)\n  File \"/testbed/django/db/backends/sqlite3/base.py\", line 416, in execute\n    return Database.Cursor.execute(self, query, params)\nsqlite3.OperationalError: sub-select returns 3 columns - expected 1\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 60, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 676, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 633, in _callTestMethod\n    method()\n  File \"/testbed/django/test/testcases.py\", line 1342, in skip_wrapper\n    return test_func(*args, **kwargs)\n  File \"/testbed/tests/aggregation_regress/tests.py\", line 1534, in test_having_subquery_select\n    self.assertEqual(set(books), {self.b1, self.b4})\n  File \"/testbed/django/db/models/query.py\", line 280, in __iter__\n    self._fetch_all()\n  File \"/testbed/django/db/models/query.py\", line 1343, in _fetch_all\n    self._result_cache = list(self._iterable_class(self))\n  File \"/testbed/django/db/models/query.py\", line 51, in __iter__\n    results = compiler.execute_sql(chunked_fetch=self.chunked_fetch, chunk_size=self.chunk_size)\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1188, in execute_sql\n    cursor.execute(sql, params)\n  File \"/testbed/django/db/backends/utils.py\", line 66, in execute\n    return self._execute_with_wrappers(sql, params, many=False, executor=self._execute)\n  File \"/testbed/django/db/backends/utils.py\", line 75, in _execute_with_wrappers\n    return executor(sql, params, many, context)\n  File \"/testbed/django/db/backends/utils.py\", line 84, in _execute\n    return self.cursor.execute(sql, params)\n  File \"/testbed/django/db/utils.py\", line 90, in __exit__\n    raise dj_exc_value.with_traceback(traceback) from exc_value\n  File \"/testbed/django/db/backends/utils.py\", line 84, in _execute\n    return self.cursor.execute(sql, params)\n  File \"/testbed/django/db/backends/sqlite3/base.py\", line 416, in execute\n    return Database.Cursor.execute(self, query, params)\ndjango.db.utils.OperationalError: sub-select returns 3 columns - expected 1\n\n----------------------------------------------------------------------\nRan 65 tests in 0.447s\n\nFAILED (errors=1, skipped=5)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 aggregation_regress.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/aggregation_regress/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 65,
          "failed": 0,
          "errors": 0,
          "duration": 7.93,
          "log_tail": "test_conditional_aggregate (aggregation_regress.tests.AggregationTests) ... ok\ntest_conditional_aggregate_on_complex_condition (aggregation_regress.tests.AggregationTests) ... ok\ntest_db_col_table (aggregation_regress.tests.AggregationTests) ... ok\ntest_decimal_aggregate_annotation_filter (aggregation_regress.tests.AggregationTests)\nFiltering on an aggregate annotation with Decimal values should work. ... ok\ntest_distinct_conditional_aggregate (aggregation_regress.tests.AggregationTests) ... ok\ntest_duplicate_alias (aggregation_regress.tests.AggregationTests) ... ok\ntest_empty (aggregation_regress.tests.AggregationTests) ... ok\ntest_empty_filter_aggregate (aggregation_regress.tests.AggregationTests) ... ok\ntest_empty_filter_count (aggregation_regress.tests.AggregationTests) ... ok\ntest_f_expression_annotation (aggregation_regress.tests.AggregationTests) ... ok\ntest_field_error (aggregation_regress.tests.AggregationTests) ... ok\ntest_field_name_conflict (aggregation_regress.tests.AggregationTests) ... ok\ntest_filtering_by_annotation_name (aggregation_regress.tests.AggregationTests) ... ok\ntest_fk_attname_conflict (aggregation_regress.tests.AggregationTests) ... ok\ntest_fobj_group_by (aggregation_regress.tests.AggregationTests)\nAn F() object referring to related column works correctly in group by. ... ok\ntest_having_group_by (aggregation_regress.tests.AggregationTests) ... ok\ntest_having_subquery_select (aggregation_regress.tests.AggregationTests) ... ok\ntest_m2m_name_conflict (aggregation_regress.tests.AggregationTests) ... ok\ntest_more (aggregation_regress.tests.AggregationTests) ... ok\ntest_more_more (aggregation_regress.tests.AggregationTests) ... ok\ntest_more_more_more (aggregation_regress.tests.AggregationTests) ... ok\ntest_name_expressions (aggregation_regress.tests.AggregationTests) ... ok\ntest_name_filters (aggregation_regress.tests.AggregationTests) ... ok\ntest_negated_aggregation (aggregation_regress.tests.AggregationTests) ... ok\ntest_none_call_before_aggregate (aggregation_regress.tests.AggregationTests) ... ok\ntest_pickle (aggregation_regress.tests.AggregationTests) ... ok\ntest_quoting_aggregate_order_by (aggregation_regress.tests.AggregationTests) ... ok\ntest_reverse_join_trimming (aggregation_regress.tests.AggregationTests) ... ok\ntest_reverse_relation_name_conflict (aggregation_regress.tests.AggregationTests) ... ok\ntest_sliced_conditional_aggregate (aggregation_regress.tests.AggregationTests) ... ok\ntest_stddev (aggregation_regress.tests.AggregationTests) ... ok\ntest_ticket_11293 (aggregation_regress.tests.AggregationTests) ... ok\ntest_ticket_11293_q_immutable (aggregation_regress.tests.AggregationTests)\nSplitting a q object to parts for where/having doesn't alter ... ok\ntest_values_annotate_values (aggregation_regress.tests.AggregationTests) ... ok\ntest_values_list_annotation_args_ordering (aggregation_regress.tests.AggregationTests)\nAnnotate *args ordering should be preserved in values_list results. ... ok\ntest_values_queryset_non_conflict (aggregation_regress.tests.AggregationTests) ... ok\n\n----------------------------------------------------------------------\nRan 65 tests in 0.431s\n\nOK (skipped=5)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/aggregation_regress/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-14373",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 28.60251498222351,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 19,
          "failed": 1,
          "errors": 0,
          "duration": 8.43,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application utils_tests\nFound 20 tests.\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_Y_format_year_before_1000 (utils_tests.test_dateformat.DateFormatTests) ... FAIL\ntest_am_pm (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_date (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_date_formats (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_dateformat (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_datetime_with_local_tzinfo (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_datetime_with_tzinfo (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_day_of_year_leap (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_empty_format (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_epoch (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_futuredates (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_invalid_time_format_specifiers (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_microsecond (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_naive_ambiguous_datetime (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_naive_datetime (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_r_format_with_non_en_locale (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_time_formats (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_timezones (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_twelve_hour_format (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_y_format_year_before_1000 (utils_tests.test_dateformat.DateFormatTests) ... ok\n\n======================================================================\nFAIL: test_Y_format_year_before_1000 (utils_tests.test_dateformat.DateFormatTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/utils_tests/test_dateformat.py\", line 183, in test_Y_format_year_before_1000\n    self.assertEqual(dateformat.format(datetime(1, 1, 1), 'Y'), '0001')\nAssertionError: '1' != '0001'\n- 1\n+ 0001\n\n\n----------------------------------------------------------------------\nRan 20 tests in 0.034s\n\nFAILED (failures=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 utils_tests.test_dateformat` failed. (See above for error)",
          "test_files_run": [
            "tests/utils_tests/test_dateformat.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 20,
          "failed": 0,
          "errors": 0,
          "duration": 6.61,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application utils_tests\nFound 20 tests.\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_Y_format_year_before_1000 (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_am_pm (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_date (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_date_formats (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_dateformat (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_datetime_with_local_tzinfo (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_datetime_with_tzinfo (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_day_of_year_leap (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_empty_format (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_epoch (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_futuredates (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_invalid_time_format_specifiers (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_microsecond (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_naive_ambiguous_datetime (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_naive_datetime (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_r_format_with_non_en_locale (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_time_formats (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_timezones (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_twelve_hour_format (utils_tests.test_dateformat.DateFormatTests) ... ok\ntest_y_format_year_before_1000 (utils_tests.test_dateformat.DateFormatTests) ... ok\n\n----------------------------------------------------------------------\nRan 20 tests in 0.022s\n\nOK\n",
          "test_files_run": [
            "tests/utils_tests/test_dateformat.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-14376",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 27.43296790122986,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 7,
          "failed": 2,
          "errors": 0,
          "duration": 7.97,
          "log_tail": "======================================================================\nFAIL: test_options_non_deprecated_keys_preferred (dbshell.test_mysql.MySqlDbshellCommandTestCase)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/dbshell/test_mysql.py\", line 83, in test_options_non_deprecated_keys_preferred\n    self.assertEqual(\nAssertionError: Tuples differ: (['my[54 chars]4', 'deprecatedoptiondbname'], {'MYSQL_PWD': 'optionpassword'}) != (['my[54 chars]4', 'optiondbname'], {'MYSQL_PWD': 'optionpassword'})\n\nFirst differing element 0:\n['mys[19 chars]er', '--host=somehost', '--port=444', 'deprecatedoptiondbname']\n['mys[19 chars]er', '--host=somehost', '--port=444', 'optiondbname']\n\n+ (['mysql', '--user=someuser', '--host=somehost', '--port=444', 'optiondbname'],\n- (['mysql',\n-   '--user=someuser',\n-   '--host=somehost',\n-   '--port=444',\n-   'deprecatedoptiondbname'],\n   {'MYSQL_PWD': 'optionpassword'})\n\n======================================================================\nFAIL: test_options_override_settings_proper_values (dbshell.test_mysql.MySqlDbshellCommandTestCase) (keys=('database', 'password'))\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/dbshell/test_mysql.py\", line 56, in test_options_override_settings_proper_values\n    self.assertEqual(\nAssertionError: Tuples differ: (['my[49 chars]--port=555', 'settingdbname'], {'MYSQL_PWD': 'optionpassword'}) != (['my[49 chars]--port=555', 'optiondbname'], {'MYSQL_PWD': 'optionpassword'})\n\nFirst differing element 0:\n['mys[14 chars]ptionuser', '--host=optionhost', '--port=555', 'settingdbname']\n['mys[14 chars]ptionuser', '--host=optionhost', '--port=555', 'optiondbname']\n\n  (['mysql',\n    '--user=optionuser',\n    '--host=optionhost',\n    '--port=555',\n-   'settingdbname'],\n?    ^^^   -\n\n+   'optiondbname'],\n?    ^^  +\n\n   {'MYSQL_PWD': 'optionpassword'})\n\n----------------------------------------------------------------------\nRan 9 tests in 0.032s\n\nFAILED (failures=2)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 dbshell.test_mysql` failed. (See above for error)",
          "test_files_run": [
            "tests/dbshell/test_mysql.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 9,
          "failed": 0,
          "errors": 0,
          "duration": 7.66,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application dbshell\nFound 9 tests.\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_basic_params_specified_in_settings (dbshell.test_mysql.MySqlDbshellCommandTestCase) ... ok\ntest_can_connect_using_sockets (dbshell.test_mysql.MySqlDbshellCommandTestCase) ... ok\ntest_crash_password_does_not_leak (dbshell.test_mysql.MySqlDbshellCommandTestCase) ... ok\ntest_fails_with_keyerror_on_incomplete_config (dbshell.test_mysql.MySqlDbshellCommandTestCase) ... ok\ntest_options_charset (dbshell.test_mysql.MySqlDbshellCommandTestCase) ... ok\ntest_options_non_deprecated_keys_preferred (dbshell.test_mysql.MySqlDbshellCommandTestCase) ... ok\ntest_options_override_settings_proper_values (dbshell.test_mysql.MySqlDbshellCommandTestCase) ... ok\ntest_parameters (dbshell.test_mysql.MySqlDbshellCommandTestCase) ... ok\ntest_ssl_certificate_is_added (dbshell.test_mysql.MySqlDbshellCommandTestCase) ... ok\n\n----------------------------------------------------------------------\nRan 9 tests in 0.033s\n\nOK\n",
          "test_files_run": [
            "tests/dbshell/test_mysql.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-14404",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 44.593239068984985,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 342,
          "failed": 2,
          "errors": 0,
          "duration": 16.78,
          "log_tail": "Ran 344 tests in 8.027s\n\nFAILED (failures=2, skipped=15)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 admin_views.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/admin_views/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 344,
          "failed": 0,
          "errors": 0,
          "duration": 17.73,
          "log_tail": "----------------------------------------------------------------------\nRan 344 tests in 8.677s\n\nOK (skipped=15)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/admin_views/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-14434",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 30.361837148666382,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 167,
          "failed": 1,
          "errors": 0,
          "duration": 10.1,
          "log_tail": "Foreign keys without database level constraint don't prevent the table ... ok\ntest_remove_constraints_capital_letters (schema.tests.SchemaTests)\n#23065 - Constraint names must be quoted if they contain capital letters. ... ok\ntest_remove_db_index_doesnt_remove_custom_indexes (schema.tests.SchemaTests)\nChanging db_index to False doesn't remove indexes from Meta.indexes. ... ok\ntest_remove_field_check_does_not_remove_meta_constraints (schema.tests.SchemaTests) ... ok\ntest_remove_field_unique_does_not_remove_meta_constraints (schema.tests.SchemaTests) ... ok\ntest_remove_index_together_does_not_remove_meta_indexes (schema.tests.SchemaTests) ... ok\ntest_remove_unique_together_does_not_remove_meta_constraints (schema.tests.SchemaTests) ... ok\ntest_rename (schema.tests.SchemaTests)\nTests simple altering of fields ... ok\ntest_rename_column_renames_deferred_sql_references (schema.tests.SchemaTests) ... skipped 'SQLite naively remakes the table on field alteration.'\ntest_rename_keep_null_status (schema.tests.SchemaTests)\nRenaming a field shouldn't affect the not null status. ... ok\ntest_rename_referenced_field (schema.tests.SchemaTests) ... ok\ntest_rename_table_renames_deferred_sql_references (schema.tests.SchemaTests) ... ok\ntest_text_field_with_db_index (schema.tests.SchemaTests) ... ok\ntest_text_field_with_db_index_to_fk (schema.tests.SchemaTests) ... ok\ntest_unique (schema.tests.SchemaTests)\nTests removing and adding unique constraints to a single column. ... ok\ntest_unique_and_reverse_m2m (schema.tests.SchemaTests)\nAlterField can modify a unique field when there's a reverse M2M ... skipped 'SQLite naively remakes the table on field alteration.'\ntest_unique_constraint (schema.tests.SchemaTests) ... FAIL\ntest_unique_constraint_field_and_expression (schema.tests.SchemaTests) ... ok\ntest_unique_name_quoting (schema.tests.SchemaTests) ... ok\ntest_unique_no_unnecessary_fk_drops (schema.tests.SchemaTests)\nIf AlterField isn't selective about dropping foreign key constraints ... skipped 'SQLite naively remakes the table on field alteration.'\ntest_unique_together (schema.tests.SchemaTests)\nTests removing and adding unique_together constraints on a model. ... ok\ntest_unique_together_with_fk (schema.tests.SchemaTests)\nTests removing and adding unique_together constraints that include ... ok\ntest_unique_together_with_fk_with_existing_index (schema.tests.SchemaTests)\nTests removing and adding unique_together constraints that include ... ok\ntest_unsupported_transactional_ddl_disallowed (schema.tests.SchemaTests) ... skipped 'Database has feature(s) can_rollback_ddl'\n\n======================================================================\nFAIL: test_unique_constraint (schema.tests.SchemaTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/schema/tests.py\", line 2211, in test_unique_constraint\n    self.assertIs(sql.references_column(table, 'name'), True)\nAssertionError: False is not True\n\n----------------------------------------------------------------------\nRan 168 tests in 2.232s\n\nFAILED (failures=1, skipped=28)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 schema.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/schema/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 168,
          "failed": 0,
          "errors": 0,
          "duration": 10.06,
          "log_tail": "test_no_db_constraint_added_during_primary_key_change (schema.tests.SchemaTests)\nWhen a primary key that's pointed to by a ForeignKey with ... ok\ntest_order_index (schema.tests.SchemaTests)\nIndexes defined with ordering (ASC/DESC) defined on column ... ok\ntest_primary_key (schema.tests.SchemaTests)\nTests altering of the primary key ... ok\ntest_referenced_field_without_constraint_rename_inside_atomic_block (schema.tests.SchemaTests)\nForeign keys without database level constraint don't prevent the field ... ok\ntest_referenced_table_without_constraint_rename_inside_atomic_block (schema.tests.SchemaTests)\nForeign keys without database level constraint don't prevent the table ... ok\ntest_remove_constraints_capital_letters (schema.tests.SchemaTests)\n#23065 - Constraint names must be quoted if they contain capital letters. ... ok\ntest_remove_db_index_doesnt_remove_custom_indexes (schema.tests.SchemaTests)\nChanging db_index to False doesn't remove indexes from Meta.indexes. ... ok\ntest_remove_field_check_does_not_remove_meta_constraints (schema.tests.SchemaTests) ... ok\ntest_remove_field_unique_does_not_remove_meta_constraints (schema.tests.SchemaTests) ... ok\ntest_remove_index_together_does_not_remove_meta_indexes (schema.tests.SchemaTests) ... ok\ntest_remove_unique_together_does_not_remove_meta_constraints (schema.tests.SchemaTests) ... ok\ntest_rename (schema.tests.SchemaTests)\nTests simple altering of fields ... ok\ntest_rename_column_renames_deferred_sql_references (schema.tests.SchemaTests) ... skipped 'SQLite naively remakes the table on field alteration.'\ntest_rename_keep_null_status (schema.tests.SchemaTests)\nRenaming a field shouldn't affect the not null status. ... ok\ntest_rename_referenced_field (schema.tests.SchemaTests) ... ok\ntest_rename_table_renames_deferred_sql_references (schema.tests.SchemaTests) ... ok\ntest_text_field_with_db_index (schema.tests.SchemaTests) ... ok\ntest_text_field_with_db_index_to_fk (schema.tests.SchemaTests) ... ok\ntest_unique (schema.tests.SchemaTests)\nTests removing and adding unique constraints to a single column. ... ok\ntest_unique_and_reverse_m2m (schema.tests.SchemaTests)\nAlterField can modify a unique field when there's a reverse M2M ... skipped 'SQLite naively remakes the table on field alteration.'\ntest_unique_constraint (schema.tests.SchemaTests) ... ok\ntest_unique_constraint_field_and_expression (schema.tests.SchemaTests) ... ok\ntest_unique_name_quoting (schema.tests.SchemaTests) ... ok\ntest_unique_no_unnecessary_fk_drops (schema.tests.SchemaTests)\nIf AlterField isn't selective about dropping foreign key constraints ... skipped 'SQLite naively remakes the table on field alteration.'\ntest_unique_together (schema.tests.SchemaTests)\nTests removing and adding unique_together constraints on a model. ... ok\ntest_unique_together_with_fk (schema.tests.SchemaTests)\nTests removing and adding unique_together constraints that include ... ok\ntest_unique_together_with_fk_with_existing_index (schema.tests.SchemaTests)\nTests removing and adding unique_together constraints that include ... ok\ntest_unsupported_transactional_ddl_disallowed (schema.tests.SchemaTests) ... skipped 'Database has feature(s) can_rollback_ddl'\n\n----------------------------------------------------------------------\nRan 168 tests in 2.607s\n\nOK (skipped=28)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/schema/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-14493",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 30.25975513458252,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 36,
          "failed": 0,
          "errors": 1,
          "duration": 10.83,
          "log_tail": "test_path_with_fragment (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_path_with_querystring (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_path_with_querystring_and_fragment (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_post_processing (staticfiles_tests.test_storage.TestCollectionManifestStorage)\npost_processing behaves correctly. ... ok\ntest_post_processing_failure (staticfiles_tests.test_storage.TestCollectionManifestStorage)\npost_processing indicates the origin of the error when it fails. ... ok\ntest_template_tag_absolute (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_template_tag_absolute_root (staticfiles_tests.test_storage.TestCollectionManifestStorage)\nLike test_template_tag_absolute, but for a file in STATIC_ROOT (#26249). ... ok\ntest_template_tag_deep_relative (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_template_tag_relative (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_template_tag_return (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_template_tag_simple_content (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_template_tag_url (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\n\n======================================================================\nERROR: test_collectstatistic_no_post_process_replaced_paths (staticfiles_tests.test_storage.TestCollectionNoPostProcessReplacedPaths)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 60, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 676, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 633, in _callTestMethod\n    method()\n  File \"/testbed/tests/staticfiles_tests/test_storage.py\", line 474, in test_collectstatistic_no_post_process_replaced_paths\n    self.run_collectstatic(verbosity=1, stdout=stdout)\n  File \"/testbed/tests/staticfiles_tests/cases.py\", line 85, in run_collectstatic\n    call_command('collectstatic', interactive=False, verbosity=verbosity,\n  File \"/testbed/django/core/management/__init__.py\", line 181, in call_command\n    return command.execute(*args, **defaults)\n  File \"/testbed/django/core/management/base.py\", line 398, in execute\n    output = self.handle(*args, **options)\n  File \"/testbed/django/contrib/staticfiles/management/commands/collectstatic.py\", line 187, in handle\n    collected = self.collect()\n  File \"/testbed/django/contrib/staticfiles/management/commands/collectstatic.py\", line 128, in collect\n    for original_path, processed_path, processed in processor:\n  File \"/testbed/django/contrib/staticfiles/storage.py\", line 431, in post_process\n    yield from super().post_process(*args, **kwargs)\n  File \"/testbed/django/contrib/staticfiles/storage.py\", line 274, in post_process\n    if substitutions:\nUnboundLocalError: local variable 'substitutions' referenced before assignment\n\n----------------------------------------------------------------------\nRan 37 tests in 3.102s\n\nFAILED (errors=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 staticfiles_tests.storage staticfiles_tests.test_storage` failed. (See above for error)",
          "test_files_run": [
            "tests/staticfiles_tests/storage.py",
            "tests/staticfiles_tests/test_storage.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 37,
          "failed": 0,
          "errors": 0,
          "duration": 10.8,
          "log_tail": "\n\ntest_collectstatistic_no_post_process_replaced_paths (staticfiles_tests.test_storage.TestCollectionNoPostProcessReplacedPaths) ... ok\ntest_hashed_name (staticfiles_tests.test_storage.TestCollectionNoneHashStorage) ... ok\ntest_collect_static_files_default_permissions (staticfiles_tests.test_storage.TestStaticFilePermissions) ... ok\ntest_collect_static_files_permissions (staticfiles_tests.test_storage.TestStaticFilePermissions) ... ok\ntest_collect_static_files_subclass_of_static_storage (staticfiles_tests.test_storage.TestStaticFilePermissions) ... ok\ntest_multi_extension_patterns (staticfiles_tests.test_storage.TestExtraPatternsStorage)\nWith storage classes having several file extension patterns, only the ... ok\ntest_template_tag_return (staticfiles_tests.test_storage.TestCollectionSimpleStorage) ... ok\ntest_template_tag_simple_content (staticfiles_tests.test_storage.TestCollectionSimpleStorage) ... ok\ntest_file_change_after_collectstatic (staticfiles_tests.test_storage.TestCollectionHashedFilesCache) ... ok\ntest_aggregating_modules (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_clear_empties_manifest (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_css_import_case_insensitive (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_import_loop (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_import_replacement (staticfiles_tests.test_storage.TestCollectionManifestStorage)\nSee #18050 ... ok\ntest_intermediate_files (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_js_source_map (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_js_source_map_sensitive (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_loaded_cache (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_manifest_does_not_exist (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_manifest_does_not_ignore_permission_error (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_manifest_exists (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_missing_entry (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_module_import (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_parse_cache (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_path_ignored_completely (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_path_with_fragment (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_path_with_querystring (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_path_with_querystring_and_fragment (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_post_processing (staticfiles_tests.test_storage.TestCollectionManifestStorage)\npost_processing behaves correctly. ... ok\ntest_post_processing_failure (staticfiles_tests.test_storage.TestCollectionManifestStorage)\npost_processing indicates the origin of the error when it fails. ... ok\ntest_template_tag_absolute (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_template_tag_absolute_root (staticfiles_tests.test_storage.TestCollectionManifestStorage)\nLike test_template_tag_absolute, but for a file in STATIC_ROOT (#26249). ... ok\ntest_template_tag_deep_relative (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_template_tag_relative (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_template_tag_return (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_template_tag_simple_content (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\ntest_template_tag_url (staticfiles_tests.test_storage.TestCollectionManifestStorage) ... ok\n\n----------------------------------------------------------------------\nRan 37 tests in 3.521s\n\nOK\n",
          "test_files_run": [
            "tests/staticfiles_tests/storage.py",
            "tests/staticfiles_tests/test_storage.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-14500",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 28.524636030197144,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 21,
          "failed": 1,
          "errors": 0,
          "duration": 9.88,
          "log_tail": "Although the MigrationExecutor interfaces allows for mixed migration ... ok\ntest_non_atomic_migration (migrations.test_executor.ExecutorTests)\nApplying a non-atomic migration works as expected. ... ok\ntest_process_callback (migrations.test_executor.ExecutorTests)\n#24129 - Tests callback process ... ok\ntest_run (migrations.test_executor.ExecutorTests)\nTests running a simple set of migrations. ... ok\ntest_run_with_squashed (migrations.test_executor.ExecutorTests)\nTests running a squashed migration from zero (should ignore what it replaces) ... ok\ntest_soft_apply (migrations.test_executor.ExecutorTests)\nTests detection of initial migrations already having been applied. ... ok\ntest_unrelated_applied_migrations_mutate_state (migrations.test_executor.ExecutorTests)\n#26647 - Unrelated applied migrations should be part of the final ... ok\ntest_unrelated_model_lookups_backwards (migrations.test_executor.ExecutorTests)\n#24123 - All models of apps being unapplied which are ... ok\ntest_unrelated_model_lookups_forwards (migrations.test_executor.ExecutorTests)\n#24123 - All models of apps already applied which are ... ok\n\n======================================================================\nFAIL: test_migrate_marks_replacement_unapplied (migrations.test_executor.ExecutorTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 60, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 676, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 633, in _callTestMethod\n    method()\n  File \"/testbed/django/test/utils.py\", line 430, in inner\n    return func(*args, **kwargs)\n  File \"/testbed/tests/migrations/test_executor.py\", line 668, in test_migrate_marks_replacement_unapplied\n    self.assertNotIn(\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 1186, in assertNotIn\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 753, in fail\n    raise self.failureException(msg)\nAssertionError: ('migrations', '0001_squashed_0002') unexpectedly found in {('admin', '0001_initial'): <Migration: Migration 0001_initial for admin>, ('admin', '0002_logentry_remove_auto_add'): <Migration: Migration 0002_logentry_remove_auto_add for admin>, ('admin', '0003_logentry_add_action_flag_choices'): <Migration: Migration 0003_logentry_add_action_flag_choices for admin>, ('sites', '0001_initial'): <Migration: Migration 0001_initial for sites>, ('sites', '0002_alter_domain_unique'): <Migration: Migration 0002_alter_domain_unique for sites>, ('migrations', '0001_squashed_0002'): <Migration: Migration 0001_squashed_0002 for migrations>}\n\n----------------------------------------------------------------------\nRan 22 tests in 2.258s\n\nFAILED (failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 migrations.test_executor` failed. (See above for error)",
          "test_files_run": [
            "tests/migrations/test_executor.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 22,
          "failed": 0,
          "errors": 0,
          "duration": 10.08,
          "log_tail": "test_minimize_rollbacks_branchy (migrations.test_executor.ExecutorUnitTests)\nMinimize rollbacks when target has multiple in-app children. ... ok\ntest_alter_id_type_with_fk (migrations.test_executor.ExecutorTests) ... ok\ntest_apply_all_replaced_marks_replacement_as_applied (migrations.test_executor.ExecutorTests)\nApplying all replaced migrations marks replacement as applied (#24628). ... ok\ntest_atomic_operation_in_non_atomic_migration (migrations.test_executor.ExecutorTests)\nAn atomic operation is properly rolled back inside a non-atomic ... ok\ntest_custom_user (migrations.test_executor.ExecutorTests)\nRegression test for #22325 - references to a custom user model defined in the ... ok\ntest_detect_soft_applied_add_field_manytomanyfield (migrations.test_executor.ExecutorTests)\nexecutor.detect_soft_applied() detects ManyToManyField tables from an ... ok\ntest_empty_plan (migrations.test_executor.ExecutorTests)\nRe-planning a full migration of a fully-migrated set doesn't ... ok\ntest_migrate_marks_replacement_applied_even_if_it_did_nothing (migrations.test_executor.ExecutorTests)\nA new squash migration will be marked as applied even if all its ... ok\ntest_migrate_marks_replacement_unapplied (migrations.test_executor.ExecutorTests) ... ok\ntest_migrations_applied_and_recorded_atomically (migrations.test_executor.ExecutorTests)\nMigrations are applied and recorded atomically. ... ok\ntest_migrations_not_applied_on_deferred_sql_failure (migrations.test_executor.ExecutorTests)\nMigrations are not recorded if deferred SQL application fails. ... ok\ntest_mixed_plan_not_supported (migrations.test_executor.ExecutorTests)\nAlthough the MigrationExecutor interfaces allows for mixed migration ... ok\ntest_non_atomic_migration (migrations.test_executor.ExecutorTests)\nApplying a non-atomic migration works as expected. ... ok\ntest_process_callback (migrations.test_executor.ExecutorTests)\n#24129 - Tests callback process ... ok\ntest_run (migrations.test_executor.ExecutorTests)\nTests running a simple set of migrations. ... ok\ntest_run_with_squashed (migrations.test_executor.ExecutorTests)\nTests running a squashed migration from zero (should ignore what it replaces) ... ok\ntest_soft_apply (migrations.test_executor.ExecutorTests)\nTests detection of initial migrations already having been applied. ... ok\ntest_unrelated_applied_migrations_mutate_state (migrations.test_executor.ExecutorTests)\n#26647 - Unrelated applied migrations should be part of the final ... ok\ntest_unrelated_model_lookups_backwards (migrations.test_executor.ExecutorTests)\n#24123 - All models of apps being unapplied which are ... ok\ntest_unrelated_model_lookups_forwards (migrations.test_executor.ExecutorTests)\n#24123 - All models of apps already applied which are ... ok\n\n----------------------------------------------------------------------\nRan 22 tests in 2.738s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/migrations/test_executor.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-14534",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 19.885016679763794,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 119,
          "failed": 2,
          "errors": 0,
          "duration": 7.87,
          "log_tail": "======================================================================\nFAIL: test_boundfield_subwidget_id_for_label (forms_tests.tests.test_forms.FormsTestCase)\nIf auto_id is provided when initializing the form, the generated ID in\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 60, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 676, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 633, in _callTestMethod\n    method()\n  File \"/testbed/tests/forms_tests/tests/test_forms.py\", line 3218, in test_boundfield_subwidget_id_for_label\n    self.assertEqual(subwidgets[0].id_for_label, 'prefix_field_0')\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 912, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 1292, in assertMultiLineEqual\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 753, in fail\n    raise self.failureException(msg)\nAssertionError: 'id_field_0' != 'prefix_field_0'\n- id_field_0\n?  ^\n+ prefix_field_0\n? ++++ ^\n\n\n======================================================================\nFAIL: test_iterable_boundfield_select (forms_tests.tests.test_forms.FormsTestCase)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 60, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 676, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 633, in _callTestMethod\n    method()\n  File \"/testbed/tests/forms_tests/tests/test_forms.py\", line 723, in test_iterable_boundfield_select\n    self.assertEqual(fields[0].id_for_label, None)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 912, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 905, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: 'id_name_0' != None\n\n----------------------------------------------------------------------\nRan 121 tests in 0.422s\n\nFAILED (failures=2)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 forms_tests.tests.test_forms` failed. (See above for error)",
          "test_files_run": [
            "tests/forms_tests/tests/test_forms.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 121,
          "failed": 0,
          "errors": 0,
          "duration": 8.8,
          "log_tail": "test_forms_with_radio (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_get_initial_for_field (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_has_error (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_help_text (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_hidden_data (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_hidden_initial_gets_id (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_hidden_widget (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_html_output_with_hidden_input_field_errors (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_html_safe (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_id_on_field (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_initial_data (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_initial_datetime_values (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_iterable_boundfield_select (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_label_has_required_css_class (forms_tests.tests.test_forms.FormsTestCase)\n#17922 - required_css_class is added to the label_tag() of required fields. ... ok\ntest_label_split_datetime_not_displayed (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_label_suffix (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_label_tag_override (forms_tests.tests.test_forms.FormsTestCase)\nBoundField label_suffix (if provided) overrides Form label_suffix ... ok\ntest_multipart_encoded_form (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_multiple_choice_checkbox (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_multiple_choice_list_data (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_multiple_hidden (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_multivalue_deep_copy (forms_tests.tests.test_forms.FormsTestCase)\n#19298 -- MultiValueField needs to override the default as it needs ... ok\ntest_multivalue_field_validation (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_multivalue_initial_data (forms_tests.tests.test_forms.FormsTestCase)\n#23674 -- invalid initial data should not break form.changed_data() ... ok\ntest_multivalue_optional_subfields (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_only_hidden_fields (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_optional_data (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_specifying_labels (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_subclassing_forms (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_templates_with_forms (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_unbound_form (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_unicode_values (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_update_error_dict (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_use_required_attribute_false (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_use_required_attribute_true (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_validating_multiple_fields (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_validators_independence (forms_tests.tests.test_forms.FormsTestCase)\nThe list of form field validators can be modified without polluting ... ok\ntest_various_boolean_values (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_widget_output (forms_tests.tests.test_forms.FormsTestCase) ... ok\n\n----------------------------------------------------------------------\nRan 121 tests in 0.357s\n\nOK\n",
          "test_files_run": [
            "tests/forms_tests/tests/test_forms.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-14539",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 16.787134885787964,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 15,
          "failed": 1,
          "errors": 0,
          "duration": 6.66,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application utils_tests\nFound 16 test(s).\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_conditional_escape (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_escape (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_escapejs (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_format_html (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_html_safe (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_html_safe_defines_html_error (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_html_safe_doesnt_define_str (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_html_safe_subclass (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_json_script (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_linebreaks (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_smart_urlquote (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_strip_spaces_between_tags (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_strip_tags (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_strip_tags_files (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_urlize (utils_tests.test_html.TestUtilsHtml) ... test_urlize_unchanged_inputs (utils_tests.test_html.TestUtilsHtml) ... ok\n\n======================================================================\nFAIL: test_urlize (utils_tests.test_html.TestUtilsHtml) (value='Search for google.com/?q=1&lt! and see.')\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/utils_tests/test_html.py\", line 265, in test_urlize\n    self.assertEqual(urlize(value), output)\nAssertionError: 'Sear[15 chars]\"http://google.com/?q=1%3C\">google.com/?q=1&lt</a>lt! and see.' != 'Sear[15 chars]\"http://google.com/?q=1%3C\">google.com/?q=1&lt</a>! and see.'\n- Search for <a href=\"http://google.com/?q=1%3C\">google.com/?q=1&lt</a>lt! and see.\n?                                                                      --\n+ Search for <a href=\"http://google.com/?q=1%3C\">google.com/?q=1&lt</a>! and see.\n\n\n----------------------------------------------------------------------\nRan 16 tests in 0.270s\n\nFAILED (failures=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 utils_tests.test_html` failed. (See above for error)",
          "test_files_run": [
            "tests/utils_tests/test_html.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 16,
          "failed": 0,
          "errors": 0,
          "duration": 8.5,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application utils_tests\nFound 16 test(s).\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_conditional_escape (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_escape (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_escapejs (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_format_html (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_html_safe (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_html_safe_defines_html_error (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_html_safe_doesnt_define_str (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_html_safe_subclass (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_json_script (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_linebreaks (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_smart_urlquote (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_strip_spaces_between_tags (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_strip_tags (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_strip_tags_files (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_urlize (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_urlize_unchanged_inputs (utils_tests.test_html.TestUtilsHtml) ... ok\n\n----------------------------------------------------------------------\nRan 16 tests in 0.299s\n\nOK\n",
          "test_files_run": [
            "tests/utils_tests/test_html.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-14559",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 19.258938789367676,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 23,
          "failed": 3,
          "errors": 0,
          "duration": 8.35,
          "log_tail": "Destroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 queries.test_bulk_update` failed. (See above for error)",
          "test_files_run": [
            "tests/queries/test_bulk_update.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 26,
          "failed": 0,
          "errors": 0,
          "duration": 9.8,
          "log_tail": "Destroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/queries/test_bulk_update.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-14580",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 16.10532307624817,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 49,
          "failed": 1,
          "errors": 0,
          "duration": 6.76,
          "log_tail": "test_serialize_settings (migrations.test_writer.WriterTests) ... ok\ntest_serialize_strings (migrations.test_writer.WriterTests) ... ok\ntest_serialize_timedelta (migrations.test_writer.WriterTests) ... ok\ntest_serialize_type_model (migrations.test_writer.WriterTests) ... FAIL\ntest_serialize_type_none (migrations.test_writer.WriterTests) ... ok\ntest_serialize_unbound_method_reference (migrations.test_writer.WriterTests)\nAn unbound method used within a class body can be serialized. ... ok\ntest_serialize_uuid (migrations.test_writer.WriterTests) ... ok\ntest_simple_migration (migrations.test_writer.WriterTests)\nTests serializing a simple migration. ... ok\ntest_sorted_imports (migrations.test_writer.WriterTests)\n#24155 - Tests ordering of imports. ... ok\n\n======================================================================\nFAIL: test_serialize_type_model (migrations.test_writer.WriterTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 60, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 676, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 633, in _callTestMethod\n    method()\n  File \"/testbed/tests/migrations/test_writer.py\", line 663, in test_serialize_type_model\n    self.assertSerializedResultEqual(\n  File \"/testbed/tests/migrations/test_writer.py\", line 221, in assertSerializedResultEqual\n    self.assertEqual(MigrationWriter.serialize(value), target)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 912, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 1129, in assertTupleEqual\n    self.assertSequenceEqual(tuple1, tuple2, msg, seq_type=tuple)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 1100, in assertSequenceEqual\n    self.fail(msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 753, in fail\n    raise self.failureException(msg)\nAssertionError: Tuples differ: (\"('models.Model', set())\", set()) != (\"('models.Model', {'from django.db import models'})\", set())\n\nFirst differing element 0:\n\"('models.Model', set())\"\n\"('models.Model', {'from django.db import models'})\"\n\n- (\"('models.Model', set())\", set())\n+ (\"('models.Model', {'from django.db import models'})\", set())\n\n----------------------------------------------------------------------\nRan 50 tests in 0.200s\n\nFAILED (failures=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 migrations.test_writer` failed. (See above for error)",
          "test_files_run": [
            "tests/migrations/test_writer.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 50,
          "failed": 0,
          "errors": 0,
          "duration": 8.11,
          "log_tail": "test_register_non_serializer (migrations.test_writer.WriterTests) ... ok\ntest_register_serializer (migrations.test_writer.WriterTests) ... ok\ntest_serialize_builtin_types (migrations.test_writer.WriterTests) ... ok\ntest_serialize_builtins (migrations.test_writer.WriterTests) ... ok\ntest_serialize_choices (migrations.test_writer.WriterTests) ... ok\ntest_serialize_class_based_validators (migrations.test_writer.WriterTests)\nTicket #22943: Test serialization of class-based validators, including ... ok\ntest_serialize_collections (migrations.test_writer.WriterTests) ... ok\ntest_serialize_compiled_regex (migrations.test_writer.WriterTests)\nMake sure compiled regex can be serialized. ... ok\ntest_serialize_constants (migrations.test_writer.WriterTests) ... ok\ntest_serialize_datetime (migrations.test_writer.WriterTests) ... ok\ntest_serialize_empty_nonempty_tuple (migrations.test_writer.WriterTests)\nTicket #22679: makemigrations generates invalid code for (an empty ... ok\ntest_serialize_enums (migrations.test_writer.WriterTests) ... ok\ntest_serialize_fields (migrations.test_writer.WriterTests) ... ok\ntest_serialize_frozensets (migrations.test_writer.WriterTests) ... ok\ntest_serialize_functions (migrations.test_writer.WriterTests) ... ok\ntest_serialize_functools_partial (migrations.test_writer.WriterTests) ... ok\ntest_serialize_functools_partialmethod (migrations.test_writer.WriterTests) ... ok\ntest_serialize_iterators (migrations.test_writer.WriterTests) ... ok\ntest_serialize_lazy_objects (migrations.test_writer.WriterTests) ... ok\ntest_serialize_local_function_reference (migrations.test_writer.WriterTests)\nA reference in a local scope can't be serialized. ... ok\ntest_serialize_managers (migrations.test_writer.WriterTests) ... ok\ntest_serialize_multiline_strings (migrations.test_writer.WriterTests) ... ok\ntest_serialize_nested_class (migrations.test_writer.WriterTests) ... ok\ntest_serialize_numbers (migrations.test_writer.WriterTests) ... ok\ntest_serialize_path_like (migrations.test_writer.WriterTests) ... ok\ntest_serialize_pathlib (migrations.test_writer.WriterTests) ... ok\ntest_serialize_range (migrations.test_writer.WriterTests) ... ok\ntest_serialize_set (migrations.test_writer.WriterTests) ... ok\ntest_serialize_settings (migrations.test_writer.WriterTests) ... ok\ntest_serialize_strings (migrations.test_writer.WriterTests) ... ok\ntest_serialize_timedelta (migrations.test_writer.WriterTests) ... ok\ntest_serialize_type_model (migrations.test_writer.WriterTests) ... ok\ntest_serialize_type_none (migrations.test_writer.WriterTests) ... ok\ntest_serialize_unbound_method_reference (migrations.test_writer.WriterTests)\nAn unbound method used within a class body can be serialized. ... ok\ntest_serialize_uuid (migrations.test_writer.WriterTests) ... ok\ntest_simple_migration (migrations.test_writer.WriterTests)\nTests serializing a simple migration. ... ok\ntest_sorted_imports (migrations.test_writer.WriterTests)\n#24155 - Tests ordering of imports. ... ok\n\n----------------------------------------------------------------------\nRan 50 tests in 0.110s\n\nOK\n",
          "test_files_run": [
            "tests/migrations/test_writer.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-14608",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 35.37233805656433,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 413,
          "failed": 4,
          "errors": 0,
          "duration": 18.25,
          "log_tail": "Destroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 admin_views.tests forms_tests.tests.test_formsets` failed. (See above for error)",
          "test_files_run": [
            "tests/admin_views/tests.py",
            "tests/forms_tests/tests/test_formsets.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 417,
          "failed": 0,
          "errors": 0,
          "duration": 15.94,
          "log_tail": "Destroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/admin_views/tests.py",
            "tests/forms_tests/tests/test_formsets.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-14631",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 18.168546676635742,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 118,
          "failed": 2,
          "errors": 0,
          "duration": 7.16,
          "log_tail": "======================================================================\nFAIL: test_datetime_clean_disabled_callable_initial_bound_field (forms_tests.tests.test_forms.FormsTestCase)\nThe cleaned value for a form with a disabled DateTimeField and callable\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 60, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 676, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 633, in _callTestMethod\n    method()\n  File \"/testbed/tests/forms_tests/tests/test_forms.py\", line 2155, in test_datetime_clean_disabled_callable_initial_bound_field\n    self.assertEqual(cleaned, bf.initial)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 912, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 905, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: datetime.datetime(2006, 10, 25, 14, 30, 46) != datetime.datetime(2006, 10, 25, 14, 30, 47)\n\n======================================================================\nFAIL: test_datetime_clean_disabled_callable_initial_microseconds (forms_tests.tests.test_forms.FormsTestCase)\nCleaning a form with a disabled DateTimeField and callable initial\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 60, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 676, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 633, in _callTestMethod\n    method()\n  File \"/testbed/tests/forms_tests/tests/test_forms.py\", line 2141, in test_datetime_clean_disabled_callable_initial_microseconds\n    self.assertEqual(form.cleaned_data, {\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 912, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 1211, in assertDictEqual\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 753, in fail\n    raise self.failureException(msg)\nAssertionError: {'dt': datetime.datetime(2006, 10, 25, 14, 30, 46, 123456)} != {'dt': datetime.datetime(2006, 10, 25, 14, 30, 46)}\n- {'dt': datetime.datetime(2006, 10, 25, 14, 30, 46, 123456)}\n?                                                 --------\n\n+ {'dt': datetime.datetime(2006, 10, 25, 14, 30, 46)}\n\n----------------------------------------------------------------------\nRan 120 tests in 0.383s\n\nFAILED (failures=2)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 forms_tests.tests.test_forms` failed. (See above for error)",
          "test_files_run": [
            "tests/forms_tests/tests/test_forms.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 120,
          "failed": 0,
          "errors": 0,
          "duration": 8.8,
          "log_tail": "test_forms_with_radio (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_get_initial_for_field (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_has_error (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_help_text (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_hidden_data (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_hidden_initial_gets_id (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_hidden_widget (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_html_output_with_hidden_input_field_errors (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_html_safe (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_id_on_field (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_initial_data (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_initial_datetime_values (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_iterable_boundfield_select (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_label_has_required_css_class (forms_tests.tests.test_forms.FormsTestCase)\n#17922 - required_css_class is added to the label_tag() of required fields. ... ok\ntest_label_split_datetime_not_displayed (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_label_suffix (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_label_tag_override (forms_tests.tests.test_forms.FormsTestCase)\nBoundField label_suffix (if provided) overrides Form label_suffix ... ok\ntest_multipart_encoded_form (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_multiple_choice_checkbox (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_multiple_choice_list_data (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_multiple_hidden (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_multivalue_deep_copy (forms_tests.tests.test_forms.FormsTestCase)\n#19298 -- MultiValueField needs to override the default as it needs ... ok\ntest_multivalue_field_validation (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_multivalue_initial_data (forms_tests.tests.test_forms.FormsTestCase)\n#23674 -- invalid initial data should not break form.changed_data() ... ok\ntest_multivalue_optional_subfields (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_only_hidden_fields (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_optional_data (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_specifying_labels (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_subclassing_forms (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_templates_with_forms (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_unbound_form (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_unicode_values (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_update_error_dict (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_use_required_attribute_false (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_use_required_attribute_true (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_validating_multiple_fields (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_validators_independence (forms_tests.tests.test_forms.FormsTestCase)\nThe list of form field validators can be modified without polluting ... ok\ntest_various_boolean_values (forms_tests.tests.test_forms.FormsTestCase) ... ok\ntest_widget_output (forms_tests.tests.test_forms.FormsTestCase) ... ok\n\n----------------------------------------------------------------------\nRan 120 tests in 0.357s\n\nOK\n",
          "test_files_run": [
            "tests/forms_tests/tests/test_forms.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-14672",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 18.046897172927856,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 7.91,
          "log_tail": "Destroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nTraceback (most recent call last):\n  File \"runtests.py\", line 659, in <module>\n    failures = django_tests(\n  File \"runtests.py\", line 385, in django_tests\n    failures = test_runner.run_tests(test_labels)\n  File \"/testbed/django/test/runner.py\", line 899, in run_tests\n    self.run_checks(databases)\n  File \"/testbed/django/test/runner.py\", line 818, in run_checks\n    call_command('check', verbosity=self.verbosity, databases=databases)\n  File \"/testbed/django/core/management/__init__.py\", line 181, in call_command\n    return command.execute(*args, **defaults)\n  File \"/testbed/django/core/management/base.py\", line 398, in execute\n    output = self.handle(*args, **options)\n  File \"/testbed/django/core/management/commands/check.py\", line 63, in handle\n    self.check(\n  File \"/testbed/django/core/management/base.py\", line 419, in check\n    all_issues = checks.run_checks(\n  File \"/testbed/django/core/checks/registry.py\", line 77, in run_checks\n    new_errors = check(app_configs=app_configs, databases=databases)\n  File \"/testbed/django/core/checks/model_checks.py\", line 34, in check_all_models\n    errors.extend(model.check(**kwargs))\n  File \"/testbed/django/db/models/base.py\", line 1281, in check\n    *cls._check_field_name_clashes(),\n  File \"/testbed/django/db/models/base.py\", line 1471, in _check_field_name_clashes\n    if f not in used_fields:\n  File \"/testbed/django/db/models/fields/reverse_related.py\", line 139, in __hash__\n    return hash(self.identity)\nTypeError: unhashable type: 'list'\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 invalid_models_tests.test_models m2m_through.models m2m_through.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/invalid_models_tests/test_models.py",
            "tests/m2m_through/models.py",
            "tests/m2m_through/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 178,
          "failed": 0,
          "errors": 0,
          "duration": 8.94,
          "log_tail": "Destroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/invalid_models_tests/test_models.py",
            "tests/m2m_through/models.py",
            "tests/m2m_through/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-14725",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 18.747193813323975,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 64,
          "failed": 0,
          "errors": 3,
          "duration": 8.74,
          "log_tail": "----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/tests/model_formsets/tests.py\", line 1776, in test_edit_only\n    AuthorFormSet = modelformset_factory(Author, fields='__all__', edit_only=True)\nTypeError: modelformset_factory() got an unexpected keyword argument 'edit_only'\n\n======================================================================\nERROR: test_edit_only_inlineformset_factory (model_formsets.tests.ModelFormsetTest)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/tests/model_formsets/tests.py\", line 1806, in test_edit_only_inlineformset_factory\n    AuthorFormSet = inlineformset_factory(\nTypeError: inlineformset_factory() got an unexpected keyword argument 'edit_only'\n\n======================================================================\nERROR: test_edit_only_object_outside_of_queryset (model_formsets.tests.ModelFormsetTest)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/tests/model_formsets/tests.py\", line 1835, in test_edit_only_object_outside_of_queryset\n    AuthorFormSet = modelformset_factory(Author, fields='__all__', edit_only=True)\nTypeError: modelformset_factory() got an unexpected keyword argument 'edit_only'\n\n----------------------------------------------------------------------\nRan 67 tests in 1.025s\n\nFAILED (errors=3)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 model_formsets.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/model_formsets/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 67,
          "failed": 0,
          "errors": 0,
          "duration": 8.52,
          "log_tail": "test_model_formset_with_custom_pk (model_formsets.tests.ModelFormsetTest) ... ok\ntest_model_formset_with_initial_model_instance (model_formsets.tests.ModelFormsetTest) ... ok\ntest_model_formset_with_initial_queryset (model_formsets.tests.ModelFormsetTest) ... ok\ntest_model_inheritance (model_formsets.tests.ModelFormsetTest) ... ok\ntest_modelformset_factory_without_fields (model_formsets.tests.ModelFormsetTest)\nRegression for #19733 ... ok\ntest_modelformset_min_num_equals_max_num_less_than (model_formsets.tests.ModelFormsetTest) ... ok\ntest_modelformset_min_num_equals_max_num_more_than (model_formsets.tests.ModelFormsetTest) ... ok\ntest_modelformset_validate_max_flag (model_formsets.tests.ModelFormsetTest) ... ok\ntest_prevent_change_outer_model_and_create_invalid_data (model_formsets.tests.ModelFormsetTest) ... ok\ntest_prevent_duplicates_from_with_the_same_formset (model_formsets.tests.ModelFormsetTest) ... ok\ntest_simple_save (model_formsets.tests.ModelFormsetTest) ... ok\ntest_unique_together_validation (model_formsets.tests.ModelFormsetTest) ... ok\ntest_unique_together_with_inlineformset_factory (model_formsets.tests.ModelFormsetTest) ... ok\ntest_unique_true_enforces_max_num_one (model_formsets.tests.ModelFormsetTest) ... ok\ntest_unique_validation (model_formsets.tests.ModelFormsetTest) ... ok\ntest_validation_with_child_model_without_id (model_formsets.tests.ModelFormsetTest) ... ok\ntest_validation_with_invalid_id (model_formsets.tests.ModelFormsetTest) ... ok\ntest_validation_with_nonexistent_id (model_formsets.tests.ModelFormsetTest) ... ok\ntest_validation_without_id (model_formsets.tests.ModelFormsetTest) ... ok\ntest_inlineformset_factory_absolute_max (model_formsets.tests.TestModelFormsetOverridesTroughFormMeta) ... ok\ntest_inlineformset_factory_absolute_max_with_max_num (model_formsets.tests.TestModelFormsetOverridesTroughFormMeta) ... ok\ntest_inlineformset_factory_can_delete_extra (model_formsets.tests.TestModelFormsetOverridesTroughFormMeta) ... ok\ntest_inlineformset_factory_can_not_delete_extra (model_formsets.tests.TestModelFormsetOverridesTroughFormMeta) ... ok\ntest_inlineformset_factory_error_messages_overrides (model_formsets.tests.TestModelFormsetOverridesTroughFormMeta) ... ok\ntest_inlineformset_factory_field_class_overrides (model_formsets.tests.TestModelFormsetOverridesTroughFormMeta) ... ok\ntest_inlineformset_factory_help_text_overrides (model_formsets.tests.TestModelFormsetOverridesTroughFormMeta) ... ok\ntest_inlineformset_factory_labels_overrides (model_formsets.tests.TestModelFormsetOverridesTroughFormMeta) ... ok\ntest_inlineformset_factory_passes_renderer (model_formsets.tests.TestModelFormsetOverridesTroughFormMeta) ... ok\ntest_inlineformset_factory_widgets (model_formsets.tests.TestModelFormsetOverridesTroughFormMeta) ... ok\ntest_modelformset_factory_absolute_max (model_formsets.tests.TestModelFormsetOverridesTroughFormMeta) ... ok\ntest_modelformset_factory_absolute_max_with_max_num (model_formsets.tests.TestModelFormsetOverridesTroughFormMeta) ... ok\ntest_modelformset_factory_can_delete_extra (model_formsets.tests.TestModelFormsetOverridesTroughFormMeta) ... ok\ntest_modelformset_factory_disable_delete_extra (model_formsets.tests.TestModelFormsetOverridesTroughFormMeta) ... ok\ntest_modelformset_factory_error_messages_overrides (model_formsets.tests.TestModelFormsetOverridesTroughFormMeta) ... ok\ntest_modelformset_factory_field_class_overrides (model_formsets.tests.TestModelFormsetOverridesTroughFormMeta) ... ok\ntest_modelformset_factory_help_text_overrides (model_formsets.tests.TestModelFormsetOverridesTroughFormMeta) ... ok\ntest_modelformset_factory_labels_overrides (model_formsets.tests.TestModelFormsetOverridesTroughFormMeta) ... ok\ntest_modelformset_factory_passes_renderer (model_formsets.tests.TestModelFormsetOverridesTroughFormMeta) ... ok\ntest_modelformset_factory_widgets (model_formsets.tests.TestModelFormsetOverridesTroughFormMeta) ... ok\n\n----------------------------------------------------------------------\nRan 67 tests in 0.568s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/model_formsets/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-14752",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 20.266183853149414,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 18,
          "failed": 1,
          "errors": 0,
          "duration": 9.14,
          "log_tail": "Users require the change permission for the related model to the ... ok\ntest_limit_choices_to (admin_views.test_autocomplete_view.AutocompleteJsonViewTests) ... ok\ntest_missing_search_fields (admin_views.test_autocomplete_view.AutocompleteJsonViewTests) ... ok\ntest_must_be_logged_in (admin_views.test_autocomplete_view.AutocompleteJsonViewTests) ... ok\ntest_search_use_distinct (admin_views.test_autocomplete_view.AutocompleteJsonViewTests)\nSearching across model relations use QuerySet.distinct() to avoid ... ok\ntest_serialize_result (admin_views.test_autocomplete_view.AutocompleteJsonViewTests) ... FAIL\ntest_success (admin_views.test_autocomplete_view.AutocompleteJsonViewTests) ... ok\ntest_to_field_resolution_with_fk_pk (admin_views.test_autocomplete_view.AutocompleteJsonViewTests) ... ok\ntest_to_field_resolution_with_mti (admin_views.test_autocomplete_view.AutocompleteJsonViewTests)\nto_field resolution should correctly resolve for target models using ... ok\n\n======================================================================\nFAIL: test_serialize_result (admin_views.test_autocomplete_view.AutocompleteJsonViewTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 60, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 676, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 633, in _callTestMethod\n    method()\n  File \"/testbed/tests/admin_views/test_autocomplete_view.py\", line 312, in test_serialize_result\n    self.assertEqual(data, {\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 912, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 1211, in assertDictEqual\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 753, in fail\n    raise self.failureException(msg)\nAssertionError: {'res[35 chars]on 1'}, {'id': '2', 'text': 'Question 2'}], 'p[23 chars]lse}} != {'res[35 chars]on 1', 'posted': '2021-08-09'}, {'id': '2', 't[71 chars]lse}}\n  {'pagination': {'more': False},\n-  'results': [{'id': '1', 'text': 'Question 1'},\n+  'results': [{'id': '1', 'posted': '2021-08-09', 'text': 'Question 1'},\n?                         ++++++++++++++++++++++++\n\n-              {'id': '2', 'text': 'Question 2'}]}\n+              {'id': '2', 'posted': '2021-08-07', 'text': 'Question 2'}]}\n?                         ++++++++++++++++++++++++\n\n\n----------------------------------------------------------------------\nRan 19 tests in 1.267s\n\nFAILED (failures=1, skipped=3)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 admin_views.test_autocomplete_view` failed. (See above for error)",
          "test_files_run": [
            "tests/admin_views/test_autocomplete_view.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 19,
          "failed": 0,
          "errors": 0,
          "duration": 9.57,
          "log_tail": "    Creating table admin_views_parentwithuuidpk\n    Creating table admin_views_relatedwithuuidpkmodel\n    Creating table admin_views_author\n    Creating table admin_views_authorship\n    Creating table admin_views_readonlyrelatedfield\n    Running deferred SQL...\nRunning migrations:\n  Applying admin.0001_initial... OK\n  Applying admin.0002_logentry_remove_auto_add... OK\n  Applying admin.0003_logentry_add_action_flag_choices... OK\n  Applying sites.0001_initial... OK\n  Applying sites.0002_alter_domain_unique... OK\nSystem check identified no issues (1 silenced).\n\n\nCreating test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\ntest_inline_add_another_widgets (admin_views.test_autocomplete_view.SeleniumTests) ... skipped 'No browsers specified.'\ntest_select (admin_views.test_autocomplete_view.SeleniumTests) ... skipped 'No browsers specified.'\ntest_select_multiple (admin_views.test_autocomplete_view.SeleniumTests) ... skipped 'No browsers specified.'\ntest_custom_to_field (admin_views.test_autocomplete_view.AutocompleteJsonViewTests) ... ok\ntest_custom_to_field_custom_pk (admin_views.test_autocomplete_view.AutocompleteJsonViewTests) ... ok\ntest_custom_to_field_permission_denied (admin_views.test_autocomplete_view.AutocompleteJsonViewTests) ... ok\ntest_field_does_not_allowed (admin_views.test_autocomplete_view.AutocompleteJsonViewTests) ... ok\ntest_field_does_not_exist (admin_views.test_autocomplete_view.AutocompleteJsonViewTests) ... ok\ntest_field_no_related_field (admin_views.test_autocomplete_view.AutocompleteJsonViewTests) ... ok\ntest_get_paginator (admin_views.test_autocomplete_view.AutocompleteJsonViewTests)\nSearch results are paginated. ... ok\ntest_has_view_or_change_permission_required (admin_views.test_autocomplete_view.AutocompleteJsonViewTests)\nUsers require the change permission for the related model to the ... ok\ntest_limit_choices_to (admin_views.test_autocomplete_view.AutocompleteJsonViewTests) ... ok\ntest_missing_search_fields (admin_views.test_autocomplete_view.AutocompleteJsonViewTests) ... ok\ntest_must_be_logged_in (admin_views.test_autocomplete_view.AutocompleteJsonViewTests) ... ok\ntest_search_use_distinct (admin_views.test_autocomplete_view.AutocompleteJsonViewTests)\nSearching across model relations use QuerySet.distinct() to avoid ... ok\ntest_serialize_result (admin_views.test_autocomplete_view.AutocompleteJsonViewTests) ... ok\ntest_success (admin_views.test_autocomplete_view.AutocompleteJsonViewTests) ... ok\ntest_to_field_resolution_with_fk_pk (admin_views.test_autocomplete_view.AutocompleteJsonViewTests) ... ok\ntest_to_field_resolution_with_mti (admin_views.test_autocomplete_view.AutocompleteJsonViewTests)\nto_field resolution should correctly resolve for target models using ... ok\n\n----------------------------------------------------------------------\nRan 19 tests in 0.785s\n\nOK (skipped=3)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/admin_views/test_autocomplete_view.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-14765",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 16.499330043792725,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 64,
          "failed": 1,
          "errors": 0,
          "duration": 7.3,
          "log_tail": "test_ignore_order_wrt (migrations.test_state.StateTests)\nMakes sure ProjectState doesn't include OrderWrt fields when ... ok\ntest_manager_refer_correct_model_version (migrations.test_state.StateTests)\n#24147 - Managers refer to the correct version of a ... ok\ntest_no_duplicate_managers (migrations.test_state.StateTests)\nWhen a manager is added with `use_in_migrations = True` and a parent ... ok\ntest_real_apps (migrations.test_state.StateTests)\nIncluding real apps can resolve dangling FK errors. ... ok\ntest_real_apps_non_set (migrations.test_state.StateTests) ... FAIL\ntest_reference_mixed_case_app_label (migrations.test_state.StateTests) ... ok\ntest_reload_model_relationship_consistency (migrations.test_state.StateTests) ... ok\ntest_reload_related_model_on_non_relational_fields (migrations.test_state.StateTests)\nThe model is reloaded even on changes that are not involved in ... ok\ntest_remove_relations (migrations.test_state.StateTests)\n#24225 - Relations between models are updated while ... ok\ntest_render (migrations.test_state.StateTests)\nTests rendering a ProjectState into an Apps. ... ok\ntest_render_model_inheritance (migrations.test_state.StateTests) ... ok\ntest_render_model_with_multiple_inheritance (migrations.test_state.StateTests) ... ok\ntest_render_project_dependencies (migrations.test_state.StateTests)\nThe ProjectState render method correctly renders models ... ok\ntest_render_unique_app_labels (migrations.test_state.StateTests)\nThe ProjectState render method doesn't raise an ... ok\ntest_self_relation (migrations.test_state.StateTests)\n#24513 - Modifying an object pointing to itself would cause it to be ... ok\n\n======================================================================\nFAIL: test_real_apps_non_set (migrations.test_state.StateTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 60, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 676, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 633, in _callTestMethod\n    method()\n  File \"/testbed/tests/migrations/test_state.py\", line 929, in test_real_apps_non_set\n    ProjectState(real_apps=['contenttypes'])\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 227, in __exit__\n    self._raiseFailure(\"{} not raised\".format(exc_name))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.8/unittest/case.py\", line 164, in _raiseFailure\n    raise self.test_case.failureException(msg)\nAssertionError: AssertionError not raised\n\n----------------------------------------------------------------------\nRan 65 tests in 0.199s\n\nFAILED (failures=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 migrations.test_state` failed. (See above for error)",
          "test_files_run": [
            "tests/migrations/test_state.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 65,
          "failed": 0,
          "errors": 0,
          "duration": 7.83,
          "log_tail": "test_two_sided (migrations.test_state.RelatedModelsTests) ... ok\ntest_unrelated (migrations.test_state.RelatedModelsTests) ... ok\ntest_add_relations (migrations.test_state.StateTests)\n#24573 - Adding relations to existing models should reload the ... ok\ntest_apps_bulk_update (migrations.test_state.StateTests)\nStateApps.bulk_update() should update apps.ready to False and reset ... ok\ntest_choices_iterator (migrations.test_state.StateTests)\n#24483 - ProjectState.from_apps should not destructively consume ... ok\ntest_create (migrations.test_state.StateTests)\nTests making a ProjectState from an Apps ... ok\ntest_custom_base_manager (migrations.test_state.StateTests) ... ok\ntest_custom_default_manager (migrations.test_state.StateTests) ... ok\ntest_custom_default_manager_added_to_the_model_state (migrations.test_state.StateTests)\nWhen the default manager of the model is a custom manager, ... ok\ntest_custom_default_manager_named_objects_with_false_migration_flag (migrations.test_state.StateTests)\nWhen a manager is added with a name of 'objects' but it does not ... ok\ntest_dangling_references_throw_error (migrations.test_state.StateTests) ... ok\ntest_equality (migrations.test_state.StateTests)\n== and != are implemented correctly. ... ok\ntest_ignore_order_wrt (migrations.test_state.StateTests)\nMakes sure ProjectState doesn't include OrderWrt fields when ... ok\ntest_manager_refer_correct_model_version (migrations.test_state.StateTests)\n#24147 - Managers refer to the correct version of a ... ok\ntest_no_duplicate_managers (migrations.test_state.StateTests)\nWhen a manager is added with `use_in_migrations = True` and a parent ... ok\ntest_real_apps (migrations.test_state.StateTests)\nIncluding real apps can resolve dangling FK errors. ... ok\ntest_real_apps_non_set (migrations.test_state.StateTests) ... ok\ntest_reference_mixed_case_app_label (migrations.test_state.StateTests) ... ok\ntest_reload_model_relationship_consistency (migrations.test_state.StateTests) ... ok\ntest_reload_related_model_on_non_relational_fields (migrations.test_state.StateTests)\nThe model is reloaded even on changes that are not involved in ... ok\ntest_remove_relations (migrations.test_state.StateTests)\n#24225 - Relations between models are updated while ... ok\ntest_render (migrations.test_state.StateTests)\nTests rendering a ProjectState into an Apps. ... ok\ntest_render_model_inheritance (migrations.test_state.StateTests) ... ok\ntest_render_model_with_multiple_inheritance (migrations.test_state.StateTests) ... ok\ntest_render_project_dependencies (migrations.test_state.StateTests)\nThe ProjectState render method correctly renders models ... ok\ntest_render_unique_app_labels (migrations.test_state.StateTests)\nThe ProjectState render method doesn't raise an ... ok\ntest_self_relation (migrations.test_state.StateTests)\n#24513 - Modifying an object pointing to itself would cause it to be ... ok\n\n----------------------------------------------------------------------\nRan 65 tests in 0.097s\n\nOK\n",
          "test_files_run": [
            "tests/migrations/test_state.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-14771",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 18.836055040359497,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 80,
          "failed": 1,
          "errors": 0,
          "duration": 8.91,
          "log_tail": "test_paths_are_pathlib_instances (utils_tests.test_autoreload.TestIterModulesAndFiles) ... ok\ntest_weakref_in_sys_module (utils_tests.test_autoreload.TestIterModulesAndFiles)\niter_all_python_module_file() ignores weakref modules. ... ok\ntest_zip_reload (utils_tests.test_autoreload.TestIterModulesAndFiles)\nModules imported from zipped files have their archive location included ... ok\n\n======================================================================\nFAIL: test_xoptions (utils_tests.test_autoreload.TestChildArguments)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/mock.py\", line 1336, in patched\n    return func(*newargs, **newkeywargs)\n  File \"/testbed/tests/utils_tests/test_autoreload.py\", line 214, in test_xoptions\n    self.assertEqual(\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 837, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 1043, in assertListEqual\n    self.assertSequenceEqual(list1, list2, msg, seq_type=list)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 1025, in assertSequenceEqual\n    self.fail(msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 676, in fail\n    raise self.failureException(msg)\nAssertionError: Lists differ: ['/op[35 chars]n', '/testbed/tests/utils_tests/test_autoreloa[14 chars]ver'] != ['/op[35 chars]n', '-Xutf8', '-Xa=b', '/testbed/tests/utils_t[33 chars]ver']\n\nFirst differing element 1:\n'/testbed/tests/utils_tests/test_autoreload.py'\n'-Xutf8'\n\nSecond list contains 2 additional elements.\nFirst extra element 3:\n'/testbed/tests/utils_tests/test_autoreload.py'\n\n  ['/opt/miniconda3/envs/testbed/bin/python',\n+  '-Xutf8',\n+  '-Xa=b',\n   '/testbed/tests/utils_tests/test_autoreload.py',\n   'runserver']\n\n----------------------------------------------------------------------\nRan 81 tests in 0.364s\n\nFAILED (failures=1, skipped=20)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 utils_tests.test_autoreload` failed. (See above for error)",
          "test_files_run": [
            "tests/utils_tests/test_autoreload.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 81,
          "failed": 0,
          "errors": 0,
          "duration": 8.48,
          "log_tail": "test_run_as_module (utils_tests.test_autoreload.TestChildArguments) ... ok\ntest_run_as_non_django_module (utils_tests.test_autoreload.TestChildArguments) ... ok\ntest_run_as_non_django_module_non_package (utils_tests.test_autoreload.TestChildArguments) ... ok\ntest_warnoptions (utils_tests.test_autoreload.TestChildArguments) ... ok\ntest_xoptions (utils_tests.test_autoreload.TestChildArguments) ... ok\ntest_check_errors_called (utils_tests.test_autoreload.StartDjangoTests) ... ok\ntest_echo_on_called (utils_tests.test_autoreload.StartDjangoTests) ... ok\ntest_starts_thread_with_args (utils_tests.test_autoreload.StartDjangoTests) ... ok\ntest_watchman_becomes_unavailable (utils_tests.test_autoreload.StartDjangoTests) ... ok\ntest_run_loop_catches_stopiteration (utils_tests.test_autoreload.BaseReloaderTests) ... ok\ntest_run_loop_stop_and_return (utils_tests.test_autoreload.BaseReloaderTests) ... ok\ntest_wait_for_apps_ready_checks_for_exception (utils_tests.test_autoreload.BaseReloaderTests) ... ok\ntest_wait_for_apps_ready_without_exception (utils_tests.test_autoreload.BaseReloaderTests) ... ok\ntest_watch_dir_with_unresolvable_path (utils_tests.test_autoreload.BaseReloaderTests) ... ok\ntest_watch_files_with_recursive_glob (utils_tests.test_autoreload.BaseReloaderTests) ... ok\ntest_watch_with_glob (utils_tests.test_autoreload.BaseReloaderTests) ... ok\ntest_glob (utils_tests.test_autoreload.StatReloaderTests) ... ok\ntest_glob_recursive (utils_tests.test_autoreload.StatReloaderTests) ... ok\ntest_multiple_globs (utils_tests.test_autoreload.StatReloaderTests) ... ok\ntest_multiple_recursive_globs (utils_tests.test_autoreload.StatReloaderTests) ... ok\ntest_nested_glob_recursive (utils_tests.test_autoreload.StatReloaderTests) ... ok\ntest_overlapping_glob_recursive (utils_tests.test_autoreload.StatReloaderTests) ... ok\ntest_overlapping_globs (utils_tests.test_autoreload.StatReloaderTests) ... ok\ntest_snapshot_files_ignores_missing_files (utils_tests.test_autoreload.StatReloaderTests) ... ok\ntest_snapshot_files_updates (utils_tests.test_autoreload.StatReloaderTests) ... ok\ntest_snapshot_files_with_duplicates (utils_tests.test_autoreload.StatReloaderTests) ... ok\ntest_tick_does_not_trigger_twice (utils_tests.test_autoreload.StatReloaderTests) ... ok\ntest_bytecode_conversion_to_source (utils_tests.test_autoreload.TestIterModulesAndFiles)\n.pyc and .pyo files are included in the files list. ... ok\ntest_check_errors (utils_tests.test_autoreload.TestIterModulesAndFiles)\nWhen a file containing an error is imported in a function wrapped by ... ok\ntest_check_errors_catches_all_exceptions (utils_tests.test_autoreload.TestIterModulesAndFiles)\nSince Python may raise arbitrary exceptions when importing code, ... ok\ntest_file_added (utils_tests.test_autoreload.TestIterModulesAndFiles)\nWhen a file is added, it's returned by iter_all_python_module_files(). ... ok\ntest_main_module_is_resolved (utils_tests.test_autoreload.TestIterModulesAndFiles) ... ok\ntest_main_module_without_file_is_not_resolved (utils_tests.test_autoreload.TestIterModulesAndFiles) ... ok\ntest_module_without_spec (utils_tests.test_autoreload.TestIterModulesAndFiles) ... ok\ntest_path_with_embedded_null_bytes (utils_tests.test_autoreload.TestIterModulesAndFiles) ... ok\ntest_paths_are_pathlib_instances (utils_tests.test_autoreload.TestIterModulesAndFiles) ... ok\ntest_weakref_in_sys_module (utils_tests.test_autoreload.TestIterModulesAndFiles)\niter_all_python_module_file() ignores weakref modules. ... ok\ntest_zip_reload (utils_tests.test_autoreload.TestIterModulesAndFiles)\nModules imported from zipped files have their archive location included ... ok\n\n----------------------------------------------------------------------\nRan 81 tests in 0.383s\n\nOK (skipped=20)\n",
          "test_files_run": [
            "tests/utils_tests/test_autoreload.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-14787",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 17.614975929260254,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 20,
          "failed": 1,
          "errors": 0,
          "duration": 8.6,
          "log_tail": "test_cache_page (decorators.tests.DecoratorsTest) ... ok\ntest_require_safe_accepts_only_safe_methods (decorators.tests.DecoratorsTest)\nTest for the require_safe decorator. ... ok\ntest_user_passes_test_composition (decorators.tests.DecoratorsTest)\nThe user_passes_test decorator can be applied multiple times (#9474). ... ok\ntest_argumented (decorators.tests.MethodDecoratorTests) ... ok\ntest_bad_iterable (decorators.tests.MethodDecoratorTests) ... ok\ntest_class_decoration (decorators.tests.MethodDecoratorTests)\n@method_decorator can be used to decorate a class and its methods. ... ok\ntest_descriptors (decorators.tests.MethodDecoratorTests) ... ok\ntest_invalid_method_name_to_decorate (decorators.tests.MethodDecoratorTests)\n@method_decorator on a nonexistent method raises an error. ... ok\ntest_invalid_non_callable_attribute_decoration (decorators.tests.MethodDecoratorTests)\n@method_decorator on a non-callable attribute raises an error. ... ok\ntest_new_attribute (decorators.tests.MethodDecoratorTests)\nA decorator that sets a new attribute on the method. ... ok\ntest_preserve_attributes (decorators.tests.MethodDecoratorTests) ... ok\ntest_preserve_signature (decorators.tests.MethodDecoratorTests) ... ok\ntest_tuple_of_decorators (decorators.tests.MethodDecoratorTests)\n@method_decorator can accept a tuple of decorators. ... ok\ntest_wrapper_assignments (decorators.tests.MethodDecoratorTests)\n@method_decorator preserves wrapper assignments. ... FAIL\ntest_never_cache_decorator (decorators.tests.NeverCacheDecoratorTest) ... ok\ntest_never_cache_decorator_http_request (decorators.tests.NeverCacheDecoratorTest) ... ok\n\n======================================================================\nFAIL: test_wrapper_assignments (decorators.tests.MethodDecoratorTests)\n@method_decorator preserves wrapper assignments.\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/tests/decorators/tests.py\", line 448, in test_wrapper_assignments\n    self.assertEqual(func_name, 'method')\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 837, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 830, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: None != 'method'\n\n----------------------------------------------------------------------\nRan 21 tests in 0.037s\n\nFAILED (failures=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 decorators.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/decorators/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 21,
          "failed": 0,
          "errors": 0,
          "duration": 7.93,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application decorators\nFound 21 test(s).\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_cache_control_decorator_http_request (decorators.tests.CacheControlDecoratorTest) ... ok\ntest_attributes (decorators.tests.DecoratorsTest)\nBuilt-in decorators set certain attributes of the wrapped function. ... ok\ntest_cache_page (decorators.tests.DecoratorsTest) ... ok\ntest_require_safe_accepts_only_safe_methods (decorators.tests.DecoratorsTest)\nTest for the require_safe decorator. ... ok\ntest_user_passes_test_composition (decorators.tests.DecoratorsTest)\nThe user_passes_test decorator can be applied multiple times (#9474). ... ok\ntest_deny_decorator (decorators.tests.XFrameOptionsDecoratorsTests)\nEnsures @xframe_options_deny properly sets the X-Frame-Options header. ... ok\ntest_exempt_decorator (decorators.tests.XFrameOptionsDecoratorsTests)\nEnsures @xframe_options_exempt properly instructs the ... ok\ntest_sameorigin_decorator (decorators.tests.XFrameOptionsDecoratorsTests)\nEnsures @xframe_options_sameorigin properly sets the X-Frame-Options ... ok\ntest_argumented (decorators.tests.MethodDecoratorTests) ... ok\ntest_bad_iterable (decorators.tests.MethodDecoratorTests) ... ok\ntest_class_decoration (decorators.tests.MethodDecoratorTests)\n@method_decorator can be used to decorate a class and its methods. ... ok\ntest_descriptors (decorators.tests.MethodDecoratorTests) ... ok\ntest_invalid_method_name_to_decorate (decorators.tests.MethodDecoratorTests)\n@method_decorator on a nonexistent method raises an error. ... ok\ntest_invalid_non_callable_attribute_decoration (decorators.tests.MethodDecoratorTests)\n@method_decorator on a non-callable attribute raises an error. ... ok\ntest_new_attribute (decorators.tests.MethodDecoratorTests)\nA decorator that sets a new attribute on the method. ... ok\ntest_preserve_attributes (decorators.tests.MethodDecoratorTests) ... ok\ntest_preserve_signature (decorators.tests.MethodDecoratorTests) ... ok\ntest_tuple_of_decorators (decorators.tests.MethodDecoratorTests)\n@method_decorator can accept a tuple of decorators. ... ok\ntest_wrapper_assignments (decorators.tests.MethodDecoratorTests)\n@method_decorator preserves wrapper assignments. ... ok\ntest_never_cache_decorator (decorators.tests.NeverCacheDecoratorTest) ... ok\ntest_never_cache_decorator_http_request (decorators.tests.NeverCacheDecoratorTest) ... ok\n\n----------------------------------------------------------------------\nRan 21 tests in 0.034s\n\nOK\n",
          "test_files_run": [
            "tests/decorators/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-14792",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 16.529872179031372,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 23,
          "failed": 2,
          "errors": 0,
          "duration": 7.91,
          "log_tail": "The _get_timezone_name() helper must return the offset for fixed offset ... test_is_aware (utils_tests.test_timezone.TimezoneTests) ... ok\ntest_is_naive (utils_tests.test_timezone.TimezoneTests) ... ok\ntest_localdate (utils_tests.test_timezone.TimezoneTests) ... ok\ntest_make_aware (utils_tests.test_timezone.TimezoneTests) ... ok\ntest_make_aware2 (utils_tests.test_timezone.TimezoneTests) ... ok\ntest_make_aware_no_tz (utils_tests.test_timezone.TimezoneTests) ... ok\ntest_make_aware_pytz_ambiguous (utils_tests.test_timezone.TimezoneTests) ... ok\ntest_make_aware_pytz_non_existent (utils_tests.test_timezone.TimezoneTests) ... ok\ntest_make_aware_zoneinfo_ambiguous (utils_tests.test_timezone.TimezoneTests) ... ok\ntest_make_aware_zoneinfo_non_existent (utils_tests.test_timezone.TimezoneTests) ... ok\ntest_make_naive (utils_tests.test_timezone.TimezoneTests) ... ok\ntest_make_naive_no_tz (utils_tests.test_timezone.TimezoneTests) ... ok\ntest_make_naive_pytz (utils_tests.test_timezone.TimezoneTests) ... ok\ntest_make_naive_zoneinfo (utils_tests.test_timezone.TimezoneTests) ... ok\ntest_now (utils_tests.test_timezone.TimezoneTests) ... ok\ntest_override (utils_tests.test_timezone.TimezoneTests) ... ok\ntest_override_decorator (utils_tests.test_timezone.TimezoneTests) ... ok\ntest_override_fixed_offset (utils_tests.test_timezone.TimezoneTests) ... ok\ntest_override_string_tz (utils_tests.test_timezone.TimezoneTests) ... ok\n\n======================================================================\nFAIL: test_get_timezone_name (utils_tests.test_timezone.TimezoneTests) (tz=<StaticTzInfo 'Etc/GMT-10'>, expected='+10')\nThe _get_timezone_name() helper must return the offset for fixed offset\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/utils_tests/test_timezone.py\", line 286, in test_get_timezone_name\n    self.assertEqual(timezone._get_timezone_name(tz), expected)\nAssertionError: 'Etc/GMT-10' != '+10'\n- Etc/GMT-10\n+ +10\n\n\n======================================================================\nFAIL: test_get_timezone_name (utils_tests.test_timezone.TimezoneTests) (tz=backports.zoneinfo.ZoneInfo(key='Etc/GMT-10'), expected='+10')\nThe _get_timezone_name() helper must return the offset for fixed offset\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/utils_tests/test_timezone.py\", line 286, in test_get_timezone_name\n    self.assertEqual(timezone._get_timezone_name(tz), expected)\nAssertionError: 'Etc/GMT-10' != '+10'\n- Etc/GMT-10\n+ +10\n\n\n----------------------------------------------------------------------\nRan 25 tests in 0.011s\n\nFAILED (failures=2)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 utils_tests.test_timezone` failed. (See above for error)",
          "test_files_run": [
            "tests/utils_tests/test_timezone.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 25,
          "failed": 0,
          "errors": 0,
          "duration": 7.5,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application utils_tests\nFound 25 test(s).\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_activate_invalid_timezone (utils_tests.test_timezone.TimezoneTests) ... ok\ntest_fixedoffset_negative_timedelta (utils_tests.test_timezone.TimezoneTests) ... ok\ntest_fixedoffset_timedelta (utils_tests.test_timezone.TimezoneTests) ... ok\ntest_get_default_timezone (utils_tests.test_timezone.TimezoneTests) ... ok\ntest_get_default_timezone_utc (utils_tests.test_timezone.TimezoneTests) ... ok\ntest_get_timezone_name (utils_tests.test_timezone.TimezoneTests)\nThe _get_timezone_name() helper must return the offset for fixed offset ... ok\ntest_is_aware (utils_tests.test_timezone.TimezoneTests) ... ok\ntest_is_naive (utils_tests.test_timezone.TimezoneTests) ... ok\ntest_localdate (utils_tests.test_timezone.TimezoneTests) ... ok\ntest_make_aware (utils_tests.test_timezone.TimezoneTests) ... ok\ntest_make_aware2 (utils_tests.test_timezone.TimezoneTests) ... ok\ntest_make_aware_no_tz (utils_tests.test_timezone.TimezoneTests) ... ok\ntest_make_aware_pytz_ambiguous (utils_tests.test_timezone.TimezoneTests) ... ok\ntest_make_aware_pytz_non_existent (utils_tests.test_timezone.TimezoneTests) ... ok\ntest_make_aware_zoneinfo_ambiguous (utils_tests.test_timezone.TimezoneTests) ... ok\ntest_make_aware_zoneinfo_non_existent (utils_tests.test_timezone.TimezoneTests) ... ok\ntest_make_naive (utils_tests.test_timezone.TimezoneTests) ... ok\ntest_make_naive_no_tz (utils_tests.test_timezone.TimezoneTests) ... ok\ntest_make_naive_pytz (utils_tests.test_timezone.TimezoneTests) ... ok\ntest_make_naive_zoneinfo (utils_tests.test_timezone.TimezoneTests) ... ok\ntest_now (utils_tests.test_timezone.TimezoneTests) ... ok\ntest_override (utils_tests.test_timezone.TimezoneTests) ... ok\ntest_override_decorator (utils_tests.test_timezone.TimezoneTests) ... ok\ntest_override_fixed_offset (utils_tests.test_timezone.TimezoneTests) ... ok\ntest_override_string_tz (utils_tests.test_timezone.TimezoneTests) ... ok\n\n----------------------------------------------------------------------\nRan 25 tests in 0.009s\n\nOK\n",
          "test_files_run": [
            "tests/utils_tests/test_timezone.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-14855",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 34.78290915489197,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 344,
          "failed": 1,
          "errors": 0,
          "duration": 17.4,
          "log_tail": "Ran 345 tests in 8.402s\n\nFAILED (failures=1, skipped=15)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 admin_views.admin admin_views.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/admin_views/admin.py",
            "tests/admin_views/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 345,
          "failed": 0,
          "errors": 0,
          "duration": 16.0,
          "log_tail": "----------------------------------------------------------------------\nRan 345 tests in 8.451s\n\nOK (skipped=15)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/admin_views/admin.py",
            "tests/admin_views/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-14915",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 18.345752239227295,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 23,
          "failed": 0,
          "errors": 1,
          "duration": 8.89,
          "log_tail": "  Applying admin.0003_logentry_add_action_flag_choices... OK\n  Applying sites.0001_initial... OK\n  Applying sites.0002_alter_domain_unique... OK\nSystem check identified no issues (0 silenced).\n\n\nCreating test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\ntest_basics (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ok\ntest_choice_iterator_passes_model_to_widget (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ok\ntest_choice_value_hash (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ERROR\ntest_choices (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ok\ntest_choices_bool (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ok\ntest_choices_bool_empty_label (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ok\ntest_choices_freshness (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ok\ntest_choices_not_fetched_when_not_rendering (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ok\ntest_choices_radio_blank (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ok\ntest_clean_model_instance (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ok\ntest_clean_to_field_name (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ok\ntest_custom_choice_iterator_passes_model_to_widget (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ok\ntest_deepcopies_widget (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ok\ntest_disabled_modelchoicefield (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ok\ntest_disabled_modelchoicefield_has_changed (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ok\ntest_disabled_modelchoicefield_initial_model_instance (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ok\ntest_disabled_modelmultiplechoicefield_has_changed (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ok\ntest_disabled_multiplemodelchoicefield (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ok\ntest_no_extra_query_when_accessing_attrs (model_forms.test_modelchoicefield.ModelChoiceFieldTests)\nModelChoiceField with RadioSelect widget doesn't produce unnecessary ... ok\ntest_num_queries (model_forms.test_modelchoicefield.ModelChoiceFieldTests)\nWidgets that render multiple subwidgets shouldn't make more than one ... ok\ntest_overridable_choice_iterator (model_forms.test_modelchoicefield.ModelChoiceFieldTests)\nIterator defaults to ModelChoiceIterator and can be overridden with ... ok\ntest_queryset_manager (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ok\ntest_queryset_none (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ok\ntest_result_cache_not_shared (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ok\n\n======================================================================\nERROR: test_choice_value_hash (model_forms.test_modelchoicefield.ModelChoiceFieldTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/model_forms/test_modelchoicefield.py\", line 347, in test_choice_value_hash\n    self.assertEqual(hash(value_1), hash(ModelChoiceIteratorValue(self.c1.pk, None)))\nTypeError: unhashable type: 'ModelChoiceIteratorValue'\n\n----------------------------------------------------------------------\nRan 24 tests in 0.090s\n\nFAILED (errors=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 model_forms.test_modelchoicefield` failed. (See above for error)",
          "test_files_run": [
            "tests/model_forms/test_modelchoicefield.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 24,
          "failed": 0,
          "errors": 0,
          "duration": 7.91,
          "log_tail": "    Creating table model_forms_award\n    Creating table model_forms_nullableuniquecharfieldmodel\n    Creating table model_forms_number\n    Creating table model_forms_numberstodice\n    Creating table model_forms_dice\n    Running deferred SQL...\nRunning migrations:\n  Applying admin.0001_initial... OK\n  Applying admin.0002_logentry_remove_auto_add... OK\n  Applying admin.0003_logentry_add_action_flag_choices... OK\n  Applying sites.0001_initial... OK\n  Applying sites.0002_alter_domain_unique... OK\nSystem check identified no issues (0 silenced).\n\n\nCreating test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\ntest_basics (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ok\ntest_choice_iterator_passes_model_to_widget (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ok\ntest_choice_value_hash (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ok\ntest_choices (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ok\ntest_choices_bool (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ok\ntest_choices_bool_empty_label (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ok\ntest_choices_freshness (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ok\ntest_choices_not_fetched_when_not_rendering (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ok\ntest_choices_radio_blank (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ok\ntest_clean_model_instance (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ok\ntest_clean_to_field_name (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ok\ntest_custom_choice_iterator_passes_model_to_widget (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ok\ntest_deepcopies_widget (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ok\ntest_disabled_modelchoicefield (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ok\ntest_disabled_modelchoicefield_has_changed (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ok\ntest_disabled_modelchoicefield_initial_model_instance (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ok\ntest_disabled_modelmultiplechoicefield_has_changed (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ok\ntest_disabled_multiplemodelchoicefield (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ok\ntest_no_extra_query_when_accessing_attrs (model_forms.test_modelchoicefield.ModelChoiceFieldTests)\nModelChoiceField with RadioSelect widget doesn't produce unnecessary ... ok\ntest_num_queries (model_forms.test_modelchoicefield.ModelChoiceFieldTests)\nWidgets that render multiple subwidgets shouldn't make more than one ... ok\ntest_overridable_choice_iterator (model_forms.test_modelchoicefield.ModelChoiceFieldTests)\nIterator defaults to ModelChoiceIterator and can be overridden with ... ok\ntest_queryset_manager (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ok\ntest_queryset_none (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ok\ntest_result_cache_not_shared (model_forms.test_modelchoicefield.ModelChoiceFieldTests) ... ok\n\n----------------------------------------------------------------------\nRan 24 tests in 0.073s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/model_forms/test_modelchoicefield.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-14999",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 20.875053644180298,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 119,
          "failed": 1,
          "errors": 0,
          "duration": 10.66,
          "log_tail": "Tests the SeparateDatabaseAndState operation. ... ok\ntest_separate_database_and_state2 (migrations.test_operations.OperationTests)\nA complex SeparateDatabaseAndState operation: Multiple operations both ... ok\ntest_smallfield_autofield_foreignfield_growth (migrations.test_operations.OperationTests)\nA field may be migrated from SmallAutoField to AutoField. ... ok\ntest_smallfield_bigautofield_foreignfield_growth (migrations.test_operations.OperationTests)\nA field may be migrated from SmallAutoField to BigAutoField. ... ok\n\n======================================================================\nFAIL: test_rename_model_with_db_table_noop (migrations.test_operations.OperationTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/tests/migrations/test_operations.py\", line 813, in test_rename_model_with_db_table_noop\n    operation.database_forwards(app_label, editor, project_state, new_state)\n  File \"/testbed/django/test/testcases.py\", line 84, in __exit__\n    self.test_case.assertEqual(\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 837, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 830, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: 5 != 0 : 5 queries executed, 0 expected\nCaptured queries were:\n1. CREATE TABLE \"new__test_rmwdbtn_pony\" (\"id\" integer NOT NULL PRIMARY KEY AUTOINCREMENT, \"rider_id\" integer NOT NULL REFERENCES \"rider\" (\"id\") DEFERRABLE INITIALLY DEFERRED)\n2. INSERT INTO \"new__test_rmwdbtn_pony\" (\"id\", \"rider_id\") SELECT \"id\", \"rider_id\" FROM \"test_rmwdbtn_pony\"\n3. DROP TABLE \"test_rmwdbtn_pony\"\n4. ALTER TABLE \"new__test_rmwdbtn_pony\" RENAME TO \"test_rmwdbtn_pony\"\n5. CREATE INDEX \"test_rmwdbtn_pony_rider_id_7b3213e0\" ON \"test_rmwdbtn_pony\" (\"rider_id\")\n\n----------------------------------------------------------------------\nRan 120 tests in 2.214s\n\nFAILED (failures=1, skipped=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 migrations.test_operations` failed. (See above for error)",
          "test_files_run": [
            "tests/migrations/test_operations.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 120,
          "failed": 0,
          "errors": 0,
          "duration": 8.92,
          "log_tail": "test_rename_model_with_db_table_noop (migrations.test_operations.OperationTests) ... ok\ntest_rename_model_with_m2m (migrations.test_operations.OperationTests) ... ok\ntest_rename_model_with_self_referential_fk (migrations.test_operations.OperationTests)\nTests the RenameModel operation on model with self referential FK. ... ok\ntest_rename_model_with_self_referential_m2m (migrations.test_operations.OperationTests) ... ok\ntest_rename_model_with_superclass_fk (migrations.test_operations.OperationTests)\nTests the RenameModel operation on a model which has a superclass that ... ok\ntest_rename_referenced_field_state_forward (migrations.test_operations.OperationTests) ... ok\ntest_repoint_field_m2m (migrations.test_operations.OperationTests) ... ok\ntest_run_python (migrations.test_operations.OperationTests)\nTests the RunPython operation ... ok\ntest_run_python_atomic (migrations.test_operations.OperationTests)\nTests the RunPython operation correctly handles the \"atomic\" keyword ... ok\ntest_run_python_noop (migrations.test_operations.OperationTests)\n#24098 - Tests no-op RunPython operations. ... ok\ntest_run_python_related_assignment (migrations.test_operations.OperationTests)\n#24282 - Model changes to a FK reverse side update the model ... ok\ntest_run_sql (migrations.test_operations.OperationTests)\nTests the RunSQL operation. ... ok\ntest_run_sql_add_missing_semicolon_on_collect_sql (migrations.test_operations.OperationTests) ... ok\ntest_run_sql_noop (migrations.test_operations.OperationTests)\n#24098 - Tests no-op RunSQL operations. ... ok\ntest_run_sql_params (migrations.test_operations.OperationTests)\n#23426 - RunSQL should accept parameters. ... ok\ntest_run_sql_params_invalid (migrations.test_operations.OperationTests)\n#23426 - RunSQL should fail when a list of statements with an incorrect ... ok\ntest_separate_database_and_state (migrations.test_operations.OperationTests)\nTests the SeparateDatabaseAndState operation. ... ok\ntest_separate_database_and_state2 (migrations.test_operations.OperationTests)\nA complex SeparateDatabaseAndState operation: Multiple operations both ... ok\ntest_smallfield_autofield_foreignfield_growth (migrations.test_operations.OperationTests)\nA field may be migrated from SmallAutoField to AutoField. ... ok\ntest_smallfield_bigautofield_foreignfield_growth (migrations.test_operations.OperationTests)\nA field may be migrated from SmallAutoField to BigAutoField. ... ok\n\n----------------------------------------------------------------------\nRan 120 tests in 1.658s\n\nOK (skipped=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/migrations/test_operations.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-15022",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 22.16022777557373,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 66,
          "failed": 2,
          "errors": 1,
          "duration": 11.21,
          "log_tail": "  File \"/testbed/django/db/backends/sqlite3/base.py\", line 420, in execute\n    return Database.Cursor.execute(self, query, params)\ndjango.db.utils.OperationalError: at most 64 tables in a join\n\n======================================================================\nFAIL: test_multiple_search_fields (admin_changelist.tests.ChangeListTests) [<object object at 0x7c4a45e29350>] (search_string='Mary Jonathan Duo')\nAll rows containing each of the searched words are returned, where each\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 499, in subTest\n    yield\n  File \"/testbed/tests/admin_changelist/tests.py\", line 601, in test_multiple_search_fields\n    self.assertEqual(group_changelist.queryset.count(), result_count)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 837, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 830, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: 1 != 0\n\n======================================================================\nFAIL: test_related_field_multiple_search_terms (admin_changelist.tests.ChangeListTests)\nSearches over multi-valued relationships return rows from related\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/tests/admin_changelist/tests.py\", line 185, in test_related_field_multiple_search_terms\n    self.assertEqual(cl.queryset.count(), 0)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 837, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 830, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: 1 != 0\n\n----------------------------------------------------------------------\nRan 69 tests in 1.630s\n\nFAILED (failures=2, errors=1, skipped=6)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 admin_changelist.admin admin_changelist.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/admin_changelist/admin.py",
            "tests/admin_changelist/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 69,
          "failed": 0,
          "errors": 0,
          "duration": 8.64,
          "log_tail": "Regression test for #13902: When using a ManyToMany in list_filter, ... ok\ntest_no_exists_for_m2m_in_list_filter_without_params (admin_changelist.tests.ChangeListTests)\nIf a ManyToManyField is in list_filter but isn't in any lookup params, ... ok\ntest_no_list_display_links (admin_changelist.tests.ChangeListTests)\n#15185 -- Allow no links from the 'change list' view grid. ... ok\ntest_object_tools_displayed_no_add_permission (admin_changelist.tests.ChangeListTests)\nWhen ModelAdmin.has_add_permission() returns False, the object-tools ... ok\ntest_pagination (admin_changelist.tests.ChangeListTests)\nRegression tests for #12893: Pagination in admins changelist doesn't ... ok\ntest_pagination_page_range (admin_changelist.tests.ChangeListTests)\nRegression tests for ticket #15653: ensure the number of pages ... ok\ntest_pk_in_search_fields (admin_changelist.tests.ChangeListTests) ... ok\ntest_related_field_multiple_search_terms (admin_changelist.tests.ChangeListTests)\nSearches over multi-valued relationships return rows from related ... ok\ntest_repr (admin_changelist.tests.ChangeListTests) ... ok\ntest_result_list_editable (admin_changelist.tests.ChangeListTests)\nRegression test for #14312: list_editable with pagination ... ok\ntest_result_list_editable_html (admin_changelist.tests.ChangeListTests)\nRegression tests for #11791: Inclusion tag result_list generates a ... ok\ntest_result_list_empty_changelist_value (admin_changelist.tests.ChangeListTests)\nRegression test for #14982: EMPTY_CHANGELIST_VALUE should be honored ... ok\ntest_result_list_html (admin_changelist.tests.ChangeListTests)\nInclusion tag result_list generates a table when with default ... ok\ntest_result_list_set_empty_value_display_in_model_admin (admin_changelist.tests.ChangeListTests)\nEmpty value display can be set in ModelAdmin or individual fields. ... ok\ntest_result_list_set_empty_value_display_on_admin_site (admin_changelist.tests.ChangeListTests)\nEmpty value display can be set on AdminSite. ... ok\ntest_search_help_text (admin_changelist.tests.ChangeListTests) ... ok\ntest_select_related_as_empty_tuple (admin_changelist.tests.ChangeListTests) ... ok\ntest_select_related_as_tuple (admin_changelist.tests.ChangeListTests) ... ok\ntest_select_related_preserved (admin_changelist.tests.ChangeListTests)\nRegression test for #10348: ChangeList.get_queryset() shouldn't ... ok\ntest_select_related_preserved_when_multi_valued_in_search_fields (admin_changelist.tests.ChangeListTests) ... ok\ntest_show_all (admin_changelist.tests.ChangeListTests) ... ok\ntest_spanning_relations_with_custom_lookup_in_search_fields (admin_changelist.tests.ChangeListTests) ... ok\ntest_specified_ordering_by_f_expression (admin_changelist.tests.ChangeListTests) ... ok\ntest_specified_ordering_by_f_expression_without_asc_desc (admin_changelist.tests.ChangeListTests) ... ok\ntest_total_ordering_optimization (admin_changelist.tests.ChangeListTests) ... ok\ntest_total_ordering_optimization_meta_constraints (admin_changelist.tests.ChangeListTests) ... ok\ntest_tuple_list_display (admin_changelist.tests.ChangeListTests) ... ok\n\n----------------------------------------------------------------------\nRan 69 tests in 1.666s\n\nOK (skipped=6)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/admin_changelist/admin.py",
            "tests/admin_changelist/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-15037",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "duration": 18.286334991455078,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 19,
          "failed": 2,
          "errors": 0,
          "duration": 9.12,
          "log_tail": "Unsupported index types (COALESCE here) are skipped. ... skipped 'PostgreSQL specific SQL'\n\n======================================================================\nFAIL: test_custom_fields (inspectdb.tests.InspectDBTestCase)\nIntrospection of columns with a custom field (#21090)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/tests/inspectdb/tests.py\", line 323, in test_custom_fields\n    self.assertIn(\"text_field = myfields.TextField()\", output)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 1104, in assertIn\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 676, in fail\n    raise self.failureException(msg)\nAssertionError: 'text_field = myfields.TextField()' not found in \"# This is an auto-generated Django model module.\\n# You'll have to do the following manually to clean this up:\\n#   * Rearrange models' order\\n#   * Make sure each model has one field with primary_key=True\\n#   * Make sure each ForeignKey and OneToOneField has `on_delete` set to the desired behavior\\n#   * Remove `managed = False` lines if you wish to allow Django to create, modify, and delete the table\\n# Feel free to rename the models, but don't rename db_table values or field names.\\nfrom django.db import models\\n\\n\\nclass InspectdbColumntypes(models.Model):\\n    id = models.TextField(primary_key=True)  # This field type is a guess.\\n    big_int_field = models.BigIntegerField()\\n    bool_field = models.TextField()  # This field type is a guess.\\n    null_bool_field = models.TextField(blank=True, null=True)  # This field type is a guess.\\n    char_field = models.TextField()  # This field type is a guess.\\n    null_char_field = models.TextField(blank=True, null=True)  # This field type is a guess.\\n    date_field = models.TextField()  # This field type is a guess.\\n    date_time_field = models.TextField()  # This field type is a guess.\\n    decimal_field = models.TextField()  # This field type is a guess.\\n    email_field = models.TextField()  # This field type is a guess.\\n    file_field = models.TextField()  # This field type is a guess.\\n    file_path_field = models.TextField()  # This field type is a guess.\\n    float_field = models.TextField()  # This field type is a guess.\\n    int_field = models.TextField()  # This field type is a guess.\\n    gen_ip_address_field = models.TextField()  # This field type is a guess.\\n    pos_big_int_field = models.TextField()  # This field type is a guess.\\n    pos_int_field = models.TextField()  # This field type is a guess.\\n    pos_small_int_field = models.TextField()  # This field type is a guess.\\n    slug_field = models.TextField()  # This field type is a guess.\\n    small_int_field = models.TextField()  # This field type is a guess.\\n    text_field = models.TextField()  # This field type is a guess.\\n    time_field = models.TextField()  # This field type is a guess.\\n    url_field = models.TextField()  # This field type is a guess.\\n    uuid_field = models.TextField()  # This field type is a guess.\\n\\n    class Meta:\\n        managed = False\\n        db_table = 'inspectdb_columntypes'\\n\"\n\n======================================================================\nFAIL: test_foreign_key_to_field (inspectdb.tests.InspectDBTestCase)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/django/test/testcases.py\", line 1305, in skip_wrapper\n    return test_func(*args, **kwargs)\n  File \"/testbed/tests/inspectdb/tests.py\", line 211, in test_foreign_key_to_field\n    self.assertIn(\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 1104, in assertIn\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 676, in fail\n    raise self.failureException(msg)\nAssertionError: \"to_field_fk = models.ForeignKey('InspectdbPeoplemoredata', models.DO_NOTHING, to_field='people_unique_id')\" not found in \"# This is an auto-generated Django model module.\\n# You'll have to do the following manually to clean this up:\\n#   * Rearrange models' order\\n#   * Make sure each model has one field with primary_key=True\\n#   * Make sure each ForeignKey and OneToOneField has `on_delete` set to the desired behavior\\n#   * Remove `managed = False` lines if you wish to allow Django to create, modify, and delete the table\\n# Feel free to rename the models, but don't rename db_table values or field names.\\nfrom django.db import models\\n\\n\\nclass InspectdbForeignkeytofield(models.Model):\\n    to_field_fk = models.ForeignKey('InspectdbPeoplemoredata', models.DO_NOTHING)\\n\\n    class Meta:\\n        managed = False\\n        db_table = 'inspectdb_foreignkeytofield'\\n\"\n\n----------------------------------------------------------------------\nRan 21 tests in 0.658s\n\nFAILED (failures=2, skipped=4)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 inspectdb.models inspectdb.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/inspectdb/models.py",
            "tests/inspectdb/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 20,
          "failed": 1,
          "errors": 0,
          "duration": 7.91,
          "log_tail": "test_field_types (inspectdb.tests.InspectDBTestCase)\nTest introspection of various Django field types ... ok\ntest_foreign_key_to_field (inspectdb.tests.InspectDBTestCase) ... ok\ntest_introspection_errors (inspectdb.tests.InspectDBTestCase)\nIntrospection errors should not crash the command, and the error should ... ok\ntest_json_field (inspectdb.tests.InspectDBTestCase) ... ok\ntest_managed_models (inspectdb.tests.InspectDBTestCase)\nBy default the command generates models with `Meta.managed = False` (#14305) ... ok\ntest_number_field_types (inspectdb.tests.InspectDBTestCase)\nTest introspection of various Django field types ... ok\ntest_special_column_name_introspection (inspectdb.tests.InspectDBTestCase)\nIntrospection of column names containing special characters, ... ok\ntest_stealth_table_name_filter_option (inspectdb.tests.InspectDBTestCase) ... ok\ntest_table_name_introspection (inspectdb.tests.InspectDBTestCase)\nIntrospection of table names containing special characters, ... ok\ntest_table_option (inspectdb.tests.InspectDBTestCase)\ninspectdb can inspect a subset of tables by passing the table names as ... ok\ntest_text_field_db_collation (inspectdb.tests.InspectDBTestCase) ... ok\ntest_unique_together_meta (inspectdb.tests.InspectDBTestCase) ... ok\ntest_unsupported_unique_together (inspectdb.tests.InspectDBTestCase)\nUnsupported index types (COALESCE here) are skipped. ... skipped 'PostgreSQL specific SQL'\n\n======================================================================\nFAIL: test_custom_fields (inspectdb.tests.InspectDBTestCase)\nIntrospection of columns with a custom field (#21090)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/tests/inspectdb/tests.py\", line 323, in test_custom_fields\n    self.assertIn(\"text_field = myfields.TextField()\", output)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 1104, in assertIn\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 676, in fail\n    raise self.failureException(msg)\nAssertionError: 'text_field = myfields.TextField()' not found in \"# This is an auto-generated Django model module.\\n# You'll have to do the following manually to clean this up:\\n#   * Rearrange models' order\\n#   * Make sure each model has one field with primary_key=True\\n#   * Make sure each ForeignKey and OneToOneField has `on_delete` set to the desired behavior\\n#   * Remove `managed = False` lines if you wish to allow Django to create, modify, and delete the table\\n# Feel free to rename the models, but don't rename db_table values or field names.\\nfrom django.db import models\\n\\n\\nclass InspectdbColumntypes(models.Model):\\n    id = models.TextField(primary_key=True)  # This field type is a guess.\\n    big_int_field = models.BigIntegerField()\\n    bool_field = models.TextField()  # This field type is a guess.\\n    null_bool_field = models.TextField(blank=True, null=True)  # This field type is a guess.\\n    char_field = models.TextField()  # This field type is a guess.\\n    null_char_field = models.TextField(blank=True, null=True)  # This field type is a guess.\\n    date_field = models.TextField()  # This field type is a guess.\\n    date_time_field = models.TextField()  # This field type is a guess.\\n    decimal_field = models.TextField()  # This field type is a guess.\\n    email_field = models.TextField()  # This field type is a guess.\\n    file_field = models.TextField()  # This field type is a guess.\\n    file_path_field = models.TextField()  # This field type is a guess.\\n    float_field = models.TextField()  # This field type is a guess.\\n    int_field = models.TextField()  # This field type is a guess.\\n    gen_ip_address_field = models.TextField()  # This field type is a guess.\\n    pos_big_int_field = models.TextField()  # This field type is a guess.\\n    pos_int_field = models.TextField()  # This field type is a guess.\\n    pos_small_int_field = models.TextField()  # This field type is a guess.\\n    slug_field = models.TextField()  # This field type is a guess.\\n    small_int_field = models.TextField()  # This field type is a guess.\\n    text_field = models.TextField()  # This field type is a guess.\\n    time_field = models.TextField()  # This field type is a guess.\\n    url_field = models.TextField()  # This field type is a guess.\\n    uuid_field = models.TextField()  # This field type is a guess.\\n\\n    class Meta:\\n        managed = False\\n        db_table = 'inspectdb_columntypes'\\n\"\n\n----------------------------------------------------------------------\nRan 21 tests in 0.378s\n\nFAILED (failures=1, skipped=4)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 inspectdb.models inspectdb.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/inspectdb/models.py",
            "tests/inspectdb/tests.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "django__django-15098",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 20.58044195175171,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 87,
          "failed": 4,
          "errors": 0,
          "duration": 10.52,
          "log_tail": "  File \"/testbed/tests/i18n/tests.py\", line 1630, in test_get_language_from_path_real\n    self.assertEqual(g(path), language)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 837, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 830, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: None != 'de-ch-1901'\n\n======================================================================\nFAIL: test_get_language_from_path_real (i18n.tests.MiscTests) [<object object at 0x7f7ae3faaea0>] (path='/nan-hani-tw/')\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 499, in subTest\n    yield\n  File \"/testbed/tests/i18n/tests.py\", line 1630, in test_get_language_from_path_real\n    self.assertEqual(g(path), language)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 837, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 830, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: None != 'nan-hani-tw'\n\n----------------------------------------------------------------------\nRan 91 tests in 2.319s\n\nFAILED (failures=4)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 i18n.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/i18n/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 91,
          "failed": 0,
          "errors": 0,
          "duration": 8.7,
          "log_tail": "test_iter_format_modules (i18n.tests.FormattingTests)\nTests the iter_format_modules function. ... ok\ntest_iter_format_modules_stability (i18n.tests.FormattingTests)\nTests the iter_format_modules function always yields format modules in ... ok\ntest_l10n_disabled (i18n.tests.FormattingTests)\nCatalan locale with format i18n disabled translations will be used, ... ok\ntest_l10n_enabled (i18n.tests.FormattingTests) ... ok\ntest_locale_independent (i18n.tests.FormattingTests)\nLocalization of numbers ... ok\ntest_localize_templatetag_and_filter (i18n.tests.FormattingTests)\nTest the {% localize %} templatetag and the localize/unlocalize filters. ... ok\ntest_localized_as_text_as_hidden_input (i18n.tests.FormattingTests)\nTests if form input with 'as_hidden' or 'as_text' is correctly localized. Ticket #18777 ... ok\ntest_localized_input (i18n.tests.FormattingTests)\nTests if form input is correctly localized ... ok\ntest_localized_input_func (i18n.tests.FormattingTests) ... ok\ntest_localized_off_numbers (i18n.tests.FormattingTests)\nA string representation is returned for unlocalized numbers. ... ok\ntest_sanitize_separators (i18n.tests.FormattingTests)\nTests django.utils.formats.sanitize_separators. ... ok\ntest_sanitize_strftime_format (i18n.tests.FormattingTests) ... ok\ntest_sanitize_strftime_format_with_escaped_percent (i18n.tests.FormattingTests) ... ok\ntest_sub_locales (i18n.tests.FormattingTests)\nCheck if sublocales fall back to the main locale ... ok\n\n----------------------------------------------------------------------\nRan 91 tests in 0.900s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/i18n/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-15103",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 17.456290006637573,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 17,
          "failed": 0,
          "errors": 2,
          "duration": 8.4,
          "log_tail": "  File \"/testbed/tests/template_tests/utils.py\", line 55, in inner\n    func(self)\n  File \"/testbed/tests/template_tests/filter_tests/test_json_script.py\", line 23, in test_without_id\n    output = self.engine.render_to_string('json-tag02', {'value': {}})\n  File \"/testbed/django/template/engine.py\", line 177, in render_to_string\n    t = self.get_template(template_name)\n  File \"/testbed/django/template/engine.py\", line 163, in get_template\n    template, origin = self.find_template(template_name)\n  File \"/testbed/django/template/engine.py\", line 145, in find_template\n    template = loader.get_template(name, skip=skip)\n  File \"/testbed/django/template/loaders/cached.py\", line 58, in get_template\n    template = super().get_template(template_name, skip)\n  File \"/testbed/django/template/loaders/base.py\", line 29, in get_template\n    return Template(\n  File \"/testbed/django/template/base.py\", line 155, in __init__\n    self.nodelist = self.compile_nodelist()\n  File \"/testbed/django/template/base.py\", line 199, in compile_nodelist\n    return parser.parse()\n  File \"/testbed/django/template/base.py\", line 479, in parse\n    raise self.error(token, e)\n  File \"/testbed/django/template/base.py\", line 477, in parse\n    filter_expression = self.compile_filter(token.contents)\n  File \"/testbed/django/template/base.py\", line 593, in compile_filter\n    return FilterExpression(token, self)\n  File \"/testbed/django/template/base.py\", line 688, in __init__\n    self.args_check(filter_name, filter_func, args)\n  File \"/testbed/django/template/base.py\", line 747, in args_check\n    raise TemplateSyntaxError(\"%s requires %d arguments, %d provided\" %\ndjango.template.exceptions.TemplateSyntaxError: json_script requires 2 arguments, 1 provided\n\n======================================================================\nERROR: test_json_script_without_id (utils_tests.test_html.TestUtilsHtml)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/tests/utils_tests/test_html.py\", line 178, in test_json_script_without_id\n    json_script({'key': 'value'}),\nTypeError: json_script() missing 1 required positional argument: 'element_id'\n\n----------------------------------------------------------------------\nRan 19 tests in 0.304s\n\nFAILED (errors=2)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 template_tests.filter_tests.test_json_script utils_tests.test_html` failed. (See above for error)",
          "test_files_run": [
            "tests/template_tests/filter_tests/test_json_script.py",
            "tests/utils_tests/test_html.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 19,
          "failed": 0,
          "errors": 0,
          "duration": 7.55,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application utils_tests\nImporting application template_tests\nFound 19 test(s).\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_basic (template_tests.filter_tests.test_json_script.JsonScriptTests) ... ok\ntest_without_id (template_tests.filter_tests.test_json_script.JsonScriptTests) ... ok\ntest_conditional_escape (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_escape (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_escapejs (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_format_html (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_html_safe (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_html_safe_defines_html_error (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_html_safe_doesnt_define_str (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_html_safe_subclass (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_json_script (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_json_script_without_id (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_linebreaks (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_smart_urlquote (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_strip_spaces_between_tags (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_strip_tags (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_strip_tags_files (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_urlize (utils_tests.test_html.TestUtilsHtml) ... ok\ntest_urlize_unchanged_inputs (utils_tests.test_html.TestUtilsHtml) ... ok\n\n----------------------------------------------------------------------\nRan 19 tests in 0.229s\n\nOK\n",
          "test_files_run": [
            "tests/template_tests/filter_tests/test_json_script.py",
            "tests/utils_tests/test_html.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-15104",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 17.83271813392639,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 138,
          "failed": 0,
          "errors": 1,
          "duration": 9.36,
          "log_tail": "Setting order_with_respect_to adds a field. ... ok\ntest_set_alter_order_with_respect_to_index_constraint_foo_together (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_supports_functools_partial (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_swappable (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_swappable_changed (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_swappable_circular_multi_mti (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_swappable_first_inheritance (migrations.test_autodetector.AutodetectorTests)\nSwappable models get their CreateModel first. ... ok\ntest_swappable_first_setting (migrations.test_autodetector.AutodetectorTests)\nSwappable models get their CreateModel first. ... ok\ntest_trim_apps (migrations.test_autodetector.AutodetectorTests)\nTrim does not remove dependencies but does remove unwanted apps. ... ok\ntest_unmanaged_create (migrations.test_autodetector.AutodetectorTests)\nThe autodetector correctly deals with managed models. ... ok\ntest_unmanaged_custom_pk (migrations.test_autodetector.AutodetectorTests)\n#23415 - The autodetector must correctly deal with custom FK on ... ok\ntest_unmanaged_delete (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_unmanaged_to_managed (migrations.test_autodetector.AutodetectorTests) ... ok\n\n======================================================================\nERROR: test_add_custom_fk_with_hardcoded_to (migrations.test_autodetector.AutodetectorTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/tests/migrations/test_autodetector.py\", line 2851, in test_add_custom_fk_with_hardcoded_to\n    changes = self.get_changes(\n  File \"/testbed/tests/migrations/test_autodetector.py\", line 591, in get_changes\n    return MigrationAutodetector(\n  File \"/testbed/django/db/migrations/autodetector.py\", line 159, in _detect_changes\n    self.generate_renamed_models()\n  File \"/testbed/django/db/migrations/autodetector.py\", line 477, in generate_renamed_models\n    model_fields_def = self.only_relation_agnostic_fields(model_state.fields)\n  File \"/testbed/django/db/migrations/autodetector.py\", line 99, in only_relation_agnostic_fields\n    del deconstruction[2]['to']\nKeyError: 'to'\n\n----------------------------------------------------------------------\nRan 139 tests in 0.584s\n\nFAILED (errors=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 migrations.test_autodetector` failed. (See above for error)",
          "test_files_run": [
            "tests/migrations/test_autodetector.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 139,
          "failed": 0,
          "errors": 0,
          "duration": 7.36,
          "log_tail": "Tests autodetection of renamed models that are used in M2M relations as ... ok\ntest_rename_model (migrations.test_autodetector.AutodetectorTests)\nTests autodetection of renamed models. ... ok\ntest_rename_model_case (migrations.test_autodetector.AutodetectorTests)\nModel name is case-insensitive. Changing case doesn't lead to any ... ok\ntest_rename_model_reverse_relation_dependencies (migrations.test_autodetector.AutodetectorTests)\nThe migration to rename a model pointed to by a foreign key in another ... ok\ntest_rename_model_with_fks_in_different_position (migrations.test_autodetector.AutodetectorTests)\n#24537 - The order of fields in a model does not influence ... ok\ntest_rename_model_with_renamed_rel_field (migrations.test_autodetector.AutodetectorTests)\nTests autodetection of renamed models while simultaneously renaming one ... ok\ntest_rename_referenced_primary_key (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_rename_related_field_preserved_db_column (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_renamed_referenced_m2m_model_case (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_replace_string_with_foreignkey (migrations.test_autodetector.AutodetectorTests)\n#22300 - Adding an FK in the same \"spot\" as a deleted CharField should ... ok\ntest_same_app_circular_fk_dependency (migrations.test_autodetector.AutodetectorTests)\nA migration with a FK between two models of the same app does ... ok\ntest_same_app_circular_fk_dependency_with_unique_together_and_indexes (migrations.test_autodetector.AutodetectorTests)\n#22275 - A migration with circular FK dependency does not try ... ok\ntest_same_app_no_fk_dependency (migrations.test_autodetector.AutodetectorTests)\nA migration with a FK between two models of the same app ... ok\ntest_set_alter_order_with_respect_to (migrations.test_autodetector.AutodetectorTests)\nSetting order_with_respect_to adds a field. ... ok\ntest_set_alter_order_with_respect_to_index_constraint_foo_together (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_supports_functools_partial (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_swappable (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_swappable_changed (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_swappable_circular_multi_mti (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_swappable_first_inheritance (migrations.test_autodetector.AutodetectorTests)\nSwappable models get their CreateModel first. ... ok\ntest_swappable_first_setting (migrations.test_autodetector.AutodetectorTests)\nSwappable models get their CreateModel first. ... ok\ntest_trim_apps (migrations.test_autodetector.AutodetectorTests)\nTrim does not remove dependencies but does remove unwanted apps. ... ok\ntest_unmanaged_create (migrations.test_autodetector.AutodetectorTests)\nThe autodetector correctly deals with managed models. ... ok\ntest_unmanaged_custom_pk (migrations.test_autodetector.AutodetectorTests)\n#23415 - The autodetector must correctly deal with custom FK on ... ok\ntest_unmanaged_delete (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_unmanaged_to_managed (migrations.test_autodetector.AutodetectorTests) ... ok\n\n----------------------------------------------------------------------\nRan 139 tests in 0.168s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/migrations/test_autodetector.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-15127",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 17.164700984954834,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 1,
          "failed": 1,
          "errors": 0,
          "duration": 8.48,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application messages_tests\nFound 2 test(s).\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_eq (messages_tests.tests.MessageTests) ... ok\ntest_override_settings_level_tags (messages_tests.tests.TestLevelTags) ... FAIL\n\n======================================================================\nFAIL: test_override_settings_level_tags (messages_tests.tests.TestLevelTags)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/django/test/utils.py\", line 437, in inner\n    return func(*args, **kwargs)\n  File \"/testbed/tests/messages_tests/tests.py\", line 33, in test_override_settings_level_tags\n    self.assertEqual(base.LEVEL_TAGS, self.message_tags)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 837, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 1136, in assertDictEqual\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 676, in fail\n    raise self.failureException(msg)\nAssertionError: {10: 'debug', 20: 'info', 25: 'success', 30: 'warning', 40: 'error'} != {20: 'info', 10: '', 30: '', 40: 'bad', 25: '', 12: 'custom'}\n- {10: 'debug', 20: 'info', 25: 'success', 30: 'warning', 40: 'error'}\n+ {10: '', 12: 'custom', 20: 'info', 25: '', 30: '', 40: 'bad'}\n\n----------------------------------------------------------------------\nRan 2 tests in 0.045s\n\nFAILED (failures=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 messages_tests.base messages_tests.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/messages_tests/base.py",
            "tests/messages_tests/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 2,
          "failed": 0,
          "errors": 0,
          "duration": 6.99,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application messages_tests\nFound 2 test(s).\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_override_settings_level_tags (messages_tests.tests.TestLevelTags) ... ok\ntest_eq (messages_tests.tests.MessageTests) ... ok\n\n----------------------------------------------------------------------\nRan 2 tests in 0.024s\n\nOK\n",
          "test_files_run": [
            "tests/messages_tests/base.py",
            "tests/messages_tests/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-15128",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 20.329869985580444,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 293,
          "failed": 2,
          "errors": 0,
          "duration": 10.57,
          "log_tail": "Destroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 queries.models queries.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/queries/models.py",
            "tests/queries/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 295,
          "failed": 0,
          "errors": 0,
          "duration": 8.37,
          "log_tail": "Destroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/queries/models.py",
            "tests/queries/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-15161",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 18.674851179122925,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 213,
          "failed": 1,
          "errors": 0,
          "duration": 9.67,
          "log_tail": "?                  ------------\n+ django.db.models.Value\n\n\n======================================================================\nFAIL: test_serialize_complex_func_index (migrations.test_writer.WriterTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/tests/migrations/test_writer.py\", line 625, in test_serialize_complex_func_index\n    self.assertEqual(\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 837, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 1217, in assertMultiLineEqual\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 676, in fail\n    raise self.failureException(msg)\nAssertionError: \"models.Index(django.db.models.expressions.Func('rating[441 chars]ex')\" != \"models.Index(models.Func('rating', function='ABS'), mo[265 chars]ex')\"\nDiff is 829 characters long. Set self.maxDiff to None to see it.\n\n----------------------------------------------------------------------\nRan 214 tests in 0.276s\n\nFAILED (failures=3, skipped=1, expected failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 expressions.tests migrations.test_writer` failed. (See above for error)",
          "test_files_run": [
            "tests/expressions/tests.py",
            "tests/migrations/test_writer.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 214,
          "failed": 0,
          "errors": 0,
          "duration": 7.87,
          "log_tail": "test_order_by_multiline_sql (expressions.tests.BasicExpressionsTests) ... ok\ntest_order_of_operations (expressions.tests.BasicExpressionsTests) ... ok\ntest_outerref (expressions.tests.BasicExpressionsTests) ... ok\ntest_outerref_mixed_case_table_name (expressions.tests.BasicExpressionsTests) ... ok\ntest_outerref_with_operator (expressions.tests.BasicExpressionsTests) ... ok\ntest_parenthesis_priority (expressions.tests.BasicExpressionsTests) ... ok\ntest_pickle_expression (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_eq (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_filter_by_aggregate (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_filter_by_lazy (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_group_by_outerref_in_filter (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_in_filter (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_references_joined_table_twice (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_11722_iexact_lookup (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_16731_startswith_lookup (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_18375_chained_filters (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_18375_join_reuse (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_18375_kwarg_ordering (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_18375_kwarg_ordering_2 (expressions.tests.BasicExpressionsTests) ... ok\ntest_update (expressions.tests.BasicExpressionsTests) ... ok\ntest_update_inherited_field_value (expressions.tests.BasicExpressionsTests) ... ok\ntest_update_with_fk (expressions.tests.BasicExpressionsTests) ... ok\ntest_update_with_none (expressions.tests.BasicExpressionsTests) ... ok\ntest_uuid_pk_subquery (expressions.tests.BasicExpressionsTests) ... ok\n\n----------------------------------------------------------------------\nRan 214 tests in 0.250s\n\nOK (skipped=1, expected failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/expressions/tests.py",
            "tests/migrations/test_writer.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-15252",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 22.929681062698364,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 34,
          "failed": 1,
          "errors": 1,
          "duration": 11.76,
          "log_tail": "    method()\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/mock.py\", line 1336, in patched\n    return func(*newargs, **newkeywargs)\n  File \"/testbed/tests/migrations/test_executor.py\", line 771, in test_migrate_skips_schema_creation\n    executor.migrate([], plan=[])\n  File \"/testbed/django/db/migrations/executor.py\", line 100, in migrate\n    self.recorder.ensure_schema()\n  File \"/testbed/django/db/migrations/recorder.py\", line 70, in ensure_schema\n    raise MigrationSchemaMissing(\"Unable to create the django_migrations table (%s)\" % exc)\ndjango.db.migrations.exceptions.MigrationSchemaMissing: Unable to create the django_migrations table (table \"django_migrations\" already exists)\n\n======================================================================\nFAIL: test_migrate_test_setting_false_ensure_schema (backends.base.test_creation.TestDbCreationTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/mock.py\", line 1336, in patched\n    return func(*newargs, **newkeywargs)\n  File \"/testbed/tests/backends/base/test_creation.py\", line 104, in test_migrate_test_setting_false_ensure_schema\n    mocked_ensure_schema.assert_not_called()\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/mock.py\", line 868, in assert_not_called\n    raise AssertionError(msg)\nAssertionError: Expected 'ensure_schema' to not have been called. Called 1 times.\nCalls: [call()].\n\n----------------------------------------------------------------------\nRan 36 tests in 2.161s\n\nFAILED (failures=1, errors=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 backends.base.test_creation migrations.test_executor` failed. (See above for error)",
          "test_files_run": [
            "tests/backends/base/test_creation.py",
            "tests/migrations/test_executor.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 36,
          "failed": 0,
          "errors": 0,
          "duration": 8.76,
          "log_tail": "test_empty_plan (migrations.test_executor.ExecutorTests)\nRe-planning a full migration of a fully-migrated set doesn't ... ok\ntest_migrate_backward_to_squashed_migration (migrations.test_executor.ExecutorTests) ... ok\ntest_migrate_marks_replacement_applied_even_if_it_did_nothing (migrations.test_executor.ExecutorTests)\nA new squash migration will be marked as applied even if all its ... ok\ntest_migrate_marks_replacement_unapplied (migrations.test_executor.ExecutorTests) ... ok\ntest_migrate_skips_schema_creation (migrations.test_executor.ExecutorTests)\nThe django_migrations table is not created if there are no migrations ... ok\ntest_migrations_applied_and_recorded_atomically (migrations.test_executor.ExecutorTests)\nMigrations are applied and recorded atomically. ... ok\ntest_migrations_not_applied_on_deferred_sql_failure (migrations.test_executor.ExecutorTests)\nMigrations are not recorded if deferred SQL application fails. ... ok\ntest_mixed_plan_not_supported (migrations.test_executor.ExecutorTests)\nAlthough the MigrationExecutor interfaces allows for mixed migration ... ok\ntest_non_atomic_migration (migrations.test_executor.ExecutorTests)\nApplying a non-atomic migration works as expected. ... ok\ntest_process_callback (migrations.test_executor.ExecutorTests)\n#24129 - Tests callback process ... ok\ntest_run (migrations.test_executor.ExecutorTests)\nTests running a simple set of migrations. ... ok\ntest_run_with_squashed (migrations.test_executor.ExecutorTests)\nTests running a squashed migration from zero (should ignore what it replaces) ... ok\ntest_soft_apply (migrations.test_executor.ExecutorTests)\nTests detection of initial migrations already having been applied. ... ok\ntest_unrelated_applied_migrations_mutate_state (migrations.test_executor.ExecutorTests)\n#26647 - Unrelated applied migrations should be part of the final ... ok\ntest_unrelated_model_lookups_backwards (migrations.test_executor.ExecutorTests)\n#24123 - All models of apps being unapplied which are ... ok\ntest_unrelated_model_lookups_forwards (migrations.test_executor.ExecutorTests)\n#24123 - All models of apps already applied which are ... ok\n\n----------------------------------------------------------------------\nRan 36 tests in 1.872s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/backends/base/test_creation.py",
            "tests/migrations/test_executor.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-15268",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 18.877081155776978,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 137,
          "failed": 3,
          "errors": 0,
          "duration": 9.37,
          "log_tail": "  File \"/testbed/tests/migrations/test_autodetector.py\", line 513, in assertOperationTypes\n    self.fail(\"Operation type mismatch for %s.%s (expected %s):\\n%s\" % (\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 676, in fail\n    raise self.failureException(msg)\nAssertionError: Operation type mismatch for otherapp.auto_1 (expected ['AlterUniqueTogether', 'AlterIndexTogether', 'RemoveField']):\n  otherapp:\n    auto_1\n      <AlterUniqueTogether  name='book', unique_together=set()>\n      <AlterIndexTogether  name='book', index_together=set()>\n      <AlterUniqueTogether  name='book', unique_together={('author', 'title')}>\n      <AlterIndexTogether  name='book', index_together={('author', 'title')}>\n      <RemoveField  model_name='book', name='newfield'>\n\n\n======================================================================\nFAIL: test_rename_field_and_foo_together (migrations.test_autodetector.AutodetectorTests)\nFields are renamed before updating index/unique_together.\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/tests/migrations/test_autodetector.py\", line 1727, in test_rename_field_and_foo_together\n    self.assertOperationTypes(changes, 'otherapp', 0, [\n  File \"/testbed/tests/migrations/test_autodetector.py\", line 513, in assertOperationTypes\n    self.fail(\"Operation type mismatch for %s.%s (expected %s):\\n%s\" % (\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 676, in fail\n    raise self.failureException(msg)\nAssertionError: Operation type mismatch for otherapp.auto_1 (expected ['RenameField', 'AlterUniqueTogether', 'AlterIndexTogether']):\n  otherapp:\n    auto_1\n      <RenameField  model_name='book', old_name='newfield', new_name='newfield2'>\n      <AlterUniqueTogether  name='book', unique_together=set()>\n      <AlterIndexTogether  name='book', index_together=set()>\n      <AlterUniqueTogether  name='book', unique_together={('title', 'newfield2')}>\n      <AlterIndexTogether  name='book', index_together={('title', 'newfield2')}>\n\n\n----------------------------------------------------------------------\nRan 140 tests in 0.273s\n\nFAILED (failures=3)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 migrations.test_autodetector` failed. (See above for error)",
          "test_files_run": [
            "tests/migrations/test_autodetector.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 140,
          "failed": 0,
          "errors": 0,
          "duration": 8.13,
          "log_tail": "test_rename_model (migrations.test_autodetector.AutodetectorTests)\nTests autodetection of renamed models. ... ok\ntest_rename_model_case (migrations.test_autodetector.AutodetectorTests)\nModel name is case-insensitive. Changing case doesn't lead to any ... ok\ntest_rename_model_reverse_relation_dependencies (migrations.test_autodetector.AutodetectorTests)\nThe migration to rename a model pointed to by a foreign key in another ... ok\ntest_rename_model_with_fks_in_different_position (migrations.test_autodetector.AutodetectorTests)\n#24537 - The order of fields in a model does not influence ... ok\ntest_rename_model_with_renamed_rel_field (migrations.test_autodetector.AutodetectorTests)\nTests autodetection of renamed models while simultaneously renaming one ... ok\ntest_rename_referenced_primary_key (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_rename_related_field_preserved_db_column (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_renamed_referenced_m2m_model_case (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_replace_string_with_foreignkey (migrations.test_autodetector.AutodetectorTests)\n#22300 - Adding an FK in the same \"spot\" as a deleted CharField should ... ok\ntest_same_app_circular_fk_dependency (migrations.test_autodetector.AutodetectorTests)\nA migration with a FK between two models of the same app does ... ok\ntest_same_app_circular_fk_dependency_with_unique_together_and_indexes (migrations.test_autodetector.AutodetectorTests)\n#22275 - A migration with circular FK dependency does not try ... ok\ntest_same_app_no_fk_dependency (migrations.test_autodetector.AutodetectorTests)\nA migration with a FK between two models of the same app ... ok\ntest_set_alter_order_with_respect_to (migrations.test_autodetector.AutodetectorTests)\nSetting order_with_respect_to adds a field. ... ok\ntest_set_alter_order_with_respect_to_index_constraint_foo_together (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_supports_functools_partial (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_swappable (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_swappable_changed (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_swappable_circular_multi_mti (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_swappable_first_inheritance (migrations.test_autodetector.AutodetectorTests)\nSwappable models get their CreateModel first. ... ok\ntest_swappable_first_setting (migrations.test_autodetector.AutodetectorTests)\nSwappable models get their CreateModel first. ... ok\ntest_swappable_lowercase (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_trim_apps (migrations.test_autodetector.AutodetectorTests)\nTrim does not remove dependencies but does remove unwanted apps. ... ok\ntest_unmanaged_create (migrations.test_autodetector.AutodetectorTests)\nThe autodetector correctly deals with managed models. ... ok\ntest_unmanaged_custom_pk (migrations.test_autodetector.AutodetectorTests)\n#23415 - The autodetector must correctly deal with custom FK on ... ok\ntest_unmanaged_delete (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_unmanaged_to_managed (migrations.test_autodetector.AutodetectorTests) ... ok\n\n----------------------------------------------------------------------\nRan 140 tests in 0.226s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/migrations/test_autodetector.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-15277",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 18.464643001556396,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 161,
          "failed": 1,
          "errors": 1,
          "duration": 9.38,
          "log_tail": "test_multiple_query_compilation (expressions.tests.FTimeDeltaTests) ... ok\ntest_negative_timedelta_update (expressions.tests.FTimeDeltaTests) ... ok\ntest_query_clone (expressions.tests.FTimeDeltaTests) ... ok\ntest_time_subquery_subtraction (expressions.tests.FTimeDeltaTests) ... ok\ntest_time_subtraction (expressions.tests.FTimeDeltaTests) ... ok\n\n======================================================================\nERROR: test_output_field_does_not_create_broken_validators (expressions.tests.ValueTests) [<object object at 0x70c3aee05180>] (type=<class 'str'>)\nThe output field for a given Value doesn't get cleaned & validated,\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 499, in subTest\n    yield\n  File \"/testbed/tests/expressions/tests.py\", line 1877, in test_output_field_does_not_create_broken_validators\n    field.clean(value, model_instance=None)\n  File \"/testbed/django/db/models/fields/__init__.py\", line 672, in clean\n    self.run_validators(value)\n  File \"/testbed/django/db/models/fields/__init__.py\", line 624, in run_validators\n    v(value)\n  File \"/testbed/django/core/validators.py\", line 330, in __call__\n    if self.compare(cleaned, limit_value):\n  File \"/testbed/django/core/validators.py\", line 391, in compare\n    return a > b\nTypeError: '>' not supported between instances of 'int' and 'NoneType'\n\n----------------------------------------------------------------------\nRan 163 tests in 0.252s\n\nFAILED (errors=1, skipped=1, expected failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 expressions.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/expressions/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 163,
          "failed": 0,
          "errors": 0,
          "duration": 7.85,
          "log_tail": "test_object_update_unsaved_objects (expressions.tests.BasicExpressionsTests) ... ok\ntest_order_by_exists (expressions.tests.BasicExpressionsTests) ... ok\ntest_order_by_multiline_sql (expressions.tests.BasicExpressionsTests) ... ok\ntest_order_of_operations (expressions.tests.BasicExpressionsTests) ... ok\ntest_outerref (expressions.tests.BasicExpressionsTests) ... ok\ntest_outerref_mixed_case_table_name (expressions.tests.BasicExpressionsTests) ... ok\ntest_outerref_with_operator (expressions.tests.BasicExpressionsTests) ... ok\ntest_parenthesis_priority (expressions.tests.BasicExpressionsTests) ... ok\ntest_pickle_expression (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_eq (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_filter_by_aggregate (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_filter_by_lazy (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_group_by_outerref_in_filter (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_in_filter (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_references_joined_table_twice (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_11722_iexact_lookup (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_16731_startswith_lookup (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_18375_chained_filters (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_18375_join_reuse (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_18375_kwarg_ordering (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_18375_kwarg_ordering_2 (expressions.tests.BasicExpressionsTests) ... ok\ntest_update (expressions.tests.BasicExpressionsTests) ... ok\ntest_update_inherited_field_value (expressions.tests.BasicExpressionsTests) ... ok\ntest_update_with_fk (expressions.tests.BasicExpressionsTests) ... ok\ntest_update_with_none (expressions.tests.BasicExpressionsTests) ... ok\ntest_uuid_pk_subquery (expressions.tests.BasicExpressionsTests) ... ok\n\n----------------------------------------------------------------------\nRan 163 tests in 0.263s\n\nOK (skipped=1, expected failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/expressions/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-15278",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 22.614115953445435,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 172,
          "failed": 0,
          "errors": 1,
          "duration": 11.36,
          "log_tail": "test_unique_together (schema.tests.SchemaTests)\nTests removing and adding unique_together constraints on a model. ... ok\ntest_unique_together_with_fk (schema.tests.SchemaTests)\nTests removing and adding unique_together constraints that include ... ok\ntest_unique_together_with_fk_with_existing_index (schema.tests.SchemaTests)\nTests removing and adding unique_together constraints that include ... ok\ntest_unsupported_transactional_ddl_disallowed (schema.tests.SchemaTests) ... skipped 'Database has feature(s) can_rollback_ddl'\n\n======================================================================\nERROR: test_add_field_o2o_nullable (schema.tests.SchemaTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/django/db/backends/utils.py\", line 85, in _execute\n    return self.cursor.execute(sql, params)\n  File \"/testbed/django/db/backends/sqlite3/base.py\", line 334, in execute\n    return Database.Cursor.execute(self, query, params)\nsqlite3.OperationalError: Cannot add a UNIQUE column\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/testbed/tests/schema/tests.py\", line 634, in test_add_field_o2o_nullable\n    editor.add_field(Author, new_field)\n  File \"/testbed/django/db/backends/sqlite3/schema.py\", line 333, in add_field\n    super().add_field(model, field)\n  File \"/testbed/django/db/backends/base/schema.py\", line 532, in add_field\n    self.execute(sql, params)\n  File \"/testbed/django/db/backends/base/schema.py\", line 151, in execute\n    cursor.execute(sql, params)\n  File \"/testbed/django/db/backends/utils.py\", line 67, in execute\n    return self._execute_with_wrappers(sql, params, many=False, executor=self._execute)\n  File \"/testbed/django/db/backends/utils.py\", line 76, in _execute_with_wrappers\n    return executor(sql, params, many, context)\n  File \"/testbed/django/db/backends/utils.py\", line 85, in _execute\n    return self.cursor.execute(sql, params)\n  File \"/testbed/django/db/utils.py\", line 90, in __exit__\n    raise dj_exc_value.with_traceback(traceback) from exc_value\n  File \"/testbed/django/db/backends/utils.py\", line 85, in _execute\n    return self.cursor.execute(sql, params)\n  File \"/testbed/django/db/backends/sqlite3/base.py\", line 334, in execute\n    return Database.Cursor.execute(self, query, params)\ndjango.db.utils.OperationalError: Cannot add a UNIQUE column\n\n----------------------------------------------------------------------\nRan 173 tests in 2.388s\n\nFAILED (errors=1, skipped=28)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 schema.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/schema/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 173,
          "failed": 0,
          "errors": 0,
          "duration": 9.1,
          "log_tail": "test_no_db_constraint_added_during_primary_key_change (schema.tests.SchemaTests)\nWhen a primary key that's pointed to by a ForeignKey with ... ok\ntest_order_index (schema.tests.SchemaTests)\nIndexes defined with ordering (ASC/DESC) defined on column ... ok\ntest_primary_key (schema.tests.SchemaTests)\nTests altering of the primary key ... ok\ntest_referenced_field_without_constraint_rename_inside_atomic_block (schema.tests.SchemaTests)\nForeign keys without database level constraint don't prevent the field ... ok\ntest_referenced_table_without_constraint_rename_inside_atomic_block (schema.tests.SchemaTests)\nForeign keys without database level constraint don't prevent the table ... ok\ntest_remove_constraints_capital_letters (schema.tests.SchemaTests)\n#23065 - Constraint names must be quoted if they contain capital letters. ... ok\ntest_remove_db_index_doesnt_remove_custom_indexes (schema.tests.SchemaTests)\nChanging db_index to False doesn't remove indexes from Meta.indexes. ... ok\ntest_remove_field_check_does_not_remove_meta_constraints (schema.tests.SchemaTests) ... ok\ntest_remove_field_unique_does_not_remove_meta_constraints (schema.tests.SchemaTests) ... ok\ntest_remove_index_together_does_not_remove_meta_indexes (schema.tests.SchemaTests) ... ok\ntest_remove_unique_together_does_not_remove_meta_constraints (schema.tests.SchemaTests) ... ok\ntest_rename (schema.tests.SchemaTests)\nTests simple altering of fields ... ok\ntest_rename_column_renames_deferred_sql_references (schema.tests.SchemaTests) ... skipped 'SQLite naively remakes the table on field alteration.'\ntest_rename_keep_null_status (schema.tests.SchemaTests)\nRenaming a field shouldn't affect the not null status. ... ok\ntest_rename_referenced_field (schema.tests.SchemaTests) ... ok\ntest_rename_table_renames_deferred_sql_references (schema.tests.SchemaTests) ... ok\ntest_text_field_with_db_index (schema.tests.SchemaTests) ... ok\ntest_text_field_with_db_index_to_fk (schema.tests.SchemaTests) ... ok\ntest_unique (schema.tests.SchemaTests)\nTests removing and adding unique constraints to a single column. ... ok\ntest_unique_and_reverse_m2m (schema.tests.SchemaTests)\nAlterField can modify a unique field when there's a reverse M2M ... skipped 'SQLite naively remakes the table on field alteration.'\ntest_unique_constraint (schema.tests.SchemaTests) ... ok\ntest_unique_constraint_field_and_expression (schema.tests.SchemaTests) ... ok\ntest_unique_name_quoting (schema.tests.SchemaTests) ... ok\ntest_unique_no_unnecessary_fk_drops (schema.tests.SchemaTests)\nIf AlterField isn't selective about dropping foreign key constraints ... skipped 'SQLite naively remakes the table on field alteration.'\ntest_unique_together (schema.tests.SchemaTests)\nTests removing and adding unique_together constraints on a model. ... ok\ntest_unique_together_with_fk (schema.tests.SchemaTests)\nTests removing and adding unique_together constraints that include ... ok\ntest_unique_together_with_fk_with_existing_index (schema.tests.SchemaTests)\nTests removing and adding unique_together constraints that include ... ok\ntest_unsupported_transactional_ddl_disallowed (schema.tests.SchemaTests) ... skipped 'Database has feature(s) can_rollback_ddl'\n\n----------------------------------------------------------------------\nRan 173 tests in 2.130s\n\nOK (skipped=28)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/schema/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-15280",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 18.575602054595947,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 85,
          "failed": 1,
          "errors": 0,
          "duration": 9.52,
          "log_tail": "  File \"/testbed/django/test/testcases.py\", line 84, in __exit__\n    self.test_case.assertEqual(\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 837, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 830, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: 1 != 0 : 1 queries executed, 0 expected\nCaptured queries were:\n1. SELECT \"prefetch_related_house\".\"id\", \"prefetch_related_house\".\"address\" FROM \"prefetch_related_house\" WHERE \"prefetch_related_house\".\"id\" = 1 LIMIT 21\n\n----------------------------------------------------------------------\nRan 86 tests in 0.264s\n\nFAILED (failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 prefetch_related.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/prefetch_related/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 86,
          "failed": 0,
          "errors": 0,
          "duration": 7.68,
          "log_tail": "Nested prefetches whose name clashes with descriptor names ... ok\ntest_o2m_through_m2m (prefetch_related.tests.CustomPrefetchTests) ... ok\ntest_raw_queryset (prefetch_related.tests.CustomPrefetchTests) ... ok\ntest_reverse_m2m (prefetch_related.tests.CustomPrefetchTests) ... ok\ntest_to_attr_cached_property (prefetch_related.tests.CustomPrefetchTests) ... ok\ntest_to_attr_doesnt_cache_through_attr_as_list (prefetch_related.tests.CustomPrefetchTests) ... ok\ntest_traverse_multiple_items_property (prefetch_related.tests.CustomPrefetchTests) ... ok\ntest_traverse_qs (prefetch_related.tests.CustomPrefetchTests) ... ok\ntest_traverse_single_item_property (prefetch_related.tests.CustomPrefetchTests) ... ok\ntest_values_queryset (prefetch_related.tests.CustomPrefetchTests) ... ok\n\n----------------------------------------------------------------------\nRan 86 tests in 0.268s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/prefetch_related/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-15315",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 18.057680130004883,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 33,
          "failed": 1,
          "errors": 0,
          "duration": 9.02,
          "log_tail": "Fields are ordered based on their creation. ... ok\ntest_field_repr (model_fields.tests.BasicFieldTests)\n__repr__() of a field displays its name. ... ok\ntest_field_repr_nested (model_fields.tests.BasicFieldTests)\n__repr__() uses __qualname__ for nested class support. ... ok\ntest_field_str (model_fields.tests.BasicFieldTests) ... ok\ntest_field_verbose_name (model_fields.tests.BasicFieldTests) ... ok\ntest_formfield_disabled (model_fields.tests.BasicFieldTests)\nField.formfield() sets disabled for fields with choices. ... ok\ntest_hash_immutability (model_fields.tests.BasicFieldTests) ... FAIL\ntest_show_hidden_initial (model_fields.tests.BasicFieldTests)\nFields with choices respect show_hidden_initial as a kwarg to ... ok\ntest_get_choices (model_fields.tests.GetChoicesLimitChoicesToTests) ... ok\ntest_get_choices_reverse_related_field (model_fields.tests.GetChoicesLimitChoicesToTests) ... ok\ntest_get_choices (model_fields.tests.GetChoicesOrderingTests) ... ok\ntest_get_choices_default_ordering (model_fields.tests.GetChoicesOrderingTests) ... ok\ntest_get_choices_reverse_related_field (model_fields.tests.GetChoicesOrderingTests) ... ok\ntest_get_choices_reverse_related_field_default_ordering (model_fields.tests.GetChoicesOrderingTests) ... ok\n\n======================================================================\nFAIL: test_hash_immutability (model_fields.tests.BasicFieldTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/tests/model_fields/tests.py\", line 138, in test_hash_immutability\n    self.assertEqual(field_hash, hash(field))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 837, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 830, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: 8113426018888112013 != 7322114465313928270\n\n----------------------------------------------------------------------\nRan 34 tests in 0.065s\n\nFAILED (failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 model_fields.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/model_fields/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 34,
          "failed": 0,
          "errors": 0,
          "duration": 7.36,
          "log_tail": "test_empty_iterator_choices (model_fields.tests.GetFieldDisplayTests)\nget_choices() works with empty iterators. ... ok\ntest_get_FIELD_display_translated (model_fields.tests.GetFieldDisplayTests)\nA translated display value is coerced to str. ... ok\ntest_iterator_choices (model_fields.tests.GetFieldDisplayTests)\nget_choices() works with Iterators. ... ok\ntest_overriding_FIELD_display (model_fields.tests.GetFieldDisplayTests) ... ok\ntest_overriding_inherited_FIELD_display (model_fields.tests.GetFieldDisplayTests) ... ok\ntest_abstract_inherited_fields (model_fields.tests.BasicFieldTests)\nField instances from abstract models are not equal. ... ok\ntest_choices_form_class (model_fields.tests.BasicFieldTests)\nCan supply a custom choices form class to Field.formfield() ... ok\ntest_deconstruct_nested_field (model_fields.tests.BasicFieldTests)\ndeconstruct() uses __qualname__ for nested class support. ... ok\ntest_field_instance_is_picklable (model_fields.tests.BasicFieldTests)\nField instances can be pickled. ... ok\ntest_field_name (model_fields.tests.BasicFieldTests)\nA defined field name (name=\"fieldname\") is used instead of the model ... ok\ntest_field_ordering (model_fields.tests.BasicFieldTests)\nFields are ordered based on their creation. ... ok\ntest_field_repr (model_fields.tests.BasicFieldTests)\n__repr__() of a field displays its name. ... ok\ntest_field_repr_nested (model_fields.tests.BasicFieldTests)\n__repr__() uses __qualname__ for nested class support. ... ok\ntest_field_str (model_fields.tests.BasicFieldTests) ... ok\ntest_field_verbose_name (model_fields.tests.BasicFieldTests) ... ok\ntest_formfield_disabled (model_fields.tests.BasicFieldTests)\nField.formfield() sets disabled for fields with choices. ... ok\ntest_hash_immutability (model_fields.tests.BasicFieldTests) ... ok\ntest_show_hidden_initial (model_fields.tests.BasicFieldTests)\nFields with choices respect show_hidden_initial as a kwarg to ... ok\ntest_get_choices (model_fields.tests.GetChoicesOrderingTests) ... ok\ntest_get_choices_default_ordering (model_fields.tests.GetChoicesOrderingTests) ... ok\ntest_get_choices_reverse_related_field (model_fields.tests.GetChoicesOrderingTests) ... ok\ntest_get_choices_reverse_related_field_default_ordering (model_fields.tests.GetChoicesOrderingTests) ... ok\ntest_get_choices (model_fields.tests.GetChoicesLimitChoicesToTests) ... ok\ntest_get_choices_reverse_related_field (model_fields.tests.GetChoicesLimitChoicesToTests) ... ok\n\n----------------------------------------------------------------------\nRan 34 tests in 0.052s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/model_fields/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-15368",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 18.942543029785156,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 29,
          "failed": 1,
          "errors": 0,
          "duration": 10.07,
          "log_tail": "test_ipaddressfield (queries.test_bulk_update.BulkUpdateTests) ... ok\ntest_json_field (queries.test_bulk_update.BulkUpdateTests) ... ok\ntest_large_batch (queries.test_bulk_update.BulkUpdateTests) ... ok\ntest_no_fields (queries.test_bulk_update.BulkUpdateTests) ... ok\ntest_nonexistent_field (queries.test_bulk_update.BulkUpdateTests) ... ok\ntest_nullable_fk_after_related_save (queries.test_bulk_update.BulkUpdateTests) ... ok\ntest_only_concrete_fields_allowed (queries.test_bulk_update.BulkUpdateTests) ... ok\ntest_unsaved_parent (queries.test_bulk_update.BulkUpdateTests) ... ok\ntest_unspecified_unsaved_parent (queries.test_bulk_update.BulkUpdateTests) ... ok\ntest_update_custom_primary_key (queries.test_bulk_update.BulkUpdateTests) ... ok\ntest_update_primary_key (queries.test_bulk_update.BulkUpdateTests) ... ok\ntest_updated_rows_when_passing_duplicates (queries.test_bulk_update.BulkUpdateTests) ... ok\n\n======================================================================\nFAIL: test_f_expression (queries.test_bulk_update.BulkUpdateTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/tests/queries/test_bulk_update.py\", line 222, in test_f_expression\n    self.assertCountEqual(Note.objects.filter(misc='test_note'), notes)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 1197, in assertCountEqual\n    self.fail(msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 676, in fail\n    raise self.failureException(msg)\nAssertionError: Element counts were not equal:\nFirst has 0, Second has 1:  <Note: test_note>\nFirst has 0, Second has 1:  <Note: test_note>\nFirst has 0, Second has 1:  <Note: test_note>\nFirst has 0, Second has 1:  <Note: test_note>\nFirst has 0, Second has 1:  <Note: test_note>\nFirst has 0, Second has 1:  <Note: test_note>\nFirst has 0, Second has 1:  <Note: test_note>\nFirst has 0, Second has 1:  <Note: test_note>\nFirst has 0, Second has 1:  <Note: test_note>\nFirst has 0, Second has 1:  <Note: test_note>\n\n----------------------------------------------------------------------\nRan 30 tests in 0.641s\n\nFAILED (failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 queries.test_bulk_update` failed. (See above for error)",
          "test_files_run": [
            "tests/queries/test_bulk_update.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 30,
          "failed": 0,
          "errors": 0,
          "duration": 7.61,
          "log_tail": "  Applying admin.0001_initial... OK\n  Applying admin.0002_logentry_remove_auto_add... OK\n  Applying admin.0003_logentry_add_action_flag_choices... OK\n  Applying sites.0001_initial... OK\n  Applying sites.0002_alter_domain_unique... OK\nSystem check identified no issues (1 silenced).\n\n\nCreating test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\ntest_batch_size (queries.test_bulk_update.BulkUpdateNoteTests) ... ok\ntest_foreign_keys_do_not_lookup (queries.test_bulk_update.BulkUpdateNoteTests) ... ok\ntest_functions (queries.test_bulk_update.BulkUpdateNoteTests) ... ok\ntest_multiple_fields (queries.test_bulk_update.BulkUpdateNoteTests) ... ok\ntest_set_field_to_null (queries.test_bulk_update.BulkUpdateNoteTests) ... ok\ntest_set_mixed_fields_to_null (queries.test_bulk_update.BulkUpdateNoteTests) ... ok\ntest_simple (queries.test_bulk_update.BulkUpdateNoteTests) ... ok\ntest_unsaved_models (queries.test_bulk_update.BulkUpdateNoteTests) ... ok\ntest_booleanfield (queries.test_bulk_update.BulkUpdateTests) ... ok\ntest_custom_db_columns (queries.test_bulk_update.BulkUpdateTests) ... ok\ntest_custom_pk (queries.test_bulk_update.BulkUpdateTests) ... ok\ntest_datetime_field (queries.test_bulk_update.BulkUpdateTests) ... ok\ntest_empty_objects (queries.test_bulk_update.BulkUpdateTests) ... ok\ntest_f_expression (queries.test_bulk_update.BulkUpdateTests) ... ok\ntest_falsey_pk_value (queries.test_bulk_update.BulkUpdateTests) ... ok\ntest_field_references (queries.test_bulk_update.BulkUpdateTests) ... ok\ntest_inherited_fields (queries.test_bulk_update.BulkUpdateTests) ... ok\ntest_invalid_batch_size (queries.test_bulk_update.BulkUpdateTests) ... ok\ntest_ipaddressfield (queries.test_bulk_update.BulkUpdateTests) ... ok\ntest_json_field (queries.test_bulk_update.BulkUpdateTests) ... ok\ntest_large_batch (queries.test_bulk_update.BulkUpdateTests) ... ok\ntest_no_fields (queries.test_bulk_update.BulkUpdateTests) ... ok\ntest_nonexistent_field (queries.test_bulk_update.BulkUpdateTests) ... ok\ntest_nullable_fk_after_related_save (queries.test_bulk_update.BulkUpdateTests) ... ok\ntest_only_concrete_fields_allowed (queries.test_bulk_update.BulkUpdateTests) ... ok\ntest_unsaved_parent (queries.test_bulk_update.BulkUpdateTests) ... ok\ntest_unspecified_unsaved_parent (queries.test_bulk_update.BulkUpdateTests) ... ok\ntest_update_custom_primary_key (queries.test_bulk_update.BulkUpdateTests) ... ok\ntest_update_primary_key (queries.test_bulk_update.BulkUpdateTests) ... ok\ntest_updated_rows_when_passing_duplicates (queries.test_bulk_update.BulkUpdateTests) ... ok\n\n----------------------------------------------------------------------\nRan 30 tests in 0.440s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/queries/test_bulk_update.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-15375",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 16.58562684059143,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 95,
          "failed": 0,
          "errors": 1,
          "duration": 8.42,
          "log_tail": "Subqueries do not needlessly contain ORDER BY, SELECT FOR UPDATE or ... ok\ntest_ticket12886 (aggregation.tests.AggregateTestCase)\nAggregation over sliced queryset works correctly. ... ok\ntest_ticket17424 (aggregation.tests.AggregateTestCase)\nDoing exclude() on a foreign model after annotate() doesn't crash. ... ok\ntest_values_aggregation (aggregation.tests.AggregateTestCase) ... ok\ntest_values_annotation_with_expression (aggregation.tests.AggregateTestCase) ... ok\n\n======================================================================\nERROR: test_aggregation_default_after_annotation (aggregation.tests.AggregateTestCase)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/django/db/backends/utils.py\", line 85, in _execute\n    return self.cursor.execute(sql, params)\n  File \"/testbed/django/db/backends/sqlite3/base.py\", line 334, in execute\n    return Database.Cursor.execute(self, query, params)\nsqlite3.OperationalError: near \"FROM\": syntax error\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/testbed/tests/aggregation/tests.py\", line 1634, in test_aggregation_default_after_annotation\n    result = Publisher.objects.annotate(\n  File \"/testbed/django/db/models/query.py\", line 432, in aggregate\n    return query.get_aggregation(self.db, kwargs)\n  File \"/testbed/django/db/models/sql/query.py\", line 504, in get_aggregation\n    result = compiler.execute_sql(SINGLE)\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1216, in execute_sql\n    cursor.execute(sql, params)\n  File \"/testbed/django/db/backends/utils.py\", line 67, in execute\n    return self._execute_with_wrappers(sql, params, many=False, executor=self._execute)\n  File \"/testbed/django/db/backends/utils.py\", line 76, in _execute_with_wrappers\n    return executor(sql, params, many, context)\n  File \"/testbed/django/db/backends/utils.py\", line 85, in _execute\n    return self.cursor.execute(sql, params)\n  File \"/testbed/django/db/utils.py\", line 90, in __exit__\n    raise dj_exc_value.with_traceback(traceback) from exc_value\n  File \"/testbed/django/db/backends/utils.py\", line 85, in _execute\n    return self.cursor.execute(sql, params)\n  File \"/testbed/django/db/backends/sqlite3/base.py\", line 334, in execute\n    return Database.Cursor.execute(self, query, params)\ndjango.db.utils.OperationalError: near \"FROM\": syntax error\n\n----------------------------------------------------------------------\nRan 96 tests in 0.278s\n\nFAILED (errors=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 aggregation.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/aggregation/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 96,
          "failed": 0,
          "errors": 0,
          "duration": 6.74,
          "log_tail": "test_dates_with_aggregation (aggregation.tests.AggregateTestCase)\n.dates() returns a distinct set of dates when applied to a ... ok\ntest_decimal_max_digits_has_no_effect (aggregation.tests.AggregateTestCase) ... ok\ntest_distinct_on_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_empty_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_empty_result_optimization (aggregation.tests.AggregateTestCase) ... ok\ntest_even_more_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_exists_extra_where_with_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_exists_none_with_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_expression_on_aggregation (aggregation.tests.AggregateTestCase) ... ok\ntest_filter_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_filter_in_subquery_or_aggregation (aggregation.tests.AggregateTestCase)\nFiltering against an aggregate requires the usage of the HAVING clause. ... ok\ntest_filtering (aggregation.tests.AggregateTestCase) ... ok\ntest_fkey_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_group_by_exists_annotation (aggregation.tests.AggregateTestCase)\nExists annotations are included in the GROUP BY if they are ... ok\ntest_group_by_subquery_annotation (aggregation.tests.AggregateTestCase)\nSubquery annotations are included in the GROUP BY if they are ... ok\ntest_grouped_annotation_in_group_by (aggregation.tests.AggregateTestCase)\nAn annotation included in values() before an aggregate should be ... ok\ntest_more_aggregation (aggregation.tests.AggregateTestCase) ... ok\ntest_multi_arg_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_multiple_aggregates (aggregation.tests.AggregateTestCase) ... ok\ntest_non_grouped_annotation_not_in_group_by (aggregation.tests.AggregateTestCase)\nAn annotation not included in values() before an aggregate should be ... ok\ntest_nonaggregate_aggregation_throws (aggregation.tests.AggregateTestCase) ... ok\ntest_nonfield_annotation (aggregation.tests.AggregateTestCase) ... ok\ntest_order_of_precedence (aggregation.tests.AggregateTestCase) ... ok\ntest_related_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_reverse_fkey_annotate (aggregation.tests.AggregateTestCase) ... ok\ntest_single_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_sum_distinct_aggregate (aggregation.tests.AggregateTestCase)\nSum on a distinct() QuerySet should aggregate only the distinct items. ... ok\ntest_sum_duration_field (aggregation.tests.AggregateTestCase) ... ok\ntest_ticket11881 (aggregation.tests.AggregateTestCase)\nSubqueries do not needlessly contain ORDER BY, SELECT FOR UPDATE or ... ok\ntest_ticket12886 (aggregation.tests.AggregateTestCase)\nAggregation over sliced queryset works correctly. ... ok\ntest_ticket17424 (aggregation.tests.AggregateTestCase)\nDoing exclude() on a foreign model after annotate() doesn't crash. ... ok\ntest_values_aggregation (aggregation.tests.AggregateTestCase) ... ok\ntest_values_annotation_with_expression (aggregation.tests.AggregateTestCase) ... ok\n\n----------------------------------------------------------------------\nRan 96 tests in 0.212s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/aggregation/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-15380",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 18.374752044677734,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 140,
          "failed": 0,
          "errors": 1,
          "duration": 8.91,
          "log_tail": "test_set_alter_order_with_respect_to (migrations.test_autodetector.AutodetectorTests)\nSetting order_with_respect_to adds a field. ... ok\ntest_set_alter_order_with_respect_to_index_constraint_foo_together (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_supports_functools_partial (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_swappable (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_swappable_changed (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_swappable_circular_multi_mti (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_swappable_first_inheritance (migrations.test_autodetector.AutodetectorTests)\nSwappable models get their CreateModel first. ... ok\ntest_swappable_first_setting (migrations.test_autodetector.AutodetectorTests)\nSwappable models get their CreateModel first. ... ok\ntest_swappable_lowercase (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_trim_apps (migrations.test_autodetector.AutodetectorTests)\nTrim does not remove dependencies but does remove unwanted apps. ... ok\ntest_unmanaged_create (migrations.test_autodetector.AutodetectorTests)\nThe autodetector correctly deals with managed models. ... ok\ntest_unmanaged_custom_pk (migrations.test_autodetector.AutodetectorTests)\n#23415 - The autodetector must correctly deal with custom FK on ... ok\ntest_unmanaged_delete (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_unmanaged_to_managed (migrations.test_autodetector.AutodetectorTests) ... ok\n\n======================================================================\nERROR: test_rename_field_with_renamed_model (migrations.test_autodetector.AutodetectorTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/tests/migrations/test_autodetector.py\", line 1053, in test_rename_field_with_renamed_model\n    changes = self.get_changes(\n  File \"/testbed/tests/migrations/test_autodetector.py\", line 591, in get_changes\n    return MigrationAutodetector(\n  File \"/testbed/django/db/migrations/autodetector.py\", line 182, in _detect_changes\n    self.generate_renamed_fields()\n  File \"/testbed/django/db/migrations/autodetector.py\", line 827, in generate_renamed_fields\n    new_model_state = self.to_state.models[app_label, old_model_name]\nKeyError: ('testapp', 'author')\n\n----------------------------------------------------------------------\nRan 141 tests in 0.356s\n\nFAILED (errors=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 migrations.test_autodetector` failed. (See above for error)",
          "test_files_run": [
            "tests/migrations/test_autodetector.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 141,
          "failed": 0,
          "errors": 0,
          "duration": 7.25,
          "log_tail": "test_rename_model (migrations.test_autodetector.AutodetectorTests)\nTests autodetection of renamed models. ... ok\ntest_rename_model_case (migrations.test_autodetector.AutodetectorTests)\nModel name is case-insensitive. Changing case doesn't lead to any ... ok\ntest_rename_model_reverse_relation_dependencies (migrations.test_autodetector.AutodetectorTests)\nThe migration to rename a model pointed to by a foreign key in another ... ok\ntest_rename_model_with_fks_in_different_position (migrations.test_autodetector.AutodetectorTests)\n#24537 - The order of fields in a model does not influence ... ok\ntest_rename_model_with_renamed_rel_field (migrations.test_autodetector.AutodetectorTests)\nTests autodetection of renamed models while simultaneously renaming one ... ok\ntest_rename_referenced_primary_key (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_rename_related_field_preserved_db_column (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_renamed_referenced_m2m_model_case (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_replace_string_with_foreignkey (migrations.test_autodetector.AutodetectorTests)\n#22300 - Adding an FK in the same \"spot\" as a deleted CharField should ... ok\ntest_same_app_circular_fk_dependency (migrations.test_autodetector.AutodetectorTests)\nA migration with a FK between two models of the same app does ... ok\ntest_same_app_circular_fk_dependency_with_unique_together_and_indexes (migrations.test_autodetector.AutodetectorTests)\n#22275 - A migration with circular FK dependency does not try ... ok\ntest_same_app_no_fk_dependency (migrations.test_autodetector.AutodetectorTests)\nA migration with a FK between two models of the same app ... ok\ntest_set_alter_order_with_respect_to (migrations.test_autodetector.AutodetectorTests)\nSetting order_with_respect_to adds a field. ... ok\ntest_set_alter_order_with_respect_to_index_constraint_foo_together (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_supports_functools_partial (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_swappable (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_swappable_changed (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_swappable_circular_multi_mti (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_swappable_first_inheritance (migrations.test_autodetector.AutodetectorTests)\nSwappable models get their CreateModel first. ... ok\ntest_swappable_first_setting (migrations.test_autodetector.AutodetectorTests)\nSwappable models get their CreateModel first. ... ok\ntest_swappable_lowercase (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_trim_apps (migrations.test_autodetector.AutodetectorTests)\nTrim does not remove dependencies but does remove unwanted apps. ... ok\ntest_unmanaged_create (migrations.test_autodetector.AutodetectorTests)\nThe autodetector correctly deals with managed models. ... ok\ntest_unmanaged_custom_pk (migrations.test_autodetector.AutodetectorTests)\n#23415 - The autodetector must correctly deal with custom FK on ... ok\ntest_unmanaged_delete (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_unmanaged_to_managed (migrations.test_autodetector.AutodetectorTests) ... ok\n\n----------------------------------------------------------------------\nRan 141 tests in 0.261s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/migrations/test_autodetector.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-15382",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 17.140144109725952,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 164,
          "failed": 1,
          "errors": 0,
          "duration": 8.93,
          "log_tail": "test_uuid_pk_subquery (expressions.tests.BasicExpressionsTests) ... ok\n\n======================================================================\nFAIL: test_negated_empty_exists (expressions.tests.ExistsTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/tests/expressions/tests.py\", line 1913, in test_negated_empty_exists\n    self.assertSequenceEqual(qs, [manager])\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 1025, in assertSequenceEqual\n    self.fail(msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 676, in fail\n    raise self.failureException(msg)\nAssertionError: Sequences differ: <QuerySet []> != [<Manager: Manager object (1)>]\n\nSecond sequence contains 1 additional elements.\nFirst extra element 0:\n<Manager: Manager object (1)>\n\n- <QuerySet []>\n+ [<Manager: Manager object (1)>]\n\n----------------------------------------------------------------------\nRan 165 tests in 0.268s\n\nFAILED (failures=1, skipped=1, expected failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 expressions.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/expressions/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 165,
          "failed": 0,
          "errors": 0,
          "duration": 7.02,
          "log_tail": "test_update_with_none (expressions.tests.BasicExpressionsTests) ... ok\ntest_uuid_pk_subquery (expressions.tests.BasicExpressionsTests) ... ok\ntest_date_case_subtraction (expressions.tests.FTimeDeltaTests) ... ok\ntest_date_comparison (expressions.tests.FTimeDeltaTests) ... ok\ntest_date_minus_duration (expressions.tests.FTimeDeltaTests) ... ok\ntest_date_subquery_subtraction (expressions.tests.FTimeDeltaTests) ... ok\ntest_date_subtraction (expressions.tests.FTimeDeltaTests) ... ok\ntest_datetime_subquery_subtraction (expressions.tests.FTimeDeltaTests) ... ok\ntest_datetime_subtraction (expressions.tests.FTimeDeltaTests) ... ok\ntest_datetime_subtraction_microseconds (expressions.tests.FTimeDeltaTests) ... ok\ntest_delta_add (expressions.tests.FTimeDeltaTests) ... ok\ntest_delta_subtract (expressions.tests.FTimeDeltaTests) ... ok\ntest_delta_update (expressions.tests.FTimeDeltaTests) ... ok\ntest_duration_expressions (expressions.tests.FTimeDeltaTests) ... ok\ntest_duration_with_datetime (expressions.tests.FTimeDeltaTests) ... ok\ntest_duration_with_datetime_microseconds (expressions.tests.FTimeDeltaTests) ... ok\ntest_durationfield_add (expressions.tests.FTimeDeltaTests) ... ok\ntest_durationfield_multiply_divide (expressions.tests.FTimeDeltaTests) ... ok\ntest_exclude (expressions.tests.FTimeDeltaTests) ... ok\ntest_invalid_operator (expressions.tests.FTimeDeltaTests) ... ok\ntest_mixed_comparisons1 (expressions.tests.FTimeDeltaTests) ... expected failure\ntest_mixed_comparisons2 (expressions.tests.FTimeDeltaTests) ... ok\ntest_multiple_query_compilation (expressions.tests.FTimeDeltaTests) ... ok\ntest_negative_timedelta_update (expressions.tests.FTimeDeltaTests) ... ok\ntest_query_clone (expressions.tests.FTimeDeltaTests) ... ok\ntest_time_subquery_subtraction (expressions.tests.FTimeDeltaTests) ... ok\ntest_time_subtraction (expressions.tests.FTimeDeltaTests) ... ok\n\n----------------------------------------------------------------------\nRan 165 tests in 0.240s\n\nOK (skipped=1, expected failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/expressions/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-15467",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 17.7553870677948,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 76,
          "failed": 1,
          "errors": 0,
          "duration": 8.37,
          "log_tail": "======================================================================\nFAIL: test_radio_fields_foreignkey_formfield_overrides_empty_label (admin_widgets.tests.AdminFormfieldForDBFieldTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/tests/admin_widgets/tests.py\", line 154, in test_radio_fields_foreignkey_formfield_overrides_empty_label\n    self.assertEqual(ff.empty_label, \"Custom empty label\")\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 837, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 1217, in assertMultiLineEqual\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 676, in fail\n    raise self.failureException(msg)\nAssertionError: 'None' != 'Custom empty label'\n- None\n+ Custom empty label\n\n\n----------------------------------------------------------------------\nRan 77 tests in 0.287s\n\nFAILED (failures=1, skipped=14)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 admin_widgets.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/admin_widgets/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 77,
          "failed": 0,
          "errors": 0,
          "duration": 7.34,
          "log_tail": "test_proper_manager_for_label_lookup (admin_widgets.tests.ForeignKeyRawIdWidgetTest) ... ok\ntest_relations_to_non_primary_key (admin_widgets.tests.ForeignKeyRawIdWidgetTest) ... ok\ntest_render (admin_widgets.tests.ForeignKeyRawIdWidgetTest) ... ok\ntest_render_fk_as_pk_model (admin_widgets.tests.ForeignKeyRawIdWidgetTest) ... ok\ntest_render_unsafe_limit_choices_to (admin_widgets.tests.ForeignKeyRawIdWidgetTest) ... ok\ntest_get_context_validates_url (admin_widgets.tests.AdminURLWidgetTest) ... ok\ntest_render (admin_widgets.tests.AdminURLWidgetTest) ... ok\ntest_render_idn (admin_widgets.tests.AdminURLWidgetTest) ... ok\ntest_render_quoting (admin_widgets.tests.AdminURLWidgetTest)\nWARNING: This test doesn't use assertHTMLEqual since it will get rid ... ok\ntest_filter_choices_by_request_user (admin_widgets.tests.AdminFormfieldForDBFieldWithRequestTests)\nEnsure the user can only see their own cars in the foreign key dropdown. ... ok\ntest_changelist_ForeignKey (admin_widgets.tests.AdminForeignKeyWidgetChangeList) ... ok\ntest_readonly_fields (admin_widgets.tests.AdminFileWidgetTests)\nFile widgets should render as a link when they're marked \"read only.\" ... ok\ntest_render (admin_widgets.tests.AdminFileWidgetTests) ... ok\ntest_render_disabled (admin_widgets.tests.AdminFileWidgetTests) ... ok\ntest_render_required (admin_widgets.tests.AdminFileWidgetTests) ... ok\ntest_invalid_target_id (admin_widgets.tests.AdminForeignKeyRawIdWidget) ... ok\ntest_label_and_url_for_value_invalid_uuid (admin_widgets.tests.AdminForeignKeyRawIdWidget) ... ok\ntest_nonexistent_target_id (admin_widgets.tests.AdminForeignKeyRawIdWidget) ... ok\ntest_url_params_from_lookup_dict_any_iterable (admin_widgets.tests.AdminForeignKeyRawIdWidget) ... ok\ntest_url_params_from_lookup_dict_callable (admin_widgets.tests.AdminForeignKeyRawIdWidget) ... ok\n\n----------------------------------------------------------------------\nRan 77 tests in 0.376s\n\nOK (skipped=14)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/admin_widgets/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-15499",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 15.414727210998535,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 35,
          "failed": 1,
          "errors": 0,
          "duration": 7.96,
          "log_tail": "test_create_rename_model (migrations.test_optimizer.OptimizerTests)\nCreateModel should absorb RenameModels. ... ok\ntest_none_app_label (migrations.test_optimizer.OptimizerTests) ... ok\ntest_optimize_elidable_operation (migrations.test_optimizer.OptimizerTests) ... ok\ntest_optimize_through_create (migrations.test_optimizer.OptimizerTests)\nWe should be able to optimize away create/delete through a create or ... ok\ntest_optimize_through_fields (migrations.test_optimizer.OptimizerTests)\nfield-level through checking is working. This should manage to collapse ... ok\ntest_rename_model_self (migrations.test_optimizer.OptimizerTests)\nRenameModels should absorb themselves. ... ok\ntest_single (migrations.test_optimizer.OptimizerTests)\nThe optimizer does nothing on a single operation, ... ok\ntest_swapping_fields_names (migrations.test_optimizer.OptimizerTests) ... ok\n\n======================================================================\nFAIL: test_create_alter_model_managers (migrations.test_optimizer.OptimizerTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/migrations/test_optimizer.py\", line 133, in test_create_alter_model_managers\n    self.assertOptimizesTo(\n  File \"/testbed/tests/migrations/test_optimizer.py\", line 31, in assertOptimizesTo\n    self.assertEqual(expected, result)\nAssertionError: Lists differ: [\"mig[56 chars] ],\\n    managers=[\\n        ('objects', djang[96 chars]\\n)\"] != [\"mig[56 chars] ],\\n)\", \"migrations.AlterModelManagers(\\n    [150 chars]\\n)\"]\n\nFirst differing element 0:\n\"migr[55 chars] ],\\n    managers=[\\n        ('objects', djang[95 chars],\\n)\"\n\"migr[55 chars] ],\\n)\"\n\nSecond list contains 1 additional elements.\nFirst extra element 1:\n\"migrations.AlterModelManagers(\\n    name='Foo',\\n    managers=[\\n        ('objects', django.db.models.manager.Manager()),\\n        ('things', django.db.models.manager.Manager()),\\n    ],\\n)\"\n\n- ['migrations.CreateModel(\\n'\n+ [\"migrations.CreateModel(\\n    name='Foo',\\n    fields=[\\n    ],\\n)\",\n+  'migrations.AlterModelManagers(\\n'\n   \"    name='Foo',\\n\"\n-  '    fields=[\\n'\n-  '    ],\\n'\n   '    managers=[\\n'\n   \"        ('objects', django.db.models.manager.Manager()),\\n\"\n   \"        ('things', django.db.models.manager.Manager()),\\n\"\n   '    ],\\n'\n   ')']\n\n----------------------------------------------------------------------\nRan 36 tests in 0.042s\n\nFAILED (failures=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 migrations.test_optimizer` failed. (See above for error)",
          "test_files_run": [
            "tests/migrations/test_optimizer.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 36,
          "failed": 0,
          "errors": 0,
          "duration": 6.23,
          "log_tail": "test_alter_field_rename_field (migrations.test_optimizer.OptimizerTests)\nRenameField should optimize to the other side of AlterField, ... ok\ntest_create_alter_index_delete_model (migrations.test_optimizer.OptimizerTests) ... ok\ntest_create_alter_index_field (migrations.test_optimizer.OptimizerTests) ... ok\ntest_create_alter_model_managers (migrations.test_optimizer.OptimizerTests) ... ok\ntest_create_alter_model_options (migrations.test_optimizer.OptimizerTests) ... ok\ntest_create_alter_owrt_delete_model (migrations.test_optimizer.OptimizerTests) ... ok\ntest_create_alter_owrt_field (migrations.test_optimizer.OptimizerTests) ... ok\ntest_create_alter_unique_delete_model (migrations.test_optimizer.OptimizerTests) ... ok\ntest_create_alter_unique_field (migrations.test_optimizer.OptimizerTests) ... ok\ntest_create_delete_model (migrations.test_optimizer.OptimizerTests)\nCreateModel and DeleteModel should collapse into nothing. ... ok\ntest_create_model_add_field (migrations.test_optimizer.OptimizerTests)\nAddField should optimize into CreateModel. ... ok\ntest_create_model_add_field_not_through_m2m_through (migrations.test_optimizer.OptimizerTests)\nAddField should NOT optimize into CreateModel if it's an M2M using a ... ok\ntest_create_model_alter_field (migrations.test_optimizer.OptimizerTests)\nAlterField should optimize into CreateModel. ... ok\ntest_create_model_and_remove_model_options (migrations.test_optimizer.OptimizerTests) ... ok\ntest_create_model_no_reordering_for_unrelated_fk (migrations.test_optimizer.OptimizerTests)\nCreateModel order remains unchanged if the later AddField operation ... ok\ntest_create_model_no_reordering_of_inherited_model (migrations.test_optimizer.OptimizerTests)\nA CreateModel that inherits from another isn't reordered to avoid ... ok\ntest_create_model_remove_field (migrations.test_optimizer.OptimizerTests)\nRemoveField should optimize into CreateModel. ... ok\ntest_create_model_rename_field (migrations.test_optimizer.OptimizerTests)\nRenameField should optimize into CreateModel. ... ok\ntest_create_model_reordering (migrations.test_optimizer.OptimizerTests)\nAddField optimizes into CreateModel if it's a FK to a model that's ... ok\ntest_create_model_reordering_circular_fk (migrations.test_optimizer.OptimizerTests)\nCreateModel reordering behavior doesn't result in an infinite loop if ... ok\ntest_create_rename_model (migrations.test_optimizer.OptimizerTests)\nCreateModel should absorb RenameModels. ... ok\ntest_none_app_label (migrations.test_optimizer.OptimizerTests) ... ok\ntest_optimize_elidable_operation (migrations.test_optimizer.OptimizerTests) ... ok\ntest_optimize_through_create (migrations.test_optimizer.OptimizerTests)\nWe should be able to optimize away create/delete through a create or ... ok\ntest_optimize_through_fields (migrations.test_optimizer.OptimizerTests)\nfield-level through checking is working. This should manage to collapse ... ok\ntest_rename_model_self (migrations.test_optimizer.OptimizerTests)\nRenameModels should absorb themselves. ... ok\ntest_single (migrations.test_optimizer.OptimizerTests)\nThe optimizer does nothing on a single operation, ... ok\ntest_swapping_fields_names (migrations.test_optimizer.OptimizerTests) ... ok\n\n----------------------------------------------------------------------\nRan 36 tests in 0.031s\n\nOK\n",
          "test_files_run": [
            "tests/migrations/test_optimizer.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-15503",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 16.7962908744812,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 79,
          "failed": 9,
          "errors": 0,
          "duration": 8.01,
          "log_tail": "  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 1025, in assertSequenceEqual\n    self.fail(msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 676, in fail\n    raise self.failureException(msg)\nAssertionError: Sequences differ: <QuerySet []> != [<NullableJSONModel: NullableJSONModel object (14)>]\n\nSecond sequence contains 1 additional elements.\nFirst extra element 0:\n<NullableJSONModel: NullableJSONModel object (14)>\n\n- <QuerySet []>\n+ [<NullableJSONModel: NullableJSONModel object (14)>]\n\n======================================================================\nFAIL: test_has_key_number (model_fields.test_jsonfield.TestQuerying) [<object object at 0x7800a05e66d0>] (condition=<Q: (AND: ('value__array__0__has_any_keys', ['777', 'nonexistent']))>)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 499, in subTest\n    yield\n  File \"/testbed/tests/model_fields/test_jsonfield.py\", line 601, in test_has_key_number\n    self.assertSequenceEqual(\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 1025, in assertSequenceEqual\n    self.fail(msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 676, in fail\n    raise self.failureException(msg)\nAssertionError: Sequences differ: <QuerySet []> != [<NullableJSONModel: NullableJSONModel object (14)>]\n\nSecond sequence contains 1 additional elements.\nFirst extra element 0:\n<NullableJSONModel: NullableJSONModel object (14)>\n\n- <QuerySet []>\n+ [<NullableJSONModel: NullableJSONModel object (14)>]\n\n----------------------------------------------------------------------\nRan 88 tests in 0.225s\n\nFAILED (failures=9, skipped=8)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 model_fields.test_jsonfield` failed. (See above for error)",
          "test_files_run": [
            "tests/model_fields/test_jsonfield.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 88,
          "failed": 0,
          "errors": 0,
          "duration": 7.47,
          "log_tail": "test_key_escape (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_key_icontains (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_key_iendswith (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_key_iexact (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_key_in (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_key_iregex (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_key_istartswith (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_key_quoted_string (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_key_regex (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_key_sql_injection (model_fields.test_jsonfield.TestQuerying) ... skipped \"Database doesn't support feature(s): has_json_operators\"\ntest_key_sql_injection_escape (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_key_startswith (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_key_transform_annotation_expression (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_key_transform_expression (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_key_transform_raw_expression (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_key_values (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_key_values_boolean (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_lookup_exclude (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_lookup_exclude_nonexistent_key (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_lookups_with_key_transform (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_nested_key_transform_annotation_expression (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_nested_key_transform_expression (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_nested_key_transform_on_subquery (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_nested_key_transform_raw_expression (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_none_key (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_none_key_and_exact_lookup (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_none_key_exclude (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_obj_subquery_lookup (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_order_grouping_custom_decoder (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_ordering_by_transform (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_ordering_grouping_by_count (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_ordering_grouping_by_key_transform (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_shallow_list_lookup (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_shallow_lookup_obj_target (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_shallow_obj_lookup (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_usage_in_subquery (model_fields.test_jsonfield.TestQuerying) ... ok\n\n----------------------------------------------------------------------\nRan 88 tests in 0.212s\n\nOK (skipped=8)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/model_fields/test_jsonfield.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-15525",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 18.114511728286743,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 57,
          "failed": 0,
          "errors": 1,
          "duration": 7.77,
          "log_tail": "    raise DatabaseOperationForbidden(self.message)\ndjango.test.testcases.DatabaseOperationForbidden: Database queries to 'default' are not allowed in this test. Add 'default' to fixtures_regress.tests.NaturalKeyFixtureOnOtherDatabaseTests.databases to ensure proper test isolation and silence this failure.\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/tests/fixtures_regress/tests.py\", line 803, in test_natural_key_dependencies\n    management.call_command(\n  File \"/testbed/django/core/management/__init__.py\", line 198, in call_command\n    return command.execute(*args, **defaults)\n  File \"/testbed/django/core/management/base.py\", line 448, in execute\n    output = self.handle(*args, **options)\n  File \"/testbed/django/core/management/commands/loaddata.py\", line 102, in handle\n    self.loaddata(fixture_labels)\n  File \"/testbed/django/core/management/commands/loaddata.py\", line 163, in loaddata\n    self.load_label(fixture_label)\n  File \"/testbed/django/core/management/commands/loaddata.py\", line 251, in load_label\n    for obj in objects:\n  File \"/testbed/django/core/serializers/json.py\", line 74, in Deserializer\n    raise DeserializationError() from exc\ndjango.core.serializers.base.DeserializationError: Problem installing fixture '/testbed/tests/fixtures_regress/fixtures/nk_with_foreign_key.json': \n\n----------------------------------------------------------------------\nRan 58 tests in 0.286s\n\nFAILED (errors=1, skipped=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 backends.sqlite.test_features fixtures_regress.models fixtures_regress.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/backends/sqlite/test_features.py",
            "tests/fixtures_regress/models.py",
            "tests/fixtures_regress/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 58,
          "failed": 0,
          "errors": 0,
          "duration": 8.97,
          "log_tail": "test_loaddata_not_found_fields_not_ignore (fixtures_regress.tests.TestFixtures)\nTest for ticket #9279 -- Error is raised for entries in ... ok\ntest_loaddata_raises_error_when_fixture_has_invalid_foreign_key (fixtures_regress.tests.TestFixtures)\nData with nonexistent child key references raises error. ... ok\ntest_loaddata_with_m2m_to_self (fixtures_regress.tests.TestFixtures)\nRegression test for ticket #17946. ... ok\ntest_loaddata_with_valid_fixture_dirs (fixtures_regress.tests.TestFixtures) ... ok\ntest_loaddata_works_when_fixture_has_forward_refs (fixtures_regress.tests.TestFixtures)\nForward references cause fixtures not to load in MySQL (InnoDB). ... ok\ntest_path_containing_dots (fixtures_regress.tests.TestFixtures) ... ok\ntest_pg_sequence_resetting_checks (fixtures_regress.tests.TestFixtures)\nTest for ticket #7565 -- PostgreSQL sequence resetting checks shouldn't ... ok\ntest_pretty_print_xml (fixtures_regress.tests.TestFixtures)\nRegression test for ticket #4558 -- pretty printing of XML fixtures ... ok\ntest_pretty_print_xml_empty_strings (fixtures_regress.tests.TestFixtures)\nRegression test for ticket #4558 -- pretty printing of XML fixtures ... skipped \"Database doesn't support feature(s): interprets_empty_strings_as_nulls\"\ntest_proxy_model_included (fixtures_regress.tests.TestFixtures)\nRegression for #11428 - Proxy models aren't included when you dumpdata ... ok\ntest_relative_path (fixtures_regress.tests.TestFixtures) ... ok\ntest_relative_path_in_fixture_dirs (fixtures_regress.tests.TestFixtures) ... ok\ntest_ticket_20820 (fixtures_regress.tests.TestFixtures)\nRegression for ticket #20820 -- loaddata on a model that inherits ... ok\ntest_ticket_22421 (fixtures_regress.tests.TestFixtures)\nRegression for ticket #22421 -- loaddata on a model that inherits from ... ok\ntest_unimportable_serializer (fixtures_regress.tests.TestFixtures)\nFailing serializer import raises the proper error ... ok\ntest_unknown_format (fixtures_regress.tests.TestFixtures)\nTest for ticket #4371 -- Loading data of an unknown format should fail ... ok\n\n----------------------------------------------------------------------\nRan 58 tests in 0.296s\n\nOK (skipped=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/backends/sqlite/test_features.py",
            "tests/fixtures_regress/models.py",
            "tests/fixtures_regress/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-15554",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 16.277667760849,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 42,
          "failed": 1,
          "errors": 0,
          "duration": 7.12,
          "log_tail": "test_select_related_foreign_key_for_update_of (filtered_relation.tests.FilteredRelationTests) ... skipped \"Database doesn't support feature(s): has_select_for_update, has_select_for_update_of\"\ntest_select_related_multiple (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_select_related_with_empty_relation (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_union (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_values (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_values_list (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_with_condition_as_expression_error (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_with_empty_relation_name_error (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_with_exclude (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_with_generic_foreign_key (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_with_join (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_with_join_and_complex_condition (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_with_m2m (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_with_m2m_deep (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_with_m2m_multijoin (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_with_multiple_filter (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_with_prefetch_related (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_without_join (filtered_relation.tests.FilteredRelationTests) ... ok\n\n======================================================================\nFAIL: test_multiple (filtered_relation.tests.FilteredRelationTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/tests/filtered_relation/tests.py\", line 228, in test_multiple\n    self.assertCountEqual(\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 1197, in assertCountEqual\n    self.fail(msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 676, in fail\n    raise self.failureException(msg)\nAssertionError: Element counts were not equal:\nFirst has 1, Second has 0:  {'book_title_alice__title': None, 'book_title_jane__title': None}\nFirst has 0, Second has 1:  {'book_title_alice__title': None, 'book_title_jane__title': 'The book by Jane A'}\nFirst has 0, Second has 1:  {'book_title_alice__title': None, 'book_title_jane__title': 'The book by Jane B'}\n\n----------------------------------------------------------------------\nRan 43 tests in 0.128s\n\nFAILED (failures=1, skipped=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 filtered_relation.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/filtered_relation/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 43,
          "failed": 0,
          "errors": 0,
          "duration": 7.83,
          "log_tail": "test_condition_deeper_relation_name (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_condition_outside_relation_name (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_deep_nested_foreign_key (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_defer (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_difference (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_eq (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_exclude_relation_with_join (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_extra (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_internal_queryset_alias_mapping (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_intersection (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_multiple (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_multiple_times (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_nested_chained_relations (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_nested_foreign_key (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_nested_foreign_key_filtered_base_object (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_nested_foreign_key_nested_field (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_nested_m2m_filtered (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_only_not_supported (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_relation_name_lookup (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_select_for_update (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_select_related (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_select_related_foreign_key (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_select_related_foreign_key_for_update_of (filtered_relation.tests.FilteredRelationTests) ... skipped \"Database doesn't support feature(s): has_select_for_update, has_select_for_update_of\"\ntest_select_related_multiple (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_select_related_with_empty_relation (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_union (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_values (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_values_list (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_with_condition_as_expression_error (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_with_empty_relation_name_error (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_with_exclude (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_with_generic_foreign_key (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_with_join (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_with_join_and_complex_condition (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_with_m2m (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_with_m2m_deep (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_with_m2m_multijoin (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_with_multiple_filter (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_with_prefetch_related (filtered_relation.tests.FilteredRelationTests) ... ok\ntest_without_join (filtered_relation.tests.FilteredRelationTests) ... ok\n\n----------------------------------------------------------------------\nRan 43 tests in 0.145s\n\nOK (skipped=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/filtered_relation/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-15561",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 21.141003131866455,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 175,
          "failed": 1,
          "errors": 0,
          "duration": 9.23,
          "log_tail": "test_remove_index_together_does_not_remove_meta_indexes (schema.tests.SchemaTests) ... ok\ntest_remove_unique_together_does_not_remove_meta_constraints (schema.tests.SchemaTests) ... ok\ntest_rename (schema.tests.SchemaTests)\nTests simple altering of fields ... ok\ntest_rename_column_renames_deferred_sql_references (schema.tests.SchemaTests) ... skipped 'SQLite naively remakes the table on field alteration.'\ntest_rename_keep_null_status (schema.tests.SchemaTests)\nRenaming a field shouldn't affect the not null status. ... ok\ntest_rename_referenced_field (schema.tests.SchemaTests) ... ok\ntest_rename_table_renames_deferred_sql_references (schema.tests.SchemaTests) ... ok\ntest_text_field_with_db_index (schema.tests.SchemaTests) ... ok\ntest_text_field_with_db_index_to_fk (schema.tests.SchemaTests) ... ok\ntest_unique (schema.tests.SchemaTests)\nTests removing and adding unique constraints to a single column. ... ok\ntest_unique_and_reverse_m2m (schema.tests.SchemaTests)\nAlterField can modify a unique field when there's a reverse M2M ... skipped 'SQLite naively remakes the table on field alteration.'\ntest_unique_constraint (schema.tests.SchemaTests) ... ok\ntest_unique_constraint_field_and_expression (schema.tests.SchemaTests) ... ok\ntest_unique_name_quoting (schema.tests.SchemaTests) ... ok\ntest_unique_no_unnecessary_fk_drops (schema.tests.SchemaTests)\nIf AlterField isn't selective about dropping foreign key constraints ... skipped 'SQLite naively remakes the table on field alteration.'\ntest_unique_together (schema.tests.SchemaTests)\nTests removing and adding unique_together constraints on a model. ... ok\ntest_unique_together_with_fk (schema.tests.SchemaTests)\nTests removing and adding unique_together constraints that include ... ok\ntest_unique_together_with_fk_with_existing_index (schema.tests.SchemaTests)\nTests removing and adding unique_together constraints that include ... ok\ntest_unsupported_transactional_ddl_disallowed (schema.tests.SchemaTests) ... skipped 'Database has feature(s) can_rollback_ddl'\n\n======================================================================\nFAIL: test_alter_field_choices_noop (schema.tests.SchemaTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/schema/tests.py\", line 3974, in test_alter_field_choices_noop\n    editor.alter_field(Author, old_field, new_field, strict=True)\n  File \"/testbed/django/test/testcases.py\", line 98, in __exit__\n    self.test_case.assertEqual(\nAssertionError: 4 != 0 : 4 queries executed, 0 expected\nCaptured queries were:\n1. CREATE TABLE \"new__schema_author\" (\"id\" integer NOT NULL PRIMARY KEY AUTOINCREMENT, \"height\" integer unsigned NULL CHECK (\"height\" >= 0), \"weight\" integer NULL, \"uuid\" char(32) NULL, \"name\" varchar(255) NOT NULL)\n2. INSERT INTO \"new__schema_author\" (\"id\", \"height\", \"weight\", \"uuid\", \"name\") SELECT \"id\", \"height\", \"weight\", \"uuid\", \"name\" FROM \"schema_author\"\n3. DROP TABLE \"schema_author\"\n4. ALTER TABLE \"new__schema_author\" RENAME TO \"schema_author\"\n\n----------------------------------------------------------------------\nRan 176 tests in 2.448s\n\nFAILED (failures=1, skipped=28)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 schema.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/schema/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 176,
          "failed": 0,
          "errors": 0,
          "duration": 10.69,
          "log_tail": "When a primary key that's pointed to by a ForeignKey with ... ok\ntest_order_index (schema.tests.SchemaTests)\nIndexes defined with ordering (ASC/DESC) defined on column ... ok\ntest_primary_key (schema.tests.SchemaTests)\nTests altering of the primary key ... ok\ntest_referenced_field_without_constraint_rename_inside_atomic_block (schema.tests.SchemaTests)\nForeign keys without database level constraint don't prevent the field ... ok\ntest_referenced_table_without_constraint_rename_inside_atomic_block (schema.tests.SchemaTests)\nForeign keys without database level constraint don't prevent the table ... ok\ntest_remove_constraints_capital_letters (schema.tests.SchemaTests)\n#23065 - Constraint names must be quoted if they contain capital letters. ... ok\ntest_remove_db_index_doesnt_remove_custom_indexes (schema.tests.SchemaTests)\nChanging db_index to False doesn't remove indexes from Meta.indexes. ... ok\ntest_remove_field (schema.tests.SchemaTests) ... ok\ntest_remove_field_check_does_not_remove_meta_constraints (schema.tests.SchemaTests) ... ok\ntest_remove_field_unique_does_not_remove_meta_constraints (schema.tests.SchemaTests) ... ok\ntest_remove_index_together_does_not_remove_meta_indexes (schema.tests.SchemaTests) ... ok\ntest_remove_unique_together_does_not_remove_meta_constraints (schema.tests.SchemaTests) ... ok\ntest_rename (schema.tests.SchemaTests)\nTests simple altering of fields ... ok\ntest_rename_column_renames_deferred_sql_references (schema.tests.SchemaTests) ... skipped 'SQLite naively remakes the table on field alteration.'\ntest_rename_keep_null_status (schema.tests.SchemaTests)\nRenaming a field shouldn't affect the not null status. ... ok\ntest_rename_referenced_field (schema.tests.SchemaTests) ... ok\ntest_rename_table_renames_deferred_sql_references (schema.tests.SchemaTests) ... ok\ntest_text_field_with_db_index (schema.tests.SchemaTests) ... ok\ntest_text_field_with_db_index_to_fk (schema.tests.SchemaTests) ... ok\ntest_unique (schema.tests.SchemaTests)\nTests removing and adding unique constraints to a single column. ... ok\ntest_unique_and_reverse_m2m (schema.tests.SchemaTests)\nAlterField can modify a unique field when there's a reverse M2M ... skipped 'SQLite naively remakes the table on field alteration.'\ntest_unique_constraint (schema.tests.SchemaTests) ... ok\ntest_unique_constraint_field_and_expression (schema.tests.SchemaTests) ... ok\ntest_unique_name_quoting (schema.tests.SchemaTests) ... ok\ntest_unique_no_unnecessary_fk_drops (schema.tests.SchemaTests)\nIf AlterField isn't selective about dropping foreign key constraints ... skipped 'SQLite naively remakes the table on field alteration.'\ntest_unique_together (schema.tests.SchemaTests)\nTests removing and adding unique_together constraints on a model. ... ok\ntest_unique_together_with_fk (schema.tests.SchemaTests)\nTests removing and adding unique_together constraints that include ... ok\ntest_unique_together_with_fk_with_existing_index (schema.tests.SchemaTests)\nTests removing and adding unique_together constraints that include ... ok\ntest_unsupported_transactional_ddl_disallowed (schema.tests.SchemaTests) ... skipped 'Database has feature(s) can_rollback_ddl'\n\n----------------------------------------------------------------------\nRan 176 tests in 2.438s\n\nOK (skipped=28)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/schema/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-15563",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 16.418572187423706,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 31,
          "failed": 1,
          "errors": 0,
          "duration": 6.84,
          "log_tail": "Regression test for #8825 and #9390 ... ok\ntest_inherited_nullable_exclude (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_inherited_unique_field_with_form (model_inheritance_regress.tests.ModelInheritanceTest)\nA model which has different primary key for the parent model passes ... ok\ntest_issue_11764 (model_inheritance_regress.tests.ModelInheritanceTest)\nRegression test for #11764 ... ok\ntest_issue_21554 (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_issue_6755 (model_inheritance_regress.tests.ModelInheritanceTest)\nRegression test for #6755 ... ok\ntest_issue_7105 (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_issue_7276 (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_issue_7853 (model_inheritance_regress.tests.ModelInheritanceTest)\nRegression test for #7853 ... ok\ntest_model_inheritance (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_mti_update_grand_parent_through_child (model_inheritance_regress.tests.ModelInheritanceTest) ... FAIL\ntest_mti_update_parent_through_child (model_inheritance_regress.tests.ModelInheritanceTest) ... FAIL\ntest_ptr_accessor_assigns_state (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_queries_on_parent_access (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_queryset_update_on_parent_model (model_inheritance_regress.tests.ModelInheritanceTest)\nRegression test for #10362 ... ok\ntest_related_filtering_query_efficiency_ticket_15844 (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_use_explicit_o2o_to_parent_as_pk (model_inheritance_regress.tests.ModelInheritanceTest)\nThe connector from child to parent need not be the pk on the child. ... ok\ntest_use_explicit_o2o_to_parent_from_abstract_model (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\n\n======================================================================\nFAIL: test_mti_update_grand_parent_through_child (model_inheritance_regress.tests.ModelInheritanceTest)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/model_inheritance_regress/tests.py\", line 681, in test_mti_update_grand_parent_through_child\n    self.assertEqual(Senator.objects.get().title, \"senator 1\")\nAssertionError: '' != 'senator 1'\n+ senator 1\n\n======================================================================\nFAIL: test_mti_update_parent_through_child (model_inheritance_regress.tests.ModelInheritanceTest)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/model_inheritance_regress/tests.py\", line 675, in test_mti_update_parent_through_child\n    self.assertEqual(Congressman.objects.get().title, \"senator 1\")\nAssertionError: '' != 'senator 1'\n+ senator 1\n\n----------------------------------------------------------------------\nRan 32 tests in 0.085s\n\nFAILED (failures=2, expected failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 model_inheritance_regress.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/model_inheritance_regress/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 32,
          "failed": 0,
          "errors": 0,
          "duration": 8.38,
          "log_tail": "test_abstract_base_class_m2m_relation_inheritance (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_abstract_base_class_m2m_relation_inheritance_manager_reused (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_abstract_verbose_name_plural_inheritance (model_inheritance_regress.tests.ModelInheritanceTest)\nverbose_name_plural correctly inherited from ABC if inheritance chain ... ok\ntest_all_fields_from_abstract_base_class (model_inheritance_regress.tests.ModelInheritanceTest)\nRegression tests for #7588 ... ok\ntest_concrete_abstract_concrete_pk (model_inheritance_regress.tests.ModelInheritanceTest)\nPrimary key set correctly with concrete->abstract->concrete inheritance. ... ok\ntest_create_new_instance_with_pk_equals_none (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_create_new_instance_with_pk_equals_none_multi_inheritance (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_filter_with_parent_fk (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_get_next_previous_by_date (model_inheritance_regress.tests.ModelInheritanceTest)\nRegression tests for #8076 ... ok\ntest_id_field_update_on_ancestor_change (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_inheritance_joins (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_inheritance_resolve_columns (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_inheritance_select_related (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_inheritance_values_joins (model_inheritance_regress.tests.ModelInheritanceTest) ... expected failure\ntest_inherited_fields (model_inheritance_regress.tests.ModelInheritanceTest)\nRegression test for #8825 and #9390 ... ok\ntest_inherited_nullable_exclude (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_inherited_unique_field_with_form (model_inheritance_regress.tests.ModelInheritanceTest)\nA model which has different primary key for the parent model passes ... ok\ntest_issue_11764 (model_inheritance_regress.tests.ModelInheritanceTest)\nRegression test for #11764 ... ok\ntest_issue_21554 (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_issue_6755 (model_inheritance_regress.tests.ModelInheritanceTest)\nRegression test for #6755 ... ok\ntest_issue_7105 (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_issue_7276 (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_issue_7853 (model_inheritance_regress.tests.ModelInheritanceTest)\nRegression test for #7853 ... ok\ntest_model_inheritance (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_mti_update_grand_parent_through_child (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_mti_update_parent_through_child (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_ptr_accessor_assigns_state (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_queries_on_parent_access (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_queryset_update_on_parent_model (model_inheritance_regress.tests.ModelInheritanceTest)\nRegression test for #10362 ... ok\ntest_related_filtering_query_efficiency_ticket_15844 (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\ntest_use_explicit_o2o_to_parent_as_pk (model_inheritance_regress.tests.ModelInheritanceTest)\nThe connector from child to parent need not be the pk on the child. ... ok\ntest_use_explicit_o2o_to_parent_from_abstract_model (model_inheritance_regress.tests.ModelInheritanceTest) ... ok\n\n----------------------------------------------------------------------\nRan 32 tests in 0.089s\n\nOK (expected failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/model_inheritance_regress/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-15569",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 22.222231149673462,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 288,
          "failed": 2,
          "errors": 0,
          "duration": 9.98,
          "log_tail": "  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/tests/custom_lookups/tests.py\", line 327, in test_lookups_caching\n    self.assertNotIn(\"exactly\", field.get_lookups())\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 1111, in assertNotIn\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 676, in fail\n    raise self.failureException(msg)\nAssertionError: 'exactly' unexpectedly found in {'in': <class 'django.db.models.fields.related_lookups.RelatedIn'>, 'exact': <class 'django.db.models.fields.related_lookups.RelatedExact'>, 'lt': <class 'django.db.models.fields.related_lookups.RelatedLessThan'>, 'gt': <class 'django.db.models.fields.related_lookups.RelatedGreaterThan'>, 'gte': <class 'django.db.models.fields.related_lookups.RelatedGreaterThanOrEqual'>, 'lte': <class 'django.db.models.fields.related_lookups.RelatedLessThanOrEqual'>, 'isnull': <class 'django.db.models.fields.related_lookups.RelatedIsNull'>, 'exactly': <class 'custom_lookups.tests.Exactly'>}\n\n======================================================================\nFAIL: test_get_transforms (model_fields.test_jsonfield.TestMethods)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/tests/model_fields/test_jsonfield.py\", line 92, in test_get_transforms\n    self.assertIsInstance(transform, KeyTransformFactory)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 1260, in assertIsInstance\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 676, in fail\n    raise self.failureException(msg)\nAssertionError: <class 'model_fields.test_jsonfield.TestMethods.test_get_transforms.<locals>.MyTransform'> is not an instance of <class 'django.db.models.fields.json.KeyTransformFactory'>\n\n----------------------------------------------------------------------\nRan 290 tests in 2.815s\n\nFAILED (failures=2, skipped=40)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 custom_lookups.tests model_fields.test_jsonfield schema.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/custom_lookups/tests.py",
            "tests/model_fields/test_jsonfield.py",
            "tests/schema/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 290,
          "failed": 0,
          "errors": 0,
          "duration": 11.13,
          "log_tail": "test_remove_field_unique_does_not_remove_meta_constraints (schema.tests.SchemaTests) ... ok\ntest_remove_index_together_does_not_remove_meta_indexes (schema.tests.SchemaTests) ... ok\ntest_remove_unique_together_does_not_remove_meta_constraints (schema.tests.SchemaTests) ... ok\ntest_rename (schema.tests.SchemaTests)\nTests simple altering of fields ... ok\ntest_rename_column_renames_deferred_sql_references (schema.tests.SchemaTests) ... skipped 'SQLite naively remakes the table on field alteration.'\ntest_rename_keep_null_status (schema.tests.SchemaTests)\nRenaming a field shouldn't affect the not null status. ... ok\ntest_rename_referenced_field (schema.tests.SchemaTests) ... ok\ntest_rename_table_renames_deferred_sql_references (schema.tests.SchemaTests) ... ok\ntest_text_field_with_db_index (schema.tests.SchemaTests) ... ok\ntest_text_field_with_db_index_to_fk (schema.tests.SchemaTests) ... ok\ntest_unique (schema.tests.SchemaTests)\nTests removing and adding unique constraints to a single column. ... ok\ntest_unique_and_reverse_m2m (schema.tests.SchemaTests)\nAlterField can modify a unique field when there's a reverse M2M ... skipped 'SQLite naively remakes the table on field alteration.'\ntest_unique_constraint (schema.tests.SchemaTests) ... ok\ntest_unique_constraint_field_and_expression (schema.tests.SchemaTests) ... ok\ntest_unique_name_quoting (schema.tests.SchemaTests) ... ok\ntest_unique_no_unnecessary_fk_drops (schema.tests.SchemaTests)\nIf AlterField isn't selective about dropping foreign key constraints ... skipped 'SQLite naively remakes the table on field alteration.'\ntest_unique_together (schema.tests.SchemaTests)\nTests removing and adding unique_together constraints on a model. ... ok\ntest_unique_together_with_fk (schema.tests.SchemaTests)\nTests removing and adding unique_together constraints that include ... ok\ntest_unique_together_with_fk_with_existing_index (schema.tests.SchemaTests)\nTests removing and adding unique_together constraints that include ... ok\ntest_unsupported_transactional_ddl_disallowed (schema.tests.SchemaTests) ... skipped 'Database has feature(s) can_rollback_ddl'\n\n----------------------------------------------------------------------\nRan 290 tests in 2.835s\n\nOK (skipped=40)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/custom_lookups/tests.py",
            "tests/model_fields/test_jsonfield.py",
            "tests/schema/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-15572",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 15.756643056869507,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 10,
          "failed": 1,
          "errors": 0,
          "duration": 6.68,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application template_tests\nFound 11 test(s).\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_get_template_directories (template_tests.test_autoreloader.Jinja2TemplateReloadTests) ... ok\ntest_reset_all_loaders (template_tests.test_autoreloader.Jinja2TemplateReloadTests) ... ok\ntest_watch_for_template_changes (template_tests.test_autoreloader.Jinja2TemplateReloadTests) ... ok\ntest_get_template_directories (template_tests.test_autoreloader.TemplateReloadTests) ... ok\ntest_non_template_changed (template_tests.test_autoreloader.TemplateReloadTests) ... ok\ntest_non_template_changed_in_template_directory (template_tests.test_autoreloader.TemplateReloadTests) ... ok\ntest_reset_all_loaders (template_tests.test_autoreloader.TemplateReloadTests) ... ok\ntest_template_changed (template_tests.test_autoreloader.TemplateReloadTests) ... ok\ntest_template_dirs_ignore_empty_path (template_tests.test_autoreloader.TemplateReloadTests) ... FAIL\ntest_template_dirs_normalized_to_paths (template_tests.test_autoreloader.TemplateReloadTests) ... ok\ntest_watch_for_template_changes (template_tests.test_autoreloader.TemplateReloadTests) ... ok\n\n======================================================================\nFAIL: test_template_dirs_ignore_empty_path (template_tests.test_autoreloader.TemplateReloadTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/django/test/utils.py\", line 460, in inner\n    return func(*args, **kwargs)\n  File \"/testbed/tests/template_tests/test_autoreloader.py\", line 93, in test_template_dirs_ignore_empty_path\n    self.assertEqual(autoreload.get_template_directories(), set())\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 837, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 1097, in assertSetEqual\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 676, in fail\n    raise self.failureException(msg)\nAssertionError: Items in the first set but not the second:\nPosixPath('/testbed/tests')\n\n----------------------------------------------------------------------\nRan 11 tests in 0.062s\n\nFAILED (failures=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 template_tests.test_autoreloader` failed. (See above for error)",
          "test_files_run": [
            "tests/template_tests/test_autoreloader.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 11,
          "failed": 0,
          "errors": 0,
          "duration": 7.96,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application template_tests\nFound 11 test(s).\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_get_template_directories (template_tests.test_autoreloader.Jinja2TemplateReloadTests) ... ok\ntest_reset_all_loaders (template_tests.test_autoreloader.Jinja2TemplateReloadTests) ... ok\ntest_watch_for_template_changes (template_tests.test_autoreloader.Jinja2TemplateReloadTests) ... ok\ntest_get_template_directories (template_tests.test_autoreloader.TemplateReloadTests) ... ok\ntest_non_template_changed (template_tests.test_autoreloader.TemplateReloadTests) ... ok\ntest_non_template_changed_in_template_directory (template_tests.test_autoreloader.TemplateReloadTests) ... ok\ntest_reset_all_loaders (template_tests.test_autoreloader.TemplateReloadTests) ... ok\ntest_template_changed (template_tests.test_autoreloader.TemplateReloadTests) ... ok\ntest_template_dirs_ignore_empty_path (template_tests.test_autoreloader.TemplateReloadTests) ... ok\ntest_template_dirs_normalized_to_paths (template_tests.test_autoreloader.TemplateReloadTests) ... ok\ntest_watch_for_template_changes (template_tests.test_autoreloader.TemplateReloadTests) ... ok\n\n----------------------------------------------------------------------\nRan 11 tests in 0.063s\n\nOK\n",
          "test_files_run": [
            "tests/template_tests/test_autoreloader.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-15629",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 20.84317684173584,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 121,
          "failed": 2,
          "errors": 0,
          "duration": 8.99,
          "log_tail": "    return test_func(*args, **kwargs)\n  File \"/testbed/tests/migrations/test_operations.py\", line 2037, in test_alter_field_pk_fk_db_collation\n    self.assertColumnCollation(f\"{app_label}_rider\", \"pony_id\", collation)\n  File \"/testbed/tests/migrations/test_base.py\", line 76, in assertColumnCollation\n    self.assertEqual(self._get_column_collation(table, column, using), collation)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 837, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 830, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: None != 'nocase'\n\n======================================================================\nFAIL: test_create_fk_models_to_pk_field_db_collation (migrations.test_operations.OperationTests)\nCreation of models with a FK to a PK with db_collation.\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/django/test/testcases.py\", line 1571, in skip_wrapper\n    return test_func(*args, **kwargs)\n  File \"/testbed/tests/migrations/test_operations.py\", line 299, in test_create_fk_models_to_pk_field_db_collation\n    self.assertColumnCollation(f\"{app_label}_rider\", \"pony_id\", collation)\n  File \"/testbed/tests/migrations/test_base.py\", line 76, in assertColumnCollation\n    self.assertEqual(self._get_column_collation(table, column, using), collation)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 837, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 830, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: None != 'nocase'\n\n----------------------------------------------------------------------\nRan 123 tests in 2.289s\n\nFAILED (failures=2, skipped=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 migrations.test_base migrations.test_operations` failed. (See above for error)",
          "test_files_run": [
            "tests/migrations/test_base.py",
            "tests/migrations/test_operations.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 123,
          "failed": 0,
          "errors": 0,
          "duration": 10.73,
          "log_tail": "test_rename_model_with_db_table_noop (migrations.test_operations.OperationTests) ... ok\ntest_rename_model_with_m2m (migrations.test_operations.OperationTests) ... ok\ntest_rename_model_with_self_referential_fk (migrations.test_operations.OperationTests)\nTests the RenameModel operation on model with self referential FK. ... ok\ntest_rename_model_with_self_referential_m2m (migrations.test_operations.OperationTests) ... ok\ntest_rename_model_with_superclass_fk (migrations.test_operations.OperationTests)\nTests the RenameModel operation on a model which has a superclass that ... ok\ntest_rename_referenced_field_state_forward (migrations.test_operations.OperationTests) ... ok\ntest_repoint_field_m2m (migrations.test_operations.OperationTests) ... ok\ntest_run_python (migrations.test_operations.OperationTests)\nTests the RunPython operation ... ok\ntest_run_python_atomic (migrations.test_operations.OperationTests)\nTests the RunPython operation correctly handles the \"atomic\" keyword ... ok\ntest_run_python_noop (migrations.test_operations.OperationTests)\n#24098 - Tests no-op RunPython operations. ... ok\ntest_run_python_related_assignment (migrations.test_operations.OperationTests)\n#24282 - Model changes to a FK reverse side update the model ... ok\ntest_run_sql (migrations.test_operations.OperationTests)\nTests the RunSQL operation. ... ok\ntest_run_sql_add_missing_semicolon_on_collect_sql (migrations.test_operations.OperationTests) ... ok\ntest_run_sql_noop (migrations.test_operations.OperationTests)\n#24098 - Tests no-op RunSQL operations. ... ok\ntest_run_sql_params (migrations.test_operations.OperationTests)\n#23426 - RunSQL should accept parameters. ... ok\ntest_run_sql_params_invalid (migrations.test_operations.OperationTests)\n#23426 - RunSQL should fail when a list of statements with an incorrect ... ok\ntest_separate_database_and_state (migrations.test_operations.OperationTests)\nTests the SeparateDatabaseAndState operation. ... ok\ntest_separate_database_and_state2 (migrations.test_operations.OperationTests)\nA complex SeparateDatabaseAndState operation: Multiple operations both ... ok\ntest_smallfield_autofield_foreignfield_growth (migrations.test_operations.OperationTests)\nA field may be migrated from SmallAutoField to AutoField. ... ok\ntest_smallfield_bigautofield_foreignfield_growth (migrations.test_operations.OperationTests)\nA field may be migrated from SmallAutoField to BigAutoField. ... ok\n\n----------------------------------------------------------------------\nRan 123 tests in 2.685s\n\nOK (skipped=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/migrations/test_base.py",
            "tests/migrations/test_operations.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-15695",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 20.850618839263916,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 129,
          "failed": 0,
          "errors": 1,
          "duration": 9.49,
          "log_tail": "test_run_sql_add_missing_semicolon_on_collect_sql (migrations.test_operations.OperationTests) ... ok\ntest_run_sql_noop (migrations.test_operations.OperationTests)\n#24098 - Tests no-op RunSQL operations. ... ok\ntest_run_sql_params (migrations.test_operations.OperationTests)\n#23426 - RunSQL should accept parameters. ... ok\ntest_run_sql_params_invalid (migrations.test_operations.OperationTests)\n#23426 - RunSQL should fail when a list of statements with an incorrect ... ok\ntest_separate_database_and_state (migrations.test_operations.OperationTests)\nTests the SeparateDatabaseAndState operation. ... ok\ntest_separate_database_and_state2 (migrations.test_operations.OperationTests)\nA complex SeparateDatabaseAndState operation: Multiple operations both ... ok\ntest_smallfield_autofield_foreignfield_growth (migrations.test_operations.OperationTests)\nA field may be migrated from SmallAutoField to AutoField. ... ok\ntest_smallfield_bigautofield_foreignfield_growth (migrations.test_operations.OperationTests)\nA field may be migrated from SmallAutoField to BigAutoField. ... ok\n\n======================================================================\nERROR: test_rename_index_unnamed_index (migrations.test_operations.OperationTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/tests/migrations/test_operations.py\", line 2994, in test_rename_index_unnamed_index\n    operation.database_forwards(app_label, editor, new_state, project_state)\n  File \"/testbed/django/db/migrations/operations/models.py\", line 965, in database_forwards\n    new_index = to_model_state.get_index_by_name(self.new_name)\n  File \"/testbed/django/db/migrations/state.py\", line 959, in get_index_by_name\n    raise ValueError(\"No index named %s on model %s\" % (name, self.name))\nValueError: No index named new_pony_test_idx on model Pony\n\n----------------------------------------------------------------------\nRan 130 tests in 2.721s\n\nFAILED (errors=1, skipped=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 migrations.test_operations` failed. (See above for error)",
          "test_files_run": [
            "tests/migrations/test_operations.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 130,
          "failed": 0,
          "errors": 0,
          "duration": 10.07,
          "log_tail": "test_rename_model_with_db_table_noop (migrations.test_operations.OperationTests) ... ok\ntest_rename_model_with_m2m (migrations.test_operations.OperationTests) ... ok\ntest_rename_model_with_self_referential_fk (migrations.test_operations.OperationTests)\nTests the RenameModel operation on model with self referential FK. ... ok\ntest_rename_model_with_self_referential_m2m (migrations.test_operations.OperationTests) ... ok\ntest_rename_model_with_superclass_fk (migrations.test_operations.OperationTests)\nTests the RenameModel operation on a model which has a superclass that ... ok\ntest_rename_referenced_field_state_forward (migrations.test_operations.OperationTests) ... ok\ntest_repoint_field_m2m (migrations.test_operations.OperationTests) ... ok\ntest_run_python (migrations.test_operations.OperationTests)\nTests the RunPython operation ... ok\ntest_run_python_atomic (migrations.test_operations.OperationTests)\nTests the RunPython operation correctly handles the \"atomic\" keyword ... ok\ntest_run_python_noop (migrations.test_operations.OperationTests)\n#24098 - Tests no-op RunPython operations. ... ok\ntest_run_python_related_assignment (migrations.test_operations.OperationTests)\n#24282 - Model changes to a FK reverse side update the model ... ok\ntest_run_sql (migrations.test_operations.OperationTests)\nTests the RunSQL operation. ... ok\ntest_run_sql_add_missing_semicolon_on_collect_sql (migrations.test_operations.OperationTests) ... ok\ntest_run_sql_noop (migrations.test_operations.OperationTests)\n#24098 - Tests no-op RunSQL operations. ... ok\ntest_run_sql_params (migrations.test_operations.OperationTests)\n#23426 - RunSQL should accept parameters. ... ok\ntest_run_sql_params_invalid (migrations.test_operations.OperationTests)\n#23426 - RunSQL should fail when a list of statements with an incorrect ... ok\ntest_separate_database_and_state (migrations.test_operations.OperationTests)\nTests the SeparateDatabaseAndState operation. ... ok\ntest_separate_database_and_state2 (migrations.test_operations.OperationTests)\nA complex SeparateDatabaseAndState operation: Multiple operations both ... ok\ntest_smallfield_autofield_foreignfield_growth (migrations.test_operations.OperationTests)\nA field may be migrated from SmallAutoField to AutoField. ... ok\ntest_smallfield_bigautofield_foreignfield_growth (migrations.test_operations.OperationTests)\nA field may be migrated from SmallAutoField to BigAutoField. ... ok\n\n----------------------------------------------------------------------\nRan 130 tests in 2.436s\n\nOK (skipped=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/migrations/test_operations.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-15731",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 23.91716194152832,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 60,
          "failed": 1,
          "errors": 0,
          "duration": 11.79,
          "log_tail": "test_hash_function (basic.tests.ModelTest) ... ok\ntest_manually_specify_primary_key (basic.tests.ModelTest) ... ok\ntest_microsecond_precision (basic.tests.ModelTest) ... ok\ntest_missing_hash_not_inherited (basic.tests.ModelTest) ... ok\ntest_multiple_objects_max_num_fetched (basic.tests.ModelTest) ... ok\ntest_not_equal_and_equal_operators_behave_as_expected_on_instances (basic.tests.ModelTest) ... ok\ntest_objects_attribute_is_only_available_on_the_class_itself (basic.tests.ModelTest) ... ok\ntest_queryset_delete_removes_all_items_in_that_queryset (basic.tests.ModelTest) ... ok\ntest_specified_parent_hash_inherited (basic.tests.ModelTest) ... ok\ntest_ticket_20278 (basic.tests.ModelTest) ... ok\ntest_unicode_data (basic.tests.ModelTest) ... ok\ntest_year_lookup_edge_case (basic.tests.ModelTest) ... ok\n\n======================================================================\nFAIL: test_manager_method_signature (basic.tests.ManagerTest)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/tests/basic/tests.py\", line 745, in test_manager_method_signature\n    self.assertEqual(\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 837, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 1217, in assertMultiLineEqual\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 676, in fail\n    raise self.failureException(msg)\nAssertionError: '(*args, **kwargs)' != '(objs, batch_size=None, ignore_conflicts=F[65 chars]one)'\n- (*args, **kwargs)\n+ (objs, batch_size=None, ignore_conflicts=False, update_conflicts=False, update_fields=None, unique_fields=None)\n\n\n----------------------------------------------------------------------\nRan 61 tests in 0.098s\n\nFAILED (failures=1, skipped=2)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 basic.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/basic/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 61,
          "failed": 0,
          "errors": 0,
          "duration": 10.8,
          "log_tail": "test_prefetched_cache_cleared (basic.tests.ModelRefreshTests) ... ok\ntest_refresh (basic.tests.ModelRefreshTests) ... ok\ntest_refresh_clears_one_to_one_field (basic.tests.ModelRefreshTests) ... ok\ntest_refresh_clears_reverse_related (basic.tests.ModelRefreshTests)\nrefresh_from_db() clear cached reverse relations. ... ok\ntest_refresh_fk (basic.tests.ModelRefreshTests) ... ok\ntest_refresh_fk_on_delete_set_null (basic.tests.ModelRefreshTests) ... ok\ntest_refresh_no_fields (basic.tests.ModelRefreshTests) ... ok\ntest_refresh_null_fk (basic.tests.ModelRefreshTests) ... ok\ntest_refresh_unsaved (basic.tests.ModelRefreshTests) ... ok\ntest_unknown_kwarg (basic.tests.ModelRefreshTests) ... ok\ntest_create_method (basic.tests.ModelTest) ... ok\ntest_create_relation_with_gettext_lazy (basic.tests.ModelTest)\ngettext_lazy objects work when saving model instances ... ok\ntest_delete_and_access_field (basic.tests.ModelTest) ... ok\ntest_emptyqs (basic.tests.ModelTest) ... ok\ntest_emptyqs_customqs (basic.tests.ModelTest) ... ok\ntest_emptyqs_distinct (basic.tests.ModelTest) ... skipped \"Database doesn't support feature(s): can_distinct_on_fields\"\ntest_emptyqs_values (basic.tests.ModelTest) ... ok\ntest_emptyqs_values_order (basic.tests.ModelTest) ... ok\ntest_eq (basic.tests.ModelTest) ... ok\ntest_extra_method_select_argument_with_dashes (basic.tests.ModelTest) ... ok\ntest_extra_method_select_argument_with_dashes_and_values (basic.tests.ModelTest) ... ok\ntest_hash (basic.tests.ModelTest) ... ok\ntest_hash_function (basic.tests.ModelTest) ... ok\ntest_manually_specify_primary_key (basic.tests.ModelTest) ... ok\ntest_microsecond_precision (basic.tests.ModelTest) ... ok\ntest_missing_hash_not_inherited (basic.tests.ModelTest) ... ok\ntest_multiple_objects_max_num_fetched (basic.tests.ModelTest) ... ok\ntest_not_equal_and_equal_operators_behave_as_expected_on_instances (basic.tests.ModelTest) ... ok\ntest_objects_attribute_is_only_available_on_the_class_itself (basic.tests.ModelTest) ... ok\ntest_queryset_delete_removes_all_items_in_that_queryset (basic.tests.ModelTest) ... ok\ntest_specified_parent_hash_inherited (basic.tests.ModelTest) ... ok\ntest_ticket_20278 (basic.tests.ModelTest) ... ok\ntest_unicode_data (basic.tests.ModelTest) ... ok\ntest_year_lookup_edge_case (basic.tests.ModelTest) ... ok\n\n----------------------------------------------------------------------\nRan 61 tests in 0.099s\n\nOK (skipped=2)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/basic/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-15732",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 29.446810245513916,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 131,
          "failed": 0,
          "errors": 1,
          "duration": 13.57,
          "log_tail": "#23426 - RunSQL should accept parameters. ... ok\ntest_run_sql_params_invalid (migrations.test_operations.OperationTests)\n#23426 - RunSQL should fail when a list of statements with an incorrect ... ok\ntest_separate_database_and_state (migrations.test_operations.OperationTests)\nTests the SeparateDatabaseAndState operation. ... ok\ntest_separate_database_and_state2 (migrations.test_operations.OperationTests)\nA complex SeparateDatabaseAndState operation: Multiple operations both ... ok\ntest_smallfield_autofield_foreignfield_growth (migrations.test_operations.OperationTests)\nA field may be migrated from SmallAutoField to AutoField. ... ok\ntest_smallfield_bigautofield_foreignfield_growth (migrations.test_operations.OperationTests)\nA field may be migrated from SmallAutoField to BigAutoField. ... ok\n\n======================================================================\nERROR: test_remove_unique_together_on_unique_field (migrations.test_operations.OperationTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/django/test/testcases.py\", line 1571, in skip_wrapper\n    return test_func(*args, **kwargs)\n  File \"/testbed/tests/migrations/test_operations.py\", line 2871, in test_remove_unique_together_on_unique_field\n    operation.database_forwards(app_label, editor, project_state, new_state)\n  File \"/testbed/django/db/migrations/operations/models.py\", line 565, in database_forwards\n    alter_together(\n  File \"/testbed/django/db/backends/base/schema.py\", line 530, in alter_unique_together\n    self._delete_composed_index(\n  File \"/testbed/django/db/backends/base/schema.py\", line 572, in _delete_composed_index\n    raise ValueError(\nValueError: Found wrong number (2) of constraints for test_rutouf_pony(name)\n\n----------------------------------------------------------------------\nRan 132 tests in 1.961s\n\nFAILED (errors=1, skipped=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 migrations.test_operations` failed. (See above for error)",
          "test_files_run": [
            "tests/migrations/test_operations.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 132,
          "failed": 0,
          "errors": 0,
          "duration": 13.76,
          "log_tail": "test_rename_model_with_db_table_noop (migrations.test_operations.OperationTests) ... ok\ntest_rename_model_with_m2m (migrations.test_operations.OperationTests) ... ok\ntest_rename_model_with_self_referential_fk (migrations.test_operations.OperationTests)\nTests the RenameModel operation on model with self referential FK. ... ok\ntest_rename_model_with_self_referential_m2m (migrations.test_operations.OperationTests) ... ok\ntest_rename_model_with_superclass_fk (migrations.test_operations.OperationTests)\nTests the RenameModel operation on a model which has a superclass that ... ok\ntest_rename_referenced_field_state_forward (migrations.test_operations.OperationTests) ... ok\ntest_repoint_field_m2m (migrations.test_operations.OperationTests) ... ok\ntest_run_python (migrations.test_operations.OperationTests)\nTests the RunPython operation ... ok\ntest_run_python_atomic (migrations.test_operations.OperationTests)\nTests the RunPython operation correctly handles the \"atomic\" keyword ... ok\ntest_run_python_noop (migrations.test_operations.OperationTests)\n#24098 - Tests no-op RunPython operations. ... ok\ntest_run_python_related_assignment (migrations.test_operations.OperationTests)\n#24282 - Model changes to a FK reverse side update the model ... ok\ntest_run_sql (migrations.test_operations.OperationTests)\nTests the RunSQL operation. ... ok\ntest_run_sql_add_missing_semicolon_on_collect_sql (migrations.test_operations.OperationTests) ... ok\ntest_run_sql_noop (migrations.test_operations.OperationTests)\n#24098 - Tests no-op RunSQL operations. ... ok\ntest_run_sql_params (migrations.test_operations.OperationTests)\n#23426 - RunSQL should accept parameters. ... ok\ntest_run_sql_params_invalid (migrations.test_operations.OperationTests)\n#23426 - RunSQL should fail when a list of statements with an incorrect ... ok\ntest_separate_database_and_state (migrations.test_operations.OperationTests)\nTests the SeparateDatabaseAndState operation. ... ok\ntest_separate_database_and_state2 (migrations.test_operations.OperationTests)\nA complex SeparateDatabaseAndState operation: Multiple operations both ... ok\ntest_smallfield_autofield_foreignfield_growth (migrations.test_operations.OperationTests)\nA field may be migrated from SmallAutoField to AutoField. ... ok\ntest_smallfield_bigautofield_foreignfield_growth (migrations.test_operations.OperationTests)\nA field may be migrated from SmallAutoField to BigAutoField. ... ok\n\n----------------------------------------------------------------------\nRan 132 tests in 2.019s\n\nOK (skipped=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/migrations/test_operations.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-15741",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 27.695041179656982,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 104,
          "failed": 0,
          "errors": 2,
          "duration": 12.31,
          "log_tail": "  File \"/testbed/django/utils/formats.py\", line 158, in date_format\n    value, get_format(format or \"DATE_FORMAT\", use_l10n=use_l10n)\n  File \"/testbed/django/utils/formats.py\", line 128, in get_format\n    val = getattr(module, format_type, None)\nTypeError: getattr(): attribute name must be string\n\n======================================================================\nERROR: test_get_format_lazy_format (i18n.tests.FormattingTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/tests/i18n/tests.py\", line 1522, in test_get_format_lazy_format\n    self.assertEqual(get_format(gettext_lazy(\"DATE_FORMAT\")), \"N j, Y\")\n  File \"/testbed/django/utils/formats.py\", line 128, in get_format\n    val = getattr(module, format_type, None)\nTypeError: getattr(): attribute name must be string\n\n----------------------------------------------------------------------\nRan 106 tests in 1.030s\n\nFAILED (errors=2)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 i18n.tests template_tests.filter_tests.test_date` failed. (See above for error)",
          "test_files_run": [
            "tests/i18n/tests.py",
            "tests/template_tests/filter_tests/test_date.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 106,
          "failed": 0,
          "errors": 0,
          "duration": 13.17,
          "log_tail": "test_iter_format_modules_stability (i18n.tests.FormattingTests)\nTests the iter_format_modules function always yields format modules in ... ok\ntest_l10n_disabled (i18n.tests.FormattingTests)\nCatalan locale with format i18n disabled translations will be used, ... ok\ntest_l10n_enabled (i18n.tests.FormattingTests) ... ok\ntest_locale_independent (i18n.tests.FormattingTests)\nLocalization of numbers ... ok\ntest_localize_templatetag_and_filter (i18n.tests.FormattingTests)\nTest the {% localize %} templatetag and the localize/unlocalize filters. ... ok\ntest_localized_as_text_as_hidden_input (i18n.tests.FormattingTests)\nForm input with 'as_hidden' or 'as_text' is correctly localized. ... ok\ntest_localized_input (i18n.tests.FormattingTests)\nTests if form input is correctly localized ... ok\ntest_localized_input_func (i18n.tests.FormattingTests) ... ok\ntest_localized_off_numbers (i18n.tests.FormattingTests)\nA string representation is returned for unlocalized numbers. ... ok\ntest_sanitize_separators (i18n.tests.FormattingTests)\nTests django.utils.formats.sanitize_separators. ... ok\ntest_sanitize_strftime_format (i18n.tests.FormattingTests) ... ok\ntest_sanitize_strftime_format_with_escaped_percent (i18n.tests.FormattingTests) ... ok\ntest_sub_locales (i18n.tests.FormattingTests)\nCheck if sublocales fall back to the main locale ... ok\n\n----------------------------------------------------------------------\nRan 106 tests in 1.050s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/i18n/tests.py",
            "tests/template_tests/filter_tests/test_date.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-15814",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 24.54077410697937,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 29,
          "failed": 0,
          "errors": 1,
          "duration": 11.7,
          "log_tail": "Test save signals for proxy models ... ok\ntest_proxy_update (proxy_models.tests.ProxyModelTests) ... ok\ntest_same_manager_queries (proxy_models.tests.ProxyModelTests)\nThe MyPerson model should be generating the same database queries as ... ok\ntest_select_related (proxy_models.tests.ProxyModelTests)\nWe can still use `select_related()` to include related models in our ... ok\ntest_select_related_only (proxy_models.tests.ProxyModelTests) ... ERROR\ntest_swappable (proxy_models.tests.ProxyModelTests) ... ok\ntest_too_many_concrete_classes (proxy_models.tests.ProxyModelTests) ... ok\ntest_user_proxy_models (proxy_models.tests.ProxyModelTests) ... ok\ntest_cascade_delete_proxy_model_admin_warning (proxy_models.tests.ProxyModelAdminTests)\nTest if admin gives warning about cascade deleting models referenced ... ok\ntest_delete_str_in_model_admin (proxy_models.tests.ProxyModelAdminTests)\nTest if the admin delete page shows the correct string representation ... ok\n\n======================================================================\nERROR: test_select_related_only (proxy_models.tests.ProxyModelTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/tests/proxy_models/tests.py\", line 402, in test_select_related_only\n    self.assertEqual(qs.get(), issue)\n  File \"/testbed/django/db/models/query.py\", line 646, in get\n    num = len(clone)\n  File \"/testbed/django/db/models/query.py\", line 376, in __len__\n    self._fetch_all()\n  File \"/testbed/django/db/models/query.py\", line 1876, in _fetch_all\n    self._result_cache = list(self._iterable_class(self))\n  File \"/testbed/django/db/models/query.py\", line 101, in __iter__\n    related_populators = get_related_populators(klass_info, select, db)\n  File \"/testbed/django/db/models/query.py\", line 2624, in get_related_populators\n    rel_cls = RelatedPopulator(rel_klass_info, select, db)\n  File \"/testbed/django/db/models/query.py\", line 2599, in __init__\n    self.pk_idx = self.init_list.index(self.model_cls._meta.pk.attname)\nValueError: 'baseuser_ptr_id' is not in list\n\n----------------------------------------------------------------------\nRan 30 tests in 0.178s\n\nFAILED (errors=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 proxy_models.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/proxy_models/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 30,
          "failed": 0,
          "errors": 0,
          "duration": 11.76,
          "log_tail": "Test if admin gives warning about cascade deleting models referenced ... ok\ntest_delete_str_in_model_admin (proxy_models.tests.ProxyModelAdminTests)\nTest if the admin delete page shows the correct string representation ... ok\ntest_abstract_base_with_model_fields (proxy_models.tests.ProxyModelTests) ... ok\ntest_basic_proxy (proxy_models.tests.ProxyModelTests)\nCreating a Person makes them accessible through the MyPerson proxy. ... ok\ntest_basic_proxy_reverse (proxy_models.tests.ProxyModelTests)\nA new MyPerson also shows up as a standard Person. ... ok\ntest_concrete_model (proxy_models.tests.ProxyModelTests) ... ok\ntest_content_type (proxy_models.tests.ProxyModelTests) ... ok\ntest_correct_type_proxy_of_proxy (proxy_models.tests.ProxyModelTests)\nCorrect type when querying a proxy of proxy ... ok\ntest_eq (proxy_models.tests.ProxyModelTests) ... ok\ntest_filter_proxy_relation_reverse (proxy_models.tests.ProxyModelTests) ... ok\ntest_inheritance_new_table (proxy_models.tests.ProxyModelTests)\nThe StatusPerson models should have its own table (it's using ORM-level ... ok\ntest_myperson_manager (proxy_models.tests.ProxyModelTests) ... ok\ntest_new_fields (proxy_models.tests.ProxyModelTests) ... ok\ntest_no_base_classes (proxy_models.tests.ProxyModelTests) ... ok\ntest_no_proxy (proxy_models.tests.ProxyModelTests)\nPerson is not proxied by StatusPerson subclass. ... ok\ntest_otherperson_manager (proxy_models.tests.ProxyModelTests) ... ok\ntest_permissions_created (proxy_models.tests.ProxyModelTests) ... ok\ntest_proxy_bug (proxy_models.tests.ProxyModelTests) ... ok\ntest_proxy_delete (proxy_models.tests.ProxyModelTests)\nProxy objects can be deleted ... ok\ntest_proxy_for_model (proxy_models.tests.ProxyModelTests) ... ok\ntest_proxy_included_in_ancestors (proxy_models.tests.ProxyModelTests)\nProxy models are included in the ancestors for a model's DoesNotExist ... ok\ntest_proxy_load_from_fixture (proxy_models.tests.ProxyModelTests) ... ok\ntest_proxy_model_signals (proxy_models.tests.ProxyModelTests)\nTest save signals for proxy models ... ok\ntest_proxy_update (proxy_models.tests.ProxyModelTests) ... ok\ntest_same_manager_queries (proxy_models.tests.ProxyModelTests)\nThe MyPerson model should be generating the same database queries as ... ok\ntest_select_related (proxy_models.tests.ProxyModelTests)\nWe can still use `select_related()` to include related models in our ... ok\ntest_select_related_only (proxy_models.tests.ProxyModelTests) ... ok\ntest_swappable (proxy_models.tests.ProxyModelTests) ... ok\ntest_too_many_concrete_classes (proxy_models.tests.ProxyModelTests) ... ok\ntest_user_proxy_models (proxy_models.tests.ProxyModelTests) ... ok\n\n----------------------------------------------------------------------\nRan 30 tests in 0.160s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/proxy_models/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-15851",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 23.249145984649658,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 9,
          "failed": 1,
          "errors": 0,
          "duration": 11.41,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application dbshell\nFound 10 test(s).\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_accent (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase) ... ok\ntest_basic (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase) ... ok\ntest_column (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase) ... ok\ntest_crash_password_does_not_leak (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase) ... ok\ntest_nopass (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase) ... ok\ntest_parameters (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase) ... FAIL\ntest_passfile (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase) ... ok\ntest_service (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase) ... ok\ntest_sigint_handler (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase)\nSIGINT is ignored in Python and passed to psql to abort queries. ... skipped 'Requires a PostgreSQL connection'\ntest_ssl_certificate (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase) ... ok\n\n======================================================================\nFAIL: test_parameters (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/dbshell/test_postgresql.py\", line 155, in test_parameters\n    self.assertEqual(\nAssertionError: Tuples differ: (['psql', 'dbname', '--help'], None) != (['psql', '--help', 'dbname'], None)\n\nFirst differing element 0:\n['psql', 'dbname', '--help']\n['psql', '--help', 'dbname']\n\n- (['psql', 'dbname', '--help'], None)\n+ (['psql', '--help', 'dbname'], None)\n\n----------------------------------------------------------------------\nRan 10 tests in 0.042s\n\nFAILED (failures=1, skipped=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 dbshell.test_postgresql` failed. (See above for error)",
          "test_files_run": [
            "tests/dbshell/test_postgresql.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 10,
          "failed": 0,
          "errors": 0,
          "duration": 10.62,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application dbshell\nFound 10 test(s).\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_accent (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase) ... ok\ntest_basic (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase) ... ok\ntest_column (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase) ... ok\ntest_crash_password_does_not_leak (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase) ... ok\ntest_nopass (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase) ... ok\ntest_parameters (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase) ... ok\ntest_passfile (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase) ... ok\ntest_service (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase) ... ok\ntest_sigint_handler (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase)\nSIGINT is ignored in Python and passed to psql to abort queries. ... skipped 'Requires a PostgreSQL connection'\ntest_ssl_certificate (dbshell.test_postgresql.PostgreSqlDbshellCommandTestCase) ... ok\n\n----------------------------------------------------------------------\nRan 10 tests in 0.057s\n\nOK (skipped=1)\n",
          "test_files_run": [
            "tests/dbshell/test_postgresql.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-15863",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 23.61756920814514,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 9,
          "failed": 1,
          "errors": 0,
          "duration": 11.22,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application template_tests\nFound 10 test(s).\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_floatformat01 (template_tests.filter_tests.test_floatformat.FloatformatTests) ... ok\ntest_floatformat02 (template_tests.filter_tests.test_floatformat.FloatformatTests) ... ok\ntest_float_dunder_method (template_tests.filter_tests.test_floatformat.FunctionTests) ... ok\ntest_force_grouping (template_tests.filter_tests.test_floatformat.FunctionTests) ... ok\ntest_infinity (template_tests.filter_tests.test_floatformat.FunctionTests) ... ok\ntest_inputs (template_tests.filter_tests.test_floatformat.FunctionTests) ... FAIL\ntest_low_decimal_precision (template_tests.filter_tests.test_floatformat.FunctionTests)\n#15789 ... ok\ntest_negative_zero_values (template_tests.filter_tests.test_floatformat.FunctionTests) ... ok\ntest_unlocalize (template_tests.filter_tests.test_floatformat.FunctionTests) ... ok\ntest_zero_values (template_tests.filter_tests.test_floatformat.FunctionTests) ... ok\n\n======================================================================\nFAIL: test_inputs (template_tests.filter_tests.test_floatformat.FunctionTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/tests/template_tests/filter_tests/test_floatformat.py\", line 59, in test_inputs\n    self.assertEqual(\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 837, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 830, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: '123456.123456789000000000000' != '123456.123456789012345678901'\n\n----------------------------------------------------------------------\nRan 10 tests in 0.048s\n\nFAILED (failures=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 template_tests.filter_tests.test_floatformat` failed. (See above for error)",
          "test_files_run": [
            "tests/template_tests/filter_tests/test_floatformat.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 10,
          "failed": 0,
          "errors": 0,
          "duration": 11.28,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application template_tests\nFound 10 test(s).\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_floatformat01 (template_tests.filter_tests.test_floatformat.FloatformatTests) ... ok\ntest_floatformat02 (template_tests.filter_tests.test_floatformat.FloatformatTests) ... ok\ntest_float_dunder_method (template_tests.filter_tests.test_floatformat.FunctionTests) ... ok\ntest_force_grouping (template_tests.filter_tests.test_floatformat.FunctionTests) ... ok\ntest_infinity (template_tests.filter_tests.test_floatformat.FunctionTests) ... ok\ntest_inputs (template_tests.filter_tests.test_floatformat.FunctionTests) ... ok\ntest_low_decimal_precision (template_tests.filter_tests.test_floatformat.FunctionTests)\n#15789 ... ok\ntest_negative_zero_values (template_tests.filter_tests.test_floatformat.FunctionTests) ... ok\ntest_unlocalize (template_tests.filter_tests.test_floatformat.FunctionTests) ... ok\ntest_zero_values (template_tests.filter_tests.test_floatformat.FunctionTests) ... ok\n\n----------------------------------------------------------------------\nRan 10 tests in 0.082s\n\nOK\n",
          "test_files_run": [
            "tests/template_tests/filter_tests/test_floatformat.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-15916",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 25.210308074951172,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 150,
          "failed": 2,
          "errors": 0,
          "duration": 11.73,
          "log_tail": "  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 837, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 830, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: <class 'django.forms.widgets.TextInput'> != <class 'django.forms.widgets.Textarea'>\n\n======================================================================\nFAIL: test_custom_callback_in_meta (model_forms.tests.FormFieldCallbackTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/tests/model_forms/tests.py\", line 3510, in test_custom_callback_in_meta\n    self.assertEqual(type(field.widget), forms.Textarea)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 837, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 830, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: <class 'django.forms.widgets.TextInput'> != <class 'django.forms.widgets.Textarea'>\n\n----------------------------------------------------------------------\nRan 152 tests in 0.256s\n\nFAILED (failures=2)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 model_forms.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/model_forms/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 152,
          "failed": 0,
          "errors": 0,
          "duration": 12.36,
          "log_tail": "If the date for unique_for_* constraints is excluded from the ... ok\ntest_unique_for_date_with_nullable_date (model_forms.tests.UniqueTest) ... ok\ntest_unique_null (model_forms.tests.UniqueTest) ... ok\ntest_unique_together (model_forms.tests.UniqueTest)\nModelForm test of unique_together constraint ... ok\ntest_unique_together_exclusion (model_forms.tests.UniqueTest)\nForms don't validate unique_together constraints when only part of the ... ok\ntest_auto_id (model_forms.tests.ModelFormBasicTests) ... ok\ntest_base_form (model_forms.tests.ModelFormBasicTests) ... ok\ntest_basic_creation (model_forms.tests.ModelFormBasicTests) ... ok\ntest_custom_form_fields (model_forms.tests.ModelFormBasicTests) ... ok\ntest_initial_values (model_forms.tests.ModelFormBasicTests) ... ok\ntest_m2m_editing (model_forms.tests.ModelFormBasicTests) ... ok\ntest_m2m_initial_callable (model_forms.tests.ModelFormBasicTests)\nA callable can be provided as the initial value for an m2m field. ... ok\ntest_multi_fields (model_forms.tests.ModelFormBasicTests) ... ok\ntest_recleaning_model_form_instance (model_forms.tests.ModelFormBasicTests)\nRe-cleaning an instance that was added via a ModelForm shouldn't raise ... ok\ntest_runtime_choicefield_populated (model_forms.tests.ModelFormBasicTests) ... ok\ntest_save_commit_false (model_forms.tests.ModelFormBasicTests) ... ok\ntest_save_with_data_errors (model_forms.tests.ModelFormBasicTests) ... ok\ntest_subset_fields (model_forms.tests.ModelFormBasicTests) ... ok\ntest_validate_foreign_key_to_model_with_overridden_manager (model_forms.tests.ModelFormBasicTests) ... ok\ntest_validate_foreign_key_uses_default_manager (model_forms.tests.ModelFormBasicTests) ... ok\n\n----------------------------------------------------------------------\nRan 152 tests in 0.249s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/model_forms/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-15930",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 24.92662501335144,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 88,
          "failed": 0,
          "errors": 1,
          "duration": 11.75,
          "log_tail": "Traceback (most recent call last):\n  File \"/testbed/django/db/backends/utils.py\", line 89, in _execute\n    return self.cursor.execute(sql, params)\n  File \"/testbed/django/db/backends/sqlite3/base.py\", line 369, in execute\n    return Database.Cursor.execute(self, query, params)\nsqlite3.OperationalError: near \"THEN\": syntax error\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/tests/expressions_case/tests.py\", line 425, in test_annotate_with_full_when\n    self.assertEqual(len(objects), CaseTestModel.objects.count())\n  File \"/testbed/django/db/models/query.py\", line 376, in __len__\n    self._fetch_all()\n  File \"/testbed/django/db/models/query.py\", line 1876, in _fetch_all\n    self._result_cache = list(self._iterable_class(self))\n  File \"/testbed/django/db/models/query.py\", line 87, in __iter__\n    results = compiler.execute_sql(\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1396, in execute_sql\n    cursor.execute(sql, params)\n  File \"/testbed/django/db/backends/utils.py\", line 67, in execute\n    return self._execute_with_wrappers(\n  File \"/testbed/django/db/backends/utils.py\", line 80, in _execute_with_wrappers\n    return executor(sql, params, many, context)\n  File \"/testbed/django/db/backends/utils.py\", line 89, in _execute\n    return self.cursor.execute(sql, params)\n  File \"/testbed/django/db/utils.py\", line 91, in __exit__\n    raise dj_exc_value.with_traceback(traceback) from exc_value\n  File \"/testbed/django/db/backends/utils.py\", line 89, in _execute\n    return self.cursor.execute(sql, params)\n  File \"/testbed/django/db/backends/sqlite3/base.py\", line 369, in execute\n    return Database.Cursor.execute(self, query, params)\ndjango.db.utils.OperationalError: near \"THEN\": syntax error\n\n----------------------------------------------------------------------\nRan 89 tests in 0.239s\n\nFAILED (errors=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 expressions_case.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/expressions_case/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 89,
          "failed": 0,
          "errors": 0,
          "duration": 11.91,
          "log_tail": "test_in_subquery (expressions_case.tests.CaseExpressionTests) ... ok\ntest_join_promotion (expressions_case.tests.CaseExpressionTests) ... ok\ntest_join_promotion_multiple_annotations (expressions_case.tests.CaseExpressionTests) ... ok\ntest_lookup_different_fields (expressions_case.tests.CaseExpressionTests) ... ok\ntest_lookup_in_condition (expressions_case.tests.CaseExpressionTests) ... ok\ntest_m2m_exclude (expressions_case.tests.CaseExpressionTests) ... ok\ntest_m2m_reuse (expressions_case.tests.CaseExpressionTests) ... ok\ntest_order_by_conditional_explicit (expressions_case.tests.CaseExpressionTests) ... ok\ntest_order_by_conditional_implicit (expressions_case.tests.CaseExpressionTests) ... ok\ntest_update (expressions_case.tests.CaseExpressionTests) ... ok\ntest_update_big_integer (expressions_case.tests.CaseExpressionTests) ... ok\ntest_update_binary (expressions_case.tests.CaseExpressionTests) ... ok\ntest_update_boolean (expressions_case.tests.CaseExpressionTests) ... ok\ntest_update_date (expressions_case.tests.CaseExpressionTests) ... ok\ntest_update_date_time (expressions_case.tests.CaseExpressionTests) ... ok\ntest_update_decimal (expressions_case.tests.CaseExpressionTests) ... ok\ntest_update_duration (expressions_case.tests.CaseExpressionTests) ... ok\ntest_update_email (expressions_case.tests.CaseExpressionTests) ... ok\ntest_update_file (expressions_case.tests.CaseExpressionTests) ... ok\ntest_update_file_path (expressions_case.tests.CaseExpressionTests) ... ok\ntest_update_fk (expressions_case.tests.CaseExpressionTests) ... ok\ntest_update_float (expressions_case.tests.CaseExpressionTests) ... ok\ntest_update_generic_ip_address (expressions_case.tests.CaseExpressionTests) ... ok\ntest_update_image (expressions_case.tests.CaseExpressionTests) ... ok\ntest_update_null_boolean (expressions_case.tests.CaseExpressionTests) ... ok\ntest_update_positive_big_integer (expressions_case.tests.CaseExpressionTests) ... ok\ntest_update_positive_integer (expressions_case.tests.CaseExpressionTests) ... ok\ntest_update_positive_small_integer (expressions_case.tests.CaseExpressionTests) ... ok\ntest_update_slug (expressions_case.tests.CaseExpressionTests) ... ok\ntest_update_small_integer (expressions_case.tests.CaseExpressionTests) ... ok\ntest_update_string (expressions_case.tests.CaseExpressionTests) ... ok\ntest_update_text (expressions_case.tests.CaseExpressionTests) ... ok\ntest_update_time (expressions_case.tests.CaseExpressionTests) ... ok\ntest_update_url (expressions_case.tests.CaseExpressionTests) ... ok\ntest_update_uuid (expressions_case.tests.CaseExpressionTests) ... ok\ntest_update_with_expression_as_condition (expressions_case.tests.CaseExpressionTests) ... ok\ntest_update_with_expression_as_value (expressions_case.tests.CaseExpressionTests) ... ok\ntest_update_with_join_in_condition_raise_field_error (expressions_case.tests.CaseExpressionTests) ... ok\ntest_update_with_join_in_predicate_raise_field_error (expressions_case.tests.CaseExpressionTests) ... ok\ntest_update_without_default (expressions_case.tests.CaseExpressionTests) ... ok\n\n----------------------------------------------------------------------\nRan 89 tests in 0.271s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/expressions_case/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-15957",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 25.084074020385742,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 89,
          "failed": 0,
          "errors": 4,
          "duration": 11.74,
          "log_tail": "  File \"/testbed/django/db/models/fields/related_descriptors.py\", line 1055, in get_prefetch_queryset\n    queryset = queryset._next_is_sticky().filter(**query)\n  File \"/testbed/django/db/models/query.py\", line 1430, in filter\n    return self._filter_or_exclude(False, args, kwargs)\n  File \"/testbed/django/db/models/query.py\", line 1442, in _filter_or_exclude\n    raise TypeError(\"Cannot filter a query once a slice has been taken.\")\nTypeError: Cannot filter a query once a slice has been taken.\n\n----------------------------------------------------------------------\nRan 93 tests in 0.220s\n\nFAILED (errors=4)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 prefetch_related.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/prefetch_related/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 93,
          "failed": 0,
          "errors": 0,
          "duration": 12.28,
          "log_tail": "test_raw_queryset (prefetch_related.tests.CustomPrefetchTests) ... ok\ntest_reverse_m2m (prefetch_related.tests.CustomPrefetchTests) ... ok\ntest_to_attr_cached_property (prefetch_related.tests.CustomPrefetchTests) ... ok\ntest_to_attr_doesnt_cache_through_attr_as_list (prefetch_related.tests.CustomPrefetchTests) ... ok\ntest_traverse_multiple_items_property (prefetch_related.tests.CustomPrefetchTests) ... ok\ntest_traverse_qs (prefetch_related.tests.CustomPrefetchTests) ... ok\ntest_traverse_single_item_property (prefetch_related.tests.CustomPrefetchTests) ... ok\ntest_values_queryset (prefetch_related.tests.CustomPrefetchTests) ... ok\n\n----------------------------------------------------------------------\nRan 93 tests in 0.261s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/prefetch_related/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-15973",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 26.530383110046387,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 164,
          "failed": 1,
          "errors": 0,
          "duration": 12.21,
          "log_tail": "unique_together doesn't generate a migration if no ... ok\ntest_unique_together_ordering (migrations.test_autodetector.AutodetectorTests)\nunique_together also triggers on ordering changes. ... ok\ntest_unique_together_remove_fk (migrations.test_autodetector.AutodetectorTests)\nTests unique_together and field removal detection & ordering ... ok\ntest_unmanaged_create (migrations.test_autodetector.AutodetectorTests)\nThe autodetector correctly deals with managed models. ... ok\ntest_unmanaged_custom_pk (migrations.test_autodetector.AutodetectorTests)\n#23415 - The autodetector must correctly deal with custom FK on ... ok\ntest_unmanaged_delete (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_unmanaged_to_managed (migrations.test_autodetector.AutodetectorTests) ... ok\n\n======================================================================\nFAIL: test_create_with_through_model_separate_apps (migrations.test_autodetector.AutodetectorTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/tests/migrations/test_autodetector.py\", line 3616, in test_create_with_through_model_separate_apps\n    self.assertNumberMigrations(changes, \"authors\", 2)\n  File \"/testbed/tests/migrations/test_autodetector.py\", line 55, in assertNumberMigrations\n    self.fail(\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 676, in fail\n    raise self.failureException(msg)\nAssertionError: Incorrect number of migrations (1) for authors (expected 2)\n  authors:\n    auto_1\n      <CreateModel 'Author' fields=[('id', <django.db.models.fields.AutoField: id>), ('publishers', <django.db.models.fields.related.ManyToManyField: publishers>)], options={}, bases=(<class 'django.db.models.base.Model'>,), managers=[]>\n  contract:\n    auto_1\n      <CreateModel 'Contract' fields=[('id', <django.db.models.fields.AutoField: id>), ('author', <django.db.models.fields.related.ForeignKey: author>), ('publisher', <django.db.models.fields.related.ForeignKey: publisher>)], options={}, bases=(<class 'django.db.models.base.Model'>,), managers=[]>\n  testapp:\n    auto_1\n      <CreateModel  name='Publisher', fields=[('id', <django.db.models.fields.AutoField: id>), ('name', <django.db.models.fields.CharField: name>)], options={}, bases=(<class 'django.db.models.base.Model'>,), managers=[]>\n\n\n----------------------------------------------------------------------\nRan 165 tests in 0.297s\n\nFAILED (failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 migrations.test_autodetector` failed. (See above for error)",
          "test_files_run": [
            "tests/migrations/test_autodetector.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 165,
          "failed": 0,
          "errors": 0,
          "duration": 12.13,
          "log_tail": "test_rename_model_with_renamed_rel_field (migrations.test_autodetector.AutodetectorTests)\nTests autodetection of renamed models while simultaneously renaming one ... ok\ntest_rename_referenced_primary_key (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_rename_related_field_preserved_db_column (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_renamed_referenced_m2m_model_case (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_replace_string_with_foreignkey (migrations.test_autodetector.AutodetectorTests)\n#22300 - Adding an FK in the same \"spot\" as a deleted CharField should ... ok\ntest_same_app_circular_fk_dependency (migrations.test_autodetector.AutodetectorTests)\nA migration with a FK between two models of the same app does ... ok\ntest_same_app_circular_fk_dependency_with_unique_together_and_indexes (migrations.test_autodetector.AutodetectorTests)\n#22275 - A migration with circular FK dependency does not try ... ok\ntest_same_app_no_fk_dependency (migrations.test_autodetector.AutodetectorTests)\nA migration with a FK between two models of the same app ... ok\ntest_set_alter_order_with_respect_to (migrations.test_autodetector.AutodetectorTests)\nSetting order_with_respect_to adds a field. ... ok\ntest_set_alter_order_with_respect_to_index_constraint_unique_together (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_supports_functools_partial (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_swappable (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_swappable_changed (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_swappable_circular_multi_mti (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_swappable_first_inheritance (migrations.test_autodetector.AutodetectorTests)\nSwappable models get their CreateModel first. ... ok\ntest_swappable_first_setting (migrations.test_autodetector.AutodetectorTests)\nSwappable models get their CreateModel first. ... ok\ntest_swappable_lowercase (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_swappable_many_to_many_model_case (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_trim_apps (migrations.test_autodetector.AutodetectorTests)\nTrim does not remove dependencies but does remove unwanted apps. ... ok\ntest_unique_together_no_changes (migrations.test_autodetector.AutodetectorTests)\nunique_together doesn't generate a migration if no ... ok\ntest_unique_together_ordering (migrations.test_autodetector.AutodetectorTests)\nunique_together also triggers on ordering changes. ... ok\ntest_unique_together_remove_fk (migrations.test_autodetector.AutodetectorTests)\nTests unique_together and field removal detection & ordering ... ok\ntest_unmanaged_create (migrations.test_autodetector.AutodetectorTests)\nThe autodetector correctly deals with managed models. ... ok\ntest_unmanaged_custom_pk (migrations.test_autodetector.AutodetectorTests)\n#23415 - The autodetector must correctly deal with custom FK on ... ok\ntest_unmanaged_delete (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_unmanaged_to_managed (migrations.test_autodetector.AutodetectorTests) ... ok\n\n----------------------------------------------------------------------\nRan 165 tests in 0.226s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/migrations/test_autodetector.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-15987",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 25.0800518989563,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 57,
          "failed": 1,
          "errors": 0,
          "duration": 12.02,
          "log_tail": "test_unimportable_serializer (fixtures_regress.tests.TestFixtures)\nFailing serializer import raises the proper error ... ok\ntest_unknown_format (fixtures_regress.tests.TestFixtures)\nTest for ticket #4371 -- Loading data of an unknown format should fail ... ok\n\n======================================================================\nFAIL: test_fixture_dirs_with_default_fixture_path_as_pathlib (fixtures_regress.tests.TestFixtures)\nsettings.FIXTURE_DIRS cannot contain a default fixtures directory\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/django/test/utils.py\", line 460, in inner\n    return func(*args, **kwargs)\n  File \"/testbed/tests/fixtures_regress/tests.py\", line 584, in test_fixture_dirs_with_default_fixture_path_as_pathlib\n    management.call_command(\"loaddata\", \"absolute.json\", verbosity=0)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/contextlib.py\", line 126, in __exit__\n    next(self.gen)\n  File \"/testbed/django/test/testcases.py\", line 878, in _assert_raises_or_warns_cm\n    yield cm\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 226, in __exit__\n    self._raiseFailure(\"{} not raised\".format(exc_name))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 163, in _raiseFailure\n    raise self.test_case.failureException(msg)\nAssertionError: ImproperlyConfigured not raised\n\n----------------------------------------------------------------------\nRan 58 tests in 0.232s\n\nFAILED (failures=1, skipped=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 fixtures_regress.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/fixtures_regress/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 58,
          "failed": 0,
          "errors": 0,
          "duration": 11.93,
          "log_tail": "test_loaddata_not_found_fields_ignore_xml (fixtures_regress.tests.TestFixtures)\nTest for ticket #19998 -- Ignore entries in the XML serialized data ... ok\ntest_loaddata_not_found_fields_not_ignore (fixtures_regress.tests.TestFixtures)\nTest for ticket #9279 -- Error is raised for entries in ... ok\ntest_loaddata_raises_error_when_fixture_has_invalid_foreign_key (fixtures_regress.tests.TestFixtures)\nData with nonexistent child key references raises error. ... ok\ntest_loaddata_with_m2m_to_self (fixtures_regress.tests.TestFixtures)\nRegression test for ticket #17946. ... ok\ntest_loaddata_with_valid_fixture_dirs (fixtures_regress.tests.TestFixtures) ... ok\ntest_loaddata_works_when_fixture_has_forward_refs (fixtures_regress.tests.TestFixtures)\nForward references cause fixtures not to load in MySQL (InnoDB). ... ok\ntest_path_containing_dots (fixtures_regress.tests.TestFixtures) ... ok\ntest_pg_sequence_resetting_checks (fixtures_regress.tests.TestFixtures)\nTest for ticket #7565 -- PostgreSQL sequence resetting checks shouldn't ... ok\ntest_pretty_print_xml (fixtures_regress.tests.TestFixtures)\nRegression test for ticket #4558 -- pretty printing of XML fixtures ... ok\ntest_pretty_print_xml_empty_strings (fixtures_regress.tests.TestFixtures)\nRegression test for ticket #4558 -- pretty printing of XML fixtures ... skipped \"Database doesn't support feature(s): interprets_empty_strings_as_nulls\"\ntest_proxy_model_included (fixtures_regress.tests.TestFixtures)\nRegression for #11428 - Proxy models aren't included when you dumpdata ... ok\ntest_relative_path (fixtures_regress.tests.TestFixtures) ... ok\ntest_relative_path_in_fixture_dirs (fixtures_regress.tests.TestFixtures) ... ok\ntest_ticket_20820 (fixtures_regress.tests.TestFixtures)\nRegression for ticket #20820 -- loaddata on a model that inherits ... ok\ntest_ticket_22421 (fixtures_regress.tests.TestFixtures)\nRegression for ticket #22421 -- loaddata on a model that inherits from ... ok\ntest_unimportable_serializer (fixtures_regress.tests.TestFixtures)\nFailing serializer import raises the proper error ... ok\ntest_unknown_format (fixtures_regress.tests.TestFixtures)\nTest for ticket #4371 -- Loading data of an unknown format should fail ... ok\n\n----------------------------------------------------------------------\nRan 58 tests in 0.242s\n\nOK (skipped=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/fixtures_regress/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-16032",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 25.400892972946167,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 80,
          "failed": 0,
          "errors": 2,
          "duration": 12.32,
          "log_tail": "  File \"/testbed/django/db/backends/sqlite3/base.py\", line 369, in execute\n    return Database.Cursor.execute(self, query, params)\nsqlite3.OperationalError: sub-select returns 10 columns - expected 1\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/tests/annotations/tests.py\", line 1010, in test_annotation_and_alias_filter_related_in_subquery\n    self.assertCountEqual(\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 1179, in assertCountEqual\n    first_seq, second_seq = list(first), list(second)\n  File \"/testbed/django/db/models/query.py\", line 376, in __len__\n    self._fetch_all()\n  File \"/testbed/django/db/models/query.py\", line 1876, in _fetch_all\n    self._result_cache = list(self._iterable_class(self))\n  File \"/testbed/django/db/models/query.py\", line 204, in __iter__\n    for row in compiler.results_iter(\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1427, in results_iter\n    results = self.execute_sql(\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1476, in execute_sql\n    cursor.execute(sql, params)\n  File \"/testbed/django/db/backends/utils.py\", line 67, in execute\n    return self._execute_with_wrappers(\n  File \"/testbed/django/db/backends/utils.py\", line 80, in _execute_with_wrappers\n    return executor(sql, params, many, context)\n  File \"/testbed/django/db/backends/utils.py\", line 89, in _execute\n    return self.cursor.execute(sql, params)\n  File \"/testbed/django/db/utils.py\", line 91, in __exit__\n    raise dj_exc_value.with_traceback(traceback) from exc_value\n  File \"/testbed/django/db/backends/utils.py\", line 89, in _execute\n    return self.cursor.execute(sql, params)\n  File \"/testbed/django/db/backends/sqlite3/base.py\", line 369, in execute\n    return Database.Cursor.execute(self, query, params)\ndjango.db.utils.OperationalError: sub-select returns 10 columns - expected 1\n\n----------------------------------------------------------------------\nRan 82 tests in 0.131s\n\nFAILED (errors=2, skipped=3)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 annotations.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/annotations/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 82,
          "failed": 0,
          "errors": 0,
          "duration": 11.86,
          "log_tail": "test_column_field_ordering (annotations.tests.NonAggregateAnnotationTestCase)\nColumns are aligned in the correct order for resolve_columns. This test ... ok\ntest_column_field_ordering_with_deferred (annotations.tests.NonAggregateAnnotationTestCase) ... ok\ntest_combined_annotation_commutative (annotations.tests.NonAggregateAnnotationTestCase) ... ok\ntest_combined_expression_annotation_with_aggregation (annotations.tests.NonAggregateAnnotationTestCase) ... ok\ntest_combined_f_expression_annotation_with_aggregation (annotations.tests.NonAggregateAnnotationTestCase) ... ok\ntest_custom_functions (annotations.tests.NonAggregateAnnotationTestCase) ... ok\ntest_custom_functions_can_ref_other_functions (annotations.tests.NonAggregateAnnotationTestCase) ... ok\ntest_custom_transform_annotation (annotations.tests.NonAggregateAnnotationTestCase) ... ok\ntest_decimal_annotation (annotations.tests.NonAggregateAnnotationTestCase) ... ok\ntest_defer_annotation (annotations.tests.NonAggregateAnnotationTestCase)\nDeferred attributes can be referenced by an annotation, ... ok\ntest_distinct_on_with_annotation (annotations.tests.NonAggregateAnnotationTestCase) ... skipped \"Database doesn't support feature(s): can_distinct_on_fields\"\ntest_empty_expression_annotation (annotations.tests.NonAggregateAnnotationTestCase) ... ok\ntest_empty_queryset_annotation (annotations.tests.NonAggregateAnnotationTestCase) ... ok\ntest_filter_agg_with_double_f (annotations.tests.NonAggregateAnnotationTestCase) ... ok\ntest_filter_annotation (annotations.tests.NonAggregateAnnotationTestCase) ... ok\ntest_filter_annotation_with_double_f (annotations.tests.NonAggregateAnnotationTestCase) ... ok\ntest_filter_annotation_with_f (annotations.tests.NonAggregateAnnotationTestCase) ... ok\ntest_filter_decimal_annotation (annotations.tests.NonAggregateAnnotationTestCase) ... ok\ntest_filter_wrong_annotation (annotations.tests.NonAggregateAnnotationTestCase) ... ok\ntest_full_expression_annotation (annotations.tests.NonAggregateAnnotationTestCase) ... ok\ntest_full_expression_annotation_with_aggregation (annotations.tests.NonAggregateAnnotationTestCase) ... ok\ntest_grouping_by_q_expression_annotation (annotations.tests.NonAggregateAnnotationTestCase) ... ok\ntest_joined_annotation (annotations.tests.NonAggregateAnnotationTestCase) ... ok\ntest_joined_transformed_annotation (annotations.tests.NonAggregateAnnotationTestCase) ... ok\ntest_mixed_type_annotation_date_interval (annotations.tests.NonAggregateAnnotationTestCase) ... ok\ntest_mixed_type_annotation_numbers (annotations.tests.NonAggregateAnnotationTestCase) ... ok\ntest_mti_annotations (annotations.tests.NonAggregateAnnotationTestCase)\nFields on an inherited model can be referenced by an ... ok\ntest_null_annotation (annotations.tests.NonAggregateAnnotationTestCase)\nAnnotating None onto a model round-trips ... ok\ntest_order_by_aggregate (annotations.tests.NonAggregateAnnotationTestCase) ... ok\ntest_order_by_annotation (annotations.tests.NonAggregateAnnotationTestCase) ... ok\ntest_q_expression_annotation_with_aggregation (annotations.tests.NonAggregateAnnotationTestCase) ... ok\ntest_raw_sql_with_inherited_field (annotations.tests.NonAggregateAnnotationTestCase) ... ok\ntest_rawsql_group_by_collapse (annotations.tests.NonAggregateAnnotationTestCase) ... skipped \"Database doesn't support feature(s): allows_group_by_pk\"\ntest_update_with_annotation (annotations.tests.NonAggregateAnnotationTestCase) ... ok\ntest_values_annotation (annotations.tests.NonAggregateAnnotationTestCase)\nAnnotations can reference fields in a values clause, ... ok\ntest_values_with_pk_annotation (annotations.tests.NonAggregateAnnotationTestCase) ... ok\n\n----------------------------------------------------------------------\nRan 82 tests in 0.141s\n\nOK (skipped=3)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/annotations/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-16082",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 25.948173761367798,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 170,
          "failed": 1,
          "errors": 4,
          "duration": 12.53,
          "log_tail": "    self.assertIsInstance(expr.output_field, combined)\n  File \"/testbed/django/utils/functional.py\", line 57, in __get__\n    res = instance.__dict__[self.name] = self.func(instance)\n  File \"/testbed/django/db/models/expressions.py\", line 295, in output_field\n    output_field = self._resolve_output_field()\n  File \"/testbed/django/db/models/expressions.py\", line 659, in _resolve_output_field\n    raise FieldError(\ndjango.core.exceptions.FieldError: Cannot infer type of '%%' expression involving these types: IntegerField, FloatField. You must set output_field.\n\n======================================================================\nERROR: test_resolve_output_field_number (expressions.tests.CombinedExpressionTests) [<object object at 0x72ccbfd352d0>] (lhs=<class 'django.db.models.fields.FloatField'>, connector='%%', rhs=<class 'django.db.models.fields.IntegerField'>, combined=<class 'django.db.models.fields.FloatField'>)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 499, in subTest\n    yield\n  File \"/testbed/tests/expressions/tests.py\", line 2436, in test_resolve_output_field_number\n    self.assertIsInstance(expr.output_field, combined)\n  File \"/testbed/django/utils/functional.py\", line 57, in __get__\n    res = instance.__dict__[self.name] = self.func(instance)\n  File \"/testbed/django/db/models/expressions.py\", line 295, in output_field\n    output_field = self._resolve_output_field()\n  File \"/testbed/django/db/models/expressions.py\", line 659, in _resolve_output_field\n    raise FieldError(\ndjango.core.exceptions.FieldError: Cannot infer type of '%%' expression involving these types: FloatField, IntegerField. You must set output_field.\n\n----------------------------------------------------------------------\nRan 175 tests in 0.320s\n\nFAILED (errors=4, skipped=1, expected failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 expressions.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/expressions/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 175,
          "failed": 0,
          "errors": 0,
          "duration": 11.23,
          "log_tail": "test_order_by_exists (expressions.tests.BasicExpressionsTests) ... ok\ntest_order_by_multiline_sql (expressions.tests.BasicExpressionsTests) ... ok\ntest_order_of_operations (expressions.tests.BasicExpressionsTests) ... ok\ntest_outerref (expressions.tests.BasicExpressionsTests) ... ok\ntest_outerref_mixed_case_table_name (expressions.tests.BasicExpressionsTests) ... ok\ntest_outerref_with_operator (expressions.tests.BasicExpressionsTests) ... ok\ntest_parenthesis_priority (expressions.tests.BasicExpressionsTests) ... ok\ntest_pickle_expression (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_eq (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_filter_by_aggregate (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_filter_by_lazy (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_group_by_outerref_in_filter (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_in_filter (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_references_joined_table_twice (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_sql (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_11722_iexact_lookup (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_16731_startswith_lookup (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_18375_chained_filters (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_18375_join_reuse (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_18375_kwarg_ordering (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_18375_kwarg_ordering_2 (expressions.tests.BasicExpressionsTests) ... ok\ntest_update (expressions.tests.BasicExpressionsTests) ... ok\ntest_update_inherited_field_value (expressions.tests.BasicExpressionsTests) ... ok\ntest_update_with_fk (expressions.tests.BasicExpressionsTests) ... ok\ntest_update_with_none (expressions.tests.BasicExpressionsTests) ... ok\ntest_uuid_pk_subquery (expressions.tests.BasicExpressionsTests) ... ok\n\n----------------------------------------------------------------------\nRan 175 tests in 0.209s\n\nOK (skipped=1, expected failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/expressions/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-16100",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 27.585888862609863,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 70,
          "failed": 1,
          "errors": 0,
          "duration": 13.88,
          "log_tail": "test_result_list_html (admin_changelist.tests.ChangeListTests)\nInclusion tag result_list generates a table when with default ... ok\ntest_result_list_set_empty_value_display_in_model_admin (admin_changelist.tests.ChangeListTests)\nEmpty value display can be set in ModelAdmin or individual fields. ... ok\ntest_result_list_set_empty_value_display_on_admin_site (admin_changelist.tests.ChangeListTests)\nEmpty value display can be set on AdminSite. ... ok\ntest_search_help_text (admin_changelist.tests.ChangeListTests) ... ok\ntest_select_related_as_empty_tuple (admin_changelist.tests.ChangeListTests) ... ok\ntest_select_related_as_tuple (admin_changelist.tests.ChangeListTests) ... ok\ntest_select_related_preserved (admin_changelist.tests.ChangeListTests)\nRegression test for #10348: ChangeList.get_queryset() shouldn't ... ok\ntest_select_related_preserved_when_multi_valued_in_search_fields (admin_changelist.tests.ChangeListTests) ... ok\ntest_show_all (admin_changelist.tests.ChangeListTests) ... ok\ntest_spanning_relations_with_custom_lookup_in_search_fields (admin_changelist.tests.ChangeListTests) ... ok\ntest_specified_ordering_by_f_expression (admin_changelist.tests.ChangeListTests) ... ok\ntest_specified_ordering_by_f_expression_without_asc_desc (admin_changelist.tests.ChangeListTests) ... ok\ntest_total_ordering_optimization (admin_changelist.tests.ChangeListTests) ... ok\ntest_total_ordering_optimization_meta_constraints (admin_changelist.tests.ChangeListTests) ... ok\ntest_tuple_list_display (admin_changelist.tests.ChangeListTests) ... ok\n\n======================================================================\nFAIL: test_list_editable_atomicity (admin_changelist.tests.ChangeListTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/django/test/testcases.py\", line 1586, in skip_wrapper\n    return test_func(*args, **kwargs)\n  File \"/testbed/tests/admin_changelist/tests.py\", line 431, in test_list_editable_atomicity\n    self.assertEqual(a.load, 4)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 837, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 830, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: 9.0 != 4\n\n----------------------------------------------------------------------\nRan 71 tests in 1.982s\n\nFAILED (failures=1, skipped=7)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 admin_changelist.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/admin_changelist/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 71,
          "failed": 0,
          "errors": 0,
          "duration": 12.45,
          "log_tail": "Regression test for #13902: When using a ManyToMany in list_filter, ... ok\ntest_no_exists_for_m2m_in_list_filter_without_params (admin_changelist.tests.ChangeListTests)\nIf a ManyToManyField is in list_filter but isn't in any lookup params, ... ok\ntest_no_list_display_links (admin_changelist.tests.ChangeListTests)\n#15185 -- Allow no links from the 'change list' view grid. ... ok\ntest_object_tools_displayed_no_add_permission (admin_changelist.tests.ChangeListTests)\nWhen ModelAdmin.has_add_permission() returns False, the object-tools ... ok\ntest_pagination (admin_changelist.tests.ChangeListTests)\nRegression tests for #12893: Pagination in admins changelist doesn't ... ok\ntest_pagination_page_range (admin_changelist.tests.ChangeListTests)\nRegression tests for ticket #15653: ensure the number of pages ... ok\ntest_pk_in_search_fields (admin_changelist.tests.ChangeListTests) ... ok\ntest_related_field_multiple_search_terms (admin_changelist.tests.ChangeListTests)\nSearches over multi-valued relationships return rows from related ... ok\ntest_repr (admin_changelist.tests.ChangeListTests) ... ok\ntest_result_list_editable (admin_changelist.tests.ChangeListTests)\nRegression test for #14312: list_editable with pagination ... ok\ntest_result_list_editable_html (admin_changelist.tests.ChangeListTests)\nRegression tests for #11791: Inclusion tag result_list generates a ... ok\ntest_result_list_empty_changelist_value (admin_changelist.tests.ChangeListTests)\nRegression test for #14982: EMPTY_CHANGELIST_VALUE should be honored ... ok\ntest_result_list_html (admin_changelist.tests.ChangeListTests)\nInclusion tag result_list generates a table when with default ... ok\ntest_result_list_set_empty_value_display_in_model_admin (admin_changelist.tests.ChangeListTests)\nEmpty value display can be set in ModelAdmin or individual fields. ... ok\ntest_result_list_set_empty_value_display_on_admin_site (admin_changelist.tests.ChangeListTests)\nEmpty value display can be set on AdminSite. ... ok\ntest_search_help_text (admin_changelist.tests.ChangeListTests) ... ok\ntest_select_related_as_empty_tuple (admin_changelist.tests.ChangeListTests) ... ok\ntest_select_related_as_tuple (admin_changelist.tests.ChangeListTests) ... ok\ntest_select_related_preserved (admin_changelist.tests.ChangeListTests)\nRegression test for #10348: ChangeList.get_queryset() shouldn't ... ok\ntest_select_related_preserved_when_multi_valued_in_search_fields (admin_changelist.tests.ChangeListTests) ... ok\ntest_show_all (admin_changelist.tests.ChangeListTests) ... ok\ntest_spanning_relations_with_custom_lookup_in_search_fields (admin_changelist.tests.ChangeListTests) ... ok\ntest_specified_ordering_by_f_expression (admin_changelist.tests.ChangeListTests) ... ok\ntest_specified_ordering_by_f_expression_without_asc_desc (admin_changelist.tests.ChangeListTests) ... ok\ntest_total_ordering_optimization (admin_changelist.tests.ChangeListTests) ... ok\ntest_total_ordering_optimization_meta_constraints (admin_changelist.tests.ChangeListTests) ... ok\ntest_tuple_list_display (admin_changelist.tests.ChangeListTests) ... ok\n\n----------------------------------------------------------------------\nRan 71 tests in 1.603s\n\nOK (skipped=7)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/admin_changelist/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-16116",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 36.70344924926758,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 139,
          "failed": 1,
          "errors": 0,
          "duration": 20.67,
          "log_tail": "test_makemigrations_unspecified_app_with_conflict_merge (migrations.test_commands.MakeMigrationsTests)\nmakemigrations does not create a merge for an unspecified app even if ... ok\ntest_makemigrations_unspecified_app_with_conflict_no_merge (migrations.test_commands.MakeMigrationsTests)\nmakemigrations does not raise a CommandError when an unspecified app ... ok\ntest_makemigrations_update (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_update_applied_migration (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_update_dependency_migration (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_update_existing_name (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_update_manual_porting (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_update_no_migration (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_update_squash_migration (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_with_custom_name (migrations.test_commands.MakeMigrationsTests)\nmakemigrations --name generate a custom migration name. ... ok\ntest_makemigrations_with_invalid_custom_name (migrations.test_commands.MakeMigrationsTests) ... ok\n\n======================================================================\nFAIL: test_makemigrations_check (migrations.test_commands.MakeMigrationsTests)\nmakemigrations --check should exit with a non-zero status when\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/tests/migrations/test_commands.py\", line 2397, in test_makemigrations_check\n    self.assertFalse(os.path.exists(tmpdir))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 682, in assertFalse\n    raise self.failureException(msg)\nAssertionError: True is not false\n\n----------------------------------------------------------------------\nRan 140 tests in 8.941s\n\nFAILED (failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 migrations.test_commands` failed. (See above for error)",
          "test_files_run": [
            "tests/migrations/test_commands.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 140,
          "failed": 0,
          "errors": 0,
          "duration": 14.97,
          "log_tail": "test_makemigrations_no_init (migrations.test_commands.MakeMigrationsTests)\nMigration directories without an __init__.py file are allowed. ... ok\ntest_makemigrations_non_interactive_auto_now_add_addition (migrations.test_commands.MakeMigrationsTests)\nNon-interactive makemigrations fails when a default is missing on a ... ok\ntest_makemigrations_non_interactive_no_field_rename (migrations.test_commands.MakeMigrationsTests)\nmakemigrations adds and removes a possible field rename in ... ok\ntest_makemigrations_non_interactive_no_model_rename (migrations.test_commands.MakeMigrationsTests)\nmakemigrations adds and removes a possible model rename in ... ok\ntest_makemigrations_non_interactive_not_null_addition (migrations.test_commands.MakeMigrationsTests)\nNon-interactive makemigrations fails when a default is missing on a ... ok\ntest_makemigrations_non_interactive_not_null_alteration (migrations.test_commands.MakeMigrationsTests)\nNon-interactive makemigrations fails when a default is missing on a ... ok\ntest_makemigrations_non_interactive_unique_callable_default_addition (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_order (migrations.test_commands.MakeMigrationsTests)\nmakemigrations should recognize number-only migrations (0001.py). ... ok\ntest_makemigrations_scriptable (migrations.test_commands.MakeMigrationsTests)\nWith scriptable=True, log output is diverted to stderr, and only the ... ok\ntest_makemigrations_scriptable_merge (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_unspecified_app_with_conflict_merge (migrations.test_commands.MakeMigrationsTests)\nmakemigrations does not create a merge for an unspecified app even if ... ok\ntest_makemigrations_unspecified_app_with_conflict_no_merge (migrations.test_commands.MakeMigrationsTests)\nmakemigrations does not raise a CommandError when an unspecified app ... ok\ntest_makemigrations_update (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_update_applied_migration (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_update_dependency_migration (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_update_existing_name (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_update_manual_porting (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_update_no_migration (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_update_squash_migration (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_with_custom_name (migrations.test_commands.MakeMigrationsTests)\nmakemigrations --name generate a custom migration name. ... ok\ntest_makemigrations_with_invalid_custom_name (migrations.test_commands.MakeMigrationsTests) ... ok\n\n----------------------------------------------------------------------\nRan 140 tests in 6.218s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/migrations/test_commands.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-16136",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 24.443825006484985,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 8,
          "failed": 1,
          "errors": 0,
          "duration": 11.8,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application async\nFound 9 test(s).\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_async_unsafe (async.tests.AsyncUnsafeTest) ... ok\ntest_async_unsafe_suppressed (async.tests.AsyncUnsafeTest)\nUtility class which turns an awaitable that only works on the thread with ... ok\ntest_caches_local (async.tests.CacheTest) ... ok\ntest_base_view_class_is_sync (async.tests.ViewTests)\nView and by extension any subclasses that don't define handlers are ... ok\ntest_http_method_not_allowed_responds_correctly (async.tests.ViewTests) ... test_mixed_views_raise_error (async.tests.ViewTests) ... ok\ntest_options_handler_responds_correctly (async.tests.ViewTests) ... ok\ntest_views_are_correctly_marked (async.tests.ViewTests) ... ok\ntest_get_async_connection (async.tests.DatabaseConnectionTest) ... ok\n\n======================================================================\nFAIL: test_http_method_not_allowed_responds_correctly (async.tests.ViewTests) [<object object at 0x71bb5b183970>] (view_cls=<class 'async.tests.AsyncView'>, is_coroutine=True)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 499, in subTest\n    yield\n  File \"/testbed/tests/async/tests.py\", line 132, in test_http_method_not_allowed_responds_correctly\n    self.assertIs(\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 1118, in assertIs\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 676, in fail\n    raise self.failureException(msg)\nAssertionError: False is not True\n\n----------------------------------------------------------------------\nRan 9 tests in 0.043s\n\nFAILED (failures=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 async.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/async/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 9,
          "failed": 0,
          "errors": 0,
          "duration": 11.46,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application async\nFound 9 test(s).\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_base_view_class_is_sync (async.tests.ViewTests)\nView and by extension any subclasses that don't define handlers are ... ok\ntest_http_method_not_allowed_responds_correctly (async.tests.ViewTests) ... ok\ntest_mixed_views_raise_error (async.tests.ViewTests) ... ok\ntest_options_handler_responds_correctly (async.tests.ViewTests) ... ok\ntest_views_are_correctly_marked (async.tests.ViewTests) ... ok\ntest_async_unsafe (async.tests.AsyncUnsafeTest) ... ok\ntest_async_unsafe_suppressed (async.tests.AsyncUnsafeTest)\nUtility class which turns an awaitable that only works on the thread with ... ok\ntest_caches_local (async.tests.CacheTest) ... ok\ntest_get_async_connection (async.tests.DatabaseConnectionTest) ... ok\n\n----------------------------------------------------------------------\nRan 9 tests in 0.046s\n\nOK\n",
          "test_files_run": [
            "tests/async/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-16139",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 24.99717402458191,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 86,
          "failed": 1,
          "errors": 0,
          "duration": 11.92,
          "log_tail": "test_bug_19349_bound_password_field (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_custom_form (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_link_to_password_reset_in_helptext_via_to_field (auth_tests.test_forms.UserChangeFormTest) ... FAIL\ntest_password_excluded (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_unusable_password (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_username_field_autocapitalize_none (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_username_validity (auth_tests.test_forms.UserChangeFormTest) ... ok\n\n======================================================================\nFAIL: test_link_to_password_reset_in_helptext_via_to_field (auth_tests.test_forms.UserChangeFormTest)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/django/test/utils.py\", line 460, in inner\n    return func(*args, **kwargs)\n  File \"/testbed/tests/auth_tests/test_forms.py\", line 915, in test_link_to_password_reset_in_helptext_via_to_field\n    self.assertEqual(joined_url, pw_change_url)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 837, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 1217, in assertMultiLineEqual\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 676, in fail\n    raise self.failureException(msg)\nAssertionError: '/admin/auth/user/testclient/password/' != '/admin/auth/user/1/password/'\n- /admin/auth/user/testclient/password/\n?                  ^^^^^^^^^^\n+ /admin/auth/user/1/password/\n?                  ^\n\n\n----------------------------------------------------------------------\nRan 87 tests in 0.206s\n\nFAILED (failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 auth_tests.test_forms` failed. (See above for error)",
          "test_files_run": [
            "tests/auth_tests/test_forms.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 87,
          "failed": 0,
          "errors": 0,
          "duration": 11.92,
          "log_tail": "test_username_field_max_length_matches_user_model (auth_tests.test_forms.AuthenticationFormTest) ... ok\ntest_cleaned_data (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_custom_email_constructor (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_custom_email_field (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_custom_email_subject (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_html_autocomplete_attributes (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_inactive_user (auth_tests.test_forms.PasswordResetFormTest)\nInactive user cannot receive password reset email. ... ok\ntest_invalid_email (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_nonexistent_email (auth_tests.test_forms.PasswordResetFormTest)\nTest nonexistent email address. This should not fail because it would ... ok\ntest_preserve_username_case (auth_tests.test_forms.PasswordResetFormTest)\nPreserve the case of the user name (before the @ in the email address) ... ok\ntest_save_html_email_template_name (auth_tests.test_forms.PasswordResetFormTest)\nTest the PasswordResetForm.save() method with html_email_template_name ... ok\ntest_save_plaintext_email (auth_tests.test_forms.PasswordResetFormTest)\nTest the PasswordResetForm.save() method with no html_email_template_name ... ok\ntest_unusable_password (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_user_email_domain_unicode_collision (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_user_email_domain_unicode_collision_nonexistent (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_user_email_unicode_collision (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_user_email_unicode_collision_nonexistent (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_bug_14242 (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_bug_17944_empty_password (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_bug_17944_unknown_password_algorithm (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_bug_17944_unmanageable_password (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_bug_19133 (auth_tests.test_forms.UserChangeFormTest)\nThe change form does not return the password value ... ok\ntest_bug_19349_bound_password_field (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_custom_form (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_link_to_password_reset_in_helptext_via_to_field (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_password_excluded (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_unusable_password (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_username_field_autocapitalize_none (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_username_validity (auth_tests.test_forms.UserChangeFormTest) ... ok\n\n----------------------------------------------------------------------\nRan 87 tests in 0.181s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/auth_tests/test_forms.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-16145",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 44.69684386253357,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 208,
          "failed": 1,
          "errors": 0,
          "duration": 26.46,
          "log_tail": "  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/mock.py\", line 1336, in patched\n    return func(*newargs, **newkeywargs)\n  File \"/testbed/tests/admin_scripts/tests.py\", line 1600, in test_zero_ip_addr\n    self.assertIn(\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 1104, in assertIn\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 676, in fail\n    raise self.failureException(msg)\nAssertionError: 'Starting development server at http://0.0.0.0:8000/' not found in \"August 10, 2025 - 01:12:51\\nDjango version 4.2.dev20221004081211, using settings 'test_sqlite'\\nStarting development server at http://0:8000/\\nQuit the server with CONTROL-C.\\n\"\n\n----------------------------------------------------------------------\nRan 209 tests in 14.687s\n\nFAILED (failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 admin_scripts.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/admin_scripts/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 209,
          "failed": 0,
          "errors": 0,
          "duration": 17.31,
          "log_tail": "test_no_escaping_of_project_variables (admin_scripts.tests.StartProject)\nMake sure template context variables are not html escaped ... ok\ntest_project_template_tarball_url (admin_scripts.tests.StartProject)\n\" ... ok\ntest_simple_project (admin_scripts.tests.StartProject)\nMake sure the startproject management command creates a project ... ok\ntest_simple_project_different_directory (admin_scripts.tests.StartProject)\nThe startproject management command creates a project in a specific ... ok\ntest_template_dir_with_trailing_slash (admin_scripts.tests.StartProject)\nTicket 17475: Template dir passed has a trailing path separator ... ok\ntest_wrong_args (admin_scripts.tests.StartProject)\nPassing the wrong kinds of arguments outputs an error and prints usage. ... ok\n\n----------------------------------------------------------------------\nRan 209 tests in 9.378s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/admin_scripts/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-16255",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 25.40061616897583,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 39,
          "failed": 0,
          "errors": 1,
          "duration": 12.96,
          "log_tail": "The Last-Modified header is set to the most recent sitemap lastmod. ... ok\ntest_sitemaps_lastmod_mixed_ascending_last_modified_missing (sitemaps_tests.test_http.HTTPSitemapTests)\nThe Last-Modified header is omitted when lastmod isn't found in all ... ok\ntest_sitemaps_lastmod_mixed_descending_last_modified_missing (sitemaps_tests.test_http.HTTPSitemapTests)\nThe Last-Modified header is omitted when lastmod isn't found in all ... ok\ntest_x_robots_sitemap (sitemaps_tests.test_http.HTTPSitemapTests) ... ok\n\n======================================================================\nERROR: test_callable_sitemod_no_items (sitemaps_tests.test_http.HTTPSitemapTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/tests/sitemaps_tests/test_http.py\", line 511, in test_callable_sitemod_no_items\n    index_response = self.client.get(\"/callable-lastmod-no-items/index.xml\")\n  File \"/testbed/django/test/client.py\", line 839, in get\n    response = super().get(path, data=data, secure=secure, **extra)\n  File \"/testbed/django/test/client.py\", line 427, in get\n    return self.generic(\n  File \"/testbed/django/test/client.py\", line 544, in generic\n    return self.request(**r)\n  File \"/testbed/django/test/client.py\", line 813, in request\n    self.check_exception(response)\n  File \"/testbed/django/test/client.py\", line 666, in check_exception\n    raise exc_value\n  File \"/testbed/django/core/handlers/exception.py\", line 55, in inner\n    response = get_response(request)\n  File \"/testbed/django/core/handlers/base.py\", line 197, in _get_response\n    response = wrapped_callback(request, *callback_args, **callback_kwargs)\n  File \"/testbed/django/contrib/sitemaps/views.py\", line 34, in inner\n    response = func(request, *args, **kwargs)\n  File \"/testbed/django/contrib/sitemaps/views.py\", line 76, in index\n    site_lastmod = site.get_latest_lastmod()\n  File \"/testbed/django/contrib/sitemaps/__init__.py\", line 170, in get_latest_lastmod\n    return max([self.lastmod(item) for item in self.items()])\nValueError: max() arg is an empty sequence\n\n----------------------------------------------------------------------\nRan 40 tests in 0.310s\n\nFAILED (errors=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 sitemaps_tests.test_http sitemaps_tests.urls.http` failed. (See above for error)",
          "test_files_run": [
            "tests/sitemaps_tests/test_http.py",
            "tests/sitemaps_tests/urls/http.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 40,
          "failed": 0,
          "errors": 0,
          "duration": 11.21,
          "log_tail": "A simple sitemap can be rendered ... ok\ntest_simple_sitemap_custom_lastmod_index (sitemaps_tests.test_http.HTTPSitemapTests)\nA simple sitemap index can be rendered with a custom template ... ok\ntest_simple_sitemap_index (sitemaps_tests.test_http.HTTPSitemapTests)\nA simple sitemap index can be rendered ... ok\ntest_simple_sitemap_section (sitemaps_tests.test_http.HTTPSitemapTests)\nA simple sitemap section can be rendered ... ok\ntest_sitemap_get_latest_lastmod (sitemaps_tests.test_http.HTTPSitemapTests)\nsitemapindex.lastmod is included when Sitemap.lastmod is ... ok\ntest_sitemap_get_latest_lastmod_none (sitemaps_tests.test_http.HTTPSitemapTests)\nsitemapindex.lastmod is omitted when Sitemap.lastmod is ... ok\ntest_sitemap_get_urls_no_site_1 (sitemaps_tests.test_http.HTTPSitemapTests)\nCheck we get ImproperlyConfigured if we don't pass a site object to ... ok\ntest_sitemap_get_urls_no_site_2 (sitemaps_tests.test_http.HTTPSitemapTests)\nCheck we get ImproperlyConfigured when we don't pass a site object to ... ok\ntest_sitemap_item (sitemaps_tests.test_http.HTTPSitemapTests)\nCheck to make sure that the raw item is included with each ... ok\ntest_sitemap_last_modified (sitemaps_tests.test_http.HTTPSitemapTests)\nLast-Modified header is set correctly ... ok\ntest_sitemap_last_modified_date (sitemaps_tests.test_http.HTTPSitemapTests)\nThe Last-Modified header should be support dates (without time). ... ok\ntest_sitemap_last_modified_missing (sitemaps_tests.test_http.HTTPSitemapTests)\nLast-Modified header is missing when sitemap has no lastmod ... ok\ntest_sitemap_last_modified_mixed (sitemaps_tests.test_http.HTTPSitemapTests)\nLast-Modified header is omitted when lastmod not on all items ... ok\ntest_sitemap_last_modified_tz (sitemaps_tests.test_http.HTTPSitemapTests)\nThe Last-Modified header should be converted from timezone aware dates ... ok\ntest_sitemap_latest_lastmod_timezone (sitemaps_tests.test_http.HTTPSitemapTests)\nlastmod datestamp shows timezones if Sitemap.get_latest_lastmod ... ok\ntest_sitemap_not_callable (sitemaps_tests.test_http.HTTPSitemapTests)\nA sitemap may not be callable. ... ok\ntest_sitemap_without_entries (sitemaps_tests.test_http.HTTPSitemapTests) ... ok\ntest_sitemaps_lastmod_ascending (sitemaps_tests.test_http.HTTPSitemapTests)\nThe Last-Modified header is set to the most recent sitemap lastmod. ... ok\ntest_sitemaps_lastmod_descending (sitemaps_tests.test_http.HTTPSitemapTests)\nThe Last-Modified header is set to the most recent sitemap lastmod. ... ok\ntest_sitemaps_lastmod_mixed_ascending_last_modified_missing (sitemaps_tests.test_http.HTTPSitemapTests)\nThe Last-Modified header is omitted when lastmod isn't found in all ... ok\ntest_sitemaps_lastmod_mixed_descending_last_modified_missing (sitemaps_tests.test_http.HTTPSitemapTests)\nThe Last-Modified header is omitted when lastmod isn't found in all ... ok\ntest_x_robots_sitemap (sitemaps_tests.test_http.HTTPSitemapTests) ... ok\n\n----------------------------------------------------------------------\nRan 40 tests in 0.163s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/sitemaps_tests/test_http.py",
            "tests/sitemaps_tests/urls/http.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-16256",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 25.697787046432495,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 55,
          "failed": 4,
          "errors": 5,
          "duration": 13.01,
          "log_tail": "    return self.__get_result()\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/concurrent/futures/_base.py\", line 391, in __get_result\n    raise self._exception\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/asgiref/sync.py\", line 331, in main_wrap\n    result = await self.awaitable(*args, **kwargs)\n  File \"/testbed/tests/async/test_async_related_managers.py\", line 43, in test_aupdate_or_create\n    self.assertEqual(await self.mtm1.simples.acount(), 1)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 837, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 830, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: 0 != 1\n\n======================================================================\nFAIL: test_aupdate_or_create_reverse (async.test_async_related_managers.AsyncRelatedManagersOperationTest)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/asgiref/sync.py\", line 254, in __call__\n    return call_result.result()\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/concurrent/futures/_base.py\", line 439, in result\n    return self.__get_result()\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/concurrent/futures/_base.py\", line 391, in __get_result\n    raise self._exception\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/asgiref/sync.py\", line 331, in main_wrap\n    result = await self.awaitable(*args, **kwargs)\n  File \"/testbed/tests/async/test_async_related_managers.py\", line 55, in test_aupdate_or_create_reverse\n    self.assertEqual(await self.s1.relatedmodel_set.acount(), 1)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 837, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 830, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: 0 != 1\n\n----------------------------------------------------------------------\nRan 64 tests in 0.384s\n\nFAILED (failures=4, errors=5)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 async.models async.test_async_related_managers generic_relations.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/async/models.py",
            "tests/async/test_async_related_managers.py",
            "tests/generic_relations/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 64,
          "failed": 0,
          "errors": 0,
          "duration": 11.48,
          "log_tail": "test_generic_relation_related_name_default (generic_relations.tests.GenericRelationsTests) ... ok\ntest_generic_relation_to_inherited_child (generic_relations.tests.GenericRelationsTests) ... ok\ntest_generic_relations_m2m_mimic (generic_relations.tests.GenericRelationsTests)\nObjects with declared GenericRelations can be tagged directly -- the ... ok\ntest_generic_update_or_create_when_created (generic_relations.tests.GenericRelationsTests)\nShould be able to use update_or_create from the generic related manager ... ok\ntest_generic_update_or_create_when_updated (generic_relations.tests.GenericRelationsTests)\nShould be able to use update_or_create from the generic related manager ... ok\ntest_get_or_create (generic_relations.tests.GenericRelationsTests) ... ok\ntest_gfk_manager (generic_relations.tests.GenericRelationsTests) ... ok\ntest_gfk_subclasses (generic_relations.tests.GenericRelationsTests) ... ok\ntest_multiple_gfk (generic_relations.tests.GenericRelationsTests) ... ok\ntest_object_deletion_with_generic_relation (generic_relations.tests.GenericRelationsTests)\nIf you delete an object with an explicit Generic relation, the related ... ok\ntest_object_deletion_without_generic_relation (generic_relations.tests.GenericRelationsTests)\nIf Generic Relation is not explicitly defined, any related objects ... ok\ntest_prefetch_related_custom_object_id (generic_relations.tests.GenericRelationsTests) ... ok\ntest_prefetch_related_different_content_types (generic_relations.tests.GenericRelationsTests) ... ok\ntest_queries_across_generic_relations (generic_relations.tests.GenericRelationsTests)\nQueries across generic relations respect the content types. Even though ... ok\ntest_queries_content_type_restriction (generic_relations.tests.GenericRelationsTests)\nCreate another fatty tagged instance with different PK to ensure there ... ok\ntest_query_content_object (generic_relations.tests.GenericRelationsTests) ... ok\ntest_query_content_type (generic_relations.tests.GenericRelationsTests) ... ok\ntest_remove (generic_relations.tests.GenericRelationsTests) ... ok\ntest_remove_after_prefetch (generic_relations.tests.GenericRelationsTests) ... ok\ntest_set (generic_relations.tests.GenericRelationsTests) ... ok\ntest_set_after_prefetch (generic_relations.tests.GenericRelationsTests) ... ok\ntest_set_foreign_key (generic_relations.tests.GenericRelationsTests)\nYou can set a generic foreign key in the way you'd expect. ... ok\ntest_subclasses_with_gen_rel (generic_relations.tests.GenericRelationsTests)\nConcrete model subclasses with generic relations work ... ok\ntest_subclasses_with_parent_gen_rel (generic_relations.tests.GenericRelationsTests)\nGeneric relations on a base class (Vegetable) work correctly in ... ok\ntest_tag_deletion_related_objects_unaffected (generic_relations.tests.GenericRelationsTests)\nIf you delete a tag, the objects using the tag are unaffected (other ... ok\ntest_unsaved_generic_foreign_key_parent_bulk_create (generic_relations.tests.GenericRelationsTests) ... ok\ntest_unsaved_generic_foreign_key_parent_save (generic_relations.tests.GenericRelationsTests) ... ok\ntest_update_or_create_defaults (generic_relations.tests.GenericRelationsTests) ... ok\n\n----------------------------------------------------------------------\nRan 64 tests in 0.268s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/async/models.py",
            "tests/async/test_async_related_managers.py",
            "tests/generic_relations/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-16263",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 24.812161922454834,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 100,
          "failed": 3,
          "errors": 0,
          "duration": 12.63,
          "log_tail": "    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 830, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: 2 != 1 : No subquery wrapping required\n\n======================================================================\nFAIL: test_unreferenced_aggregate_annotation_pruned (aggregation.tests.AggregateAnnotationPruningTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/tests/aggregation/tests.py\", line 2116, in test_unreferenced_aggregate_annotation_pruned\n    self.assertNotIn(\"authors_count\", sql)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 1111, in assertNotIn\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 676, in fail\n    raise self.failureException(msg)\nAssertionError: 'authors_count' unexpectedly found in 'select count(*) from (select count(\"aggregation_book_authors\".\"author_id\") as \"authors_count\" from \"aggregation_book\" left outer join \"aggregation_book_authors\" on (\"aggregation_book\".\"id\" = \"aggregation_book_authors\".\"book_id\") group by \"aggregation_book\".\"id\") subquery'\n\n======================================================================\nFAIL: test_unused_aliased_aggregate_pruned (aggregation.tests.AggregateAnnotationPruningTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/tests/aggregation/tests.py\", line 2097, in test_unused_aliased_aggregate_pruned\n    self.assertEqual(sql.count(\"select\"), 1, \"No subquery wrapping required\")\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 837, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 830, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: 2 != 1 : No subquery wrapping required\n\n----------------------------------------------------------------------\nRan 103 tests in 0.380s\n\nFAILED (failures=3)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 aggregation.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/aggregation/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 103,
          "failed": 0,
          "errors": 0,
          "duration": 11.03,
          "log_tail": "test_decimal_max_digits_has_no_effect (aggregation.tests.AggregateTestCase) ... ok\ntest_distinct_on_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_empty_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_empty_result_optimization (aggregation.tests.AggregateTestCase) ... ok\ntest_even_more_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_exists_extra_where_with_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_exists_none_with_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_expression_on_aggregation (aggregation.tests.AggregateTestCase) ... ok\ntest_filter_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_filter_in_subquery_or_aggregation (aggregation.tests.AggregateTestCase)\nFiltering against an aggregate requires the usage of the HAVING clause. ... ok\ntest_filtering (aggregation.tests.AggregateTestCase) ... ok\ntest_fkey_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_group_by_exists_annotation (aggregation.tests.AggregateTestCase)\nExists annotations are included in the GROUP BY if they are ... ok\ntest_group_by_subquery_annotation (aggregation.tests.AggregateTestCase)\nSubquery annotations are included in the GROUP BY if they are ... ok\ntest_grouped_annotation_in_group_by (aggregation.tests.AggregateTestCase)\nAn annotation included in values() before an aggregate should be ... ok\ntest_more_aggregation (aggregation.tests.AggregateTestCase) ... ok\ntest_multi_arg_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_multiple_aggregates (aggregation.tests.AggregateTestCase) ... ok\ntest_non_grouped_annotation_not_in_group_by (aggregation.tests.AggregateTestCase)\nAn annotation not included in values() before an aggregate should be ... ok\ntest_nonaggregate_aggregation_throws (aggregation.tests.AggregateTestCase) ... ok\ntest_nonfield_annotation (aggregation.tests.AggregateTestCase) ... ok\ntest_order_of_precedence (aggregation.tests.AggregateTestCase) ... ok\ntest_related_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_reverse_fkey_annotate (aggregation.tests.AggregateTestCase) ... ok\ntest_single_aggregate (aggregation.tests.AggregateTestCase) ... ok\ntest_sum_distinct_aggregate (aggregation.tests.AggregateTestCase)\nSum on a distinct() QuerySet should aggregate only the distinct items. ... ok\ntest_sum_duration_field (aggregation.tests.AggregateTestCase) ... ok\ntest_ticket11881 (aggregation.tests.AggregateTestCase)\nSubqueries do not needlessly contain ORDER BY, SELECT FOR UPDATE or ... ok\ntest_ticket12886 (aggregation.tests.AggregateTestCase)\nAggregation over sliced queryset works correctly. ... ok\ntest_ticket17424 (aggregation.tests.AggregateTestCase)\nDoing exclude() on a foreign model after annotate() doesn't crash. ... ok\ntest_values_aggregation (aggregation.tests.AggregateTestCase) ... ok\ntest_values_annotation_with_expression (aggregation.tests.AggregateTestCase) ... ok\n\n----------------------------------------------------------------------\nRan 103 tests in 0.231s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/aggregation/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-16315",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 24.95921778678894,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 50,
          "failed": 0,
          "errors": 1,
          "duration": 12.73,
          "log_tail": "Zero as id for AutoField should raise exception in MySQL, because MySQL ... skipped 'Database has feature(s) allows_auto_pk_0'\n\n======================================================================\nERROR: test_update_conflicts_unique_fields_update_fields_db_column (bulk_create.tests.BulkCreateTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/django/db/backends/utils.py\", line 89, in _execute\n    return self.cursor.execute(sql, params)\n  File \"/testbed/django/db/backends/sqlite3/base.py\", line 378, in execute\n    return super().execute(query, params)\nsqlite3.OperationalError: no such column: EXCLUDED.name\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/testbed/django/test/testcases.py\", line 1604, in skip_wrapper\n    return test_func(*args, **kwargs)\n  File \"/testbed/tests/bulk_create/tests.py\", line 793, in test_update_conflicts_unique_fields_update_fields_db_column\n    FieldsWithDbColumns.objects.bulk_create(\n  File \"/testbed/django/db/models/manager.py\", line 87, in manager_method\n    return getattr(self.get_queryset(), name)(*args, **kwargs)\n  File \"/testbed/django/db/models/query.py\", line 821, in bulk_create\n    returned_columns = self._batched_insert(\n  File \"/testbed/django/db/models/query.py\", line 1858, in _batched_insert\n    self._insert(\n  File \"/testbed/django/db/models/query.py\", line 1824, in _insert\n    return query.get_compiler(using=using).execute_sql(returning_fields)\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1778, in execute_sql\n    cursor.execute(sql, params)\n  File \"/testbed/django/db/backends/utils.py\", line 67, in execute\n    return self._execute_with_wrappers(\n  File \"/testbed/django/db/backends/utils.py\", line 80, in _execute_with_wrappers\n    return executor(sql, params, many, context)\n  File \"/testbed/django/db/backends/utils.py\", line 89, in _execute\n    return self.cursor.execute(sql, params)\n  File \"/testbed/django/db/utils.py\", line 91, in __exit__\n    raise dj_exc_value.with_traceback(traceback) from exc_value\n  File \"/testbed/django/db/backends/utils.py\", line 89, in _execute\n    return self.cursor.execute(sql, params)\n  File \"/testbed/django/db/backends/sqlite3/base.py\", line 378, in execute\n    return super().execute(query, params)\ndjango.db.utils.OperationalError: no such column: EXCLUDED.name\n\n----------------------------------------------------------------------\nRan 51 tests in 0.345s\n\nFAILED (errors=1, skipped=7)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 bulk_create.models bulk_create.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/bulk_create/models.py",
            "tests/bulk_create/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 51,
          "failed": 0,
          "errors": 0,
          "duration": 11.07,
          "log_tail": "test_large_batch (bulk_create.tests.BulkCreateTests) ... ok\ntest_large_batch_efficiency (bulk_create.tests.BulkCreateTests) ... ok\ntest_large_batch_mixed (bulk_create.tests.BulkCreateTests)\nTest inserting a large batch with objects having primary key set ... ok\ntest_large_batch_mixed_efficiency (bulk_create.tests.BulkCreateTests)\nTest inserting a large batch with objects having primary key set ... ok\ntest_large_single_field_batch (bulk_create.tests.BulkCreateTests) ... ok\ntest_long_and_short_text (bulk_create.tests.BulkCreateTests) ... ok\ntest_long_non_ascii_text (bulk_create.tests.BulkCreateTests)\nInserting non-ASCII values with a length in the range 2001 to 4000 ... ok\ntest_multi_table_inheritance_unsupported (bulk_create.tests.BulkCreateTests) ... ok\ntest_non_auto_increment_pk (bulk_create.tests.BulkCreateTests) ... ok\ntest_non_auto_increment_pk_efficiency (bulk_create.tests.BulkCreateTests) ... ok\ntest_nullable_fk_after_parent (bulk_create.tests.BulkCreateTests) ... ok\ntest_nullable_fk_after_parent_bulk_create (bulk_create.tests.BulkCreateTests) ... ok\ntest_proxy_inheritance_supported (bulk_create.tests.BulkCreateTests) ... ok\ntest_set_pk_and_insert_single_item (bulk_create.tests.BulkCreateTests) ... ok\ntest_set_pk_and_query_efficiency (bulk_create.tests.BulkCreateTests) ... ok\ntest_set_state (bulk_create.tests.BulkCreateTests) ... ok\ntest_set_state_with_pk_specified (bulk_create.tests.BulkCreateTests) ... ok\ntest_simple (bulk_create.tests.BulkCreateTests) ... ok\ntest_unsaved_parent (bulk_create.tests.BulkCreateTests) ... ok\ntest_update_conflicts_invalid_unique_fields (bulk_create.tests.BulkCreateTests) ... ok\ntest_update_conflicts_invalid_update_fields (bulk_create.tests.BulkCreateTests) ... ok\ntest_update_conflicts_no_unique_fields (bulk_create.tests.BulkCreateTests) ... skipped 'Database has feature(s) supports_update_conflicts_with_target'\ntest_update_conflicts_no_update_fields (bulk_create.tests.BulkCreateTests) ... ok\ntest_update_conflicts_nonexistent_update_fields (bulk_create.tests.BulkCreateTests) ... ok\ntest_update_conflicts_pk_in_update_fields (bulk_create.tests.BulkCreateTests) ... ok\ntest_update_conflicts_two_fields_no_unique_fields (bulk_create.tests.BulkCreateTests) ... skipped 'Database has feature(s) supports_update_conflicts_with_target'\ntest_update_conflicts_two_fields_unique_fields_both (bulk_create.tests.BulkCreateTests) ... ok\ntest_update_conflicts_two_fields_unique_fields_first (bulk_create.tests.BulkCreateTests) ... ok\ntest_update_conflicts_two_fields_unique_fields_second (bulk_create.tests.BulkCreateTests) ... ok\ntest_update_conflicts_unique_field_unsupported (bulk_create.tests.BulkCreateTests) ... skipped 'Database has feature(s) supports_update_conflicts_with_target'\ntest_update_conflicts_unique_fields (bulk_create.tests.BulkCreateTests) ... ok\ntest_update_conflicts_unique_fields_pk (bulk_create.tests.BulkCreateTests) ... ok\ntest_update_conflicts_unique_fields_required (bulk_create.tests.BulkCreateTests) ... ok\ntest_update_conflicts_unique_fields_update_fields_db_column (bulk_create.tests.BulkCreateTests) ... ok\ntest_update_conflicts_unique_two_fields_unique_fields_both (bulk_create.tests.BulkCreateTests) ... ok\ntest_update_conflicts_unique_two_fields_unique_fields_one (bulk_create.tests.BulkCreateTests) ... ok\ntest_update_conflicts_unique_two_fields_unique_no_unique_fields (bulk_create.tests.BulkCreateTests) ... skipped 'Database has feature(s) supports_update_conflicts_with_target'\ntest_update_conflicts_unsupported (bulk_create.tests.BulkCreateTests) ... skipped 'Database has feature(s) supports_update_conflicts'\ntest_zero_as_autoval (bulk_create.tests.BulkCreateTests)\nZero as id for AutoField should raise exception in MySQL, because MySQL ... skipped 'Database has feature(s) allows_auto_pk_0'\n\n----------------------------------------------------------------------\nRan 51 tests in 0.277s\n\nOK (skipped=7)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/bulk_create/models.py",
            "tests/bulk_create/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-16333",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 25.177719116210938,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 87,
          "failed": 1,
          "errors": 0,
          "duration": 12.54,
          "log_tail": "test_bug_19133 (auth_tests.test_forms.UserChangeFormTest)\nThe change form does not return the password value ... ok\ntest_bug_19349_bound_password_field (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_custom_form (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_link_to_password_reset_in_helptext_via_to_field (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_password_excluded (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_unusable_password (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_username_field_autocapitalize_none (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_username_validity (auth_tests.test_forms.UserChangeFormTest) ... ok\n\n======================================================================\nFAIL: test_custom_form_saves_many_to_many_field (auth_tests.test_forms.UserCreationFormTest)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/tests/auth_tests/test_forms.py\", line 273, in test_custom_form_saves_many_to_many_field\n    self.assertSequenceEqual(user.orgs.all(), [organization])\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 1025, in assertSequenceEqual\n    self.fail(msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 676, in fail\n    raise self.failureException(msg)\nAssertionError: Sequences differ: <QuerySet []> != [<Organization: Organization object (1)>]\n\nSecond sequence contains 1 additional elements.\nFirst extra element 0:\n<Organization: Organization object (1)>\n\n- <QuerySet []>\n+ [<Organization: Organization object (1)>]\n\n----------------------------------------------------------------------\nRan 88 tests in 0.258s\n\nFAILED (failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 auth_tests.test_forms` failed. (See above for error)",
          "test_files_run": [
            "tests/auth_tests/test_forms.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 88,
          "failed": 0,
          "errors": 0,
          "duration": 11.46,
          "log_tail": "test_username_field_max_length_matches_user_model (auth_tests.test_forms.AuthenticationFormTest) ... ok\ntest_cleaned_data (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_custom_email_constructor (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_custom_email_field (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_custom_email_subject (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_html_autocomplete_attributes (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_inactive_user (auth_tests.test_forms.PasswordResetFormTest)\nInactive user cannot receive password reset email. ... ok\ntest_invalid_email (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_nonexistent_email (auth_tests.test_forms.PasswordResetFormTest)\nTest nonexistent email address. This should not fail because it would ... ok\ntest_preserve_username_case (auth_tests.test_forms.PasswordResetFormTest)\nPreserve the case of the user name (before the @ in the email address) ... ok\ntest_save_html_email_template_name (auth_tests.test_forms.PasswordResetFormTest)\nTest the PasswordResetForm.save() method with html_email_template_name ... ok\ntest_save_plaintext_email (auth_tests.test_forms.PasswordResetFormTest)\nTest the PasswordResetForm.save() method with no html_email_template_name ... ok\ntest_unusable_password (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_user_email_domain_unicode_collision (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_user_email_domain_unicode_collision_nonexistent (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_user_email_unicode_collision (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_user_email_unicode_collision_nonexistent (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_bug_14242 (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_bug_17944_empty_password (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_bug_17944_unknown_password_algorithm (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_bug_17944_unmanageable_password (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_bug_19133 (auth_tests.test_forms.UserChangeFormTest)\nThe change form does not return the password value ... ok\ntest_bug_19349_bound_password_field (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_custom_form (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_link_to_password_reset_in_helptext_via_to_field (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_password_excluded (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_unusable_password (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_username_field_autocapitalize_none (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_username_validity (auth_tests.test_forms.UserChangeFormTest) ... ok\n\n----------------------------------------------------------------------\nRan 88 tests in 0.193s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/auth_tests/test_forms.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-16429",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 24.151331186294556,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 23,
          "failed": 0,
          "errors": 11,
          "duration": 11.15,
          "log_tail": "  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 499, in subTest\n    yield\n  File \"/testbed/tests/utils_tests/test_timesince.py\", line 205, in test_depth\n    self.assertEqual(timesince(self.t, value, depth=depth), expected)\n  File \"/testbed/django/utils/timesince.py\", line 103, in timesince\n    remaining_time = (now - pivot).total_seconds()\nTypeError: can't subtract offset-naive and offset-aware datetimes\n\n======================================================================\nERROR: test_other_units (utils_tests.test_timesince.TZAwareTimesinceTests)\nTest other units.\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/tests/utils_tests/test_timesince.py\", line 40, in test_other_units\n    self.assertEqual(timesince(self.t, self.t + self.onemonth), \"1\\xa0month\")\n  File \"/testbed/django/utils/timesince.py\", line 103, in timesince\n    remaining_time = (now - pivot).total_seconds()\nTypeError: can't subtract offset-naive and offset-aware datetimes\n\n======================================================================\nERROR: test_thousand_years_ago (utils_tests.test_timesince.TZAwareTimesinceTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/tests/utils_tests/test_timesince.py\", line 175, in test_thousand_years_ago\n    self.assertEqual(timesince(t, self.t), \"1000\\xa0years\")\n  File \"/testbed/django/utils/timesince.py\", line 103, in timesince\n    remaining_time = (now - pivot).total_seconds()\nTypeError: can't subtract offset-naive and offset-aware datetimes\n\n----------------------------------------------------------------------\nRan 34 tests in 0.077s\n\nFAILED (errors=11)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 utils_tests.test_timesince` failed. (See above for error)",
          "test_files_run": [
            "tests/utils_tests/test_timesince.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 34,
          "failed": 0,
          "errors": 0,
          "duration": 10.84,
          "log_tail": "When the second date occurs before the first, we should always ... ok\ntest_equal_datetimes (utils_tests.test_timesince.TZAwareTimesinceTests)\nequal datetimes. ... ok\ntest_ignore_microseconds_and_seconds (utils_tests.test_timesince.TZAwareTimesinceTests)\nMicroseconds and seconds are ignored. ... ok\ntest_leap_year (utils_tests.test_timesince.TZAwareTimesinceTests) ... ok\ntest_leap_year_new_years_eve (utils_tests.test_timesince.TZAwareTimesinceTests) ... ok\ntest_months_edge (utils_tests.test_timesince.TZAwareTimesinceTests) ... ok\ntest_multiple_units (utils_tests.test_timesince.TZAwareTimesinceTests)\nTest multiple units. ... ok\ntest_naive_datetime_with_tzinfo_attribute (utils_tests.test_timesince.TZAwareTimesinceTests) ... ok\ntest_other_units (utils_tests.test_timesince.TZAwareTimesinceTests)\nTest other units. ... ok\ntest_second_before_equal_first_humanize_time_strings (utils_tests.test_timesince.TZAwareTimesinceTests) ... ok\ntest_thousand_years_ago (utils_tests.test_timesince.TZAwareTimesinceTests) ... ok\ntest_both_date_objects (utils_tests.test_timesince.TimesinceTests)\nTimesince should work with both date objects (#9672) ... ok\ntest_date_objects (utils_tests.test_timesince.TimesinceTests)\nBoth timesince and timeuntil should work on date objects (#17937). ... ok\ntest_depth (utils_tests.test_timesince.TimesinceTests) ... ok\ntest_depth_invalid (utils_tests.test_timesince.TimesinceTests) ... ok\ntest_different_timezones (utils_tests.test_timesince.TimesinceTests)\nWhen using two different timezones. ... ok\ntest_display_first_unit (utils_tests.test_timesince.TimesinceTests)\nIf the two differing units aren't adjacent, only the first unit is ... ok\ntest_display_second_before_first (utils_tests.test_timesince.TimesinceTests)\nWhen the second date occurs before the first, we should always ... ok\ntest_equal_datetimes (utils_tests.test_timesince.TimesinceTests)\nequal datetimes. ... ok\ntest_ignore_microseconds_and_seconds (utils_tests.test_timesince.TimesinceTests)\nMicroseconds and seconds are ignored. ... ok\ntest_leap_year (utils_tests.test_timesince.TimesinceTests) ... ok\ntest_leap_year_new_years_eve (utils_tests.test_timesince.TimesinceTests) ... ok\ntest_months_edge (utils_tests.test_timesince.TimesinceTests) ... ok\ntest_multiple_units (utils_tests.test_timesince.TimesinceTests)\nTest multiple units. ... ok\ntest_naive_datetime_with_tzinfo_attribute (utils_tests.test_timesince.TimesinceTests) ... ok\ntest_other_units (utils_tests.test_timesince.TimesinceTests)\nTest other units. ... ok\ntest_second_before_equal_first_humanize_time_strings (utils_tests.test_timesince.TimesinceTests) ... ok\ntest_thousand_years_ago (utils_tests.test_timesince.TimesinceTests) ... ok\n\n----------------------------------------------------------------------\nRan 34 tests in 0.036s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/utils_tests/test_timesince.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-16454",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 20.75862693786621,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 45,
          "failed": 1,
          "errors": 0,
          "duration": 8.91,
          "log_tail": "When the Command handle method is decorated with @no_translations, ... ok\ntest_output_transaction (user_commands.tests.CommandTests.test_output_transaction) ... ok\ntest_outputwrapper_flush (user_commands.tests.CommandTests.test_outputwrapper_flush) ... ok\ntest_required_const_options (user_commands.tests.CommandTests.test_required_const_options) ... ok\ntest_required_list_option (user_commands.tests.CommandTests.test_required_list_option) ... ok\ntest_requires_system_checks_empty (user_commands.tests.CommandTests.test_requires_system_checks_empty) ... ok\ntest_requires_system_checks_invalid (user_commands.tests.CommandTests.test_requires_system_checks_invalid) ... ok\ntest_requires_system_checks_specific (user_commands.tests.CommandTests.test_requires_system_checks_specific) ... ok\ntest_subparser (user_commands.tests.CommandTests.test_subparser) ... ok\ntest_subparser_dest_args (user_commands.tests.CommandTests.test_subparser_dest_args) ... ok\ntest_subparser_dest_required_args (user_commands.tests.CommandTests.test_subparser_dest_required_args) ... ok\ntest_subparser_invalid_option (user_commands.tests.CommandTests.test_subparser_invalid_option) ... ok\ntest_system_exit (user_commands.tests.CommandTests.test_system_exit)\nException raised in a command should raise CommandError with ... ok\ntest_disallowed_abbreviated_options (user_commands.tests.CommandRunTests.test_disallowed_abbreviated_options)\nTo avoid conflicts with custom options, commands don't allow ... ok\ntest_script_prefix_set_in_commands (user_commands.tests.CommandRunTests.test_script_prefix_set_in_commands) ... ok\ntest_skip_checks (user_commands.tests.CommandRunTests.test_skip_checks) ... ok\ntest_subparser_error_formatting (user_commands.tests.CommandRunTests.test_subparser_error_formatting) ... FAIL\ntest_subparser_non_django_error_formatting (user_commands.tests.CommandRunTests.test_subparser_non_django_error_formatting) ... ok\n\n======================================================================\nFAIL: test_subparser_error_formatting (user_commands.tests.CommandRunTests.test_subparser_error_formatting)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 57, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 623, in run\n    self._callTestMethod(testMethod)\n    ^^^^^^^^^^^^^^^^^\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 579, in _callTestMethod\n    if method() is not None:\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/tests/user_commands/tests.py\", line 477, in test_subparser_error_formatting\n    self.assertEqual(len(err_lines), 2)\n    ^^^^^^^^^^^^^^^^^\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 873, in assertEqual\n    assertion_func(first, second, msg=msg)\n    ^^^^^^^^^^^^^^^^^\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 866, in _baseAssertEqual\n    raise self.failureException(msg)\n    ^^^^^^^^^^^^^^^^^\nAssertionError: 65 != 2\n\n----------------------------------------------------------------------\nRan 46 tests in 1.414s\n\nFAILED (failures=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 user_commands.management.commands.subparser_vanilla user_commands.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/user_commands/management/commands/subparser_vanilla.py",
            "tests/user_commands/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 46,
          "failed": 0,
          "errors": 0,
          "duration": 9.71,
          "log_tail": "test_call_command_with_required_parameters_in_mixed_options (user_commands.tests.CommandTests.test_call_command_with_required_parameters_in_mixed_options) ... ok\ntest_call_command_with_required_parameters_in_options (user_commands.tests.CommandTests.test_call_command_with_required_parameters_in_options) ... ok\ntest_calling_a_command_with_no_app_labels_and_parameters_raise_command_error (user_commands.tests.CommandTests.test_calling_a_command_with_no_app_labels_and_parameters_raise_command_error) ... ok\ntest_calling_a_command_with_only_empty_parameter_should_ends_gracefully (user_commands.tests.CommandTests.test_calling_a_command_with_only_empty_parameter_should_ends_gracefully) ... ok\ntest_calling_command_with_app_labels_and_parameters_should_be_ok (user_commands.tests.CommandTests.test_calling_command_with_app_labels_and_parameters_should_be_ok) ... ok\ntest_calling_command_with_parameters_and_app_labels_at_the_end_should_be_ok (user_commands.tests.CommandTests.test_calling_command_with_parameters_and_app_labels_at_the_end_should_be_ok) ... ok\ntest_check_migrations (user_commands.tests.CommandTests.test_check_migrations) ... ok\ntest_command (user_commands.tests.CommandTests.test_command) ... ok\ntest_command_add_arguments_after_common_arguments (user_commands.tests.CommandTests.test_command_add_arguments_after_common_arguments) ... ok\ntest_command_style (user_commands.tests.CommandTests.test_command_style) ... ok\ntest_create_parser_kwargs (user_commands.tests.CommandTests.test_create_parser_kwargs)\nBaseCommand.create_parser() passes kwargs to CommandParser. ... ok\ntest_discover_commands_in_eggs (user_commands.tests.CommandTests.test_discover_commands_in_eggs)\nManagement commands can also be loaded from Python eggs. ... ok\ntest_explode (user_commands.tests.CommandTests.test_explode)\nAn unknown command raises CommandError ... ok\ntest_find_command_without_PATH (user_commands.tests.CommandTests.test_find_command_without_PATH)\nfind_command should still work when the PATH environment variable ... ok\ntest_language_preserved (user_commands.tests.CommandTests.test_language_preserved) ... ok\ntest_mutually_exclusive_group_required_const_options (user_commands.tests.CommandTests.test_mutually_exclusive_group_required_const_options) ... ok\ntest_mutually_exclusive_group_required_options (user_commands.tests.CommandTests.test_mutually_exclusive_group_required_options) ... ok\ntest_mutually_exclusive_group_required_with_same_dest_args (user_commands.tests.CommandTests.test_mutually_exclusive_group_required_with_same_dest_args) ... ok\ntest_mutually_exclusive_group_required_with_same_dest_options (user_commands.tests.CommandTests.test_mutually_exclusive_group_required_with_same_dest_options) ... ok\ntest_no_translations_deactivate_translations (user_commands.tests.CommandTests.test_no_translations_deactivate_translations)\nWhen the Command handle method is decorated with @no_translations, ... ok\ntest_output_transaction (user_commands.tests.CommandTests.test_output_transaction) ... ok\ntest_outputwrapper_flush (user_commands.tests.CommandTests.test_outputwrapper_flush) ... ok\ntest_required_const_options (user_commands.tests.CommandTests.test_required_const_options) ... ok\ntest_required_list_option (user_commands.tests.CommandTests.test_required_list_option) ... ok\ntest_requires_system_checks_empty (user_commands.tests.CommandTests.test_requires_system_checks_empty) ... ok\ntest_requires_system_checks_invalid (user_commands.tests.CommandTests.test_requires_system_checks_invalid) ... ok\ntest_requires_system_checks_specific (user_commands.tests.CommandTests.test_requires_system_checks_specific) ... ok\ntest_subparser (user_commands.tests.CommandTests.test_subparser) ... ok\ntest_subparser_dest_args (user_commands.tests.CommandTests.test_subparser_dest_args) ... ok\ntest_subparser_dest_required_args (user_commands.tests.CommandTests.test_subparser_dest_required_args) ... ok\ntest_subparser_invalid_option (user_commands.tests.CommandTests.test_subparser_invalid_option) ... ok\ntest_system_exit (user_commands.tests.CommandTests.test_system_exit)\nException raised in a command should raise CommandError with ... ok\ntest_disallowed_abbreviated_options (user_commands.tests.CommandRunTests.test_disallowed_abbreviated_options)\nTo avoid conflicts with custom options, commands don't allow ... ok\ntest_script_prefix_set_in_commands (user_commands.tests.CommandRunTests.test_script_prefix_set_in_commands) ... ok\ntest_skip_checks (user_commands.tests.CommandRunTests.test_skip_checks) ... ok\ntest_subparser_error_formatting (user_commands.tests.CommandRunTests.test_subparser_error_formatting) ... ok\ntest_subparser_non_django_error_formatting (user_commands.tests.CommandRunTests.test_subparser_non_django_error_formatting) ... ok\n\n----------------------------------------------------------------------\nRan 46 tests in 1.800s\n\nOK\n",
          "test_files_run": [
            "tests/user_commands/management/commands/subparser_vanilla.py",
            "tests/user_commands/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-16485",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 17.02080988883972,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 9,
          "failed": 0,
          "errors": 1,
          "duration": 7.99,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application template_tests\nFound 10 test(s).\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_floatformat01 (template_tests.filter_tests.test_floatformat.FloatformatTests.test_floatformat01) ... ok\ntest_floatformat02 (template_tests.filter_tests.test_floatformat.FloatformatTests.test_floatformat02) ... ok\ntest_float_dunder_method (template_tests.filter_tests.test_floatformat.FunctionTests.test_float_dunder_method) ... ok\ntest_force_grouping (template_tests.filter_tests.test_floatformat.FunctionTests.test_force_grouping) ... ok\ntest_infinity (template_tests.filter_tests.test_floatformat.FunctionTests.test_infinity) ... ok\ntest_inputs (template_tests.filter_tests.test_floatformat.FunctionTests.test_inputs) ... ok\ntest_low_decimal_precision (template_tests.filter_tests.test_floatformat.FunctionTests.test_low_decimal_precision)\n#15789 ... ok\ntest_negative_zero_values (template_tests.filter_tests.test_floatformat.FunctionTests.test_negative_zero_values) ... ok\ntest_unlocalize (template_tests.filter_tests.test_floatformat.FunctionTests.test_unlocalize) ... ok\ntest_zero_values (template_tests.filter_tests.test_floatformat.FunctionTests.test_zero_values) ... ERROR\n\n======================================================================\nERROR: test_zero_values (template_tests.filter_tests.test_floatformat.FunctionTests.test_zero_values)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 57, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 623, in run\n    self._callTestMethod(testMethod)\n    ^^^^^^^^^^^^^^^^^\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 579, in _callTestMethod\n    if method() is not None:\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/tests/template_tests/filter_tests/test_floatformat.py\", line 114, in test_zero_values\n    self.assertEqual(floatformat(\"0.00\", 0), \"0\")\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/template/defaultfilters.py\", line 190, in floatformat\n    rounded_d = d.quantize(exp, ROUND_HALF_UP, Context(prec=prec))\n      ^^^^^^^^^^^^^^^^^\nValueError: valid range for prec is [1, MAX_PREC]\n\n----------------------------------------------------------------------\nRan 10 tests in 0.071s\n\nFAILED (errors=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 template_tests.filter_tests.test_floatformat` failed. (See above for error)",
          "test_files_run": [
            "tests/template_tests/filter_tests/test_floatformat.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 10,
          "failed": 0,
          "errors": 0,
          "duration": 7.88,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application template_tests\nFound 10 test(s).\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_floatformat01 (template_tests.filter_tests.test_floatformat.FloatformatTests.test_floatformat01) ... ok\ntest_floatformat02 (template_tests.filter_tests.test_floatformat.FloatformatTests.test_floatformat02) ... ok\ntest_float_dunder_method (template_tests.filter_tests.test_floatformat.FunctionTests.test_float_dunder_method) ... ok\ntest_force_grouping (template_tests.filter_tests.test_floatformat.FunctionTests.test_force_grouping) ... ok\ntest_infinity (template_tests.filter_tests.test_floatformat.FunctionTests.test_infinity) ... ok\ntest_inputs (template_tests.filter_tests.test_floatformat.FunctionTests.test_inputs) ... ok\ntest_low_decimal_precision (template_tests.filter_tests.test_floatformat.FunctionTests.test_low_decimal_precision)\n#15789 ... ok\ntest_negative_zero_values (template_tests.filter_tests.test_floatformat.FunctionTests.test_negative_zero_values) ... ok\ntest_unlocalize (template_tests.filter_tests.test_floatformat.FunctionTests.test_unlocalize) ... ok\ntest_zero_values (template_tests.filter_tests.test_floatformat.FunctionTests.test_zero_values) ... ok\n\n----------------------------------------------------------------------\nRan 10 tests in 0.265s\n\nOK\n",
          "test_files_run": [
            "tests/template_tests/filter_tests/test_floatformat.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-16493",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 19.83444094657898,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 148,
          "failed": 0,
          "errors": 1,
          "duration": 9.67,
          "log_tail": "test_remove_race_handling (file_storage.tests.OverwritingStorageTests.test_remove_race_handling)\nFile storage should be robust against file removal race conditions. ... ok\ntest_save_doesnt_close (file_storage.tests.OverwritingStorageTests.test_save_doesnt_close) ... ok\ntest_save_overwrite_behavior (file_storage.tests.OverwritingStorageTests.test_save_overwrite_behavior)\nSaving to same file name twice overwrites the first file. ... ok\ntest_setting_changed (file_storage.tests.OverwritingStorageTests.test_setting_changed)\nProperties using settings values as defaults should be updated on ... ok\ntest_urllib_request_urlopen (file_storage.tests.FileLikeObjectTestCase.test_urllib_request_urlopen)\nTest the File storage API with a file-like object coming from ... ok\ntest_race_condition (file_storage.tests.FileSaveRaceConditionTest.test_race_condition) ... ok\n\n======================================================================\nERROR: test_deconstruction_storage_callable_default (file_storage.tests.FieldCallableFileStorageTests.test_deconstruction_storage_callable_default)\nA callable that returns default_storage is not omitted when\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 57, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 623, in run\n    self._callTestMethod(testMethod)\n    ^^^^^^^^^^^^^^^^^\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 579, in _callTestMethod\n    if method() is not None:\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/tests/file_storage/tests.py\", line 1034, in test_deconstruction_storage_callable_default\n    self.assertIs(kwargs[\"storage\"], callable_default_storage)\n    ^^^^^^^^^^^^^^^^^\nKeyError: 'storage'\n\n----------------------------------------------------------------------\nRan 149 tests in 1.098s\n\nFAILED (errors=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 file_storage.models file_storage.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/file_storage/models.py",
            "tests/file_storage/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 149,
          "failed": 0,
          "errors": 0,
          "duration": 8.87,
          "log_tail": "test_file_get_modified_time_timezone (file_storage.tests.FileStorageTests.test_file_get_modified_time_timezone) ... ok\ntest_file_methods_pathlib_path (file_storage.tests.FileStorageTests.test_file_methods_pathlib_path) ... ok\ntest_file_path (file_storage.tests.FileStorageTests.test_file_path)\nFile storage returns the full path of a file ... ok\ntest_file_save_abs_path (file_storage.tests.FileStorageTests.test_file_save_abs_path) ... ok\ntest_file_save_broken_symlink (file_storage.tests.FileStorageTests.test_file_save_broken_symlink)\nA new path is created on save when a broken symlink is supplied. ... ok\ntest_file_save_with_path (file_storage.tests.FileStorageTests.test_file_save_with_path)\nSaving a pathname should create intermediate directories as necessary. ... ok\ntest_file_save_without_name (file_storage.tests.FileStorageTests.test_file_save_without_name)\nFile storage extracts the filename from the content object if no ... ok\ntest_file_storage_preserves_filename_case (file_storage.tests.FileStorageTests.test_file_storage_preserves_filename_case)\nThe storage backend should preserve case of filenames. ... ok\ntest_file_storage_prevents_directory_traversal (file_storage.tests.FileStorageTests.test_file_storage_prevents_directory_traversal)\nFile storage prevents directory traversal (files can only be accessed if ... ok\ntest_file_url (file_storage.tests.FileStorageTests.test_file_url)\nFile storage returns a url to access a given file from the web. ... ok\ntest_listdir (file_storage.tests.FileStorageTests.test_listdir)\nFile storage returns a tuple containing directories and files. ... ok\ntest_makedirs_race_handling (file_storage.tests.FileStorageTests.test_makedirs_race_handling)\nFile storage should be robust against directory creation race conditions. ... ok\ntest_remove_race_handling (file_storage.tests.FileStorageTests.test_remove_race_handling)\nFile storage should be robust against file removal race conditions. ... ok\ntest_save_doesnt_close (file_storage.tests.FileStorageTests.test_save_doesnt_close) ... ok\ntest_setting_changed (file_storage.tests.FileStorageTests.test_setting_changed)\nProperties using settings values as defaults should be updated on ... ok\ntest_urllib_request_urlopen (file_storage.tests.FileLikeObjectTestCase.test_urllib_request_urlopen)\nTest the File storage API with a file-like object coming from ... ok\ntest_race_condition (file_storage.tests.FileSaveRaceConditionTest.test_race_condition) ... ok\n\n----------------------------------------------------------------------\nRan 149 tests in 1.069s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/file_storage/models.py",
            "tests/file_storage/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-16502",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 17.505455255508423,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 4,
          "failed": 1,
          "errors": 0,
          "duration": 8.01,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application servers\nFound 5 test(s).\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_broken_pipe_errors (servers.test_basehttp.WSGIServerTestCase.test_broken_pipe_errors)\nWSGIServer handles broken pipe errors. ... ok\ntest_https (servers.test_basehttp.WSGIRequestHandlerTestCase.test_https) ... ok\ntest_log_message (servers.test_basehttp.WSGIRequestHandlerTestCase.test_log_message) ... ok\ntest_no_body_returned_for_head_requests (servers.test_basehttp.WSGIRequestHandlerTestCase.test_no_body_returned_for_head_requests) ... FAIL\ntest_strips_underscore_headers (servers.test_basehttp.WSGIRequestHandlerTestCase.test_strips_underscore_headers)\nWSGIRequestHandler ignores headers containing underscores. ... ok\n\n======================================================================\nFAIL: test_no_body_returned_for_head_requests (servers.test_basehttp.WSGIRequestHandlerTestCase.test_no_body_returned_for_head_requests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 57, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 623, in run\n    self._callTestMethod(testMethod)\n    ^^^^^^^^^^^^^^^^^\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 579, in _callTestMethod\n    if method() is not None:\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/tests/servers/test_basehttp.py\", line 158, in test_no_body_returned_for_head_requests\n    self.assertEqual(body, b\"\\r\\n\")\n    ^^^^^^^^^^^^^^^^^\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 873, in assertEqual\n    assertion_func(first, second, msg=msg)\n    ^^^^^^^^^^^^^^^^^\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 866, in _baseAssertEqual\n    raise self.failureException(msg)\n    ^^^^^^^^^^^^^^^^^\nAssertionError: b'<!DOCTYPE html><html><body>Hello World</body></html>' != b'\\r\\n'\n\n----------------------------------------------------------------------\nRan 5 tests in 0.050s\n\nFAILED (failures=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 servers.test_basehttp` failed. (See above for error)",
          "test_files_run": [
            "tests/servers/test_basehttp.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 5,
          "failed": 0,
          "errors": 0,
          "duration": 8.3,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application servers\nFound 5 test(s).\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_broken_pipe_errors (servers.test_basehttp.WSGIServerTestCase.test_broken_pipe_errors)\nWSGIServer handles broken pipe errors. ... ok\ntest_https (servers.test_basehttp.WSGIRequestHandlerTestCase.test_https) ... ok\ntest_log_message (servers.test_basehttp.WSGIRequestHandlerTestCase.test_log_message) ... ok\ntest_no_body_returned_for_head_requests (servers.test_basehttp.WSGIRequestHandlerTestCase.test_no_body_returned_for_head_requests) ... ok\ntest_strips_underscore_headers (servers.test_basehttp.WSGIRequestHandlerTestCase.test_strips_underscore_headers)\nWSGIRequestHandler ignores headers containing underscores. ... ok\n\n----------------------------------------------------------------------\nRan 5 tests in 0.033s\n\nOK\n",
          "test_files_run": [
            "tests/servers/test_basehttp.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-16527",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 20.0871639251709,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 6,
          "failed": 1,
          "errors": 0,
          "duration": 9.9,
          "log_tail": "  Applying sites.0002_alter_domain_unique... OK\nSystem check identified no issues (1 silenced).\n\n\nCreating test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\ntest_choice_links (admin_views.test_templatetags.DateHierarchyTests.test_choice_links) ... ok\ntest_choice_links_datetime (admin_views.test_templatetags.DateHierarchyTests.test_choice_links_datetime) ... ok\ntest_override_change_form_template_tags (admin_views.test_templatetags.AdminTemplateTagsTest.test_override_change_form_template_tags)\nadmin_modify template tags follow the standard search pattern ... ok\ntest_override_change_list_template_tags (admin_views.test_templatetags.AdminTemplateTagsTest.test_override_change_list_template_tags)\nadmin_list template tags follow the standard search pattern ... ok\ntest_override_show_save_and_add_another (admin_views.test_templatetags.AdminTemplateTagsTest.test_override_show_save_and_add_another) ... ok\ntest_submit_row (admin_views.test_templatetags.AdminTemplateTagsTest.test_submit_row)\nsubmit_row template tag should pass whole context. ... ok\ntest_submit_row_save_as_new_add_permission_required (admin_views.test_templatetags.AdminTemplateTagsTest.test_submit_row_save_as_new_add_permission_required) ... FAIL\n\n======================================================================\nFAIL: test_submit_row_save_as_new_add_permission_required (admin_views.test_templatetags.AdminTemplateTagsTest.test_submit_row_save_as_new_add_permission_required)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 57, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 623, in run\n    self._callTestMethod(testMethod)\n    ^^^^^^^^^^^^^^^^^\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 579, in _callTestMethod\n    if method() is not None:\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/tests/admin_views/test_templatetags.py\", line 52, in test_submit_row_save_as_new_add_permission_required\n    self.assertIs(template_context[\"show_save_as_new\"], False)\n    ^^^^^^^^^^^^^^^^^\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 1154, in assertIs\n    self.fail(self._formatMessage(msg, standardMsg))\n    ^^^^^^^^^^^^^^^^^\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 703, in fail\n    raise self.failureException(msg)\n    ^^^^^^^^^^^^^^^^^\nAssertionError: True is not False\n\n----------------------------------------------------------------------\nRan 7 tests in 1.003s\n\nFAILED (failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 admin_views.test_templatetags` failed. (See above for error)",
          "test_files_run": [
            "tests/admin_views/test_templatetags.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 7,
          "failed": 0,
          "errors": 0,
          "duration": 8.95,
          "log_tail": "    Creating table admin_views_inlinereference\n    Creating table admin_views_recipe\n    Creating table admin_views_ingredient\n    Creating table admin_views_recipeingredient\n    Creating table admin_views_notreferenced\n    Creating table admin_views_explicitlyprovidedpk\n    Creating table admin_views_implicitlygeneratedpk\n    Creating table admin_views_referencedbygenrel\n    Creating table admin_views_genrelreference\n    Creating table admin_views_parentwithuuidpk\n    Creating table admin_views_relatedwithuuidpkmodel\n    Creating table admin_views_author\n    Creating table admin_views_authorship\n    Creating table admin_views_readonlyrelatedfield\n    Creating table admin_views_h\u00e9llo\n    Creating table admin_views_box\n    Creating table admin_views_country\n    Creating table admin_views_traveler\n    Running deferred SQL...\nRunning migrations:\n  Applying admin.0001_initial... OK\n  Applying admin.0002_logentry_remove_auto_add... OK\n  Applying admin.0003_logentry_add_action_flag_choices... OK\n  Applying sites.0001_initial... OK\n  Applying sites.0002_alter_domain_unique... OK\nSystem check identified no issues (1 silenced).\n\n\nCreating test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\ntest_choice_links (admin_views.test_templatetags.DateHierarchyTests.test_choice_links) ... ok\ntest_choice_links_datetime (admin_views.test_templatetags.DateHierarchyTests.test_choice_links_datetime) ... ok\ntest_override_change_form_template_tags (admin_views.test_templatetags.AdminTemplateTagsTest.test_override_change_form_template_tags)\nadmin_modify template tags follow the standard search pattern ... ok\ntest_override_change_list_template_tags (admin_views.test_templatetags.AdminTemplateTagsTest.test_override_change_list_template_tags)\nadmin_list template tags follow the standard search pattern ... ok\ntest_override_show_save_and_add_another (admin_views.test_templatetags.AdminTemplateTagsTest.test_override_show_save_and_add_another) ... ok\ntest_submit_row (admin_views.test_templatetags.AdminTemplateTagsTest.test_submit_row)\nsubmit_row template tag should pass whole context. ... ok\ntest_submit_row_save_as_new_add_permission_required (admin_views.test_templatetags.AdminTemplateTagsTest.test_submit_row_save_as_new_add_permission_required) ... ok\n\n----------------------------------------------------------------------\nRan 7 tests in 0.898s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/admin_views/test_templatetags.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-16560",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 16.430458068847656,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 120,
          "failed": 1,
          "errors": 7,
          "duration": 7.4,
          "log_tail": "    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 623, in run\n    self._callTestMethod(testMethod)\n    ^^^^^^^^^^^^^^^^^\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 579, in _callTestMethod\n    if method() is not None:\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/tests/constraints/tests.py\", line 590, in test_repr_with_violation_error_code\n    constraint = models.UniqueConstraint(\n    ^^^^^^^^^^^^^^^^^\nTypeError: UniqueConstraint.__init__() got an unexpected keyword argument 'violation_error_code'\n\n======================================================================\nFAIL: test_validate_conditon_custom_error (constraints.tests.UniqueConstraintTests.test_validate_conditon_custom_error)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 57, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 623, in run\n    self._callTestMethod(testMethod)\n    ^^^^^^^^^^^^^^^^^\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 579, in _callTestMethod\n    if method() is not None:\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/test/testcases.py\", line 1428, in skip_wrapper\n    return test_func(*args, **kwargs)\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/tests/constraints/tests.py\", line 823, in test_validate_conditon_custom_error\n    self.assertEqual(cm.exception.code, \"custom_code\")\n    ^^^^^^^^^^^^^^^^^\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 873, in assertEqual\n    assertion_func(first, second, msg=msg)\n    ^^^^^^^^^^^^^^^^^\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 866, in _baseAssertEqual\n    raise self.failureException(msg)\n    ^^^^^^^^^^^^^^^^^\nAssertionError: None != 'custom_code'\n\n----------------------------------------------------------------------\nRan 128 tests in 0.130s\n\nFAILED (failures=1, errors=7, skipped=54)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 constraints.tests postgres_tests.test_constraints` failed. (See above for error)",
          "test_files_run": [
            "tests/constraints/tests.py",
            "tests/postgres_tests/test_constraints.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 128,
          "failed": 0,
          "errors": 0,
          "duration": 7.72,
          "log_tail": "test_deferrable_with_opclasses (constraints.tests.UniqueConstraintTests.test_deferrable_with_opclasses) ... ok\ntest_eq (constraints.tests.UniqueConstraintTests.test_eq) ... ok\ntest_eq_with_condition (constraints.tests.UniqueConstraintTests.test_eq_with_condition) ... ok\ntest_eq_with_deferrable (constraints.tests.UniqueConstraintTests.test_eq_with_deferrable) ... ok\ntest_eq_with_expressions (constraints.tests.UniqueConstraintTests.test_eq_with_expressions) ... ok\ntest_eq_with_include (constraints.tests.UniqueConstraintTests.test_eq_with_include) ... ok\ntest_eq_with_opclasses (constraints.tests.UniqueConstraintTests.test_eq_with_opclasses) ... ok\ntest_expressions_and_fields_mutually_exclusive (constraints.tests.UniqueConstraintTests.test_expressions_and_fields_mutually_exclusive) ... ok\ntest_expressions_with_opclasses (constraints.tests.UniqueConstraintTests.test_expressions_with_opclasses) ... ok\ntest_include_database_constraint (constraints.tests.UniqueConstraintTests.test_include_database_constraint) ... skipped \"Database doesn't support feature(s): supports_table_check_constraints, supports_covering_indexes\"\ntest_initially_deferred_database_constraint (constraints.tests.UniqueConstraintTests.test_initially_deferred_database_constraint) ... skipped \"Database doesn't support feature(s): supports_deferrable_unique_constraints\"\ntest_initially_immediate_database_constraint (constraints.tests.UniqueConstraintTests.test_initially_immediate_database_constraint) ... skipped \"Database doesn't support feature(s): supports_deferrable_unique_constraints\"\ntest_invalid_defer_argument (constraints.tests.UniqueConstraintTests.test_invalid_defer_argument) ... ok\ntest_invalid_include_argument (constraints.tests.UniqueConstraintTests.test_invalid_include_argument) ... ok\ntest_invalid_opclasses_argument (constraints.tests.UniqueConstraintTests.test_invalid_opclasses_argument) ... ok\ntest_model_validation (constraints.tests.UniqueConstraintTests.test_model_validation) ... ok\ntest_model_validation_constraint_no_code_error (constraints.tests.UniqueConstraintTests.test_model_validation_constraint_no_code_error) ... ok\ntest_model_validation_with_condition (constraints.tests.UniqueConstraintTests.test_model_validation_with_condition)\nPartial unique constraints are not ignored by ... ok\ntest_name (constraints.tests.UniqueConstraintTests.test_name) ... ok\ntest_opclasses_and_fields_same_length (constraints.tests.UniqueConstraintTests.test_opclasses_and_fields_same_length) ... ok\ntest_repr (constraints.tests.UniqueConstraintTests.test_repr) ... ok\ntest_repr_with_condition (constraints.tests.UniqueConstraintTests.test_repr_with_condition) ... ok\ntest_repr_with_deferrable (constraints.tests.UniqueConstraintTests.test_repr_with_deferrable) ... ok\ntest_repr_with_expressions (constraints.tests.UniqueConstraintTests.test_repr_with_expressions) ... ok\ntest_repr_with_include (constraints.tests.UniqueConstraintTests.test_repr_with_include) ... ok\ntest_repr_with_opclasses (constraints.tests.UniqueConstraintTests.test_repr_with_opclasses) ... ok\ntest_repr_with_violation_error_code (constraints.tests.UniqueConstraintTests.test_repr_with_violation_error_code) ... ok\ntest_repr_with_violation_error_message (constraints.tests.UniqueConstraintTests.test_repr_with_violation_error_message) ... ok\ntest_requires_field_or_expression (constraints.tests.UniqueConstraintTests.test_requires_field_or_expression) ... ok\ntest_requires_name (constraints.tests.UniqueConstraintTests.test_requires_name) ... ok\ntest_validate (constraints.tests.UniqueConstraintTests.test_validate) ... ok\ntest_validate_condition (constraints.tests.UniqueConstraintTests.test_validate_condition) ... ok\ntest_validate_conditon_custom_error (constraints.tests.UniqueConstraintTests.test_validate_conditon_custom_error) ... ok\ntest_validate_expression (constraints.tests.UniqueConstraintTests.test_validate_expression) ... ok\ntest_validate_expression_condition (constraints.tests.UniqueConstraintTests.test_validate_expression_condition) ... ok\ntest_validate_expression_str (constraints.tests.UniqueConstraintTests.test_validate_expression_str) ... ok\ntest_validate_ordered_expression (constraints.tests.UniqueConstraintTests.test_validate_ordered_expression) ... ok\n\n----------------------------------------------------------------------\nRan 128 tests in 0.111s\n\nOK (skipped=54)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/constraints/tests.py",
            "tests/postgres_tests/test_constraints.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-16569",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 16.899155855178833,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 155,
          "failed": 0,
          "errors": 2,
          "duration": 7.92,
          "log_tail": "----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 57, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 623, in run\n    self._callTestMethod(testMethod)\n    ^^^^^^^^^^^^^^^^^\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 579, in _callTestMethod\n    if method() is not None:\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/tests/forms_tests/tests/test_formsets.py\", line 1483, in test_disable_delete_extra_formset_forms\n    self.assertNotIn(\"DELETE\", formset.empty_form.fields)\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/forms/formsets.py\", line 267, in empty_form\n    self.add_fields(form, None)\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/forms/formsets.py\", line 493, in add_fields\n    if self.can_delete and (self.can_delete_extra or index < initial_form_count):\n    ^^^^^^^^^^^^^^^^^\nTypeError: '<' not supported between instances of 'NoneType' and 'int'\n\n======================================================================\nERROR: test_disable_delete_extra_formset_forms (forms_tests.tests.test_formsets.Jinja2FormsFormsetTestCase.test_disable_delete_extra_formset_forms)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 57, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 623, in run\n    self._callTestMethod(testMethod)\n    ^^^^^^^^^^^^^^^^^\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 579, in _callTestMethod\n    if method() is not None:\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/tests/forms_tests/tests/test_formsets.py\", line 1483, in test_disable_delete_extra_formset_forms\n    self.assertNotIn(\"DELETE\", formset.empty_form.fields)\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/forms/formsets.py\", line 267, in empty_form\n    self.add_fields(form, None)\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/forms/formsets.py\", line 493, in add_fields\n    if self.can_delete and (self.can_delete_extra or index < initial_form_count):\n    ^^^^^^^^^^^^^^^^^\nTypeError: '<' not supported between instances of 'NoneType' and 'int'\n\n----------------------------------------------------------------------\nRan 157 tests in 0.479s\n\nFAILED (errors=2)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 forms_tests.tests.test_formsets` failed. (See above for error)",
          "test_files_run": [
            "tests/forms_tests/tests/test_formsets.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 157,
          "failed": 0,
          "errors": 0,
          "duration": 7.89,
          "log_tail": "test_html_safe (forms_tests.tests.test_formsets.FormsFormsetTestCase.test_html_safe) ... ok\ntest_increase_hard_limit (forms_tests.tests.test_formsets.FormsFormsetTestCase.test_increase_hard_limit)\nCan increase the built-in forms limit via a higher max_num. ... ok\ntest_invalid_deleted_form_with_ordering (forms_tests.tests.test_formsets.FormsFormsetTestCase.test_invalid_deleted_form_with_ordering)\nCan get ordered_forms from a valid formset even if a deleted form ... ok\ntest_limited_max_forms_two (forms_tests.tests.test_formsets.FormsFormsetTestCase.test_limited_max_forms_two) ... ok\ntest_limiting_extra_lest_than_max_num (forms_tests.tests.test_formsets.FormsFormsetTestCase.test_limiting_extra_lest_than_max_num)\nmax_num has no effect when extra is less than max_num. ... ok\ntest_limiting_max_forms (forms_tests.tests.test_formsets.FormsFormsetTestCase.test_limiting_max_forms)\nLimiting the maximum number of forms with max_num. ... ok\ntest_management_form_field_names (forms_tests.tests.test_formsets.FormsFormsetTestCase.test_management_form_field_names)\nThe management form class has field names matching the constants. ... ok\ntest_management_form_prefix (forms_tests.tests.test_formsets.FormsFormsetTestCase.test_management_form_prefix)\nThe management form has the correct prefix. ... ok\ntest_max_num_with_initial_data (forms_tests.tests.test_formsets.FormsFormsetTestCase.test_max_num_with_initial_data) ... ok\ntest_max_num_zero (forms_tests.tests.test_formsets.FormsFormsetTestCase.test_max_num_zero)\nIf max_num is 0 then no form is rendered at all, regardless of extra, ... ok\ntest_max_num_zero_with_initial (forms_tests.tests.test_formsets.FormsFormsetTestCase.test_max_num_zero_with_initial) ... ok\ntest_min_num_displaying_more_than_one_blank_form (forms_tests.tests.test_formsets.FormsFormsetTestCase.test_min_num_displaying_more_than_one_blank_form)\nMore than 1 empty form can also be displayed using formset_factory's ... ok\ntest_min_num_displaying_more_than_one_blank_form_with_zero_extra (forms_tests.tests.test_formsets.FormsFormsetTestCase.test_min_num_displaying_more_than_one_blank_form_with_zero_extra)\nMore than 1 empty form can be displayed using min_num. ... ok\ntest_more_initial_data (forms_tests.tests.test_formsets.FormsFormsetTestCase.test_more_initial_data)\nThe extra argument works when the formset is pre-filled with initial ... ok\ntest_more_initial_form_result_in_one (forms_tests.tests.test_formsets.FormsFormsetTestCase.test_more_initial_form_result_in_one)\nOne form from initial and extra=3 with max_num=2 results in the one ... ok\ntest_more_initial_than_max_num (forms_tests.tests.test_formsets.FormsFormsetTestCase.test_more_initial_than_max_num)\nMore initial forms than max_num results in all initial forms being ... ok\ntest_non_form_errors (forms_tests.tests.test_formsets.FormsFormsetTestCase.test_non_form_errors) ... ok\ntest_non_form_errors_run_full_clean (forms_tests.tests.test_formsets.FormsFormsetTestCase.test_non_form_errors_run_full_clean)\nIf non_form_errors() is called without calling is_valid() first, ... ok\ntest_ordering_blank_fieldsets (forms_tests.tests.test_formsets.FormsFormsetTestCase.test_ordering_blank_fieldsets)\nOrdering works with blank fieldsets. ... ok\ntest_repr (forms_tests.tests.test_formsets.FormsFormsetTestCase.test_repr) ... ok\ntest_repr_do_not_trigger_validation (forms_tests.tests.test_formsets.FormsFormsetTestCase.test_repr_do_not_trigger_validation) ... ok\ntest_second_form_partially_filled (forms_tests.tests.test_formsets.FormsFormsetTestCase.test_second_form_partially_filled)\nIf at least one field is filled out on a blank form, it will be ... ok\ntest_second_form_partially_filled_2 (forms_tests.tests.test_formsets.FormsFormsetTestCase.test_second_form_partially_filled_2)\nA partially completed form is invalid. ... ok\ntest_single_form_completed (forms_tests.tests.test_formsets.FormsFormsetTestCase.test_single_form_completed)\nJust one form may be completed. ... ok\ntest_template_name_can_be_overridden (forms_tests.tests.test_formsets.FormsFormsetTestCase.test_template_name_can_be_overridden) ... ok\ntest_template_name_uses_renderer_value (forms_tests.tests.test_formsets.FormsFormsetTestCase.test_template_name_uses_renderer_value) ... ok\ntest_validate_max_ignores_forms_marked_for_deletion (forms_tests.tests.test_formsets.FormsFormsetTestCase.test_validate_max_ignores_forms_marked_for_deletion) ... ok\n\n----------------------------------------------------------------------\nRan 157 tests in 0.457s\n\nOK\n",
          "test_files_run": [
            "tests/forms_tests/tests/test_formsets.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-16595",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 15.851876974105835,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 37,
          "failed": 1,
          "errors": 0,
          "duration": 7.33,
          "log_tail": "test_none_app_label (migrations.test_optimizer.OptimizerTests.test_none_app_label) ... ok\ntest_optimize_elidable_operation (migrations.test_optimizer.OptimizerTests.test_optimize_elidable_operation) ... ok\ntest_optimize_through_create (migrations.test_optimizer.OptimizerTests.test_optimize_through_create)\nWe should be able to optimize away create/delete through a create or ... ok\ntest_optimize_through_fields (migrations.test_optimizer.OptimizerTests.test_optimize_through_fields)\nfield-level through checking is working. This should manage to collapse ... ok\ntest_rename_index (migrations.test_optimizer.OptimizerTests.test_rename_index) ... ok\ntest_rename_model_self (migrations.test_optimizer.OptimizerTests.test_rename_model_self)\nRenameModels should absorb themselves. ... ok\ntest_single (migrations.test_optimizer.OptimizerTests.test_single)\nThe optimizer does nothing on a single operation, ... ok\ntest_swapping_fields_names (migrations.test_optimizer.OptimizerTests.test_swapping_fields_names) ... ok\n\n======================================================================\nFAIL: test_alter_alter_field (migrations.test_optimizer.OptimizerTests.test_alter_alter_field)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/migrations/test_optimizer.py\", line 264, in test_alter_alter_field\n    self._test_alter_alter(\n  File \"/testbed/tests/migrations/test_optimizer.py\", line 229, in _test_alter_alter\n    self.assertOptimizesTo(\n  File \"/testbed/tests/migrations/test_optimizer.py\", line 31, in assertOptimizesTo\n    self.assertEqual(expected, result)\nAssertionError: Lists differ: [\"mig[87 chars]ield(help_text='help'),\\n)\"] != [\"mig[87 chars]ield(),\\n)\", \"migrations.AlterField(\\n    mode[81 chars]\\n)\"]\n\nFirst differing element 0:\n\"migr[50 chars]e='name',\\n    field=models.IntegerField(help_text='help'),\\n)\"\n\"migr[50 chars]e='name',\\n    field=models.IntegerField(),\\n)\"\n\nSecond list contains 1 additional elements.\nFirst extra element 1:\n\"migrations.AlterField(\\n    model_name='Foo',\\n    name='name',\\n    field=models.IntegerField(help_text='help'),\\n)\"\n\n  ['migrations.AlterField(\\n'\n+  \"    model_name='Foo',\\n\"\n+  \"    name='name',\\n\"\n+  '    field=models.IntegerField(),\\n'\n+  ')',\n+  'migrations.AlterField(\\n'\n   \"    model_name='Foo',\\n\"\n   \"    name='name',\\n\"\n   \"    field=models.IntegerField(help_text='help'),\\n\"\n   ')']\n\n----------------------------------------------------------------------\nRan 38 tests in 0.038s\n\nFAILED (failures=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 migrations.test_optimizer` failed. (See above for error)",
          "test_files_run": [
            "tests/migrations/test_optimizer.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 38,
          "failed": 0,
          "errors": 0,
          "duration": 7.36,
          "log_tail": "RenameField should optimize to the other side of AlterField, ... ok\ntest_create_alter_index_delete_model (migrations.test_optimizer.OptimizerTests.test_create_alter_index_delete_model) ... ok\ntest_create_alter_index_field (migrations.test_optimizer.OptimizerTests.test_create_alter_index_field) ... ok\ntest_create_alter_model_managers (migrations.test_optimizer.OptimizerTests.test_create_alter_model_managers) ... ok\ntest_create_alter_model_options (migrations.test_optimizer.OptimizerTests.test_create_alter_model_options) ... ok\ntest_create_alter_owrt_delete_model (migrations.test_optimizer.OptimizerTests.test_create_alter_owrt_delete_model) ... ok\ntest_create_alter_owrt_field (migrations.test_optimizer.OptimizerTests.test_create_alter_owrt_field) ... ok\ntest_create_alter_unique_delete_model (migrations.test_optimizer.OptimizerTests.test_create_alter_unique_delete_model) ... ok\ntest_create_alter_unique_field (migrations.test_optimizer.OptimizerTests.test_create_alter_unique_field) ... ok\ntest_create_delete_model (migrations.test_optimizer.OptimizerTests.test_create_delete_model)\nCreateModel and DeleteModel should collapse into nothing. ... ok\ntest_create_model_add_field (migrations.test_optimizer.OptimizerTests.test_create_model_add_field)\nAddField should optimize into CreateModel. ... ok\ntest_create_model_add_field_not_through_m2m_through (migrations.test_optimizer.OptimizerTests.test_create_model_add_field_not_through_m2m_through)\nAddField should NOT optimize into CreateModel if it's an M2M using a ... ok\ntest_create_model_alter_field (migrations.test_optimizer.OptimizerTests.test_create_model_alter_field)\nAlterField should optimize into CreateModel. ... ok\ntest_create_model_and_remove_model_options (migrations.test_optimizer.OptimizerTests.test_create_model_and_remove_model_options) ... ok\ntest_create_model_no_reordering_for_unrelated_fk (migrations.test_optimizer.OptimizerTests.test_create_model_no_reordering_for_unrelated_fk)\nCreateModel order remains unchanged if the later AddField operation ... ok\ntest_create_model_no_reordering_of_inherited_model (migrations.test_optimizer.OptimizerTests.test_create_model_no_reordering_of_inherited_model)\nA CreateModel that inherits from another isn't reordered to avoid ... ok\ntest_create_model_remove_field (migrations.test_optimizer.OptimizerTests.test_create_model_remove_field)\nRemoveField should optimize into CreateModel. ... ok\ntest_create_model_rename_field (migrations.test_optimizer.OptimizerTests.test_create_model_rename_field)\nRenameField should optimize into CreateModel. ... ok\ntest_create_model_reordering (migrations.test_optimizer.OptimizerTests.test_create_model_reordering)\nAddField optimizes into CreateModel if it's a FK to a model that's ... ok\ntest_create_model_reordering_circular_fk (migrations.test_optimizer.OptimizerTests.test_create_model_reordering_circular_fk)\nCreateModel reordering behavior doesn't result in an infinite loop if ... ok\ntest_create_rename_model (migrations.test_optimizer.OptimizerTests.test_create_rename_model)\nCreateModel should absorb RenameModels. ... ok\ntest_none_app_label (migrations.test_optimizer.OptimizerTests.test_none_app_label) ... ok\ntest_optimize_elidable_operation (migrations.test_optimizer.OptimizerTests.test_optimize_elidable_operation) ... ok\ntest_optimize_through_create (migrations.test_optimizer.OptimizerTests.test_optimize_through_create)\nWe should be able to optimize away create/delete through a create or ... ok\ntest_optimize_through_fields (migrations.test_optimizer.OptimizerTests.test_optimize_through_fields)\nfield-level through checking is working. This should manage to collapse ... ok\ntest_rename_index (migrations.test_optimizer.OptimizerTests.test_rename_index) ... ok\ntest_rename_model_self (migrations.test_optimizer.OptimizerTests.test_rename_model_self)\nRenameModels should absorb themselves. ... ok\ntest_single (migrations.test_optimizer.OptimizerTests.test_single)\nThe optimizer does nothing on a single operation, ... ok\ntest_swapping_fields_names (migrations.test_optimizer.OptimizerTests.test_swapping_fields_names) ... ok\n\n----------------------------------------------------------------------\nRan 38 tests in 0.023s\n\nOK\n",
          "test_files_run": [
            "tests/migrations/test_optimizer.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-16612",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 27.60627007484436,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 362,
          "failed": 2,
          "errors": 0,
          "duration": 15.47,
          "log_tail": "Ran 364 tests in 7.341s\n\nFAILED (failures=2, skipped=23)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 admin_views.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/admin_views/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 364,
          "failed": 0,
          "errors": 0,
          "duration": 11.12,
          "log_tail": "----------------------------------------------------------------------\nRan 364 tests in 5.395s\n\nOK (skipped=23)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/admin_views/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-16631",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 16.040722846984863,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 12,
          "failed": 1,
          "errors": 0,
          "duration": 8.15,
          "log_tail": "The current user model can be retrieved ... ok\ntest_superuser (auth_tests.test_basic.BasicTestCase.test_superuser)\nCheck the creation and properties of a superuser ... ok\ntest_superuser_no_email_or_password (auth_tests.test_basic.BasicTestCase.test_superuser_no_email_or_password) ... ok\ntest_swappable_user (auth_tests.test_basic.BasicTestCase.test_swappable_user)\nThe current user model can be swapped out for another ... ok\ntest_swappable_user_bad_setting (auth_tests.test_basic.BasicTestCase.test_swappable_user_bad_setting)\nThe alternate user setting must point to something in the format app.model ... ok\ntest_swappable_user_nonexistent_model (auth_tests.test_basic.BasicTestCase.test_swappable_user_nonexistent_model)\nThe current user model must point to an installed model ... ok\ntest_unicode_username (auth_tests.test_basic.BasicTestCase.test_unicode_username) ... ok\ntest_user (auth_tests.test_basic.BasicTestCase.test_user)\nUsers can be created and can set their password ... ok\ntest_user_no_email (auth_tests.test_basic.BasicTestCase.test_user_no_email)\nUsers can be created without an email ... ok\ntest_user_verbose_names_translatable (auth_tests.test_basic.BasicTestCase.test_user_verbose_names_translatable)\nDefault User model verbose names are translatable (#19945) ... ok\n\n======================================================================\nFAIL: test_get_user_fallback_secret (auth_tests.test_basic.TestGetUser.test_get_user_fallback_secret)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 57, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 623, in run\n    self._callTestMethod(testMethod)\n    ^^^^^^^^^^^^^^^^^\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 579, in _callTestMethod\n    if method() is not None:\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/tests/auth_tests/test_basic.py\", line 156, in test_get_user_fallback_secret\n    self.assertIsInstance(user, User)\n    ^^^^^^^^^^^^^^^^^\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 1296, in assertIsInstance\n    self.fail(self._formatMessage(msg, standardMsg))\n    ^^^^^^^^^^^^^^^^^\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 703, in fail\n    raise self.failureException(msg)\n    ^^^^^^^^^^^^^^^^^\nAssertionError: <django.contrib.auth.models.AnonymousUser object at 0x7e0dd9c3b210> is not an instance of <class 'django.contrib.auth.models.User'>\n\n----------------------------------------------------------------------\nRan 13 tests in 0.149s\n\nFAILED (failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 auth_tests.test_basic` failed. (See above for error)",
          "test_files_run": [
            "tests/auth_tests/test_basic.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 13,
          "failed": 0,
          "errors": 0,
          "duration": 6.48,
          "log_tail": "    Creating table auth_tests_integerusernameuser\n    Creating table auth_tests_userwithdisabledlastloginfield\n    Creating table auth_tests_organization\n    Creating table auth_tests_customuserwithm2m\n    Creating table auth_tests_customuserwithm2mthrough\n    Creating table auth_tests_membership\n    Creating table auth_tests_customuserwithuniqueconstraint\n    Running deferred SQL...\nRunning migrations:\n  Applying admin.0001_initial... OK\n  Applying admin.0002_logentry_remove_auto_add... OK\n  Applying admin.0003_logentry_add_action_flag_choices... OK\n  Applying sites.0001_initial... OK\n  Applying sites.0002_alter_domain_unique... OK\nSystem check identified no issues (0 silenced).\n\n\nCreating test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\ntest_get_user (auth_tests.test_basic.TestGetUser.test_get_user) ... ok\ntest_get_user_anonymous (auth_tests.test_basic.TestGetUser.test_get_user_anonymous) ... ok\ntest_get_user_fallback_secret (auth_tests.test_basic.TestGetUser.test_get_user_fallback_secret) ... ok\ntest_get_user_model (auth_tests.test_basic.BasicTestCase.test_get_user_model)\nThe current user model can be retrieved ... ok\ntest_superuser (auth_tests.test_basic.BasicTestCase.test_superuser)\nCheck the creation and properties of a superuser ... ok\ntest_superuser_no_email_or_password (auth_tests.test_basic.BasicTestCase.test_superuser_no_email_or_password) ... ok\ntest_swappable_user (auth_tests.test_basic.BasicTestCase.test_swappable_user)\nThe current user model can be swapped out for another ... ok\ntest_swappable_user_bad_setting (auth_tests.test_basic.BasicTestCase.test_swappable_user_bad_setting)\nThe alternate user setting must point to something in the format app.model ... ok\ntest_swappable_user_nonexistent_model (auth_tests.test_basic.BasicTestCase.test_swappable_user_nonexistent_model)\nThe current user model must point to an installed model ... ok\ntest_unicode_username (auth_tests.test_basic.BasicTestCase.test_unicode_username) ... ok\ntest_user (auth_tests.test_basic.BasicTestCase.test_user)\nUsers can be created and can set their password ... ok\ntest_user_no_email (auth_tests.test_basic.BasicTestCase.test_user_no_email)\nUsers can be created without an email ... ok\ntest_user_verbose_names_translatable (auth_tests.test_basic.BasicTestCase.test_user_verbose_names_translatable)\nDefault User model verbose names are translatable (#19945) ... ok\n\n----------------------------------------------------------------------\nRan 13 tests in 0.078s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/auth_tests/test_basic.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-16642",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 14.621900081634521,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 20,
          "failed": 2,
          "errors": 0,
          "duration": 7.68,
          "log_tail": "test_content_length_buffer (responses.test_fileresponse.FileResponseTests.test_content_length_buffer) ... ok\ntest_content_length_file (responses.test_fileresponse.FileResponseTests.test_content_length_file) ... ok\ntest_content_length_nonzero_starting_position_buffer (responses.test_fileresponse.FileResponseTests.test_content_length_nonzero_starting_position_buffer) ... ok\ntest_content_length_nonzero_starting_position_file (responses.test_fileresponse.FileResponseTests.test_content_length_nonzero_starting_position_file) ... ok\ntest_content_length_nonzero_starting_position_file_seekable_no_tell (responses.test_fileresponse.FileResponseTests.test_content_length_nonzero_starting_position_file_seekable_no_tell) ... ok\ntest_content_type_buffer (responses.test_fileresponse.FileResponseTests.test_content_type_buffer) ... ok\ntest_content_type_buffer_explicit (responses.test_fileresponse.FileResponseTests.test_content_type_buffer_explicit) ... ok\ntest_content_type_buffer_explicit_default (responses.test_fileresponse.FileResponseTests.test_content_type_buffer_explicit_default) ... ok\ntest_content_type_buffer_named (responses.test_fileresponse.FileResponseTests.test_content_type_buffer_named) ... ok\ntest_content_type_file (responses.test_fileresponse.FileResponseTests.test_content_type_file) ... ok\ntest_file_from_named_pipe_response (responses.test_fileresponse.FileResponseTests.test_file_from_named_pipe_response) ... ok\ntest_repr (responses.test_fileresponse.FileResponseTests.test_repr) ... ok\ntest_response_buffer (responses.test_fileresponse.FileResponseTests.test_response_buffer) ... ok\ntest_response_nonzero_starting_position (responses.test_fileresponse.FileResponseTests.test_response_nonzero_starting_position) ... ok\ntest_unicode_attachment (responses.test_fileresponse.FileResponseTests.test_unicode_attachment) ... ok\n\n======================================================================\nFAIL: test_compressed_response (responses.test_fileresponse.FileResponseTests.test_compressed_response) (ext='.tar.br')\nIf compressed responses are served with the uncompressed Content-Type\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/responses/test_fileresponse.py\", line 265, in test_compressed_response\n    self.assertEqual(response.headers[\"Content-Type\"], mimetype)\nAssertionError: 'application/x-tar' != 'application/x-brotli'\n- application/x-tar\n?                ^^\n+ application/x-brotli\n?               +++ ^^\n\n\n======================================================================\nFAIL: test_compressed_response (responses.test_fileresponse.FileResponseTests.test_compressed_response) (ext='.tar.Z')\nIf compressed responses are served with the uncompressed Content-Type\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/responses/test_fileresponse.py\", line 265, in test_compressed_response\n    self.assertEqual(response.headers[\"Content-Type\"], mimetype)\nAssertionError: 'application/x-tar' != 'application/x-compress'\n- application/x-tar\n?               ^^\n+ application/x-compress\n?               ^^^^ +++\n\n\n----------------------------------------------------------------------\nRan 22 tests in 0.015s\n\nFAILED (failures=2)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 responses.test_fileresponse` failed. (See above for error)",
          "test_files_run": [
            "tests/responses/test_fileresponse.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 22,
          "failed": 0,
          "errors": 0,
          "duration": 5.86,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application responses\nFound 22 test(s).\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_buffer_explicit_absolute_filename (responses.test_fileresponse.FileResponseTests.test_buffer_explicit_absolute_filename)\nHeaders are set correctly with a buffer when an absolute filename is ... ok\ntest_compressed_response (responses.test_fileresponse.FileResponseTests.test_compressed_response)\nIf compressed responses are served with the uncompressed Content-Type ... ok\ntest_content_disposition_buffer (responses.test_fileresponse.FileResponseTests.test_content_disposition_buffer) ... ok\ntest_content_disposition_buffer_attachment (responses.test_fileresponse.FileResponseTests.test_content_disposition_buffer_attachment) ... ok\ntest_content_disposition_buffer_explicit_filename (responses.test_fileresponse.FileResponseTests.test_content_disposition_buffer_explicit_filename) ... ok\ntest_content_disposition_escaping (responses.test_fileresponse.FileResponseTests.test_content_disposition_escaping) ... ok\ntest_content_disposition_file (responses.test_fileresponse.FileResponseTests.test_content_disposition_file) ... ok\ntest_content_length_buffer (responses.test_fileresponse.FileResponseTests.test_content_length_buffer) ... ok\ntest_content_length_file (responses.test_fileresponse.FileResponseTests.test_content_length_file) ... ok\ntest_content_length_nonzero_starting_position_buffer (responses.test_fileresponse.FileResponseTests.test_content_length_nonzero_starting_position_buffer) ... ok\ntest_content_length_nonzero_starting_position_file (responses.test_fileresponse.FileResponseTests.test_content_length_nonzero_starting_position_file) ... ok\ntest_content_length_nonzero_starting_position_file_seekable_no_tell (responses.test_fileresponse.FileResponseTests.test_content_length_nonzero_starting_position_file_seekable_no_tell) ... ok\ntest_content_type_buffer (responses.test_fileresponse.FileResponseTests.test_content_type_buffer) ... ok\ntest_content_type_buffer_explicit (responses.test_fileresponse.FileResponseTests.test_content_type_buffer_explicit) ... ok\ntest_content_type_buffer_explicit_default (responses.test_fileresponse.FileResponseTests.test_content_type_buffer_explicit_default) ... ok\ntest_content_type_buffer_named (responses.test_fileresponse.FileResponseTests.test_content_type_buffer_named) ... ok\ntest_content_type_file (responses.test_fileresponse.FileResponseTests.test_content_type_file) ... ok\ntest_file_from_named_pipe_response (responses.test_fileresponse.FileResponseTests.test_file_from_named_pipe_response) ... ok\ntest_repr (responses.test_fileresponse.FileResponseTests.test_repr) ... ok\ntest_response_buffer (responses.test_fileresponse.FileResponseTests.test_response_buffer) ... ok\ntest_response_nonzero_starting_position (responses.test_fileresponse.FileResponseTests.test_response_nonzero_starting_position) ... ok\ntest_unicode_attachment (responses.test_fileresponse.FileResponseTests.test_unicode_attachment) ... ok\n\n----------------------------------------------------------------------\nRan 22 tests in 0.007s\n\nOK\n",
          "test_files_run": [
            "tests/responses/test_fileresponse.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-16661",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 15.059791088104248,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 36,
          "failed": 1,
          "errors": 0,
          "duration": 8.08,
          "log_tail": "test_get_fieldsets (modeladmin.tests.ModelAdminTests.test_get_fieldsets) ... ok\ntest_log_actions (modeladmin.tests.ModelAdminTests.test_log_actions) ... ok\ntest_lookup_allowed_allows_nonexistent_lookup (modeladmin.tests.ModelAdminTests.test_lookup_allowed_allows_nonexistent_lookup)\nA lookup_allowed allows a parameter whose field lookup doesn't exist. ... ok\ntest_lookup_allowed_foreign_primary (modeladmin.tests.ModelAdminTests.test_lookup_allowed_foreign_primary) ... FAIL\ntest_lookup_allowed_onetoone (modeladmin.tests.ModelAdminTests.test_lookup_allowed_onetoone) ... ok\ntest_modeladmin_repr (modeladmin.tests.ModelAdminTests.test_modeladmin_repr) ... ok\ntest_modeladmin_str (modeladmin.tests.ModelAdminTests.test_modeladmin_str) ... ok\ntest_overriding_get_exclude (modeladmin.tests.ModelAdminTests.test_overriding_get_exclude) ... ok\ntest_queryset_override (modeladmin.tests.ModelAdminTests.test_queryset_override) ... ok\ntest_raw_id_fields_widget_override (modeladmin.tests.ModelAdminTests.test_raw_id_fields_widget_override)\nThe autocomplete_fields, raw_id_fields, and radio_fields widgets may ... ok\ntest_regression_for_ticket_15820 (modeladmin.tests.ModelAdminTests.test_regression_for_ticket_15820)\n`obj` is passed from `InlineModelAdmin.get_fieldsets()` to ... ok\n\n======================================================================\nFAIL: test_lookup_allowed_foreign_primary (modeladmin.tests.ModelAdminTests.test_lookup_allowed_foreign_primary)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 57, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 623, in run\n    self._callTestMethod(testMethod)\n    ^^^^^^^^^^^^^^^^^\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 579, in _callTestMethod\n    if method() is not None:\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/test/utils.py\", line 443, in inner\n    return func(*args, **kwargs)\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/tests/modeladmin/tests.py\", line 178, in test_lookup_allowed_foreign_primary\n    self.assertIs(ma.lookup_allowed(\"restaurant__place__country\", \"1\"), True)\n    ^^^^^^^^^^^^^^^^^\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 1154, in assertIs\n    self.fail(self._formatMessage(msg, standardMsg))\n    ^^^^^^^^^^^^^^^^^\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 703, in fail\n    raise self.failureException(msg)\n    ^^^^^^^^^^^^^^^^^\nAssertionError: False is not True\n\n----------------------------------------------------------------------\nRan 37 tests in 0.142s\n\nFAILED (failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 modeladmin.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/modeladmin/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 37,
          "failed": 0,
          "errors": 0,
          "duration": 5.82,
          "log_tail": "has_view_permission() returns True for users who can view objects and ... ok\ntest_inline_has_add_permission_uses_obj (modeladmin.tests.ModelAdminPermissionTests.test_inline_has_add_permission_uses_obj) ... ok\ntest_custom_form_meta_exclude (modeladmin.tests.ModelAdminTests.test_custom_form_meta_exclude)\nThe custom ModelForm's `Meta.exclude` is overridden if ... ok\ntest_custom_form_meta_exclude_with_readonly (modeladmin.tests.ModelAdminTests.test_custom_form_meta_exclude_with_readonly)\nThe custom ModelForm's `Meta.exclude` is respected when used in ... ok\ntest_custom_form_validation (modeladmin.tests.ModelAdminTests.test_custom_form_validation) ... ok\ntest_custom_formfield_override_readonly (modeladmin.tests.ModelAdminTests.test_custom_formfield_override_readonly) ... ok\ntest_default_attributes (modeladmin.tests.ModelAdminTests.test_default_attributes) ... ok\ntest_default_fields (modeladmin.tests.ModelAdminTests.test_default_fields) ... ok\ntest_default_fieldsets (modeladmin.tests.ModelAdminTests.test_default_fieldsets) ... ok\ntest_default_foreign_key_widget (modeladmin.tests.ModelAdminTests.test_default_foreign_key_widget) ... ok\ntest_field_arguments (modeladmin.tests.ModelAdminTests.test_field_arguments) ... ok\ntest_field_arguments_restricted_on_form (modeladmin.tests.ModelAdminTests.test_field_arguments_restricted_on_form) ... ok\ntest_foreign_key_as_radio_field (modeladmin.tests.ModelAdminTests.test_foreign_key_as_radio_field) ... ok\ntest_form_exclude_kwarg_override (modeladmin.tests.ModelAdminTests.test_form_exclude_kwarg_override)\nThe `exclude` kwarg passed to `ModelAdmin.get_form()` overrides all ... ok\ntest_formset_exclude_kwarg_override (modeladmin.tests.ModelAdminTests.test_formset_exclude_kwarg_override)\nThe `exclude` kwarg passed to `InlineModelAdmin.get_formset()` ... ok\ntest_formset_overriding_get_exclude_with_form_exclude (modeladmin.tests.ModelAdminTests.test_formset_overriding_get_exclude_with_form_exclude) ... ok\ntest_formset_overriding_get_exclude_with_form_fields (modeladmin.tests.ModelAdminTests.test_formset_overriding_get_exclude_with_form_fields) ... ok\ntest_get_autocomplete_fields (modeladmin.tests.ModelAdminTests.test_get_autocomplete_fields) ... ok\ntest_get_deleted_objects (modeladmin.tests.ModelAdminTests.test_get_deleted_objects) ... ok\ntest_get_deleted_objects_with_custom_has_delete_permission (modeladmin.tests.ModelAdminTests.test_get_deleted_objects_with_custom_has_delete_permission)\nModelAdmin.get_deleted_objects() uses ModelAdmin.has_delete_permission() ... ok\ntest_get_exclude_overrides_exclude (modeladmin.tests.ModelAdminTests.test_get_exclude_overrides_exclude) ... ok\ntest_get_exclude_takes_obj (modeladmin.tests.ModelAdminTests.test_get_exclude_takes_obj) ... ok\ntest_get_fieldsets (modeladmin.tests.ModelAdminTests.test_get_fieldsets) ... ok\ntest_log_actions (modeladmin.tests.ModelAdminTests.test_log_actions) ... ok\ntest_lookup_allowed_allows_nonexistent_lookup (modeladmin.tests.ModelAdminTests.test_lookup_allowed_allows_nonexistent_lookup)\nA lookup_allowed allows a parameter whose field lookup doesn't exist. ... ok\ntest_lookup_allowed_foreign_primary (modeladmin.tests.ModelAdminTests.test_lookup_allowed_foreign_primary) ... ok\ntest_lookup_allowed_onetoone (modeladmin.tests.ModelAdminTests.test_lookup_allowed_onetoone) ... ok\ntest_modeladmin_repr (modeladmin.tests.ModelAdminTests.test_modeladmin_repr) ... ok\ntest_modeladmin_str (modeladmin.tests.ModelAdminTests.test_modeladmin_str) ... ok\ntest_overriding_get_exclude (modeladmin.tests.ModelAdminTests.test_overriding_get_exclude) ... ok\ntest_queryset_override (modeladmin.tests.ModelAdminTests.test_queryset_override) ... ok\ntest_raw_id_fields_widget_override (modeladmin.tests.ModelAdminTests.test_raw_id_fields_widget_override)\nThe autocomplete_fields, raw_id_fields, and radio_fields widgets may ... ok\ntest_regression_for_ticket_15820 (modeladmin.tests.ModelAdminTests.test_regression_for_ticket_15820)\n`obj` is passed from `InlineModelAdmin.get_fieldsets()` to ... ok\n\n----------------------------------------------------------------------\nRan 37 tests in 0.102s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/modeladmin/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-16662",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 14.601972103118896,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 51,
          "failed": 1,
          "errors": 0,
          "duration": 7.32,
          "log_tail": "test_serialize_managers (migrations.test_writer.WriterTests.test_serialize_managers) ... ok\ntest_serialize_multiline_strings (migrations.test_writer.WriterTests.test_serialize_multiline_strings) ... ok\ntest_serialize_nested_class (migrations.test_writer.WriterTests.test_serialize_nested_class) ... ok\ntest_serialize_numbers (migrations.test_writer.WriterTests.test_serialize_numbers) ... ok\ntest_serialize_path_like (migrations.test_writer.WriterTests.test_serialize_path_like) ... ok\ntest_serialize_pathlib (migrations.test_writer.WriterTests.test_serialize_pathlib) ... ok\ntest_serialize_range (migrations.test_writer.WriterTests.test_serialize_range) ... ok\ntest_serialize_set (migrations.test_writer.WriterTests.test_serialize_set) ... ok\ntest_serialize_settings (migrations.test_writer.WriterTests.test_serialize_settings) ... ok\ntest_serialize_strings (migrations.test_writer.WriterTests.test_serialize_strings) ... ok\ntest_serialize_timedelta (migrations.test_writer.WriterTests.test_serialize_timedelta) ... ok\ntest_serialize_type_model (migrations.test_writer.WriterTests.test_serialize_type_model) ... ok\ntest_serialize_type_none (migrations.test_writer.WriterTests.test_serialize_type_none) ... ok\ntest_serialize_unbound_method_reference (migrations.test_writer.WriterTests.test_serialize_unbound_method_reference)\nAn unbound method used within a class body can be serialized. ... ok\ntest_serialize_uuid (migrations.test_writer.WriterTests.test_serialize_uuid) ... ok\ntest_simple_migration (migrations.test_writer.WriterTests.test_simple_migration)\nTests serializing a simple migration. ... ok\ntest_sorted_imports (migrations.test_writer.WriterTests.test_sorted_imports)\n#24155 - Tests ordering of imports. ... FAIL\n\n======================================================================\nFAIL: test_sorted_imports (migrations.test_writer.WriterTests.test_sorted_imports)\n#24155 - Tests ordering of imports.\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 57, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 623, in run\n    self._callTestMethod(testMethod)\n    ^^^^^^^^^^^^^^^^^\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 579, in _callTestMethod\n    if method() is not None:\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/tests/migrations/test_writer.py\", line 926, in test_sorted_imports\n    self.assertIn(\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 1140, in assertIn\n    self.fail(self._formatMessage(msg, standardMsg))\n    ^^^^^^^^^^^^^^^^^\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 703, in fail\n    raise self.failureException(msg)\n    ^^^^^^^^^^^^^^^^^\nAssertionError: 'import datetime\\nimport time\\nfrom django.db import migrations, models\\n' not found in \"# Generated by Django 5.0.dev20230320050210 on 2025-08-10 01:13\\n\\nimport datetime\\nfrom django.db import migrations, models\\nimport time\\n\\n\\nclass Migration(migrations.Migration):\\n\\n    dependencies = [\\n    ]\\n\\n    operations = [\\n        migrations.AddField(\\n            model_name='mymodel',\\n            name='myfield',\\n            field=models.DateTimeField(default=datetime.datetime(2012, 1, 1, 1, 1, tzinfo=datetime.timezone.utc)),\\n        ),\\n        migrations.AddField(\\n            model_name='mymodel',\\n            name='myfield2',\\n            field=models.FloatField(default=time.time),\\n        ),\\n    ]\\n\"\n\n----------------------------------------------------------------------\nRan 52 tests in 0.125s\n\nFAILED (failures=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 migrations.test_writer` failed. (See above for error)",
          "test_files_run": [
            "tests/migrations/test_writer.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 52,
          "failed": 0,
          "errors": 0,
          "duration": 6.1,
          "log_tail": "test_serialize_builtin_types (migrations.test_writer.WriterTests.test_serialize_builtin_types) ... ok\ntest_serialize_builtins (migrations.test_writer.WriterTests.test_serialize_builtins) ... ok\ntest_serialize_choices (migrations.test_writer.WriterTests.test_serialize_choices) ... ok\ntest_serialize_class_based_validators (migrations.test_writer.WriterTests.test_serialize_class_based_validators)\nTicket #22943: Test serialization of class-based validators, including ... ok\ntest_serialize_collections (migrations.test_writer.WriterTests.test_serialize_collections) ... ok\ntest_serialize_compiled_regex (migrations.test_writer.WriterTests.test_serialize_compiled_regex)\nMake sure compiled regex can be serialized. ... ok\ntest_serialize_complex_func_index (migrations.test_writer.WriterTests.test_serialize_complex_func_index) ... ok\ntest_serialize_constants (migrations.test_writer.WriterTests.test_serialize_constants) ... ok\ntest_serialize_datetime (migrations.test_writer.WriterTests.test_serialize_datetime) ... ok\ntest_serialize_empty_nonempty_tuple (migrations.test_writer.WriterTests.test_serialize_empty_nonempty_tuple)\nTicket #22679: makemigrations generates invalid code for (an empty ... ok\ntest_serialize_enum_flags (migrations.test_writer.WriterTests.test_serialize_enum_flags) ... ok\ntest_serialize_enums (migrations.test_writer.WriterTests.test_serialize_enums) ... ok\ntest_serialize_fields (migrations.test_writer.WriterTests.test_serialize_fields) ... ok\ntest_serialize_frozensets (migrations.test_writer.WriterTests.test_serialize_frozensets) ... ok\ntest_serialize_functions (migrations.test_writer.WriterTests.test_serialize_functions) ... ok\ntest_serialize_functools_partial (migrations.test_writer.WriterTests.test_serialize_functools_partial) ... ok\ntest_serialize_functools_partialmethod (migrations.test_writer.WriterTests.test_serialize_functools_partialmethod) ... ok\ntest_serialize_iterators (migrations.test_writer.WriterTests.test_serialize_iterators) ... ok\ntest_serialize_lazy_objects (migrations.test_writer.WriterTests.test_serialize_lazy_objects) ... ok\ntest_serialize_local_function_reference (migrations.test_writer.WriterTests.test_serialize_local_function_reference)\nA reference in a local scope can't be serialized. ... ok\ntest_serialize_managers (migrations.test_writer.WriterTests.test_serialize_managers) ... ok\ntest_serialize_multiline_strings (migrations.test_writer.WriterTests.test_serialize_multiline_strings) ... ok\ntest_serialize_nested_class (migrations.test_writer.WriterTests.test_serialize_nested_class) ... ok\ntest_serialize_numbers (migrations.test_writer.WriterTests.test_serialize_numbers) ... ok\ntest_serialize_path_like (migrations.test_writer.WriterTests.test_serialize_path_like) ... ok\ntest_serialize_pathlib (migrations.test_writer.WriterTests.test_serialize_pathlib) ... ok\ntest_serialize_range (migrations.test_writer.WriterTests.test_serialize_range) ... ok\ntest_serialize_set (migrations.test_writer.WriterTests.test_serialize_set) ... ok\ntest_serialize_settings (migrations.test_writer.WriterTests.test_serialize_settings) ... ok\ntest_serialize_strings (migrations.test_writer.WriterTests.test_serialize_strings) ... ok\ntest_serialize_timedelta (migrations.test_writer.WriterTests.test_serialize_timedelta) ... ok\ntest_serialize_type_model (migrations.test_writer.WriterTests.test_serialize_type_model) ... ok\ntest_serialize_type_none (migrations.test_writer.WriterTests.test_serialize_type_none) ... ok\ntest_serialize_unbound_method_reference (migrations.test_writer.WriterTests.test_serialize_unbound_method_reference)\nAn unbound method used within a class body can be serialized. ... ok\ntest_serialize_uuid (migrations.test_writer.WriterTests.test_serialize_uuid) ... ok\ntest_simple_migration (migrations.test_writer.WriterTests.test_simple_migration)\nTests serializing a simple migration. ... ok\ntest_sorted_imports (migrations.test_writer.WriterTests.test_sorted_imports)\n#24155 - Tests ordering of imports. ... ok\n\n----------------------------------------------------------------------\nRan 52 tests in 0.058s\n\nOK\n",
          "test_files_run": [
            "tests/migrations/test_writer.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-16667",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 14.034971237182617,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 24,
          "failed": 0,
          "errors": 2,
          "duration": 7.38,
          "log_tail": "  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 579, in _callTestMethod\n    if method() is not None:\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/tests/forms_tests/field_tests/test_datefield.py\", line 48, in test_form_field\n    self.assertIs(e.is_valid(), False)\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/forms/forms.py\", line 197, in is_valid\n    return self.is_bound and not self.errors\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/forms/forms.py\", line 192, in errors\n    self.full_clean()\n  File \"/testbed/django/forms/forms.py\", line 327, in full_clean\n    self._clean_fields()\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/forms/forms.py\", line 334, in _clean_fields\n    value = bf.initial if field.disabled else bf.data\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/forms/boundfield.py\", line 135, in data\n    return self.form._widget_data_value(self.field.widget, self.html_name)\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/forms/forms.py\", line 216, in _widget_data_value\n    return widget.value_from_datadict(self.data, self.files, html_name)\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/forms/widgets.py\", line 1159, in value_from_datadict\n    date_value = datetime.date(int(y), int(m), int(d))\n    ^^^^^^^^^^^^^^^^^\nOverflowError: Python int too large to convert to C long\n\n======================================================================\nERROR: test_value_from_datadict (forms_tests.widget_tests.test_selectdatewidget.SelectDateWidgetTest.test_value_from_datadict) [<object object at 0x7fe7e42de140>] (values=('9223372036854775808', '12', '1'))\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 57, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 538, in subTest\n    yield\n  File \"/testbed/tests/forms_tests/widget_tests/test_selectdatewidget.py\", line 623, in test_value_from_datadict\n    self.widget.value_from_datadict(data, {}, \"field\"), expected\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/forms/widgets.py\", line 1159, in value_from_datadict\n    date_value = datetime.date(int(y), int(m), int(d))\n    ^^^^^^^^^^^^^^^^^\nOverflowError: Python int too large to convert to C long\n\n----------------------------------------------------------------------\nRan 26 tests in 0.221s\n\nFAILED (errors=2)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 forms_tests.field_tests.test_datefield forms_tests.widget_tests.test_selectdatewidget` failed. (See above for error)",
          "test_files_run": [
            "tests/forms_tests/field_tests/test_datefield.py",
            "tests/forms_tests/widget_tests/test_selectdatewidget.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 26,
          "failed": 0,
          "errors": 0,
          "duration": 5.57,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application forms_tests\nFound 26 test(s).\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_datefield_1 (forms_tests.field_tests.test_datefield.DateFieldTest.test_datefield_1) ... ok\ntest_datefield_2 (forms_tests.field_tests.test_datefield.DateFieldTest.test_datefield_2) ... ok\ntest_datefield_3 (forms_tests.field_tests.test_datefield.DateFieldTest.test_datefield_3) ... ok\ntest_datefield_4 (forms_tests.field_tests.test_datefield.DateFieldTest.test_datefield_4) ... ok\ntest_datefield_5 (forms_tests.field_tests.test_datefield.DateFieldTest.test_datefield_5) ... ok\ntest_datefield_changed (forms_tests.field_tests.test_datefield.DateFieldTest.test_datefield_changed) ... ok\ntest_datefield_strptime (forms_tests.field_tests.test_datefield.DateFieldTest.test_datefield_strptime)\nfield.strptime() doesn't raise a UnicodeEncodeError (#16123) ... ok\ntest_form_field (forms_tests.field_tests.test_datefield.DateFieldTest.test_form_field) ... ok\ntest_form_label_association (forms_tests.field_tests.test_datefield.DateFieldTest.test_form_label_association) ... ok\ntest_l10n_date_changed (forms_tests.field_tests.test_datefield.DateFieldTest.test_l10n_date_changed)\nDateField.has_changed() with SelectDateWidget works with a localized ... ok\ntest_l10n_invalid_date_in (forms_tests.field_tests.test_datefield.DateFieldTest.test_l10n_invalid_date_in) ... ok\ntest_custom_input_format (forms_tests.widget_tests.test_selectdatewidget.SelectDateWidgetTest.test_custom_input_format) ... ok\ntest_custom_months (forms_tests.widget_tests.test_selectdatewidget.SelectDateWidgetTest.test_custom_months) ... ok\ntest_fieldset (forms_tests.widget_tests.test_selectdatewidget.SelectDateWidgetTest.test_fieldset) ... ok\ntest_format_value (forms_tests.widget_tests.test_selectdatewidget.SelectDateWidgetTest.test_format_value) ... ok\ntest_l10n (forms_tests.widget_tests.test_selectdatewidget.SelectDateWidgetTest.test_l10n) ... ok\ntest_render_datetime (forms_tests.widget_tests.test_selectdatewidget.SelectDateWidgetTest.test_render_datetime) ... ok\ntest_render_empty (forms_tests.widget_tests.test_selectdatewidget.SelectDateWidgetTest.test_render_empty) ... ok\ntest_render_invalid_date (forms_tests.widget_tests.test_selectdatewidget.SelectDateWidgetTest.test_render_invalid_date)\nInvalid dates should still render the failed date. ... ok\ntest_render_none (forms_tests.widget_tests.test_selectdatewidget.SelectDateWidgetTest.test_render_none)\nRendering the None or '' values should yield the same output. ... ok\ntest_render_string (forms_tests.widget_tests.test_selectdatewidget.SelectDateWidgetTest.test_render_string) ... ok\ntest_selectdate_empty_label (forms_tests.widget_tests.test_selectdatewidget.SelectDateWidgetTest.test_selectdate_empty_label) ... ok\ntest_selectdate_required (forms_tests.widget_tests.test_selectdatewidget.SelectDateWidgetTest.test_selectdate_required) ... ok\ntest_value_from_datadict (forms_tests.widget_tests.test_selectdatewidget.SelectDateWidgetTest.test_value_from_datadict) ... ok\ntest_value_omitted_from_data (forms_tests.widget_tests.test_selectdatewidget.SelectDateWidgetTest.test_value_omitted_from_data) ... ok\ntest_years_rendered_without_separator (forms_tests.widget_tests.test_selectdatewidget.SelectDateWidgetTest.test_years_rendered_without_separator) ... ok\n\n----------------------------------------------------------------------\nRan 26 tests in 0.149s\n\nOK\n",
          "test_files_run": [
            "tests/forms_tests/field_tests/test_datefield.py",
            "tests/forms_tests/widget_tests/test_selectdatewidget.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-16801",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 14.98853588104248,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 46,
          "failed": 1,
          "errors": 0,
          "duration": 8.25,
          "log_tail": "Assigning ImageField to None clears dimensions. ... ok\ntest_constructor (model_fields.test_imagefield.ImageFieldOneDimensionTests.test_constructor)\nTests assigning an image field through the model's constructor. ... ok\ntest_create (model_fields.test_imagefield.ImageFieldOneDimensionTests.test_create)\nTests assigning an image in Manager.create(). ... ok\ntest_default_value (model_fields.test_imagefield.ImageFieldOneDimensionTests.test_default_value)\nThe default value for an ImageField is an instance of ... ok\ntest_dimensions (model_fields.test_imagefield.ImageFieldOneDimensionTests.test_dimensions)\nDimensions are updated correctly in various situations. ... ok\ntest_field_save_and_delete_methods (model_fields.test_imagefield.ImageFieldOneDimensionTests.test_field_save_and_delete_methods)\nTests assignment using the field's save method and deletion using ... ok\ntest_image_after_constructor (model_fields.test_imagefield.ImageFieldOneDimensionTests.test_image_after_constructor)\nTests behavior when image is not passed in constructor. ... ok\n\n======================================================================\nFAIL: test_post_init_not_connected (model_fields.test_imagefield.ImageFieldNoDimensionsTests.test_post_init_not_connected)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 57, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 623, in run\n    self._callTestMethod(testMethod)\n    ^^^^^^^^^^^^^^^^^\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 579, in _callTestMethod\n    if method() is not None:\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/tests/model_fields/test_imagefield.py\", line 334, in test_post_init_not_connected\n    self.assertNotIn(\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 1147, in assertNotIn\n    self.fail(self._formatMessage(msg, standardMsg))\n    ^^^^^^^^^^^^^^^^^\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 703, in fail\n    raise self.failureException(msg)\n    ^^^^^^^^^^^^^^^^^\nAssertionError: 49202736 unexpectedly found in [49202736, 49219184, 49227504, 48245360, 48259824, 48259824, 49451888, 49463504, 49987984, 50002672, 50018896, 50018896, 49698336, 50939184, 50952336, 50967024, 50983248, 50983248, 52692624, 52704240, 52717392, 52732080, 52748304, 52748304]\n\n----------------------------------------------------------------------\nRan 47 tests in 0.386s\n\nFAILED (failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 model_fields.test_imagefield` failed. (See above for error)",
          "test_files_run": [
            "tests/model_fields/test_imagefield.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 47,
          "failed": 0,
          "errors": 0,
          "duration": 5.68,
          "log_tail": "The default value for an ImageField is an instance of ... ok\ntest_dimensions (model_fields.test_imagefield.ImageFieldDimensionsFirstTests.test_dimensions)\nDimensions are updated correctly in various situations. ... ok\ntest_field_save_and_delete_methods (model_fields.test_imagefield.ImageFieldDimensionsFirstTests.test_field_save_and_delete_methods)\nTests assignment using the field's save method and deletion using ... ok\ntest_image_after_constructor (model_fields.test_imagefield.ImageFieldDimensionsFirstTests.test_image_after_constructor)\nTests behavior when image is not passed in constructor. ... ok\ntest_assignment_to_None (model_fields.test_imagefield.ImageFieldOneDimensionTests.test_assignment_to_None)\nAssigning ImageField to None clears dimensions. ... ok\ntest_constructor (model_fields.test_imagefield.ImageFieldOneDimensionTests.test_constructor)\nTests assigning an image field through the model's constructor. ... ok\ntest_create (model_fields.test_imagefield.ImageFieldOneDimensionTests.test_create)\nTests assigning an image in Manager.create(). ... ok\ntest_default_value (model_fields.test_imagefield.ImageFieldOneDimensionTests.test_default_value)\nThe default value for an ImageField is an instance of ... ok\ntest_dimensions (model_fields.test_imagefield.ImageFieldOneDimensionTests.test_dimensions)\nDimensions are updated correctly in various situations. ... ok\ntest_field_save_and_delete_methods (model_fields.test_imagefield.ImageFieldOneDimensionTests.test_field_save_and_delete_methods)\nTests assignment using the field's save method and deletion using ... ok\ntest_image_after_constructor (model_fields.test_imagefield.ImageFieldOneDimensionTests.test_image_after_constructor)\nTests behavior when image is not passed in constructor. ... ok\ntest_assignment_to_None (model_fields.test_imagefield.ImageFieldNoDimensionsTests.test_assignment_to_None)\nAssigning ImageField to None clears dimensions. ... ok\ntest_constructor (model_fields.test_imagefield.ImageFieldNoDimensionsTests.test_constructor)\nTests assigning an image field through the model's constructor. ... ok\ntest_create (model_fields.test_imagefield.ImageFieldNoDimensionsTests.test_create)\nTests assigning an image in Manager.create(). ... ok\ntest_default_value (model_fields.test_imagefield.ImageFieldNoDimensionsTests.test_default_value)\nThe default value for an ImageField is an instance of ... ok\ntest_dimensions (model_fields.test_imagefield.ImageFieldNoDimensionsTests.test_dimensions)\nDimensions are updated correctly in various situations. ... ok\ntest_field_save_and_delete_methods (model_fields.test_imagefield.ImageFieldNoDimensionsTests.test_field_save_and_delete_methods)\nTests assignment using the field's save method and deletion using ... ok\ntest_image_after_constructor (model_fields.test_imagefield.ImageFieldNoDimensionsTests.test_image_after_constructor)\nTests behavior when image is not passed in constructor. ... ok\ntest_post_init_not_connected (model_fields.test_imagefield.ImageFieldNoDimensionsTests.test_post_init_not_connected) ... ok\n\n----------------------------------------------------------------------\nRan 47 tests in 0.245s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/model_fields/test_imagefield.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-16819",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 12.928020000457764,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 38,
          "failed": 1,
          "errors": 0,
          "duration": 6.79,
          "log_tail": "test_create_model_reordering (migrations.test_optimizer.OptimizerTests.test_create_model_reordering)\nAddField optimizes into CreateModel if it's a FK to a model that's ... ok\ntest_create_model_reordering_circular_fk (migrations.test_optimizer.OptimizerTests.test_create_model_reordering_circular_fk)\nCreateModel reordering behavior doesn't result in an infinite loop if ... ok\ntest_create_rename_model (migrations.test_optimizer.OptimizerTests.test_create_rename_model)\nCreateModel should absorb RenameModels. ... ok\ntest_none_app_label (migrations.test_optimizer.OptimizerTests.test_none_app_label) ... ok\ntest_optimize_elidable_operation (migrations.test_optimizer.OptimizerTests.test_optimize_elidable_operation) ... ok\ntest_optimize_through_create (migrations.test_optimizer.OptimizerTests.test_optimize_through_create)\nWe should be able to optimize away create/delete through a create or ... ok\ntest_optimize_through_fields (migrations.test_optimizer.OptimizerTests.test_optimize_through_fields)\nfield-level through checking is working. This should manage to collapse ... ok\ntest_rename_index (migrations.test_optimizer.OptimizerTests.test_rename_index) ... ok\ntest_rename_model_self (migrations.test_optimizer.OptimizerTests.test_rename_model_self)\nRenameModels should absorb themselves. ... ok\ntest_single (migrations.test_optimizer.OptimizerTests.test_single)\nThe optimizer does nothing on a single operation, ... ok\ntest_swapping_fields_names (migrations.test_optimizer.OptimizerTests.test_swapping_fields_names) ... ok\n\n======================================================================\nFAIL: test_add_remove_index (migrations.test_optimizer.OptimizerTests.test_add_remove_index)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/migrations/test_optimizer.py\", line 1163, in test_add_remove_index\n    self.assertOptimizesTo(\n  File \"/testbed/tests/migrations/test_optimizer.py\", line 31, in assertOptimizesTo\n    self.assertEqual(expected, result)\nAssertionError: Lists differ: [] != [\"migrations.AddIndex(\\n    model_name='Po[173 chars]\\n)\"]\n\nSecond list contains 2 additional elements.\nFirst extra element 0:\n\"migrations.AddIndex(\\n    model_name='Pony',\\n    index=models.Index(fields=['weight', 'pink'], name='idx_pony_weight_pink'),\\n)\"\n\n- []\n+ ['migrations.AddIndex(\\n'\n+  \"    model_name='Pony',\\n\"\n+  \"    index=models.Index(fields=['weight', 'pink'], \"\n+  \"name='idx_pony_weight_pink'),\\n\"\n+  ')',\n+  'migrations.RemoveIndex(\\n'\n+  \"    model_name='Pony',\\n\"\n+  \"    name='idx_pony_weight_pink',\\n\"\n+  ')']\n\n----------------------------------------------------------------------\nRan 39 tests in 0.033s\n\nFAILED (failures=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 migrations.test_optimizer` failed. (See above for error)",
          "test_files_run": [
            "tests/migrations/test_optimizer.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 39,
          "failed": 0,
          "errors": 0,
          "duration": 5.12,
          "log_tail": "RenameField should optimize to the other side of AlterField, ... ok\ntest_create_alter_index_delete_model (migrations.test_optimizer.OptimizerTests.test_create_alter_index_delete_model) ... ok\ntest_create_alter_index_field (migrations.test_optimizer.OptimizerTests.test_create_alter_index_field) ... ok\ntest_create_alter_model_managers (migrations.test_optimizer.OptimizerTests.test_create_alter_model_managers) ... ok\ntest_create_alter_model_options (migrations.test_optimizer.OptimizerTests.test_create_alter_model_options) ... ok\ntest_create_alter_owrt_delete_model (migrations.test_optimizer.OptimizerTests.test_create_alter_owrt_delete_model) ... ok\ntest_create_alter_owrt_field (migrations.test_optimizer.OptimizerTests.test_create_alter_owrt_field) ... ok\ntest_create_alter_unique_delete_model (migrations.test_optimizer.OptimizerTests.test_create_alter_unique_delete_model) ... ok\ntest_create_alter_unique_field (migrations.test_optimizer.OptimizerTests.test_create_alter_unique_field) ... ok\ntest_create_delete_model (migrations.test_optimizer.OptimizerTests.test_create_delete_model)\nCreateModel and DeleteModel should collapse into nothing. ... ok\ntest_create_model_add_field (migrations.test_optimizer.OptimizerTests.test_create_model_add_field)\nAddField should optimize into CreateModel. ... ok\ntest_create_model_add_field_not_through_m2m_through (migrations.test_optimizer.OptimizerTests.test_create_model_add_field_not_through_m2m_through)\nAddField should NOT optimize into CreateModel if it's an M2M using a ... ok\ntest_create_model_alter_field (migrations.test_optimizer.OptimizerTests.test_create_model_alter_field)\nAlterField should optimize into CreateModel. ... ok\ntest_create_model_and_remove_model_options (migrations.test_optimizer.OptimizerTests.test_create_model_and_remove_model_options) ... ok\ntest_create_model_no_reordering_for_unrelated_fk (migrations.test_optimizer.OptimizerTests.test_create_model_no_reordering_for_unrelated_fk)\nCreateModel order remains unchanged if the later AddField operation ... ok\ntest_create_model_no_reordering_of_inherited_model (migrations.test_optimizer.OptimizerTests.test_create_model_no_reordering_of_inherited_model)\nA CreateModel that inherits from another isn't reordered to avoid ... ok\ntest_create_model_remove_field (migrations.test_optimizer.OptimizerTests.test_create_model_remove_field)\nRemoveField should optimize into CreateModel. ... ok\ntest_create_model_rename_field (migrations.test_optimizer.OptimizerTests.test_create_model_rename_field)\nRenameField should optimize into CreateModel. ... ok\ntest_create_model_reordering (migrations.test_optimizer.OptimizerTests.test_create_model_reordering)\nAddField optimizes into CreateModel if it's a FK to a model that's ... ok\ntest_create_model_reordering_circular_fk (migrations.test_optimizer.OptimizerTests.test_create_model_reordering_circular_fk)\nCreateModel reordering behavior doesn't result in an infinite loop if ... ok\ntest_create_rename_model (migrations.test_optimizer.OptimizerTests.test_create_rename_model)\nCreateModel should absorb RenameModels. ... ok\ntest_none_app_label (migrations.test_optimizer.OptimizerTests.test_none_app_label) ... ok\ntest_optimize_elidable_operation (migrations.test_optimizer.OptimizerTests.test_optimize_elidable_operation) ... ok\ntest_optimize_through_create (migrations.test_optimizer.OptimizerTests.test_optimize_through_create)\nWe should be able to optimize away create/delete through a create or ... ok\ntest_optimize_through_fields (migrations.test_optimizer.OptimizerTests.test_optimize_through_fields)\nfield-level through checking is working. This should manage to collapse ... ok\ntest_rename_index (migrations.test_optimizer.OptimizerTests.test_rename_index) ... ok\ntest_rename_model_self (migrations.test_optimizer.OptimizerTests.test_rename_model_self)\nRenameModels should absorb themselves. ... ok\ntest_single (migrations.test_optimizer.OptimizerTests.test_single)\nThe optimizer does nothing on a single operation, ... ok\ntest_swapping_fields_names (migrations.test_optimizer.OptimizerTests.test_swapping_fields_names) ... ok\n\n----------------------------------------------------------------------\nRan 39 tests in 0.020s\n\nOK\n",
          "test_files_run": [
            "tests/migrations/test_optimizer.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-16877",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 12.757335901260376,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 4,
          "duration": 6.14,
          "log_tail": "  File \"/testbed/django/template/engine.py\", line 189, in render_to_string\n    t = self.get_template(template_name)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/template/engine.py\", line 175, in get_template\n    template, origin = self.find_template(template_name)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/template/engine.py\", line 157, in find_template\n    template = loader.get_template(name, skip=skip)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/template/loaders/cached.py\", line 57, in get_template\n    template = super().get_template(template_name, skip)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/template/loaders/base.py\", line 28, in get_template\n    return Template(\n           ^^^^^^^^^\n  File \"/testbed/django/template/base.py\", line 154, in __init__\n    self.nodelist = self.compile_nodelist()\n                    ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/template/base.py\", line 196, in compile_nodelist\n    return parser.parse()\n           ^^^^^^^^^^^^^^\n  File \"/testbed/django/template/base.py\", line 510, in parse\n    raise self.error(token, e)\n  File \"/testbed/django/template/base.py\", line 508, in parse\n    compiled_result = compile_func(self, token)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/template/defaulttags.py\", line 564, in autoescape\n    nodelist = parser.parse((\"endautoescape\",))\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/template/base.py\", line 481, in parse\n    raise self.error(token, e)\n  File \"/testbed/django/template/base.py\", line 479, in parse\n    filter_expression = self.compile_filter(token.contents)\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/template/base.py\", line 597, in compile_filter\n    return FilterExpression(token, self)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/template/base.py\", line 693, in __init__\n    filter_func = parser.find_filter(filter_name)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/template/base.py\", line 603, in find_filter\n    raise TemplateSyntaxError(\"Invalid filter: '%s'\" % filter_name)\ndjango.template.exceptions.TemplateSyntaxError: Invalid filter: 'escapeseq'\n\n----------------------------------------------------------------------\nRan 4 tests in 0.009s\n\nFAILED (errors=4)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 template_tests.filter_tests.test_escapeseq` failed. (See above for error)",
          "test_files_run": [
            "tests/template_tests/filter_tests/test_escapeseq.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 4,
          "failed": 0,
          "errors": 0,
          "duration": 5.54,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application template_tests\nFound 4 test(s).\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_autoescape_off (template_tests.filter_tests.test_escapeseq.EscapeseqTests.test_autoescape_off) ... ok\ntest_basic (template_tests.filter_tests.test_escapeseq.EscapeseqTests.test_basic) ... ok\ntest_chain_join (template_tests.filter_tests.test_escapeseq.EscapeseqTests.test_chain_join) ... ok\ntest_chain_join_autoescape_off (template_tests.filter_tests.test_escapeseq.EscapeseqTests.test_chain_join_autoescape_off) ... ok\n\n----------------------------------------------------------------------\nRan 4 tests in 0.012s\n\nOK\n",
          "test_files_run": [
            "tests/template_tests/filter_tests/test_escapeseq.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-16899",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 13.080520868301392,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 54,
          "failed": 2,
          "errors": 0,
          "duration": 6.42,
          "log_tail": "The second fieldset's fields must be a list/tuple. ... ok\ntest_pk_not_editable (admin_checks.tests.SystemChecksTestCase.test_pk_not_editable) ... ok\ntest_readonly (admin_checks.tests.SystemChecksTestCase.test_readonly) ... ok\ntest_readonly_and_editable (admin_checks.tests.SystemChecksTestCase.test_readonly_and_editable) ... ok\ntest_readonly_dynamic_attribute_on_modeladmin (admin_checks.tests.SystemChecksTestCase.test_readonly_dynamic_attribute_on_modeladmin) ... ok\ntest_readonly_fields_not_list_or_tuple (admin_checks.tests.SystemChecksTestCase.test_readonly_fields_not_list_or_tuple) ... ok\ntest_readonly_lambda (admin_checks.tests.SystemChecksTestCase.test_readonly_lambda) ... ok\ntest_readonly_method_on_model (admin_checks.tests.SystemChecksTestCase.test_readonly_method_on_model) ... ok\ntest_readonly_on_method (admin_checks.tests.SystemChecksTestCase.test_readonly_on_method) ... ok\ntest_readonly_on_modeladmin (admin_checks.tests.SystemChecksTestCase.test_readonly_on_modeladmin) ... ok\ntest_several_templates_backends (admin_checks.tests.SystemChecksTestCase.test_several_templates_backends) ... ok\ntest_valid_generic_inline_model_admin (admin_checks.tests.SystemChecksTestCase.test_valid_generic_inline_model_admin)\nRegression test for #22034 - check that generic inlines don't look for ... ok\n\n======================================================================\nFAIL: test_nonexistent_field (admin_checks.tests.SystemChecksTestCase.test_nonexistent_field)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/admin_checks/tests.py\", line 808, in test_nonexistent_field\n    self.assertEqual(errors, expected)\nAssertionError: Lists differ: [<Err[48 chars][1]' is not a callable, an attribute of 'SongA[169 chars]35'>] != [<Err[48 chars][1]' refers to 'nonexistent', which is not a c[200 chars]35'>]\n\nFirst differing element 0:\n<Erro[47 chars][1]' is not a callable, an attribute of 'SongA[168 chars]035'>\n<Erro[47 chars][1]' refers to 'nonexistent', which is not a c[199 chars]035'>\n\nDiff is 754 characters long. Set self.maxDiff to None to see it.\n\n======================================================================\nFAIL: test_nonexistent_field_on_inline (admin_checks.tests.SystemChecksTestCase.test_nonexistent_field_on_inline)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/admin_checks/tests.py\", line 825, in test_nonexistent_field_on_inline\n    self.assertEqual(errors, expected)\nAssertionError: Lists differ: [<Err[48 chars][0]' is not a callable, an attribute of 'CityI[181 chars]35'>] != [<Err[48 chars][0]' refers to 'i_dont_exist', which is not a [213 chars]35'>]\n\nFirst differing element 0:\n<Erro[47 chars][0]' is not a callable, an attribute of 'CityI[180 chars]035'>\n<Erro[47 chars][0]' refers to 'i_dont_exist', which is not a [212 chars]035'>\n\nDiff is 780 characters long. Set self.maxDiff to None to see it.\n\n----------------------------------------------------------------------\nRan 56 tests in 0.050s\n\nFAILED (failures=2)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 admin_checks.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/admin_checks/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 56,
          "failed": 0,
          "errors": 0,
          "duration": 5.62,
          "log_tail": "test_generic_inline_model_admin_bad_fk_field (admin_checks.tests.SystemChecksTestCase.test_generic_inline_model_admin_bad_fk_field)\nA GenericInlineModelAdmin errors if the ct_fk_field points to a ... ok\ntest_generic_inline_model_admin_non_generic_model (admin_checks.tests.SystemChecksTestCase.test_generic_inline_model_admin_non_generic_model)\nA model without a GenericForeignKey raises problems if it's included ... ok\ntest_generic_inline_model_admin_non_gfk_ct_field (admin_checks.tests.SystemChecksTestCase.test_generic_inline_model_admin_non_gfk_ct_field)\nA GenericInlineModelAdmin raises problems if the ct_field points to a ... ok\ntest_generic_inline_model_admin_non_gfk_fk_field (admin_checks.tests.SystemChecksTestCase.test_generic_inline_model_admin_non_gfk_fk_field)\nA GenericInlineModelAdmin raises problems if the ct_fk_field points to ... ok\ntest_graceful_m2m_fail (admin_checks.tests.SystemChecksTestCase.test_graceful_m2m_fail)\nRegression test for #12203/#12237 - Fail more gracefully when a M2M field that ... ok\ntest_inline_self_check (admin_checks.tests.SystemChecksTestCase.test_inline_self_check) ... ok\ntest_inline_with_specified (admin_checks.tests.SystemChecksTestCase.test_inline_with_specified) ... ok\ntest_inlines_property (admin_checks.tests.SystemChecksTestCase.test_inlines_property) ... ok\ntest_list_editable_missing_field (admin_checks.tests.SystemChecksTestCase.test_list_editable_missing_field) ... ok\ntest_list_editable_not_a_list_or_tuple (admin_checks.tests.SystemChecksTestCase.test_list_editable_not_a_list_or_tuple) ... ok\ntest_list_filter_works_on_through_field_even_when_apps_not_ready (admin_checks.tests.SystemChecksTestCase.test_list_filter_works_on_through_field_even_when_apps_not_ready)\nEnsure list_filter can access reverse fields even when the app registry ... ok\ntest_middleware_dependencies (admin_checks.tests.SystemChecksTestCase.test_middleware_dependencies) ... ok\ntest_middleware_subclasses (admin_checks.tests.SystemChecksTestCase.test_middleware_subclasses) ... ok\ntest_nested_fields (admin_checks.tests.SystemChecksTestCase.test_nested_fields) ... ok\ntest_nested_fieldsets (admin_checks.tests.SystemChecksTestCase.test_nested_fieldsets) ... ok\ntest_no_template_engines (admin_checks.tests.SystemChecksTestCase.test_no_template_engines) ... ok\ntest_non_model_fields (admin_checks.tests.SystemChecksTestCase.test_non_model_fields)\nRegression for ensuring ModelAdmin.fields can contain non-model fields ... ok\ntest_non_model_first_field (admin_checks.tests.SystemChecksTestCase.test_non_model_first_field)\nRegression for ensuring ModelAdmin.field can handle first elem being a ... ok\ntest_nonexistent_field (admin_checks.tests.SystemChecksTestCase.test_nonexistent_field) ... ok\ntest_nonexistent_field_on_inline (admin_checks.tests.SystemChecksTestCase.test_nonexistent_field_on_inline) ... ok\ntest_nonfirst_fieldset (admin_checks.tests.SystemChecksTestCase.test_nonfirst_fieldset)\nThe second fieldset's fields must be a list/tuple. ... ok\ntest_pk_not_editable (admin_checks.tests.SystemChecksTestCase.test_pk_not_editable) ... ok\ntest_readonly (admin_checks.tests.SystemChecksTestCase.test_readonly) ... ok\ntest_readonly_and_editable (admin_checks.tests.SystemChecksTestCase.test_readonly_and_editable) ... ok\ntest_readonly_dynamic_attribute_on_modeladmin (admin_checks.tests.SystemChecksTestCase.test_readonly_dynamic_attribute_on_modeladmin) ... ok\ntest_readonly_fields_not_list_or_tuple (admin_checks.tests.SystemChecksTestCase.test_readonly_fields_not_list_or_tuple) ... ok\ntest_readonly_lambda (admin_checks.tests.SystemChecksTestCase.test_readonly_lambda) ... ok\ntest_readonly_method_on_model (admin_checks.tests.SystemChecksTestCase.test_readonly_method_on_model) ... ok\ntest_readonly_on_method (admin_checks.tests.SystemChecksTestCase.test_readonly_on_method) ... ok\ntest_readonly_on_modeladmin (admin_checks.tests.SystemChecksTestCase.test_readonly_on_modeladmin) ... ok\ntest_several_templates_backends (admin_checks.tests.SystemChecksTestCase.test_several_templates_backends) ... ok\ntest_valid_generic_inline_model_admin (admin_checks.tests.SystemChecksTestCase.test_valid_generic_inline_model_admin)\nRegression test for #22034 - check that generic inlines don't look for ... ok\n\n----------------------------------------------------------------------\nRan 56 tests in 0.037s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/admin_checks/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-16901",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 13.556962966918945,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 6,
          "failed": 1,
          "errors": 0,
          "duration": 6.13,
          "log_tail": "Found 7 test(s).\nSkipping setup of unused database(s): other.\nOperations to perform:\n  Synchronize unmigrated apps: auth, contenttypes, messages, sessions, staticfiles, xor_lookups\n  Apply all migrations: admin, sites\nSynchronizing apps without migrations:\n  Creating tables...\n    Creating table django_content_type\n    Creating table auth_permission\n    Creating table auth_group\n    Creating table auth_user\n    Creating table django_session\n    Creating table xor_lookups_number\n    Running deferred SQL...\nRunning migrations:\n  Applying admin.0001_initial... OK\n  Applying admin.0002_logentry_remove_auto_add... OK\n  Applying admin.0003_logentry_add_action_flag_choices... OK\n  Applying sites.0001_initial... OK\n  Applying sites.0002_alter_domain_unique... OK\nSystem check identified no issues (0 silenced).\n\n\nCreating test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\ntest_empty_in (xor_lookups.tests.XorLookupsTests.test_empty_in) ... ok\ntest_exclude (xor_lookups.tests.XorLookupsTests.test_exclude) ... ok\ntest_filter (xor_lookups.tests.XorLookupsTests.test_filter) ... ok\ntest_filter_multiple (xor_lookups.tests.XorLookupsTests.test_filter_multiple) ... FAIL\ntest_filter_negated (xor_lookups.tests.XorLookupsTests.test_filter_negated) ... ok\ntest_pk_q (xor_lookups.tests.XorLookupsTests.test_pk_q) ... ok\ntest_stages (xor_lookups.tests.XorLookupsTests.test_stages) ... ok\n\n======================================================================\nFAIL: test_filter_multiple (xor_lookups.tests.XorLookupsTests.test_filter_multiple)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/xor_lookups/tests.py\", line 30, in test_filter_multiple\n    self.assertCountEqual(\nAssertionError: Element counts were not equal:\nFirst has 0, Second has 1:  <Number: 5>\nFirst has 0, Second has 1:  <Number: 6>\nFirst has 0, Second has 1:  <Number: 9>\n\n----------------------------------------------------------------------\nRan 7 tests in 0.013s\n\nFAILED (failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 xor_lookups.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/xor_lookups/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 7,
          "failed": 0,
          "errors": 0,
          "duration": 5.37,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application xor_lookups\nFound 7 test(s).\nSkipping setup of unused database(s): other.\nOperations to perform:\n  Synchronize unmigrated apps: auth, contenttypes, messages, sessions, staticfiles, xor_lookups\n  Apply all migrations: admin, sites\nSynchronizing apps without migrations:\n  Creating tables...\n    Creating table django_content_type\n    Creating table auth_permission\n    Creating table auth_group\n    Creating table auth_user\n    Creating table django_session\n    Creating table xor_lookups_number\n    Running deferred SQL...\nRunning migrations:\n  Applying admin.0001_initial... OK\n  Applying admin.0002_logentry_remove_auto_add... OK\n  Applying admin.0003_logentry_add_action_flag_choices... OK\n  Applying sites.0001_initial... OK\n  Applying sites.0002_alter_domain_unique... OK\nSystem check identified no issues (0 silenced).\n\n\nCreating test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\ntest_empty_in (xor_lookups.tests.XorLookupsTests.test_empty_in) ... ok\ntest_exclude (xor_lookups.tests.XorLookupsTests.test_exclude) ... ok\ntest_filter (xor_lookups.tests.XorLookupsTests.test_filter) ... ok\ntest_filter_multiple (xor_lookups.tests.XorLookupsTests.test_filter_multiple) ... ok\ntest_filter_negated (xor_lookups.tests.XorLookupsTests.test_filter_negated) ... ok\ntest_pk_q (xor_lookups.tests.XorLookupsTests.test_pk_q) ... ok\ntest_stages (xor_lookups.tests.XorLookupsTests.test_stages) ... ok\n\n----------------------------------------------------------------------\nRan 7 tests in 0.014s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/xor_lookups/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-16938",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 14.061092853546143,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 94,
          "failed": 0,
          "errors": 41,
          "duration": 6.5,
          "log_tail": "  File \"/testbed/django/core/serializers/python.py\", line 88, in <listcomp>\n    self._current[field.name] = [m2m_value(related) for related in m2m_iter]\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 515, in _iterator\n    yield from iterable\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 90, in __iter__\n    results = compiler.execute_sql(\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1549, in execute_sql\n    sql, params = self.as_sql()\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 736, in as_sql\n    extra_select, order_by, group_by = self.pre_sql_setup(\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 84, in pre_sql_setup\n    self.setup_query(with_col_aliases=with_col_aliases)\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 73, in setup_query\n    self.select, self.klass_info, self.annotation_col_map = self.get_select(\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 279, in get_select\n    related_klass_infos = self.get_related_selections(select, select_mask)\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1211, in get_related_selections\n    if not select_related_descend(f, restricted, requested, select_mask):\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/query_utils.py\", line 347, in select_related_descend\n    raise FieldError(\ndjango.core.exceptions.FieldError: Field Topic.category cannot be both deferred and traversed using select_related at the same time.\n\n----------------------------------------------------------------------\nRan 135 tests in 0.175s\n\nFAILED (errors=41)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 serializers.models.base serializers.test_json serializers.test_jsonl serializers.test_xml serializers.test_yaml serializers.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/serializers/models/base.py",
            "tests/serializers/test_json.py",
            "tests/serializers/test_jsonl.py",
            "tests/serializers/test_xml.py",
            "tests/serializers/test_yaml.py",
            "tests/serializers/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 135,
          "failed": 0,
          "errors": 0,
          "duration": 6.47,
          "log_tail": "Year values before 1000AD are properly formatted ... ok\ntest_serialize (serializers.test_yaml.YamlSerializerTestCase.test_serialize)\nBasic serialization works. ... ok\ntest_serialize_field_subset (serializers.test_yaml.YamlSerializerTestCase.test_serialize_field_subset)\nOutput can be restricted to a subset of fields ... ok\ntest_serialize_inherited_fields (serializers.test_yaml.YamlSerializerTestCase.test_serialize_inherited_fields) ... ok\ntest_serialize_no_only_pk_with_natural_keys (serializers.test_yaml.YamlSerializerTestCase.test_serialize_no_only_pk_with_natural_keys) ... ok\ntest_serialize_only_pk (serializers.test_yaml.YamlSerializerTestCase.test_serialize_only_pk) ... ok\ntest_serialize_prefetch_related_m2m (serializers.test_yaml.YamlSerializerTestCase.test_serialize_prefetch_related_m2m) ... ok\ntest_serialize_progressbar (serializers.test_yaml.YamlSerializerTestCase.test_serialize_progressbar) ... ok\ntest_serialize_proxy_model (serializers.test_yaml.YamlSerializerTestCase.test_serialize_proxy_model) ... ok\ntest_serialize_specific_fields (serializers.test_yaml.YamlSerializerTestCase.test_serialize_specific_fields) ... ok\ntest_serialize_superfluous_queries (serializers.test_yaml.YamlSerializerTestCase.test_serialize_superfluous_queries)\nEnsure no superfluous queries are made when serializing ForeignKeys ... ok\ntest_serialize_to_stream (serializers.test_yaml.YamlSerializerTestCase.test_serialize_to_stream) ... ok\ntest_serialize_unicode_roundtrip (serializers.test_yaml.YamlSerializerTestCase.test_serialize_unicode_roundtrip)\nUnicode makes the roundtrip intact ... ok\ntest_serialize_with_null_pk (serializers.test_yaml.YamlSerializerTestCase.test_serialize_with_null_pk)\nSerialized data with no primary key results ... ok\ntest_serializer_roundtrip (serializers.test_yaml.YamlSerializerTestCase.test_serializer_roundtrip)\nSerialized content can be deserialized. ... ok\ntest_unicode_serialization (serializers.test_yaml.YamlSerializerTestCase.test_unicode_serialization) ... ok\ntest_yaml_deserializer_exception (serializers.test_yaml.YamlSerializerTestCase.test_yaml_deserializer_exception) ... ok\ntest_forward_refs (serializers.test_json.JsonSerializerTransactionTestCase.test_forward_refs)\nObjects ids can be referenced before they are ... ok\ntest_forward_refs (serializers.test_jsonl.JsonSerializerTransactionTestCase.test_forward_refs)\nObjects ids can be referenced before they are ... ok\ntest_forward_refs (serializers.test_xml.XmlSerializerTransactionTestCase.test_forward_refs)\nObjects ids can be referenced before they are ... ok\ntest_forward_refs (serializers.test_yaml.YamlSerializerTransactionTestCase.test_forward_refs)\nObjects ids can be referenced before they are ... ok\n\n----------------------------------------------------------------------\nRan 135 tests in 0.155s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/serializers/models/base.py",
            "tests/serializers/test_json.py",
            "tests/serializers/test_jsonl.py",
            "tests/serializers/test_xml.py",
            "tests/serializers/test_yaml.py",
            "tests/serializers/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-16950",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 12.31066608428955,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 6,
          "failed": 1,
          "errors": 0,
          "duration": 6.01,
          "log_tail": "    Creating table model_formsets_uuidpkparent\n    Creating table model_formsets_uuidpkchild\n    Creating table model_formsets_childwitheditablepk\n    Creating table model_formsets_autopkchildofuuidpkparent\n    Creating table model_formsets_autopkparent\n    Creating table model_formsets_uuidpkchildofautopkparent\n    Creating table model_formsets_parentwithuuidalternatekey\n    Creating table model_formsets_childrelatedviaak\n    Running deferred SQL...\nRunning migrations:\n  Applying admin.0001_initial... OK\n  Applying admin.0002_logentry_remove_auto_add... OK\n  Applying admin.0003_logentry_add_action_flag_choices... OK\n  Applying sites.0001_initial... OK\n  Applying sites.0002_alter_domain_unique... OK\nSystem check identified no issues (1 silenced).\n\n\nCreating test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\ntest_inlineformset_factory_ignores_default_pks_on_submit (model_formsets.test_uuid.InlineFormsetTests.test_inlineformset_factory_ignores_default_pks_on_submit)\n#24377 - Inlines with a model field default should ignore that default ... ok\ntest_inlineformset_factory_nulls_default_pks (model_formsets.test_uuid.InlineFormsetTests.test_inlineformset_factory_nulls_default_pks)\n#24377 - If we're adding a new object, a parent's auto-generated pk ... ok\ntest_inlineformset_factory_nulls_default_pks_alternate_key_relation (model_formsets.test_uuid.InlineFormsetTests.test_inlineformset_factory_nulls_default_pks_alternate_key_relation)\n#24958 - Variant of test_inlineformset_factory_nulls_default_pks for ... ok\ntest_inlineformset_factory_nulls_default_pks_alternate_key_relation_data (model_formsets.test_uuid.InlineFormsetTests.test_inlineformset_factory_nulls_default_pks_alternate_key_relation_data)\nIf form data is provided, a parent's auto-generated alternate key is ... FAIL\ntest_inlineformset_factory_nulls_default_pks_auto_parent_uuid_child (model_formsets.test_uuid.InlineFormsetTests.test_inlineformset_factory_nulls_default_pks_auto_parent_uuid_child)\n#24958 - Variant of test_inlineformset_factory_nulls_default_pks for ... ok\ntest_inlineformset_factory_nulls_default_pks_child_editable_pk (model_formsets.test_uuid.InlineFormsetTests.test_inlineformset_factory_nulls_default_pks_child_editable_pk)\n#24958 - Variant of test_inlineformset_factory_nulls_default_pks for ... ok\ntest_inlineformset_factory_nulls_default_pks_uuid_parent_auto_child (model_formsets.test_uuid.InlineFormsetTests.test_inlineformset_factory_nulls_default_pks_uuid_parent_auto_child)\n#24958 - Variant of test_inlineformset_factory_nulls_default_pks for ... ok\n\n======================================================================\nFAIL: test_inlineformset_factory_nulls_default_pks_alternate_key_relation_data (model_formsets.test_uuid.InlineFormsetTests.test_inlineformset_factory_nulls_default_pks_alternate_key_relation_data)\nIf form data is provided, a parent's auto-generated alternate key is\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/model_formsets/test_uuid.py\", line 116, in test_inlineformset_factory_nulls_default_pks_alternate_key_relation_data\n    self.assertIsNotNone(formset.instance.uuid)\nAssertionError: unexpectedly None\n\n----------------------------------------------------------------------\nRan 7 tests in 0.023s\n\nFAILED (failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 model_formsets.test_uuid` failed. (See above for error)",
          "test_files_run": [
            "tests/model_formsets/test_uuid.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 7,
          "failed": 0,
          "errors": 0,
          "duration": 5.29,
          "log_tail": "    Creating table model_formsets_classymexicanrestaurant\n    Creating table model_formsets_repository\n    Creating table model_formsets_revision\n    Creating table model_formsets_person\n    Creating table model_formsets_membership\n    Creating table model_formsets_team\n    Creating table model_formsets_player\n    Creating table model_formsets_poet\n    Creating table model_formsets_poem\n    Creating table model_formsets_post\n    Creating table model_formsets_uuidpkparent\n    Creating table model_formsets_uuidpkchild\n    Creating table model_formsets_childwitheditablepk\n    Creating table model_formsets_autopkchildofuuidpkparent\n    Creating table model_formsets_autopkparent\n    Creating table model_formsets_uuidpkchildofautopkparent\n    Creating table model_formsets_parentwithuuidalternatekey\n    Creating table model_formsets_childrelatedviaak\n    Running deferred SQL...\nRunning migrations:\n  Applying admin.0001_initial... OK\n  Applying admin.0002_logentry_remove_auto_add... OK\n  Applying admin.0003_logentry_add_action_flag_choices... OK\n  Applying sites.0001_initial... OK\n  Applying sites.0002_alter_domain_unique... OK\nSystem check identified no issues (1 silenced).\n\n\nCreating test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\ntest_inlineformset_factory_ignores_default_pks_on_submit (model_formsets.test_uuid.InlineFormsetTests.test_inlineformset_factory_ignores_default_pks_on_submit)\n#24377 - Inlines with a model field default should ignore that default ... ok\ntest_inlineformset_factory_nulls_default_pks (model_formsets.test_uuid.InlineFormsetTests.test_inlineformset_factory_nulls_default_pks)\n#24377 - If we're adding a new object, a parent's auto-generated pk ... ok\ntest_inlineformset_factory_nulls_default_pks_alternate_key_relation (model_formsets.test_uuid.InlineFormsetTests.test_inlineformset_factory_nulls_default_pks_alternate_key_relation)\n#24958 - Variant of test_inlineformset_factory_nulls_default_pks for ... ok\ntest_inlineformset_factory_nulls_default_pks_alternate_key_relation_data (model_formsets.test_uuid.InlineFormsetTests.test_inlineformset_factory_nulls_default_pks_alternate_key_relation_data)\nIf form data is provided, a parent's auto-generated alternate key is ... ok\ntest_inlineformset_factory_nulls_default_pks_auto_parent_uuid_child (model_formsets.test_uuid.InlineFormsetTests.test_inlineformset_factory_nulls_default_pks_auto_parent_uuid_child)\n#24958 - Variant of test_inlineformset_factory_nulls_default_pks for ... ok\ntest_inlineformset_factory_nulls_default_pks_child_editable_pk (model_formsets.test_uuid.InlineFormsetTests.test_inlineformset_factory_nulls_default_pks_child_editable_pk)\n#24958 - Variant of test_inlineformset_factory_nulls_default_pks for ... ok\ntest_inlineformset_factory_nulls_default_pks_uuid_parent_auto_child (model_formsets.test_uuid.InlineFormsetTests.test_inlineformset_factory_nulls_default_pks_uuid_parent_auto_child)\n#24958 - Variant of test_inlineformset_factory_nulls_default_pks for ... ok\n\n----------------------------------------------------------------------\nRan 7 tests in 0.010s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/model_formsets/test_uuid.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-17029",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 12.692210912704468,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 43,
          "failed": 1,
          "errors": 0,
          "duration": 5.99,
          "log_tail": "test_no_such_app_config (apps.tests.AppsTests.test_no_such_app_config) ... ok\ntest_no_such_app_config_with_choices (apps.tests.AppsTests.test_no_such_app_config_with_choices) ... ok\ntest_not_an_app_config (apps.tests.AppsTests.test_not_an_app_config)\nTests when INSTALLED_APPS contains a class that isn't an app config. ... ok\ntest_one_config_app (apps.tests.AppsTests.test_one_config_app)\nLoad an app that provides an AppConfig class. ... ok\ntest_ready (apps.tests.AppsTests.test_ready)\nTests the ready property of the main registry. ... ok\ntest_relabeling (apps.tests.AppsTests.test_relabeling) ... ok\ntest_singleton_main (apps.tests.AppsTests.test_singleton_main)\nOnly one main registry can exist. ... ok\ntest_two_configs_app (apps.tests.AppsTests.test_two_configs_app)\nLoad an app that provides two AppConfig classes. ... ok\ntest_two_configs_one_default_app (apps.tests.AppsTests.test_two_configs_one_default_app)\nLoad an app that provides two AppConfig classes, one being the default. ... ok\ntest_two_default_configs_app (apps.tests.AppsTests.test_two_default_configs_app)\nLoad an app that provides two default AppConfig classes. ... ok\n\n======================================================================\nFAIL: test_clear_cache (apps.tests.AppsTests.test_clear_cache)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 57, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 623, in run\n    self._callTestMethod(testMethod)\n    ^^^^^^^^^^^^^^^^^\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 579, in _callTestMethod\n    if method() is not None:\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/test/utils.py\", line 443, in inner\n    return func(*args, **kwargs)\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/tests/apps/tests.py\", line 208, in test_clear_cache\n    self.assertEqual(apps.get_swappable_settings_name.cache_info().currsize, 0)\n    ^^^^^^^^^^^^^^^^^\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 873, in assertEqual\n    assertion_func(first, second, msg=msg)\n    ^^^^^^^^^^^^^^^^^\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 866, in _baseAssertEqual\n    raise self.failureException(msg)\n    ^^^^^^^^^^^^^^^^^\nAssertionError: 1 != 0\n\n----------------------------------------------------------------------\nRan 44 tests in 0.083s\n\nFAILED (failures=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 apps.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/apps/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 44,
          "failed": 0,
          "errors": 0,
          "duration": 5.66,
          "log_tail": "test_duplicate_names (apps.tests.AppsTests.test_duplicate_names) ... ok\ntest_dynamic_load (apps.tests.AppsTests.test_dynamic_load)\nMakes a new model at runtime and ensures it goes into the right place. ... ok\ntest_get_app_config (apps.tests.AppsTests.test_get_app_config)\nTests apps.get_app_config(). ... ok\ntest_get_app_configs (apps.tests.AppsTests.test_get_app_configs)\nTests apps.get_app_configs(). ... ok\ntest_get_containing_app_config_apps_not_ready (apps.tests.AppsTests.test_get_containing_app_config_apps_not_ready)\napps.get_containing_app_config() should raise an exception if ... ok\ntest_get_model (apps.tests.AppsTests.test_get_model)\nTests apps.get_model(). ... ok\ntest_import_exception_is_not_masked (apps.tests.AppsTests.test_import_exception_is_not_masked)\nApp discovery should preserve stack traces. Regression test for #22920. ... ok\ntest_is_installed (apps.tests.AppsTests.test_is_installed)\nTests apps.is_installed(). ... ok\ntest_lazy_model_operation (apps.tests.AppsTests.test_lazy_model_operation)\nTests apps.lazy_model_operation(). ... ok\ntest_model_clash (apps.tests.AppsTests.test_model_clash)\nTest for behavior when two models clash in the app registry. ... ok\ntest_models_not_loaded (apps.tests.AppsTests.test_models_not_loaded)\napps.get_models() raises an exception if apps.models_ready isn't True. ... ok\ntest_models_py (apps.tests.AppsTests.test_models_py)\nThe models in the models.py file were loaded correctly. ... ok\ntest_no_config_app (apps.tests.AppsTests.test_no_config_app)\nLoad an app that doesn't provide an AppConfig class. ... ok\ntest_no_such_app (apps.tests.AppsTests.test_no_such_app)\nTests when INSTALLED_APPS contains an app that doesn't exist, either ... ok\ntest_no_such_app_config (apps.tests.AppsTests.test_no_such_app_config) ... ok\ntest_no_such_app_config_with_choices (apps.tests.AppsTests.test_no_such_app_config_with_choices) ... ok\ntest_not_an_app_config (apps.tests.AppsTests.test_not_an_app_config)\nTests when INSTALLED_APPS contains a class that isn't an app config. ... ok\ntest_one_config_app (apps.tests.AppsTests.test_one_config_app)\nLoad an app that provides an AppConfig class. ... ok\ntest_ready (apps.tests.AppsTests.test_ready)\nTests the ready property of the main registry. ... ok\ntest_relabeling (apps.tests.AppsTests.test_relabeling) ... ok\ntest_singleton_main (apps.tests.AppsTests.test_singleton_main)\nOnly one main registry can exist. ... ok\ntest_two_configs_app (apps.tests.AppsTests.test_two_configs_app)\nLoad an app that provides two AppConfig classes. ... ok\ntest_two_configs_one_default_app (apps.tests.AppsTests.test_two_configs_one_default_app)\nLoad an app that provides two AppConfig classes, one being the default. ... ok\ntest_two_default_configs_app (apps.tests.AppsTests.test_two_default_configs_app)\nLoad an app that provides two default AppConfig classes. ... ok\n\n----------------------------------------------------------------------\nRan 44 tests in 0.044s\n\nOK\n",
          "test_files_run": [
            "tests/apps/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-17084",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 12.760980367660522,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 107,
          "failed": 0,
          "errors": 1,
          "duration": 6.34,
          "log_tail": "  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 579, in _callTestMethod\n    if method() is not None:\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/test/testcases.py\", line 1428, in skip_wrapper\n    return test_func(*args, **kwargs)\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/tests/aggregation/tests.py\", line 2221, in test_referenced_window_requires_wrapping\n    aggregate = total_books_qs.aggregate(\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 584, in aggregate\n    return self.query.chain().get_aggregation(self.db, kwargs)\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/query.py\", line 556, in get_aggregation\n    result = compiler.execute_sql(SINGLE)\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1562, in execute_sql\n    cursor.execute(sql, params)\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/backends/utils.py\", line 102, in execute\n    return super().execute(sql, params)\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/backends/utils.py\", line 67, in execute\n    return self._execute_with_wrappers(\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/backends/utils.py\", line 80, in _execute_with_wrappers\n    return executor(sql, params, many, context)\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/backends/utils.py\", line 84, in _execute\n    with self.db.wrap_database_errors:\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/utils.py\", line 91, in __exit__\n    raise dj_exc_value.with_traceback(traceback) from exc_value\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/backends/utils.py\", line 89, in _execute\n    return self.cursor.execute(sql, params)\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/backends/sqlite3/base.py\", line 328, in execute\n    return super().execute(query, params)\n    ^^^^^^^^^^^^^^^^^\ndjango.db.utils.OperationalError: misuse of window function AVG()\n\n----------------------------------------------------------------------\nRan 108 tests in 0.212s\n\nFAILED (errors=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 aggregation.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/aggregation/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 108,
          "failed": 0,
          "errors": 0,
          "duration": 5.42,
          "log_tail": "test_empty_aggregate (aggregation.tests.AggregateTestCase.test_empty_aggregate) ... ok\ntest_empty_result_optimization (aggregation.tests.AggregateTestCase.test_empty_result_optimization) ... ok\ntest_even_more_aggregate (aggregation.tests.AggregateTestCase.test_even_more_aggregate) ... ok\ntest_exists_extra_where_with_aggregate (aggregation.tests.AggregateTestCase.test_exists_extra_where_with_aggregate) ... ok\ntest_exists_none_with_aggregate (aggregation.tests.AggregateTestCase.test_exists_none_with_aggregate) ... ok\ntest_expression_on_aggregation (aggregation.tests.AggregateTestCase.test_expression_on_aggregation) ... ok\ntest_filter_aggregate (aggregation.tests.AggregateTestCase.test_filter_aggregate) ... ok\ntest_filter_in_subquery_or_aggregation (aggregation.tests.AggregateTestCase.test_filter_in_subquery_or_aggregation)\nFiltering against an aggregate requires the usage of the HAVING clause. ... ok\ntest_filtering (aggregation.tests.AggregateTestCase.test_filtering) ... ok\ntest_fkey_aggregate (aggregation.tests.AggregateTestCase.test_fkey_aggregate) ... ok\ntest_group_by_exists_annotation (aggregation.tests.AggregateTestCase.test_group_by_exists_annotation)\nExists annotations are included in the GROUP BY if they are ... ok\ntest_group_by_nested_expression_with_params (aggregation.tests.AggregateTestCase.test_group_by_nested_expression_with_params) ... ok\ntest_group_by_subquery_annotation (aggregation.tests.AggregateTestCase.test_group_by_subquery_annotation)\nSubquery annotations are included in the GROUP BY if they are ... ok\ntest_grouped_annotation_in_group_by (aggregation.tests.AggregateTestCase.test_grouped_annotation_in_group_by)\nAn annotation included in values() before an aggregate should be ... ok\ntest_more_aggregation (aggregation.tests.AggregateTestCase.test_more_aggregation) ... ok\ntest_multi_arg_aggregate (aggregation.tests.AggregateTestCase.test_multi_arg_aggregate) ... ok\ntest_multiple_aggregate_references (aggregation.tests.AggregateTestCase.test_multiple_aggregate_references) ... ok\ntest_multiple_aggregates (aggregation.tests.AggregateTestCase.test_multiple_aggregates) ... ok\ntest_non_grouped_annotation_not_in_group_by (aggregation.tests.AggregateTestCase.test_non_grouped_annotation_not_in_group_by)\nAn annotation not included in values() before an aggregate should be ... ok\ntest_nonaggregate_aggregation_throws (aggregation.tests.AggregateTestCase.test_nonaggregate_aggregation_throws) ... ok\ntest_nonfield_annotation (aggregation.tests.AggregateTestCase.test_nonfield_annotation) ... ok\ntest_order_of_precedence (aggregation.tests.AggregateTestCase.test_order_of_precedence) ... ok\ntest_related_aggregate (aggregation.tests.AggregateTestCase.test_related_aggregate) ... ok\ntest_reverse_fkey_annotate (aggregation.tests.AggregateTestCase.test_reverse_fkey_annotate) ... ok\ntest_single_aggregate (aggregation.tests.AggregateTestCase.test_single_aggregate) ... ok\ntest_sum_distinct_aggregate (aggregation.tests.AggregateTestCase.test_sum_distinct_aggregate)\nSum on a distinct() QuerySet should aggregate only the distinct items. ... ok\ntest_sum_duration_field (aggregation.tests.AggregateTestCase.test_sum_duration_field) ... ok\ntest_ticket11881 (aggregation.tests.AggregateTestCase.test_ticket11881)\nSubqueries do not needlessly contain ORDER BY, SELECT FOR UPDATE or ... ok\ntest_ticket12886 (aggregation.tests.AggregateTestCase.test_ticket12886)\nAggregation over sliced queryset works correctly. ... ok\ntest_ticket17424 (aggregation.tests.AggregateTestCase.test_ticket17424)\nDoing exclude() on a foreign model after annotate() doesn't crash. ... ok\ntest_values_aggregation (aggregation.tests.AggregateTestCase.test_values_aggregation) ... ok\ntest_values_annotation_with_expression (aggregation.tests.AggregateTestCase.test_values_annotation_with_expression) ... ok\n\n----------------------------------------------------------------------\nRan 108 tests in 0.199s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/aggregation/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-17087",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 12.068673133850098,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 53,
          "failed": 1,
          "errors": 0,
          "duration": 5.76,
          "log_tail": "test_sorted_imports (migrations.test_writer.WriterTests.test_sorted_imports)\n#24155 - Tests ordering of imports. ... ok\n\n======================================================================\nFAIL: test_serialize_nested_class_method (migrations.test_writer.WriterTests.test_serialize_nested_class_method)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 57, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 623, in run\n    self._callTestMethod(testMethod)\n    ^^^^^^^^^^^^^^^^^\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 579, in _callTestMethod\n    if method() is not None:\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/tests/migrations/test_writer.py\", line 476, in test_serialize_nested_class_method\n    self.assertSerializedResultEqual(\n    ^^^^^^^^^^^^^^^^^\n  File \"/testbed/tests/migrations/test_writer.py\", line 241, in assertSerializedResultEqual\n    self.assertEqual(MigrationWriter.serialize(value), target)\n    ^^^^^^^^^^^^^^^^^\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 873, in assertEqual\n    assertion_func(first, second, msg=msg)\n    ^^^^^^^^^^^^^^^^^\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 1090, in assertTupleEqual\n    self.assertSequenceEqual(tuple1, tuple2, msg, seq_type=tuple)\n    ^^^^^^^^^^^^^^^^^\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 1061, in assertSequenceEqual\n    self.fail(msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.11/unittest/case.py\", line 703, in fail\n    raise self.failureException(msg)\n    ^^^^^^^^^^^^^^^^^\nAssertionError: Tuples differ: ('mig[15 chars]iter.NestedChoices.method', {'import migrations.test_writer'}) != ('mig[15 chars]iter.WriterTests.NestedChoices.method', {'impo[23 chars]er'})\n\nFirst differing element 0:\n'migrations.test_writer.NestedChoices.method'\n'migrations.test_writer.WriterTests.NestedChoices.method'\n\n- ('migrations.test_writer.NestedChoices.method',\n+ ('migrations.test_writer.WriterTests.NestedChoices.method',\n?                          ++++++++++++\n\n   {'import migrations.test_writer'})\n\n----------------------------------------------------------------------\nRan 54 tests in 0.068s\n\nFAILED (failures=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 migrations.test_writer` failed. (See above for error)",
          "test_files_run": [
            "tests/migrations/test_writer.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 54,
          "failed": 0,
          "errors": 0,
          "duration": 5.3,
          "log_tail": "test_serialize_choices (migrations.test_writer.WriterTests.test_serialize_choices) ... ok\ntest_serialize_class_based_validators (migrations.test_writer.WriterTests.test_serialize_class_based_validators)\nTicket #22943: Test serialization of class-based validators, including ... ok\ntest_serialize_collections (migrations.test_writer.WriterTests.test_serialize_collections) ... ok\ntest_serialize_compiled_regex (migrations.test_writer.WriterTests.test_serialize_compiled_regex)\nMake sure compiled regex can be serialized. ... ok\ntest_serialize_complex_func_index (migrations.test_writer.WriterTests.test_serialize_complex_func_index) ... ok\ntest_serialize_constants (migrations.test_writer.WriterTests.test_serialize_constants) ... ok\ntest_serialize_datetime (migrations.test_writer.WriterTests.test_serialize_datetime) ... ok\ntest_serialize_empty_nonempty_tuple (migrations.test_writer.WriterTests.test_serialize_empty_nonempty_tuple)\nTicket #22679: makemigrations generates invalid code for (an empty ... ok\ntest_serialize_enum_flags (migrations.test_writer.WriterTests.test_serialize_enum_flags) ... ok\ntest_serialize_enums (migrations.test_writer.WriterTests.test_serialize_enums) ... ok\ntest_serialize_fields (migrations.test_writer.WriterTests.test_serialize_fields) ... ok\ntest_serialize_frozensets (migrations.test_writer.WriterTests.test_serialize_frozensets) ... ok\ntest_serialize_functions (migrations.test_writer.WriterTests.test_serialize_functions) ... ok\ntest_serialize_functools_partial (migrations.test_writer.WriterTests.test_serialize_functools_partial) ... ok\ntest_serialize_functools_partialmethod (migrations.test_writer.WriterTests.test_serialize_functools_partialmethod) ... ok\ntest_serialize_iterators (migrations.test_writer.WriterTests.test_serialize_iterators) ... ok\ntest_serialize_lazy_objects (migrations.test_writer.WriterTests.test_serialize_lazy_objects) ... ok\ntest_serialize_local_function_reference (migrations.test_writer.WriterTests.test_serialize_local_function_reference)\nA reference in a local scope can't be serialized. ... ok\ntest_serialize_managers (migrations.test_writer.WriterTests.test_serialize_managers) ... ok\ntest_serialize_multiline_strings (migrations.test_writer.WriterTests.test_serialize_multiline_strings) ... ok\ntest_serialize_nested_class (migrations.test_writer.WriterTests.test_serialize_nested_class) ... ok\ntest_serialize_nested_class_method (migrations.test_writer.WriterTests.test_serialize_nested_class_method) ... ok\ntest_serialize_numbers (migrations.test_writer.WriterTests.test_serialize_numbers) ... ok\ntest_serialize_path_like (migrations.test_writer.WriterTests.test_serialize_path_like) ... ok\ntest_serialize_pathlib (migrations.test_writer.WriterTests.test_serialize_pathlib) ... ok\ntest_serialize_range (migrations.test_writer.WriterTests.test_serialize_range) ... ok\ntest_serialize_set (migrations.test_writer.WriterTests.test_serialize_set) ... ok\ntest_serialize_settings (migrations.test_writer.WriterTests.test_serialize_settings) ... ok\ntest_serialize_strings (migrations.test_writer.WriterTests.test_serialize_strings) ... ok\ntest_serialize_timedelta (migrations.test_writer.WriterTests.test_serialize_timedelta) ... ok\ntest_serialize_type_model (migrations.test_writer.WriterTests.test_serialize_type_model) ... ok\ntest_serialize_type_none (migrations.test_writer.WriterTests.test_serialize_type_none) ... ok\ntest_serialize_unbound_method_reference (migrations.test_writer.WriterTests.test_serialize_unbound_method_reference)\nAn unbound method used within a class body can be serialized. ... ok\ntest_serialize_uuid (migrations.test_writer.WriterTests.test_serialize_uuid) ... ok\ntest_simple_migration (migrations.test_writer.WriterTests.test_simple_migration)\nTests serializing a simple migration. ... ok\ntest_sorted_dependencies (migrations.test_writer.WriterTests.test_sorted_dependencies) ... ok\ntest_sorted_imports (migrations.test_writer.WriterTests.test_sorted_imports)\n#24155 - Tests ordering of imports. ... ok\n\n----------------------------------------------------------------------\nRan 54 tests in 0.053s\n\nOK\n",
          "test_files_run": [
            "tests/migrations/test_writer.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-7530",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 13.320494174957275,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 62,
          "failed": 0,
          "errors": 1,
          "duration": 6.19,
          "log_tail": "test_makemigrations_no_changes_no_apps (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_no_common_ancestor (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_non_interactive_no_field_rename (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_non_interactive_no_model_rename (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_non_interactive_not_null_addition (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_non_interactive_not_null_alteration (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_order (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_unspecified_app_with_conflict_merge (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_unspecified_app_with_conflict_no_merge (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_with_custom_name (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_migrate (migrations.test_commands.MigrateTests) ... ok\ntest_migrate_conflict_exit (migrations.test_commands.MigrateTests) ... ok\ntest_migrate_fake_initial (migrations.test_commands.MigrateTests) ... ok\ntest_migrate_fake_split_initial (migrations.test_commands.MigrateTests) ... ok\ntest_migrate_inconsistent_history (migrations.test_commands.MigrateTests) ... ok\ntest_migrate_initial_false (migrations.test_commands.MigrateTests) ... ok\ntest_migrate_record_replaced (migrations.test_commands.MigrateTests) ... ok\ntest_migrate_record_squashed (migrations.test_commands.MigrateTests) ... ok\ntest_migrate_with_system_checks (migrations.test_commands.MigrateTests) ... ok\ntest_regression_22823_unmigrated_fk_to_migrated_model (migrations.test_commands.MigrateTests) ... ok\ntest_showmigrations_list (migrations.test_commands.MigrateTests) ... ok\ntest_showmigrations_plan (migrations.test_commands.MigrateTests) ... ok\ntest_showmigrations_plan_no_migrations (migrations.test_commands.MigrateTests) ... ok\ntest_showmigrations_plan_squashed (migrations.test_commands.MigrateTests) ... ok\ntest_sqlmigrate_backwards (migrations.test_commands.MigrateTests) ... ok\ntest_sqlmigrate_for_non_atomic_migration (migrations.test_commands.MigrateTests) ... ok\ntest_sqlmigrate_forwards (migrations.test_commands.MigrateTests) ... ok\n\n======================================================================\nERROR: test_makemigrations_consistency_checks_respect_routers (migrations.test_commands.MakeMigrationsTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.5/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.5/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/django/test/utils.py\", line 378, in inner\n    return func(*args, **kwargs)\n  File \"/testbed/tests/migrations/test_commands.py\", line 650, in test_makemigrations_consistency_checks_respect_routers\n    apps.get_app_config(app_name).get_model(call_kwargs['model_name'])\n  File \"/testbed/django/apps/config.py\", line 172, in get_model\n    \"App '%s' doesn't have a '%s' model.\" % (self.label, model_name))\nLookupError: App 'migrations2' doesn't have a 'ModelWithCustomBase' model.\n\n----------------------------------------------------------------------\nRan 63 tests in 0.741s\n\nFAILED (errors=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 migrations.test_commands` failed. (See above for error)",
          "test_files_run": [
            "tests/migrations/test_commands.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 63,
          "failed": 0,
          "errors": 0,
          "duration": 6.16,
          "log_tail": "test_makemigrations_empty_migration (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_empty_no_app_specified (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_exit (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_handle_merge (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_inconsistent_history (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_interactive_accept (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_interactive_by_default (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_interactive_reject (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_merge_dont_output_dependency_operations (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_merge_no_conflict (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_migration_path_output (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_migration_path_output_valueerror (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_migrations_announce (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_migrations_modules_path_not_exist (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_no_app_sys_exit (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_no_apps_initial (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_no_changes (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_no_changes_no_apps (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_no_common_ancestor (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_non_interactive_no_field_rename (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_non_interactive_no_model_rename (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_non_interactive_not_null_addition (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_non_interactive_not_null_alteration (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_order (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_unspecified_app_with_conflict_merge (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_unspecified_app_with_conflict_no_merge (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_makemigrations_with_custom_name (migrations.test_commands.MakeMigrationsTests) ... ok\ntest_migrate (migrations.test_commands.MigrateTests) ... ok\ntest_migrate_conflict_exit (migrations.test_commands.MigrateTests) ... ok\ntest_migrate_fake_initial (migrations.test_commands.MigrateTests) ... ok\ntest_migrate_fake_split_initial (migrations.test_commands.MigrateTests) ... ok\ntest_migrate_inconsistent_history (migrations.test_commands.MigrateTests) ... ok\ntest_migrate_initial_false (migrations.test_commands.MigrateTests) ... ok\ntest_migrate_record_replaced (migrations.test_commands.MigrateTests) ... ok\ntest_migrate_record_squashed (migrations.test_commands.MigrateTests) ... ok\ntest_migrate_with_system_checks (migrations.test_commands.MigrateTests) ... ok\ntest_regression_22823_unmigrated_fk_to_migrated_model (migrations.test_commands.MigrateTests) ... ok\ntest_showmigrations_list (migrations.test_commands.MigrateTests) ... ok\ntest_showmigrations_plan (migrations.test_commands.MigrateTests) ... ok\ntest_showmigrations_plan_no_migrations (migrations.test_commands.MigrateTests) ... ok\ntest_showmigrations_plan_squashed (migrations.test_commands.MigrateTests) ... ok\ntest_sqlmigrate_backwards (migrations.test_commands.MigrateTests) ... ok\ntest_sqlmigrate_for_non_atomic_migration (migrations.test_commands.MigrateTests) ... ok\ntest_sqlmigrate_forwards (migrations.test_commands.MigrateTests) ... ok\n\n----------------------------------------------------------------------\nRan 63 tests in 0.821s\n\nOK\n",
          "test_files_run": [
            "tests/migrations/test_commands.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-9296",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 12.274374961853027,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 20,
          "failed": 0,
          "errors": 1,
          "duration": 5.71,
          "log_tail": "System check identified no issues (0 silenced).\n\n\nCreating test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\ntest_count_does_not_silence_attribute_error (pagination.tests.PaginationTests) ... ok\ntest_count_does_not_silence_type_error (pagination.tests.PaginationTests) ... ok\ntest_float_integer_page (pagination.tests.PaginationTests) ... ok\ntest_get_page (pagination.tests.PaginationTests) ... ok\ntest_get_page_empty_object_list (pagination.tests.PaginationTests)\nPaginator.get_page() with an empty object_list. ... ok\ntest_get_page_empty_object_list_and_allow_empty_first_page_false (pagination.tests.PaginationTests) ... ok\ntest_get_page_hook (pagination.tests.PaginationTests) ... ok\ntest_invalid_page_number (pagination.tests.PaginationTests) ... ok\ntest_no_content_allow_empty_first_page (pagination.tests.PaginationTests) ... ok\ntest_page_indexes (pagination.tests.PaginationTests) ... ok\ntest_page_range_iterator (pagination.tests.PaginationTests) ... ok\ntest_page_sequence (pagination.tests.PaginationTests) ... ok\ntest_paginate_misc_classes (pagination.tests.PaginationTests) ... ok\ntest_paginator (pagination.tests.PaginationTests) ... ok\ntest_paginator_iteration (pagination.tests.PaginationTests) ... ERROR\ntest_first_page (pagination.tests.ModelPaginationTests) ... ok\ntest_last_page (pagination.tests.ModelPaginationTests) ... ok\ntest_page_getitem (pagination.tests.ModelPaginationTests) ... ok\ntest_paginating_empty_queryset_does_not_warn (pagination.tests.ModelPaginationTests) ... ok\ntest_paginating_unordered_object_list_raises_warning (pagination.tests.ModelPaginationTests) ... ok\ntest_paginating_unordered_queryset_raises_warning (pagination.tests.ModelPaginationTests) ... ok\n\n======================================================================\nERROR: test_paginator_iteration (pagination.tests.PaginationTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/pagination/tests.py\", line 302, in test_paginator_iteration\n    page_iterator = iter(paginator)\nTypeError: 'Paginator' object is not iterable\n\n----------------------------------------------------------------------\nRan 21 tests in 0.219s\n\nFAILED (errors=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 pagination.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/pagination/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 21,
          "failed": 0,
          "errors": 0,
          "duration": 5.54,
          "log_tail": "    Creating table django_content_type\n    Creating table auth_permission\n    Creating table auth_group\n    Creating table auth_user\n    Creating table django_session\n    Creating table pagination_article\n    Running deferred SQL...\nRunning migrations:\n  Applying admin.0001_initial... OK\n  Applying admin.0002_logentry_remove_auto_add... OK\n  Applying admin.0003_logentry_add_action_flag_choices... OK\n  Applying sites.0001_initial... OK\n  Applying sites.0002_alter_domain_unique... OK\nSystem check identified no issues (0 silenced).\n\n\nCreating test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\ntest_count_does_not_silence_attribute_error (pagination.tests.PaginationTests) ... ok\ntest_count_does_not_silence_type_error (pagination.tests.PaginationTests) ... ok\ntest_float_integer_page (pagination.tests.PaginationTests) ... ok\ntest_get_page (pagination.tests.PaginationTests) ... ok\ntest_get_page_empty_object_list (pagination.tests.PaginationTests)\nPaginator.get_page() with an empty object_list. ... ok\ntest_get_page_empty_object_list_and_allow_empty_first_page_false (pagination.tests.PaginationTests) ... ok\ntest_get_page_hook (pagination.tests.PaginationTests) ... ok\ntest_invalid_page_number (pagination.tests.PaginationTests) ... ok\ntest_no_content_allow_empty_first_page (pagination.tests.PaginationTests) ... ok\ntest_page_indexes (pagination.tests.PaginationTests) ... ok\ntest_page_range_iterator (pagination.tests.PaginationTests) ... ok\ntest_page_sequence (pagination.tests.PaginationTests) ... ok\ntest_paginate_misc_classes (pagination.tests.PaginationTests) ... ok\ntest_paginator (pagination.tests.PaginationTests) ... ok\ntest_paginator_iteration (pagination.tests.PaginationTests) ... ok\ntest_first_page (pagination.tests.ModelPaginationTests) ... ok\ntest_last_page (pagination.tests.ModelPaginationTests) ... ok\ntest_page_getitem (pagination.tests.ModelPaginationTests) ... ok\ntest_paginating_empty_queryset_does_not_warn (pagination.tests.ModelPaginationTests) ... ok\ntest_paginating_unordered_object_list_raises_warning (pagination.tests.ModelPaginationTests) ... ok\ntest_paginating_unordered_queryset_raises_warning (pagination.tests.ModelPaginationTests) ... ok\n\n----------------------------------------------------------------------\nRan 21 tests in 0.242s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/pagination/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-11618",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 17.29052996635437,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 6,
          "failed": 1,
          "errors": 0,
          "collected": 7,
          "duration": 7.26,
          "log_tail": "sympy/solvers/solveset.py:738\n  /testbed/sympy/solvers/solveset.py:738: DeprecationWarning: invalid escape sequence \\_\n    \"\"\"Solves a given inequality or equation with set as output\n\nsympy/calculus/util.py:458\n  /testbed/sympy/calculus/util.py:458: DeprecationWarning: invalid escape sequence \\l\n    \"\"\"\n\nsympy/solvers/recurr.py:1\n  /testbed/sympy/solvers/recurr.py:1: DeprecationWarning: invalid escape sequence \\d\n    \"\"\"\n\nsympy/solvers/recurr.py:72\n  /testbed/sympy/solvers/recurr.py:72: DeprecationWarning: invalid escape sequence \\o\n    \"\"\"\n\nsympy/solvers/recurr.py:350\n  /testbed/sympy/solvers/recurr.py:350: DeprecationWarning: invalid escape sequence \\o\n    \"\"\"\n\nsympy/solvers/recurr.py:461\n  /testbed/sympy/solvers/recurr.py:461: DeprecationWarning: invalid escape sequence \\o\n    \"\"\"\n\nsympy/solvers/recurr.py:663\n  /testbed/sympy/solvers/recurr.py:663: DeprecationWarning: invalid escape sequence \\o\n    \"\"\"\n\nsympy/calculus/finite_diff.py:420\n  /testbed/sympy/calculus/finite_diff.py:420: DeprecationWarning: invalid escape sequence \\*\n    \"\"\" Differentiate expr and replace Derivatives with finite differences.\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\nsympy/interactive/printing.py:245\n  /testbed/sympy/interactive/printing.py:245: DeprecationWarning: invalid escape sequence \\/\n    \"\"\"\n\nsympy/interactive/session.py:316\n  /testbed/sympy/interactive/session.py:316: DeprecationWarning: invalid escape sequence \\/\n    \"\"\"\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 1 failed, 6 passed, 96 warnings in 0.75s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/geometry/tests/test_point.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/geometry/tests/test_point.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 7,
          "failed": 0,
          "errors": 0,
          "collected": 7,
          "duration": 8.69,
          "log_tail": "    \"\"\"\n\nsympy/solvers/solveset.py:738\n  /testbed/sympy/solvers/solveset.py:738: DeprecationWarning: invalid escape sequence \\_\n    \"\"\"Solves a given inequality or equation with set as output\n\nsympy/calculus/util.py:458\n  /testbed/sympy/calculus/util.py:458: DeprecationWarning: invalid escape sequence \\l\n    \"\"\"\n\nsympy/solvers/recurr.py:1\n  /testbed/sympy/solvers/recurr.py:1: DeprecationWarning: invalid escape sequence \\d\n    \"\"\"\n\nsympy/solvers/recurr.py:72\n  /testbed/sympy/solvers/recurr.py:72: DeprecationWarning: invalid escape sequence \\o\n    \"\"\"\n\nsympy/solvers/recurr.py:350\n  /testbed/sympy/solvers/recurr.py:350: DeprecationWarning: invalid escape sequence \\o\n    \"\"\"\n\nsympy/solvers/recurr.py:461\n  /testbed/sympy/solvers/recurr.py:461: DeprecationWarning: invalid escape sequence \\o\n    \"\"\"\n\nsympy/solvers/recurr.py:663\n  /testbed/sympy/solvers/recurr.py:663: DeprecationWarning: invalid escape sequence \\o\n    \"\"\"\n\nsympy/calculus/finite_diff.py:420\n  /testbed/sympy/calculus/finite_diff.py:420: DeprecationWarning: invalid escape sequence \\*\n    \"\"\" Differentiate expr and replace Derivatives with finite differences.\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\nsympy/interactive/printing.py:245\n  /testbed/sympy/interactive/printing.py:245: DeprecationWarning: invalid escape sequence \\/\n    \"\"\"\n\nsympy/interactive/session.py:316\n  /testbed/sympy/interactive/session.py:316: DeprecationWarning: invalid escape sequence \\/\n    \"\"\"\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================== 7 passed, 96 warnings in 0.78s ========================\n\n",
          "test_files_run": [
            "sympy/geometry/tests/test_point.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-12096",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://35.239.238.137:8080",
      "duration": 19.10926389694214,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 44,
          "failed": 27,
          "errors": 0,
          "collected": 71,
          "duration": 8.04,
          "log_tail": "sympy/solvers/solveset.py:738\n  /testbed/sympy/solvers/solveset.py:738: DeprecationWarning: invalid escape sequence \\_\n    \"\"\"Solves a given inequality or equation with set as output\n\nsympy/calculus/util.py:458\n  /testbed/sympy/calculus/util.py:458: DeprecationWarning: invalid escape sequence \\l\n    \"\"\"\n\nsympy/solvers/recurr.py:1\n  /testbed/sympy/solvers/recurr.py:1: DeprecationWarning: invalid escape sequence \\l\n    \"\"\"\n\nsympy/solvers/recurr.py:72\n  /testbed/sympy/solvers/recurr.py:72: DeprecationWarning: invalid escape sequence \\o\n    \"\"\"\n\nsympy/solvers/recurr.py:350\n  /testbed/sympy/solvers/recurr.py:350: DeprecationWarning: invalid escape sequence \\o\n    \"\"\"\n\nsympy/solvers/recurr.py:461\n  /testbed/sympy/solvers/recurr.py:461: DeprecationWarning: invalid escape sequence \\o\n    \"\"\"\n\nsympy/solvers/recurr.py:663\n  /testbed/sympy/solvers/recurr.py:663: DeprecationWarning: invalid escape sequence \\o\n    \"\"\"\n\nsympy/calculus/finite_diff.py:420\n  /testbed/sympy/calculus/finite_diff.py:420: DeprecationWarning: invalid escape sequence \\*\n    \"\"\" Differentiate expr and replace Derivatives with finite differences.\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\nsympy/interactive/printing.py:245\n  /testbed/sympy/interactive/printing.py:245: DeprecationWarning: invalid escape sequence \\/\n    \"\"\"\n\nsympy/interactive/session.py:316\n  /testbed/sympy/interactive/session.py:316: DeprecationWarning: invalid escape sequence \\/\n    \"\"\"\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n================== 27 failed, 44 passed, 97 warnings in 1.24s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/utilities/tests/test_lambdify.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/utilities/tests/test_lambdify.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 45,
          "failed": 26,
          "errors": 0,
          "collected": 71,
          "duration": 9.83,
          "log_tail": "sympy/solvers/solveset.py:738\n  /testbed/sympy/solvers/solveset.py:738: DeprecationWarning: invalid escape sequence \\_\n    \"\"\"Solves a given inequality or equation with set as output\n\nsympy/calculus/util.py:458\n  /testbed/sympy/calculus/util.py:458: DeprecationWarning: invalid escape sequence \\l\n    \"\"\"\n\nsympy/solvers/recurr.py:1\n  /testbed/sympy/solvers/recurr.py:1: DeprecationWarning: invalid escape sequence \\l\n    \"\"\"\n\nsympy/solvers/recurr.py:72\n  /testbed/sympy/solvers/recurr.py:72: DeprecationWarning: invalid escape sequence \\o\n    \"\"\"\n\nsympy/solvers/recurr.py:350\n  /testbed/sympy/solvers/recurr.py:350: DeprecationWarning: invalid escape sequence \\o\n    \"\"\"\n\nsympy/solvers/recurr.py:461\n  /testbed/sympy/solvers/recurr.py:461: DeprecationWarning: invalid escape sequence \\o\n    \"\"\"\n\nsympy/solvers/recurr.py:663\n  /testbed/sympy/solvers/recurr.py:663: DeprecationWarning: invalid escape sequence \\o\n    \"\"\"\n\nsympy/calculus/finite_diff.py:420\n  /testbed/sympy/calculus/finite_diff.py:420: DeprecationWarning: invalid escape sequence \\*\n    \"\"\" Differentiate expr and replace Derivatives with finite differences.\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\nsympy/interactive/printing.py:245\n  /testbed/sympy/interactive/printing.py:245: DeprecationWarning: invalid escape sequence \\/\n    \"\"\"\n\nsympy/interactive/session.py:316\n  /testbed/sympy/interactive/session.py:316: DeprecationWarning: invalid escape sequence \\/\n    \"\"\"\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n================== 26 failed, 45 passed, 97 warnings in 1.46s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/utilities/tests/test_lambdify.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/utilities/tests/test_lambdify.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sympy__sympy-12419",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 18.176512002944946,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 26,
          "failed": 1,
          "errors": 0,
          "collected": 27,
          "duration": 7.74,
          "log_tail": "sympy/solvers/solveset.py:760\n  /testbed/sympy/solvers/solveset.py:760: DeprecationWarning: invalid escape sequence \\_\n    \"\"\"Solves a given inequality or equation with set as output\n\nsympy/calculus/util.py:462\n  /testbed/sympy/calculus/util.py:462: DeprecationWarning: invalid escape sequence \\l\n    \"\"\"\n\nsympy/solvers/recurr.py:1\n  /testbed/sympy/solvers/recurr.py:1: DeprecationWarning: invalid escape sequence \\l\n    \"\"\"\n\nsympy/solvers/recurr.py:72\n  /testbed/sympy/solvers/recurr.py:72: DeprecationWarning: invalid escape sequence \\o\n    \"\"\"\n\nsympy/solvers/recurr.py:350\n  /testbed/sympy/solvers/recurr.py:350: DeprecationWarning: invalid escape sequence \\o\n    \"\"\"\n\nsympy/solvers/recurr.py:461\n  /testbed/sympy/solvers/recurr.py:461: DeprecationWarning: invalid escape sequence \\o\n    \"\"\"\n\nsympy/solvers/recurr.py:663\n  /testbed/sympy/solvers/recurr.py:663: DeprecationWarning: invalid escape sequence \\o\n    \"\"\"\n\nsympy/calculus/finite_diff.py:420\n  /testbed/sympy/calculus/finite_diff.py:420: DeprecationWarning: invalid escape sequence \\*\n    \"\"\" Differentiate expr and replace Derivatives with finite differences.\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\nsympy/interactive/printing.py:251\n  /testbed/sympy/interactive/printing.py:251: DeprecationWarning: invalid escape sequence \\/\n    \"\"\"\n\nsympy/interactive/session.py:316\n  /testbed/sympy/interactive/session.py:316: DeprecationWarning: invalid escape sequence \\/\n    \"\"\"\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n================== 1 failed, 26 passed, 97 warnings in 0.64s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/matrices/expressions/tests/test_matexpr.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/matrices/expressions/tests/test_matexpr.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 27,
          "failed": 0,
          "errors": 0,
          "collected": 27,
          "duration": 9.31,
          "log_tail": "    \"\"\"\n\nsympy/solvers/solveset.py:760\n  /testbed/sympy/solvers/solveset.py:760: DeprecationWarning: invalid escape sequence \\_\n    \"\"\"Solves a given inequality or equation with set as output\n\nsympy/calculus/util.py:462\n  /testbed/sympy/calculus/util.py:462: DeprecationWarning: invalid escape sequence \\l\n    \"\"\"\n\nsympy/solvers/recurr.py:1\n  /testbed/sympy/solvers/recurr.py:1: DeprecationWarning: invalid escape sequence \\l\n    \"\"\"\n\nsympy/solvers/recurr.py:72\n  /testbed/sympy/solvers/recurr.py:72: DeprecationWarning: invalid escape sequence \\o\n    \"\"\"\n\nsympy/solvers/recurr.py:350\n  /testbed/sympy/solvers/recurr.py:350: DeprecationWarning: invalid escape sequence \\o\n    \"\"\"\n\nsympy/solvers/recurr.py:461\n  /testbed/sympy/solvers/recurr.py:461: DeprecationWarning: invalid escape sequence \\o\n    \"\"\"\n\nsympy/solvers/recurr.py:663\n  /testbed/sympy/solvers/recurr.py:663: DeprecationWarning: invalid escape sequence \\o\n    \"\"\"\n\nsympy/calculus/finite_diff.py:420\n  /testbed/sympy/calculus/finite_diff.py:420: DeprecationWarning: invalid escape sequence \\*\n    \"\"\" Differentiate expr and replace Derivatives with finite differences.\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\nsympy/interactive/printing.py:251\n  /testbed/sympy/interactive/printing.py:251: DeprecationWarning: invalid escape sequence \\/\n    \"\"\"\n\nsympy/interactive/session.py:316\n  /testbed/sympy/interactive/session.py:316: DeprecationWarning: invalid escape sequence \\/\n    \"\"\"\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================= 27 passed, 97 warnings in 0.67s ========================\n\n",
          "test_files_run": [
            "sympy/matrices/expressions/tests/test_matexpr.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-12481",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 17.122289896011353,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 8,
          "failed": 1,
          "errors": 0,
          "collected": 9,
          "duration": 7.31,
          "log_tail": "sympy/solvers/recurr.py:461\n  /testbed/sympy/solvers/recurr.py:461: DeprecationWarning: invalid escape sequence \\o\n    \"\"\"\n\nsympy/solvers/recurr.py:663\n  /testbed/sympy/solvers/recurr.py:663: DeprecationWarning: invalid escape sequence \\o\n    \"\"\"\n\nsympy/calculus/finite_diff.py:420\n  /testbed/sympy/calculus/finite_diff.py:420: DeprecationWarning: invalid escape sequence \\*\n    \"\"\" Differentiate expr and replace Derivatives with finite differences.\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\nsympy/interactive/printing.py:251\n  /testbed/sympy/interactive/printing.py:251: DeprecationWarning: invalid escape sequence \\/\n    \"\"\"\n\nsympy/interactive/session.py:316\n  /testbed/sympy/interactive/session.py:316: DeprecationWarning: invalid escape sequence \\/\n    \"\"\"\n\nsympy/combinatorics/perm_groups.py:1272\n  /testbed/sympy/combinatorics/perm_groups.py:1272: DeprecationWarning: invalid escape sequence \\i\n    \"\"\"Compute the derived subgroup.\n\nsympy/combinatorics/perm_groups.py:1762\n  /testbed/sympy/combinatorics/perm_groups.py:1762: DeprecationWarning: invalid escape sequence \\{\n    \"\"\"Test if a group is primitive.\n\nsympy/combinatorics/perm_groups.py:2990\n  /testbed/sympy/combinatorics/perm_groups.py:2990: DeprecationWarning: invalid escape sequence \\{\n    \"\"\"Return a strong generating set from the Schreier-Sims algorithm.\n\nsympy/combinatorics/perm_groups.py:3274\n  /testbed/sympy/combinatorics/perm_groups.py:3274: DeprecationWarning: invalid escape sequence \\O\n    \"\"\"Compute the degree of transitivity of the group.\n\nsympy/combinatorics/util.py:119\n  /testbed/sympy/combinatorics/util.py:119: DeprecationWarning: invalid escape sequence \\i\n    \"\"\"\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n================== 1 failed, 8 passed, 102 warnings in 0.37s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/combinatorics/tests/test_permutations.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/combinatorics/tests/test_permutations.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 9,
          "failed": 0,
          "errors": 0,
          "collected": 9,
          "duration": 8.67,
          "log_tail": "    \"\"\"\n\nsympy/solvers/recurr.py:461\n  /testbed/sympy/solvers/recurr.py:461: DeprecationWarning: invalid escape sequence \\o\n    \"\"\"\n\nsympy/solvers/recurr.py:663\n  /testbed/sympy/solvers/recurr.py:663: DeprecationWarning: invalid escape sequence \\o\n    \"\"\"\n\nsympy/calculus/finite_diff.py:420\n  /testbed/sympy/calculus/finite_diff.py:420: DeprecationWarning: invalid escape sequence \\*\n    \"\"\" Differentiate expr and replace Derivatives with finite differences.\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\nsympy/interactive/printing.py:251\n  /testbed/sympy/interactive/printing.py:251: DeprecationWarning: invalid escape sequence \\/\n    \"\"\"\n\nsympy/interactive/session.py:316\n  /testbed/sympy/interactive/session.py:316: DeprecationWarning: invalid escape sequence \\/\n    \"\"\"\n\nsympy/combinatorics/perm_groups.py:1272\n  /testbed/sympy/combinatorics/perm_groups.py:1272: DeprecationWarning: invalid escape sequence \\i\n    \"\"\"Compute the derived subgroup.\n\nsympy/combinatorics/perm_groups.py:1762\n  /testbed/sympy/combinatorics/perm_groups.py:1762: DeprecationWarning: invalid escape sequence \\{\n    \"\"\"Test if a group is primitive.\n\nsympy/combinatorics/perm_groups.py:2990\n  /testbed/sympy/combinatorics/perm_groups.py:2990: DeprecationWarning: invalid escape sequence \\{\n    \"\"\"Return a strong generating set from the Schreier-Sims algorithm.\n\nsympy/combinatorics/perm_groups.py:3274\n  /testbed/sympy/combinatorics/perm_groups.py:3274: DeprecationWarning: invalid escape sequence \\O\n    \"\"\"Compute the degree of transitivity of the group.\n\nsympy/combinatorics/util.py:119\n  /testbed/sympy/combinatorics/util.py:119: DeprecationWarning: invalid escape sequence \\i\n    \"\"\"\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================= 9 passed, 102 warnings in 0.35s ========================\n\n",
          "test_files_run": [
            "sympy/combinatorics/tests/test_permutations.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-12489",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 17.20317792892456,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 9,
          "failed": 1,
          "errors": 0,
          "collected": 10,
          "duration": 7.57,
          "log_tail": "sympy/solvers/recurr.py:461\n  /testbed/sympy/solvers/recurr.py:461: DeprecationWarning: invalid escape sequence \\o\n    \"\"\"\n\nsympy/solvers/recurr.py:663\n  /testbed/sympy/solvers/recurr.py:663: DeprecationWarning: invalid escape sequence \\o\n    \"\"\"\n\nsympy/calculus/finite_diff.py:420\n  /testbed/sympy/calculus/finite_diff.py:420: DeprecationWarning: invalid escape sequence \\*\n    \"\"\" Differentiate expr and replace Derivatives with finite differences.\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\nsympy/interactive/printing.py:258\n  /testbed/sympy/interactive/printing.py:258: DeprecationWarning: invalid escape sequence \\/\n    \"\"\"\n\nsympy/interactive/session.py:316\n  /testbed/sympy/interactive/session.py:316: DeprecationWarning: invalid escape sequence \\/\n    \"\"\"\n\nsympy/combinatorics/perm_groups.py:1272\n  /testbed/sympy/combinatorics/perm_groups.py:1272: DeprecationWarning: invalid escape sequence \\i\n    \"\"\"Compute the derived subgroup.\n\nsympy/combinatorics/perm_groups.py:1762\n  /testbed/sympy/combinatorics/perm_groups.py:1762: DeprecationWarning: invalid escape sequence \\{\n    \"\"\"Test if a group is primitive.\n\nsympy/combinatorics/perm_groups.py:2990\n  /testbed/sympy/combinatorics/perm_groups.py:2990: DeprecationWarning: invalid escape sequence \\{\n    \"\"\"Return a strong generating set from the Schreier-Sims algorithm.\n\nsympy/combinatorics/perm_groups.py:3274\n  /testbed/sympy/combinatorics/perm_groups.py:3274: DeprecationWarning: invalid escape sequence \\O\n    \"\"\"Compute the degree of transitivity of the group.\n\nsympy/combinatorics/util.py:119\n  /testbed/sympy/combinatorics/util.py:119: DeprecationWarning: invalid escape sequence \\i\n    \"\"\"\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n================== 1 failed, 9 passed, 102 warnings in 0.44s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/combinatorics/tests/test_permutations.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/combinatorics/tests/test_permutations.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 10,
          "failed": 0,
          "errors": 0,
          "collected": 10,
          "duration": 8.37,
          "log_tail": "    \"\"\"\n\nsympy/solvers/recurr.py:461\n  /testbed/sympy/solvers/recurr.py:461: DeprecationWarning: invalid escape sequence \\o\n    \"\"\"\n\nsympy/solvers/recurr.py:663\n  /testbed/sympy/solvers/recurr.py:663: DeprecationWarning: invalid escape sequence \\o\n    \"\"\"\n\nsympy/calculus/finite_diff.py:420\n  /testbed/sympy/calculus/finite_diff.py:420: DeprecationWarning: invalid escape sequence \\*\n    \"\"\" Differentiate expr and replace Derivatives with finite differences.\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\nsympy/interactive/printing.py:258\n  /testbed/sympy/interactive/printing.py:258: DeprecationWarning: invalid escape sequence \\/\n    \"\"\"\n\nsympy/interactive/session.py:316\n  /testbed/sympy/interactive/session.py:316: DeprecationWarning: invalid escape sequence \\/\n    \"\"\"\n\nsympy/combinatorics/perm_groups.py:1272\n  /testbed/sympy/combinatorics/perm_groups.py:1272: DeprecationWarning: invalid escape sequence \\i\n    \"\"\"Compute the derived subgroup.\n\nsympy/combinatorics/perm_groups.py:1762\n  /testbed/sympy/combinatorics/perm_groups.py:1762: DeprecationWarning: invalid escape sequence \\{\n    \"\"\"Test if a group is primitive.\n\nsympy/combinatorics/perm_groups.py:2990\n  /testbed/sympy/combinatorics/perm_groups.py:2990: DeprecationWarning: invalid escape sequence \\{\n    \"\"\"Return a strong generating set from the Schreier-Sims algorithm.\n\nsympy/combinatorics/perm_groups.py:3274\n  /testbed/sympy/combinatorics/perm_groups.py:3274: DeprecationWarning: invalid escape sequence \\O\n    \"\"\"Compute the degree of transitivity of the group.\n\nsympy/combinatorics/util.py:119\n  /testbed/sympy/combinatorics/util.py:119: DeprecationWarning: invalid escape sequence \\i\n    \"\"\"\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================= 10 passed, 102 warnings in 0.34s =======================\n\n",
          "test_files_run": [
            "sympy/combinatorics/tests/test_permutations.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-13031",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 17.4721040725708,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 10,
          "failed": 1,
          "errors": 0,
          "collected": 11,
          "duration": 7.43,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 11 items\n\nsympy/matrices/tests/test_sparse.py::test_sparse_matrix FAILED           [  9%]\nsympy/matrices/tests/test_sparse.py::test_transpose PASSED               [ 18%]\nsympy/matrices/tests/test_sparse.py::test_trace PASSED                   [ 27%]\nsympy/matrices/tests/test_sparse.py::test_CL_RL PASSED                   [ 36%]\nsympy/matrices/tests/test_sparse.py::test_add PASSED                     [ 45%]\nsympy/matrices/tests/test_sparse.py::test_errors PASSED                  [ 54%]\nsympy/matrices/tests/test_sparse.py::test_len PASSED                     [ 63%]\nsympy/matrices/tests/test_sparse.py::test_sparse_zeros_sparse_eye PASSED [ 72%]\nsympy/matrices/tests/test_sparse.py::test_copyin PASSED                  [ 81%]\nsympy/matrices/tests/test_sparse.py::test_sparse_solve PASSED            [ 90%]\nsympy/matrices/tests/test_sparse.py::test_hermitian PASSED               [100%]\n\n=================================== FAILURES ===================================\n______________________________ test_sparse_matrix ______________________________\nsympy/matrices/tests/test_sparse.py:31: in test_sparse_matrix\n    assert SparseMatrix.hstack(*sparse_matrices) == Matrix(0, 6, [])\nE   assert Matrix(0, 3, []) == Matrix(0, 6, [])\nE     \nE     Full diff:\nE     - Matrix(0, 6, [])\nE     ?           ^\nE     + Matrix(0, 3, [])\nE     ?           ^\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 1 failed, 10 passed, 3 warnings in 0.35s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/matrices/tests/test_sparse.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/matrices/tests/test_sparse.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 11,
          "failed": 0,
          "errors": 0,
          "collected": 11,
          "duration": 8.86,
          "log_tail": "\nsympy/matrices/tests/test_sparse.py::test_sparse_matrix PASSED           [  9%]\nsympy/matrices/tests/test_sparse.py::test_transpose PASSED               [ 18%]\nsympy/matrices/tests/test_sparse.py::test_trace PASSED                   [ 27%]\nsympy/matrices/tests/test_sparse.py::test_CL_RL PASSED                   [ 36%]\nsympy/matrices/tests/test_sparse.py::test_add PASSED                     [ 45%]\nsympy/matrices/tests/test_sparse.py::test_errors PASSED                  [ 54%]\nsympy/matrices/tests/test_sparse.py::test_len PASSED                     [ 63%]\nsympy/matrices/tests/test_sparse.py::test_sparse_zeros_sparse_eye PASSED [ 72%]\nsympy/matrices/tests/test_sparse.py::test_copyin PASSED                  [ 81%]\nsympy/matrices/tests/test_sparse.py::test_sparse_solve PASSED            [ 90%]\nsympy/matrices/tests/test_sparse.py::test_hermitian PASSED               [100%]\n\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\nsympy/matrices/tests/test_sparse.py::test_sparse_matrix\n  /testbed/sympy/combinatorics/perm_groups.py:1272: DeprecationWarning: invalid escape sequence \\i\n    \"\"\"Compute the derived subgroup.\n\nsympy/matrices/tests/test_sparse.py::test_sparse_matrix\n  /testbed/sympy/combinatorics/perm_groups.py:1762: DeprecationWarning: invalid escape sequence \\{\n    \"\"\"Test if a group is primitive.\n\nsympy/matrices/tests/test_sparse.py::test_sparse_matrix\n  /testbed/sympy/combinatorics/perm_groups.py:2990: DeprecationWarning: invalid escape sequence \\{\n    \"\"\"Return a strong generating set from the Schreier-Sims algorithm.\n\nsympy/matrices/tests/test_sparse.py::test_sparse_matrix\n  /testbed/sympy/combinatorics/perm_groups.py:3286: DeprecationWarning: invalid escape sequence \\O\n    \"\"\"Compute the degree of transitivity of the group.\n\nsympy/matrices/tests/test_sparse.py::test_sparse_matrix\n  /testbed/sympy/combinatorics/util.py:119: DeprecationWarning: invalid escape sequence \\i\n    \"\"\"\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================== 11 passed, 8 warnings in 0.69s ========================\n\n",
          "test_files_run": [
            "sympy/matrices/tests/test_sparse.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-13091",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://35.239.238.137:8080",
      "duration": 20.981271982192993,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 94,
          "failed": 4,
          "errors": 0,
          "collected": 98,
          "duration": 9.12,
          "log_tail": "sympy/core/tests/test_numbers.py::test_issue_9491 PASSED                 [ 92%]\nsympy/core/tests/test_numbers.py::test_issue_10063 PASSED                [ 93%]\nsympy/core/tests/test_numbers.py::test_issue_10020 PASSED                [ 94%]\nsympy/core/tests/test_numbers.py::test_invert_numbers PASSED             [ 95%]\nsympy/core/tests/test_numbers.py::test_mod_inverse PASSED                [ 96%]\nsympy/core/tests/test_numbers.py::test_golden_ratio_rewrite_as_sqrt PASSED [ 97%]\nsympy/core/tests/test_numbers.py::test_comparisons_with_unknown_type FAILED [ 98%]\nsympy/core/tests/test_numbers.py::test_NumberSymbol_comparison FAILED    [100%]\n\n=================================== FAILURES ===================================\n________________________________ test_equality _________________________________\nsympy/core/tests/test_basic.py:73: in test_equality\n    assert b == bar\nE   assert Basic() == <sympy.core.tests.test_basic.test_equality.<locals>.Bar object at 0x7458edb05d30>\n______________________________ test_mpmath_issues ______________________________\nsympy/core/tests/test_numbers.py:1500: in test_mpmath_issues\n    assert _normalize(mpf, 53) != (0, long(0), 0, 0)\nE   TypeError: _normalize() missing 4 required positional arguments: 'exp', 'bc', 'prec', and 'rnd'\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:121: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_mpmath_issues\n______________________ test_comparisons_with_unknown_type ______________________\nsympy/core/tests/test_numbers.py:1702: in test_comparisons_with_unknown_type\n    assert n == bar\nE   assert 3 == <sympy.core.tests.test_numbers.test_comparisons_with_unknown_type.<locals>.Bar object at 0x7458ed8c8c40>\n_________________________ test_NumberSymbol_comparison _________________________\nsympy/core/tests/test_numbers.py:1731: in test_NumberSymbol_comparison\n    assert (rpi > pi) == (pi < rpi)\nE   assert (905502432259640373/288230376151711744 > pi) == (pi < 905502432259640373/288230376151711744)\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 4 failed, 94 passed, 3 warnings in 2.00s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/core/tests/test_basic.py sympy/core/tests/test_numbers.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/core/tests/test_basic.py",
            "sympy/core/tests/test_numbers.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 97,
          "failed": 1,
          "errors": 0,
          "collected": 98,
          "duration": 10.55,
          "log_tail": "sympy/core/tests/test_numbers.py::test_mpmath_issues FAILED              [ 80%]\nsympy/core/tests/test_numbers.py::test_Catalan_EulerGamma_prec PASSED    [ 81%]\nsympy/core/tests/test_numbers.py::test_Float_eq PASSED                   [ 82%]\nsympy/core/tests/test_numbers.py::test_int_NumberSymbols PASSED          [ 83%]\nsympy/core/tests/test_numbers.py::test_issue_6640 PASSED                 [ 84%]\nsympy/core/tests/test_numbers.py::test_issue_6349 PASSED                 [ 85%]\nsympy/core/tests/test_numbers.py::test_mpf_norm PASSED                   [ 86%]\nsympy/core/tests/test_numbers.py::test_latex PASSED                      [ 87%]\nsympy/core/tests/test_numbers.py::test_issue_7742 PASSED                 [ 88%]\nsympy/core/tests/test_numbers.py::test_simplify_AlgebraicNumber PASSED   [ 89%]\nsympy/core/tests/test_numbers.py::test_Float_idempotence PASSED          [ 90%]\nsympy/core/tests/test_numbers.py::test_comp PASSED                       [ 91%]\nsympy/core/tests/test_numbers.py::test_issue_9491 PASSED                 [ 92%]\nsympy/core/tests/test_numbers.py::test_issue_10063 PASSED                [ 93%]\nsympy/core/tests/test_numbers.py::test_issue_10020 PASSED                [ 94%]\nsympy/core/tests/test_numbers.py::test_invert_numbers PASSED             [ 95%]\nsympy/core/tests/test_numbers.py::test_mod_inverse PASSED                [ 96%]\nsympy/core/tests/test_numbers.py::test_golden_ratio_rewrite_as_sqrt PASSED [ 97%]\nsympy/core/tests/test_numbers.py::test_comparisons_with_unknown_type PASSED [ 98%]\nsympy/core/tests/test_numbers.py::test_NumberSymbol_comparison PASSED    [100%]\n\n=================================== FAILURES ===================================\n______________________________ test_mpmath_issues ______________________________\nsympy/core/tests/test_numbers.py:1500: in test_mpmath_issues\n    assert _normalize(mpf, 53) != (0, long(0), 0, 0)\nE   TypeError: _normalize() missing 4 required positional arguments: 'exp', 'bc', 'prec', and 'rnd'\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:121: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_mpmath_issues\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 1 failed, 97 passed, 3 warnings in 2.13s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/core/tests/test_basic.py sympy/core/tests/test_numbers.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/core/tests/test_basic.py",
            "sympy/core/tests/test_numbers.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sympy__sympy-13372",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://35.239.238.137:8080",
      "duration": 28.92747402191162,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 45,
          "failed": 3,
          "errors": 0,
          "collected": 48,
          "duration": 12.96,
          "log_tail": "E   AssertionError: assert '-389.636364136010' == '-389.63636413601 + 0.e-14*I'\nE     \nE     - -389.63636413601 + 0.e-14*I\nE     ?                 --- -------\nE     + -389.636364136010\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:121: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_evalf_complex_powers_bug\n_______________________________ test_evalf_bugs ________________________________\nsympy/core/evalf.py:1287: in evalf\n    rf = evalf_table[x.func]\nE   KeyError: Max\n\nDuring handling of the above exception, another exception occurred:\nsympy/core/tests/test_evalf.py:234: in test_evalf_bugs\n    assert NS(Mul(Max(0, y), x, evaluate=False).evalf()) == 'x*Max(0, y)'\nsympy/core/evalf.py:1396: in evalf\n    result = evalf(self, prec + 4, options)\nsympy/core/evalf.py:1288: in evalf\n    r = rf(x, prec, options)\nsympy/core/evalf.py:540: in evalf_mul\n    arg = evalf(arg, prec, options)\nsympy/core/evalf.py:1310: in evalf\n    r = re, im, reprec, imprec\nE   UnboundLocalError: local variable 'reprec' referenced before assignment\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/core/containers.py:271\n  /testbed/sympy/core/containers.py:271: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    class OrderedSet(collections.MutableSet):\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 3 failed, 45 passed, 4 warnings in 5.43s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/core/tests/test_evalf.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/core/tests/test_evalf.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 46,
          "failed": 2,
          "errors": 0,
          "collected": 48,
          "duration": 14.58,
          "log_tail": "sympy/core/tests/test_evalf.py::test_AssocOp_Function PASSED             [ 97%]\nsympy/core/tests/test_evalf.py::test_issue_10395 PASSED                  [100%]\n\n=================================== FAILURES ===================================\n____________________________ test_evalf_complex_bug ____________________________\nsympy/core/tests/test_evalf.py:66: in test_evalf_complex_bug\n    assert NS('(pi+E*I)*(E+pi*I)', 15) in ('0.e-15 + 17.25866050002*I',\nE   AssertionError: assert '17.2586605000200*I' in ('0.e-15 + 17.25866050002*I', '0.e-17 + 17.25866050002*I', '-0.e-17 + 17.25866050002*I')\nE    +  where '17.2586605000200*I' = NS('(pi+E*I)*(E+pi*I)', 15)\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:121: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_evalf_complex_bug\n________________________ test_evalf_complex_powers_bug _________________________\nsympy/core/tests/test_evalf.py:89: in test_evalf_complex_powers_bug\n    assert NS('(pi + pi*I)**4') == '-389.63636413601 + 0.e-14*I'\nE   AssertionError: assert '-389.636364136010' == '-389.63636413601 + 0.e-14*I'\nE     \nE     - -389.63636413601 + 0.e-14*I\nE     ?                 --- -------\nE     + -389.636364136010\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:121: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_evalf_complex_powers_bug\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/core/containers.py:271\n  /testbed/sympy/core/containers.py:271: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    class OrderedSet(collections.MutableSet):\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 2 failed, 46 passed, 4 warnings in 5.70s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/core/tests/test_evalf.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/core/tests/test_evalf.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sympy__sympy-13480",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 20.28500485420227,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 44,
          "failed": 1,
          "errors": 0,
          "collected": 45,
          "duration": 8.75,
          "log_tail": "sympy/functions/elementary/tests/test_hyperbolic.py::test_simplifications PASSED [ 77%]\nsympy/functions/elementary/tests/test_hyperbolic.py::test_issue_4136 PASSED [ 80%]\nsympy/functions/elementary/tests/test_hyperbolic.py::test_sinh_rewrite PASSED [ 82%]\nsympy/functions/elementary/tests/test_hyperbolic.py::test_cosh_rewrite PASSED [ 84%]\nsympy/functions/elementary/tests/test_hyperbolic.py::test_tanh_rewrite PASSED [ 86%]\nsympy/functions/elementary/tests/test_hyperbolic.py::test_coth_rewrite PASSED [ 88%]\nsympy/functions/elementary/tests/test_hyperbolic.py::test_csch_rewrite PASSED [ 91%]\nsympy/functions/elementary/tests/test_hyperbolic.py::test_sech_rewrite PASSED [ 93%]\nsympy/functions/elementary/tests/test_hyperbolic.py::test_derivs PASSED  [ 95%]\nsympy/functions/elementary/tests/test_hyperbolic.py::test_sinh_expansion PASSED [ 97%]\nsympy/functions/elementary/tests/test_hyperbolic.py::test_cosh_expansion PASSED [100%]\n\n=================================== FAILURES ===================================\n__________________________________ test_coth ___________________________________\nsympy/functions/elementary/tests/test_hyperbolic.py:275: in test_coth\n    assert coth(log(tan(2))) == coth(log(-tan(2)))\nsympy/core/cache.py:93: in wrapper\n    retval = cfunc(*args, **kwargs)\nsympy/core/function.py:439: in __new__\n    result = super(Function, cls).__new__(cls, *args, **options)\nsympy/core/cache.py:93: in wrapper\n    retval = cfunc(*args, **kwargs)\nsympy/core/function.py:250: in __new__\n    evaluated = cls.eval(*args)\nsympy/functions/elementary/hyperbolic.py:590: in eval\n    if cotm is S.ComplexInfinity:\nE   NameError: name 'cotm' is not defined\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/core/containers.py:271\n  /testbed/sympy/core/containers.py:271: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    class OrderedSet(collections.MutableSet):\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 1 failed, 44 passed, 4 warnings in 1.58s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/functions/elementary/tests/test_hyperbolic.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/functions/elementary/tests/test_hyperbolic.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 45,
          "failed": 0,
          "errors": 0,
          "collected": 45,
          "duration": 10.33,
          "log_tail": "sympy/functions/elementary/tests/test_hyperbolic.py::test_acosh_series PASSED [ 40%]\nsympy/functions/elementary/tests/test_hyperbolic.py::test_asech PASSED   [ 42%]\nsympy/functions/elementary/tests/test_hyperbolic.py::test_asech_series PASSED [ 44%]\nsympy/functions/elementary/tests/test_hyperbolic.py::test_asech_rewrite PASSED [ 46%]\nsympy/functions/elementary/tests/test_hyperbolic.py::test_acsch PASSED   [ 48%]\nsympy/functions/elementary/tests/test_hyperbolic.py::test_acsch_infinities PASSED [ 51%]\nsympy/functions/elementary/tests/test_hyperbolic.py::test_acsch_rewrite PASSED [ 53%]\nsympy/functions/elementary/tests/test_hyperbolic.py::test_atanh PASSED   [ 55%]\nsympy/functions/elementary/tests/test_hyperbolic.py::test_atanh_rewrite PASSED [ 57%]\nsympy/functions/elementary/tests/test_hyperbolic.py::test_atanh_series PASSED [ 60%]\nsympy/functions/elementary/tests/test_hyperbolic.py::test_acoth PASSED   [ 62%]\nsympy/functions/elementary/tests/test_hyperbolic.py::test_acoth_rewrite PASSED [ 64%]\nsympy/functions/elementary/tests/test_hyperbolic.py::test_acoth_series PASSED [ 66%]\nsympy/functions/elementary/tests/test_hyperbolic.py::test_inverses PASSED [ 68%]\nsympy/functions/elementary/tests/test_hyperbolic.py::test_leading_term PASSED [ 71%]\nsympy/functions/elementary/tests/test_hyperbolic.py::test_complex PASSED [ 73%]\nsympy/functions/elementary/tests/test_hyperbolic.py::test_complex_2899 PASSED [ 75%]\nsympy/functions/elementary/tests/test_hyperbolic.py::test_simplifications PASSED [ 77%]\nsympy/functions/elementary/tests/test_hyperbolic.py::test_issue_4136 PASSED [ 80%]\nsympy/functions/elementary/tests/test_hyperbolic.py::test_sinh_rewrite PASSED [ 82%]\nsympy/functions/elementary/tests/test_hyperbolic.py::test_cosh_rewrite PASSED [ 84%]\nsympy/functions/elementary/tests/test_hyperbolic.py::test_tanh_rewrite PASSED [ 86%]\nsympy/functions/elementary/tests/test_hyperbolic.py::test_coth_rewrite PASSED [ 88%]\nsympy/functions/elementary/tests/test_hyperbolic.py::test_csch_rewrite PASSED [ 91%]\nsympy/functions/elementary/tests/test_hyperbolic.py::test_sech_rewrite PASSED [ 93%]\nsympy/functions/elementary/tests/test_hyperbolic.py::test_derivs PASSED  [ 95%]\nsympy/functions/elementary/tests/test_hyperbolic.py::test_sinh_expansion PASSED [ 97%]\nsympy/functions/elementary/tests/test_hyperbolic.py::test_cosh_expansion PASSED [100%]\n\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/core/containers.py:271\n  /testbed/sympy/core/containers.py:271: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    class OrderedSet(collections.MutableSet):\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================== 45 passed, 4 warnings in 1.65s ========================\n\n",
          "test_files_run": [
            "sympy/functions/elementary/tests/test_hyperbolic.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-13551",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 19.530449151992798,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 18,
          "failed": 1,
          "errors": 0,
          "collected": 19,
          "duration": 8.23,
          "log_tail": "sympy/concrete/tests/test_products.py::test_simple_products PASSED       [ 21%]\nsympy/concrete/tests/test_products.py::test_multiple_products PASSED     [ 26%]\nsympy/concrete/tests/test_products.py::test_rational_products PASSED     [ 31%]\nsympy/concrete/tests/test_products.py::test_special_products PASSED      [ 36%]\nsympy/concrete/tests/test_products.py::test__eval_product PASSED         [ 42%]\nsympy/concrete/tests/test_products.py::test_product_pow PASSED           [ 47%]\nsympy/concrete/tests/test_products.py::test_infinite_product PASSED      [ 52%]\nsympy/concrete/tests/test_products.py::test_conjugate_transpose PASSED   [ 57%]\nsympy/concrete/tests/test_products.py::test_simplify PASSED              [ 63%]\nsympy/concrete/tests/test_products.py::test_change_index PASSED          [ 68%]\nsympy/concrete/tests/test_products.py::test_reorder PASSED               [ 73%]\nsympy/concrete/tests/test_products.py::test_Product_is_convergent PASSED [ 78%]\nsympy/concrete/tests/test_products.py::test_reverse_order PASSED         [ 84%]\nsympy/concrete/tests/test_products.py::test_issue_9983 PASSED            [ 89%]\nsympy/concrete/tests/test_products.py::test_issue_13546 FAILED           [ 94%]\nsympy/concrete/tests/test_products.py::test_rewrite_Sum PASSED           [100%]\n\n=================================== FAILURES ===================================\n_______________________________ test_issue_13546 _______________________________\nsympy/concrete/tests/test_products.py:362: in test_issue_13546\n    assert p.subs(n, 2).doit() == S(15)/2\nE   assert 9/2 == (15 / 2)\nE    +  where 9/2 = doit()\nE    +    where doit = 9/2.doit\nE    +      where 9/2 = subs(n, 2)\nE    +        where subs = 2**(-n**2/2 + n/2)*(2**(n**2/2 - n/2)*n**n + 1).subs\nE    +  and   15 = S(15)\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/core/containers.py:271\n  /testbed/sympy/core/containers.py:271: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    class OrderedSet(collections.MutableSet):\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 1 failed, 18 passed, 4 warnings in 1.26s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/concrete/tests/test_products.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/concrete/tests/test_products.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 19,
          "failed": 0,
          "errors": 0,
          "collected": 19,
          "duration": 9.84,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 19 items\n\nsympy/concrete/tests/test_products.py::test_karr_convention PASSED       [  5%]\nsympy/concrete/tests/test_products.py::test_karr_proposition_2a PASSED   [ 10%]\nsympy/concrete/tests/test_products.py::test_karr_proposition_2b PASSED   [ 15%]\nsympy/concrete/tests/test_products.py::test_simple_products PASSED       [ 21%]\nsympy/concrete/tests/test_products.py::test_multiple_products PASSED     [ 26%]\nsympy/concrete/tests/test_products.py::test_rational_products PASSED     [ 31%]\nsympy/concrete/tests/test_products.py::test_special_products PASSED      [ 36%]\nsympy/concrete/tests/test_products.py::test__eval_product PASSED         [ 42%]\nsympy/concrete/tests/test_products.py::test_product_pow PASSED           [ 47%]\nsympy/concrete/tests/test_products.py::test_infinite_product PASSED      [ 52%]\nsympy/concrete/tests/test_products.py::test_conjugate_transpose PASSED   [ 57%]\nsympy/concrete/tests/test_products.py::test_simplify PASSED              [ 63%]\nsympy/concrete/tests/test_products.py::test_change_index PASSED          [ 68%]\nsympy/concrete/tests/test_products.py::test_reorder PASSED               [ 73%]\nsympy/concrete/tests/test_products.py::test_Product_is_convergent PASSED [ 78%]\nsympy/concrete/tests/test_products.py::test_reverse_order PASSED         [ 84%]\nsympy/concrete/tests/test_products.py::test_issue_9983 PASSED            [ 89%]\nsympy/concrete/tests/test_products.py::test_issue_13546 PASSED           [ 94%]\nsympy/concrete/tests/test_products.py::test_rewrite_Sum PASSED           [100%]\n\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/core/containers.py:271\n  /testbed/sympy/core/containers.py:271: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    class OrderedSet(collections.MutableSet):\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================== 19 passed, 4 warnings in 1.37s ========================\n\n",
          "test_files_run": [
            "sympy/concrete/tests/test_products.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-13615",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://35.239.238.137:8080",
      "duration": 31.768595933914185,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 71,
          "failed": 3,
          "errors": 0,
          "collected": 74,
          "duration": 14.41,
          "log_tail": "___________________________ test_image_Intersection ____________________________\nsympy/sets/tests/test_sets.py:797: in test_image_Intersection\n    assert imageset(x, x**2, Interval(-2, 0).intersect(Interval(x, y))) == \\\nE   assert Intersection(...terval(x, y))) == Intersection(...(x**2, y**2)))\nE     \nE     Full diff:\nE     - Intersection(Interval(0, 4), Interval(Min(x**2, y**2), Max(x**2, y**2)))\nE     + Intersection(Interval(0, 4), ImageSet(Lambda(x, x**2), Interval(x, y)))\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:121: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_image_Intersection\n_____________________ test_union_boundary_of_joining_sets ______________________\nsympy/sets/tests/test_sets.py:848: in test_union_boundary_of_joining_sets\n    assert Union(Interval(0, 10), Interval(10, 15), evaluate=False).boundary \\\nE   assert {0, 10, 15} == {0, 15}\nE     \nE     Full diff:\nE     - {0, 15}\nE     + {0, 10, 15}\nE     ?     ++++\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:121: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_union_boundary_of_joining_sets\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/core/containers.py:271\n  /testbed/sympy/core/containers.py:271: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    class OrderedSet(collections.MutableSet):\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 3 failed, 71 passed, 4 warnings in 7.35s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/sets/tests/test_sets.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/sets/tests/test_sets.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 72,
          "failed": 2,
          "errors": 0,
          "collected": 74,
          "duration": 16.13,
          "log_tail": "___________________________ test_image_Intersection ____________________________\nsympy/sets/tests/test_sets.py:797: in test_image_Intersection\n    assert imageset(x, x**2, Interval(-2, 0).intersect(Interval(x, y))) == \\\nE   assert Intersection(...terval(x, y))) == Intersection(...(x**2, y**2)))\nE     \nE     Full diff:\nE     - Intersection(Interval(0, 4), Interval(Min(x**2, y**2), Max(x**2, y**2)))\nE     + Intersection(Interval(0, 4), ImageSet(Lambda(x, x**2), Interval(x, y)))\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:121: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_image_Intersection\n_____________________ test_union_boundary_of_joining_sets ______________________\nsympy/sets/tests/test_sets.py:848: in test_union_boundary_of_joining_sets\n    assert Union(Interval(0, 10), Interval(10, 15), evaluate=False).boundary \\\nE   assert {0, 10, 15} == {0, 15}\nE     \nE     Full diff:\nE     - {0, 15}\nE     + {0, 10, 15}\nE     ?     ++++\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:121: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_union_boundary_of_joining_sets\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/core/containers.py:271\n  /testbed/sympy/core/containers.py:271: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    class OrderedSet(collections.MutableSet):\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 2 failed, 72 passed, 4 warnings in 7.42s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/sets/tests/test_sets.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/sets/tests/test_sets.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sympy__sympy-13647",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://35.239.238.137:8080",
      "duration": 22.197828769683838,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 79,
          "failed": 2,
          "errors": 0,
          "collected": 81,
          "duration": 9.4,
          "log_tail": "E     \nE     ...Full output truncated (3 lines hidden), use '-vv' to show\n__________________________________ test_diff ___________________________________\nsympy/matrices/tests/test_commonmatrix.py:1316: in test_diff\n    assert m.diff(x) == Matrix(2, 1, [1, 0])\nsympy/matrices/matrices.py:1564: in diff\n    return Derivative(self, *args, evaluate=True)\nsympy/core/function.py:1105: in __new__\n    expr = sympify(expr)\nsympy/core/sympify.py:322: in sympify\n    return type(a)([sympify(x, locals=locals, convert_xor=convert_xor,\nsympy/matrices/common.py:2183: in __init__\n    raise NotImplementedError(\"Cannot initialize matrix with given parameters\")\nE   NotImplementedError: Cannot initialize matrix with given parameters\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:121: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_diff\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/core/containers.py:271\n  /testbed/sympy/core/containers.py:271: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    class OrderedSet(collections.MutableSet):\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\nsympy/matrices/tests/test_commonmatrix.py::test_refine\n  /testbed/sympy/assumptions/sathandlers.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import MutableMapping, defaultdict\n\nsympy/matrices/tests/test_commonmatrix.py::test_jacobian2\n  /testbed/sympy/core/function.py:1227: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    if isinstance(v, (collections.Iterable, Tuple, MatrixCommon, NDimArray)):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 2 failed, 79 passed, 6 warnings in 2.41s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/matrices/tests/test_commonmatrix.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/matrices/tests/test_commonmatrix.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 80,
          "failed": 1,
          "errors": 0,
          "collected": 81,
          "duration": 11.69,
          "log_tail": "\n=================================== FAILURES ===================================\n__________________________________ test_diff ___________________________________\nsympy/matrices/tests/test_commonmatrix.py:1316: in test_diff\n    assert m.diff(x) == Matrix(2, 1, [1, 0])\nsympy/matrices/matrices.py:1564: in diff\n    return Derivative(self, *args, evaluate=True)\nsympy/core/function.py:1105: in __new__\n    expr = sympify(expr)\nsympy/core/sympify.py:322: in sympify\n    return type(a)([sympify(x, locals=locals, convert_xor=convert_xor,\nsympy/matrices/common.py:2183: in __init__\n    raise NotImplementedError(\"Cannot initialize matrix with given parameters\")\nE   NotImplementedError: Cannot initialize matrix with given parameters\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:121: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_diff\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/core/containers.py:271\n  /testbed/sympy/core/containers.py:271: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    class OrderedSet(collections.MutableSet):\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\nsympy/matrices/tests/test_commonmatrix.py::test_refine\n  /testbed/sympy/assumptions/sathandlers.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import MutableMapping, defaultdict\n\nsympy/matrices/tests/test_commonmatrix.py::test_jacobian2\n  /testbed/sympy/core/function.py:1227: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    if isinstance(v, (collections.Iterable, Tuple, MatrixCommon, NDimArray)):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 1 failed, 80 passed, 6 warnings in 2.96s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/matrices/tests/test_commonmatrix.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/matrices/tests/test_commonmatrix.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sympy__sympy-13757",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://35.239.238.137:8080",
      "duration": 29.53737187385559,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 173,
          "failed": 6,
          "errors": 0,
          "collected": 179,
          "duration": 13.33,
          "log_tail": "E    +  where Poly(x, x, domain='ZZ') = Poly(x, x)\nE    +  and   Poly(I*x, x, domain='EX') = Poly((I * x), x)\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:121: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_poly_matching_consistency\n_______________________________ test_issue_5786 ________________________________\nsympy/polys/tests/test_polytools.py:3214: in test_issue_5786\n    assert expand(factor(expand(\nE   assert x - I*y == (((((-I * t) * x) - (t * y)) + (x * z)) - ((I * y) * z))\nE    +  where x - I*y = expand(x - I*y)\nE    +    where x - I*y = factor(-I*t*x - t*y + x*z - I*y*z, extension=[I])\nE    +      where -I*t*x - t*y + x*z - I*y*z = expand(((x - (I * y)) * (z - (I * t))))\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:121: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_issue_5786\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/core/containers.py:271\n  /testbed/sympy/core/containers.py:271: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    class OrderedSet(collections.MutableSet):\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\nsympy/core/tests/test_match.py::test_match_deriv_bug1\n  /testbed/sympy/core/function.py:1227: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    if isinstance(v, (collections.Iterable, Tuple, MatrixCommon, NDimArray)):\n\nsympy/polys/tests/test_polytools.py::test_Poly__unify\n  /testbed/sympy/polys/agca/modules.py:351: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    elif elem is 0:\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n================== 6 failed, 173 passed, 6 warnings in 6.17s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/core/tests/test_match.py sympy/polys/tests/test_polytools.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/core/tests/test_match.py",
            "sympy/polys/tests/test_polytools.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 174,
          "failed": 5,
          "errors": 0,
          "collected": 179,
          "duration": 15.01,
          "log_tail": "sympy/utilities/pytest.py:121: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_factor_noeval\n________________________ test_poly_matching_consistency ________________________\nsympy/utilities/pytest.py:124: in wrapper\n    raise XPass(get_function_name(func))\nE   sympy.utilities.pytest.XPass: test_poly_matching_consistency\n_______________________________ test_issue_5786 ________________________________\nsympy/polys/tests/test_polytools.py:3214: in test_issue_5786\n    assert expand(factor(expand(\nE   assert x - I*y == (((((-I * t) * x) - (t * y)) + (x * z)) - ((I * y) * z))\nE    +  where x - I*y = expand(x - I*y)\nE    +    where x - I*y = factor(-I*t*x - t*y + x*z - I*y*z, extension=[I])\nE    +      where -I*t*x - t*y + x*z - I*y*z = expand(((x - (I * y)) * (z - (I * t))))\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:121: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_issue_5786\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/core/containers.py:271\n  /testbed/sympy/core/containers.py:271: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    class OrderedSet(collections.MutableSet):\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\nsympy/core/tests/test_match.py::test_match_deriv_bug1\n  /testbed/sympy/core/function.py:1227: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    if isinstance(v, (collections.Iterable, Tuple, MatrixCommon, NDimArray)):\n\nsympy/polys/tests/test_polytools.py::test_Poly__unify\n  /testbed/sympy/polys/agca/modules.py:351: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    elif elem is 0:\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n================== 5 failed, 174 passed, 6 warnings in 6.27s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/core/tests/test_match.py sympy/polys/tests/test_polytools.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/core/tests/test_match.py",
            "sympy/polys/tests/test_polytools.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sympy__sympy-13798",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://35.239.238.137:8080",
      "duration": 22.171881914138794,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 111,
          "failed": 5,
          "errors": 0,
          "collected": 116,
          "duration": 9.52,
          "log_tail": "sympy/printing/tests/test_latex.py:1613: in test_issue_8470\n    e = parse_expr(\"-B*A\", evaluate=False)\nsympy/parsing/sympy_parser.py:892: in parse_expr\n    code = compile(evaluateFalse(code), '<string>', 'eval')\nE   ValueError: Name node can't be used with 'False' constant\n_______________________________ test_issue_13559 _______________________________\nsympy/printing/tests/test_latex.py:1646: in test_issue_13559\n    expr = parse_expr('5/1', evaluate=False)\nsympy/parsing/sympy_parser.py:892: in parse_expr\n    code = compile(evaluateFalse(code), '<string>', 'eval')\nE   ValueError: Name node can't be used with 'False' constant\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/core/containers.py:271\n  /testbed/sympy/core/containers.py:271: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    class OrderedSet(collections.MutableSet):\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\nsympy/vector/coordsysrect.py:171\n  /testbed/sympy/vector/coordsysrect.py:171: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if transformation.name is 'spherical':\n\nsympy/vector/coordsysrect.py:173\n  /testbed/sympy/vector/coordsysrect.py:173: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    elif transformation.name is 'cylindrical':\n\nsympy/printing/tests/test_latex.py::test_latex_indexed\n  /testbed/sympy/tensor/indexed.py:155: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    if isinstance(base, (NDimArray, collections.Iterable, Tuple, MatrixBase)) and all([i.is_number for i in args]):\n\nsympy/printing/tests/test_latex.py::test_PolynomialRingBase\n  /testbed/sympy/polys/agca/modules.py:351: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    elif elem is 0:\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n================== 5 failed, 111 passed, 8 warnings in 2.50s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/printing/tests/test_latex.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/printing/tests/test_latex.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 112,
          "failed": 4,
          "errors": 0,
          "collected": 116,
          "duration": 11.51,
          "log_tail": "sympy/printing/tests/test_latex.py:1613: in test_issue_8470\n    e = parse_expr(\"-B*A\", evaluate=False)\nsympy/parsing/sympy_parser.py:892: in parse_expr\n    code = compile(evaluateFalse(code), '<string>', 'eval')\nE   ValueError: Name node can't be used with 'False' constant\n_______________________________ test_issue_13559 _______________________________\nsympy/printing/tests/test_latex.py:1646: in test_issue_13559\n    expr = parse_expr('5/1', evaluate=False)\nsympy/parsing/sympy_parser.py:892: in parse_expr\n    code = compile(evaluateFalse(code), '<string>', 'eval')\nE   ValueError: Name node can't be used with 'False' constant\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/core/containers.py:271\n  /testbed/sympy/core/containers.py:271: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    class OrderedSet(collections.MutableSet):\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\nsympy/vector/coordsysrect.py:171\n  /testbed/sympy/vector/coordsysrect.py:171: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if transformation.name is 'spherical':\n\nsympy/vector/coordsysrect.py:173\n  /testbed/sympy/vector/coordsysrect.py:173: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    elif transformation.name is 'cylindrical':\n\nsympy/printing/tests/test_latex.py::test_latex_indexed\n  /testbed/sympy/tensor/indexed.py:155: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    if isinstance(base, (NDimArray, collections.Iterable, Tuple, MatrixBase)) and all([i.is_number for i in args]):\n\nsympy/printing/tests/test_latex.py::test_PolynomialRingBase\n  /testbed/sympy/polys/agca/modules.py:351: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    elif elem is 0:\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n================== 4 failed, 112 passed, 8 warnings in 2.72s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/printing/tests/test_latex.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/printing/tests/test_latex.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sympy__sympy-13852",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 26.678005933761597,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 9,
          "failed": 2,
          "errors": 0,
          "collected": 11,
          "duration": 11.43,
          "log_tail": "sympy/functions/special/tests/test_zeta_functions.py::test_lerchphi_expansion PASSED [ 72%]\nsympy/functions/special/tests/test_zeta_functions.py::test_stieltjes PASSED [ 81%]\nsympy/functions/special/tests/test_zeta_functions.py::test_stieltjes_evalf PASSED [ 90%]\nsympy/functions/special/tests/test_zeta_functions.py::test_issue_10475 PASSED [100%]\n\n=================================== FAILURES ===================================\n____________________________ test_polylog_expansion ____________________________\nsympy/functions/special/tests/test_zeta_functions.py:131: in test_polylog_expansion\n    assert myexpand(polylog(1, z), -log(1 - z))\nE   assert False\nE    +  where False = myexpand(polylog(1, z), -log(-z + 1))\nE    +    where polylog(1, z) = polylog(1, z)\nE    +    and   log(-z + 1) = log((1 - z))\n_____________________________ test_polylog_values ______________________________\nsympy/functions/special/tests/test_zeta_functions.py:140: in test_polylog_values\n    assert polylog(2, 2) == pi**2/4 - I*pi*log(2)\nE   assert polylog(2, 2) == (((pi ** 2) / 4) - ((I * pi) * log(2)))\nE    +  where polylog(2, 2) = polylog(2, 2)\nE    +  and   log(2) = log(2)\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/core/containers.py:271\n  /testbed/sympy/core/containers.py:271: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    class OrderedSet(collections.MutableSet):\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\nsympy/functions/special/tests/test_zeta_functions.py::test_zeta_series\n  /testbed/sympy/core/function.py:1246: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    if isinstance(v, (collections.Iterable, Tuple, MatrixCommon, NDimArray)):\n\nsympy/functions/special/tests/test_zeta_functions.py::test_rewriting\n  /testbed/sympy/assumptions/sathandlers.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import MutableMapping, defaultdict\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 2 failed, 9 passed, 6 warnings in 4.24s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/functions/special/tests/test_zeta_functions.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/functions/special/tests/test_zeta_functions.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 11,
          "failed": 0,
          "errors": 0,
          "collected": 11,
          "duration": 13.78,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 11 items\n\nsympy/functions/special/tests/test_zeta_functions.py::test_zeta_eval PASSED [  9%]\nsympy/functions/special/tests/test_zeta_functions.py::test_zeta_series PASSED [ 18%]\nsympy/functions/special/tests/test_zeta_functions.py::test_dirichlet_eta_eval PASSED [ 27%]\nsympy/functions/special/tests/test_zeta_functions.py::test_rewriting PASSED [ 36%]\nsympy/functions/special/tests/test_zeta_functions.py::test_derivatives PASSED [ 45%]\nsympy/functions/special/tests/test_zeta_functions.py::test_polylog_expansion PASSED [ 54%]\nsympy/functions/special/tests/test_zeta_functions.py::test_polylog_values PASSED [ 63%]\nsympy/functions/special/tests/test_zeta_functions.py::test_lerchphi_expansion PASSED [ 72%]\nsympy/functions/special/tests/test_zeta_functions.py::test_stieltjes PASSED [ 81%]\nsympy/functions/special/tests/test_zeta_functions.py::test_stieltjes_evalf PASSED [ 90%]\nsympy/functions/special/tests/test_zeta_functions.py::test_issue_10475 PASSED [100%]\n\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/core/containers.py:271\n  /testbed/sympy/core/containers.py:271: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    class OrderedSet(collections.MutableSet):\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\nsympy/functions/special/tests/test_zeta_functions.py::test_zeta_series\n  /testbed/sympy/core/function.py:1246: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    if isinstance(v, (collections.Iterable, Tuple, MatrixCommon, NDimArray)):\n\nsympy/functions/special/tests/test_zeta_functions.py::test_rewriting\n  /testbed/sympy/assumptions/sathandlers.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import MutableMapping, defaultdict\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================== 11 passed, 6 warnings in 4.80s ========================\n\n",
          "test_files_run": [
            "sympy/functions/special/tests/test_zeta_functions.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-13877",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://35.239.238.137:8080",
      "error": "HTTPConnectionPool(host='35.239.238.137', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "sympy__sympy-13878",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://35.239.238.137:8080",
      "error": "HTTPConnectionPool(host='35.239.238.137', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "sympy__sympy-13974",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 18.631215810775757,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 6,
          "failed": 1,
          "errors": 0,
          "collected": 7,
          "duration": 8.03,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 7 items\n\nsympy/physics/quantum/tests/test_tensorproduct.py::test_tensor_product_dagger PASSED [ 14%]\nsympy/physics/quantum/tests/test_tensorproduct.py::test_tensor_product_abstract PASSED [ 28%]\nsympy/physics/quantum/tests/test_tensorproduct.py::test_tensor_product_expand PASSED [ 42%]\nsympy/physics/quantum/tests/test_tensorproduct.py::test_tensor_product_commutator PASSED [ 57%]\nsympy/physics/quantum/tests/test_tensorproduct.py::test_tensor_product_simp FAILED [ 71%]\nsympy/physics/quantum/tests/test_tensorproduct.py::test_issue_5923 PASSED [ 85%]\nsympy/physics/quantum/tests/test_tensorproduct.py::test_eval_trace PASSED [100%]\n\n=================================== FAILURES ===================================\n___________________________ test_tensor_product_simp ___________________________\nsympy/physics/quantum/tests/test_tensorproduct.py:51: in test_tensor_product_simp\n    assert tensor_product_simp(TP(A, B)**x) == TP(A**x, B**x)\nE   assert AxB**x == (A**x)x(B**x)\nE    +  where AxB**x = tensor_product_simp((AxB ** x))\nE    +    where AxB = TP(A, B)\nE    +  and   (A**x)x(B**x) = TP((A ** x), (B ** x))\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/core/containers.py:271\n  /testbed/sympy/core/containers.py:271: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    class OrderedSet(collections.MutableSet):\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\nsympy/physics/quantum/tests/test_tensorproduct.py::test_tensor_product_dagger\n  /testbed/sympy/matrices/common.py:2026: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    if not isinstance(other, collections.Iterable):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 1 failed, 6 passed, 5 warnings in 0.54s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/physics/quantum/tests/test_tensorproduct.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/physics/quantum/tests/test_tensorproduct.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 7,
          "failed": 0,
          "errors": 0,
          "collected": 7,
          "duration": 9.27,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 7 items\n\nsympy/physics/quantum/tests/test_tensorproduct.py::test_tensor_product_dagger PASSED [ 14%]\nsympy/physics/quantum/tests/test_tensorproduct.py::test_tensor_product_abstract PASSED [ 28%]\nsympy/physics/quantum/tests/test_tensorproduct.py::test_tensor_product_expand PASSED [ 42%]\nsympy/physics/quantum/tests/test_tensorproduct.py::test_tensor_product_commutator PASSED [ 57%]\nsympy/physics/quantum/tests/test_tensorproduct.py::test_tensor_product_simp PASSED [ 71%]\nsympy/physics/quantum/tests/test_tensorproduct.py::test_issue_5923 PASSED [ 85%]\nsympy/physics/quantum/tests/test_tensorproduct.py::test_eval_trace PASSED [100%]\n\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/core/containers.py:271\n  /testbed/sympy/core/containers.py:271: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    class OrderedSet(collections.MutableSet):\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\nsympy/physics/quantum/tests/test_tensorproduct.py::test_tensor_product_dagger\n  /testbed/sympy/matrices/common.py:2026: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    if not isinstance(other, collections.Iterable):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================== 7 passed, 5 warnings in 0.57s =========================\n\n",
          "test_files_run": [
            "sympy/physics/quantum/tests/test_tensorproduct.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-14248",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://35.239.238.137:8080",
      "duration": 37.510648012161255,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 499,
          "failed": 21,
          "errors": 0,
          "collected": 520,
          "duration": 17.13,
          "log_tail": "__________________________ test_MatrixSymbol_printing __________________________\nsympy/printing/tests/test_str.py:794: in test_MatrixSymbol_printing\n    assert str(A - A*B - B) == \"-B - A*B + A\"\nE   AssertionError: assert '(-1)*B + (-1)*A*B + A' == '-B - A*B + A'\nE     \nE     - -B - A*B + A\nE     + (-1)*B + (-1)*A*B + A\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/core/expr.py:12\n  /testbed/sympy/core/expr.py:12: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import defaultdict, Iterable\n\nsympy/core/containers.py:271\n  /testbed/sympy/core/containers.py:271: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    class OrderedSet(collections.MutableSet):\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\nsympy/vector/coordsysrect.py:171\n  /testbed/sympy/vector/coordsysrect.py:171: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if transformation.name is 'spherical':\n\nsympy/vector/coordsysrect.py:173\n  /testbed/sympy/vector/coordsysrect.py:173: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    elif transformation.name is 'cylindrical':\n\nsympy/printing/pretty/tests/test_pretty.py::test_pretty_geometry\n  /testbed/sympy/assumptions/sathandlers.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import MutableMapping, defaultdict\n\nsympy/printing/pretty/tests/test_pretty.py::test_PrettyModules\n  /testbed/sympy/polys/agca/modules.py:351: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    elif elem is 0:\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n================== 21 failed, 499 passed, 9 warnings in 9.13s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/printing/pretty/tests/test_pretty.py sympy/printing/tests/test_ccode.py sympy/printing/tests/test_fcode.py sympy/printing/tests/test_jscode.py sympy/printing/tests/test_julia.py sympy/printing/tests/test_latex.py sympy/printing/tests/test_octave.py sympy/printing/tests/test_rcode.py sympy/printing/tests/test_str.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/printing/pretty/tests/test_pretty.py",
            "sympy/printing/tests/test_ccode.py",
            "sympy/printing/tests/test_fcode.py",
            "sympy/printing/tests/test_jscode.py",
            "sympy/printing/tests/test_julia.py",
            "sympy/printing/tests/test_latex.py",
            "sympy/printing/tests/test_octave.py",
            "sympy/printing/tests/test_rcode.py",
            "sympy/printing/tests/test_str.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 510,
          "failed": 10,
          "errors": 0,
          "collected": 520,
          "duration": 19.09,
          "log_tail": "E     ?         +        +       ^^^^^^^^^^\nE     - 1        2        x*y]\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:121: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_Matrices_entries_not_hadamard\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/core/expr.py:12\n  /testbed/sympy/core/expr.py:12: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import defaultdict, Iterable\n\nsympy/core/containers.py:271\n  /testbed/sympy/core/containers.py:271: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    class OrderedSet(collections.MutableSet):\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\nsympy/vector/coordsysrect.py:171\n  /testbed/sympy/vector/coordsysrect.py:171: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if transformation.name is 'spherical':\n\nsympy/vector/coordsysrect.py:173\n  /testbed/sympy/vector/coordsysrect.py:173: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    elif transformation.name is 'cylindrical':\n\nsympy/printing/pretty/tests/test_pretty.py::test_pretty_geometry\n  /testbed/sympy/assumptions/sathandlers.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import MutableMapping, defaultdict\n\nsympy/printing/pretty/tests/test_pretty.py::test_PrettyModules\n  /testbed/sympy/polys/agca/modules.py:351: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    elif elem is 0:\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n================== 10 failed, 510 passed, 9 warnings in 9.84s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/printing/pretty/tests/test_pretty.py sympy/printing/tests/test_ccode.py sympy/printing/tests/test_fcode.py sympy/printing/tests/test_jscode.py sympy/printing/tests/test_julia.py sympy/printing/tests/test_latex.py sympy/printing/tests/test_octave.py sympy/printing/tests/test_rcode.py sympy/printing/tests/test_str.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/printing/pretty/tests/test_pretty.py",
            "sympy/printing/tests/test_ccode.py",
            "sympy/printing/tests/test_fcode.py",
            "sympy/printing/tests/test_jscode.py",
            "sympy/printing/tests/test_julia.py",
            "sympy/printing/tests/test_latex.py",
            "sympy/printing/tests/test_octave.py",
            "sympy/printing/tests/test_rcode.py",
            "sympy/printing/tests/test_str.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sympy__sympy-14531",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://35.239.238.137:8080",
      "duration": 20.27049207687378,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 86,
          "failed": 3,
          "errors": 0,
          "collected": 89,
          "duration": 9.12,
          "log_tail": "_______________________ test_python_functions_conjugates _______________________\nsympy/printing/tests/test_python.py:131: in test_python_functions_conjugates\n    assert python( conjugate(a + b*I) ) == '_     _\\na - I*b'\nE   assert \"a = Symbol('...*conjugate(b)\" == '_     _\\na - I*b'\nE     \nE     - _     _\nE     - a - I*b\nE     + a = Symbol('a')\nE     + b = Symbol('b')\nE     + e = conjugate(a) - I*conjugate(b)\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:121: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_python_functions_conjugates\n________________________________ test_Rational _________________________________\nsympy/printing/tests/test_str.py:495: in test_Rational\n    assert sstr(Eq(x, Rational(2, 3)), sympy_integers=True) == \"Eq(x, S(2)/3)\"\nE   AssertionError: assert 'Eq(x, 2/3)' == 'Eq(x, S(2)/3)'\nE     \nE     - Eq(x, S(2)/3)\nE     ?       -- -\nE     + Eq(x, 2/3)\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/core/expr.py:12\n  /testbed/sympy/core/expr.py:12: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import defaultdict, Iterable\n\nsympy/core/containers.py:271\n  /testbed/sympy/core/containers.py:271: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    class OrderedSet(collections.MutableSet):\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 3 failed, 86 passed, 5 warnings in 1.43s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/printing/tests/test_python.py sympy/printing/tests/test_str.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/printing/tests/test_python.py",
            "sympy/printing/tests/test_str.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 88,
          "failed": 1,
          "errors": 0,
          "collected": 89,
          "duration": 9.98,
          "log_tail": "sympy/printing/tests/test_str.py::test_Xor PASSED                        [ 94%]\nsympy/printing/tests/test_str.py::test_Complement PASSED                 [ 95%]\nsympy/printing/tests/test_str.py::test_SymmetricDifference PASSED        [ 96%]\nsympy/printing/tests/test_str.py::test_UnevaluatedExpr PASSED            [ 97%]\nsympy/printing/tests/test_str.py::test_MatrixElement_printing PASSED     [ 98%]\nsympy/printing/tests/test_str.py::test_MatrixSymbol_printing PASSED      [100%]\n\n=================================== FAILURES ===================================\n_______________________ test_python_functions_conjugates _______________________\nsympy/printing/tests/test_python.py:131: in test_python_functions_conjugates\n    assert python( conjugate(a + b*I) ) == '_     _\\na - I*b'\nE   assert \"a = Symbol('...*conjugate(b)\" == '_     _\\na - I*b'\nE     \nE     - _     _\nE     - a - I*b\nE     + a = Symbol('a')\nE     + b = Symbol('b')\nE     + e = conjugate(a) - I*conjugate(b)\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:121: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_python_functions_conjugates\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/core/expr.py:12\n  /testbed/sympy/core/expr.py:12: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import defaultdict, Iterable\n\nsympy/core/containers.py:271\n  /testbed/sympy/core/containers.py:271: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    class OrderedSet(collections.MutableSet):\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 1 failed, 88 passed, 5 warnings in 1.58s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/printing/tests/test_python.py sympy/printing/tests/test_str.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/printing/tests/test_python.py",
            "sympy/printing/tests/test_str.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sympy__sympy-14711",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 20.212460041046143,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 3,
          "failed": 1,
          "errors": 0,
          "collected": 4,
          "duration": 9.06,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 4 items\n\nsympy/physics/vector/tests/test_vector.py::test_Vector FAILED            [ 25%]\nsympy/physics/vector/tests/test_vector.py::test_Vector_diffs PASSED      [ 50%]\nsympy/physics/vector/tests/test_vector.py::test_vector_var_in_dcm PASSED [ 75%]\nsympy/physics/vector/tests/test_vector.py::test_vector_simplify PASSED   [100%]\n\n=================================== FAILURES ===================================\n_________________________________ test_Vector __________________________________\nsympy/physics/vector/tests/test_vector.py:16: in test_Vector\n    assert A.x + 0 == A.x\nsympy/physics/vector/vector.py:60: in __add__\n    other = _check_vector(other)\nsympy/physics/vector/vector.py:725: in _check_vector\n    raise TypeError('A Vector must be supplied')\nE   TypeError: A Vector must be supplied\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/core/expr.py:12\n  /testbed/sympy/core/expr.py:12: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import defaultdict, Iterable\n\nsympy/core/containers.py:271\n  /testbed/sympy/core/containers.py:271: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    class OrderedSet(collections.MutableSet):\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\nsympy/physics/vector/printing.py:151\n  /testbed/sympy/physics/vector/printing.py:151: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n    if len(base_split) is not 1:\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 1 failed, 3 passed, 6 warnings in 1.14s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/physics/vector/tests/test_vector.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/physics/vector/tests/test_vector.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 4,
          "failed": 0,
          "errors": 0,
          "collected": 4,
          "duration": 9.86,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 4 items\n\nsympy/physics/vector/tests/test_vector.py::test_Vector PASSED            [ 25%]\nsympy/physics/vector/tests/test_vector.py::test_Vector_diffs PASSED      [ 50%]\nsympy/physics/vector/tests/test_vector.py::test_vector_var_in_dcm PASSED [ 75%]\nsympy/physics/vector/tests/test_vector.py::test_vector_simplify PASSED   [100%]\n\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/core/expr.py:12\n  /testbed/sympy/core/expr.py:12: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import defaultdict, Iterable\n\nsympy/core/containers.py:271\n  /testbed/sympy/core/containers.py:271: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    class OrderedSet(collections.MutableSet):\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\nsympy/physics/vector/printing.py:151\n  /testbed/sympy/physics/vector/printing.py:151: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n    if len(base_split) is not 1:\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================== 4 passed, 6 warnings in 1.08s =========================\n\n",
          "test_files_run": [
            "sympy/physics/vector/tests/test_vector.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-14976",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://35.239.238.137:8080",
      "duration": 19.13353705406189,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 14,
          "failed": 4,
          "errors": 0,
          "collected": 18,
          "duration": 8.79,
          "log_tail": "sympy/utilities/decorator.py:91: in func_wrapper\n    return func(*args, **kwargs)\nsympy/solvers/solvers.py:2927: in nsolve\n    x = sympify(findroot(f, x0, **kwargs))\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/mpmath/calculus/optimization.py:985: in findroot\n    raise ValueError('Could not find root within given tolerance. '\nE   ValueError: Could not find root within given tolerance. (10000.0 > 2.16840434497100886801e-19)\nE   Try another starting point or tweak arguments.\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:121: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_nsolve_fail\n_____________________________ test_issue_6408_fail _____________________________\nsympy/solvers/tests/test_numeric.py:76: in test_issue_6408_fail\n    assert nsolve(Integral(x*y, (x, 0, 5)), y, 2) == 0.0\nsympy/utilities/decorator.py:91: in func_wrapper\n    return func(*args, **kwargs)\nsympy/solvers/solvers.py:2927: in nsolve\n    x = sympify(findroot(f, x0, **kwargs))\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/mpmath/calculus/optimization.py:937: in findroot\n    fx = f(*x0)\n<lambdifygenerated-22>:4: in _lambdifygenerated\n    Integral(x*y, (x, 0, 5)))\nE   NameError: name 'Integral' is not defined\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:121: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_issue_6408_fail\n_____________________________ test_nsolve_rational _____________________________\nsympy/solvers/tests/test_numeric.py:126: in test_nsolve_rational\n    assert nsolve(x - Rational(1, 3), 0, prec=100) == Rational(1, 3).evalf(100)\nE   assert 0.3333333333333333148296162562473909929394721984863281250000000000000000000000000000000000000000000000 == 0.3333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333\nE    +  where 0.3333333333333333148296162562473909929394721984863281250000000000000000000000000000000000000000000000 = nsolve((x - 1/3), 0, prec=100)\nE    +    where 1/3 = Rational(1, 3)\nE    +  and   0.3333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333 = evalf(100)\nE    +    where evalf = 1/3.evalf\nE    +      where 1/3 = Rational(1, 3)\n=============================== warnings summary ===============================\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 4 failed, 14 passed, 1 warning in 0.43s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/printing/tests/test_pycode.py sympy/solvers/tests/test_numeric.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/printing/tests/test_pycode.py",
            "sympy/solvers/tests/test_numeric.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 16,
          "failed": 2,
          "errors": 0,
          "collected": 18,
          "duration": 9.01,
          "log_tail": "sympy/solvers/tests/test_numeric.py::test_nsolve_precision PASSED        [ 83%]\nsympy/solvers/tests/test_numeric.py::test_nsolve_complex PASSED          [ 88%]\nsympy/solvers/tests/test_numeric.py::test_nsolve_dict_kwarg PASSED       [ 94%]\nsympy/solvers/tests/test_numeric.py::test_nsolve_rational PASSED         [100%]\n\n=================================== FAILURES ===================================\n_______________________________ test_nsolve_fail _______________________________\nsympy/solvers/tests/test_numeric.py:15: in test_nsolve_fail\n    ans = nsolve(x**2/(1 - x)/(1 - 2*x)**2 - 100, x, 0)\nsympy/utilities/decorator.py:91: in func_wrapper\n    return func(*args, **kwargs)\nsympy/solvers/solvers.py:2927: in nsolve\n    x = sympify(findroot(f, x0, **kwargs))\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/mpmath/calculus/optimization.py:985: in findroot\n    raise ValueError('Could not find root within given tolerance. '\nE   ValueError: Could not find root within given tolerance. (10000.0 > 2.16840434497100886801e-19)\nE   Try another starting point or tweak arguments.\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:121: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_nsolve_fail\n_____________________________ test_issue_6408_fail _____________________________\nsympy/solvers/tests/test_numeric.py:76: in test_issue_6408_fail\n    assert nsolve(Integral(x*y, (x, 0, 5)), y, 2) == 0.0\nsympy/utilities/decorator.py:91: in func_wrapper\n    return func(*args, **kwargs)\nsympy/solvers/solvers.py:2927: in nsolve\n    x = sympify(findroot(f, x0, **kwargs))\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/mpmath/calculus/optimization.py:937: in findroot\n    fx = f(*x0)\n<lambdifygenerated-22>:4: in _lambdifygenerated\n    Integral(x*y, (x, 0, 5)))\nE   NameError: name 'Integral' is not defined\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:121: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_issue_6408_fail\n=============================== warnings summary ===============================\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 2 failed, 16 passed, 1 warning in 0.46s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/printing/tests/test_pycode.py sympy/solvers/tests/test_numeric.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/printing/tests/test_pycode.py",
            "sympy/solvers/tests/test_numeric.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sympy__sympy-15017",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 18.730338096618652,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 15,
          "failed": 1,
          "errors": 0,
          "collected": 16,
          "duration": 8.48,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 16 items\n\nsympy/tensor/array/tests/test_immutable_ndim_array.py::test_ndim_array_initiation FAILED [  6%]\nsympy/tensor/array/tests/test_immutable_ndim_array.py::test_reshape PASSED [ 12%]\nsympy/tensor/array/tests/test_immutable_ndim_array.py::test_iterator PASSED [ 18%]\nsympy/tensor/array/tests/test_immutable_ndim_array.py::test_sparse PASSED [ 25%]\nsympy/tensor/array/tests/test_immutable_ndim_array.py::test_calculation PASSED [ 31%]\nsympy/tensor/array/tests/test_immutable_ndim_array.py::test_ndim_array_converting PASSED [ 37%]\nsympy/tensor/array/tests/test_immutable_ndim_array.py::test_converting_functions PASSED [ 43%]\nsympy/tensor/array/tests/test_immutable_ndim_array.py::test_equality PASSED [ 50%]\nsympy/tensor/array/tests/test_immutable_ndim_array.py::test_arithmetic PASSED [ 56%]\nsympy/tensor/array/tests/test_immutable_ndim_array.py::test_higher_dimenions PASSED [ 62%]\nsympy/tensor/array/tests/test_immutable_ndim_array.py::test_rebuild_immutable_arrays PASSED [ 68%]\nsympy/tensor/array/tests/test_immutable_ndim_array.py::test_slices PASSED [ 75%]\nsympy/tensor/array/tests/test_immutable_ndim_array.py::test_diff_and_applyfunc PASSED [ 81%]\nsympy/tensor/array/tests/test_immutable_ndim_array.py::test_op_priority PASSED [ 87%]\nsympy/tensor/array/tests/test_immutable_ndim_array.py::test_symbolic_indexing PASSED [ 93%]\nsympy/tensor/array/tests/test_immutable_ndim_array.py::test_issue_12665 PASSED [100%]\n\n=================================== FAILURES ===================================\n__________________________ test_ndim_array_initiation __________________________\nsympy/tensor/array/tests/test_immutable_ndim_array.py:80: in test_ndim_array_initiation\n    assert len(rank_zero_array) == 1\nE   assert 0 == 1\nE    +  where 0 = len(x)\n=============================== warnings summary ===============================\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 1 failed, 15 passed, 1 warning in 0.28s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/tensor/array/tests/test_immutable_ndim_array.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/tensor/array/tests/test_immutable_ndim_array.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 16,
          "failed": 0,
          "errors": 0,
          "collected": 16,
          "duration": 9.01,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 16 items\n\nsympy/tensor/array/tests/test_immutable_ndim_array.py::test_ndim_array_initiation PASSED [  6%]\nsympy/tensor/array/tests/test_immutable_ndim_array.py::test_reshape PASSED [ 12%]\nsympy/tensor/array/tests/test_immutable_ndim_array.py::test_iterator PASSED [ 18%]\nsympy/tensor/array/tests/test_immutable_ndim_array.py::test_sparse PASSED [ 25%]\nsympy/tensor/array/tests/test_immutable_ndim_array.py::test_calculation PASSED [ 31%]\nsympy/tensor/array/tests/test_immutable_ndim_array.py::test_ndim_array_converting PASSED [ 37%]\nsympy/tensor/array/tests/test_immutable_ndim_array.py::test_converting_functions PASSED [ 43%]\nsympy/tensor/array/tests/test_immutable_ndim_array.py::test_equality PASSED [ 50%]\nsympy/tensor/array/tests/test_immutable_ndim_array.py::test_arithmetic PASSED [ 56%]\nsympy/tensor/array/tests/test_immutable_ndim_array.py::test_higher_dimenions PASSED [ 62%]\nsympy/tensor/array/tests/test_immutable_ndim_array.py::test_rebuild_immutable_arrays PASSED [ 68%]\nsympy/tensor/array/tests/test_immutable_ndim_array.py::test_slices PASSED [ 75%]\nsympy/tensor/array/tests/test_immutable_ndim_array.py::test_diff_and_applyfunc PASSED [ 81%]\nsympy/tensor/array/tests/test_immutable_ndim_array.py::test_op_priority PASSED [ 87%]\nsympy/tensor/array/tests/test_immutable_ndim_array.py::test_symbolic_indexing PASSED [ 93%]\nsympy/tensor/array/tests/test_immutable_ndim_array.py::test_issue_12665 PASSED [100%]\n\n=============================== warnings summary ===============================\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================== 16 passed, 1 warning in 0.30s =========================\n\n",
          "test_files_run": [
            "sympy/tensor/array/tests/test_immutable_ndim_array.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-15345",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 19.356653928756714,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 9,
          "failed": 1,
          "errors": 0,
          "collected": 10,
          "duration": 8.93,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 10 items\n\nsympy/printing/tests/test_mathematica.py::test_Integer PASSED            [ 10%]\nsympy/printing/tests/test_mathematica.py::test_Rational PASSED           [ 20%]\nsympy/printing/tests/test_mathematica.py::test_Function FAILED           [ 30%]\nsympy/printing/tests/test_mathematica.py::test_Pow PASSED                [ 40%]\nsympy/printing/tests/test_mathematica.py::test_Mul PASSED                [ 50%]\nsympy/printing/tests/test_mathematica.py::test_constants PASSED          [ 60%]\nsympy/printing/tests/test_mathematica.py::test_containers PASSED         [ 70%]\nsympy/printing/tests/test_mathematica.py::test_Integral PASSED           [ 80%]\nsympy/printing/tests/test_mathematica.py::test_Derivative PASSED         [ 90%]\nsympy/printing/tests/test_mathematica.py::test_Sum PASSED                [100%]\n\n=================================== FAILURES ===================================\n________________________________ test_Function _________________________________\nsympy/printing/tests/test_mathematica.py:31: in test_Function\n    assert mcode(Max(x,y,z)*Min(y,z)) == \"Max[x, y, z]*Min[y, z]\"\nE   AssertionError: assert 'Max(x, y, z)*Min(y, z)' == 'Max[x, y, z]*Min[y, z]'\nE     \nE     - Max[x, y, z]*Min[y, z]\nE     ?    ^       ^    ^    ^\nE     + Max(x, y, z)*Min(y, z)\nE     ?    ^       ^    ^    ^\n=============================== warnings summary ===============================\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n==================== 1 failed, 9 passed, 1 warning in 0.16s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/printing/tests/test_mathematica.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/printing/tests/test_mathematica.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 10,
          "failed": 0,
          "errors": 0,
          "collected": 10,
          "duration": 9.21,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 10 items\n\nsympy/printing/tests/test_mathematica.py::test_Integer PASSED            [ 10%]\nsympy/printing/tests/test_mathematica.py::test_Rational PASSED           [ 20%]\nsympy/printing/tests/test_mathematica.py::test_Function PASSED           [ 30%]\nsympy/printing/tests/test_mathematica.py::test_Pow PASSED                [ 40%]\nsympy/printing/tests/test_mathematica.py::test_Mul PASSED                [ 50%]\nsympy/printing/tests/test_mathematica.py::test_constants PASSED          [ 60%]\nsympy/printing/tests/test_mathematica.py::test_containers PASSED         [ 70%]\nsympy/printing/tests/test_mathematica.py::test_Integral PASSED           [ 80%]\nsympy/printing/tests/test_mathematica.py::test_Derivative PASSED         [ 90%]\nsympy/printing/tests/test_mathematica.py::test_Sum PASSED                [100%]\n\n=============================== warnings summary ===============================\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================== 10 passed, 1 warning in 0.13s =========================\n\n",
          "test_files_run": [
            "sympy/printing/tests/test_mathematica.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-15349",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 19.338500022888184,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 3,
          "failed": 2,
          "errors": 0,
          "collected": 5,
          "duration": 8.84,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 5 items\n\nsympy/algebras/tests/test_quaternion.py::test_quaternion_construction PASSED [ 20%]\nsympy/algebras/tests/test_quaternion.py::test_quaternion_complex_real_addition PASSED [ 40%]\nsympy/algebras/tests/test_quaternion.py::test_quaternion_functions PASSED [ 60%]\nsympy/algebras/tests/test_quaternion.py::test_quaternion_conversions FAILED [ 80%]\nsympy/algebras/tests/test_quaternion.py::test_quaternion_rotation_iss1593 FAILED [100%]\n\n=================================== FAILURES ===================================\n_________________________ test_quaternion_conversions __________________________\nsympy/algebras/tests/test_quaternion.py:98: in test_quaternion_conversions\n    assert q1.to_rotation_matrix() == Matrix([[-S(2)/3, S(2)/15, S(11)/15],\nE   assert Matrix([\\n[-2/...4/15,  2/15]]) == Matrix([\\n[-2/...4/15,  2/15]])\nE     \nE     Full diff:\nE       Matrix([\nE       [-2/3,  2/15, 11/15],\nE     - [ 2/3,  -1/3,   2/3],\nE     ?               ^^^ ^\nE     + [ 2/3,  -1/3, 14/15],\nE     ?               ^^ ^^\nE       [ 1/3, 14/15,  2/15]])\n_______________________ test_quaternion_rotation_iss1593 _______________________\nsympy/algebras/tests/test_quaternion.py:135: in test_quaternion_rotation_iss1593\n    assert(trigsimp(q.to_rotation_matrix()) == Matrix([\nE   AssertionError: assert Matrix([\\n[1, ...(x), cos(x)]]) == Matrix([\\n[1, ...x),  cos(x)]])\nE     \nE     Full diff:\nE       Matrix([\nE     - [1,      0,       0],\nE     ?            -\nE     + [1,      0,      0],\nE     - [0, cos(x), -sin(x)],...\nE     \nE     ...Full output truncated (5 lines hidden), use '-vv' to show\n=============================== warnings summary ===============================\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n==================== 2 failed, 3 passed, 1 warning in 0.44s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/algebras/tests/test_quaternion.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/algebras/tests/test_quaternion.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 5,
          "failed": 0,
          "errors": 0,
          "collected": 5,
          "duration": 9.24,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 5 items\n\nsympy/algebras/tests/test_quaternion.py::test_quaternion_construction PASSED [ 20%]\nsympy/algebras/tests/test_quaternion.py::test_quaternion_complex_real_addition PASSED [ 40%]\nsympy/algebras/tests/test_quaternion.py::test_quaternion_functions PASSED [ 60%]\nsympy/algebras/tests/test_quaternion.py::test_quaternion_conversions PASSED [ 80%]\nsympy/algebras/tests/test_quaternion.py::test_quaternion_rotation_iss1593 PASSED [100%]\n\n=============================== warnings summary ===============================\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n========================= 5 passed, 1 warning in 0.57s =========================\n\n",
          "test_files_run": [
            "sympy/algebras/tests/test_quaternion.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-15599",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://35.239.238.137:8080",
      "duration": 30.557758808135986,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 81,
          "failed": 4,
          "errors": 0,
          "collected": 85,
          "duration": 14.37,
          "log_tail": "E    +  where None = ((y * x) * (x + k)).is_odd\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:124: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_oddness_in_ternary_integer_product_with_odd\n_______________________________ test_issue_3531 ________________________________\nsympy/core/tests/test_arit.py:1351: in test_issue_3531\n    assert sympify(1)/MightyNumeric((1, 2)) == \"something\"\nsympy/core/decorators.py:91: in __sympifyit_wrapper\n    return func(a, b)\nsympy/core/numbers.py:1643: in __div__\n    return Number.__div__(self, other)\nsympy/core/decorators.py:91: in __sympifyit_wrapper\n    return func(a, b)\nsympy/core/numbers.py:691: in __div__\n    return AtomicExpr.__div__(self, other)\nsympy/core/decorators.py:91: in __sympifyit_wrapper\n    return func(a, b)\nsympy/core/decorators.py:132: in binary_op_wrapper\n    return func(self, other)\nsympy/core/expr.py:188: in __div__\n    return Mul(self, Pow(other, S.NegativeOne))\nsympy/core/cache.py:94: in wrapper\n    retval = cfunc(*args, **kwargs)\nsympy/core/power.py:286: in __new__\n    obj = b._eval_power(e)\nE   AttributeError: 'Tuple' object has no attribute '_eval_power'\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:124: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_issue_3531\n___________________________________ test_Mod ___________________________________\nsympy/core/tests/test_arit.py:1667: in test_Mod\n    assert Mod(3*i, 2) == Mod(i, 2)\nE   assert Mod(3*i, 2) == Mod(i, 2)\nE    +  where Mod(3*i, 2) = Mod((3 * i), 2)\nE    +  and   Mod(i, 2) = Mod(i, 2)\n=============================== warnings summary ===============================\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 4 failed, 81 passed, 1 warning in 5.44s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/core/tests/test_arit.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/core/tests/test_arit.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 82,
          "failed": 3,
          "errors": 0,
          "collected": 85,
          "duration": 14.93,
          "log_tail": "    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_evenness_in_ternary_integer_product_with_odd\n_______________ test_oddness_in_ternary_integer_product_with_odd _______________\nsympy/core/tests/test_arit.py:480: in test_oddness_in_ternary_integer_product_with_odd\n    assert (y*x*(x + k)).is_odd is False\nE   assert None is False\nE    +  where None = ((y * x) * (x + k)).is_odd\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:124: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_oddness_in_ternary_integer_product_with_odd\n_______________________________ test_issue_3531 ________________________________\nsympy/core/tests/test_arit.py:1351: in test_issue_3531\n    assert sympify(1)/MightyNumeric((1, 2)) == \"something\"\nsympy/core/decorators.py:91: in __sympifyit_wrapper\n    return func(a, b)\nsympy/core/numbers.py:1643: in __div__\n    return Number.__div__(self, other)\nsympy/core/decorators.py:91: in __sympifyit_wrapper\n    return func(a, b)\nsympy/core/numbers.py:691: in __div__\n    return AtomicExpr.__div__(self, other)\nsympy/core/decorators.py:91: in __sympifyit_wrapper\n    return func(a, b)\nsympy/core/decorators.py:132: in binary_op_wrapper\n    return func(self, other)\nsympy/core/expr.py:188: in __div__\n    return Mul(self, Pow(other, S.NegativeOne))\nsympy/core/cache.py:94: in wrapper\n    retval = cfunc(*args, **kwargs)\nsympy/core/power.py:286: in __new__\n    obj = b._eval_power(e)\nE   AttributeError: 'Tuple' object has no attribute '_eval_power'\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:124: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_issue_3531\n=============================== warnings summary ===============================\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 3 failed, 82 passed, 1 warning in 5.34s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/core/tests/test_arit.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/core/tests/test_arit.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sympy__sympy-15809",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://35.239.238.137:8080",
      "duration": 24.25441884994507,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 11,
          "failed": 3,
          "errors": 0,
          "collected": 14,
          "duration": 11.07,
          "log_tail": "___________________________________ test_Min ___________________________________\nsympy/functions/elementary/tests/test_miscellaneous.py:88: in test_Min\n    assert Min() == S.Infinity\nsympy/functions/elementary/miscellaneous.py:343: in __new__\n    raise ValueError(\"The Max/Min functions must have arguments.\")\nE   ValueError: The Max/Min functions must have arguments.\n___________________________________ test_Max ___________________________________\nsympy/functions/elementary/tests/test_miscellaneous.py:160: in test_Max\n    assert Max() == S.NegativeInfinity\nsympy/functions/elementary/miscellaneous.py:343: in __new__\n    raise ValueError(\"The Max/Min functions must have arguments.\")\nE   ValueError: The Max/Min functions must have arguments.\n_______________________________ test_issue_11463 _______________________________\nsympy/functions/elementary/tests/test_miscellaneous.py:346: in test_issue_11463\n    skip(\"numpy not installed.\")\nsympy/utilities/pytest.py:138: in skip\n    raise Skipped(str)\nE   sympy.utilities.pytest.Skipped: numpy not installed.\n=============================== warnings summary ===============================\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:520\n  /testbed/sympy/plotting/plot.py:520: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:540\n  /testbed/sympy/plotting/plot.py:540: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:553\n  /testbed/sympy/plotting/plot.py:553: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:560\n  /testbed/sympy/plotting/plot.py:560: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 3 failed, 11 passed, 6 warnings in 2.29s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/functions/elementary/tests/test_miscellaneous.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/functions/elementary/tests/test_miscellaneous.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 13,
          "failed": 1,
          "errors": 0,
          "collected": 14,
          "duration": 11.98,
          "log_tail": "sympy/functions/elementary/tests/test_miscellaneous.py::test_root PASSED [ 35%]\nsympy/functions/elementary/tests/test_miscellaneous.py::test_real_root PASSED [ 42%]\nsympy/functions/elementary/tests/test_miscellaneous.py::test_issue_11463 FAILED [ 50%]\nsympy/functions/elementary/tests/test_miscellaneous.py::test_rewrite_MaxMin_as_Heaviside PASSED [ 57%]\nsympy/functions/elementary/tests/test_miscellaneous.py::test_rewrite_MaxMin_as_Piecewise PASSED [ 64%]\nsympy/functions/elementary/tests/test_miscellaneous.py::test_issue_11099 PASSED [ 71%]\nsympy/functions/elementary/tests/test_miscellaneous.py::test_issue_12638 PASSED [ 78%]\nsympy/functions/elementary/tests/test_miscellaneous.py::test_instantiation_evaluation PASSED [ 85%]\nsympy/functions/elementary/tests/test_miscellaneous.py::test_rewrite_as_Abs PASSED [ 92%]\nsympy/functions/elementary/tests/test_miscellaneous.py::test_issue_14000 PASSED [100%]\n\n=================================== FAILURES ===================================\n_______________________________ test_issue_11463 _______________________________\nsympy/functions/elementary/tests/test_miscellaneous.py:346: in test_issue_11463\n    skip(\"numpy not installed.\")\nsympy/utilities/pytest.py:138: in skip\n    raise Skipped(str)\nE   sympy.utilities.pytest.Skipped: numpy not installed.\n=============================== warnings summary ===============================\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:520\n  /testbed/sympy/plotting/plot.py:520: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:540\n  /testbed/sympy/plotting/plot.py:540: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:553\n  /testbed/sympy/plotting/plot.py:553: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:560\n  /testbed/sympy/plotting/plot.py:560: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 1 failed, 13 passed, 6 warnings in 2.49s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/functions/elementary/tests/test_miscellaneous.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/functions/elementary/tests/test_miscellaneous.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sympy__sympy-15875",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://35.239.238.137:8080",
      "duration": 30.595710039138794,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 81,
          "failed": 4,
          "errors": 0,
          "collected": 85,
          "duration": 14.29,
          "log_tail": "    return func(self, other)\nsympy/core/expr.py:188: in __div__\n    return Mul(self, Pow(other, S.NegativeOne))\nsympy/core/cache.py:94: in wrapper\n    retval = cfunc(*args, **kwargs)\nsympy/core/power.py:286: in __new__\n    obj = b._eval_power(e)\nE   AttributeError: 'Tuple' object has no attribute '_eval_power'\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_issue_3531\n_______________________________ test_Add_is_zero _______________________________\nsympy/core/tests/test_arit.py:1991: in test_Add_is_zero\n    assert e.is_zero is None\nE   assert False is None\nE    +  where False = -2*I + (1 + I)**2.is_zero\n=============================== warnings summary ===============================\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:520\n  /testbed/sympy/plotting/plot.py:520: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:540\n  /testbed/sympy/plotting/plot.py:540: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:553\n  /testbed/sympy/plotting/plot.py:553: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:560\n  /testbed/sympy/plotting/plot.py:560: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 4 failed, 81 passed, 6 warnings in 5.47s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/core/tests/test_arit.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/core/tests/test_arit.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 82,
          "failed": 3,
          "errors": 0,
          "collected": 85,
          "duration": 15.1,
          "log_tail": "sympy/core/numbers.py:673: in __div__\n    return AtomicExpr.__div__(self, other)\nsympy/core/decorators.py:91: in __sympifyit_wrapper\n    return func(a, b)\nsympy/core/decorators.py:132: in binary_op_wrapper\n    return func(self, other)\nsympy/core/expr.py:188: in __div__\n    return Mul(self, Pow(other, S.NegativeOne))\nsympy/core/cache.py:94: in wrapper\n    retval = cfunc(*args, **kwargs)\nsympy/core/power.py:286: in __new__\n    obj = b._eval_power(e)\nE   AttributeError: 'Tuple' object has no attribute '_eval_power'\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_issue_3531\n=============================== warnings summary ===============================\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:520\n  /testbed/sympy/plotting/plot.py:520: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:540\n  /testbed/sympy/plotting/plot.py:540: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:553\n  /testbed/sympy/plotting/plot.py:553: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:560\n  /testbed/sympy/plotting/plot.py:560: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 3 failed, 82 passed, 6 warnings in 5.11s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/core/tests/test_arit.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/core/tests/test_arit.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sympy__sympy-15976",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 20.714490175247192,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 38,
          "failed": 1,
          "errors": 0,
          "collected": 39,
          "duration": 10.07,
          "log_tail": "sympy/printing/tests/test_mathml.py::test_presentation_symbol FAILED     [ 79%]\nsympy/printing/tests/test_mathml.py::test_presentation_mathml_greek PASSED [ 82%]\nsympy/printing/tests/test_mathml.py::test_presentation_mathml_order PASSED [ 84%]\nsympy/printing/tests/test_mathml.py::test_presentation_settings PASSED   [ 87%]\nsympy/printing/tests/test_mathml.py::test_toprettyxml_hooking PASSED     [ 89%]\nsympy/printing/tests/test_mathml.py::test_print_basic PASSED             [ 92%]\nsympy/printing/tests/test_mathml.py::test_root_notation_print PASSED     [ 94%]\nsympy/printing/tests/test_mathml.py::test_print_matrix_symbol PASSED     [ 97%]\nsympy/printing/tests/test_mathml.py::test_print_random_symbol PASSED     [100%]\n\n=================================== FAILURES ===================================\n___________________________ test_presentation_symbol ___________________________\nsympy/printing/tests/test_mathml.py:738: in test_presentation_symbol\n    assert mml.nodeName == 'msup'\nE   AssertionError: assert 'mi' == 'msup'\nE     \nE     - msup\nE     + mi\n=============================== warnings summary ===============================\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:520\n  /testbed/sympy/plotting/plot.py:520: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:540\n  /testbed/sympy/plotting/plot.py:540: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:553\n  /testbed/sympy/plotting/plot.py:553: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:560\n  /testbed/sympy/plotting/plot.py:560: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 1 failed, 38 passed, 6 warnings in 0.82s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/printing/tests/test_mathml.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/printing/tests/test_mathml.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 39,
          "failed": 0,
          "errors": 0,
          "collected": 39,
          "duration": 9.29,
          "log_tail": "sympy/printing/tests/test_mathml.py::test_presentation_mathml_functions PASSED [ 53%]\nsympy/printing/tests/test_mathml.py::test_presentation_mathml_limits PASSED [ 56%]\nsympy/printing/tests/test_mathml.py::test_presentation_mathml_integrals PASSED [ 58%]\nsympy/printing/tests/test_mathml.py::test_presentation_mathml_matrices PASSED [ 61%]\nsympy/printing/tests/test_mathml.py::test_presentation_mathml_sums PASSED [ 64%]\nsympy/printing/tests/test_mathml.py::test_presentation_mathml_add PASSED [ 66%]\nsympy/printing/tests/test_mathml.py::test_presentation_mathml_Rational PASSED [ 69%]\nsympy/printing/tests/test_mathml.py::test_presentation_mathml_constants PASSED [ 71%]\nsympy/printing/tests/test_mathml.py::test_presentation_mathml_trig PASSED [ 74%]\nsympy/printing/tests/test_mathml.py::test_presentation_mathml_relational PASSED [ 76%]\nsympy/printing/tests/test_mathml.py::test_presentation_symbol PASSED     [ 79%]\nsympy/printing/tests/test_mathml.py::test_presentation_mathml_greek PASSED [ 82%]\nsympy/printing/tests/test_mathml.py::test_presentation_mathml_order PASSED [ 84%]\nsympy/printing/tests/test_mathml.py::test_presentation_settings PASSED   [ 87%]\nsympy/printing/tests/test_mathml.py::test_toprettyxml_hooking PASSED     [ 89%]\nsympy/printing/tests/test_mathml.py::test_print_basic PASSED             [ 92%]\nsympy/printing/tests/test_mathml.py::test_root_notation_print PASSED     [ 94%]\nsympy/printing/tests/test_mathml.py::test_print_matrix_symbol PASSED     [ 97%]\nsympy/printing/tests/test_mathml.py::test_print_random_symbol PASSED     [100%]\n\n=============================== warnings summary ===============================\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:520\n  /testbed/sympy/plotting/plot.py:520: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:540\n  /testbed/sympy/plotting/plot.py:540: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:553\n  /testbed/sympy/plotting/plot.py:553: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:560\n  /testbed/sympy/plotting/plot.py:560: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================== 39 passed, 6 warnings in 0.66s ========================\n\n",
          "test_files_run": [
            "sympy/printing/tests/test_mathml.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-16450",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://35.239.238.137:8080",
      "duration": 39.870766162872314,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 40,
          "failed": 3,
          "errors": 0,
          "collected": 43,
          "duration": 19.19,
          "log_tail": "E     Full diff:\nE       {...\nE     \nE     ...Full output truncated (14 lines hidden), use '-vv' to show\n________________________ test_simplify_float_vs_integer ________________________\nsympy/simplify/tests/test_simplify.py:533: in test_simplify_float_vs_integer\n    assert simplify(x**2.0 - x**2) == 0\nE   assert -x**2 + x**2.0 == 0\nE    +  where -x**2 + x**2.0 = simplify(((x ** 2.0) - (x ** 2)))\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_simplify_float_vs_integer\n=============================== warnings summary ===============================\nsympy/solvers/diophantine.py:3186\n  /testbed/sympy/solvers/diophantine.py:3186: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:509\n  /testbed/sympy/plotting/plot.py:509: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:529\n  /testbed/sympy/plotting/plot.py:529: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:542\n  /testbed/sympy/plotting/plot.py:542: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:549\n  /testbed/sympy/plotting/plot.py:549: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\nsympy/simplify/tests/test_simplify.py::test_simplify_expr\n  /testbed/sympy/polys/agca/modules.py:360: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    elif elem is 0:\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n================== 3 failed, 40 passed, 7 warnings in 10.09s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/simplify/tests/test_simplify.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/simplify/tests/test_simplify.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 41,
          "failed": 2,
          "errors": 0,
          "collected": 43,
          "duration": 19.44,
          "log_tail": "During handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_factorial_simplify\n________________________ test_simplify_float_vs_integer ________________________\nsympy/simplify/tests/test_simplify.py:533: in test_simplify_float_vs_integer\n    assert simplify(x**2.0 - x**2) == 0\nE   assert -x**2 + x**2.0 == 0\nE    +  where -x**2 + x**2.0 = simplify(((x ** 2.0) - (x ** 2)))\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_simplify_float_vs_integer\n=============================== warnings summary ===============================\nsympy/solvers/diophantine.py:3186\n  /testbed/sympy/solvers/diophantine.py:3186: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:509\n  /testbed/sympy/plotting/plot.py:509: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:529\n  /testbed/sympy/plotting/plot.py:529: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:542\n  /testbed/sympy/plotting/plot.py:542: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:549\n  /testbed/sympy/plotting/plot.py:549: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\nsympy/simplify/tests/test_simplify.py::test_simplify_expr\n  /testbed/sympy/polys/agca/modules.py:360: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    elif elem is 0:\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n================== 2 failed, 41 passed, 7 warnings in 10.57s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/simplify/tests/test_simplify.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/simplify/tests/test_simplify.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sympy__sympy-16597",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://35.239.238.137:8080",
      "duration": 27.260037183761597,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 76,
          "failed": 7,
          "errors": 0,
          "collected": 83,
          "duration": 12.64,
          "log_tail": "    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_issue_6275\n_______________________________ test_issue_7993 ________________________________\nsympy/core/tests/test_assumptions.py:1007: in test_issue_7993\n    assert (x - y).is_zero is False\nE   assert None is False\nE    +  where None = (_Dummy_207 - _Dummy_208).is_zero\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_issue_7993\n_______________________________ test_issue_11463 _______________________________\nsympy/functions/elementary/tests/test_miscellaneous.py:346: in test_issue_11463\n    skip(\"numpy not installed.\")\nsympy/utilities/pytest.py:138: in skip\n    raise Skipped(str)\nE   sympy.utilities.pytest.Skipped: numpy not installed.\n=============================== warnings summary ===============================\nsympy/solvers/diophantine.py:3185\n  /testbed/sympy/solvers/diophantine.py:3185: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:644\n  /testbed/sympy/plotting/plot.py:644: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:664\n  /testbed/sympy/plotting/plot.py:664: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:677\n  /testbed/sympy/plotting/plot.py:677: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:684\n  /testbed/sympy/plotting/plot.py:684: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 7 failed, 76 passed, 6 warnings in 3.68s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/core/tests/test_assumptions.py sympy/functions/elementary/tests/test_miscellaneous.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/core/tests/test_assumptions.py",
            "sympy/functions/elementary/tests/test_miscellaneous.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 79,
          "failed": 4,
          "errors": 0,
          "collected": 83,
          "duration": 13.29,
          "log_tail": "    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_issue_6275\n_______________________________ test_issue_7993 ________________________________\nsympy/core/tests/test_assumptions.py:1007: in test_issue_7993\n    assert (x - y).is_zero is False\nE   assert None is False\nE    +  where None = (_Dummy_208 - _Dummy_209).is_zero\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_issue_7993\n_______________________________ test_issue_11463 _______________________________\nsympy/functions/elementary/tests/test_miscellaneous.py:346: in test_issue_11463\n    skip(\"numpy not installed.\")\nsympy/utilities/pytest.py:138: in skip\n    raise Skipped(str)\nE   sympy.utilities.pytest.Skipped: numpy not installed.\n=============================== warnings summary ===============================\nsympy/solvers/diophantine.py:3185\n  /testbed/sympy/solvers/diophantine.py:3185: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:644\n  /testbed/sympy/plotting/plot.py:644: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:664\n  /testbed/sympy/plotting/plot.py:664: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:677\n  /testbed/sympy/plotting/plot.py:677: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:684\n  /testbed/sympy/plotting/plot.py:684: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 4 failed, 79 passed, 6 warnings in 4.02s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/core/tests/test_assumptions.py sympy/functions/elementary/tests/test_miscellaneous.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/core/tests/test_assumptions.py",
            "sympy/functions/elementary/tests/test_miscellaneous.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sympy__sympy-16766",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 20.79118800163269,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 8,
          "failed": 1,
          "errors": 0,
          "collected": 9,
          "duration": 9.38,
          "log_tail": "sympy/printing/tests/test_pycode.py::test_MpmathPrinter PASSED           [ 22%]\nsympy/printing/tests/test_pycode.py::test_NumPyPrinter PASSED            [ 33%]\nsympy/printing/tests/test_pycode.py::test_SciPyPrinter PASSED            [ 44%]\nsympy/printing/tests/test_pycode.py::test_pycode_reserved_words PASSED   [ 55%]\nsympy/printing/tests/test_pycode.py::test_printmethod PASSED             [ 66%]\nsympy/printing/tests/test_pycode.py::test_codegen_ast_nodes PASSED       [ 77%]\nsympy/printing/tests/test_pycode.py::test_issue_14283 PASSED             [ 88%]\nsympy/printing/tests/test_pycode.py::test_NumPyPrinter_print_seq PASSED  [100%]\n\n=================================== FAILURES ===================================\n____________________________ test_PythonCodePrinter ____________________________\nsympy/printing/tests/test_pycode.py:38: in test_PythonCodePrinter\n    assert prntr.doprint(p[0, 1]) == 'p[0, 1]'\nE   AssertionError: assert '  # Not supp...exed\\np[0, 1]' == 'p[0, 1]'\nE     \nE     +   # Not supported in Python:\nE     +   # Indexed\nE       p[0, 1]\n=============================== warnings summary ===============================\nsympy/solvers/diophantine.py:3185\n  /testbed/sympy/solvers/diophantine.py:3185: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:644\n  /testbed/sympy/plotting/plot.py:644: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:664\n  /testbed/sympy/plotting/plot.py:664: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:677\n  /testbed/sympy/plotting/plot.py:677: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:684\n  /testbed/sympy/plotting/plot.py:684: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 1 failed, 8 passed, 6 warnings in 0.30s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/printing/tests/test_pycode.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/printing/tests/test_pycode.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 9,
          "failed": 0,
          "errors": 0,
          "collected": 9,
          "duration": 10.04,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 9 items\n\nsympy/printing/tests/test_pycode.py::test_PythonCodePrinter PASSED       [ 11%]\nsympy/printing/tests/test_pycode.py::test_MpmathPrinter PASSED           [ 22%]\nsympy/printing/tests/test_pycode.py::test_NumPyPrinter PASSED            [ 33%]\nsympy/printing/tests/test_pycode.py::test_SciPyPrinter PASSED            [ 44%]\nsympy/printing/tests/test_pycode.py::test_pycode_reserved_words PASSED   [ 55%]\nsympy/printing/tests/test_pycode.py::test_printmethod PASSED             [ 66%]\nsympy/printing/tests/test_pycode.py::test_codegen_ast_nodes PASSED       [ 77%]\nsympy/printing/tests/test_pycode.py::test_issue_14283 PASSED             [ 88%]\nsympy/printing/tests/test_pycode.py::test_NumPyPrinter_print_seq PASSED  [100%]\n\n=============================== warnings summary ===============================\nsympy/solvers/diophantine.py:3185\n  /testbed/sympy/solvers/diophantine.py:3185: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:644\n  /testbed/sympy/plotting/plot.py:644: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:664\n  /testbed/sympy/plotting/plot.py:664: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:677\n  /testbed/sympy/plotting/plot.py:677: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:684\n  /testbed/sympy/plotting/plot.py:684: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================== 9 passed, 6 warnings in 0.17s =========================\n\n",
          "test_files_run": [
            "sympy/printing/tests/test_pycode.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-16792",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 20.48787808418274,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 55,
          "failed": 1,
          "errors": 0,
          "collected": 56,
          "duration": 9.36,
          "log_tail": "E   assert '#include \"te..._result;\\n}\\n' == '#include \"te..._result;\\n}\\n'\nE     \nE       #include \"test.h\"\nE       #include <math.h>\nE     - double test(double *x) {\nE     ?                    -\nE     + double test(double x) {\nE          double test_result;...\nE     \nE     ...Full output truncated (3 lines hidden), use '-vv' to show\n=============================== warnings summary ===============================\nsympy/solvers/diophantine.py:3185\n  /testbed/sympy/solvers/diophantine.py:3185: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:644\n  /testbed/sympy/plotting/plot.py:644: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:664\n  /testbed/sympy/plotting/plot.py:664: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:677\n  /testbed/sympy/plotting/plot.py:677: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:684\n  /testbed/sympy/plotting/plot.py:684: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\nsympy/utilities/codegen.py:277\n  /testbed/sympy/utilities/codegen.py:277: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if dt is \"int\" and not element.is_integer:\n\nsympy/utilities/codegen.py:279\n  /testbed/sympy/utilities/codegen.py:279: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if dt is \"float\" and not element.is_real:\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 1 failed, 55 passed, 8 warnings in 0.63s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/utilities/tests/test_codegen.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/utilities/tests/test_codegen.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 56,
          "failed": 0,
          "errors": 0,
          "collected": 56,
          "duration": 9.83,
          "log_tail": "sympy/utilities/tests/test_codegen.py::test_check_case PASSED            [ 82%]\nsympy/utilities/tests/test_codegen.py::test_check_case_false_positive PASSED [ 83%]\nsympy/utilities/tests/test_codegen.py::test_c_fortran_omit_routine_name PASSED [ 85%]\nsympy/utilities/tests/test_codegen.py::test_fcode_matrix_output PASSED   [ 87%]\nsympy/utilities/tests/test_codegen.py::test_fcode_results_named_ordered PASSED [ 89%]\nsympy/utilities/tests/test_codegen.py::test_fcode_matrixsymbol_slice PASSED [ 91%]\nsympy/utilities/tests/test_codegen.py::test_fcode_matrixsymbol_slice_autoname PASSED [ 92%]\nsympy/utilities/tests/test_codegen.py::test_global_vars PASSED           [ 94%]\nsympy/utilities/tests/test_codegen.py::test_custom_codegen PASSED        [ 96%]\nsympy/utilities/tests/test_codegen.py::test_c_with_printer PASSED        [ 98%]\nsympy/utilities/tests/test_codegen.py::test_fcode_complex PASSED         [100%]\n\n=============================== warnings summary ===============================\nsympy/solvers/diophantine.py:3185\n  /testbed/sympy/solvers/diophantine.py:3185: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:644\n  /testbed/sympy/plotting/plot.py:644: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:664\n  /testbed/sympy/plotting/plot.py:664: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:677\n  /testbed/sympy/plotting/plot.py:677: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:684\n  /testbed/sympy/plotting/plot.py:684: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\nsympy/utilities/codegen.py:277\n  /testbed/sympy/utilities/codegen.py:277: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if dt is \"int\" and not element.is_integer:\n\nsympy/utilities/codegen.py:279\n  /testbed/sympy/utilities/codegen.py:279: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if dt is \"float\" and not element.is_real:\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================== 56 passed, 8 warnings in 0.83s ========================\n\n",
          "test_files_run": [
            "sympy/utilities/tests/test_codegen.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-16886",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 21.158236026763916,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 43,
          "failed": 1,
          "errors": 0,
          "collected": 44,
          "duration": 9.65,
          "log_tail": "sympy/crypto/tests/test_crypto.py::test_elgamal PASSED                   [ 75%]\nsympy/crypto/tests/test_crypto.py::test_dh_private_key PASSED            [ 77%]\nsympy/crypto/tests/test_crypto.py::test_dh_public_key PASSED             [ 79%]\nsympy/crypto/tests/test_crypto.py::test_dh_shared_key PASSED             [ 81%]\nsympy/crypto/tests/test_crypto.py::test_padded_key PASSED                [ 84%]\nsympy/crypto/tests/test_crypto.py::test_bifid PASSED                     [ 86%]\nsympy/crypto/tests/test_crypto.py::test_encipher_decipher_gm PASSED      [ 88%]\nsympy/crypto/tests/test_crypto.py::test_gm_private_key PASSED            [ 90%]\nsympy/crypto/tests/test_crypto.py::test_gm_public_key PASSED             [ 93%]\nsympy/crypto/tests/test_crypto.py::test_encipher_decipher_bg PASSED      [ 95%]\nsympy/crypto/tests/test_crypto.py::test_bg_private_key PASSED            [ 97%]\nsympy/crypto/tests/test_crypto.py::test_bg_public_key PASSED             [100%]\n\n=================================== FAILURES ===================================\n______________________________ test_encode_morse _______________________________\nsympy/crypto/tests/test_crypto.py:250: in test_encode_morse\n    assert encode_morse('12345') == '.----|..---|...--|....-|.....'\nE   AssertionError: assert '----|..---|...--|....-|.....' == '.----|..---|...-|....-|.....'\nE     \nE     - .----|..---|...--|....-|.....\nE     ? -\nE     + ----|..---|...--|....-|.....\n=============================== warnings summary ===============================\nsympy/solvers/diophantine.py:3185\n  /testbed/sympy/solvers/diophantine.py:3185: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:645\n  /testbed/sympy/plotting/plot.py:645: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:674\n  /testbed/sympy/plotting/plot.py:674: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:681\n  /testbed/sympy/plotting/plot.py:681: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 1 failed, 43 passed, 5 warnings in 1.03s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/crypto/tests/test_crypto.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/crypto/tests/test_crypto.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 44,
          "failed": 0,
          "errors": 0,
          "collected": 44,
          "duration": 10.2,
          "log_tail": "sympy/crypto/tests/test_crypto.py::test_decipher_rsa PASSED              [ 50%]\nsympy/crypto/tests/test_crypto.py::test_kid_rsa_public_key PASSED        [ 52%]\nsympy/crypto/tests/test_crypto.py::test_kid_rsa_private_key PASSED       [ 54%]\nsympy/crypto/tests/test_crypto.py::test_encipher_kid_rsa PASSED          [ 56%]\nsympy/crypto/tests/test_crypto.py::test_decipher_kid_rsa PASSED          [ 59%]\nsympy/crypto/tests/test_crypto.py::test_encode_morse PASSED              [ 61%]\nsympy/crypto/tests/test_crypto.py::test_decode_morse PASSED              [ 63%]\nsympy/crypto/tests/test_crypto.py::test_lfsr_sequence PASSED             [ 65%]\nsympy/crypto/tests/test_crypto.py::test_lfsr_autocorrelation PASSED      [ 68%]\nsympy/crypto/tests/test_crypto.py::test_lfsr_connection_polynomial PASSED [ 70%]\nsympy/crypto/tests/test_crypto.py::test_elgamal_private_key PASSED       [ 72%]\nsympy/crypto/tests/test_crypto.py::test_elgamal PASSED                   [ 75%]\nsympy/crypto/tests/test_crypto.py::test_dh_private_key PASSED            [ 77%]\nsympy/crypto/tests/test_crypto.py::test_dh_public_key PASSED             [ 79%]\nsympy/crypto/tests/test_crypto.py::test_dh_shared_key PASSED             [ 81%]\nsympy/crypto/tests/test_crypto.py::test_padded_key PASSED                [ 84%]\nsympy/crypto/tests/test_crypto.py::test_bifid PASSED                     [ 86%]\nsympy/crypto/tests/test_crypto.py::test_encipher_decipher_gm PASSED      [ 88%]\nsympy/crypto/tests/test_crypto.py::test_gm_private_key PASSED            [ 90%]\nsympy/crypto/tests/test_crypto.py::test_gm_public_key PASSED             [ 93%]\nsympy/crypto/tests/test_crypto.py::test_encipher_decipher_bg PASSED      [ 95%]\nsympy/crypto/tests/test_crypto.py::test_bg_private_key PASSED            [ 97%]\nsympy/crypto/tests/test_crypto.py::test_bg_public_key PASSED             [100%]\n\n=============================== warnings summary ===============================\nsympy/solvers/diophantine.py:3185\n  /testbed/sympy/solvers/diophantine.py:3185: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:645\n  /testbed/sympy/plotting/plot.py:645: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:674\n  /testbed/sympy/plotting/plot.py:674: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:681\n  /testbed/sympy/plotting/plot.py:681: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================== 44 passed, 5 warnings in 1.04s ========================\n\n",
          "test_files_run": [
            "sympy/crypto/tests/test_crypto.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-17139",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://35.239.238.137:8080",
      "duration": 43.207552909851074,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 69,
          "failed": 4,
          "errors": 0,
          "collected": 73,
          "duration": 21.54,
          "log_tail": "During handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_simplify_float_vs_integer\n_______________________________ test_issue_17137 _______________________________\nsympy/simplify/tests/test_simplify.py:815: in test_issue_17137\n    assert simplify(cos(x)**I) == cos(x)**I\nsympy/simplify/simplify.py:587: in simplify\n    expr = trigsimp(expr, deep=True)\nsympy/simplify/trigsimp.py:508: in trigsimp\n    return trigsimpfunc(expr)\nsympy/simplify/trigsimp.py:501: in <lambda>\n    'matching': (lambda x: futrig(x)),\nsympy/simplify/trigsimp.py:1101: in futrig\n    e = bottom_up(e, lambda x: _futrig(x, **kwargs))\nsympy/simplify/simplify.py:1081: in bottom_up\n    rv = F(rv)\nsympy/simplify/trigsimp.py:1101: in <lambda>\n    e = bottom_up(e, lambda x: _futrig(x, **kwargs))\nsympy/simplify/trigsimp.py:1169: in _futrig\n    e = greedy(tree, objective=Lops)(e)\nsympy/strategies/core.py:115: in minrule\n    return min([rule(expr) for rule in rules], key=objective)\nsympy/strategies/core.py:115: in <listcomp>\n    return min([rule(expr) for rule in rules], key=objective)\nsympy/strategies/core.py:44: in chain_rl\n    expr = rule(expr)\nsympy/simplify/fu.py:566: in TR6\n    return _TR56(rv, cos, sin, lambda x: 1 - x, max=max, pow=pow)\nsympy/simplify/fu.py:524: in _TR56\n    return bottom_up(rv, _f)\nsympy/simplify/simplify.py:1081: in bottom_up\n    rv = F(rv)\nsympy/simplify/fu.py:504: in _f\n    if (rv.exp < 0) == True:\nsympy/core/expr.py:406: in __lt__\n    raise TypeError(\"Invalid comparison of complex %s\" % me)\nE   TypeError: Invalid comparison of complex I\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 4 failed, 69 passed, 1 warning in 12.41s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/simplify/tests/test_fu.py sympy/simplify/tests/test_simplify.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/simplify/tests/test_fu.py",
            "sympy/simplify/tests/test_simplify.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 71,
          "failed": 2,
          "errors": 0,
          "collected": 73,
          "duration": 20.46,
          "log_tail": "sympy/simplify/tests/test_simplify.py::test_besselsimp PASSED            [ 78%]\nsympy/simplify/tests/test_simplify.py::test_Piecewise PASSED             [ 79%]\nsympy/simplify/tests/test_simplify.py::test_polymorphism PASSED          [ 80%]\nsympy/simplify/tests/test_simplify.py::test_issue_from_PR1599 PASSED     [ 82%]\nsympy/simplify/tests/test_simplify.py::test_issue_6811 PASSED            [ 83%]\nsympy/simplify/tests/test_simplify.py::test_issue_6920 PASSED            [ 84%]\nsympy/simplify/tests/test_simplify.py::test_issue_7001 PASSED            [ 86%]\nsympy/simplify/tests/test_simplify.py::test_inequality_no_auto_simplify PASSED [ 87%]\nsympy/simplify/tests/test_simplify.py::test_issue_9398 PASSED            [ 89%]\nsympy/simplify/tests/test_simplify.py::test_issue_9324_simplify PASSED   [ 90%]\nsympy/simplify/tests/test_simplify.py::test_issue_13474 PASSED           [ 91%]\nsympy/simplify/tests/test_simplify.py::test_simplify_function_inverse PASSED [ 93%]\nsympy/simplify/tests/test_simplify.py::test_clear_coefficients PASSED    [ 94%]\nsympy/simplify/tests/test_simplify.py::test_nc_simplify PASSED           [ 95%]\nsympy/simplify/tests/test_simplify.py::test_issue_15965 PASSED           [ 97%]\nsympy/simplify/tests/test_simplify.py::test_issue_17137 PASSED           [ 98%]\nsympy/simplify/tests/test_simplify.py::test_issue_7971 PASSED            [100%]\n\n=================================== FAILURES ===================================\n___________________________ test_factorial_simplify ____________________________\nsympy/simplify/tests/test_simplify.py:29: in test_factorial_simplify\n    from sympy.specfun.factorials import factorial\nE   ModuleNotFoundError: No module named 'sympy.specfun'\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_factorial_simplify\n________________________ test_simplify_float_vs_integer ________________________\nsympy/simplify/tests/test_simplify.py:538: in test_simplify_float_vs_integer\n    assert simplify(x**2.0 - x**2) == 0\nE   assert -x**2 + x**2.0 == 0\nE    +  where -x**2 + x**2.0 = simplify(((x ** 2.0) - (x ** 2)))\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_simplify_float_vs_integer\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 2 failed, 71 passed, 1 warning in 11.33s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/simplify/tests/test_fu.py sympy/simplify/tests/test_simplify.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/simplify/tests/test_fu.py",
            "sympy/simplify/tests/test_simplify.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sympy__sympy-17318",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://35.239.238.137:8080",
      "error": "HTTPConnectionPool(host='35.239.238.137', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "sympy__sympy-17630",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://35.239.238.137:8080",
      "duration": 20.962123155593872,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 20,
          "failed": 3,
          "errors": 0,
          "collected": 23,
          "duration": 9.92,
          "log_tail": "    result = rule(expr)\nsympy/strategies/core.py:11: in exhaustive_rl\n    new, old = rule(expr), expr\nsympy/strategies/core.py:44: in chain_rl\n    expr = rule(expr)\nsympy/strategies/core.py:11: in exhaustive_rl\n    new, old = rule(expr), expr\nsympy/strategies/core.py:33: in conditioned_rl\n    return rule(expr)\nsympy/strategies/core.py:95: in switch_rl\n    return rl(expr)\nsympy/matrices/expressions/blockmatrix.py:467: in bc_matmul\n    matrices[i] = A._blockmul(B)\nsympy/matrices/expressions/blockmatrix.py:167: in _blockmul\n    return BlockMatrix(self.blocks*other.blocks)\nsympy/matrices/expressions/blockmatrix.py:86: in __new__\n    raise ValueError(filldedent('''\nE   ValueError: \nE   expecting a sequence of 1 or more rows containing Matrices.\n_____________________________ test_zero_matrix_add _____________________________\nsympy/matrices/expressions/tests/test_matadd.py:37: in test_zero_matrix_add\n    assert Add(ZeroMatrix(2, 2), ZeroMatrix(2, 2)) == ZeroMatrix(2, 2)\nE   assert 0 == 0\nE    +  where 0 = Add(0, 0)\nE    +    where 0 = ZeroMatrix(2, 2)\nE    +    and   0 = ZeroMatrix(2, 2)\nE    +  and   0 = ZeroMatrix(2, 2)\n_________________________ test_matrix_add_with_scalar __________________________\nsympy/matrices/expressions/tests/test_matadd.py:41: in test_matrix_add_with_scalar\n    raises(TypeError, lambda: Add(0, ZeroMatrix(2, 2)))\nsympy/utilities/pytest.py:86: in raises\n    raise Failed(\"DID NOT RAISE\")\nE   sympy.utilities.pytest.Failed: DID NOT RAISE\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_matrix_add_with_scalar\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 3 failed, 20 passed, 1 warning in 0.83s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/matrices/expressions/tests/test_blockmatrix.py sympy/matrices/expressions/tests/test_matadd.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/matrices/expressions/tests/test_blockmatrix.py",
            "sympy/matrices/expressions/tests/test_matadd.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 22,
          "failed": 1,
          "errors": 0,
          "collected": 23,
          "duration": 9.79,
          "log_tail": "collecting ... collected 23 items\n\nsympy/matrices/expressions/tests/test_blockmatrix.py::test_bc_matmul PASSED [  4%]\nsympy/matrices/expressions/tests/test_blockmatrix.py::test_bc_matadd PASSED [  8%]\nsympy/matrices/expressions/tests/test_blockmatrix.py::test_bc_transpose PASSED [ 13%]\nsympy/matrices/expressions/tests/test_blockmatrix.py::test_bc_dist_diag PASSED [ 17%]\nsympy/matrices/expressions/tests/test_blockmatrix.py::test_block_plus_ident PASSED [ 21%]\nsympy/matrices/expressions/tests/test_blockmatrix.py::test_BlockMatrix PASSED [ 26%]\nsympy/matrices/expressions/tests/test_blockmatrix.py::test_block_collapse_explicit_matrices PASSED [ 30%]\nsympy/matrices/expressions/tests/test_blockmatrix.py::test_issue_17624 PASSED [ 34%]\nsympy/matrices/expressions/tests/test_blockmatrix.py::test_BlockMatrix_trace PASSED [ 39%]\nsympy/matrices/expressions/tests/test_blockmatrix.py::test_BlockMatrix_Determinant PASSED [ 43%]\nsympy/matrices/expressions/tests/test_blockmatrix.py::test_squareBlockMatrix PASSED [ 47%]\nsympy/matrices/expressions/tests/test_blockmatrix.py::test_BlockDiagMatrix PASSED [ 52%]\nsympy/matrices/expressions/tests/test_blockmatrix.py::test_blockcut PASSED [ 56%]\nsympy/matrices/expressions/tests/test_blockmatrix.py::test_reblock_2x2 PASSED [ 60%]\nsympy/matrices/expressions/tests/test_blockmatrix.py::test_deblock PASSED [ 65%]\nsympy/matrices/expressions/tests/test_blockmatrix.py::test_block_collapse_type PASSED [ 69%]\nsympy/matrices/expressions/tests/test_matadd.py::test_sort_key PASSED    [ 73%]\nsympy/matrices/expressions/tests/test_matadd.py::test_matadd_sympify PASSED [ 78%]\nsympy/matrices/expressions/tests/test_matadd.py::test_matadd_of_matrices PASSED [ 82%]\nsympy/matrices/expressions/tests/test_matadd.py::test_doit_args PASSED   [ 86%]\nsympy/matrices/expressions/tests/test_matadd.py::test_generic_identity PASSED [ 91%]\nsympy/matrices/expressions/tests/test_matadd.py::test_zero_matrix_add PASSED [ 95%]\nsympy/matrices/expressions/tests/test_matadd.py::test_matrix_add_with_scalar FAILED [100%]\n\n=================================== FAILURES ===================================\n_________________________ test_matrix_add_with_scalar __________________________\nsympy/matrices/expressions/tests/test_matadd.py:41: in test_matrix_add_with_scalar\n    raises(TypeError, lambda: Add(0, ZeroMatrix(2, 2)))\nsympy/utilities/pytest.py:86: in raises\n    raise Failed(\"DID NOT RAISE\")\nE   sympy.utilities.pytest.Failed: DID NOT RAISE\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_matrix_add_with_scalar\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 1 failed, 22 passed, 1 warning in 0.54s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/matrices/expressions/tests/test_blockmatrix.py sympy/matrices/expressions/tests/test_matadd.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/matrices/expressions/tests/test_blockmatrix.py",
            "sympy/matrices/expressions/tests/test_matadd.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sympy__sympy-17655",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 24.927191019058228,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 10,
          "failed": 2,
          "errors": 0,
          "collected": 12,
          "duration": 11.54,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 12 items\n\nsympy/geometry/tests/test_point.py::test_point FAILED                    [  8%]\nsympy/geometry/tests/test_point.py::test_point3D FAILED                  [ 16%]\nsympy/geometry/tests/test_point.py::test_Point2D PASSED                  [ 25%]\nsympy/geometry/tests/test_point.py::test_issue_9214 PASSED               [ 33%]\nsympy/geometry/tests/test_point.py::test_issue_11617 PASSED              [ 41%]\nsympy/geometry/tests/test_point.py::test_transform PASSED                [ 50%]\nsympy/geometry/tests/test_point.py::test_concyclic_doctest_bug PASSED    [ 58%]\nsympy/geometry/tests/test_point.py::test_arguments PASSED                [ 66%]\nsympy/geometry/tests/test_point.py::test_unit PASSED                     [ 75%]\nsympy/geometry/tests/test_point.py::test_dot PASSED                      [ 83%]\nsympy/geometry/tests/test_point.py::test__normalize_dimension PASSED     [ 91%]\nsympy/geometry/tests/test_point.py::test_direction_cosine PASSED         [100%]\n\n=================================== FAILURES ===================================\n__________________________________ test_point __________________________________\nsympy/geometry/tests/test_point.py:94: in test_point\n    assert 5 * p4 == Point(5, 5)\nE   TypeError: unsupported operand type(s) for *: 'int' and 'Point2D'\n_________________________________ test_point3D _________________________________\nsympy/geometry/tests/test_point.py:171: in test_point3D\n    assert 5 * p4 == Point3D(5, 5, 5)\nE   TypeError: unsupported operand type(s) for *: 'int' and 'Point3D'\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 2 failed, 10 passed, 1 warning in 2.13s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/geometry/tests/test_point.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/geometry/tests/test_point.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 12,
          "failed": 0,
          "errors": 0,
          "collected": 12,
          "duration": 11.96,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 12 items\n\nsympy/geometry/tests/test_point.py::test_point PASSED                    [  8%]\nsympy/geometry/tests/test_point.py::test_point3D PASSED                  [ 16%]\nsympy/geometry/tests/test_point.py::test_Point2D PASSED                  [ 25%]\nsympy/geometry/tests/test_point.py::test_issue_9214 PASSED               [ 33%]\nsympy/geometry/tests/test_point.py::test_issue_11617 PASSED              [ 41%]\nsympy/geometry/tests/test_point.py::test_transform PASSED                [ 50%]\nsympy/geometry/tests/test_point.py::test_concyclic_doctest_bug PASSED    [ 58%]\nsympy/geometry/tests/test_point.py::test_arguments PASSED                [ 66%]\nsympy/geometry/tests/test_point.py::test_unit PASSED                     [ 75%]\nsympy/geometry/tests/test_point.py::test_dot PASSED                      [ 83%]\nsympy/geometry/tests/test_point.py::test__normalize_dimension PASSED     [ 91%]\nsympy/geometry/tests/test_point.py::test_direction_cosine PASSED         [100%]\n\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================== 12 passed, 1 warning in 2.86s =========================\n\n",
          "test_files_run": [
            "sympy/geometry/tests/test_point.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-18189",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://35.239.238.137:8080",
      "error": "HTTPConnectionPool(host='35.239.238.137', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "sympy__sympy-18199",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://35.239.238.137:8080",
      "error": "HTTPConnectionPool(host='35.239.238.137', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "sympy__sympy-18211",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://35.239.238.137:8080",
      "duration": 28.28247904777527,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 55,
          "failed": 3,
          "errors": 0,
          "collected": 58,
          "duration": 13.93,
          "log_tail": "sympy/logic/boolalg.py:161: in as_set\n    raise NotImplementedError(\"Sorry, as_set has not yet been\"\nE   NotImplementedError: Sorry, as_set has not yet been implemented for multivariate expressions\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_multivariate_relational_as_set\n_______________________ test_issue_8444_nonworkingtests ________________________\nsympy/core/tests/test_relational.py:828: in test_issue_8444_nonworkingtests\n    assert x >= floor(x)\nsympy/core/relational.py:385: in __nonzero__\n    raise TypeError(\"cannot determine truth value of Relational\")\nE   TypeError: cannot determine truth value of Relational\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_issue_8444_nonworkingtests\n_______________________________ test_issue_18188 _______________________________\nsympy/solvers/inequalities.py:524: in solve_univariate_inequality\n    solns = solvify(e, gen, domain)\nsympy/solvers/solveset.py:2138: in solvify\n    raise NotImplementedError('solveset is unable to solve this equation.')\nE   NotImplementedError: solveset is unable to solve this equation.\n\nDuring handling of the above exception, another exception occurred:\nsympy/core/tests/test_relational.py:964: in test_issue_18188\n    assert result1.as_set() == ConditionSet(x, Eq(x*cos(x) - 3*sin(x), 0), Reals)\nsympy/logic/boolalg.py:159: in as_set\n    return self.subs(reps)._eval_as_set()\nsympy/core/relational.py:395: in _eval_as_set\n    return solve_univariate_inequality(self, x, relational=False)\nsympy/solvers/inequalities.py:531: in solve_univariate_inequality\n    raise NotImplementedError(filldedent('''\nE   NotImplementedError: \nE   The inequality, Eq(x*cos(x) - 3*sin(x), 0), cannot be solved using\nE   solve_univariate_inequality.\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 3 failed, 55 passed, 1 warning in 4.77s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/core/tests/test_relational.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/core/tests/test_relational.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 56,
          "failed": 2,
          "errors": 0,
          "collected": 58,
          "duration": 13.07,
          "log_tail": "sympy/core/tests/test_relational.py::test_issue_18188 PASSED             [ 77%]\nsympy/core/tests/test_relational.py::test_binary_symbols PASSED          [ 79%]\nsympy/core/tests/test_relational.py::test_rel_args PASSED                [ 81%]\nsympy/core/tests/test_relational.py::test_Equality_rewrite_as_Add PASSED [ 82%]\nsympy/core/tests/test_relational.py::test_issue_15847 PASSED             [ 84%]\nsympy/core/tests/test_relational.py::test_negated_property PASSED        [ 86%]\nsympy/core/tests/test_relational.py::test_reversedsign_property PASSED   [ 87%]\nsympy/core/tests/test_relational.py::test_reversed_reversedsign_property PASSED [ 89%]\nsympy/core/tests/test_relational.py::test_improved_canonical PASSED      [ 91%]\nsympy/core/tests/test_relational.py::test_set_equality_canonical PASSED  [ 93%]\nsympy/core/tests/test_relational.py::test_trigsimp PASSED                [ 94%]\nsympy/core/tests/test_relational.py::test_polynomial_relation_simplification PASSED [ 96%]\nsympy/core/tests/test_relational.py::test_multivariate_linear_function_simplification PASSED [ 98%]\nsympy/core/tests/test_relational.py::test_nonpolymonial_relations PASSED [100%]\n\n=================================== FAILURES ===================================\n_____________________ test_multivariate_relational_as_set ______________________\nsympy/core/tests/test_relational.py:432: in test_multivariate_relational_as_set\n    assert (x*y >= 0).as_set() == Interval(0, oo)*Interval(0, oo) + \\\nsympy/logic/boolalg.py:161: in as_set\n    raise NotImplementedError(\"Sorry, as_set has not yet been\"\nE   NotImplementedError: Sorry, as_set has not yet been implemented for multivariate expressions\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_multivariate_relational_as_set\n_______________________ test_issue_8444_nonworkingtests ________________________\nsympy/core/tests/test_relational.py:828: in test_issue_8444_nonworkingtests\n    assert x >= floor(x)\nsympy/core/relational.py:385: in __nonzero__\n    raise TypeError(\"cannot determine truth value of Relational\")\nE   TypeError: cannot determine truth value of Relational\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_issue_8444_nonworkingtests\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 2 failed, 56 passed, 1 warning in 3.86s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/core/tests/test_relational.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/core/tests/test_relational.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sympy__sympy-18698",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 34.55966591835022,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 147,
          "failed": 2,
          "errors": 0,
          "collected": 150,
          "duration": 17.42,
          "log_tail": "sympy/polys/tests/test_polytools.py::test_factor_terms FAILED            [ 94%]\nsympy/polys/tests/test_polytools.py::test_as_list PASSED                 [ 94%]\nsympy/polys/tests/test_polytools.py::test_issue_11198 PASSED             [ 95%]\nsympy/polys/tests/test_polytools.py::test_Poly_precision PASSED          [ 96%]\nsympy/polys/tests/test_polytools.py::test_issue_12400 PASSED             [ 96%]\nsympy/polys/tests/test_polytools.py::test_issue_14364 PASSED             [ 97%]\nsympy/polys/tests/test_polytools.py::test_issue_15669 PASSED             [ 98%]\nsympy/polys/tests/test_polytools.py::test_issue_17988 PASSED             [ 98%]\nsympy/polys/tests/test_polytools.py::test_issue_18205 PASSED             [ 99%]\nsympy/polys/tests/test_polytools.py::test_issue_8695 FAILED              [100%]\n\n=================================== FAILURES ===================================\n______________________________ test_factor_terms _______________________________\nsympy/polys/tests/test_polytools.py:3276: in test_factor_terms\n    assert sqf_list(x*(x + y)) == (1, [(x**2 + x*y, 1)])\nE   AssertionError: assert (1, [(x, 1), (x + y, 1)]) == (1, [(x**2 + x*y, 1)])\nE     \nE     At index 1 diff: [(x, 1), (x + y, 1)] != [(x**2 + x*y, 1)]\nE     \nE     Full diff:\nE       (\nE           1,\nE           [...\nE     \nE     ...Full output truncated (12 lines hidden), use '-vv' to show\n_______________________________ test_issue_8695 ________________________________\nsympy/polys/tests/test_polytools.py:3340: in test_issue_8695\n    assert sqf_list(p) == result\nE   AssertionError: assert (1, [(x**2 + ..., (x - 2, 3)]) == (1, [(x**2 + ... 5*x + 6, 3)])\nE     \nE     At index 1 diff: [(x**2 + 1, 1), (x - 1, 2), (x - 3, 3), (x - 2, 3)] != [(x**2 + 1, 1), (x - 1, 2), (x**2 - 5*x + 6, 3)]\nE     \nE     Full diff:\nE       (\nE           1,\nE           [...\nE     \nE     ...Full output truncated (21 lines hidden), use '-vv' to show\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n============= 2 failed, 147 passed, 1 xfailed, 1 warning in 8.19s ==============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/polys/tests/test_polytools.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/polys/tests/test_polytools.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 149,
          "failed": 0,
          "errors": 0,
          "collected": 150,
          "duration": 15.78,
          "log_tail": "sympy/polys/tests/test_polytools.py::test_gff PASSED                     [ 74%]\nsympy/polys/tests/test_polytools.py::test_norm PASSED                    [ 75%]\nsympy/polys/tests/test_polytools.py::test_sqf_norm PASSED                [ 76%]\nsympy/polys/tests/test_polytools.py::test_sqf PASSED                     [ 76%]\nsympy/polys/tests/test_polytools.py::test_factor PASSED                  [ 77%]\nsympy/polys/tests/test_polytools.py::test_factor_large PASSED            [ 78%]\nsympy/polys/tests/test_polytools.py::test_factor_noeval PASSED           [ 78%]\nsympy/polys/tests/test_polytools.py::test_intervals PASSED               [ 79%]\nsympy/polys/tests/test_polytools.py::test_refine_root PASSED             [ 80%]\nsympy/polys/tests/test_polytools.py::test_count_roots PASSED             [ 80%]\nsympy/polys/tests/test_polytools.py::test_Poly_root PASSED               [ 81%]\nsympy/polys/tests/test_polytools.py::test_real_roots PASSED              [ 82%]\nsympy/polys/tests/test_polytools.py::test_all_roots PASSED               [ 82%]\nsympy/polys/tests/test_polytools.py::test_nroots PASSED                  [ 83%]\nsympy/polys/tests/test_polytools.py::test_ground_roots PASSED            [ 84%]\nsympy/polys/tests/test_polytools.py::test_nth_power_roots_poly PASSED    [ 84%]\nsympy/polys/tests/test_polytools.py::test_torational_factor_list PASSED  [ 85%]\nsympy/polys/tests/test_polytools.py::test_cancel PASSED                  [ 86%]\nsympy/polys/tests/test_polytools.py::test_reduced PASSED                 [ 86%]\nsympy/polys/tests/test_polytools.py::test_groebner PASSED                [ 87%]\nsympy/polys/tests/test_polytools.py::test_fglm PASSED                    [ 88%]\nsympy/polys/tests/test_polytools.py::test_is_zero_dimensional PASSED     [ 88%]\nsympy/polys/tests/test_polytools.py::test_GroebnerBasis PASSED           [ 89%]\nsympy/polys/tests/test_polytools.py::test_poly PASSED                    [ 90%]\nsympy/polys/tests/test_polytools.py::test_keep_coeff PASSED              [ 90%]\nsympy/polys/tests/test_polytools.py::test_poly_matching_consistency PASSED [ 91%]\nsympy/polys/tests/test_polytools.py::test_issue_5786 XFAIL               [ 92%]\nsympy/polys/tests/test_polytools.py::test_noncommutative PASSED          [ 92%]\nsympy/polys/tests/test_polytools.py::test_to_rational_coeffs PASSED      [ 93%]\nsympy/polys/tests/test_polytools.py::test_factor_terms PASSED            [ 94%]\nsympy/polys/tests/test_polytools.py::test_as_list PASSED                 [ 94%]\nsympy/polys/tests/test_polytools.py::test_issue_11198 PASSED             [ 95%]\nsympy/polys/tests/test_polytools.py::test_Poly_precision PASSED          [ 96%]\nsympy/polys/tests/test_polytools.py::test_issue_12400 PASSED             [ 96%]\nsympy/polys/tests/test_polytools.py::test_issue_14364 PASSED             [ 97%]\nsympy/polys/tests/test_polytools.py::test_issue_15669 PASSED             [ 98%]\nsympy/polys/tests/test_polytools.py::test_issue_17988 PASSED             [ 98%]\nsympy/polys/tests/test_polytools.py::test_issue_18205 PASSED             [ 99%]\nsympy/polys/tests/test_polytools.py::test_issue_8695 PASSED              [100%]\n\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================== 149 passed, 1 xfailed, 1 warning in 6.68s ===================\n\n",
          "test_files_run": [
            "sympy/polys/tests/test_polytools.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-18763",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://35.239.238.137:8080",
      "duration": 28.73121476173401,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 142,
          "failed": 5,
          "errors": 0,
          "collected": 147,
          "duration": 13.75,
          "log_tail": "E     + \\text{False}\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_latex_symbols_failing\n_______________________________ test_latex_subs ________________________________\nsympy/printing/tests/test_latex.py:676: in test_latex_subs\n    assert latex(Subs(x*y, (\nE   AssertionError: assert '\\\\left. x y ...=1\\\\\\\\ y=2 }}' == '\\\\left. \\\\le...=1\\\\\\\\ y=2 }}'\nE     \nE     - \\left. \\left(x y\\right) \\right|_{\\substack{ x=1\\\\ y=2 }}\nE     ?        ------   -------\nE     + \\left. x y \\right|_{\\substack{ x=1\\\\ y=2 }}\n__________________ test_builtin_without_args_mismatched_names __________________\nsympy/printing/tests/test_latex.py:2030: in test_builtin_without_args_mismatched_names\n    assert latex(CosineTransform) == r'\\mathcal{COS}'\nE   AssertionError: assert '\\\\operatorna...ineTransform}' == '\\\\mathcal{COS}'\nE     \nE     - \\mathcal{COS}\nE     + \\operatorname{CosineTransform}\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_builtin_without_args_mismatched_names\n_______________________________ test_issue_8470 ________________________________\nsympy/printing/tests/test_latex.py:2083: in test_issue_8470\n    e = parse_expr(\"-B*A\", evaluate=False)\nsympy/parsing/sympy_parser.py:1006: in parse_expr\n    code = compile(evaluateFalse(code), '<string>', 'eval')\nE   ValueError: Name node can't be used with 'False' constant\n_______________________________ test_issue_13559 _______________________________\nsympy/printing/tests/test_latex.py:2125: in test_issue_13559\n    expr = parse_expr('5/1', evaluate=False)\nsympy/parsing/sympy_parser.py:1006: in parse_expr\n    code = compile(evaluateFalse(code), '<string>', 'eval')\nE   ValueError: Name node can't be used with 'False' constant\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 5 failed, 142 passed, 1 warning in 4.34s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/printing/tests/test_latex.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/printing/tests/test_latex.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 143,
          "failed": 4,
          "errors": 0,
          "collected": 147,
          "duration": 13.68,
          "log_tail": "\n=================================== FAILURES ===================================\n__________________________ test_latex_symbols_failing __________________________\nsympy/printing/tests/test_latex.py:287: in test_latex_symbols_failing\n    assert latex(\nE   AssertionError: assert '\\\\text{False}' == '\\\\rho \\\\math...\\mathrm{mass}'\nE     \nE     - \\rho \\mathrm{volume} = \\mathrm{mass}\nE     + \\text{False}\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_latex_symbols_failing\n__________________ test_builtin_without_args_mismatched_names __________________\nsympy/printing/tests/test_latex.py:2030: in test_builtin_without_args_mismatched_names\n    assert latex(CosineTransform) == r'\\mathcal{COS}'\nE   AssertionError: assert '\\\\operatorna...ineTransform}' == '\\\\mathcal{COS}'\nE     \nE     - \\mathcal{COS}\nE     + \\operatorname{CosineTransform}\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_builtin_without_args_mismatched_names\n_______________________________ test_issue_8470 ________________________________\nsympy/printing/tests/test_latex.py:2083: in test_issue_8470\n    e = parse_expr(\"-B*A\", evaluate=False)\nsympy/parsing/sympy_parser.py:1006: in parse_expr\n    code = compile(evaluateFalse(code), '<string>', 'eval')\nE   ValueError: Name node can't be used with 'False' constant\n_______________________________ test_issue_13559 _______________________________\nsympy/printing/tests/test_latex.py:2125: in test_issue_13559\n    expr = parse_expr('5/1', evaluate=False)\nsympy/parsing/sympy_parser.py:1006: in parse_expr\n    code = compile(evaluateFalse(code), '<string>', 'eval')\nE   ValueError: Name node can't be used with 'False' constant\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 4 failed, 143 passed, 1 warning in 4.65s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/printing/tests/test_latex.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/printing/tests/test_latex.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sympy__sympy-19040",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 34.03952217102051,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 149,
          "failed": 1,
          "errors": 0,
          "collected": 150,
          "duration": 17.46,
          "log_tail": "sympy/polys/tests/test_polytools.py::test_Poly_root PASSED               [ 81%]\nsympy/polys/tests/test_polytools.py::test_real_roots PASSED              [ 82%]\nsympy/polys/tests/test_polytools.py::test_all_roots PASSED               [ 82%]\nsympy/polys/tests/test_polytools.py::test_nroots PASSED                  [ 83%]\nsympy/polys/tests/test_polytools.py::test_ground_roots PASSED            [ 84%]\nsympy/polys/tests/test_polytools.py::test_nth_power_roots_poly PASSED    [ 84%]\nsympy/polys/tests/test_polytools.py::test_torational_factor_list PASSED  [ 85%]\nsympy/polys/tests/test_polytools.py::test_cancel PASSED                  [ 86%]\nsympy/polys/tests/test_polytools.py::test_reduced PASSED                 [ 86%]\nsympy/polys/tests/test_polytools.py::test_groebner PASSED                [ 87%]\nsympy/polys/tests/test_polytools.py::test_fglm PASSED                    [ 88%]\nsympy/polys/tests/test_polytools.py::test_is_zero_dimensional PASSED     [ 88%]\nsympy/polys/tests/test_polytools.py::test_GroebnerBasis PASSED           [ 89%]\nsympy/polys/tests/test_polytools.py::test_poly PASSED                    [ 90%]\nsympy/polys/tests/test_polytools.py::test_keep_coeff PASSED              [ 90%]\nsympy/polys/tests/test_polytools.py::test_poly_matching_consistency PASSED [ 91%]\nsympy/polys/tests/test_polytools.py::test_issue_5786 FAILED              [ 92%]\nsympy/polys/tests/test_polytools.py::test_noncommutative PASSED          [ 92%]\nsympy/polys/tests/test_polytools.py::test_to_rational_coeffs PASSED      [ 93%]\nsympy/polys/tests/test_polytools.py::test_factor_terms PASSED            [ 94%]\nsympy/polys/tests/test_polytools.py::test_as_list PASSED                 [ 94%]\nsympy/polys/tests/test_polytools.py::test_issue_11198 PASSED             [ 95%]\nsympy/polys/tests/test_polytools.py::test_Poly_precision PASSED          [ 96%]\nsympy/polys/tests/test_polytools.py::test_issue_12400 PASSED             [ 96%]\nsympy/polys/tests/test_polytools.py::test_issue_14364 PASSED             [ 97%]\nsympy/polys/tests/test_polytools.py::test_issue_15669 PASSED             [ 98%]\nsympy/polys/tests/test_polytools.py::test_issue_17988 PASSED             [ 98%]\nsympy/polys/tests/test_polytools.py::test_issue_18205 PASSED             [ 99%]\nsympy/polys/tests/test_polytools.py::test_issue_8695 PASSED              [100%]\n\n=================================== FAILURES ===================================\n_______________________________ test_issue_5786 ________________________________\nsympy/polys/tests/test_polytools.py:3253: in test_issue_5786\n    assert expand(factor(expand(\nE   assert x - I*y == (((((-I * t) * x) - (t * y)) + (x * z)) - ((I * y) * z))\nE    +  where x - I*y = expand(x - I*y)\nE    +    where x - I*y = factor(-I*t*x - t*y + x*z - I*y*z, extension=[I])\nE    +      where -I*t*x - t*y + x*z - I*y*z = expand(((x - (I * y)) * (z - (I * t))))\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 1 failed, 149 passed, 1 warning in 7.98s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/polys/tests/test_polytools.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/polys/tests/test_polytools.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 150,
          "failed": 0,
          "errors": 0,
          "collected": 150,
          "duration": 15.43,
          "log_tail": "sympy/polys/tests/test_polytools.py::test_gff PASSED                     [ 74%]\nsympy/polys/tests/test_polytools.py::test_norm PASSED                    [ 75%]\nsympy/polys/tests/test_polytools.py::test_sqf_norm PASSED                [ 76%]\nsympy/polys/tests/test_polytools.py::test_sqf PASSED                     [ 76%]\nsympy/polys/tests/test_polytools.py::test_factor PASSED                  [ 77%]\nsympy/polys/tests/test_polytools.py::test_factor_large PASSED            [ 78%]\nsympy/polys/tests/test_polytools.py::test_factor_noeval PASSED           [ 78%]\nsympy/polys/tests/test_polytools.py::test_intervals PASSED               [ 79%]\nsympy/polys/tests/test_polytools.py::test_refine_root PASSED             [ 80%]\nsympy/polys/tests/test_polytools.py::test_count_roots PASSED             [ 80%]\nsympy/polys/tests/test_polytools.py::test_Poly_root PASSED               [ 81%]\nsympy/polys/tests/test_polytools.py::test_real_roots PASSED              [ 82%]\nsympy/polys/tests/test_polytools.py::test_all_roots PASSED               [ 82%]\nsympy/polys/tests/test_polytools.py::test_nroots PASSED                  [ 83%]\nsympy/polys/tests/test_polytools.py::test_ground_roots PASSED            [ 84%]\nsympy/polys/tests/test_polytools.py::test_nth_power_roots_poly PASSED    [ 84%]\nsympy/polys/tests/test_polytools.py::test_torational_factor_list PASSED  [ 85%]\nsympy/polys/tests/test_polytools.py::test_cancel PASSED                  [ 86%]\nsympy/polys/tests/test_polytools.py::test_reduced PASSED                 [ 86%]\nsympy/polys/tests/test_polytools.py::test_groebner PASSED                [ 87%]\nsympy/polys/tests/test_polytools.py::test_fglm PASSED                    [ 88%]\nsympy/polys/tests/test_polytools.py::test_is_zero_dimensional PASSED     [ 88%]\nsympy/polys/tests/test_polytools.py::test_GroebnerBasis PASSED           [ 89%]\nsympy/polys/tests/test_polytools.py::test_poly PASSED                    [ 90%]\nsympy/polys/tests/test_polytools.py::test_keep_coeff PASSED              [ 90%]\nsympy/polys/tests/test_polytools.py::test_poly_matching_consistency PASSED [ 91%]\nsympy/polys/tests/test_polytools.py::test_issue_5786 PASSED              [ 92%]\nsympy/polys/tests/test_polytools.py::test_noncommutative PASSED          [ 92%]\nsympy/polys/tests/test_polytools.py::test_to_rational_coeffs PASSED      [ 93%]\nsympy/polys/tests/test_polytools.py::test_factor_terms PASSED            [ 94%]\nsympy/polys/tests/test_polytools.py::test_as_list PASSED                 [ 94%]\nsympy/polys/tests/test_polytools.py::test_issue_11198 PASSED             [ 95%]\nsympy/polys/tests/test_polytools.py::test_Poly_precision PASSED          [ 96%]\nsympy/polys/tests/test_polytools.py::test_issue_12400 PASSED             [ 96%]\nsympy/polys/tests/test_polytools.py::test_issue_14364 PASSED             [ 97%]\nsympy/polys/tests/test_polytools.py::test_issue_15669 PASSED             [ 98%]\nsympy/polys/tests/test_polytools.py::test_issue_17988 PASSED             [ 98%]\nsympy/polys/tests/test_polytools.py::test_issue_18205 PASSED             [ 99%]\nsympy/polys/tests/test_polytools.py::test_issue_8695 PASSED              [100%]\n\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================== 150 passed, 1 warning in 6.38s ========================\n\n",
          "test_files_run": [
            "sympy/polys/tests/test_polytools.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-19346",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://35.239.238.137:8080",
      "duration": 20.765334129333496,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 40,
          "failed": 4,
          "errors": 0,
          "collected": 44,
          "duration": 9.76,
          "log_tail": "sympy/printing/tests/test_repr.py::test_Naturals0 PASSED                 [ 84%]\nsympy/printing/tests/test_repr.py::test_Reals PASSED                     [ 86%]\nsympy/printing/tests/test_repr.py::test_matrix_expressions PASSED        [ 88%]\nsympy/printing/tests/test_repr.py::test_Cycle PASSED                     [ 90%]\nsympy/printing/tests/test_repr.py::test_Permutation PASSED               [ 93%]\nsympy/printing/tests/test_repr.py::test_diffgeom PASSED                  [ 95%]\nsympy/printing/tests/test_repr.py::test_dict FAILED                      [ 97%]\nsympy/printing/tests/test_repr.py::test_set FAILED                       [100%]\n\n=================================== FAILURES ===================================\n___________________________________ test_Add ___________________________________\nsympy/printing/tests/test_repr.py:51: in test_Add\n    assert srepr(sympify('x + 3 - 2', evaluate=False), order='none') == \"Add(Symbol('x'), Integer(3), Mul(Integer(-1), Integer(2)))\"\nsympy/core/sympify.py:406: in sympify\n    expr = parse_expr(a, local_dict=locals, transformations=transformations, evaluate=evaluate)\nsympy/parsing/sympy_parser.py:1006: in parse_expr\n    code = compile(evaluateFalse(code), '<string>', 'eval')\nE   ValueError: Name node can't be used with 'False' constant\n___________________________________ test_Mul ___________________________________\nsympy/printing/tests/test_repr.py:207: in test_Mul\n    assert srepr(sympify('(x+4)*2*x*7', evaluate=False), order='none') == \"Mul(Add(Symbol('x'), Integer(4)), Integer(2), Symbol('x'), Integer(7))\"\nsympy/core/sympify.py:406: in sympify\n    expr = parse_expr(a, local_dict=locals, transformations=transformations, evaluate=evaluate)\nsympy/parsing/sympy_parser.py:1006: in parse_expr\n    code = compile(evaluateFalse(code), '<string>', 'eval')\nE   ValueError: Name node can't be used with 'False' constant\n__________________________________ test_dict ___________________________________\nsympy/printing/tests/test_repr.py:328: in test_dict\n    assert srepr(d) == \"{Symbol('x'): Symbol('y')}\"\nE   assert '{x: y}' == \"{Symbol('x'): Symbol('y')}\"\nE     \nE     - {Symbol('x'): Symbol('y')}\nE     + {x: y}\n___________________________________ test_set ___________________________________\nsympy/printing/tests/test_repr.py:343: in test_set\n    assert srepr(s) in (\"{Symbol('x'), Symbol('y')}\", \"{Symbol('y'), Symbol('x')}\")\nE   assert '{y, x}' in (\"{Symbol('x'), Symbol('y')}\", \"{Symbol('y'), Symbol('x')}\")\nE    +  where '{y, x}' = <function srepr at 0x7ff92b47bee0>({y, x})\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 4 failed, 40 passed, 1 warning in 0.92s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/printing/tests/test_repr.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/printing/tests/test_repr.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 42,
          "failed": 2,
          "errors": 0,
          "collected": 44,
          "duration": 9.8,
          "log_tail": "sympy/printing/tests/test_repr.py::test_PolyRing PASSED                  [ 56%]\nsympy/printing/tests/test_repr.py::test_FracField PASSED                 [ 59%]\nsympy/printing/tests/test_repr.py::test_PolyElement PASSED               [ 61%]\nsympy/printing/tests/test_repr.py::test_FracElement PASSED               [ 63%]\nsympy/printing/tests/test_repr.py::test_FractionField PASSED             [ 65%]\nsympy/printing/tests/test_repr.py::test_PolynomialRingBase PASSED        [ 68%]\nsympy/printing/tests/test_repr.py::test_DMP PASSED                       [ 70%]\nsympy/printing/tests/test_repr.py::test_FiniteExtension PASSED           [ 72%]\nsympy/printing/tests/test_repr.py::test_ExtensionElement PASSED          [ 75%]\nsympy/printing/tests/test_repr.py::test_BooleanAtom PASSED               [ 77%]\nsympy/printing/tests/test_repr.py::test_Integers PASSED                  [ 79%]\nsympy/printing/tests/test_repr.py::test_Naturals PASSED                  [ 81%]\nsympy/printing/tests/test_repr.py::test_Naturals0 PASSED                 [ 84%]\nsympy/printing/tests/test_repr.py::test_Reals PASSED                     [ 86%]\nsympy/printing/tests/test_repr.py::test_matrix_expressions PASSED        [ 88%]\nsympy/printing/tests/test_repr.py::test_Cycle PASSED                     [ 90%]\nsympy/printing/tests/test_repr.py::test_Permutation PASSED               [ 93%]\nsympy/printing/tests/test_repr.py::test_diffgeom PASSED                  [ 95%]\nsympy/printing/tests/test_repr.py::test_dict PASSED                      [ 97%]\nsympy/printing/tests/test_repr.py::test_set PASSED                       [100%]\n\n=================================== FAILURES ===================================\n___________________________________ test_Add ___________________________________\nsympy/printing/tests/test_repr.py:51: in test_Add\n    assert srepr(sympify('x + 3 - 2', evaluate=False), order='none') == \"Add(Symbol('x'), Integer(3), Mul(Integer(-1), Integer(2)))\"\nsympy/core/sympify.py:406: in sympify\n    expr = parse_expr(a, local_dict=locals, transformations=transformations, evaluate=evaluate)\nsympy/parsing/sympy_parser.py:1006: in parse_expr\n    code = compile(evaluateFalse(code), '<string>', 'eval')\nE   ValueError: Name node can't be used with 'False' constant\n___________________________________ test_Mul ___________________________________\nsympy/printing/tests/test_repr.py:207: in test_Mul\n    assert srepr(sympify('(x+4)*2*x*7', evaluate=False), order='none') == \"Mul(Add(Symbol('x'), Integer(4)), Integer(2), Symbol('x'), Integer(7))\"\nsympy/core/sympify.py:406: in sympify\n    expr = parse_expr(a, local_dict=locals, transformations=transformations, evaluate=evaluate)\nsympy/parsing/sympy_parser.py:1006: in parse_expr\n    code = compile(evaluateFalse(code), '<string>', 'eval')\nE   ValueError: Name node can't be used with 'False' constant\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 2 failed, 42 passed, 1 warning in 0.67s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/printing/tests/test_repr.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/printing/tests/test_repr.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sympy__sympy-19495",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 21.418150901794434,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 8,
          "failed": 1,
          "errors": 0,
          "collected": 10,
          "duration": 10.32,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 10 items\n\nsympy/sets/tests/test_conditionset.py::test_CondSet PASSED               [ 10%]\nsympy/sets/tests/test_conditionset.py::test_CondSet_intersect PASSED     [ 20%]\nsympy/sets/tests/test_conditionset.py::test_issue_9849 PASSED            [ 30%]\nsympy/sets/tests/test_conditionset.py::test_simplified_FiniteSet_in_CondSet PASSED [ 40%]\nsympy/sets/tests/test_conditionset.py::test_free_symbols PASSED          [ 50%]\nsympy/sets/tests/test_conditionset.py::test_subs_CondSet FAILED          [ 60%]\nsympy/sets/tests/test_conditionset.py::test_subs_CondSet_tebr PASSED     [ 70%]\nsympy/sets/tests/test_conditionset.py::test_dummy_eq PASSED              [ 80%]\nsympy/sets/tests/test_conditionset.py::test_contains PASSED              [ 90%]\nsympy/sets/tests/test_conditionset.py::test_failing_contains XFAIL       [100%]\n\n=================================== FAILURES ===================================\n______________________________ test_subs_CondSet _______________________________\nsympy/sets/tests/test_conditionset.py:127: in test_subs_CondSet\n    assert ConditionSet(\nE   assert EmptySet == Interval(-oo, 0)\nE    +  where EmptySet = subs(x, p)\nE    +    where subs = ConditionSet(n, n < x, Interval(-oo, 0)).subs\nE    +      where ConditionSet(n, n < x, Interval(-oo, 0)) = ConditionSet(n, n < x, Interval(-oo, 0))\nE    +        where Interval(-oo, 0) = Interval(-oo, 0)\nE    +  and   Interval(-oo, 0) = Interval(-oo, 0)\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n============== 1 failed, 8 passed, 1 xfailed, 1 warning in 1.08s ===============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/sets/tests/test_conditionset.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/sets/tests/test_conditionset.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 9,
          "failed": 0,
          "errors": 0,
          "collected": 10,
          "duration": 9.79,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 10 items\n\nsympy/sets/tests/test_conditionset.py::test_CondSet PASSED               [ 10%]\nsympy/sets/tests/test_conditionset.py::test_CondSet_intersect PASSED     [ 20%]\nsympy/sets/tests/test_conditionset.py::test_issue_9849 PASSED            [ 30%]\nsympy/sets/tests/test_conditionset.py::test_simplified_FiniteSet_in_CondSet PASSED [ 40%]\nsympy/sets/tests/test_conditionset.py::test_free_symbols PASSED          [ 50%]\nsympy/sets/tests/test_conditionset.py::test_subs_CondSet PASSED          [ 60%]\nsympy/sets/tests/test_conditionset.py::test_subs_CondSet_tebr PASSED     [ 70%]\nsympy/sets/tests/test_conditionset.py::test_dummy_eq PASSED              [ 80%]\nsympy/sets/tests/test_conditionset.py::test_contains PASSED              [ 90%]\nsympy/sets/tests/test_conditionset.py::test_failing_contains XFAIL       [100%]\n\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=================== 9 passed, 1 xfailed, 1 warning in 0.80s ====================\n\n",
          "test_files_run": [
            "sympy/sets/tests/test_conditionset.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-19637",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://35.239.238.137:8080",
      "duration": 21.77184796333313,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 40,
          "failed": 3,
          "errors": 0,
          "collected": 50,
          "duration": 10.27,
          "log_tail": "sympy/core/tests/test_sympify.py::test_issue_6540_6552 PASSED            [ 74%]\nsympy/core/tests/test_sympify.py::test_issue_6046 PASSED                 [ 76%]\nsympy/core/tests/test_sympify.py::test_issue_8821_highprec_from_str PASSED [ 78%]\nsympy/core/tests/test_sympify.py::test_issue_10295 SKIPPED (numpy no...) [ 80%]\nsympy/core/tests/test_sympify.py::test_Range PASSED                      [ 82%]\nsympy/core/tests/test_sympify.py::test_sympify_set PASSED                [ 84%]\nsympy/core/tests/test_sympify.py::test_sympify_numpy SKIPPED (numpy ...) [ 86%]\nsympy/core/tests/test_sympify.py::test_sympify_rational_numbers_set XFAIL [ 88%]\nsympy/core/tests/test_sympify.py::test_issue_13924 SKIPPED (numpy no...) [ 90%]\nsympy/core/tests/test_sympify.py::test_numpy_sympify_args SKIPPED (n...) [ 92%]\nsympy/core/tests/test_sympify.py::test_issue_5939 PASSED                 [ 94%]\nsympy/core/tests/test_sympify.py::test_issue_16759 PASSED                [ 96%]\nsympy/core/tests/test_sympify.py::test_issue_17811 FAILED                [ 98%]\nsympy/core/tests/test_sympify.py::test_issue_14706 SKIPPED (numpy no...) [100%]\n\n=================================== FAILURES ===================================\n_____________________________ test_evaluate_false ______________________________\nsympy/core/tests/test_sympify.py:435: in test_evaluate_false\n    assert sympify(case, evaluate=False) == result\nsympy/core/sympify.py:406: in sympify\n    expr = parse_expr(a, local_dict=locals, transformations=transformations, evaluate=evaluate)\nsympy/parsing/sympy_parser.py:1006: in parse_expr\n    code = compile(evaluateFalse(code), '<string>', 'eval')\nE   ValueError: Name node can't be used with 'False' constant\n__________________________________ test_kernS __________________________________\nsympy/core/tests/test_sympify.py:515: in test_kernS\n    assert kernS(\"(2*x)/(x-1)\") == 2*x/(x-1)\nsympy/core/sympify.py:516: in kernS\n    hit = kern in s\nE   UnboundLocalError: local variable 'kern' referenced before assignment\n_______________________________ test_issue_17811 _______________________________\nsympy/core/tests/test_sympify.py:707: in test_issue_17811\n    assert sympify('a(x)*5', evaluate=False) == Mul(a(x), 5, evaluate=False)\nsympy/core/sympify.py:406: in sympify\n    expr = parse_expr(a, local_dict=locals, transformations=transformations, evaluate=evaluate)\nsympy/parsing/sympy_parser.py:1006: in parse_expr\n    code = compile(evaluateFalse(code), '<string>', 'eval')\nE   ValueError: Name node can't be used with 'False' constant\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n======== 3 failed, 40 passed, 5 skipped, 2 xfailed, 1 warning in 1.07s =========\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/core/tests/test_sympify.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/core/tests/test_sympify.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 41,
          "failed": 2,
          "errors": 0,
          "collected": 50,
          "duration": 10.3,
          "log_tail": "sympy/core/tests/test_sympify.py::test_issue_4788 PASSED                 [ 62%]\nsympy/core/tests/test_sympify.py::test_issue_4798_None PASSED            [ 64%]\nsympy/core/tests/test_sympify.py::test_issue_3218 PASSED                 [ 66%]\nsympy/core/tests/test_sympify.py::test_issue_4988_builtins PASSED        [ 68%]\nsympy/core/tests/test_sympify.py::test_geometry PASSED                   [ 70%]\nsympy/core/tests/test_sympify.py::test_kernS PASSED                      [ 72%]\nsympy/core/tests/test_sympify.py::test_issue_6540_6552 PASSED            [ 74%]\nsympy/core/tests/test_sympify.py::test_issue_6046 PASSED                 [ 76%]\nsympy/core/tests/test_sympify.py::test_issue_8821_highprec_from_str PASSED [ 78%]\nsympy/core/tests/test_sympify.py::test_issue_10295 SKIPPED (numpy no...) [ 80%]\nsympy/core/tests/test_sympify.py::test_Range PASSED                      [ 82%]\nsympy/core/tests/test_sympify.py::test_sympify_set PASSED                [ 84%]\nsympy/core/tests/test_sympify.py::test_sympify_numpy SKIPPED (numpy ...) [ 86%]\nsympy/core/tests/test_sympify.py::test_sympify_rational_numbers_set XFAIL [ 88%]\nsympy/core/tests/test_sympify.py::test_issue_13924 SKIPPED (numpy no...) [ 90%]\nsympy/core/tests/test_sympify.py::test_numpy_sympify_args SKIPPED (n...) [ 92%]\nsympy/core/tests/test_sympify.py::test_issue_5939 PASSED                 [ 94%]\nsympy/core/tests/test_sympify.py::test_issue_16759 PASSED                [ 96%]\nsympy/core/tests/test_sympify.py::test_issue_17811 FAILED                [ 98%]\nsympy/core/tests/test_sympify.py::test_issue_14706 SKIPPED (numpy no...) [100%]\n\n=================================== FAILURES ===================================\n_____________________________ test_evaluate_false ______________________________\nsympy/core/tests/test_sympify.py:435: in test_evaluate_false\n    assert sympify(case, evaluate=False) == result\nsympy/core/sympify.py:406: in sympify\n    expr = parse_expr(a, local_dict=locals, transformations=transformations, evaluate=evaluate)\nsympy/parsing/sympy_parser.py:1006: in parse_expr\n    code = compile(evaluateFalse(code), '<string>', 'eval')\nE   ValueError: Name node can't be used with 'False' constant\n_______________________________ test_issue_17811 _______________________________\nsympy/core/tests/test_sympify.py:707: in test_issue_17811\n    assert sympify('a(x)*5', evaluate=False) == Mul(a(x), 5, evaluate=False)\nsympy/core/sympify.py:406: in sympify\n    expr = parse_expr(a, local_dict=locals, transformations=transformations, evaluate=evaluate)\nsympy/parsing/sympy_parser.py:1006: in parse_expr\n    code = compile(evaluateFalse(code), '<string>', 'eval')\nE   ValueError: Name node can't be used with 'False' constant\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n======== 2 failed, 41 passed, 5 skipped, 2 xfailed, 1 warning in 1.07s =========\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/core/tests/test_sympify.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/core/tests/test_sympify.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sympy__sympy-19783",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 21.94691514968872,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 10,
          "failed": 2,
          "errors": 0,
          "collected": 14,
          "duration": 10.5,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 14 items\n\nsympy/physics/quantum/tests/test_dagger.py::test_scalars PASSED          [  7%]\nsympy/physics/quantum/tests/test_dagger.py::test_matrix PASSED           [ 14%]\nsympy/physics/quantum/tests/test_dagger.py::test_dagger_mul FAILED       [ 21%]\nsympy/physics/quantum/tests/test_dagger.py::test_eval_adjoint PASSED     [ 28%]\nsympy/physics/quantum/tests/test_dagger.py::test_numpy_dagger SKIPPED    [ 35%]\nsympy/physics/quantum/tests/test_dagger.py::test_scipy_sparse_dagger SKIPPED [ 42%]\nsympy/physics/quantum/tests/test_operator.py::test_operator PASSED       [ 50%]\nsympy/physics/quantum/tests/test_operator.py::test_operator_inv PASSED   [ 57%]\nsympy/physics/quantum/tests/test_operator.py::test_hermitian PASSED      [ 64%]\nsympy/physics/quantum/tests/test_operator.py::test_unitary PASSED        [ 71%]\nsympy/physics/quantum/tests/test_operator.py::test_identity FAILED       [ 78%]\nsympy/physics/quantum/tests/test_operator.py::test_outer_product PASSED  [ 85%]\nsympy/physics/quantum/tests/test_operator.py::test_operator_dagger PASSED [ 92%]\nsympy/physics/quantum/tests/test_operator.py::test_differential_operator PASSED [100%]\n\n=================================== FAILURES ===================================\n_______________________________ test_dagger_mul ________________________________\nsympy/physics/quantum/tests/test_dagger.py:39: in test_dagger_mul\n    assert Dagger(O)*Dagger(I) == Dagger(O)\nE   assert (Dagger(O) * I) == Dagger(O)\nE    +  where Dagger(O) = Dagger(O)\nE    +  and   I = Dagger(I)\nE    +  and   Dagger(O) = Dagger(O)\n________________________________ test_identity _________________________________\nsympy/physics/quantum/tests/test_operator.py:97: in test_identity\n    assert I * Dagger(O) == Dagger(O)\nE   assert (I * Dagger(O)) == Dagger(O)\nE    +  where Dagger(O) = Dagger(O)\nE    +  and   Dagger(O) = Dagger(O)\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n============== 2 failed, 10 passed, 2 skipped, 1 warning in 0.85s ==============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/physics/quantum/tests/test_dagger.py sympy/physics/quantum/tests/test_operator.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/physics/quantum/tests/test_dagger.py",
            "sympy/physics/quantum/tests/test_operator.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 12,
          "failed": 0,
          "errors": 0,
          "collected": 14,
          "duration": 10.19,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 14 items\n\nsympy/physics/quantum/tests/test_dagger.py::test_scalars PASSED          [  7%]\nsympy/physics/quantum/tests/test_dagger.py::test_matrix PASSED           [ 14%]\nsympy/physics/quantum/tests/test_dagger.py::test_dagger_mul PASSED       [ 21%]\nsympy/physics/quantum/tests/test_dagger.py::test_eval_adjoint PASSED     [ 28%]\nsympy/physics/quantum/tests/test_dagger.py::test_numpy_dagger SKIPPED    [ 35%]\nsympy/physics/quantum/tests/test_dagger.py::test_scipy_sparse_dagger SKIPPED [ 42%]\nsympy/physics/quantum/tests/test_operator.py::test_operator PASSED       [ 50%]\nsympy/physics/quantum/tests/test_operator.py::test_operator_inv PASSED   [ 57%]\nsympy/physics/quantum/tests/test_operator.py::test_hermitian PASSED      [ 64%]\nsympy/physics/quantum/tests/test_operator.py::test_unitary PASSED        [ 71%]\nsympy/physics/quantum/tests/test_operator.py::test_identity PASSED       [ 78%]\nsympy/physics/quantum/tests/test_operator.py::test_outer_product PASSED  [ 85%]\nsympy/physics/quantum/tests/test_operator.py::test_operator_dagger PASSED [ 92%]\nsympy/physics/quantum/tests/test_operator.py::test_differential_operator PASSED [100%]\n\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=================== 12 passed, 2 skipped, 1 warning in 1.08s ===================\n\n",
          "test_files_run": [
            "sympy/physics/quantum/tests/test_dagger.py",
            "sympy/physics/quantum/tests/test_operator.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-19954",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 40.68692898750305,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 58,
          "failed": 1,
          "errors": 0,
          "collected": 61,
          "duration": 21.59,
          "log_tail": "sympy/combinatorics/tests/test_perm_groups.py::test_derived_series PASSED [ 55%]\nsympy/combinatorics/tests/test_perm_groups.py::test_lower_central_series PASSED [ 57%]\nsympy/combinatorics/tests/test_perm_groups.py::test_commutator PASSED    [ 59%]\nsympy/combinatorics/tests/test_perm_groups.py::test_is_nilpotent PASSED  [ 60%]\nsympy/combinatorics/tests/test_perm_groups.py::test_is_trivial PASSED    [ 62%]\nsympy/combinatorics/tests/test_perm_groups.py::test_pointwise_stabilizer PASSED [ 63%]\nsympy/combinatorics/tests/test_perm_groups.py::test_make_perm PASSED     [ 65%]\nsympy/combinatorics/tests/test_perm_groups.py::test_elements PASSED      [ 67%]\nsympy/combinatorics/tests/test_perm_groups.py::test_is_group PASSED      [ 68%]\nsympy/combinatorics/tests/test_perm_groups.py::test_PermutationGroup PASSED [ 70%]\nsympy/combinatorics/tests/test_perm_groups.py::test_coset_transvesal PASSED [ 72%]\nsympy/combinatorics/tests/test_perm_groups.py::test_coset_table PASSED   [ 73%]\nsympy/combinatorics/tests/test_perm_groups.py::test_subgroup PASSED      [ 75%]\nsympy/combinatorics/tests/test_perm_groups.py::test_generator_product PASSED [ 77%]\nsympy/combinatorics/tests/test_perm_groups.py::test_sylow_subgroup FAILED [ 78%]\nsympy/combinatorics/tests/test_perm_groups.py::test_presentation PASSED  [ 80%]\nsympy/combinatorics/tests/test_perm_groups.py::test_polycyclic PASSED    [ 81%]\nsympy/combinatorics/tests/test_perm_groups.py::test_elementary PASSED    [ 83%]\nsympy/combinatorics/tests/test_perm_groups.py::test_perfect PASSED       [ 85%]\nsympy/combinatorics/tests/test_perm_groups.py::test_index PASSED         [ 86%]\nsympy/combinatorics/tests/test_perm_groups.py::test_cyclic PASSED        [ 88%]\nsympy/combinatorics/tests/test_perm_groups.py::test_abelian_invariants PASSED [ 90%]\nsympy/combinatorics/tests/test_perm_groups.py::test_composition_series PASSED [ 91%]\nsympy/combinatorics/tests/test_perm_groups.py::test_is_symmetric PASSED  [ 93%]\nsympy/combinatorics/tests/test_perm_groups.py::test_conjugacy_class PASSED [ 95%]\nsympy/combinatorics/tests/test_perm_groups.py::test_conjugacy_classes PASSED [ 96%]\nsympy/combinatorics/tests/test_perm_groups.py::test_coset_class PASSED   [ 98%]\nsympy/combinatorics/tests/test_perm_groups.py::test_symmetricpermutationgroup PASSED [100%]\n\n=================================== FAILURES ===================================\n_____________________________ test_sylow_subgroup ______________________________\nsympy/combinatorics/tests/test_perm_groups.py:909: in test_sylow_subgroup\n    S = G.sylow_subgroup(p=2)\nsympy/combinatorics/perm_groups.py:4354: in sylow_subgroup\n    blocks = self.minimal_blocks()\nsympy/combinatorics/perm_groups.py:2201: in minimal_blocks\n    del num_blocks[i], blocks[i]\nE   IndexError: list assignment index out of range\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n============= 1 failed, 58 passed, 2 skipped, 1 warning in 12.13s ==============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/combinatorics/tests/test_perm_groups.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/combinatorics/tests/test_perm_groups.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 59,
          "failed": 0,
          "errors": 0,
          "collected": 61,
          "duration": 18.06,
          "log_tail": "sympy/combinatorics/tests/test_perm_groups.py::test_minimal_blocks PASSED [ 37%]\nsympy/combinatorics/tests/test_perm_groups.py::test_max_div PASSED       [ 39%]\nsympy/combinatorics/tests/test_perm_groups.py::test_is_primitive PASSED  [ 40%]\nsympy/combinatorics/tests/test_perm_groups.py::test_random_stab PASSED   [ 42%]\nsympy/combinatorics/tests/test_perm_groups.py::test_transitivity_degree PASSED [ 44%]\nsympy/combinatorics/tests/test_perm_groups.py::test_schreier_sims_random PASSED [ 45%]\nsympy/combinatorics/tests/test_perm_groups.py::test_baseswap PASSED      [ 47%]\nsympy/combinatorics/tests/test_perm_groups.py::test_schreier_sims_incremental PASSED [ 49%]\nsympy/combinatorics/tests/test_perm_groups.py::test_subgroup_search PASSED [ 50%]\nsympy/combinatorics/tests/test_perm_groups.py::test_subgroup_search2 SKIPPED [ 52%]\nsympy/combinatorics/tests/test_perm_groups.py::test_normal_closure PASSED [ 54%]\nsympy/combinatorics/tests/test_perm_groups.py::test_derived_series PASSED [ 55%]\nsympy/combinatorics/tests/test_perm_groups.py::test_lower_central_series PASSED [ 57%]\nsympy/combinatorics/tests/test_perm_groups.py::test_commutator PASSED    [ 59%]\nsympy/combinatorics/tests/test_perm_groups.py::test_is_nilpotent PASSED  [ 60%]\nsympy/combinatorics/tests/test_perm_groups.py::test_is_trivial PASSED    [ 62%]\nsympy/combinatorics/tests/test_perm_groups.py::test_pointwise_stabilizer PASSED [ 63%]\nsympy/combinatorics/tests/test_perm_groups.py::test_make_perm PASSED     [ 65%]\nsympy/combinatorics/tests/test_perm_groups.py::test_elements PASSED      [ 67%]\nsympy/combinatorics/tests/test_perm_groups.py::test_is_group PASSED      [ 68%]\nsympy/combinatorics/tests/test_perm_groups.py::test_PermutationGroup PASSED [ 70%]\nsympy/combinatorics/tests/test_perm_groups.py::test_coset_transvesal PASSED [ 72%]\nsympy/combinatorics/tests/test_perm_groups.py::test_coset_table PASSED   [ 73%]\nsympy/combinatorics/tests/test_perm_groups.py::test_subgroup PASSED      [ 75%]\nsympy/combinatorics/tests/test_perm_groups.py::test_generator_product PASSED [ 77%]\nsympy/combinatorics/tests/test_perm_groups.py::test_sylow_subgroup PASSED [ 78%]\nsympy/combinatorics/tests/test_perm_groups.py::test_presentation PASSED  [ 80%]\nsympy/combinatorics/tests/test_perm_groups.py::test_polycyclic PASSED    [ 81%]\nsympy/combinatorics/tests/test_perm_groups.py::test_elementary PASSED    [ 83%]\nsympy/combinatorics/tests/test_perm_groups.py::test_perfect PASSED       [ 85%]\nsympy/combinatorics/tests/test_perm_groups.py::test_index PASSED         [ 86%]\nsympy/combinatorics/tests/test_perm_groups.py::test_cyclic PASSED        [ 88%]\nsympy/combinatorics/tests/test_perm_groups.py::test_abelian_invariants PASSED [ 90%]\nsympy/combinatorics/tests/test_perm_groups.py::test_composition_series PASSED [ 91%]\nsympy/combinatorics/tests/test_perm_groups.py::test_is_symmetric PASSED  [ 93%]\nsympy/combinatorics/tests/test_perm_groups.py::test_conjugacy_class PASSED [ 95%]\nsympy/combinatorics/tests/test_perm_groups.py::test_conjugacy_classes PASSED [ 96%]\nsympy/combinatorics/tests/test_perm_groups.py::test_coset_class PASSED   [ 98%]\nsympy/combinatorics/tests/test_perm_groups.py::test_symmetricpermutationgroup PASSED [100%]\n\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=================== 59 passed, 2 skipped, 1 warning in 9.67s ===================\n\n",
          "test_files_run": [
            "sympy/combinatorics/tests/test_perm_groups.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-20154",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 21.51974320411682,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 41,
          "failed": 2,
          "errors": 0,
          "collected": 43,
          "duration": 10.37,
          "log_tail": "sympy/utilities/tests/test_iterables.py::test_ordered PASSED             [ 79%]\nsympy/utilities/tests/test_iterables.py::test_runs PASSED                [ 81%]\nsympy/utilities/tests/test_iterables.py::test_reshape PASSED             [ 83%]\nsympy/utilities/tests/test_iterables.py::test_uniq FAILED                [ 86%]\nsympy/utilities/tests/test_iterables.py::test_kbins PASSED               [ 88%]\nsympy/utilities/tests/test_iterables.py::test_has_dups PASSED            [ 90%]\nsympy/utilities/tests/test_iterables.py::test__partition PASSED          [ 93%]\nsympy/utilities/tests/test_iterables.py::test_ordered_partitions PASSED  [ 95%]\nsympy/utilities/tests/test_iterables.py::test_rotations PASSED           [ 97%]\nsympy/utilities/tests/test_iterables.py::test_ibin PASSED                [100%]\n\n=================================== FAILURES ===================================\n_______________________________ test_partitions ________________________________\nsympy/utilities/tests/test_iterables.py:484: in test_partitions\n    assert [p for p in partitions(6, k=2)] == [\nE   AssertionError: assert [{1: 6}, {1: ...1: 6}, {1: 6}] == [{2: 3}, {1: ...2: 1}, {1: 6}]\nE     \nE     At index 0 diff: {1: 6} != {2: 3}\nE     \nE     Full diff:\nE       [\nE           {\nE     -         2: 3,...\nE     \nE     ...Full output truncated (22 lines hidden), use '-vv' to show\n__________________________________ test_uniq ___________________________________\nsympy/utilities/tests/test_iterables.py:700: in test_uniq\n    assert list(uniq(p for p in partitions(4))) == \\\nE   AssertionError: assert [{1: 4}] == [{4: 1}, {1: ...2: 1}, {1: 4}]\nE     \nE     At index 0 diff: {1: 4} != {4: 1}\nE     Right contains 4 more items, first extra item: {1: 1, 3: 1}\nE     \nE     Full diff:\nE       [\nE     -     {...\nE     \nE     ...Full output truncated (17 lines hidden), use '-vv' to show\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 2 failed, 41 passed, 1 warning in 1.36s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/utilities/tests/test_iterables.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/utilities/tests/test_iterables.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 43,
          "failed": 0,
          "errors": 0,
          "collected": 43,
          "duration": 10.01,
          "log_tail": "sympy/utilities/tests/test_iterables.py::test_group PASSED               [ 11%]\nsympy/utilities/tests/test_iterables.py::test_subsets PASSED             [ 13%]\nsympy/utilities/tests/test_iterables.py::test_variations PASSED          [ 16%]\nsympy/utilities/tests/test_iterables.py::test_cartes PASSED              [ 18%]\nsympy/utilities/tests/test_iterables.py::test_filter_symbols PASSED      [ 20%]\nsympy/utilities/tests/test_iterables.py::test_numbered_symbols PASSED    [ 23%]\nsympy/utilities/tests/test_iterables.py::test_sift PASSED                [ 25%]\nsympy/utilities/tests/test_iterables.py::test_take PASSED                [ 27%]\nsympy/utilities/tests/test_iterables.py::test_dict_merge PASSED          [ 30%]\nsympy/utilities/tests/test_iterables.py::test_prefixes PASSED            [ 32%]\nsympy/utilities/tests/test_iterables.py::test_postfixes PASSED           [ 34%]\nsympy/utilities/tests/test_iterables.py::test_topological_sort PASSED    [ 37%]\nsympy/utilities/tests/test_iterables.py::test_strongly_connected_components PASSED [ 39%]\nsympy/utilities/tests/test_iterables.py::test_connected_components PASSED [ 41%]\nsympy/utilities/tests/test_iterables.py::test_rotate PASSED              [ 44%]\nsympy/utilities/tests/test_iterables.py::test_multiset_partitions PASSED [ 46%]\nsympy/utilities/tests/test_iterables.py::test_multiset_combinations PASSED [ 48%]\nsympy/utilities/tests/test_iterables.py::test_multiset_permutations PASSED [ 51%]\nsympy/utilities/tests/test_iterables.py::test_partitions PASSED          [ 53%]\nsympy/utilities/tests/test_iterables.py::test_binary_partitions PASSED   [ 55%]\nsympy/utilities/tests/test_iterables.py::test_bell_perm PASSED           [ 58%]\nsympy/utilities/tests/test_iterables.py::test_involutions PASSED         [ 60%]\nsympy/utilities/tests/test_iterables.py::test_derangements PASSED        [ 62%]\nsympy/utilities/tests/test_iterables.py::test_necklaces PASSED           [ 65%]\nsympy/utilities/tests/test_iterables.py::test_bracelets PASSED           [ 67%]\nsympy/utilities/tests/test_iterables.py::test_generate_oriented_forest PASSED [ 69%]\nsympy/utilities/tests/test_iterables.py::test_unflatten PASSED           [ 72%]\nsympy/utilities/tests/test_iterables.py::test_common_prefix_suffix PASSED [ 74%]\nsympy/utilities/tests/test_iterables.py::test_minlex PASSED              [ 76%]\nsympy/utilities/tests/test_iterables.py::test_ordered PASSED             [ 79%]\nsympy/utilities/tests/test_iterables.py::test_runs PASSED                [ 81%]\nsympy/utilities/tests/test_iterables.py::test_reshape PASSED             [ 83%]\nsympy/utilities/tests/test_iterables.py::test_uniq PASSED                [ 86%]\nsympy/utilities/tests/test_iterables.py::test_kbins PASSED               [ 88%]\nsympy/utilities/tests/test_iterables.py::test_has_dups PASSED            [ 90%]\nsympy/utilities/tests/test_iterables.py::test__partition PASSED          [ 93%]\nsympy/utilities/tests/test_iterables.py::test_ordered_partitions PASSED  [ 95%]\nsympy/utilities/tests/test_iterables.py::test_rotations PASSED           [ 97%]\nsympy/utilities/tests/test_iterables.py::test_ibin PASSED                [100%]\n\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================== 43 passed, 1 warning in 0.93s =========================\n\n",
          "test_files_run": [
            "sympy/utilities/tests/test_iterables.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-20428",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 37.73777365684509,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 155,
          "failed": 1,
          "errors": 0,
          "collected": 156,
          "duration": 17.54,
          "log_tail": "sympy/polys/tests/test_polytools.py::test_all_roots PASSED               [ 80%]\nsympy/polys/tests/test_polytools.py::test_nroots PASSED                  [ 81%]\nsympy/polys/tests/test_polytools.py::test_ground_roots PASSED            [ 82%]\nsympy/polys/tests/test_polytools.py::test_nth_power_roots_poly PASSED    [ 82%]\nsympy/polys/tests/test_polytools.py::test_torational_factor_list PASSED  [ 83%]\nsympy/polys/tests/test_polytools.py::test_cancel PASSED                  [ 83%]\nsympy/polys/tests/test_polytools.py::test_reduced PASSED                 [ 84%]\nsympy/polys/tests/test_polytools.py::test_groebner PASSED                [ 85%]\nsympy/polys/tests/test_polytools.py::test_fglm PASSED                    [ 85%]\nsympy/polys/tests/test_polytools.py::test_is_zero_dimensional PASSED     [ 86%]\nsympy/polys/tests/test_polytools.py::test_GroebnerBasis PASSED           [ 87%]\nsympy/polys/tests/test_polytools.py::test_poly PASSED                    [ 87%]\nsympy/polys/tests/test_polytools.py::test_keep_coeff PASSED              [ 88%]\nsympy/polys/tests/test_polytools.py::test_poly_matching_consistency PASSED [ 89%]\nsympy/polys/tests/test_polytools.py::test_issue_5786 PASSED              [ 89%]\nsympy/polys/tests/test_polytools.py::test_noncommutative PASSED          [ 90%]\nsympy/polys/tests/test_polytools.py::test_to_rational_coeffs PASSED      [ 91%]\nsympy/polys/tests/test_polytools.py::test_factor_terms PASSED            [ 91%]\nsympy/polys/tests/test_polytools.py::test_as_list PASSED                 [ 92%]\nsympy/polys/tests/test_polytools.py::test_issue_11198 PASSED             [ 92%]\nsympy/polys/tests/test_polytools.py::test_Poly_precision PASSED          [ 93%]\nsympy/polys/tests/test_polytools.py::test_issue_12400 PASSED             [ 94%]\nsympy/polys/tests/test_polytools.py::test_issue_14364 PASSED             [ 94%]\nsympy/polys/tests/test_polytools.py::test_issue_15669 PASSED             [ 95%]\nsympy/polys/tests/test_polytools.py::test_issue_17988 PASSED             [ 96%]\nsympy/polys/tests/test_polytools.py::test_issue_18205 PASSED             [ 96%]\nsympy/polys/tests/test_polytools.py::test_issue_8695 PASSED              [ 97%]\nsympy/polys/tests/test_polytools.py::test_issue_19113 PASSED             [ 98%]\nsympy/polys/tests/test_polytools.py::test_issue_19360 PASSED             [ 98%]\nsympy/polys/tests/test_polytools.py::test_poly_copy_equals_original PASSED [ 99%]\nsympy/polys/tests/test_polytools.py::test_deserialized_poly_equals_original PASSED [100%]\n\n=================================== FAILURES ===================================\n_______________________________ test_issue_20427 _______________________________\nsympy/polys/tests/test_polytools.py:1472: in test_issue_20427\n    assert f == Poly(0, x, domain='EX')\nE   AssertionError: assert Poly(-117968192370600*18**(1/3)/(217603955769048*(24201 + 253*sqrt(9165))**(1/3) + 2273005839412*sqrt(9165)*(24201 + 253*sqrt(9165))**(1/3)) - 15720318185*2**(2/3)*3**(1/3)*(24201 + 253*sqrt(9165))**(2/3)/(217603955769048*(24201 + 253*sqrt(9165))**(1/3) + 2273005839412*sqrt(9165)*(24201 + 253*sqrt(9165))**(1/3)) + 15720318185*12**(1/3)*(24201 + 253*sqrt(9165))**(2/3)/(217603955769048*(24201 + 253*sqrt(9165))**(1/3) + 2273005839412*sqrt(9165)*(24201 + 253*sqrt(9165))**(1/3)) + 117968192370600*2**(1/3)*3**(2/3)/(217603955769048*(24201 + 253*sqrt(9165))**(1/3) + 2273005839412*sqrt(9165)*(24201 + 253*sqrt(9165))**(1/3)), x, domain='EX') == Poly(0, x, domain='EX')\nE    +  where Poly(0, x, domain='EX') = Poly(0, x, domain='EX')\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 1 failed, 155 passed, 1 warning in 7.67s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/polys/tests/test_polytools.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/polys/tests/test_polytools.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 156,
          "failed": 0,
          "errors": 0,
          "collected": 156,
          "duration": 19.08,
          "log_tail": "sympy/polys/tests/test_polytools.py::test_factor PASSED                  [ 75%]\nsympy/polys/tests/test_polytools.py::test_factor_large PASSED            [ 76%]\nsympy/polys/tests/test_polytools.py::test_factor_noeval PASSED           [ 76%]\nsympy/polys/tests/test_polytools.py::test_intervals PASSED               [ 77%]\nsympy/polys/tests/test_polytools.py::test_refine_root PASSED             [ 78%]\nsympy/polys/tests/test_polytools.py::test_count_roots PASSED             [ 78%]\nsympy/polys/tests/test_polytools.py::test_Poly_root PASSED               [ 79%]\nsympy/polys/tests/test_polytools.py::test_real_roots PASSED              [ 80%]\nsympy/polys/tests/test_polytools.py::test_all_roots PASSED               [ 80%]\nsympy/polys/tests/test_polytools.py::test_nroots PASSED                  [ 81%]\nsympy/polys/tests/test_polytools.py::test_ground_roots PASSED            [ 82%]\nsympy/polys/tests/test_polytools.py::test_nth_power_roots_poly PASSED    [ 82%]\nsympy/polys/tests/test_polytools.py::test_torational_factor_list PASSED  [ 83%]\nsympy/polys/tests/test_polytools.py::test_cancel PASSED                  [ 83%]\nsympy/polys/tests/test_polytools.py::test_reduced PASSED                 [ 84%]\nsympy/polys/tests/test_polytools.py::test_groebner PASSED                [ 85%]\nsympy/polys/tests/test_polytools.py::test_fglm PASSED                    [ 85%]\nsympy/polys/tests/test_polytools.py::test_is_zero_dimensional PASSED     [ 86%]\nsympy/polys/tests/test_polytools.py::test_GroebnerBasis PASSED           [ 87%]\nsympy/polys/tests/test_polytools.py::test_poly PASSED                    [ 87%]\nsympy/polys/tests/test_polytools.py::test_keep_coeff PASSED              [ 88%]\nsympy/polys/tests/test_polytools.py::test_poly_matching_consistency PASSED [ 89%]\nsympy/polys/tests/test_polytools.py::test_issue_5786 PASSED              [ 89%]\nsympy/polys/tests/test_polytools.py::test_noncommutative PASSED          [ 90%]\nsympy/polys/tests/test_polytools.py::test_to_rational_coeffs PASSED      [ 91%]\nsympy/polys/tests/test_polytools.py::test_factor_terms PASSED            [ 91%]\nsympy/polys/tests/test_polytools.py::test_as_list PASSED                 [ 92%]\nsympy/polys/tests/test_polytools.py::test_issue_11198 PASSED             [ 92%]\nsympy/polys/tests/test_polytools.py::test_Poly_precision PASSED          [ 93%]\nsympy/polys/tests/test_polytools.py::test_issue_12400 PASSED             [ 94%]\nsympy/polys/tests/test_polytools.py::test_issue_14364 PASSED             [ 94%]\nsympy/polys/tests/test_polytools.py::test_issue_15669 PASSED             [ 95%]\nsympy/polys/tests/test_polytools.py::test_issue_17988 PASSED             [ 96%]\nsympy/polys/tests/test_polytools.py::test_issue_18205 PASSED             [ 96%]\nsympy/polys/tests/test_polytools.py::test_issue_8695 PASSED              [ 97%]\nsympy/polys/tests/test_polytools.py::test_issue_19113 PASSED             [ 98%]\nsympy/polys/tests/test_polytools.py::test_issue_19360 PASSED             [ 98%]\nsympy/polys/tests/test_polytools.py::test_poly_copy_equals_original PASSED [ 99%]\nsympy/polys/tests/test_polytools.py::test_deserialized_poly_equals_original PASSED [100%]\n\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================= 156 passed, 1 warning in 10.52s ========================\n\n",
          "test_files_run": [
            "sympy/polys/tests/test_polytools.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-20438",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 31.014016151428223,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 94,
          "failed": 2,
          "errors": 0,
          "collected": 100,
          "duration": 15.45,
          "log_tail": "sympy/sets/tests/test_sets.py::test_Union_contains PASSED                [ 90%]\nsympy/sets/tests/test_sets.py::test_issue_16878b XFAIL                   [ 91%]\nsympy/sets/tests/test_sets.py::test_DisjointUnion PASSED                 [ 92%]\nsympy/sets/tests/test_sets.py::test_DisjointUnion_is_empty PASSED        [ 93%]\nsympy/sets/tests/test_sets.py::test_DisjointUnion_is_iterable PASSED     [ 94%]\nsympy/sets/tests/test_sets.py::test_DisjointUnion_contains PASSED        [ 95%]\nsympy/sets/tests/test_sets.py::test_DisjointUnion_iter PASSED            [ 96%]\nsympy/sets/tests/test_sets.py::test_DisjointUnion_len PASSED             [ 97%]\nsympy/sets/tests/test_sets.py::test_issue_20089 PASSED                   [ 98%]\nsympy/sets/tests/test_sets.py::test_issue_19378 FAILED                   [ 99%]\nsympy/sets/tests/test_sets.py::test_issue_20379 PASSED                   [100%]\n\n=================================== FAILURES ===================================\n___________________________________ test_Eq ____________________________________\nsympy/sets/tests/test_sets.py:1254: in test_Eq\n    assert Eq(ProductSet({1}, {2}), Interval(1, 2)) is S.false\nE   assert Eq(ProductSet(FiniteSet(1), FiniteSet(2)), Interval(1, 2)) is False\nE    +  where Eq(ProductSet(FiniteSet(1), FiniteSet(2)), Interval(1, 2)) = Eq(ProductSet(FiniteSet(1), FiniteSet(2)), Interval(1, 2))\nE    +    where ProductSet(FiniteSet(1), FiniteSet(2)) = ProductSet({1}, {2})\nE    +    and   Interval(1, 2) = Interval(1, 2)\nE    +  and   False = S.false\n_______________________________ test_issue_19378 _______________________________\nsympy/sets/tests/test_sets.py:1604: in test_issue_19378\n    assert b.is_subset(c) is True\nE   assert None is True\nE    +  where None = is_subset(FiniteSet((1, 1), (1, 2), (2, 1), (2, 2)))\nE    +    where is_subset = ProductSet(FiniteSet(1, 2), FiniteSet(1, 2)).is_subset\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\nsympy/sets/tests/test_sets.py::test_union_intersection_constructor\nsympy/sets/tests/test_sets.py::test_union_intersection_constructor\n  /testbed/sympy/core/sympify.py:456: SymPyDeprecationWarning: \n  \n  String fallback in sympify has been deprecated since SymPy 1.6. Use\n  sympify(str(obj)) or sympy.core.sympify.converter or obj._sympy_\n  instead. See https://github.com/sympy/sympy/issues/18066 for more\n  info.\n  \n    SymPyDeprecationWarning(\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n============= 2 failed, 94 passed, 4 xfailed, 3 warnings in 5.88s ==============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/sets/tests/test_sets.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/sets/tests/test_sets.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 96,
          "failed": 0,
          "errors": 0,
          "collected": 100,
          "duration": 14.19,
          "log_tail": "sympy/sets/tests/test_sets.py::test_issue_9808 PASSED                    [ 73%]\nsympy/sets/tests/test_sets.py::test_issue_9956 PASSED                    [ 74%]\nsympy/sets/tests/test_sets.py::test_issue_Symbol_inter PASSED            [ 75%]\nsympy/sets/tests/test_sets.py::test_issue_11827 PASSED                   [ 76%]\nsympy/sets/tests/test_sets.py::test_issue_10113 PASSED                   [ 77%]\nsympy/sets/tests/test_sets.py::test_issue_10248 PASSED                   [ 78%]\nsympy/sets/tests/test_sets.py::test_issue_9447 PASSED                    [ 79%]\nsympy/sets/tests/test_sets.py::test_issue_10337 PASSED                   [ 80%]\nsympy/sets/tests/test_sets.py::test_issue_10326 PASSED                   [ 81%]\nsympy/sets/tests/test_sets.py::test_issue_2799 PASSED                    [ 82%]\nsympy/sets/tests/test_sets.py::test_issue_9706 PASSED                    [ 83%]\nsympy/sets/tests/test_sets.py::test_issue_8257 PASSED                    [ 84%]\nsympy/sets/tests/test_sets.py::test_issue_10931 PASSED                   [ 85%]\nsympy/sets/tests/test_sets.py::test_issue_11174 PASSED                   [ 86%]\nsympy/sets/tests/test_sets.py::test_issue_18505 PASSED                   [ 87%]\nsympy/sets/tests/test_sets.py::test_finite_set_intersection PASSED       [ 88%]\nsympy/sets/tests/test_sets.py::test_union_intersection_constructor PASSED [ 89%]\nsympy/sets/tests/test_sets.py::test_Union_contains PASSED                [ 90%]\nsympy/sets/tests/test_sets.py::test_issue_16878b XFAIL                   [ 91%]\nsympy/sets/tests/test_sets.py::test_DisjointUnion PASSED                 [ 92%]\nsympy/sets/tests/test_sets.py::test_DisjointUnion_is_empty PASSED        [ 93%]\nsympy/sets/tests/test_sets.py::test_DisjointUnion_is_iterable PASSED     [ 94%]\nsympy/sets/tests/test_sets.py::test_DisjointUnion_contains PASSED        [ 95%]\nsympy/sets/tests/test_sets.py::test_DisjointUnion_iter PASSED            [ 96%]\nsympy/sets/tests/test_sets.py::test_DisjointUnion_len PASSED             [ 97%]\nsympy/sets/tests/test_sets.py::test_issue_20089 PASSED                   [ 98%]\nsympy/sets/tests/test_sets.py::test_issue_19378 PASSED                   [ 99%]\nsympy/sets/tests/test_sets.py::test_issue_20379 PASSED                   [100%]\n\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\nsympy/sets/tests/test_sets.py::test_union_intersection_constructor\nsympy/sets/tests/test_sets.py::test_union_intersection_constructor\n  /testbed/sympy/core/sympify.py:456: SymPyDeprecationWarning: \n  \n  String fallback in sympify has been deprecated since SymPy 1.6. Use\n  sympify(str(obj)) or sympy.core.sympify.converter or obj._sympy_\n  instead. See https://github.com/sympy/sympy/issues/18066 for more\n  info.\n  \n    SymPyDeprecationWarning(\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================== 96 passed, 4 xfailed, 3 warnings in 4.87s ===================\n\n",
          "test_files_run": [
            "sympy/sets/tests/test_sets.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-20590",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 20.113893032073975,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 22,
          "failed": 1,
          "errors": 0,
          "collected": 23,
          "duration": 9.12,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 23 items\n\nsympy/core/tests/test_basic.py::test__aresame PASSED                     [  4%]\nsympy/core/tests/test_basic.py::test_structure PASSED                    [  8%]\nsympy/core/tests/test_basic.py::test_immutable FAILED                    [ 13%]\nsympy/core/tests/test_basic.py::test_equality PASSED                     [ 17%]\nsympy/core/tests/test_basic.py::test_matches_basic PASSED                [ 21%]\nsympy/core/tests/test_basic.py::test_has PASSED                          [ 26%]\nsympy/core/tests/test_basic.py::test_subs PASSED                         [ 30%]\nsympy/core/tests/test_basic.py::test_subs_with_unicode_symbols PASSED    [ 34%]\nsympy/core/tests/test_basic.py::test_atoms PASSED                        [ 39%]\nsympy/core/tests/test_basic.py::test_free_symbols_empty PASSED           [ 43%]\nsympy/core/tests/test_basic.py::test_doit PASSED                         [ 47%]\nsympy/core/tests/test_basic.py::test_S PASSED                            [ 52%]\nsympy/core/tests/test_basic.py::test_xreplace PASSED                     [ 56%]\nsympy/core/tests/test_basic.py::test_preorder_traversal PASSED           [ 60%]\nsympy/core/tests/test_basic.py::test_sorted_args PASSED                  [ 65%]\nsympy/core/tests/test_basic.py::test_call PASSED                         [ 69%]\nsympy/core/tests/test_basic.py::test_rewrite PASSED                      [ 73%]\nsympy/core/tests/test_basic.py::test_literal_evalf_is_number_is_zero_is_comparable PASSED [ 78%]\nsympy/core/tests/test_basic.py::test_as_Basic PASSED                     [ 82%]\nsympy/core/tests/test_basic.py::test_atomic PASSED                       [ 86%]\nsympy/core/tests/test_basic.py::test_as_dummy PASSED                     [ 91%]\nsympy/core/tests/test_basic.py::test_canonical_variables PASSED          [ 95%]\nsympy/core/tests/test_basic.py::test_replace_exceptions PASSED           [100%]\n\n=================================== FAILURES ===================================\n________________________________ test_immutable ________________________________\nsympy/core/tests/test_basic.py:38: in test_immutable\n    assert not hasattr(b1, '__dict__')\nE   AssertionError: assert not True\nE    +  where True = hasattr(Basic(), '__dict__')\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 1 failed, 22 passed, 1 warning in 0.56s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/core/tests/test_basic.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/core/tests/test_basic.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 23,
          "failed": 0,
          "errors": 0,
          "collected": 23,
          "duration": 9.74,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 23 items\n\nsympy/core/tests/test_basic.py::test__aresame PASSED                     [  4%]\nsympy/core/tests/test_basic.py::test_structure PASSED                    [  8%]\nsympy/core/tests/test_basic.py::test_immutable PASSED                    [ 13%]\nsympy/core/tests/test_basic.py::test_equality PASSED                     [ 17%]\nsympy/core/tests/test_basic.py::test_matches_basic PASSED                [ 21%]\nsympy/core/tests/test_basic.py::test_has PASSED                          [ 26%]\nsympy/core/tests/test_basic.py::test_subs PASSED                         [ 30%]\nsympy/core/tests/test_basic.py::test_subs_with_unicode_symbols PASSED    [ 34%]\nsympy/core/tests/test_basic.py::test_atoms PASSED                        [ 39%]\nsympy/core/tests/test_basic.py::test_free_symbols_empty PASSED           [ 43%]\nsympy/core/tests/test_basic.py::test_doit PASSED                         [ 47%]\nsympy/core/tests/test_basic.py::test_S PASSED                            [ 52%]\nsympy/core/tests/test_basic.py::test_xreplace PASSED                     [ 56%]\nsympy/core/tests/test_basic.py::test_preorder_traversal PASSED           [ 60%]\nsympy/core/tests/test_basic.py::test_sorted_args PASSED                  [ 65%]\nsympy/core/tests/test_basic.py::test_call PASSED                         [ 69%]\nsympy/core/tests/test_basic.py::test_rewrite PASSED                      [ 73%]\nsympy/core/tests/test_basic.py::test_literal_evalf_is_number_is_zero_is_comparable PASSED [ 78%]\nsympy/core/tests/test_basic.py::test_as_Basic PASSED                     [ 82%]\nsympy/core/tests/test_basic.py::test_atomic PASSED                       [ 86%]\nsympy/core/tests/test_basic.py::test_as_dummy PASSED                     [ 91%]\nsympy/core/tests/test_basic.py::test_canonical_variables PASSED          [ 95%]\nsympy/core/tests/test_basic.py::test_replace_exceptions PASSED           [100%]\n\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================== 23 passed, 1 warning in 0.52s =========================\n\n",
          "test_files_run": [
            "sympy/core/tests/test_basic.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-20801",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 28.636121034622192,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 97,
          "failed": 1,
          "errors": 0,
          "collected": 100,
          "duration": 14.64,
          "log_tail": "sympy/core/tests/test_numbers.py::test_bool_eq PASSED                    [ 71%]\nsympy/core/tests/test_numbers.py::test_Float_eq PASSED                   [ 72%]\nsympy/core/tests/test_numbers.py::test_int_NumberSymbols PASSED          [ 73%]\nsympy/core/tests/test_numbers.py::test_issue_6640 PASSED                 [ 74%]\nsympy/core/tests/test_numbers.py::test_issue_6349 PASSED                 [ 75%]\nsympy/core/tests/test_numbers.py::test_mpf_norm PASSED                   [ 76%]\nsympy/core/tests/test_numbers.py::test_latex PASSED                      [ 77%]\nsympy/core/tests/test_numbers.py::test_issue_7742 PASSED                 [ 78%]\nsympy/core/tests/test_numbers.py::test_simplify_AlgebraicNumber PASSED   [ 79%]\nsympy/core/tests/test_numbers.py::test_Float_idempotence PASSED          [ 80%]\nsympy/core/tests/test_numbers.py::test_comp1 PASSED                      [ 81%]\nsympy/core/tests/test_numbers.py::test_issue_9491 PASSED                 [ 82%]\nsympy/core/tests/test_numbers.py::test_issue_10063 PASSED                [ 83%]\nsympy/core/tests/test_numbers.py::test_issue_10020 PASSED                [ 84%]\nsympy/core/tests/test_numbers.py::test_invert_numbers PASSED             [ 85%]\nsympy/core/tests/test_numbers.py::test_mod_inverse PASSED                [ 86%]\nsympy/core/tests/test_numbers.py::test_golden_ratio_rewrite_as_sqrt PASSED [ 87%]\nsympy/core/tests/test_numbers.py::test_tribonacci_constant_rewrite_as_sqrt PASSED [ 88%]\nsympy/core/tests/test_numbers.py::test_comparisons_with_unknown_type PASSED [ 89%]\nsympy/core/tests/test_numbers.py::test_NumberSymbol_comparison PASSED    [ 90%]\nsympy/core/tests/test_numbers.py::test_Integer_precision PASSED          [ 91%]\nsympy/core/tests/test_numbers.py::test_numpy_to_float SKIPPED (numpy...) [ 92%]\nsympy/core/tests/test_numbers.py::test_Integer_ceiling_floor PASSED      [ 93%]\nsympy/core/tests/test_numbers.py::test_ComplexInfinity PASSED            [ 94%]\nsympy/core/tests/test_numbers.py::test_Infinity_floor_ceiling_power PASSED [ 95%]\nsympy/core/tests/test_numbers.py::test_One_power PASSED                  [ 96%]\nsympy/core/tests/test_numbers.py::test_NegativeInfinity PASSED           [ 97%]\nsympy/core/tests/test_numbers.py::test_issue_6133 PASSED                 [ 98%]\nsympy/core/tests/test_numbers.py::test_abc PASSED                        [ 99%]\nsympy/core/tests/test_numbers.py::test_floordiv PASSED                   [100%]\n\n=================================== FAILURES ===================================\n_____________________________ test_zero_not_false ______________________________\nsympy/core/tests/test_numbers.py:588: in test_zero_not_false\n    assert (S(0.0) == S.false) is False\nE   assert (0.0 == False) is False\nE    +  where 0.0 = S(0.0)\nE    +  and   False = S.false\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n======== 1 failed, 97 passed, 1 skipped, 1 xfailed, 1 warning in 5.01s =========\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/core/tests/test_numbers.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/core/tests/test_numbers.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 98,
          "failed": 0,
          "errors": 0,
          "collected": 100,
          "duration": 12.83,
          "log_tail": "sympy/core/tests/test_numbers.py::test_issue_4122 PASSED                 [ 62%]\nsympy/core/tests/test_numbers.py::test_GoldenRatio_expand PASSED         [ 63%]\nsympy/core/tests/test_numbers.py::test_TribonacciConstant_expand PASSED  [ 64%]\nsympy/core/tests/test_numbers.py::test_as_content_primitive PASSED       [ 65%]\nsympy/core/tests/test_numbers.py::test_hashing_sympy_integers PASSED     [ 66%]\nsympy/core/tests/test_numbers.py::test_rounding_issue_4172 PASSED        [ 67%]\nsympy/core/tests/test_numbers.py::test_mpmath_issues XFAIL               [ 68%]\nsympy/core/tests/test_numbers.py::test_Catalan_EulerGamma_prec PASSED    [ 69%]\nsympy/core/tests/test_numbers.py::test_Catalan_rewrite PASSED            [ 70%]\nsympy/core/tests/test_numbers.py::test_bool_eq PASSED                    [ 71%]\nsympy/core/tests/test_numbers.py::test_Float_eq PASSED                   [ 72%]\nsympy/core/tests/test_numbers.py::test_int_NumberSymbols PASSED          [ 73%]\nsympy/core/tests/test_numbers.py::test_issue_6640 PASSED                 [ 74%]\nsympy/core/tests/test_numbers.py::test_issue_6349 PASSED                 [ 75%]\nsympy/core/tests/test_numbers.py::test_mpf_norm PASSED                   [ 76%]\nsympy/core/tests/test_numbers.py::test_latex PASSED                      [ 77%]\nsympy/core/tests/test_numbers.py::test_issue_7742 PASSED                 [ 78%]\nsympy/core/tests/test_numbers.py::test_simplify_AlgebraicNumber PASSED   [ 79%]\nsympy/core/tests/test_numbers.py::test_Float_idempotence PASSED          [ 80%]\nsympy/core/tests/test_numbers.py::test_comp1 PASSED                      [ 81%]\nsympy/core/tests/test_numbers.py::test_issue_9491 PASSED                 [ 82%]\nsympy/core/tests/test_numbers.py::test_issue_10063 PASSED                [ 83%]\nsympy/core/tests/test_numbers.py::test_issue_10020 PASSED                [ 84%]\nsympy/core/tests/test_numbers.py::test_invert_numbers PASSED             [ 85%]\nsympy/core/tests/test_numbers.py::test_mod_inverse PASSED                [ 86%]\nsympy/core/tests/test_numbers.py::test_golden_ratio_rewrite_as_sqrt PASSED [ 87%]\nsympy/core/tests/test_numbers.py::test_tribonacci_constant_rewrite_as_sqrt PASSED [ 88%]\nsympy/core/tests/test_numbers.py::test_comparisons_with_unknown_type PASSED [ 89%]\nsympy/core/tests/test_numbers.py::test_NumberSymbol_comparison PASSED    [ 90%]\nsympy/core/tests/test_numbers.py::test_Integer_precision PASSED          [ 91%]\nsympy/core/tests/test_numbers.py::test_numpy_to_float SKIPPED (numpy...) [ 92%]\nsympy/core/tests/test_numbers.py::test_Integer_ceiling_floor PASSED      [ 93%]\nsympy/core/tests/test_numbers.py::test_ComplexInfinity PASSED            [ 94%]\nsympy/core/tests/test_numbers.py::test_Infinity_floor_ceiling_power PASSED [ 95%]\nsympy/core/tests/test_numbers.py::test_One_power PASSED                  [ 96%]\nsympy/core/tests/test_numbers.py::test_NegativeInfinity PASSED           [ 97%]\nsympy/core/tests/test_numbers.py::test_issue_6133 PASSED                 [ 98%]\nsympy/core/tests/test_numbers.py::test_abc PASSED                        [ 99%]\nsympy/core/tests/test_numbers.py::test_floordiv PASSED                   [100%]\n\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n============= 98 passed, 1 skipped, 1 xfailed, 1 warning in 4.12s ==============\n\n",
          "test_files_run": [
            "sympy/core/tests/test_numbers.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-20916",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 21.660319089889526,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 1,
          "failed": 1,
          "errors": 0,
          "collected": 3,
          "duration": 10.29,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 3 items\n\nsympy/printing/tests/test_conventions.py::test_super_sub FAILED          [ 33%]\nsympy/printing/tests/test_conventions.py::test_requires_partial PASSED   [ 66%]\nsympy/printing/tests/test_conventions.py::test_requires_partial_unspecified_variables XFAIL [100%]\n\n=================================== FAILURES ===================================\n________________________________ test_super_sub ________________________________\nsympy/printing/tests/test_conventions.py:35: in test_super_sub\n    assert split_super_sub(\"w\ud835\udfd9\") == (\"w\", [], [\"\ud835\udfd9\"])\nE   AssertionError: assert ('w\ud835\udfd9', [], []) == ('w', [], ['\ud835\udfd9'])\nE     \nE     At index 0 diff: 'w\ud835\udfd9' != 'w'\nE     \nE     Full diff:\nE       (\nE     -     'w',\nE     +     'w\ud835\udfd9',...\nE     \nE     ...Full output truncated (8 lines hidden), use '-vv' to show\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n============== 1 failed, 1 passed, 1 xfailed, 1 warning in 0.64s ===============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/printing/tests/test_conventions.py sympy/testing/quality_unicode.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/printing/tests/test_conventions.py",
            "sympy/testing/quality_unicode.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 2,
          "failed": 0,
          "errors": 0,
          "collected": 3,
          "duration": 9.79,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 3 items\n\nsympy/printing/tests/test_conventions.py::test_super_sub PASSED          [ 33%]\nsympy/printing/tests/test_conventions.py::test_requires_partial PASSED   [ 66%]\nsympy/printing/tests/test_conventions.py::test_requires_partial_unspecified_variables XFAIL [100%]\n\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=================== 2 passed, 1 xfailed, 1 warning in 0.46s ====================\n\n",
          "test_files_run": [
            "sympy/printing/tests/test_conventions.py",
            "sympy/testing/quality_unicode.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-21379",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 30.700609922409058,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 92,
          "failed": 1,
          "errors": 0,
          "collected": 95,
          "duration": 15.34,
          "log_tail": "sympy/core/tests/test_arit.py::test_Mul_does_not_cancel_infinities PASSED [ 90%]\nsympy/core/tests/test_arit.py::test_Mul_does_not_distribute_infinity PASSED [ 91%]\nsympy/core/tests/test_arit.py::test_issue_8247_8354 PASSED               [ 92%]\nsympy/core/tests/test_arit.py::test_Add_is_zero PASSED                   [ 93%]\nsympy/core/tests/test_arit.py::test_issue_14392 PASSED                   [ 94%]\nsympy/core/tests/test_arit.py::test_divmod PASSED                        [ 95%]\nsympy/core/tests/test_arit.py::test__neg__ PASSED                        [ 96%]\nsympy/core/tests/test_arit.py::test_issue_18507 PASSED                   [ 97%]\nsympy/core/tests/test_arit.py::test_issue_17130 PASSED                   [ 98%]\nsympy/core/tests/test_arit.py::test_issue_21034 PASSED                   [100%]\n\n=================================== FAILURES ===================================\n___________________________________ test_Mod ___________________________________\nsympy/core/tests/test_arit.py:1921: in test_Mod\n    (Piecewise((x_r, y_r > x_r), (y_r, True)) / z) % 1\nsympy/core/decorators.py:266: in _func\n    return func(self, other)\nsympy/core/decorators.py:136: in binary_op_wrapper\n    return func(self, other)\nsympy/core/expr.py:280: in __mod__\n    return Mod(self, other)\nsympy/core/cache.py:72: in wrapper\n    retval = cfunc(*args, **kwargs)\nsympy/core/function.py:473: in __new__\n    result = super().__new__(cls, *args, **options)\nsympy/core/cache.py:72: in wrapper\n    retval = cfunc(*args, **kwargs)\nsympy/core/function.py:285: in __new__\n    evaluated = cls.eval(*args)\nsympy/core/mod.py:169: in eval\n    G = gcd(p, q)\nsympy/polys/polytools.py:5306: in gcd\n    (F, G), opt = parallel_poly_from_expr((f, g), *gens, **args)\nsympy/polys/polytools.py:4340: in parallel_poly_from_expr\n    return _parallel_poly_from_expr(exprs, opt)\nsympy/polys/polytools.py:4399: in _parallel_poly_from_expr\n    raise PolynomialError(\"Piecewise generators do not make sense\")\nE   sympy.polys.polyerrors.PolynomialError: Piecewise generators do not make sense\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n============== 1 failed, 92 passed, 2 xfailed, 1 warning in 6.20s ==============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/core/tests/test_arit.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/core/tests/test_arit.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 93,
          "failed": 0,
          "errors": 0,
          "collected": 95,
          "duration": 14.07,
          "log_tail": "sympy/core/tests/test_arit.py::test_Pow_as_coeff_mul_doesnt_expand PASSED [ 60%]\nsympy/core/tests/test_arit.py::test_issue_3514_18626 PASSED              [ 61%]\nsympy/core/tests/test_arit.py::test_make_args PASSED                     [ 62%]\nsympy/core/tests/test_arit.py::test_issue_5126 PASSED                    [ 63%]\nsympy/core/tests/test_arit.py::test_Rational_as_content_primitive PASSED [ 64%]\nsympy/core/tests/test_arit.py::test_Add_as_content_primitive PASSED      [ 65%]\nsympy/core/tests/test_arit.py::test_Mul_as_content_primitive PASSED      [ 66%]\nsympy/core/tests/test_arit.py::test_Pow_as_content_primitive PASSED      [ 67%]\nsympy/core/tests/test_arit.py::test_issue_5460 PASSED                    [ 68%]\nsympy/core/tests/test_arit.py::test_product_irrational PASSED            [ 69%]\nsympy/core/tests/test_arit.py::test_issue_5919 PASSED                    [ 70%]\nsympy/core/tests/test_arit.py::test_Mod PASSED                           [ 71%]\nsympy/core/tests/test_arit.py::test_Mod_Pow PASSED                       [ 72%]\nsympy/core/tests/test_arit.py::test_Mod_is_integer PASSED                [ 73%]\nsympy/core/tests/test_arit.py::test_Mod_is_nonposneg PASSED              [ 74%]\nsympy/core/tests/test_arit.py::test_issue_6001 PASSED                    [ 75%]\nsympy/core/tests/test_arit.py::test_polar PASSED                         [ 76%]\nsympy/core/tests/test_arit.py::test_issue_6040 PASSED                    [ 77%]\nsympy/core/tests/test_arit.py::test_issue_6082 PASSED                    [ 78%]\nsympy/core/tests/test_arit.py::test_issue_6077 PASSED                    [ 80%]\nsympy/core/tests/test_arit.py::test_mul_flatten_oo PASSED                [ 81%]\nsympy/core/tests/test_arit.py::test_add_flatten PASSED                   [ 82%]\nsympy/core/tests/test_arit.py::test_issue_5160_6087_6089_6090 PASSED     [ 83%]\nsympy/core/tests/test_arit.py::test_float_int_round PASSED               [ 84%]\nsympy/core/tests/test_arit.py::test_issue_6611a PASSED                   [ 85%]\nsympy/core/tests/test_arit.py::test_denest_add_mul PASSED                [ 86%]\nsympy/core/tests/test_arit.py::test_mul_coeff PASSED                     [ 87%]\nsympy/core/tests/test_arit.py::test_mul_zero_detection PASSED            [ 88%]\nsympy/core/tests/test_arit.py::test_Mul_with_zero_infinite PASSED        [ 89%]\nsympy/core/tests/test_arit.py::test_Mul_does_not_cancel_infinities PASSED [ 90%]\nsympy/core/tests/test_arit.py::test_Mul_does_not_distribute_infinity PASSED [ 91%]\nsympy/core/tests/test_arit.py::test_issue_8247_8354 PASSED               [ 92%]\nsympy/core/tests/test_arit.py::test_Add_is_zero PASSED                   [ 93%]\nsympy/core/tests/test_arit.py::test_issue_14392 PASSED                   [ 94%]\nsympy/core/tests/test_arit.py::test_divmod PASSED                        [ 95%]\nsympy/core/tests/test_arit.py::test__neg__ PASSED                        [ 96%]\nsympy/core/tests/test_arit.py::test_issue_18507 PASSED                   [ 97%]\nsympy/core/tests/test_arit.py::test_issue_17130 PASSED                   [ 98%]\nsympy/core/tests/test_arit.py::test_issue_21034 PASSED                   [100%]\n\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=================== 93 passed, 2 xfailed, 1 warning in 5.23s ===================\n\n",
          "test_files_run": [
            "sympy/core/tests/test_arit.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-21596",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 29.51395297050476,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 47,
          "failed": 1,
          "errors": 0,
          "collected": 49,
          "duration": 14.93,
          "log_tail": "sympy/sets/tests/test_fancysets.py::test_imageset_intersect_real FAILED  [ 44%]\nsympy/sets/tests/test_fancysets.py::test_imageset_intersect_interval PASSED [ 46%]\nsympy/sets/tests/test_fancysets.py::test_imageset_intersect_diophantine PASSED [ 48%]\nsympy/sets/tests/test_fancysets.py::test_infinitely_indexed_set_3 PASSED [ 51%]\nsympy/sets/tests/test_fancysets.py::test_ImageSet_simplification PASSED  [ 53%]\nsympy/sets/tests/test_fancysets.py::test_ImageSet_contains PASSED        [ 55%]\nsympy/sets/tests/test_fancysets.py::test_ComplexRegion_contains PASSED   [ 57%]\nsympy/sets/tests/test_fancysets.py::test_ComplexRegion_intersect PASSED  [ 59%]\nsympy/sets/tests/test_fancysets.py::test_ComplexRegion_union PASSED      [ 61%]\nsympy/sets/tests/test_fancysets.py::test_ComplexRegion_from_real PASSED  [ 63%]\nsympy/sets/tests/test_fancysets.py::test_ComplexRegion_measure PASSED    [ 65%]\nsympy/sets/tests/test_fancysets.py::test_normalize_theta_set PASSED      [ 67%]\nsympy/sets/tests/test_fancysets.py::test_ComplexRegion_FiniteSet PASSED  [ 69%]\nsympy/sets/tests/test_fancysets.py::test_union_RealSubSet PASSED         [ 71%]\nsympy/sets/tests/test_fancysets.py::test_issue_9980 PASSED               [ 73%]\nsympy/sets/tests/test_fancysets.py::test_issue_11732 PASSED              [ 75%]\nsympy/sets/tests/test_fancysets.py::test_issue_11730 PASSED              [ 77%]\nsympy/sets/tests/test_fancysets.py::test_issue_11938 PASSED              [ 79%]\nsympy/sets/tests/test_fancysets.py::test_issue_11914 PASSED              [ 81%]\nsympy/sets/tests/test_fancysets.py::test_issue_9543 PASSED               [ 83%]\nsympy/sets/tests/test_fancysets.py::test_issue_16871 PASSED              [ 85%]\nsympy/sets/tests/test_fancysets.py::test_issue_16871b XFAIL              [ 87%]\nsympy/sets/tests/test_fancysets.py::test_issue_18050 PASSED              [ 89%]\nsympy/sets/tests/test_fancysets.py::test_Rationals PASSED                [ 91%]\nsympy/sets/tests/test_fancysets.py::test_NZQRC_unions PASSED             [ 93%]\nsympy/sets/tests/test_fancysets.py::test_imageset_intersection PASSED    [ 95%]\nsympy/sets/tests/test_fancysets.py::test_issue_17858 PASSED              [ 97%]\nsympy/sets/tests/test_fancysets.py::test_issue_17859 PASSED              [100%]\n\n=================================== FAILURES ===================================\n_________________________ test_imageset_intersect_real _________________________\nsympy/sets/tests/test_fancysets.py:661: in test_imageset_intersect_real\n    assert imageset(Lambda(n, n + (n - 1)*(n + 1)*I), S.Integers).intersect(S.Reals) == FiniteSet(-1, 1)\nE   assert Complement(In...eSet((-1, 1))) == FiniteSet(-1, 1)\nE     \nE     Full diff:\nE     - FiniteSet(-1, 1)\nE     + Complement(Integers, FiniteSet((-1, 1)))\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n============== 1 failed, 47 passed, 1 xfailed, 1 warning in 5.28s ==============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/sets/tests/test_fancysets.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/sets/tests/test_fancysets.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 48,
          "failed": 0,
          "errors": 0,
          "collected": 49,
          "duration": 13.33,
          "log_tail": "sympy/sets/tests/test_fancysets.py::test_range_range_intersection PASSED [ 22%]\nsympy/sets/tests/test_fancysets.py::test_range_interval_intersection PASSED [ 24%]\nsympy/sets/tests/test_fancysets.py::test_range_is_finite_set PASSED      [ 26%]\nsympy/sets/tests/test_fancysets.py::test_Integers_eval_imageset PASSED   [ 28%]\nsympy/sets/tests/test_fancysets.py::test_Range_eval_imageset PASSED      [ 30%]\nsympy/sets/tests/test_fancysets.py::test_fun PASSED                      [ 32%]\nsympy/sets/tests/test_fancysets.py::test_Reals PASSED                    [ 34%]\nsympy/sets/tests/test_fancysets.py::test_Complex PASSED                  [ 36%]\nsympy/sets/tests/test_fancysets.py::test_intersections PASSED            [ 38%]\nsympy/sets/tests/test_fancysets.py::test_infinitely_indexed_set_1 PASSED [ 40%]\nsympy/sets/tests/test_fancysets.py::test_infinitely_indexed_set_2 PASSED [ 42%]\nsympy/sets/tests/test_fancysets.py::test_imageset_intersect_real PASSED  [ 44%]\nsympy/sets/tests/test_fancysets.py::test_imageset_intersect_interval PASSED [ 46%]\nsympy/sets/tests/test_fancysets.py::test_imageset_intersect_diophantine PASSED [ 48%]\nsympy/sets/tests/test_fancysets.py::test_infinitely_indexed_set_3 PASSED [ 51%]\nsympy/sets/tests/test_fancysets.py::test_ImageSet_simplification PASSED  [ 53%]\nsympy/sets/tests/test_fancysets.py::test_ImageSet_contains PASSED        [ 55%]\nsympy/sets/tests/test_fancysets.py::test_ComplexRegion_contains PASSED   [ 57%]\nsympy/sets/tests/test_fancysets.py::test_ComplexRegion_intersect PASSED  [ 59%]\nsympy/sets/tests/test_fancysets.py::test_ComplexRegion_union PASSED      [ 61%]\nsympy/sets/tests/test_fancysets.py::test_ComplexRegion_from_real PASSED  [ 63%]\nsympy/sets/tests/test_fancysets.py::test_ComplexRegion_measure PASSED    [ 65%]\nsympy/sets/tests/test_fancysets.py::test_normalize_theta_set PASSED      [ 67%]\nsympy/sets/tests/test_fancysets.py::test_ComplexRegion_FiniteSet PASSED  [ 69%]\nsympy/sets/tests/test_fancysets.py::test_union_RealSubSet PASSED         [ 71%]\nsympy/sets/tests/test_fancysets.py::test_issue_9980 PASSED               [ 73%]\nsympy/sets/tests/test_fancysets.py::test_issue_11732 PASSED              [ 75%]\nsympy/sets/tests/test_fancysets.py::test_issue_11730 PASSED              [ 77%]\nsympy/sets/tests/test_fancysets.py::test_issue_11938 PASSED              [ 79%]\nsympy/sets/tests/test_fancysets.py::test_issue_11914 PASSED              [ 81%]\nsympy/sets/tests/test_fancysets.py::test_issue_9543 PASSED               [ 83%]\nsympy/sets/tests/test_fancysets.py::test_issue_16871 PASSED              [ 85%]\nsympy/sets/tests/test_fancysets.py::test_issue_16871b XFAIL              [ 87%]\nsympy/sets/tests/test_fancysets.py::test_issue_18050 PASSED              [ 89%]\nsympy/sets/tests/test_fancysets.py::test_Rationals PASSED                [ 91%]\nsympy/sets/tests/test_fancysets.py::test_NZQRC_unions PASSED             [ 93%]\nsympy/sets/tests/test_fancysets.py::test_imageset_intersection PASSED    [ 95%]\nsympy/sets/tests/test_fancysets.py::test_issue_17858 PASSED              [ 97%]\nsympy/sets/tests/test_fancysets.py::test_issue_17859 PASSED              [100%]\n\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=================== 48 passed, 1 xfailed, 1 warning in 4.37s ===================\n\n",
          "test_files_run": [
            "sympy/sets/tests/test_fancysets.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-21612",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 23.84648585319519,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 99,
          "failed": 1,
          "errors": 0,
          "collected": 100,
          "duration": 12.1,
          "log_tail": "sympy/printing/tests/test_str.py::test_FiniteSet PASSED                  [ 73%]\nsympy/printing/tests/test_str.py::test_UniversalSet PASSED               [ 74%]\nsympy/printing/tests/test_str.py::test_PrettyPoly PASSED                 [ 75%]\nsympy/printing/tests/test_str.py::test_categories PASSED                 [ 76%]\nsympy/printing/tests/test_str.py::test_Tr PASSED                         [ 77%]\nsympy/printing/tests/test_str.py::test_issue_6387 PASSED                 [ 78%]\nsympy/printing/tests/test_str.py::test_MatMul_MatAdd PASSED              [ 79%]\nsympy/printing/tests/test_str.py::test_MatrixSlice PASSED                [ 80%]\nsympy/printing/tests/test_str.py::test_true_false PASSED                 [ 81%]\nsympy/printing/tests/test_str.py::test_Equivalent PASSED                 [ 82%]\nsympy/printing/tests/test_str.py::test_Xor PASSED                        [ 83%]\nsympy/printing/tests/test_str.py::test_Complement PASSED                 [ 84%]\nsympy/printing/tests/test_str.py::test_SymmetricDifference PASSED        [ 85%]\nsympy/printing/tests/test_str.py::test_UnevaluatedExpr PASSED            [ 86%]\nsympy/printing/tests/test_str.py::test_MatrixElement_printing PASSED     [ 87%]\nsympy/printing/tests/test_str.py::test_MatrixSymbol_printing PASSED      [ 88%]\nsympy/printing/tests/test_str.py::test_MatrixExpressions PASSED          [ 89%]\nsympy/printing/tests/test_str.py::test_Subs_printing PASSED              [ 90%]\nsympy/printing/tests/test_str.py::test_issue_15716 PASSED                [ 91%]\nsympy/printing/tests/test_str.py::test_str_special_matrices PASSED       [ 92%]\nsympy/printing/tests/test_str.py::test_issue_14567 PASSED                [ 93%]\nsympy/printing/tests/test_str.py::test_issue_21119_21460 PASSED          [ 94%]\nsympy/printing/tests/test_str.py::test_Str PASSED                        [ 95%]\nsympy/printing/tests/test_str.py::test_diffgeom PASSED                   [ 96%]\nsympy/printing/tests/test_str.py::test_NDimArray PASSED                  [ 97%]\nsympy/printing/tests/test_str.py::test_Predicate PASSED                  [ 98%]\nsympy/printing/tests/test_str.py::test_AppliedPredicate PASSED           [ 99%]\nsympy/printing/tests/test_str.py::test_printing_str_array_expressions PASSED [100%]\n\n=================================== FAILURES ===================================\n___________________________________ test_Mul ___________________________________\nsympy/printing/tests/test_str.py:256: in test_Mul\n    assert str(Mul(x, Pow(1/y, -1, evaluate=False), evaluate=False)) == 'x/(1/y)'\nE   AssertionError: assert 'x/1/y' == 'x/(1/y)'\nE     \nE     - x/(1/y)\nE     ?   -   -\nE     + x/1/y\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 1 failed, 99 passed, 1 warning in 2.31s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/printing/tests/test_str.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/printing/tests/test_str.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 100,
          "failed": 0,
          "errors": 0,
          "collected": 100,
          "duration": 10.36,
          "log_tail": "sympy/printing/tests/test_str.py::test_zeta PASSED                       [ 62%]\nsympy/printing/tests/test_str.py::test_issue_3101 PASSED                 [ 63%]\nsympy/printing/tests/test_str.py::test_issue_3103 PASSED                 [ 64%]\nsympy/printing/tests/test_str.py::test_issue_4021 PASSED                 [ 65%]\nsympy/printing/tests/test_str.py::test_sstrrepr PASSED                   [ 66%]\nsympy/printing/tests/test_str.py::test_infinity PASSED                   [ 67%]\nsympy/printing/tests/test_str.py::test_full_prec PASSED                  [ 68%]\nsympy/printing/tests/test_str.py::test_noncommutative PASSED             [ 69%]\nsympy/printing/tests/test_str.py::test_empty_printer PASSED              [ 70%]\nsympy/printing/tests/test_str.py::test_settings PASSED                   [ 71%]\nsympy/printing/tests/test_str.py::test_RandomDomain PASSED               [ 72%]\nsympy/printing/tests/test_str.py::test_FiniteSet PASSED                  [ 73%]\nsympy/printing/tests/test_str.py::test_UniversalSet PASSED               [ 74%]\nsympy/printing/tests/test_str.py::test_PrettyPoly PASSED                 [ 75%]\nsympy/printing/tests/test_str.py::test_categories PASSED                 [ 76%]\nsympy/printing/tests/test_str.py::test_Tr PASSED                         [ 77%]\nsympy/printing/tests/test_str.py::test_issue_6387 PASSED                 [ 78%]\nsympy/printing/tests/test_str.py::test_MatMul_MatAdd PASSED              [ 79%]\nsympy/printing/tests/test_str.py::test_MatrixSlice PASSED                [ 80%]\nsympy/printing/tests/test_str.py::test_true_false PASSED                 [ 81%]\nsympy/printing/tests/test_str.py::test_Equivalent PASSED                 [ 82%]\nsympy/printing/tests/test_str.py::test_Xor PASSED                        [ 83%]\nsympy/printing/tests/test_str.py::test_Complement PASSED                 [ 84%]\nsympy/printing/tests/test_str.py::test_SymmetricDifference PASSED        [ 85%]\nsympy/printing/tests/test_str.py::test_UnevaluatedExpr PASSED            [ 86%]\nsympy/printing/tests/test_str.py::test_MatrixElement_printing PASSED     [ 87%]\nsympy/printing/tests/test_str.py::test_MatrixSymbol_printing PASSED      [ 88%]\nsympy/printing/tests/test_str.py::test_MatrixExpressions PASSED          [ 89%]\nsympy/printing/tests/test_str.py::test_Subs_printing PASSED              [ 90%]\nsympy/printing/tests/test_str.py::test_issue_15716 PASSED                [ 91%]\nsympy/printing/tests/test_str.py::test_str_special_matrices PASSED       [ 92%]\nsympy/printing/tests/test_str.py::test_issue_14567 PASSED                [ 93%]\nsympy/printing/tests/test_str.py::test_issue_21119_21460 PASSED          [ 94%]\nsympy/printing/tests/test_str.py::test_Str PASSED                        [ 95%]\nsympy/printing/tests/test_str.py::test_diffgeom PASSED                   [ 96%]\nsympy/printing/tests/test_str.py::test_NDimArray PASSED                  [ 97%]\nsympy/printing/tests/test_str.py::test_Predicate PASSED                  [ 98%]\nsympy/printing/tests/test_str.py::test_AppliedPredicate PASSED           [ 99%]\nsympy/printing/tests/test_str.py::test_printing_str_array_expressions PASSED [100%]\n\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================== 100 passed, 1 warning in 1.68s ========================\n\n",
          "test_files_run": [
            "sympy/printing/tests/test_str.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-21847",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 20.497509241104126,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 10,
          "failed": 1,
          "errors": 0,
          "collected": 11,
          "duration": 10.1,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 11 items\n\nsympy/polys/tests/test_monomials.py::test_monomials FAILED               [  9%]\nsympy/polys/tests/test_monomials.py::test_monomial_count PASSED          [ 18%]\nsympy/polys/tests/test_monomials.py::test_monomial_mul PASSED            [ 27%]\nsympy/polys/tests/test_monomials.py::test_monomial_div PASSED            [ 36%]\nsympy/polys/tests/test_monomials.py::test_monomial_gcd PASSED            [ 45%]\nsympy/polys/tests/test_monomials.py::test_monomial_lcm PASSED            [ 54%]\nsympy/polys/tests/test_monomials.py::test_monomial_max PASSED            [ 63%]\nsympy/polys/tests/test_monomials.py::test_monomial_pow PASSED            [ 72%]\nsympy/polys/tests/test_monomials.py::test_monomial_min PASSED            [ 81%]\nsympy/polys/tests/test_monomials.py::test_monomial_divides PASSED        [ 90%]\nsympy/polys/tests/test_monomials.py::test_Monomial PASSED                [100%]\n\n=================================== FAILURES ===================================\n________________________________ test_monomials ________________________________\nsympy/polys/tests/test_monomials.py:116: in test_monomials\n    assert set(itermonomials([x, y], 3, 3)) == {x**3, x**2*y, x*y**2, y**3}\nE   assert {y**3, x**3} == {x**2*y, y**3, x**3, x*y**2}\nE     \nE     (pytest_assertion plugin: representation of details failed: /testbed/sympy/core/relational.py:398: TypeError: cannot determine truth value of Relational.\nE      Probably an object has a faulty __repr__.)\n                                DO *NOT* COMMIT!                                \n========================= 1 failed, 10 passed in 0.83s =========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/polys/tests/test_monomials.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/polys/tests/test_monomials.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 11,
          "failed": 0,
          "errors": 0,
          "collected": 11,
          "duration": 9.11,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 11 items\n\nsympy/polys/tests/test_monomials.py::test_monomials PASSED               [  9%]\nsympy/polys/tests/test_monomials.py::test_monomial_count PASSED          [ 18%]\nsympy/polys/tests/test_monomials.py::test_monomial_mul PASSED            [ 27%]\nsympy/polys/tests/test_monomials.py::test_monomial_div PASSED            [ 36%]\nsympy/polys/tests/test_monomials.py::test_monomial_gcd PASSED            [ 45%]\nsympy/polys/tests/test_monomials.py::test_monomial_lcm PASSED            [ 54%]\nsympy/polys/tests/test_monomials.py::test_monomial_max PASSED            [ 63%]\nsympy/polys/tests/test_monomials.py::test_monomial_pow PASSED            [ 72%]\nsympy/polys/tests/test_monomials.py::test_monomial_min PASSED            [ 81%]\nsympy/polys/tests/test_monomials.py::test_monomial_divides PASSED        [ 90%]\nsympy/polys/tests/test_monomials.py::test_Monomial PASSED                [100%]\n\n============================== 11 passed in 0.40s ==============================\n\n",
          "test_files_run": [
            "sympy/polys/tests/test_monomials.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-21930",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://35.239.238.137:8080",
      "error": "HTTPConnectionPool(host='35.239.238.137', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "sympy__sympy-22080",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 24.04735016822815,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 94,
          "failed": 3,
          "errors": 0,
          "collected": 151,
          "duration": 12.29,
          "log_tail": "sympy/utilities/tests/test_lambdify.py::test_issue_14941 PASSED          [ 86%]\nsympy/utilities/tests/test_lambdify.py::test_lambdify_Derivative_arg_issue_16468 PASSED [ 86%]\nsympy/utilities/tests/test_lambdify.py::test_imag_real PASSED            [ 87%]\nsympy/utilities/tests/test_lambdify.py::test_MatrixSymbol_issue_15578 SKIPPED [ 88%]\nsympy/utilities/tests/test_lambdify.py::test_issue_15654 SKIPPED (sc...) [ 88%]\nsympy/utilities/tests/test_lambdify.py::test_issue_15827 SKIPPED (nu...) [ 89%]\nsympy/utilities/tests/test_lambdify.py::test_issue_16930 SKIPPED (sc...) [ 90%]\nsympy/utilities/tests/test_lambdify.py::test_issue_17898 SKIPPED (sc...) [ 90%]\nsympy/utilities/tests/test_lambdify.py::test_issue_13167_21411 SKIPPED   [ 91%]\nsympy/utilities/tests/test_lambdify.py::test_single_e PASSED             [ 92%]\nsympy/utilities/tests/test_lambdify.py::test_issue_16536 SKIPPED (sc...) [ 92%]\nsympy/utilities/tests/test_lambdify.py::test_fresnel_integrals_scipy SKIPPED [ 93%]\nsympy/utilities/tests/test_lambdify.py::test_beta_scipy SKIPPED (sci...) [ 94%]\nsympy/utilities/tests/test_lambdify.py::test_beta_math PASSED            [ 94%]\nsympy/utilities/tests/test_lambdify.py::test_betainc_scipy SKIPPED (...) [ 95%]\nsympy/utilities/tests/test_lambdify.py::test_betainc_regularized_scipy SKIPPED [ 96%]\nsympy/utilities/tests/test_lambdify.py::test_numpy_special_math SKIPPED  [ 96%]\nsympy/utilities/tests/test_lambdify.py::test_scipy_special_math SKIPPED  [ 97%]\nsympy/utilities/tests/test_lambdify.py::test_cupy_array_arg SKIPPED      [ 98%]\nsympy/utilities/tests/test_lambdify.py::test_cupy_array_arg_using_numpy SKIPPED [ 98%]\nsympy/utilities/tests/test_lambdify.py::test_cupy_dotproduct SKIPPED     [ 99%]\nsympy/utilities/tests/test_lambdify.py::test_lambdify_cse PASSED         [100%]\n\n=================================== FAILURES ===================================\n_____________________ test_create_expand_pow_optimization ______________________\nsympy/codegen/tests/test_rewriting.py:269: in test_create_expand_pow_optimization\n    assert cc(-x**4) == '-(x*x*x*x)'\nE   AssertionError: assert '-x*x*x*x' == '-(x*x*x*x)'\nE     \nE     - -(x*x*x*x)\nE     ?  -       -\nE     + -x*x*x*x\n____________________________ test_PythonCodePrinter ____________________________\nsympy/printing/tests/test_pycode.py:33: in test_PythonCodePrinter\n    assert prntr.doprint(-Mod(x, y)) == '-(x % y)'\nE   AssertionError: assert '-x % y' == '-(x % y)'\nE     \nE     - -(x % y)\nE     ?  -     -\nE     + -x % y\n______________________________ test_empty_modules ______________________________\nsympy/utilities/tests/test_lambdify.py:275: in test_empty_modules\n    assert no_modules(3, 7) == -3\nE   assert 4 == -3\nE    +  where 4 = <function _lambdifygenerated at 0x712f809951f0>(3, 7)\n                                DO *NOT* COMMIT!                                \n============= 3 failed, 94 passed, 53 skipped, 1 xfailed in 3.18s ==============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/codegen/tests/test_rewriting.py sympy/printing/tests/test_pycode.py sympy/utilities/tests/test_lambdify.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/codegen/tests/test_rewriting.py",
            "sympy/printing/tests/test_pycode.py",
            "sympy/utilities/tests/test_lambdify.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 97,
          "failed": 0,
          "errors": 0,
          "collected": 151,
          "duration": 10.66,
          "log_tail": "sympy/utilities/tests/test_lambdify.py::test_imps_errors PASSED          [ 70%]\nsympy/utilities/tests/test_lambdify.py::test_imps_wrong_args PASSED      [ 70%]\nsympy/utilities/tests/test_lambdify.py::test_lambdify_imps PASSED        [ 71%]\nsympy/utilities/tests/test_lambdify.py::test_dummification PASSED        [ 72%]\nsympy/utilities/tests/test_lambdify.py::test_curly_matrix_symbol PASSED  [ 72%]\nsympy/utilities/tests/test_lambdify.py::test_python_keywords PASSED      [ 73%]\nsympy/utilities/tests/test_lambdify.py::test_lambdify_docstring PASSED   [ 74%]\nsympy/utilities/tests/test_lambdify.py::test_special_printers PASSED     [ 74%]\nsympy/utilities/tests/test_lambdify.py::test_true_false PASSED           [ 75%]\nsympy/utilities/tests/test_lambdify.py::test_issue_2790 PASSED           [ 76%]\nsympy/utilities/tests/test_lambdify.py::test_issue_12092 PASSED          [ 76%]\nsympy/utilities/tests/test_lambdify.py::test_issue_14911 PASSED          [ 77%]\nsympy/utilities/tests/test_lambdify.py::test_ITE PASSED                  [ 78%]\nsympy/utilities/tests/test_lambdify.py::test_Min_Max PASSED              [ 78%]\nsympy/utilities/tests/test_lambdify.py::test_Indexed SKIPPED (numpy ...) [ 79%]\nsympy/utilities/tests/test_lambdify.py::test_issue_12173 PASSED          [ 80%]\nsympy/utilities/tests/test_lambdify.py::test_issue_13642 SKIPPED (nu...) [ 80%]\nsympy/utilities/tests/test_lambdify.py::test_sinc_mpmath PASSED          [ 81%]\nsympy/utilities/tests/test_lambdify.py::test_lambdify_dummy_arg PASSED   [ 82%]\nsympy/utilities/tests/test_lambdify.py::test_lambdify_mixed_symbol_dummy_args PASSED [ 82%]\nsympy/utilities/tests/test_lambdify.py::test_numpy_array_arg SKIPPED     [ 83%]\nsympy/utilities/tests/test_lambdify.py::test_scipy_fns SKIPPED (scip...) [ 84%]\nsympy/utilities/tests/test_lambdify.py::test_scipy_polys SKIPPED (sc...) [ 84%]\nsympy/utilities/tests/test_lambdify.py::test_lambdify_inspect PASSED     [ 85%]\nsympy/utilities/tests/test_lambdify.py::test_issue_14941 PASSED          [ 86%]\nsympy/utilities/tests/test_lambdify.py::test_lambdify_Derivative_arg_issue_16468 PASSED [ 86%]\nsympy/utilities/tests/test_lambdify.py::test_imag_real PASSED            [ 87%]\nsympy/utilities/tests/test_lambdify.py::test_MatrixSymbol_issue_15578 SKIPPED [ 88%]\nsympy/utilities/tests/test_lambdify.py::test_issue_15654 SKIPPED (sc...) [ 88%]\nsympy/utilities/tests/test_lambdify.py::test_issue_15827 SKIPPED (nu...) [ 89%]\nsympy/utilities/tests/test_lambdify.py::test_issue_16930 SKIPPED (sc...) [ 90%]\nsympy/utilities/tests/test_lambdify.py::test_issue_17898 SKIPPED (sc...) [ 90%]\nsympy/utilities/tests/test_lambdify.py::test_issue_13167_21411 SKIPPED   [ 91%]\nsympy/utilities/tests/test_lambdify.py::test_single_e PASSED             [ 92%]\nsympy/utilities/tests/test_lambdify.py::test_issue_16536 SKIPPED (sc...) [ 92%]\nsympy/utilities/tests/test_lambdify.py::test_fresnel_integrals_scipy SKIPPED [ 93%]\nsympy/utilities/tests/test_lambdify.py::test_beta_scipy SKIPPED (sci...) [ 94%]\nsympy/utilities/tests/test_lambdify.py::test_beta_math PASSED            [ 94%]\nsympy/utilities/tests/test_lambdify.py::test_betainc_scipy SKIPPED (...) [ 95%]\nsympy/utilities/tests/test_lambdify.py::test_betainc_regularized_scipy SKIPPED [ 96%]\nsympy/utilities/tests/test_lambdify.py::test_numpy_special_math SKIPPED  [ 96%]\nsympy/utilities/tests/test_lambdify.py::test_scipy_special_math SKIPPED  [ 97%]\nsympy/utilities/tests/test_lambdify.py::test_cupy_array_arg SKIPPED      [ 98%]\nsympy/utilities/tests/test_lambdify.py::test_cupy_array_arg_using_numpy SKIPPED [ 98%]\nsympy/utilities/tests/test_lambdify.py::test_cupy_dotproduct SKIPPED     [ 99%]\nsympy/utilities/tests/test_lambdify.py::test_lambdify_cse PASSED         [100%]\n\n================== 97 passed, 53 skipped, 1 xfailed in 2.34s ===================\n\n",
          "test_files_run": [
            "sympy/codegen/tests/test_rewriting.py",
            "sympy/printing/tests/test_pycode.py",
            "sympy/utilities/tests/test_lambdify.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-22456",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 20.088128089904785,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 30,
          "failed": 1,
          "errors": 0,
          "collected": 31,
          "duration": 9.78,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 31 items\n\nsympy/codegen/tests/test_ast.py::test_Assignment PASSED                  [  3%]\nsympy/codegen/tests/test_ast.py::test_AugAssign PASSED                   [  6%]\nsympy/codegen/tests/test_ast.py::test_Assignment_printing PASSED         [  9%]\nsympy/codegen/tests/test_ast.py::test_CodeBlock PASSED                   [ 12%]\nsympy/codegen/tests/test_ast.py::test_CodeBlock_topological_sort PASSED  [ 16%]\nsympy/codegen/tests/test_ast.py::test_CodeBlock_free_symbols PASSED      [ 19%]\nsympy/codegen/tests/test_ast.py::test_CodeBlock_cse PASSED               [ 22%]\nsympy/codegen/tests/test_ast.py::test_CodeBlock_cse__issue_14118 PASSED  [ 25%]\nsympy/codegen/tests/test_ast.py::test_For PASSED                         [ 29%]\nsympy/codegen/tests/test_ast.py::test_none PASSED                        [ 32%]\nsympy/codegen/tests/test_ast.py::test_String FAILED                      [ 35%]\nsympy/codegen/tests/test_ast.py::test_Comment PASSED                     [ 38%]\nsympy/codegen/tests/test_ast.py::test_Node PASSED                        [ 41%]\nsympy/codegen/tests/test_ast.py::test_Type PASSED                        [ 45%]\nsympy/codegen/tests/test_ast.py::test_Type__from_expr PASSED             [ 48%]\nsympy/codegen/tests/test_ast.py::test_Type__cast_check__integers PASSED  [ 51%]\nsympy/codegen/tests/test_ast.py::test_Attribute PASSED                   [ 54%]\nsympy/codegen/tests/test_ast.py::test_Variable PASSED                    [ 58%]\nsympy/codegen/tests/test_ast.py::test_Pointer PASSED                     [ 61%]\nsympy/codegen/tests/test_ast.py::test_Declaration PASSED                 [ 64%]\nsympy/codegen/tests/test_ast.py::test_IntBaseType PASSED                 [ 67%]\nsympy/codegen/tests/test_ast.py::test_FloatType PASSED                   [ 70%]\nsympy/codegen/tests/test_ast.py::test_Type__cast_check__floating_point PASSED [ 74%]\nsympy/codegen/tests/test_ast.py::test_Type__cast_check__complex_floating_point PASSED [ 77%]\nsympy/codegen/tests/test_ast.py::test_While PASSED                       [ 80%]\nsympy/codegen/tests/test_ast.py::test_Scope PASSED                       [ 83%]\nsympy/codegen/tests/test_ast.py::test_Print PASSED                       [ 87%]\nsympy/codegen/tests/test_ast.py::test_FunctionPrototype_and_FunctionDefinition PASSED [ 90%]\nsympy/codegen/tests/test_ast.py::test_Return PASSED                      [ 93%]\nsympy/codegen/tests/test_ast.py::test_FunctionCall PASSED                [ 96%]\nsympy/codegen/tests/test_ast.py::test_ast_replace PASSED                 [100%]\n\n=================================== FAILURES ===================================\n_________________________________ test_String __________________________________\nsympy/codegen/tests/test_ast.py:270: in test_String\n    assert st.func(*st.args) == st\nsympy/codegen/ast.py:237: in __new__\n    raise TypeError('No value for %r given and attribute has no default' % attrname)\nE   TypeError: No value for 'text' given and attribute has no default\n                                DO *NOT* COMMIT!                                \n========================= 1 failed, 30 passed in 0.81s =========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/codegen/tests/test_ast.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/codegen/tests/test_ast.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 31,
          "failed": 0,
          "errors": 0,
          "collected": 31,
          "duration": 9.18,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 31 items\n\nsympy/codegen/tests/test_ast.py::test_Assignment PASSED                  [  3%]\nsympy/codegen/tests/test_ast.py::test_AugAssign PASSED                   [  6%]\nsympy/codegen/tests/test_ast.py::test_Assignment_printing PASSED         [  9%]\nsympy/codegen/tests/test_ast.py::test_CodeBlock PASSED                   [ 12%]\nsympy/codegen/tests/test_ast.py::test_CodeBlock_topological_sort PASSED  [ 16%]\nsympy/codegen/tests/test_ast.py::test_CodeBlock_free_symbols PASSED      [ 19%]\nsympy/codegen/tests/test_ast.py::test_CodeBlock_cse PASSED               [ 22%]\nsympy/codegen/tests/test_ast.py::test_CodeBlock_cse__issue_14118 PASSED  [ 25%]\nsympy/codegen/tests/test_ast.py::test_For PASSED                         [ 29%]\nsympy/codegen/tests/test_ast.py::test_none PASSED                        [ 32%]\nsympy/codegen/tests/test_ast.py::test_String PASSED                      [ 35%]\nsympy/codegen/tests/test_ast.py::test_Comment PASSED                     [ 38%]\nsympy/codegen/tests/test_ast.py::test_Node PASSED                        [ 41%]\nsympy/codegen/tests/test_ast.py::test_Type PASSED                        [ 45%]\nsympy/codegen/tests/test_ast.py::test_Type__from_expr PASSED             [ 48%]\nsympy/codegen/tests/test_ast.py::test_Type__cast_check__integers PASSED  [ 51%]\nsympy/codegen/tests/test_ast.py::test_Attribute PASSED                   [ 54%]\nsympy/codegen/tests/test_ast.py::test_Variable PASSED                    [ 58%]\nsympy/codegen/tests/test_ast.py::test_Pointer PASSED                     [ 61%]\nsympy/codegen/tests/test_ast.py::test_Declaration PASSED                 [ 64%]\nsympy/codegen/tests/test_ast.py::test_IntBaseType PASSED                 [ 67%]\nsympy/codegen/tests/test_ast.py::test_FloatType PASSED                   [ 70%]\nsympy/codegen/tests/test_ast.py::test_Type__cast_check__floating_point PASSED [ 74%]\nsympy/codegen/tests/test_ast.py::test_Type__cast_check__complex_floating_point PASSED [ 77%]\nsympy/codegen/tests/test_ast.py::test_While PASSED                       [ 80%]\nsympy/codegen/tests/test_ast.py::test_Scope PASSED                       [ 83%]\nsympy/codegen/tests/test_ast.py::test_Print PASSED                       [ 87%]\nsympy/codegen/tests/test_ast.py::test_FunctionPrototype_and_FunctionDefinition PASSED [ 90%]\nsympy/codegen/tests/test_ast.py::test_Return PASSED                      [ 93%]\nsympy/codegen/tests/test_ast.py::test_FunctionCall PASSED                [ 96%]\nsympy/codegen/tests/test_ast.py::test_ast_replace PASSED                 [100%]\n\n============================== 31 passed in 0.65s ==============================\n\n",
          "test_files_run": [
            "sympy/codegen/tests/test_ast.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-22714",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 23.586907863616943,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 12,
          "failed": 1,
          "errors": 0,
          "collected": 13,
          "duration": 11.97,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 13 items\n\nsympy/geometry/tests/test_point.py::test_point PASSED                    [  7%]\nsympy/geometry/tests/test_point.py::test_point3D PASSED                  [ 15%]\nsympy/geometry/tests/test_point.py::test_Point2D PASSED                  [ 23%]\nsympy/geometry/tests/test_point.py::test_issue_9214 PASSED               [ 30%]\nsympy/geometry/tests/test_point.py::test_issue_11617 PASSED              [ 38%]\nsympy/geometry/tests/test_point.py::test_transform PASSED                [ 46%]\nsympy/geometry/tests/test_point.py::test_concyclic_doctest_bug PASSED    [ 53%]\nsympy/geometry/tests/test_point.py::test_arguments PASSED                [ 61%]\nsympy/geometry/tests/test_point.py::test_unit PASSED                     [ 69%]\nsympy/geometry/tests/test_point.py::test_dot PASSED                      [ 76%]\nsympy/geometry/tests/test_point.py::test__normalize_dimension PASSED     [ 84%]\nsympy/geometry/tests/test_point.py::test_issue_22684 FAILED              [ 92%]\nsympy/geometry/tests/test_point.py::test_direction_cosine PASSED         [100%]\n\n=================================== FAILURES ===================================\n_______________________________ test_issue_22684 _______________________________\nsympy/geometry/tests/test_point.py:459: in test_issue_22684\n    Point(1, 2)\nsympy/geometry/point.py:156: in __new__\n    raise ValueError('Imaginary coordinates are not permitted.')\nE   ValueError: Imaginary coordinates are not permitted.\n=============================== warnings summary ===============================\nsympy/geometry/tests/test_point.py::test_point\n  /testbed/sympy/geometry/point.py:148: UserWarning: Dimension of (0, 0) needs to be changed from 2 to 3.\n    warnings.warn(message)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 1 failed, 12 passed, 1 warning in 2.90s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/geometry/tests/test_point.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/geometry/tests/test_point.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 13,
          "failed": 0,
          "errors": 0,
          "collected": 13,
          "duration": 10.41,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 13 items\n\nsympy/geometry/tests/test_point.py::test_point PASSED                    [  7%]\nsympy/geometry/tests/test_point.py::test_point3D PASSED                  [ 15%]\nsympy/geometry/tests/test_point.py::test_Point2D PASSED                  [ 23%]\nsympy/geometry/tests/test_point.py::test_issue_9214 PASSED               [ 30%]\nsympy/geometry/tests/test_point.py::test_issue_11617 PASSED              [ 38%]\nsympy/geometry/tests/test_point.py::test_transform PASSED                [ 46%]\nsympy/geometry/tests/test_point.py::test_concyclic_doctest_bug PASSED    [ 53%]\nsympy/geometry/tests/test_point.py::test_arguments PASSED                [ 61%]\nsympy/geometry/tests/test_point.py::test_unit PASSED                     [ 69%]\nsympy/geometry/tests/test_point.py::test_dot PASSED                      [ 76%]\nsympy/geometry/tests/test_point.py::test__normalize_dimension PASSED     [ 84%]\nsympy/geometry/tests/test_point.py::test_issue_22684 PASSED              [ 92%]\nsympy/geometry/tests/test_point.py::test_direction_cosine PASSED         [100%]\n\n=============================== warnings summary ===============================\nsympy/geometry/tests/test_point.py::test_point\n  /testbed/sympy/geometry/point.py:148: UserWarning: Dimension of (0, 0) needs to be changed from 2 to 3.\n    warnings.warn(message)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================== 13 passed, 1 warning in 1.95s =========================\n\n",
          "test_files_run": [
            "sympy/geometry/tests/test_point.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-22914",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 19.656191110610962,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 18,
          "failed": 1,
          "errors": 0,
          "collected": 21,
          "duration": 9.77,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 21 items\n\nsympy/printing/tests/test_pycode.py::test_PythonCodePrinter FAILED       [  4%]\nsympy/printing/tests/test_pycode.py::test_PythonCodePrinter_standard PASSED [  9%]\nsympy/printing/tests/test_pycode.py::test_MpmathPrinter PASSED           [ 14%]\nsympy/printing/tests/test_pycode.py::test_NumPyPrinter PASSED            [ 19%]\nsympy/printing/tests/test_pycode.py::test_issue_18770 SKIPPED (numpy...) [ 23%]\nsympy/printing/tests/test_pycode.py::test_SciPyPrinter PASSED            [ 28%]\nsympy/printing/tests/test_pycode.py::test_pycode_reserved_words PASSED   [ 33%]\nsympy/printing/tests/test_pycode.py::test_issue_20762 SKIPPED (antlr...) [ 38%]\nsympy/printing/tests/test_pycode.py::test_sqrt PASSED                    [ 42%]\nsympy/printing/tests/test_pycode.py::test_frac PASSED                    [ 47%]\nsympy/printing/tests/test_pycode.py::test_printmethod PASSED             [ 52%]\nsympy/printing/tests/test_pycode.py::test_codegen_ast_nodes PASSED       [ 57%]\nsympy/printing/tests/test_pycode.py::test_issue_14283 PASSED             [ 61%]\nsympy/printing/tests/test_pycode.py::test_NumPyPrinter_print_seq PASSED  [ 66%]\nsympy/printing/tests/test_pycode.py::test_issue_16535_16536 PASSED       [ 71%]\nsympy/printing/tests/test_pycode.py::test_Integral PASSED                [ 76%]\nsympy/printing/tests/test_pycode.py::test_fresnel_integrals PASSED       [ 80%]\nsympy/printing/tests/test_pycode.py::test_beta PASSED                    [ 85%]\nsympy/printing/tests/test_pycode.py::test_airy PASSED                    [ 90%]\nsympy/printing/tests/test_pycode.py::test_airy_prime PASSED              [ 95%]\nsympy/printing/tests/test_pycode.py::test_numerical_accuracy_functions PASSED [100%]\n\n=================================== FAILURES ===================================\n____________________________ test_PythonCodePrinter ____________________________\nsympy/printing/tests/test_pycode.py:61: in test_PythonCodePrinter\n    assert prntr.doprint(Min(x, y)) == \"min(x, y)\"\nE   AssertionError: assert '((x) if (x <= y) else (y))' == 'min(x, y)'\nE     \nE     - min(x, y)\nE     + ((x) if (x <= y) else (y))\n                                DO *NOT* COMMIT!                                \n=================== 1 failed, 18 passed, 2 skipped in 0.78s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/printing/tests/test_pycode.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/printing/tests/test_pycode.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 19,
          "failed": 0,
          "errors": 0,
          "collected": 21,
          "duration": 8.77,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 21 items\n\nsympy/printing/tests/test_pycode.py::test_PythonCodePrinter PASSED       [  4%]\nsympy/printing/tests/test_pycode.py::test_PythonCodePrinter_standard PASSED [  9%]\nsympy/printing/tests/test_pycode.py::test_MpmathPrinter PASSED           [ 14%]\nsympy/printing/tests/test_pycode.py::test_NumPyPrinter PASSED            [ 19%]\nsympy/printing/tests/test_pycode.py::test_issue_18770 SKIPPED (numpy...) [ 23%]\nsympy/printing/tests/test_pycode.py::test_SciPyPrinter PASSED            [ 28%]\nsympy/printing/tests/test_pycode.py::test_pycode_reserved_words PASSED   [ 33%]\nsympy/printing/tests/test_pycode.py::test_issue_20762 SKIPPED (antlr...) [ 38%]\nsympy/printing/tests/test_pycode.py::test_sqrt PASSED                    [ 42%]\nsympy/printing/tests/test_pycode.py::test_frac PASSED                    [ 47%]\nsympy/printing/tests/test_pycode.py::test_printmethod PASSED             [ 52%]\nsympy/printing/tests/test_pycode.py::test_codegen_ast_nodes PASSED       [ 57%]\nsympy/printing/tests/test_pycode.py::test_issue_14283 PASSED             [ 61%]\nsympy/printing/tests/test_pycode.py::test_NumPyPrinter_print_seq PASSED  [ 66%]\nsympy/printing/tests/test_pycode.py::test_issue_16535_16536 PASSED       [ 71%]\nsympy/printing/tests/test_pycode.py::test_Integral PASSED                [ 76%]\nsympy/printing/tests/test_pycode.py::test_fresnel_integrals PASSED       [ 80%]\nsympy/printing/tests/test_pycode.py::test_beta PASSED                    [ 85%]\nsympy/printing/tests/test_pycode.py::test_airy PASSED                    [ 90%]\nsympy/printing/tests/test_pycode.py::test_airy_prime PASSED              [ 95%]\nsympy/printing/tests/test_pycode.py::test_numerical_accuracy_functions PASSED [100%]\n\n======================== 19 passed, 2 skipped in 0.48s =========================\n\n",
          "test_files_run": [
            "sympy/printing/tests/test_pycode.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-23262",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 21.548198223114014,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 62,
          "failed": 1,
          "errors": 0,
          "collected": 117,
          "duration": 10.85,
          "log_tail": "sympy/utilities/tests/test_lambdify.py::test_Min_Max PASSED              [ 68%]\nsympy/utilities/tests/test_lambdify.py::test_Indexed SKIPPED (numpy ...) [ 69%]\nsympy/utilities/tests/test_lambdify.py::test_issue_12173 PASSED          [ 70%]\nsympy/utilities/tests/test_lambdify.py::test_issue_13642 SKIPPED (nu...) [ 70%]\nsympy/utilities/tests/test_lambdify.py::test_sinc_mpmath PASSED          [ 71%]\nsympy/utilities/tests/test_lambdify.py::test_lambdify_dummy_arg PASSED   [ 72%]\nsympy/utilities/tests/test_lambdify.py::test_lambdify_mixed_symbol_dummy_args PASSED [ 73%]\nsympy/utilities/tests/test_lambdify.py::test_numpy_array_arg SKIPPED     [ 74%]\nsympy/utilities/tests/test_lambdify.py::test_scipy_fns SKIPPED (scip...) [ 75%]\nsympy/utilities/tests/test_lambdify.py::test_scipy_polys SKIPPED (sc...) [ 76%]\nsympy/utilities/tests/test_lambdify.py::test_lambdify_inspect PASSED     [ 76%]\nsympy/utilities/tests/test_lambdify.py::test_issue_14941 FAILED          [ 77%]\nsympy/utilities/tests/test_lambdify.py::test_lambdify_Derivative_arg_issue_16468 PASSED [ 78%]\nsympy/utilities/tests/test_lambdify.py::test_imag_real PASSED            [ 79%]\nsympy/utilities/tests/test_lambdify.py::test_MatrixSymbol_issue_15578 SKIPPED [ 80%]\nsympy/utilities/tests/test_lambdify.py::test_issue_15654 SKIPPED (sc...) [ 81%]\nsympy/utilities/tests/test_lambdify.py::test_issue_15827 SKIPPED (nu...) [ 82%]\nsympy/utilities/tests/test_lambdify.py::test_issue_16930 SKIPPED (sc...) [ 82%]\nsympy/utilities/tests/test_lambdify.py::test_issue_17898 SKIPPED (sc...) [ 83%]\nsympy/utilities/tests/test_lambdify.py::test_issue_13167_21411 SKIPPED   [ 84%]\nsympy/utilities/tests/test_lambdify.py::test_single_e PASSED             [ 85%]\nsympy/utilities/tests/test_lambdify.py::test_issue_16536 SKIPPED (sc...) [ 86%]\nsympy/utilities/tests/test_lambdify.py::test_issue_22726 SKIPPED (nu...) [ 87%]\nsympy/utilities/tests/test_lambdify.py::test_issue_22739 SKIPPED (nu...) [ 88%]\nsympy/utilities/tests/test_lambdify.py::test_issue_19764 SKIPPED (nu...) [ 88%]\nsympy/utilities/tests/test_lambdify.py::test_issue_20070 SKIPPED (nu...) [ 89%]\nsympy/utilities/tests/test_lambdify.py::test_fresnel_integrals_scipy SKIPPED [ 90%]\nsympy/utilities/tests/test_lambdify.py::test_beta_scipy SKIPPED (sci...) [ 91%]\nsympy/utilities/tests/test_lambdify.py::test_beta_math PASSED            [ 92%]\nsympy/utilities/tests/test_lambdify.py::test_betainc_scipy SKIPPED (...) [ 93%]\nsympy/utilities/tests/test_lambdify.py::test_betainc_regularized_scipy SKIPPED [ 94%]\nsympy/utilities/tests/test_lambdify.py::test_numpy_special_math SKIPPED  [ 94%]\nsympy/utilities/tests/test_lambdify.py::test_scipy_special_math SKIPPED  [ 95%]\nsympy/utilities/tests/test_lambdify.py::test_cupy_array_arg SKIPPED      [ 96%]\nsympy/utilities/tests/test_lambdify.py::test_cupy_array_arg_using_numpy SKIPPED [ 97%]\nsympy/utilities/tests/test_lambdify.py::test_cupy_dotproduct SKIPPED     [ 98%]\nsympy/utilities/tests/test_lambdify.py::test_lambdify_cse PASSED         [ 99%]\nsympy/utilities/tests/test_lambdify.py::test_deprecated_set PASSED       [100%]\n\n=================================== FAILURES ===================================\n_______________________________ test_issue_14941 _______________________________\nsympy/utilities/tests/test_lambdify.py:1196: in test_issue_14941\n    assert f2b() == (1,)\nE   assert 1 == (1,)\nE    +  where 1 = <function _lambdifygenerated at 0x72e20efafc10>()\n                                DO *NOT* COMMIT!                                \n=================== 1 failed, 62 passed, 54 skipped in 1.56s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/utilities/tests/test_lambdify.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/utilities/tests/test_lambdify.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 63,
          "failed": 0,
          "errors": 0,
          "collected": 117,
          "duration": 9.55,
          "log_tail": "sympy/utilities/tests/test_lambdify.py::test_python_keywords PASSED      [ 61%]\nsympy/utilities/tests/test_lambdify.py::test_lambdify_docstring PASSED   [ 62%]\nsympy/utilities/tests/test_lambdify.py::test_special_printers PASSED     [ 63%]\nsympy/utilities/tests/test_lambdify.py::test_true_false PASSED           [ 64%]\nsympy/utilities/tests/test_lambdify.py::test_issue_2790 PASSED           [ 64%]\nsympy/utilities/tests/test_lambdify.py::test_issue_12092 PASSED          [ 65%]\nsympy/utilities/tests/test_lambdify.py::test_issue_14911 PASSED          [ 66%]\nsympy/utilities/tests/test_lambdify.py::test_ITE PASSED                  [ 67%]\nsympy/utilities/tests/test_lambdify.py::test_Min_Max PASSED              [ 68%]\nsympy/utilities/tests/test_lambdify.py::test_Indexed SKIPPED (numpy ...) [ 69%]\nsympy/utilities/tests/test_lambdify.py::test_issue_12173 PASSED          [ 70%]\nsympy/utilities/tests/test_lambdify.py::test_issue_13642 SKIPPED (nu...) [ 70%]\nsympy/utilities/tests/test_lambdify.py::test_sinc_mpmath PASSED          [ 71%]\nsympy/utilities/tests/test_lambdify.py::test_lambdify_dummy_arg PASSED   [ 72%]\nsympy/utilities/tests/test_lambdify.py::test_lambdify_mixed_symbol_dummy_args PASSED [ 73%]\nsympy/utilities/tests/test_lambdify.py::test_numpy_array_arg SKIPPED     [ 74%]\nsympy/utilities/tests/test_lambdify.py::test_scipy_fns SKIPPED (scip...) [ 75%]\nsympy/utilities/tests/test_lambdify.py::test_scipy_polys SKIPPED (sc...) [ 76%]\nsympy/utilities/tests/test_lambdify.py::test_lambdify_inspect PASSED     [ 76%]\nsympy/utilities/tests/test_lambdify.py::test_issue_14941 PASSED          [ 77%]\nsympy/utilities/tests/test_lambdify.py::test_lambdify_Derivative_arg_issue_16468 PASSED [ 78%]\nsympy/utilities/tests/test_lambdify.py::test_imag_real PASSED            [ 79%]\nsympy/utilities/tests/test_lambdify.py::test_MatrixSymbol_issue_15578 SKIPPED [ 80%]\nsympy/utilities/tests/test_lambdify.py::test_issue_15654 SKIPPED (sc...) [ 81%]\nsympy/utilities/tests/test_lambdify.py::test_issue_15827 SKIPPED (nu...) [ 82%]\nsympy/utilities/tests/test_lambdify.py::test_issue_16930 SKIPPED (sc...) [ 82%]\nsympy/utilities/tests/test_lambdify.py::test_issue_17898 SKIPPED (sc...) [ 83%]\nsympy/utilities/tests/test_lambdify.py::test_issue_13167_21411 SKIPPED   [ 84%]\nsympy/utilities/tests/test_lambdify.py::test_single_e PASSED             [ 85%]\nsympy/utilities/tests/test_lambdify.py::test_issue_16536 SKIPPED (sc...) [ 86%]\nsympy/utilities/tests/test_lambdify.py::test_issue_22726 SKIPPED (nu...) [ 87%]\nsympy/utilities/tests/test_lambdify.py::test_issue_22739 SKIPPED (nu...) [ 88%]\nsympy/utilities/tests/test_lambdify.py::test_issue_19764 SKIPPED (nu...) [ 88%]\nsympy/utilities/tests/test_lambdify.py::test_issue_20070 SKIPPED (nu...) [ 89%]\nsympy/utilities/tests/test_lambdify.py::test_fresnel_integrals_scipy SKIPPED [ 90%]\nsympy/utilities/tests/test_lambdify.py::test_beta_scipy SKIPPED (sci...) [ 91%]\nsympy/utilities/tests/test_lambdify.py::test_beta_math PASSED            [ 92%]\nsympy/utilities/tests/test_lambdify.py::test_betainc_scipy SKIPPED (...) [ 93%]\nsympy/utilities/tests/test_lambdify.py::test_betainc_regularized_scipy SKIPPED [ 94%]\nsympy/utilities/tests/test_lambdify.py::test_numpy_special_math SKIPPED  [ 94%]\nsympy/utilities/tests/test_lambdify.py::test_scipy_special_math SKIPPED  [ 95%]\nsympy/utilities/tests/test_lambdify.py::test_cupy_array_arg SKIPPED      [ 96%]\nsympy/utilities/tests/test_lambdify.py::test_cupy_array_arg_using_numpy SKIPPED [ 97%]\nsympy/utilities/tests/test_lambdify.py::test_cupy_dotproduct SKIPPED     [ 98%]\nsympy/utilities/tests/test_lambdify.py::test_lambdify_cse PASSED         [ 99%]\nsympy/utilities/tests/test_lambdify.py::test_deprecated_set PASSED       [100%]\n\n======================== 63 passed, 54 skipped in 1.08s ========================\n\n",
          "test_files_run": [
            "sympy/utilities/tests/test_lambdify.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-23413",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 19.415581941604614,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 3,
          "failed": 3,
          "errors": 0,
          "collected": 6,
          "duration": 9.29,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 6 items\n\nsympy/matrices/tests/test_normalforms.py::test_smith_normal PASSED       [ 16%]\nsympy/matrices/tests/test_normalforms.py::test_smith_normal_deprecated PASSED [ 33%]\nsympy/matrices/tests/test_normalforms.py::test_hermite_normal FAILED     [ 50%]\nsympy/matrices/tests/test_normalforms.py::test_issue_23410 FAILED        [ 66%]\nsympy/polys/matrices/tests/test_normalforms.py::test_smith_normal PASSED [ 83%]\nsympy/polys/matrices/tests/test_normalforms.py::test_hermite_normal FAILED [100%]\n\n=================================== FAILURES ===================================\n_____________________________ test_hermite_normal ______________________________\nsympy/matrices/tests/test_normalforms.py:81: in test_hermite_normal\n    assert hermite_normal_form(m) == hnf\nE   assert Matrix(3, 0, []) == Matrix([\\n[1],\\n[0],\\n[0]])\nE     \nE     Full diff:\nE     + Matrix(3, 0, [])\nE     - Matrix([\nE     - [1],\nE     - [0],\nE     - [0]])\n_______________________________ test_issue_23410 _______________________________\nsympy/matrices/tests/test_normalforms.py:87: in test_issue_23410\n    assert hermite_normal_form(A) == H\nE   AssertionError: assert Matrix([\\n[12],\\n[ 8],\\n[ 5]]) == Matrix([\\n[1, ..., 8],\\n[0, 5]])\nE     \nE     Full diff:\nE       Matrix([\nE     - [1, 0],\nE     + [12],\nE     - [0, 8],\nE     ?  --...\nE     \nE     ...Full output truncated (4 lines hidden), use '-vv' to show\n_____________________________ test_hermite_normal ______________________________\nsympy/polys/matrices/tests/test_normalforms.py:66: in test_hermite_normal\n    assert hermite_normal_form(m) == hnf\nE   assert DomainMatrix(...], (3, 0), ZZ) == DomainMatrix(...], (3, 1), ZZ)\nE     \nE     Full diff:\nE     - DomainMatrix([[1], [0], [0]], (3, 1), ZZ)\nE     ?                -    -    -        ^\nE     + DomainMatrix([[], [], []], (3, 0), ZZ)\nE     ?                                ^\n                                DO *NOT* COMMIT!                                \n========================= 3 failed, 3 passed in 0.53s ==========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/matrices/tests/test_normalforms.py sympy/polys/matrices/tests/test_normalforms.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/matrices/tests/test_normalforms.py",
            "sympy/polys/matrices/tests/test_normalforms.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 6,
          "failed": 0,
          "errors": 0,
          "collected": 6,
          "duration": 8.85,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 6 items\n\nsympy/matrices/tests/test_normalforms.py::test_smith_normal PASSED       [ 16%]\nsympy/matrices/tests/test_normalforms.py::test_smith_normal_deprecated PASSED [ 33%]\nsympy/matrices/tests/test_normalforms.py::test_hermite_normal PASSED     [ 50%]\nsympy/matrices/tests/test_normalforms.py::test_issue_23410 PASSED        [ 66%]\nsympy/polys/matrices/tests/test_normalforms.py::test_smith_normal PASSED [ 83%]\nsympy/polys/matrices/tests/test_normalforms.py::test_hermite_normal PASSED [100%]\n\n============================== 6 passed in 0.35s ===============================\n\n",
          "test_files_run": [
            "sympy/matrices/tests/test_normalforms.py",
            "sympy/polys/matrices/tests/test_normalforms.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-23534",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 19.610962867736816,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 12,
          "failed": 1,
          "errors": 0,
          "collected": 13,
          "duration": 9.64,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 13 items\n\nsympy/core/tests/test_symbol.py::test_Str PASSED                         [  7%]\nsympy/core/tests/test_symbol.py::test_Symbol PASSED                      [ 15%]\nsympy/core/tests/test_symbol.py::test_Dummy PASSED                       [ 23%]\nsympy/core/tests/test_symbol.py::test_Dummy_force_dummy_index PASSED     [ 30%]\nsympy/core/tests/test_symbol.py::test_lt_gt PASSED                       [ 38%]\nsympy/core/tests/test_symbol.py::test_no_len PASSED                      [ 46%]\nsympy/core/tests/test_symbol.py::test_ineq_unequal PASSED                [ 53%]\nsympy/core/tests/test_symbol.py::test_Wild_properties PASSED             [ 61%]\nsympy/core/tests/test_symbol.py::test_symbols FAILED                     [ 69%]\nsympy/core/tests/test_symbol.py::test_symbols_become_functions_issue_3539 PASSED [ 76%]\nsympy/core/tests/test_symbol.py::test_unicode PASSED                     [ 84%]\nsympy/core/tests/test_symbol.py::test_uniquely_named_symbol_and_Symbol PASSED [ 92%]\nsympy/core/tests/test_symbol.py::test_disambiguate PASSED                [100%]\n\n=================================== FAILURES ===================================\n_________________________________ test_symbols _________________________________\nsympy/core/tests/test_symbol.py:298: in test_symbols\n    assert type(symbols(('q:2', 'u:2'), cls=Function)[0][0]) == UndefinedFunction  # issue 23532\nE   AssertionError: assert <class 'sympy.core.symbol.Symbol'> == UndefinedFunction\nE    +  where <class 'sympy.core.symbol.Symbol'> = type(q0)\n                                DO *NOT* COMMIT!                                \n========================= 1 failed, 12 passed in 0.70s =========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/core/tests/test_symbol.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/core/tests/test_symbol.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 13,
          "failed": 0,
          "errors": 0,
          "collected": 13,
          "duration": 8.74,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 13 items\n\nsympy/core/tests/test_symbol.py::test_Str PASSED                         [  7%]\nsympy/core/tests/test_symbol.py::test_Symbol PASSED                      [ 15%]\nsympy/core/tests/test_symbol.py::test_Dummy PASSED                       [ 23%]\nsympy/core/tests/test_symbol.py::test_Dummy_force_dummy_index PASSED     [ 30%]\nsympy/core/tests/test_symbol.py::test_lt_gt PASSED                       [ 38%]\nsympy/core/tests/test_symbol.py::test_no_len PASSED                      [ 46%]\nsympy/core/tests/test_symbol.py::test_ineq_unequal PASSED                [ 53%]\nsympy/core/tests/test_symbol.py::test_Wild_properties PASSED             [ 61%]\nsympy/core/tests/test_symbol.py::test_symbols PASSED                     [ 69%]\nsympy/core/tests/test_symbol.py::test_symbols_become_functions_issue_3539 PASSED [ 76%]\nsympy/core/tests/test_symbol.py::test_unicode PASSED                     [ 84%]\nsympy/core/tests/test_symbol.py::test_uniquely_named_symbol_and_Symbol PASSED [ 92%]\nsympy/core/tests/test_symbol.py::test_disambiguate PASSED                [100%]\n\n============================== 13 passed in 0.45s ==============================\n\n",
          "test_files_run": [
            "sympy/core/tests/test_symbol.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-23824",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 26.11592388153076,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 3,
          "failed": 1,
          "errors": 0,
          "collected": 4,
          "duration": 14.14,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 4 items\n\nsympy/physics/hep/tests/test_gamma_matrices.py::test_kahane_algorithm PASSED [ 25%]\nsympy/physics/hep/tests/test_gamma_matrices.py::test_kahane_simplify1 FAILED [ 50%]\nsympy/physics/hep/tests/test_gamma_matrices.py::test_gamma_matrix_class PASSED [ 75%]\nsympy/physics/hep/tests/test_gamma_matrices.py::test_gamma_matrix_trace PASSED [100%]\n\n=================================== FAILURES ===================================\n____________________________ test_kahane_simplify1 _____________________________\nsympy/physics/hep/tests/test_gamma_matrices.py:265: in test_kahane_simplify1\n    assert r.equals(4*G(rho)*G(sigma))\nE   assert False\nE    +  where False = equals(((4 * GammaMatrix(rho)) * GammaMatrix(sigma)))\nE    +    where equals = 4*GammaMatrix(sigma)*GammaMatrix(rho).equals\nE    +    and   GammaMatrix(rho) = G(rho)\nE    +    and   GammaMatrix(sigma) = G(sigma)\n                                DO *NOT* COMMIT!                                \n========================= 1 failed, 3 passed in 4.71s ==========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/physics/hep/tests/test_gamma_matrices.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/physics/hep/tests/test_gamma_matrices.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 4,
          "failed": 0,
          "errors": 0,
          "collected": 4,
          "duration": 10.73,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 4 items\n\nsympy/physics/hep/tests/test_gamma_matrices.py::test_kahane_algorithm PASSED [ 25%]\nsympy/physics/hep/tests/test_gamma_matrices.py::test_kahane_simplify1 PASSED [ 50%]\nsympy/physics/hep/tests/test_gamma_matrices.py::test_gamma_matrix_class PASSED [ 75%]\nsympy/physics/hep/tests/test_gamma_matrices.py::test_gamma_matrix_trace PASSED [100%]\n\n============================== 4 passed in 4.15s ===============================\n\n",
          "test_files_run": [
            "sympy/physics/hep/tests/test_gamma_matrices.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-23950",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 18.65489625930786,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 5,
          "failed": 1,
          "errors": 0,
          "collected": 6,
          "duration": 9.36,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 6 items\n\nsympy/sets/tests/test_contains.py::test_contains_basic PASSED            [ 16%]\nsympy/sets/tests/test_contains.py::test_issue_6194 PASSED                [ 33%]\nsympy/sets/tests/test_contains.py::test_issue_10326 PASSED               [ 50%]\nsympy/sets/tests/test_contains.py::test_binary_symbols PASSED            [ 66%]\nsympy/sets/tests/test_contains.py::test_as_set FAILED                    [ 83%]\nsympy/sets/tests/test_contains.py::test_type_error PASSED                [100%]\n\n=================================== FAILURES ===================================\n_________________________________ test_as_set __________________________________\nsympy/sets/tests/test_contains.py:44: in test_as_set\n    assert Contains(x, FiniteSet(y)).as_set() == FiniteSet(y)\nsympy/sets/contains.py:48: in as_set\n    raise NotImplementedError()\nE   NotImplementedError\n                                DO *NOT* COMMIT!                                \n========================= 1 failed, 5 passed in 0.29s ==========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/sets/tests/test_contains.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/sets/tests/test_contains.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 6,
          "failed": 0,
          "errors": 0,
          "collected": 6,
          "duration": 7.71,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 6 items\n\nsympy/sets/tests/test_contains.py::test_contains_basic PASSED            [ 16%]\nsympy/sets/tests/test_contains.py::test_issue_6194 PASSED                [ 33%]\nsympy/sets/tests/test_contains.py::test_issue_10326 PASSED               [ 50%]\nsympy/sets/tests/test_contains.py::test_binary_symbols PASSED            [ 66%]\nsympy/sets/tests/test_contains.py::test_as_set PASSED                    [ 83%]\nsympy/sets/tests/test_contains.py::test_type_error PASSED                [100%]\n\n============================== 6 passed in 0.21s ===============================\n\n",
          "test_files_run": [
            "sympy/sets/tests/test_contains.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-24066",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 19.219449758529663,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 31,
          "failed": 1,
          "errors": 0,
          "collected": 33,
          "duration": 9.83,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 33 items\n\nsympy/physics/units/tests/test_quantities.py::test_str_repr PASSED       [  3%]\nsympy/physics/units/tests/test_quantities.py::test_eq PASSED             [  6%]\nsympy/physics/units/tests/test_quantities.py::test_convert_to PASSED     [  9%]\nsympy/physics/units/tests/test_quantities.py::test_Quantity_definition PASSED [ 12%]\nsympy/physics/units/tests/test_quantities.py::test_abbrev PASSED         [ 15%]\nsympy/physics/units/tests/test_quantities.py::test_print PASSED          [ 18%]\nsympy/physics/units/tests/test_quantities.py::test_Quantity_eq PASSED    [ 21%]\nsympy/physics/units/tests/test_quantities.py::test_add_sub PASSED        [ 24%]\nsympy/physics/units/tests/test_quantities.py::test_quantity_abs PASSED   [ 27%]\nsympy/physics/units/tests/test_quantities.py::test_check_unit_consistency PASSED [ 30%]\nsympy/physics/units/tests/test_quantities.py::test_mul_div PASSED        [ 33%]\nsympy/physics/units/tests/test_quantities.py::test_units PASSED          [ 36%]\nsympy/physics/units/tests/test_quantities.py::test_issue_quart PASSED    [ 39%]\nsympy/physics/units/tests/test_quantities.py::test_issue_5565 PASSED     [ 42%]\nsympy/physics/units/tests/test_quantities.py::test_find_unit PASSED      [ 45%]\nsympy/physics/units/tests/test_quantities.py::test_Quantity_derivative PASSED [ 48%]\nsympy/physics/units/tests/test_quantities.py::test_quantity_postprocessing PASSED [ 51%]\nsympy/physics/units/tests/test_quantities.py::test_factor_and_dimension PASSED [ 54%]\nsympy/physics/units/tests/test_quantities.py::test_factor_and_dimension_with_Abs XFAIL [ 57%]\nsympy/physics/units/tests/test_quantities.py::test_dimensional_expr_of_derivative PASSED [ 60%]\nsympy/physics/units/tests/test_quantities.py::test_get_dimensional_expr_with_function PASSED [ 63%]\nsympy/physics/units/tests/test_quantities.py::test_binary_information PASSED [ 66%]\nsympy/physics/units/tests/test_quantities.py::test_conversion_with_2_nonstandard_dimensions PASSED [ 69%]\nsympy/physics/units/tests/test_quantities.py::test_eval_subs PASSED      [ 72%]\nsympy/physics/units/tests/test_quantities.py::test_issue_14932 PASSED    [ 75%]\nsympy/physics/units/tests/test_quantities.py::test_issue_14547 PASSED    [ 78%]\nsympy/physics/units/tests/test_quantities.py::test_deprecated_quantity_methods PASSED [ 81%]\nsympy/physics/units/tests/test_quantities.py::test_issue_22164 PASSED    [ 84%]\nsympy/physics/units/tests/test_quantities.py::test_issue_22819 PASSED    [ 87%]\nsympy/physics/units/tests/test_quantities.py::test_issue_20288 PASSED    [ 90%]\nsympy/physics/units/tests/test_quantities.py::test_issue_24062 FAILED    [ 93%]\nsympy/physics/units/tests/test_quantities.py::test_prefixed_property PASSED [ 96%]\nsympy/physics/units/tests/test_quantities.py::test_physics_constant PASSED [100%]\n\n=================================== FAILURES ===================================\n_______________________________ test_issue_24062 _______________________________\nsympy/physics/units/tests/test_quantities.py:562: in test_issue_24062\n    assert SI._collect_factor_and_dimension(exp_expr) == (1 + E, Dimension(1))\nsympy/physics/units/unitsystem.py:179: in _collect_factor_and_dimension\n    raise ValueError(\nE   ValueError: Dimension of \"exp(T/(C*R))\" is Dimension(time/(capacitance*impedance)), but it should be Dimension(1)\n                                DO *NOT* COMMIT!                                \n=================== 1 failed, 31 passed, 1 xfailed in 0.83s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/physics/units/tests/test_quantities.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/physics/units/tests/test_quantities.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 32,
          "failed": 0,
          "errors": 0,
          "collected": 33,
          "duration": 8.27,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 33 items\n\nsympy/physics/units/tests/test_quantities.py::test_str_repr PASSED       [  3%]\nsympy/physics/units/tests/test_quantities.py::test_eq PASSED             [  6%]\nsympy/physics/units/tests/test_quantities.py::test_convert_to PASSED     [  9%]\nsympy/physics/units/tests/test_quantities.py::test_Quantity_definition PASSED [ 12%]\nsympy/physics/units/tests/test_quantities.py::test_abbrev PASSED         [ 15%]\nsympy/physics/units/tests/test_quantities.py::test_print PASSED          [ 18%]\nsympy/physics/units/tests/test_quantities.py::test_Quantity_eq PASSED    [ 21%]\nsympy/physics/units/tests/test_quantities.py::test_add_sub PASSED        [ 24%]\nsympy/physics/units/tests/test_quantities.py::test_quantity_abs PASSED   [ 27%]\nsympy/physics/units/tests/test_quantities.py::test_check_unit_consistency PASSED [ 30%]\nsympy/physics/units/tests/test_quantities.py::test_mul_div PASSED        [ 33%]\nsympy/physics/units/tests/test_quantities.py::test_units PASSED          [ 36%]\nsympy/physics/units/tests/test_quantities.py::test_issue_quart PASSED    [ 39%]\nsympy/physics/units/tests/test_quantities.py::test_issue_5565 PASSED     [ 42%]\nsympy/physics/units/tests/test_quantities.py::test_find_unit PASSED      [ 45%]\nsympy/physics/units/tests/test_quantities.py::test_Quantity_derivative PASSED [ 48%]\nsympy/physics/units/tests/test_quantities.py::test_quantity_postprocessing PASSED [ 51%]\nsympy/physics/units/tests/test_quantities.py::test_factor_and_dimension PASSED [ 54%]\nsympy/physics/units/tests/test_quantities.py::test_factor_and_dimension_with_Abs XFAIL [ 57%]\nsympy/physics/units/tests/test_quantities.py::test_dimensional_expr_of_derivative PASSED [ 60%]\nsympy/physics/units/tests/test_quantities.py::test_get_dimensional_expr_with_function PASSED [ 63%]\nsympy/physics/units/tests/test_quantities.py::test_binary_information PASSED [ 66%]\nsympy/physics/units/tests/test_quantities.py::test_conversion_with_2_nonstandard_dimensions PASSED [ 69%]\nsympy/physics/units/tests/test_quantities.py::test_eval_subs PASSED      [ 72%]\nsympy/physics/units/tests/test_quantities.py::test_issue_14932 PASSED    [ 75%]\nsympy/physics/units/tests/test_quantities.py::test_issue_14547 PASSED    [ 78%]\nsympy/physics/units/tests/test_quantities.py::test_deprecated_quantity_methods PASSED [ 81%]\nsympy/physics/units/tests/test_quantities.py::test_issue_22164 PASSED    [ 84%]\nsympy/physics/units/tests/test_quantities.py::test_issue_22819 PASSED    [ 87%]\nsympy/physics/units/tests/test_quantities.py::test_issue_20288 PASSED    [ 90%]\nsympy/physics/units/tests/test_quantities.py::test_issue_24062 PASSED    [ 93%]\nsympy/physics/units/tests/test_quantities.py::test_prefixed_property PASSED [ 96%]\nsympy/physics/units/tests/test_quantities.py::test_physics_constant PASSED [100%]\n\n======================== 32 passed, 1 xfailed in 0.81s =========================\n\n",
          "test_files_run": [
            "sympy/physics/units/tests/test_quantities.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-24213",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 19.3250150680542,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 32,
          "failed": 1,
          "errors": 0,
          "collected": 34,
          "duration": 10.04,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 34 items\n\nsympy/physics/units/tests/test_quantities.py::test_str_repr PASSED       [  2%]\nsympy/physics/units/tests/test_quantities.py::test_eq PASSED             [  5%]\nsympy/physics/units/tests/test_quantities.py::test_convert_to PASSED     [  8%]\nsympy/physics/units/tests/test_quantities.py::test_Quantity_definition PASSED [ 11%]\nsympy/physics/units/tests/test_quantities.py::test_abbrev PASSED         [ 14%]\nsympy/physics/units/tests/test_quantities.py::test_print PASSED          [ 17%]\nsympy/physics/units/tests/test_quantities.py::test_Quantity_eq PASSED    [ 20%]\nsympy/physics/units/tests/test_quantities.py::test_add_sub PASSED        [ 23%]\nsympy/physics/units/tests/test_quantities.py::test_quantity_abs PASSED   [ 26%]\nsympy/physics/units/tests/test_quantities.py::test_check_unit_consistency PASSED [ 29%]\nsympy/physics/units/tests/test_quantities.py::test_mul_div PASSED        [ 32%]\nsympy/physics/units/tests/test_quantities.py::test_units PASSED          [ 35%]\nsympy/physics/units/tests/test_quantities.py::test_issue_quart PASSED    [ 38%]\nsympy/physics/units/tests/test_quantities.py::test_issue_5565 PASSED     [ 41%]\nsympy/physics/units/tests/test_quantities.py::test_find_unit PASSED      [ 44%]\nsympy/physics/units/tests/test_quantities.py::test_Quantity_derivative PASSED [ 47%]\nsympy/physics/units/tests/test_quantities.py::test_quantity_postprocessing PASSED [ 50%]\nsympy/physics/units/tests/test_quantities.py::test_factor_and_dimension PASSED [ 52%]\nsympy/physics/units/tests/test_quantities.py::test_factor_and_dimension_with_Abs XFAIL [ 55%]\nsympy/physics/units/tests/test_quantities.py::test_dimensional_expr_of_derivative PASSED [ 58%]\nsympy/physics/units/tests/test_quantities.py::test_get_dimensional_expr_with_function PASSED [ 61%]\nsympy/physics/units/tests/test_quantities.py::test_binary_information PASSED [ 64%]\nsympy/physics/units/tests/test_quantities.py::test_conversion_with_2_nonstandard_dimensions PASSED [ 67%]\nsympy/physics/units/tests/test_quantities.py::test_eval_subs PASSED      [ 70%]\nsympy/physics/units/tests/test_quantities.py::test_issue_14932 PASSED    [ 73%]\nsympy/physics/units/tests/test_quantities.py::test_issue_14547 PASSED    [ 76%]\nsympy/physics/units/tests/test_quantities.py::test_deprecated_quantity_methods PASSED [ 79%]\nsympy/physics/units/tests/test_quantities.py::test_issue_22164 PASSED    [ 82%]\nsympy/physics/units/tests/test_quantities.py::test_issue_22819 PASSED    [ 85%]\nsympy/physics/units/tests/test_quantities.py::test_issue_20288 PASSED    [ 88%]\nsympy/physics/units/tests/test_quantities.py::test_issue_24062 PASSED    [ 91%]\nsympy/physics/units/tests/test_quantities.py::test_issue_24211 FAILED    [ 94%]\nsympy/physics/units/tests/test_quantities.py::test_prefixed_property PASSED [ 97%]\nsympy/physics/units/tests/test_quantities.py::test_physics_constant PASSED [100%]\n\n=================================== FAILURES ===================================\n_______________________________ test_issue_24211 _______________________________\nsympy/physics/units/tests/test_quantities.py:578: in test_issue_24211\n    SI._collect_factor_and_dimension(expr)\nsympy/physics/units/unitsystem.py:179: in _collect_factor_and_dimension\n    raise ValueError(\nE   ValueError: Dimension of \"V1\" is Dimension(velocity), but it should be Dimension(acceleration*time)\n                                DO *NOT* COMMIT!                                \n=================== 1 failed, 32 passed, 1 xfailed in 1.29s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/physics/units/tests/test_quantities.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/physics/units/tests/test_quantities.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 33,
          "failed": 0,
          "errors": 0,
          "collected": 34,
          "duration": 8.01,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 34 items\n\nsympy/physics/units/tests/test_quantities.py::test_str_repr PASSED       [  2%]\nsympy/physics/units/tests/test_quantities.py::test_eq PASSED             [  5%]\nsympy/physics/units/tests/test_quantities.py::test_convert_to PASSED     [  8%]\nsympy/physics/units/tests/test_quantities.py::test_Quantity_definition PASSED [ 11%]\nsympy/physics/units/tests/test_quantities.py::test_abbrev PASSED         [ 14%]\nsympy/physics/units/tests/test_quantities.py::test_print PASSED          [ 17%]\nsympy/physics/units/tests/test_quantities.py::test_Quantity_eq PASSED    [ 20%]\nsympy/physics/units/tests/test_quantities.py::test_add_sub PASSED        [ 23%]\nsympy/physics/units/tests/test_quantities.py::test_quantity_abs PASSED   [ 26%]\nsympy/physics/units/tests/test_quantities.py::test_check_unit_consistency PASSED [ 29%]\nsympy/physics/units/tests/test_quantities.py::test_mul_div PASSED        [ 32%]\nsympy/physics/units/tests/test_quantities.py::test_units PASSED          [ 35%]\nsympy/physics/units/tests/test_quantities.py::test_issue_quart PASSED    [ 38%]\nsympy/physics/units/tests/test_quantities.py::test_issue_5565 PASSED     [ 41%]\nsympy/physics/units/tests/test_quantities.py::test_find_unit PASSED      [ 44%]\nsympy/physics/units/tests/test_quantities.py::test_Quantity_derivative PASSED [ 47%]\nsympy/physics/units/tests/test_quantities.py::test_quantity_postprocessing PASSED [ 50%]\nsympy/physics/units/tests/test_quantities.py::test_factor_and_dimension PASSED [ 52%]\nsympy/physics/units/tests/test_quantities.py::test_factor_and_dimension_with_Abs XFAIL [ 55%]\nsympy/physics/units/tests/test_quantities.py::test_dimensional_expr_of_derivative PASSED [ 58%]\nsympy/physics/units/tests/test_quantities.py::test_get_dimensional_expr_with_function PASSED [ 61%]\nsympy/physics/units/tests/test_quantities.py::test_binary_information PASSED [ 64%]\nsympy/physics/units/tests/test_quantities.py::test_conversion_with_2_nonstandard_dimensions PASSED [ 67%]\nsympy/physics/units/tests/test_quantities.py::test_eval_subs PASSED      [ 70%]\nsympy/physics/units/tests/test_quantities.py::test_issue_14932 PASSED    [ 73%]\nsympy/physics/units/tests/test_quantities.py::test_issue_14547 PASSED    [ 76%]\nsympy/physics/units/tests/test_quantities.py::test_deprecated_quantity_methods PASSED [ 79%]\nsympy/physics/units/tests/test_quantities.py::test_issue_22164 PASSED    [ 82%]\nsympy/physics/units/tests/test_quantities.py::test_issue_22819 PASSED    [ 85%]\nsympy/physics/units/tests/test_quantities.py::test_issue_20288 PASSED    [ 88%]\nsympy/physics/units/tests/test_quantities.py::test_issue_24062 PASSED    [ 91%]\nsympy/physics/units/tests/test_quantities.py::test_issue_24211 PASSED    [ 94%]\nsympy/physics/units/tests/test_quantities.py::test_prefixed_property PASSED [ 97%]\nsympy/physics/units/tests/test_quantities.py::test_physics_constant PASSED [100%]\n\n======================== 33 passed, 1 xfailed in 0.81s =========================\n\n",
          "test_files_run": [
            "sympy/physics/units/tests/test_quantities.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-24443",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 18.4855899810791,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 2,
          "failed": 1,
          "errors": 0,
          "collected": 3,
          "duration": 9.45,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 3 items\n\nsympy/combinatorics/tests/test_homomorphisms.py::test_homomorphism FAILED [ 33%]\nsympy/combinatorics/tests/test_homomorphisms.py::test_isomorphisms PASSED [ 66%]\nsympy/combinatorics/tests/test_homomorphisms.py::test_check_homomorphism PASSED [100%]\n\n=================================== FAILURES ===================================\n______________________________ test_homomorphism _______________________________\nsympy/combinatorics/tests/test_homomorphisms.py:61: in test_homomorphism\n    T = homomorphism(D3, D3, D3.generators, D3.generators)\nsympy/combinatorics/homomorphisms.py:307: in homomorphism\n    raise ValueError(\"The given images do not define a homomorphism\")\nE   ValueError: The given images do not define a homomorphism\n                                DO *NOT* COMMIT!                                \n========================= 1 failed, 2 passed in 0.93s ==========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/combinatorics/tests/test_homomorphisms.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/combinatorics/tests/test_homomorphisms.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 3,
          "failed": 0,
          "errors": 0,
          "collected": 3,
          "duration": 7.75,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 3 items\n\nsympy/combinatorics/tests/test_homomorphisms.py::test_homomorphism PASSED [ 33%]\nsympy/combinatorics/tests/test_homomorphisms.py::test_isomorphisms PASSED [ 66%]\nsympy/combinatorics/tests/test_homomorphisms.py::test_check_homomorphism PASSED [100%]\n\n============================== 3 passed in 0.68s ===============================\n\n",
          "test_files_run": [
            "sympy/combinatorics/tests/test_homomorphisms.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-24539",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 18.562229871749878,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 63,
          "failed": 1,
          "errors": 0,
          "collected": 64,
          "duration": 9.35,
          "log_tail": "sympy/polys/tests/test_rings.py::test_PolyElement_terms PASSED           [ 43%]\nsympy/polys/tests/test_rings.py::test_PolyElement_monoms PASSED          [ 45%]\nsympy/polys/tests/test_rings.py::test_PolyElement_coeffs PASSED          [ 46%]\nsympy/polys/tests/test_rings.py::test_PolyElement___add__ PASSED         [ 48%]\nsympy/polys/tests/test_rings.py::test_PolyElement___sub__ PASSED         [ 50%]\nsympy/polys/tests/test_rings.py::test_PolyElement___mul__ PASSED         [ 51%]\nsympy/polys/tests/test_rings.py::test_PolyElement___truediv__ PASSED     [ 53%]\nsympy/polys/tests/test_rings.py::test_PolyElement___pow__ PASSED         [ 54%]\nsympy/polys/tests/test_rings.py::test_PolyElement_div PASSED             [ 56%]\nsympy/polys/tests/test_rings.py::test_PolyElement_rem PASSED             [ 57%]\nsympy/polys/tests/test_rings.py::test_PolyElement_deflate PASSED         [ 59%]\nsympy/polys/tests/test_rings.py::test_PolyElement_clear_denoms PASSED    [ 60%]\nsympy/polys/tests/test_rings.py::test_PolyElement_cofactors PASSED       [ 62%]\nsympy/polys/tests/test_rings.py::test_PolyElement_gcd PASSED             [ 64%]\nsympy/polys/tests/test_rings.py::test_PolyElement_cancel PASSED          [ 65%]\nsympy/polys/tests/test_rings.py::test_PolyElement_max_norm PASSED        [ 67%]\nsympy/polys/tests/test_rings.py::test_PolyElement_l1_norm PASSED         [ 68%]\nsympy/polys/tests/test_rings.py::test_PolyElement_diff PASSED            [ 70%]\nsympy/polys/tests/test_rings.py::test_PolyElement___call__ PASSED        [ 71%]\nsympy/polys/tests/test_rings.py::test_PolyElement_evaluate PASSED        [ 73%]\nsympy/polys/tests/test_rings.py::test_PolyElement_subs PASSED            [ 75%]\nsympy/polys/tests/test_rings.py::test_PolyElement_compose PASSED         [ 76%]\nsympy/polys/tests/test_rings.py::test_PolyElement_is_ PASSED             [ 78%]\nsympy/polys/tests/test_rings.py::test_PolyElement_drop PASSED            [ 79%]\nsympy/polys/tests/test_rings.py::test_PolyElement_pdiv PASSED            [ 81%]\nsympy/polys/tests/test_rings.py::test_PolyElement_gcdex PASSED           [ 82%]\nsympy/polys/tests/test_rings.py::test_PolyElement_subresultants PASSED   [ 84%]\nsympy/polys/tests/test_rings.py::test_PolyElement_resultant PASSED       [ 85%]\nsympy/polys/tests/test_rings.py::test_PolyElement_discriminant PASSED    [ 87%]\nsympy/polys/tests/test_rings.py::test_PolyElement_decompose PASSED       [ 89%]\nsympy/polys/tests/test_rings.py::test_PolyElement_shift PASSED           [ 90%]\nsympy/polys/tests/test_rings.py::test_PolyElement_sturm PASSED           [ 92%]\nsympy/polys/tests/test_rings.py::test_PolyElement_gff_list PASSED        [ 93%]\nsympy/polys/tests/test_rings.py::test_PolyElement_sqf_norm PASSED        [ 95%]\nsympy/polys/tests/test_rings.py::test_PolyElement_sqf_list PASSED        [ 96%]\nsympy/polys/tests/test_rings.py::test_PolyElement_factor_list PASSED     [ 98%]\nsympy/polys/tests/test_rings.py::test_issue_21410 PASSED                 [100%]\n\n=================================== FAILURES ===================================\n___________________________ test_PolyElement_as_expr ___________________________\nsympy/polys/tests/test_rings.py:266: in test_PolyElement_as_expr\n    assert f.as_expr(U, V, W) == g\nE   assert 3*x**2*y - x*y*z + 7*z**3 + 1 == 3*u**2*v - u*v*w + 7*w**3 + 1\nE    +  where 3*x**2*y - x*y*z + 7*z**3 + 1 = as_expr(u, v, w)\nE    +    where as_expr = 3*x**2*y - x*y*z + 7*z**3 + 1.as_expr\n                                DO *NOT* COMMIT!                                \n========================= 1 failed, 63 passed in 1.27s =========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/polys/tests/test_rings.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/polys/tests/test_rings.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 64,
          "failed": 0,
          "errors": 0,
          "collected": 64,
          "duration": 8.07,
          "log_tail": "sympy/polys/tests/test_rings.py::test_PolyElement_tail_degree PASSED     [ 29%]\nsympy/polys/tests/test_rings.py::test_PolyElement_degrees PASSED         [ 31%]\nsympy/polys/tests/test_rings.py::test_PolyElement_tail_degrees PASSED    [ 32%]\nsympy/polys/tests/test_rings.py::test_PolyElement_coeff PASSED           [ 34%]\nsympy/polys/tests/test_rings.py::test_PolyElement_LC PASSED              [ 35%]\nsympy/polys/tests/test_rings.py::test_PolyElement_LM PASSED              [ 37%]\nsympy/polys/tests/test_rings.py::test_PolyElement_LT PASSED              [ 39%]\nsympy/polys/tests/test_rings.py::test_PolyElement_leading_monom PASSED   [ 40%]\nsympy/polys/tests/test_rings.py::test_PolyElement_leading_term PASSED    [ 42%]\nsympy/polys/tests/test_rings.py::test_PolyElement_terms PASSED           [ 43%]\nsympy/polys/tests/test_rings.py::test_PolyElement_monoms PASSED          [ 45%]\nsympy/polys/tests/test_rings.py::test_PolyElement_coeffs PASSED          [ 46%]\nsympy/polys/tests/test_rings.py::test_PolyElement___add__ PASSED         [ 48%]\nsympy/polys/tests/test_rings.py::test_PolyElement___sub__ PASSED         [ 50%]\nsympy/polys/tests/test_rings.py::test_PolyElement___mul__ PASSED         [ 51%]\nsympy/polys/tests/test_rings.py::test_PolyElement___truediv__ PASSED     [ 53%]\nsympy/polys/tests/test_rings.py::test_PolyElement___pow__ PASSED         [ 54%]\nsympy/polys/tests/test_rings.py::test_PolyElement_div PASSED             [ 56%]\nsympy/polys/tests/test_rings.py::test_PolyElement_rem PASSED             [ 57%]\nsympy/polys/tests/test_rings.py::test_PolyElement_deflate PASSED         [ 59%]\nsympy/polys/tests/test_rings.py::test_PolyElement_clear_denoms PASSED    [ 60%]\nsympy/polys/tests/test_rings.py::test_PolyElement_cofactors PASSED       [ 62%]\nsympy/polys/tests/test_rings.py::test_PolyElement_gcd PASSED             [ 64%]\nsympy/polys/tests/test_rings.py::test_PolyElement_cancel PASSED          [ 65%]\nsympy/polys/tests/test_rings.py::test_PolyElement_max_norm PASSED        [ 67%]\nsympy/polys/tests/test_rings.py::test_PolyElement_l1_norm PASSED         [ 68%]\nsympy/polys/tests/test_rings.py::test_PolyElement_diff PASSED            [ 70%]\nsympy/polys/tests/test_rings.py::test_PolyElement___call__ PASSED        [ 71%]\nsympy/polys/tests/test_rings.py::test_PolyElement_evaluate PASSED        [ 73%]\nsympy/polys/tests/test_rings.py::test_PolyElement_subs PASSED            [ 75%]\nsympy/polys/tests/test_rings.py::test_PolyElement_compose PASSED         [ 76%]\nsympy/polys/tests/test_rings.py::test_PolyElement_is_ PASSED             [ 78%]\nsympy/polys/tests/test_rings.py::test_PolyElement_drop PASSED            [ 79%]\nsympy/polys/tests/test_rings.py::test_PolyElement_pdiv PASSED            [ 81%]\nsympy/polys/tests/test_rings.py::test_PolyElement_gcdex PASSED           [ 82%]\nsympy/polys/tests/test_rings.py::test_PolyElement_subresultants PASSED   [ 84%]\nsympy/polys/tests/test_rings.py::test_PolyElement_resultant PASSED       [ 85%]\nsympy/polys/tests/test_rings.py::test_PolyElement_discriminant PASSED    [ 87%]\nsympy/polys/tests/test_rings.py::test_PolyElement_decompose PASSED       [ 89%]\nsympy/polys/tests/test_rings.py::test_PolyElement_shift PASSED           [ 90%]\nsympy/polys/tests/test_rings.py::test_PolyElement_sturm PASSED           [ 92%]\nsympy/polys/tests/test_rings.py::test_PolyElement_gff_list PASSED        [ 93%]\nsympy/polys/tests/test_rings.py::test_PolyElement_sqf_norm PASSED        [ 95%]\nsympy/polys/tests/test_rings.py::test_PolyElement_sqf_list PASSED        [ 96%]\nsympy/polys/tests/test_rings.py::test_PolyElement_factor_list PASSED     [ 98%]\nsympy/polys/tests/test_rings.py::test_issue_21410 PASSED                 [100%]\n\n============================== 64 passed in 1.00s ==============================\n\n",
          "test_files_run": [
            "sympy/polys/tests/test_rings.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-24562",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 23.956828832626343,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 106,
          "failed": 1,
          "errors": 0,
          "collected": 109,
          "duration": 12.86,
          "log_tail": "sympy/core/tests/test_numbers.py::test_bool_eq PASSED                    [ 72%]\nsympy/core/tests/test_numbers.py::test_Float_eq PASSED                   [ 73%]\nsympy/core/tests/test_numbers.py::test_issue_6640 PASSED                 [ 74%]\nsympy/core/tests/test_numbers.py::test_issue_6349 PASSED                 [ 75%]\nsympy/core/tests/test_numbers.py::test_mpf_norm PASSED                   [ 76%]\nsympy/core/tests/test_numbers.py::test_latex PASSED                      [ 77%]\nsympy/core/tests/test_numbers.py::test_issue_7742 PASSED                 [ 77%]\nsympy/core/tests/test_numbers.py::test_simplify_AlgebraicNumber PASSED   [ 78%]\nsympy/core/tests/test_numbers.py::test_Float_idempotence PASSED          [ 79%]\nsympy/core/tests/test_numbers.py::test_comp1 PASSED                      [ 80%]\nsympy/core/tests/test_numbers.py::test_issue_9491 PASSED                 [ 81%]\nsympy/core/tests/test_numbers.py::test_issue_10063 PASSED                [ 82%]\nsympy/core/tests/test_numbers.py::test_issue_10020 PASSED                [ 83%]\nsympy/core/tests/test_numbers.py::test_invert_numbers PASSED             [ 84%]\nsympy/core/tests/test_numbers.py::test_mod_inverse PASSED                [ 85%]\nsympy/core/tests/test_numbers.py::test_golden_ratio_rewrite_as_sqrt PASSED [ 86%]\nsympy/core/tests/test_numbers.py::test_tribonacci_constant_rewrite_as_sqrt PASSED [ 87%]\nsympy/core/tests/test_numbers.py::test_comparisons_with_unknown_type PASSED [ 88%]\nsympy/core/tests/test_numbers.py::test_NumberSymbol_comparison PASSED    [ 88%]\nsympy/core/tests/test_numbers.py::test_Integer_precision PASSED          [ 89%]\nsympy/core/tests/test_numbers.py::test_numpy_to_float SKIPPED (numpy...) [ 90%]\nsympy/core/tests/test_numbers.py::test_Integer_ceiling_floor PASSED      [ 91%]\nsympy/core/tests/test_numbers.py::test_ComplexInfinity PASSED            [ 92%]\nsympy/core/tests/test_numbers.py::test_Infinity_floor_ceiling_power PASSED [ 93%]\nsympy/core/tests/test_numbers.py::test_One_power PASSED                  [ 94%]\nsympy/core/tests/test_numbers.py::test_NegativeInfinity PASSED           [ 95%]\nsympy/core/tests/test_numbers.py::test_issue_6133 PASSED                 [ 96%]\nsympy/core/tests/test_numbers.py::test_abc PASSED                        [ 97%]\nsympy/core/tests/test_numbers.py::test_floordiv PASSED                   [ 98%]\nsympy/core/tests/test_numbers.py::test_negation PASSED                   [ 99%]\nsympy/core/tests/test_numbers.py::test_exponentiation_of_0 PASSED        [100%]\n\n=================================== FAILURES ===================================\n_______________________________ test_issue_24543 _______________________________\nsympy/core/tests/test_numbers.py:375: in test_issue_24543\n    assert Rational(p, q).as_numer_denom() == Rational('%s/%s'%(p,q)).as_numer_denom()\nsympy/core/cache.py:72: in wrapper\n    retval = cfunc(*args, **kwargs)\nsympy/core/numbers.py:1636: in __new__\n    q = Rational(q)\nsympy/core/cache.py:72: in wrapper\n    retval = cfunc(*args, **kwargs)\nsympy/core/numbers.py:1623: in __new__\n    raise TypeError('invalid input: %s' % p)\nE   TypeError: invalid input: 1.51.5\n                                DO *NOT* COMMIT!                                \n============= 1 failed, 106 passed, 1 skipped, 1 xfailed in 4.15s ==============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/core/tests/test_numbers.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/core/tests/test_numbers.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 107,
          "failed": 0,
          "errors": 0,
          "collected": 109,
          "duration": 10.11,
          "log_tail": "sympy/core/tests/test_numbers.py::test_issue_4611 PASSED                 [ 58%]\nsympy/core/tests/test_numbers.py::test_conversion_to_mpmath PASSED       [ 59%]\nsympy/core/tests/test_numbers.py::test_relational PASSED                 [ 60%]\nsympy/core/tests/test_numbers.py::test_Integer_as_index PASSED           [ 61%]\nsympy/core/tests/test_numbers.py::test_Rational_int PASSED               [ 62%]\nsympy/core/tests/test_numbers.py::test_zoo PASSED                        [ 63%]\nsympy/core/tests/test_numbers.py::test_issue_4122 PASSED                 [ 64%]\nsympy/core/tests/test_numbers.py::test_GoldenRatio_expand PASSED         [ 65%]\nsympy/core/tests/test_numbers.py::test_TribonacciConstant_expand PASSED  [ 66%]\nsympy/core/tests/test_numbers.py::test_as_content_primitive PASSED       [ 66%]\nsympy/core/tests/test_numbers.py::test_hashing_sympy_integers PASSED     [ 67%]\nsympy/core/tests/test_numbers.py::test_rounding_issue_4172 PASSED        [ 68%]\nsympy/core/tests/test_numbers.py::test_mpmath_issues XFAIL               [ 69%]\nsympy/core/tests/test_numbers.py::test_Catalan_EulerGamma_prec PASSED    [ 70%]\nsympy/core/tests/test_numbers.py::test_Catalan_rewrite PASSED            [ 71%]\nsympy/core/tests/test_numbers.py::test_bool_eq PASSED                    [ 72%]\nsympy/core/tests/test_numbers.py::test_Float_eq PASSED                   [ 73%]\nsympy/core/tests/test_numbers.py::test_issue_6640 PASSED                 [ 74%]\nsympy/core/tests/test_numbers.py::test_issue_6349 PASSED                 [ 75%]\nsympy/core/tests/test_numbers.py::test_mpf_norm PASSED                   [ 76%]\nsympy/core/tests/test_numbers.py::test_latex PASSED                      [ 77%]\nsympy/core/tests/test_numbers.py::test_issue_7742 PASSED                 [ 77%]\nsympy/core/tests/test_numbers.py::test_simplify_AlgebraicNumber PASSED   [ 78%]\nsympy/core/tests/test_numbers.py::test_Float_idempotence PASSED          [ 79%]\nsympy/core/tests/test_numbers.py::test_comp1 PASSED                      [ 80%]\nsympy/core/tests/test_numbers.py::test_issue_9491 PASSED                 [ 81%]\nsympy/core/tests/test_numbers.py::test_issue_10063 PASSED                [ 82%]\nsympy/core/tests/test_numbers.py::test_issue_10020 PASSED                [ 83%]\nsympy/core/tests/test_numbers.py::test_invert_numbers PASSED             [ 84%]\nsympy/core/tests/test_numbers.py::test_mod_inverse PASSED                [ 85%]\nsympy/core/tests/test_numbers.py::test_golden_ratio_rewrite_as_sqrt PASSED [ 86%]\nsympy/core/tests/test_numbers.py::test_tribonacci_constant_rewrite_as_sqrt PASSED [ 87%]\nsympy/core/tests/test_numbers.py::test_comparisons_with_unknown_type PASSED [ 88%]\nsympy/core/tests/test_numbers.py::test_NumberSymbol_comparison PASSED    [ 88%]\nsympy/core/tests/test_numbers.py::test_Integer_precision PASSED          [ 89%]\nsympy/core/tests/test_numbers.py::test_numpy_to_float SKIPPED (numpy...) [ 90%]\nsympy/core/tests/test_numbers.py::test_Integer_ceiling_floor PASSED      [ 91%]\nsympy/core/tests/test_numbers.py::test_ComplexInfinity PASSED            [ 92%]\nsympy/core/tests/test_numbers.py::test_Infinity_floor_ceiling_power PASSED [ 93%]\nsympy/core/tests/test_numbers.py::test_One_power PASSED                  [ 94%]\nsympy/core/tests/test_numbers.py::test_NegativeInfinity PASSED           [ 95%]\nsympy/core/tests/test_numbers.py::test_issue_6133 PASSED                 [ 96%]\nsympy/core/tests/test_numbers.py::test_abc PASSED                        [ 97%]\nsympy/core/tests/test_numbers.py::test_floordiv PASSED                   [ 98%]\nsympy/core/tests/test_numbers.py::test_negation PASSED                   [ 99%]\nsympy/core/tests/test_numbers.py::test_exponentiation_of_0 PASSED        [100%]\n\n================== 107 passed, 1 skipped, 1 xfailed in 3.54s ===================\n\n",
          "test_files_run": [
            "sympy/core/tests/test_numbers.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-24661",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 17.84975504875183,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 28,
          "failed": 1,
          "errors": 0,
          "collected": 29,
          "duration": 9.33,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 29 items\n\nsympy/parsing/tests/test_sympy_parser.py::test_sympy_parser PASSED       [  3%]\nsympy/parsing/tests/test_sympy_parser.py::test_rationalize PASSED        [  6%]\nsympy/parsing/tests/test_sympy_parser.py::test_factorial_fail PASSED     [ 10%]\nsympy/parsing/tests/test_sympy_parser.py::test_repeated_fail PASSED      [ 13%]\nsympy/parsing/tests/test_sympy_parser.py::test_repeated_dot_only PASSED  [ 17%]\nsympy/parsing/tests/test_sympy_parser.py::test_local_dict PASSED         [ 20%]\nsympy/parsing/tests/test_sympy_parser.py::test_local_dict_split_implmult PASSED [ 24%]\nsympy/parsing/tests/test_sympy_parser.py::test_local_dict_symbol_to_fcn PASSED [ 27%]\nsympy/parsing/tests/test_sympy_parser.py::test_global_dict PASSED        [ 31%]\nsympy/parsing/tests/test_sympy_parser.py::test_no_globals PASSED         [ 34%]\nsympy/parsing/tests/test_sympy_parser.py::test_issue_2515 PASSED         [ 37%]\nsympy/parsing/tests/test_sympy_parser.py::test_issue_7663 PASSED         [ 41%]\nsympy/parsing/tests/test_sympy_parser.py::test_recursive_evaluate_false_10560 PASSED [ 44%]\nsympy/parsing/tests/test_sympy_parser.py::test_function_evaluate_false PASSED [ 48%]\nsympy/parsing/tests/test_sympy_parser.py::test_issue_10773 PASSED        [ 51%]\nsympy/parsing/tests/test_sympy_parser.py::test_split_symbols PASSED      [ 55%]\nsympy/parsing/tests/test_sympy_parser.py::test_split_symbols_function PASSED [ 58%]\nsympy/parsing/tests/test_sympy_parser.py::test_functional_exponent PASSED [ 62%]\nsympy/parsing/tests/test_sympy_parser.py::test_match_parentheses_implicit_multiplication PASSED [ 65%]\nsympy/parsing/tests/test_sympy_parser.py::test_convert_equals_signs PASSED [ 68%]\nsympy/parsing/tests/test_sympy_parser.py::test_parse_function_issue_3539 PASSED [ 72%]\nsympy/parsing/tests/test_sympy_parser.py::test_issue_24288 FAILED        [ 75%]\nsympy/parsing/tests/test_sympy_parser.py::test_split_symbols_numeric PASSED [ 79%]\nsympy/parsing/tests/test_sympy_parser.py::test_unicode_names PASSED      [ 82%]\nsympy/parsing/tests/test_sympy_parser.py::test_python3_features PASSED   [ 86%]\nsympy/parsing/tests/test_sympy_parser.py::test_issue_19501 PASSED        [ 89%]\nsympy/parsing/tests/test_sympy_parser.py::test_parsing_definitions PASSED [ 93%]\nsympy/parsing/tests/test_sympy_parser.py::test_builtins PASSED           [ 96%]\nsympy/parsing/tests/test_sympy_parser.py::test_issue_22822 PASSED        [100%]\n\n=================================== FAILURES ===================================\n_______________________________ test_issue_24288 _______________________________\nsympy/parsing/tests/test_sympy_parser.py:292: in test_issue_24288\n    assert parse_expr(text, evaluate=False) == result\nE   AssertionError: assert True == 1 < 2\nE    +  where True = parse_expr('1 < 2', evaluate=False)\n                                DO *NOT* COMMIT!                                \n========================= 1 failed, 28 passed in 0.71s =========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/parsing/tests/test_sympy_parser.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/parsing/tests/test_sympy_parser.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 29,
          "failed": 0,
          "errors": 0,
          "collected": 29,
          "duration": 7.4,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 29 items\n\nsympy/parsing/tests/test_sympy_parser.py::test_sympy_parser PASSED       [  3%]\nsympy/parsing/tests/test_sympy_parser.py::test_rationalize PASSED        [  6%]\nsympy/parsing/tests/test_sympy_parser.py::test_factorial_fail PASSED     [ 10%]\nsympy/parsing/tests/test_sympy_parser.py::test_repeated_fail PASSED      [ 13%]\nsympy/parsing/tests/test_sympy_parser.py::test_repeated_dot_only PASSED  [ 17%]\nsympy/parsing/tests/test_sympy_parser.py::test_local_dict PASSED         [ 20%]\nsympy/parsing/tests/test_sympy_parser.py::test_local_dict_split_implmult PASSED [ 24%]\nsympy/parsing/tests/test_sympy_parser.py::test_local_dict_symbol_to_fcn PASSED [ 27%]\nsympy/parsing/tests/test_sympy_parser.py::test_global_dict PASSED        [ 31%]\nsympy/parsing/tests/test_sympy_parser.py::test_no_globals PASSED         [ 34%]\nsympy/parsing/tests/test_sympy_parser.py::test_issue_2515 PASSED         [ 37%]\nsympy/parsing/tests/test_sympy_parser.py::test_issue_7663 PASSED         [ 41%]\nsympy/parsing/tests/test_sympy_parser.py::test_recursive_evaluate_false_10560 PASSED [ 44%]\nsympy/parsing/tests/test_sympy_parser.py::test_function_evaluate_false PASSED [ 48%]\nsympy/parsing/tests/test_sympy_parser.py::test_issue_10773 PASSED        [ 51%]\nsympy/parsing/tests/test_sympy_parser.py::test_split_symbols PASSED      [ 55%]\nsympy/parsing/tests/test_sympy_parser.py::test_split_symbols_function PASSED [ 58%]\nsympy/parsing/tests/test_sympy_parser.py::test_functional_exponent PASSED [ 62%]\nsympy/parsing/tests/test_sympy_parser.py::test_match_parentheses_implicit_multiplication PASSED [ 65%]\nsympy/parsing/tests/test_sympy_parser.py::test_convert_equals_signs PASSED [ 68%]\nsympy/parsing/tests/test_sympy_parser.py::test_parse_function_issue_3539 PASSED [ 72%]\nsympy/parsing/tests/test_sympy_parser.py::test_issue_24288 PASSED        [ 75%]\nsympy/parsing/tests/test_sympy_parser.py::test_split_symbols_numeric PASSED [ 79%]\nsympy/parsing/tests/test_sympy_parser.py::test_unicode_names PASSED      [ 82%]\nsympy/parsing/tests/test_sympy_parser.py::test_python3_features PASSED   [ 86%]\nsympy/parsing/tests/test_sympy_parser.py::test_issue_19501 PASSED        [ 89%]\nsympy/parsing/tests/test_sympy_parser.py::test_parsing_definitions PASSED [ 93%]\nsympy/parsing/tests/test_sympy_parser.py::test_builtins PASSED           [ 96%]\nsympy/parsing/tests/test_sympy_parser.py::test_issue_22822 PASSED        [100%]\n\n============================== 29 passed in 0.57s ==============================\n\n",
          "test_files_run": [
            "sympy/parsing/tests/test_sympy_parser.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "matplotlib__matplotlib-13989",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://34.41.233.120:8080",
      "error": "HTTPConnectionPool(host='34.41.233.120', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "matplotlib__matplotlib-14623",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://34.41.233.120:8080",
      "error": "HTTPConnectionPool(host='34.41.233.120', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "matplotlib__matplotlib-20488",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://34.41.233.120:8080",
      "duration": 45.52655792236328,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 111,
          "failed": 10,
          "errors": 0,
          "collected": 140,
          "duration": 21.55,
          "log_tail": "    return self._comparison(other, operator.gt)\n/opt/miniconda3/envs/testbed/lib/python3.8/site-packages/numpy/ma/core.py:4123: in _comparison\n    check = compare(sdata, odata)\nlib/matplotlib/tests/test_image.py:1200: in __array_ufunc__\n    raise NotImplementedError\nE   NotImplementedError\n_________________________ test_huge_range_log[png--1] __________________________\nlib/matplotlib/testing/decorators.py:443: in wrapper\n    fig_test.savefig(test_image_path)\nlib/matplotlib/figure.py:2969: in savefig\n    self.canvas.print_figure(fname, **kwargs)\nlib/matplotlib/backend_bases.py:2297: in print_figure\n    result = print_method(\nlib/matplotlib/backend_bases.py:1650: in wrapper\n    return func(*args, **kwargs)\nlib/matplotlib/_api/deprecation.py:449: in wrapper\n    return func(*inner_args, **inner_kwargs)\nlib/matplotlib/backends/backend_agg.py:491: in print_png\n    FigureCanvasAgg.draw(self)\nlib/matplotlib/backends/backend_agg.py:387: in draw\n    self.figure.draw(self.renderer)\nlib/matplotlib/artist.py:71: in draw_wrapper\n    result = draw(artist, renderer, *args, **kwargs)\nlib/matplotlib/artist.py:48: in draw_wrapper\n    return draw(artist, renderer)\nlib/matplotlib/figure.py:2754: in draw\n    mimage._draw_list_compositing_images(\nlib/matplotlib/image.py:132: in _draw_list_compositing_images\n    a.draw(renderer)\nlib/matplotlib/artist.py:48: in draw_wrapper\n    return draw(artist, renderer)\nlib/matplotlib/axes/_base.py:3074: in draw\n    mimage._draw_list_compositing_images(\nlib/matplotlib/image.py:132: in _draw_list_compositing_images\n    a.draw(renderer)\nlib/matplotlib/artist.py:48: in draw_wrapper\n    return draw(artist, renderer)\nlib/matplotlib/image.py:638: in draw\n    im, l, b, trans = self.make_image(\nlib/matplotlib/image.py:924: in make_image\n    return self._make_image(self._A, bbox, transformed_bbox, clip,\nlib/matplotlib/image.py:542: in _make_image\n    output = self.norm(resampled_masked)\nlib/matplotlib/colors.py:1477: in __call__\n    raise ValueError(\"Invalid vmin or vmax\")\nE   ValueError: Invalid vmin or vmax\n================= 10 failed, 111 passed, 19 skipped in 18.60s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_image.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_image.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 112,
          "failed": 9,
          "errors": 0,
          "collected": 140,
          "duration": 22.45,
          "log_tail": "    \tresult_images/test_image/bbox_image_inverted_pdf-failed-diff.png\nAll traceback entries are hidden. Pass `--full-trace` to see hidden and internal frames.\n_____________________________ test_mask_image[pdf] _____________________________\nE   matplotlib.testing.exceptions.ImageComparisonFailure: images not close (RMS 7.745):\n    \tresult_images/test_image/mask_image_pdf.png\n    \tresult_images/test_image/mask_image-expected_pdf.png\n    \tresult_images/test_image/mask_image_pdf-failed-diff.png\nAll traceback entries are hidden. Pass `--full-trace` to see hidden and internal frames.\n______________________________ test_full_invalid _______________________________\nlib/matplotlib/tests/test_image.py:1021: in test_full_invalid\n    fig.canvas.draw()\nE   DeprecationWarning: Passing `np.nan` to mean no clipping in np.clip has always been unreliable, and is now deprecated. In future, this will always return nan, like it already does when min or max are arrays that contain nan. To skip a bound, pass either None or an np.inf of an appropriate sign.\n____________________________ test_imshow_quantitynd ____________________________\nlib/matplotlib/tests/test_image.py:1233: in test_imshow_quantitynd\n    fig.canvas.draw()\nlib/matplotlib/backends/backend_agg.py:387: in draw\n    self.figure.draw(self.renderer)\nlib/matplotlib/artist.py:71: in draw_wrapper\n    result = draw(artist, renderer, *args, **kwargs)\nlib/matplotlib/artist.py:48: in draw_wrapper\n    return draw(artist, renderer)\nlib/matplotlib/figure.py:2754: in draw\n    mimage._draw_list_compositing_images(\nlib/matplotlib/image.py:132: in _draw_list_compositing_images\n    a.draw(renderer)\nlib/matplotlib/artist.py:48: in draw_wrapper\n    return draw(artist, renderer)\nlib/matplotlib/axes/_base.py:3074: in draw\n    mimage._draw_list_compositing_images(\nlib/matplotlib/image.py:132: in _draw_list_compositing_images\n    a.draw(renderer)\nlib/matplotlib/artist.py:48: in draw_wrapper\n    return draw(artist, renderer)\nlib/matplotlib/image.py:638: in draw\n    im, l, b, trans = self.make_image(\nlib/matplotlib/image.py:924: in make_image\n    return self._make_image(self._A, bbox, transformed_bbox, clip,\nlib/matplotlib/image.py:445: in _make_image\n    if newmin < a_min:\n/opt/miniconda3/envs/testbed/lib/python3.8/site-packages/numpy/ma/core.py:4191: in __gt__\n    return self._comparison(other, operator.gt)\n/opt/miniconda3/envs/testbed/lib/python3.8/site-packages/numpy/ma/core.py:4123: in _comparison\n    check = compare(sdata, odata)\nlib/matplotlib/tests/test_image.py:1200: in __array_ufunc__\n    raise NotImplementedError\nE   NotImplementedError\n================== 9 failed, 112 passed, 19 skipped in 18.63s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_image.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_image.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "matplotlib__matplotlib-20676",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://34.41.233.120:8080",
      "duration": 29.068162202835083,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 32,
          "failed": 3,
          "errors": 0,
          "collected": 36,
          "duration": 12.56,
          "log_tail": "lib/matplotlib/tests/test_widgets.py::test_range_slider[vertical] PASSED [ 66%]\nlib/matplotlib/tests/test_widgets.py::test_polygon_selector PASSED       [ 69%]\nlib/matplotlib/tests/test_widgets.py::test_MultiCursor[True-True] PASSED [ 72%]\nlib/matplotlib/tests/test_widgets.py::test_MultiCursor[True-False] PASSED [ 75%]\nlib/matplotlib/tests/test_widgets.py::test_MultiCursor[False-True] PASSED [ 77%]\nlib/matplotlib/tests/test_widgets.py::test_rect_visibility[png] PASSED   [ 80%]\nlib/matplotlib/tests/test_widgets.py::test_rect_visibility[pdf] PASSED   [ 83%]\nlib/matplotlib/tests/test_widgets.py::test_rect_visibility[svg] SKIPPED  [ 86%]\nlib/matplotlib/tests/test_widgets.py::test_polygon_selector_remove[1] PASSED [ 88%]\nlib/matplotlib/tests/test_widgets.py::test_polygon_selector_remove[2] PASSED [ 91%]\nlib/matplotlib/tests/test_widgets.py::test_polygon_selector_remove[3] PASSED [ 94%]\nlib/matplotlib/tests/test_widgets.py::test_polygon_selector_remove_first_point PASSED [ 97%]\nlib/matplotlib/tests/test_widgets.py::test_polygon_selector_redraw PASSED [100%]\n\n=================================== FAILURES ===================================\n___________________________ test_rectangle_selector ____________________________\nlib/matplotlib/tests/test_widgets.py:45: in test_rectangle_selector\n    check_rectangle(drawtype='line', useblit=False)\nE   matplotlib._api.deprecation.MatplotlibDeprecationWarning: \nE   The 'drawtype' parameter of __init__() was deprecated in Matplotlib 3.5 and will be removed two minor releases later. If any parameter follows 'drawtype', they should be passed as keyword, not positionally.\n_____________________ test_span_selector_bound[horizontal] _____________________\nlib/matplotlib/tests/test_widgets.py:314: in test_span_selector_bound\n    assert ax.get_xbound() == x_bound\nE   AssertionError: assert (0.0, 20.0) == (10.0, 20.0)\nE     \nE     At index 0 diff: 0.0 != 10.0\nE     \nE     Full diff:\nE       (\nE     -     10.0,\nE     ?     -...\nE     \nE     ...Full output truncated (3 lines hidden), use '-vv' to show\n______________________ test_span_selector_bound[vertical] ______________________\nlib/matplotlib/tests/test_widgets.py:315: in test_span_selector_bound\n    assert ax.get_ybound() == y_bound\nE   AssertionError: assert (0.0, 30.0) == (10.0, 30.0)\nE     \nE     At index 0 diff: 0.0 != 10.0\nE     \nE     Full diff:\nE       (\nE     -     10.0,\nE     ?     -...\nE     \nE     ...Full output truncated (3 lines hidden), use '-vv' to show\n=================== 3 failed, 32 passed, 1 skipped in 9.63s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_widgets.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_widgets.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 34,
          "failed": 1,
          "errors": 0,
          "collected": 36,
          "duration": 15.45,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 36 items\n\nlib/matplotlib/tests/test_widgets.py::test_rectangle_selector FAILED     [  2%]\nlib/matplotlib/tests/test_widgets.py::test_rectangle_drag[True-new_center0] PASSED [  5%]\nlib/matplotlib/tests/test_widgets.py::test_rectangle_drag[False-new_center1] PASSED [  8%]\nlib/matplotlib/tests/test_widgets.py::test_ellipse PASSED                [ 11%]\nlib/matplotlib/tests/test_widgets.py::test_rectangle_handles PASSED      [ 13%]\nlib/matplotlib/tests/test_widgets.py::test_span_selector PASSED          [ 16%]\nlib/matplotlib/tests/test_widgets.py::test_span_selector_drag[True] PASSED [ 19%]\nlib/matplotlib/tests/test_widgets.py::test_span_selector_drag[False] PASSED [ 22%]\nlib/matplotlib/tests/test_widgets.py::test_span_selector_direction PASSED [ 25%]\nlib/matplotlib/tests/test_widgets.py::test_tool_line_handle PASSED       [ 27%]\nlib/matplotlib/tests/test_widgets.py::test_span_selector_bound[horizontal] PASSED [ 30%]\nlib/matplotlib/tests/test_widgets.py::test_span_selector_bound[vertical] PASSED [ 33%]\nlib/matplotlib/tests/test_widgets.py::test_lasso_selector PASSED         [ 36%]\nlib/matplotlib/tests/test_widgets.py::test_CheckButtons PASSED           [ 38%]\nlib/matplotlib/tests/test_widgets.py::test_TextBox PASSED                [ 41%]\nlib/matplotlib/tests/test_widgets.py::test_check_radio_buttons_image[png] PASSED [ 44%]\nlib/matplotlib/tests/test_widgets.py::test_check_bunch_of_radio_buttons[png] PASSED [ 47%]\nlib/matplotlib/tests/test_widgets.py::test_slider_slidermin_slidermax_invalid PASSED [ 50%]\nlib/matplotlib/tests/test_widgets.py::test_slider_slidermin_slidermax PASSED [ 52%]\nlib/matplotlib/tests/test_widgets.py::test_slider_valmin_valmax PASSED   [ 55%]\nlib/matplotlib/tests/test_widgets.py::test_slider_valstep_snapping PASSED [ 58%]\nlib/matplotlib/tests/test_widgets.py::test_slider_horizontal_vertical PASSED [ 61%]\nlib/matplotlib/tests/test_widgets.py::test_range_slider[horizontal] PASSED [ 63%]\nlib/matplotlib/tests/test_widgets.py::test_range_slider[vertical] PASSED [ 66%]\nlib/matplotlib/tests/test_widgets.py::test_polygon_selector PASSED       [ 69%]\nlib/matplotlib/tests/test_widgets.py::test_MultiCursor[True-True] PASSED [ 72%]\nlib/matplotlib/tests/test_widgets.py::test_MultiCursor[True-False] PASSED [ 75%]\nlib/matplotlib/tests/test_widgets.py::test_MultiCursor[False-True] PASSED [ 77%]\nlib/matplotlib/tests/test_widgets.py::test_rect_visibility[png] PASSED   [ 80%]\nlib/matplotlib/tests/test_widgets.py::test_rect_visibility[pdf] PASSED   [ 83%]\nlib/matplotlib/tests/test_widgets.py::test_rect_visibility[svg] SKIPPED  [ 86%]\nlib/matplotlib/tests/test_widgets.py::test_polygon_selector_remove[1] PASSED [ 88%]\nlib/matplotlib/tests/test_widgets.py::test_polygon_selector_remove[2] PASSED [ 91%]\nlib/matplotlib/tests/test_widgets.py::test_polygon_selector_remove[3] PASSED [ 94%]\nlib/matplotlib/tests/test_widgets.py::test_polygon_selector_remove_first_point PASSED [ 97%]\nlib/matplotlib/tests/test_widgets.py::test_polygon_selector_redraw PASSED [100%]\n\n=================================== FAILURES ===================================\n___________________________ test_rectangle_selector ____________________________\nlib/matplotlib/tests/test_widgets.py:45: in test_rectangle_selector\n    check_rectangle(drawtype='line', useblit=False)\nE   matplotlib._api.deprecation.MatplotlibDeprecationWarning: \nE   The 'drawtype' parameter of __init__() was deprecated in Matplotlib 3.5 and will be removed two minor releases later. If any parameter follows 'drawtype', they should be passed as keyword, not positionally.\n=================== 1 failed, 34 passed, 1 skipped in 11.68s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_widgets.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_widgets.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "matplotlib__matplotlib-20826",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://34.41.233.120:8080",
      "error": "HTTPConnectionPool(host='34.41.233.120', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "matplotlib__matplotlib-20859",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://34.41.233.120:8080",
      "error": "HTTPConnectionPool(host='34.41.233.120', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "matplotlib__matplotlib-21568",
      "repo": "matplotlib/matplotlib",
      "valid": true,
      "worker": "http://34.41.233.120:8080",
      "duration": 26.12481117248535,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 73,
          "failed": 4,
          "errors": 0,
          "collected": 77,
          "duration": 11.43,
          "log_tail": "E     \nE     Full diff:\nE       [\nE     -     '$\\\\mathdefault{01{-}01\\\\;00}$',\nE     ?                            ^^^...\nE     \nE     ...Full output truncated (43 lines hidden), use '-vv' to show\n_________________ test_date_formatter_usetex[delta3-expected3] _________________\nlib/matplotlib/tests/test_dates.py:345: in test_date_formatter_usetex\n    assert [formatter(loc) for loc in locator()] == expected\nE   AssertionError: assert ['$\\\\mathdefa...00:05}$', ...] == ['$\\\\mathdefa...{:}05}$', ...]\nE     \nE     At index 0 diff: '$\\\\mathdefault{01 00:00}$' != '$\\\\mathdefault{01\\\\;00{:}00}$'\nE     \nE     Full diff:\nE       [\nE     -     '$\\\\mathdefault{01\\\\;00{:}00}$',\nE     ?                       ^^^  - -...\nE     \nE     ...Full output truncated (43 lines hidden), use '-vv' to show\n______________ test_concise_formatter_usetex[t_delta2-expected2] _______________\nlib/matplotlib/tests/test_dates.py:637: in test_concise_formatter_usetex\n    assert formatter.format_ticks(locator()) == expected\nE   AssertionError: assert ['Jan$\\\\mathd...20:00}$', ...] == ['Jan$\\\\mathd...{:}00}$', ...]\nE     \nE     At index 1 diff: '$\\\\mathdefault{04:00}$' != '$\\\\mathdefault{04{:}00}$'\nE     \nE     Full diff:\nE       [\nE           'Jan$\\\\mathdefault{{-}01}$',\nE     -     '$\\\\mathdefault{04{:}00}$',...\nE     \nE     ...Full output truncated (28 lines hidden), use '-vv' to show\n______________ test_concise_formatter_usetex[t_delta3-expected3] _______________\nlib/matplotlib/tests/test_dates.py:637: in test_concise_formatter_usetex\n    assert formatter.format_ticks(locator()) == expected\nE   AssertionError: assert ['$\\\\mathdefa...{02.0}$', ...] == ['$\\\\mathdefa...{02.0}$', ...]\nE     \nE     At index 1 diff: '$\\\\mathdefault{00:00}$' != '$\\\\mathdefault{00{:}00}$'\nE     \nE     Full diff:\nE       [\nE           '$\\\\mathdefault{59.5}$',\nE     -     '$\\\\mathdefault{00{:}00}$',...\nE     \nE     ...Full output truncated (8 lines hidden), use '-vv' to show\n========================= 4 failed, 73 passed in 8.44s =========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_dates.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_dates.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 77,
          "failed": 0,
          "errors": 0,
          "collected": 77,
          "duration": 13.13,
          "log_tail": "lib/matplotlib/tests/test_dates.py::test_RRuleLocator_close_minmax PASSED [ 41%]\nlib/matplotlib/tests/test_dates.py::test_DateFormatter[png] PASSED       [ 42%]\nlib/matplotlib/tests/test_dates.py::test_locator_set_formatter PASSED    [ 44%]\nlib/matplotlib/tests/test_dates.py::test_date_formatter_callable PASSED  [ 45%]\nlib/matplotlib/tests/test_dates.py::test_date_formatter_usetex[delta0-expected0] PASSED [ 46%]\nlib/matplotlib/tests/test_dates.py::test_date_formatter_usetex[delta1-expected1] PASSED [ 48%]\nlib/matplotlib/tests/test_dates.py::test_date_formatter_usetex[delta2-expected2] PASSED [ 49%]\nlib/matplotlib/tests/test_dates.py::test_date_formatter_usetex[delta3-expected3] PASSED [ 50%]\nlib/matplotlib/tests/test_dates.py::test_drange PASSED                   [ 51%]\nlib/matplotlib/tests/test_dates.py::test_auto_date_locator PASSED        [ 53%]\nlib/matplotlib/tests/test_dates.py::test_auto_date_locator_intmult PASSED [ 54%]\nlib/matplotlib/tests/test_dates.py::test_concise_formatter_subsecond PASSED [ 55%]\nlib/matplotlib/tests/test_dates.py::test_concise_formatter PASSED        [ 57%]\nlib/matplotlib/tests/test_dates.py::test_concise_formatter_show_offset[t_delta0-1997-Jan-01 00:00] PASSED [ 58%]\nlib/matplotlib/tests/test_dates.py::test_concise_formatter_show_offset[t_delta1-1997-Jan-01 00:01] PASSED [ 59%]\nlib/matplotlib/tests/test_dates.py::test_concise_formatter_show_offset[t_delta2-1997-Jan-01] PASSED [ 61%]\nlib/matplotlib/tests/test_dates.py::test_concise_formatter_show_offset[t_delta3-1997-Jan-02] PASSED [ 62%]\nlib/matplotlib/tests/test_dates.py::test_concise_formatter_show_offset[t_delta4-1997-Jan] PASSED [ 63%]\nlib/matplotlib/tests/test_dates.py::test_concise_formatter_show_offset[t_delta5-] PASSED [ 64%]\nlib/matplotlib/tests/test_dates.py::test_concise_formatter_show_offset[t_delta6-] PASSED [ 66%]\nlib/matplotlib/tests/test_dates.py::test_concise_formatter_usetex[t_delta0-expected0] PASSED [ 67%]\nlib/matplotlib/tests/test_dates.py::test_concise_formatter_usetex[t_delta1-expected1] PASSED [ 68%]\nlib/matplotlib/tests/test_dates.py::test_concise_formatter_usetex[t_delta2-expected2] PASSED [ 70%]\nlib/matplotlib/tests/test_dates.py::test_concise_formatter_usetex[t_delta3-expected3] PASSED [ 71%]\nlib/matplotlib/tests/test_dates.py::test_concise_formatter_formats PASSED [ 72%]\nlib/matplotlib/tests/test_dates.py::test_concise_formatter_zformats PASSED [ 74%]\nlib/matplotlib/tests/test_dates.py::test_concise_formatter_tz PASSED     [ 75%]\nlib/matplotlib/tests/test_dates.py::test_auto_date_locator_intmult_tz PASSED [ 76%]\nlib/matplotlib/tests/test_dates.py::test_date_inverted_limit[png] PASSED [ 77%]\nlib/matplotlib/tests/test_dates.py::test_date2num_dst PASSED             [ 79%]\nlib/matplotlib/tests/test_dates.py::test_date2num_dst_pandas PASSED      [ 80%]\nlib/matplotlib/tests/test_dates.py::test_rrulewrapper PASSED             [ 81%]\nlib/matplotlib/tests/test_dates.py::test_rrulewrapper_pytz PASSED        [ 83%]\nlib/matplotlib/tests/test_dates.py::test_yearlocator_pytz PASSED         [ 84%]\nlib/matplotlib/tests/test_dates.py::test_YearLocator PASSED              [ 85%]\nlib/matplotlib/tests/test_dates.py::test_DayLocator PASSED               [ 87%]\nlib/matplotlib/tests/test_dates.py::test_tz_utc PASSED                   [ 88%]\nlib/matplotlib/tests/test_dates.py::test_num2timedelta[1-tdelta0] PASSED [ 89%]\nlib/matplotlib/tests/test_dates.py::test_num2timedelta[x1-tdelta1] PASSED [ 90%]\nlib/matplotlib/tests/test_dates.py::test_datetime64_in_list PASSED       [ 92%]\nlib/matplotlib/tests/test_dates.py::test_change_epoch PASSED             [ 93%]\nlib/matplotlib/tests/test_dates.py::test_warn_notintervals PASSED        [ 94%]\nlib/matplotlib/tests/test_dates.py::test_change_converter PASSED         [ 96%]\nlib/matplotlib/tests/test_dates.py::test_change_interval_multiples PASSED [ 97%]\nlib/matplotlib/tests/test_dates.py::test_epoch2num PASSED                [ 98%]\nlib/matplotlib/tests/test_dates.py::test_julian2num PASSED               [100%]\n\n============================== 77 passed in 9.62s ==============================\n\n",
          "test_files_run": [
            "lib/matplotlib/tests/test_dates.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "matplotlib__matplotlib-22719",
      "repo": "matplotlib/matplotlib",
      "valid": true,
      "worker": "http://34.41.233.120:8080",
      "duration": 21.715234994888306,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 89,
          "failed": 1,
          "errors": 0,
          "collected": 98,
          "duration": 9.7,
          "log_tail": "lib/matplotlib/tests/test_category.py::TestPlotTypes::test_mixed_type_update_exception[string integer-scatter] PASSED [ 91%]\nlib/matplotlib/tests/test_category.py::TestPlotTypes::test_mixed_type_update_exception[string integer-bar] PASSED [ 92%]\nlib/matplotlib/tests/test_category.py::TestPlotTypes::test_mixed_type_update_exception[string integer-plot] XFAIL [ 93%]\nlib/matplotlib/tests/test_category.py::TestPlotTypes::test_mixed_type_update_exception[missing-scatter] PASSED [ 94%]\nlib/matplotlib/tests/test_category.py::TestPlotTypes::test_mixed_type_update_exception[missing-bar] PASSED [ 95%]\nlib/matplotlib/tests/test_category.py::TestPlotTypes::test_mixed_type_update_exception[missing-plot] XFAIL [ 96%]\nlib/matplotlib/tests/test_category.py::test_overriding_units_in_plot[png] PASSED [ 97%]\nlib/matplotlib/tests/test_category.py::test_no_deprecation_on_empty_data FAILED [ 98%]\nlib/matplotlib/tests/test_category.py::test_hist PASSED                  [100%]\n\n=================================== FAILURES ===================================\n______________________ test_no_deprecation_on_empty_data _______________________\nlib/matplotlib/axis.py:1622: in convert_units\n    ret = self.converter.convert(x, self.units, self)\nlib/matplotlib/category.py:62: in convert\n    _api.warn_deprecated(\nlib/matplotlib/_api/deprecation.py:96: in warn_deprecated\n    warn_external(warning, category=MatplotlibDeprecationWarning)\nlib/matplotlib/_api/__init__.py:361: in warn_external\n    warnings.warn(message, category, stacklevel)\nE   matplotlib._api.deprecation.MatplotlibDeprecationWarning: Support for passing numbers through unit converters is deprecated since 3.5 and support will be removed two minor releases later; use Axis.convert_units instead.\n\nThe above exception was the direct cause of the following exception:\nlib/matplotlib/tests/test_category.py:316: in test_no_deprecation_on_empty_data\n    ax.plot([], [])\nlib/matplotlib/axes/_axes.py:1640: in plot\n    self.add_line(line)\nlib/matplotlib/axes/_base.py:2301: in add_line\n    self._update_line_limits(line)\nlib/matplotlib/axes/_base.py:2324: in _update_line_limits\n    path = line.get_path()\nlib/matplotlib/lines.py:995: in get_path\n    self.recache()\nlib/matplotlib/lines.py:647: in recache\n    xconv = self.convert_xunits(self._xorig)\nlib/matplotlib/artist.py:250: in convert_xunits\n    return ax.xaxis.convert_units(x)\nlib/matplotlib/axis.py:1624: in convert_units\n    raise munits.ConversionError('Failed to convert value(s) to axis '\nE   matplotlib.units.ConversionError: Failed to convert value(s) to axis units: array([], dtype=float64)\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.11/site-packages/pyparsing.py:108\n  /opt/miniconda3/envs/testbed/lib/python3.11/site-packages/pyparsing.py:108: DeprecationWarning: module 'sre_constants' is deprecated\n    import sre_constants\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n============== 1 failed, 89 passed, 8 xfailed, 1 warning in 6.62s ==============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_category.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_category.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 90,
          "failed": 0,
          "errors": 0,
          "collected": 98,
          "duration": 10.41,
          "log_tail": "lib/matplotlib/tests/test_category.py::TestPlotTypes::test_plot_unicode[bar] PASSED [ 60%]\nlib/matplotlib/tests/test_category.py::TestPlotTypes::test_plot_xaxis[scatter] PASSED [ 61%]\nlib/matplotlib/tests/test_category.py::TestPlotTypes::test_plot_xaxis[plot] PASSED [ 62%]\nlib/matplotlib/tests/test_category.py::TestPlotTypes::test_plot_xaxis[bar] PASSED [ 63%]\nlib/matplotlib/tests/test_category.py::TestPlotTypes::test_plot_yaxis[scatter] PASSED [ 64%]\nlib/matplotlib/tests/test_category.py::TestPlotTypes::test_plot_yaxis[plot] PASSED [ 65%]\nlib/matplotlib/tests/test_category.py::TestPlotTypes::test_plot_yaxis[bar] PASSED [ 66%]\nlib/matplotlib/tests/test_category.py::TestPlotTypes::test_plot_xyaxis[scatter] PASSED [ 67%]\nlib/matplotlib/tests/test_category.py::TestPlotTypes::test_plot_xyaxis[plot] PASSED [ 68%]\nlib/matplotlib/tests/test_category.py::TestPlotTypes::test_plot_xyaxis[bar] PASSED [ 69%]\nlib/matplotlib/tests/test_category.py::TestPlotTypes::test_update_plot[scatter] PASSED [ 70%]\nlib/matplotlib/tests/test_category.py::TestPlotTypes::test_update_plot[plot] PASSED [ 71%]\nlib/matplotlib/tests/test_category.py::TestPlotTypes::test_update_plot[bar] PASSED [ 72%]\nlib/matplotlib/tests/test_category.py::TestPlotTypes::test_mixed_type_exception[mixed-scatter] PASSED [ 73%]\nlib/matplotlib/tests/test_category.py::TestPlotTypes::test_mixed_type_exception[mixed-bar] PASSED [ 74%]\nlib/matplotlib/tests/test_category.py::TestPlotTypes::test_mixed_type_exception[mixed-plot] XFAIL [ 75%]\nlib/matplotlib/tests/test_category.py::TestPlotTypes::test_mixed_type_exception[number integer-scatter] PASSED [ 76%]\nlib/matplotlib/tests/test_category.py::TestPlotTypes::test_mixed_type_exception[number integer-bar] PASSED [ 77%]\nlib/matplotlib/tests/test_category.py::TestPlotTypes::test_mixed_type_exception[number integer-plot] XFAIL [ 78%]\nlib/matplotlib/tests/test_category.py::TestPlotTypes::test_mixed_type_exception[string integer-scatter] PASSED [ 79%]\nlib/matplotlib/tests/test_category.py::TestPlotTypes::test_mixed_type_exception[string integer-bar] PASSED [ 80%]\nlib/matplotlib/tests/test_category.py::TestPlotTypes::test_mixed_type_exception[string integer-plot] XFAIL [ 81%]\nlib/matplotlib/tests/test_category.py::TestPlotTypes::test_mixed_type_exception[missing-scatter] PASSED [ 82%]\nlib/matplotlib/tests/test_category.py::TestPlotTypes::test_mixed_type_exception[missing-bar] PASSED [ 83%]\nlib/matplotlib/tests/test_category.py::TestPlotTypes::test_mixed_type_exception[missing-plot] XFAIL [ 84%]\nlib/matplotlib/tests/test_category.py::TestPlotTypes::test_mixed_type_update_exception[mixed-scatter] PASSED [ 85%]\nlib/matplotlib/tests/test_category.py::TestPlotTypes::test_mixed_type_update_exception[mixed-bar] PASSED [ 86%]\nlib/matplotlib/tests/test_category.py::TestPlotTypes::test_mixed_type_update_exception[mixed-plot] XFAIL [ 87%]\nlib/matplotlib/tests/test_category.py::TestPlotTypes::test_mixed_type_update_exception[number integer-scatter] PASSED [ 88%]\nlib/matplotlib/tests/test_category.py::TestPlotTypes::test_mixed_type_update_exception[number integer-bar] PASSED [ 89%]\nlib/matplotlib/tests/test_category.py::TestPlotTypes::test_mixed_type_update_exception[number integer-plot] XFAIL [ 90%]\nlib/matplotlib/tests/test_category.py::TestPlotTypes::test_mixed_type_update_exception[string integer-scatter] PASSED [ 91%]\nlib/matplotlib/tests/test_category.py::TestPlotTypes::test_mixed_type_update_exception[string integer-bar] PASSED [ 92%]\nlib/matplotlib/tests/test_category.py::TestPlotTypes::test_mixed_type_update_exception[string integer-plot] XFAIL [ 93%]\nlib/matplotlib/tests/test_category.py::TestPlotTypes::test_mixed_type_update_exception[missing-scatter] PASSED [ 94%]\nlib/matplotlib/tests/test_category.py::TestPlotTypes::test_mixed_type_update_exception[missing-bar] PASSED [ 95%]\nlib/matplotlib/tests/test_category.py::TestPlotTypes::test_mixed_type_update_exception[missing-plot] XFAIL [ 96%]\nlib/matplotlib/tests/test_category.py::test_overriding_units_in_plot[png] PASSED [ 97%]\nlib/matplotlib/tests/test_category.py::test_no_deprecation_on_empty_data PASSED [ 98%]\nlib/matplotlib/tests/test_category.py::test_hist PASSED                  [100%]\n\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.11/site-packages/pyparsing.py:108\n  /opt/miniconda3/envs/testbed/lib/python3.11/site-packages/pyparsing.py:108: DeprecationWarning: module 'sre_constants' is deprecated\n    import sre_constants\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=================== 90 passed, 8 xfailed, 1 warning in 6.70s ===================\n\n",
          "test_files_run": [
            "lib/matplotlib/tests/test_category.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "matplotlib__matplotlib-22865",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://34.41.233.120:8080",
      "duration": 33.018625020980835,
      "test_only": {
        "passed": true,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "collected": 61,
          "duration": 15.34,
          "log_tail": "lib/matplotlib/tests/test_colorbar.py::test_colorbar_extend_drawedges[both-1-res0] FAILED [ 83%]\nlib/matplotlib/tests/test_colorbar.py::test_colorbar_extend_drawedges[min-0-res1] FAILED [ 85%]\nlib/matplotlib/tests/test_colorbar.py::test_colorbar_extend_drawedges[max-0-res2] FAILED [ 86%]\nlib/matplotlib/tests/test_colorbar.py::test_colorbar_extend_drawedges[neither--1-res3] PASSED [ 88%]\nlib/matplotlib/tests/test_colorbar.py::test_negative_boundarynorm PASSED [ 90%]\nlib/matplotlib/tests/test_colorbar.py::test_nonorm[svg] SKIPPED (Can...) [ 91%]\nlib/matplotlib/tests/test_colorbar.py::test_boundaries[png] PASSED       [ 93%]\nlib/matplotlib/tests/test_colorbar.py::test_colorbar_no_warning_rcparams_grid_true PASSED [ 95%]\nlib/matplotlib/tests/test_colorbar.py::test_colorbar_set_formatter_locator PASSED [ 96%]\nlib/matplotlib/tests/test_colorbar.py::test_offset_text_loc PASSED       [ 98%]\nlib/matplotlib/tests/test_colorbar.py::test_title_text_loc PASSED        [100%]\n\n=================================== FAILURES ===================================\n_________________ test_colorbar_extend_drawedges[both-1-res0] __________________\nlib/matplotlib/tests/test_colorbar.py:943: in test_colorbar_extend_drawedges\n    assert np.all(np.equal(cbar.dividers.get_segments(), res))\nE   AssertionError: assert False\nE    +  where False = <function all at 0x710ce3e56db0>(array([[[False,  True],\\n        [False,  True]],\\n\\n       [[ True,  True],\\n        [ True,  True]],\\n\\n       [[False,  True],\\n        [False,  True]]]))\nE    +    where <function all at 0x710ce3e56db0> = np.all\nE    +    and   array([[[False,  True],\\n        [False,  True]],\\n\\n       [[ True,  True],\\n        [ True,  True]],\\n\\n       [[False,  True],\\n        [False,  True]]]) = <ufunc 'equal'>([array([[1., 0.],\\n       [1., 1.]])], [array([[0., 0.],\\n       [0., 1.]]), array([[1., 0.],\\n       [1., 1.]]), array([[2., 0.],\\n       [2., 1.]])])\nE    +      where <ufunc 'equal'> = np.equal\nE    +      and   [array([[1., 0.],\\n       [1., 1.]])] = get_segments()\nE    +        where get_segments = <matplotlib.collections.LineCollection object at 0x710cb0528b90>.get_segments\nE    +          where <matplotlib.collections.LineCollection object at 0x710cb0528b90> = <matplotlib.colorbar.Colorbar object at 0x710cab1cfd50>.dividers\n__________________ test_colorbar_extend_drawedges[min-0-res1] __________________\nlib/matplotlib/tests/test_colorbar.py:943: in test_colorbar_extend_drawedges\n    assert np.all(np.equal(cbar.dividers.get_segments(), res))\nE   AssertionError: assert False\nE    +  where False = <function all at 0x710ce3e56db0>(array([[[False,  True],\\n        [False,  True]],\\n\\n       [[ True,  True],\\n        [ True,  True]]]))\nE    +    where <function all at 0x710ce3e56db0> = np.all\nE    +    and   array([[[False,  True],\\n        [False,  True]],\\n\\n       [[ True,  True],\\n        [ True,  True]]]) = <ufunc 'equal'>([array([[1., 0.],\\n       [1., 1.]])], [array([[0., 0.],\\n       [0., 1.]]), array([[1., 0.],\\n       [1., 1.]])])\nE    +      where <ufunc 'equal'> = np.equal\nE    +      and   [array([[1., 0.],\\n       [1., 1.]])] = get_segments()\nE    +        where get_segments = <matplotlib.collections.LineCollection object at 0x710cadb1ead0>.get_segments\nE    +          where <matplotlib.collections.LineCollection object at 0x710cadb1ead0> = <matplotlib.colorbar.Colorbar object at 0x710cab136d10>.dividers\n__________________ test_colorbar_extend_drawedges[max-0-res2] __________________\nlib/matplotlib/tests/test_colorbar.py:943: in test_colorbar_extend_drawedges\n    assert np.all(np.equal(cbar.dividers.get_segments(), res))\nE   AssertionError: assert False\nE    +  where False = <function all at 0x710ce3e56db0>(array([[[ True,  True],\\n        [ True,  True]],\\n\\n       [[False,  True],\\n        [False,  True]]]))\nE    +    where <function all at 0x710ce3e56db0> = np.all\nE    +    and   array([[[ True,  True],\\n        [ True,  True]],\\n\\n       [[False,  True],\\n        [False,  True]]]) = <ufunc 'equal'>([array([[1., 0.],\\n       [1., 1.]])], [array([[1., 0.],\\n       [1., 1.]]), array([[2., 0.],\\n       [2., 1.]])])\nE    +      where <ufunc 'equal'> = np.equal\nE    +      and   [array([[1., 0.],\\n       [1., 1.]])] = get_segments()\nE    +        where get_segments = <matplotlib.collections.LineCollection object at 0x710ca3372c90>.get_segments\nE    +          where <matplotlib.collections.LineCollection object at 0x710ca3372c90> = <matplotlib.colorbar.Colorbar object at 0x710cab136b90>.dividers\n=================== 3 failed, 57 passed, 1 skipped in 12.27s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_colorbar.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_colorbar.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 60,
          "failed": 0,
          "errors": 0,
          "collected": 61,
          "duration": 16.14,
          "log_tail": "lib/matplotlib/tests/test_colorbar.py::test_remove_from_figure[with gridspec] PASSED [ 26%]\nlib/matplotlib/tests/test_colorbar.py::test_remove_from_figure_cl PASSED [ 27%]\nlib/matplotlib/tests/test_colorbar.py::test_colorbarbase PASSED          [ 29%]\nlib/matplotlib/tests/test_colorbar.py::test_colorbar_closed_patch[png] PASSED [ 31%]\nlib/matplotlib/tests/test_colorbar.py::test_colorbar_ticks PASSED        [ 32%]\nlib/matplotlib/tests/test_colorbar.py::test_colorbar_minorticks_on_off PASSED [ 34%]\nlib/matplotlib/tests/test_colorbar.py::test_cbar_minorticks_for_rc_xyminortickvisible PASSED [ 36%]\nlib/matplotlib/tests/test_colorbar.py::test_colorbar_autoticks PASSED    [ 37%]\nlib/matplotlib/tests/test_colorbar.py::test_colorbar_autotickslog PASSED [ 39%]\nlib/matplotlib/tests/test_colorbar.py::test_colorbar_get_ticks PASSED    [ 40%]\nlib/matplotlib/tests/test_colorbar.py::test_colorbar_lognorm_extension[both] PASSED [ 42%]\nlib/matplotlib/tests/test_colorbar.py::test_colorbar_lognorm_extension[min] PASSED [ 44%]\nlib/matplotlib/tests/test_colorbar.py::test_colorbar_lognorm_extension[max] PASSED [ 45%]\nlib/matplotlib/tests/test_colorbar.py::test_colorbar_powernorm_extension PASSED [ 47%]\nlib/matplotlib/tests/test_colorbar.py::test_colorbar_axes_kw PASSED      [ 49%]\nlib/matplotlib/tests/test_colorbar.py::test_colorbar_log_minortick_labels PASSED [ 50%]\nlib/matplotlib/tests/test_colorbar.py::test_colorbar_renorm PASSED       [ 52%]\nlib/matplotlib/tests/test_colorbar.py::test_colorbar_format[%4.2e] PASSED [ 54%]\nlib/matplotlib/tests/test_colorbar.py::test_colorbar_format[{x:.2e}] PASSED [ 55%]\nlib/matplotlib/tests/test_colorbar.py::test_colorbar_scale_reset PASSED  [ 57%]\nlib/matplotlib/tests/test_colorbar.py::test_colorbar_get_ticks_2 PASSED  [ 59%]\nlib/matplotlib/tests/test_colorbar.py::test_colorbar_inverted_ticks PASSED [ 60%]\nlib/matplotlib/tests/test_colorbar.py::test_mappable_no_alpha PASSED     [ 62%]\nlib/matplotlib/tests/test_colorbar.py::test_mappable_2d_alpha PASSED     [ 63%]\nlib/matplotlib/tests/test_colorbar.py::test_colorbar_label PASSED        [ 65%]\nlib/matplotlib/tests/test_colorbar.py::test_colorbar_int[clim0] PASSED   [ 67%]\nlib/matplotlib/tests/test_colorbar.py::test_colorbar_int[clim1] PASSED   [ 68%]\nlib/matplotlib/tests/test_colorbar.py::test_anchored_cbar_position_using_specgrid PASSED [ 70%]\nlib/matplotlib/tests/test_colorbar.py::test_colorbar_change_lim_scale[png] PASSED [ 72%]\nlib/matplotlib/tests/test_colorbar.py::test_axes_handles_same_functions[png] PASSED [ 73%]\nlib/matplotlib/tests/test_colorbar.py::test_inset_colorbar_layout PASSED [ 75%]\nlib/matplotlib/tests/test_colorbar.py::test_twoslope_colorbar[png] PASSED [ 77%]\nlib/matplotlib/tests/test_colorbar.py::test_remove_cb_whose_mappable_has_no_figure[png] PASSED [ 78%]\nlib/matplotlib/tests/test_colorbar.py::test_aspects PASSED               [ 80%]\nlib/matplotlib/tests/test_colorbar.py::test_proportional_colorbars[png] PASSED [ 81%]\nlib/matplotlib/tests/test_colorbar.py::test_colorbar_extend_drawedges[both-1-res0] PASSED [ 83%]\nlib/matplotlib/tests/test_colorbar.py::test_colorbar_extend_drawedges[min-0-res1] PASSED [ 85%]\nlib/matplotlib/tests/test_colorbar.py::test_colorbar_extend_drawedges[max-0-res2] PASSED [ 86%]\nlib/matplotlib/tests/test_colorbar.py::test_colorbar_extend_drawedges[neither--1-res3] PASSED [ 88%]\nlib/matplotlib/tests/test_colorbar.py::test_negative_boundarynorm PASSED [ 90%]\nlib/matplotlib/tests/test_colorbar.py::test_nonorm[svg] SKIPPED (Can...) [ 91%]\nlib/matplotlib/tests/test_colorbar.py::test_boundaries[png] PASSED       [ 93%]\nlib/matplotlib/tests/test_colorbar.py::test_colorbar_no_warning_rcparams_grid_true PASSED [ 95%]\nlib/matplotlib/tests/test_colorbar.py::test_colorbar_set_formatter_locator PASSED [ 96%]\nlib/matplotlib/tests/test_colorbar.py::test_offset_text_loc PASSED       [ 98%]\nlib/matplotlib/tests/test_colorbar.py::test_title_text_loc PASSED        [100%]\n\n======================== 60 passed, 1 skipped in 12.42s ========================\n\n",
          "test_files_run": [
            "lib/matplotlib/tests/test_colorbar.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got True\u2192True"
    },
    {
      "instance_id": "matplotlib__matplotlib-22871",
      "repo": "matplotlib/matplotlib",
      "valid": true,
      "worker": "http://34.41.233.120:8080",
      "duration": 25.793211936950684,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 88,
          "failed": 1,
          "errors": 0,
          "collected": 89,
          "duration": 11.79,
          "log_tail": "lib/matplotlib/tests/test_dates.py::test_offset_changes FAILED           [ 58%]\nlib/matplotlib/tests/test_dates.py::test_concise_formatter_usetex[t_delta0-expected0] PASSED [ 59%]\nlib/matplotlib/tests/test_dates.py::test_concise_formatter_usetex[t_delta1-expected1] PASSED [ 60%]\nlib/matplotlib/tests/test_dates.py::test_concise_formatter_usetex[t_delta2-expected2] PASSED [ 61%]\nlib/matplotlib/tests/test_dates.py::test_concise_formatter_usetex[t_delta3-expected3] PASSED [ 62%]\nlib/matplotlib/tests/test_dates.py::test_concise_formatter_formats PASSED [ 64%]\nlib/matplotlib/tests/test_dates.py::test_concise_formatter_zformats PASSED [ 65%]\nlib/matplotlib/tests/test_dates.py::test_concise_formatter_tz PASSED     [ 66%]\nlib/matplotlib/tests/test_dates.py::test_auto_date_locator_intmult_tz PASSED [ 67%]\nlib/matplotlib/tests/test_dates.py::test_date_inverted_limit[png] PASSED [ 68%]\nlib/matplotlib/tests/test_dates.py::test_date2num_dst PASSED             [ 69%]\nlib/matplotlib/tests/test_dates.py::test_date2num_dst_pandas PASSED      [ 70%]\nlib/matplotlib/tests/test_dates.py::test_rrulewrapper PASSED             [ 71%]\nlib/matplotlib/tests/test_dates.py::test_rrulewrapper_pytz PASSED        [ 73%]\nlib/matplotlib/tests/test_dates.py::test_yearlocator_pytz PASSED         [ 74%]\nlib/matplotlib/tests/test_dates.py::test_YearLocator PASSED              [ 75%]\nlib/matplotlib/tests/test_dates.py::test_DayLocator PASSED               [ 76%]\nlib/matplotlib/tests/test_dates.py::test_tz_utc PASSED                   [ 77%]\nlib/matplotlib/tests/test_dates.py::test_num2timedelta[1-tdelta0] PASSED [ 78%]\nlib/matplotlib/tests/test_dates.py::test_num2timedelta[x1-tdelta1] PASSED [ 79%]\nlib/matplotlib/tests/test_dates.py::test_datetime64_in_list PASSED       [ 80%]\nlib/matplotlib/tests/test_dates.py::test_change_epoch PASSED             [ 82%]\nlib/matplotlib/tests/test_dates.py::test_warn_notintervals PASSED        [ 83%]\nlib/matplotlib/tests/test_dates.py::test_change_converter PASSED         [ 84%]\nlib/matplotlib/tests/test_dates.py::test_change_interval_multiples PASSED [ 85%]\nlib/matplotlib/tests/test_dates.py::test_epoch2num PASSED                [ 86%]\nlib/matplotlib/tests/test_dates.py::test_julian2num PASSED               [ 87%]\nlib/matplotlib/tests/test_dates.py::test_DateLocator PASSED              [ 88%]\nlib/matplotlib/tests/test_dates.py::test_datestr2num PASSED              [ 89%]\nlib/matplotlib/tests/test_dates.py::test_concise_formatter_exceptions PASSED [ 91%]\nlib/matplotlib/tests/test_dates.py::test_concise_formatter_call PASSED   [ 92%]\nlib/matplotlib/tests/test_dates.py::test_date_ticker_factory[0.02-MinuteLocator] PASSED [ 93%]\nlib/matplotlib/tests/test_dates.py::test_date_ticker_factory[1-HourLocator] PASSED [ 94%]\nlib/matplotlib/tests/test_dates.py::test_date_ticker_factory[19-DayLocator] PASSED [ 95%]\nlib/matplotlib/tests/test_dates.py::test_date_ticker_factory[40-WeekdayLocator] PASSED [ 96%]\nlib/matplotlib/tests/test_dates.py::test_date_ticker_factory[200-MonthLocator] PASSED [ 97%]\nlib/matplotlib/tests/test_dates.py::test_date_ticker_factory[2000-YearLocator] PASSED [ 98%]\nlib/matplotlib/tests/test_dates.py::test_usetex_newline PASSED           [100%]\n\n=================================== FAILURES ===================================\n_____________________________ test_offset_changes ______________________________\nlib/matplotlib/tests/test_dates.py:636: in test_offset_changes\n    assert formatter.get_offset() == '1997'\nE   AssertionError: assert '' == '1997'\nE     \nE     - 1997\n========================= 1 failed, 88 passed in 8.53s =========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_dates.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_dates.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 89,
          "failed": 0,
          "errors": 0,
          "collected": 89,
          "duration": 12.51,
          "log_tail": "lib/matplotlib/tests/test_dates.py::test_concise_formatter PASSED        [ 49%]\nlib/matplotlib/tests/test_dates.py::test_concise_formatter_show_offset[t_delta0-1997-Jan-01 00:00] PASSED [ 50%]\nlib/matplotlib/tests/test_dates.py::test_concise_formatter_show_offset[t_delta1-1997-Jan-01 00:01] PASSED [ 51%]\nlib/matplotlib/tests/test_dates.py::test_concise_formatter_show_offset[t_delta2-1997-Jan-01] PASSED [ 52%]\nlib/matplotlib/tests/test_dates.py::test_concise_formatter_show_offset[t_delta3-1997-Jan-02] PASSED [ 53%]\nlib/matplotlib/tests/test_dates.py::test_concise_formatter_show_offset[t_delta4-1997-Jan] PASSED [ 55%]\nlib/matplotlib/tests/test_dates.py::test_concise_formatter_show_offset[t_delta5-] PASSED [ 56%]\nlib/matplotlib/tests/test_dates.py::test_concise_formatter_show_offset[t_delta6-] PASSED [ 57%]\nlib/matplotlib/tests/test_dates.py::test_offset_changes PASSED           [ 58%]\nlib/matplotlib/tests/test_dates.py::test_concise_formatter_usetex[t_delta0-expected0] PASSED [ 59%]\nlib/matplotlib/tests/test_dates.py::test_concise_formatter_usetex[t_delta1-expected1] PASSED [ 60%]\nlib/matplotlib/tests/test_dates.py::test_concise_formatter_usetex[t_delta2-expected2] PASSED [ 61%]\nlib/matplotlib/tests/test_dates.py::test_concise_formatter_usetex[t_delta3-expected3] PASSED [ 62%]\nlib/matplotlib/tests/test_dates.py::test_concise_formatter_formats PASSED [ 64%]\nlib/matplotlib/tests/test_dates.py::test_concise_formatter_zformats PASSED [ 65%]\nlib/matplotlib/tests/test_dates.py::test_concise_formatter_tz PASSED     [ 66%]\nlib/matplotlib/tests/test_dates.py::test_auto_date_locator_intmult_tz PASSED [ 67%]\nlib/matplotlib/tests/test_dates.py::test_date_inverted_limit[png] PASSED [ 68%]\nlib/matplotlib/tests/test_dates.py::test_date2num_dst PASSED             [ 69%]\nlib/matplotlib/tests/test_dates.py::test_date2num_dst_pandas PASSED      [ 70%]\nlib/matplotlib/tests/test_dates.py::test_rrulewrapper PASSED             [ 71%]\nlib/matplotlib/tests/test_dates.py::test_rrulewrapper_pytz PASSED        [ 73%]\nlib/matplotlib/tests/test_dates.py::test_yearlocator_pytz PASSED         [ 74%]\nlib/matplotlib/tests/test_dates.py::test_YearLocator PASSED              [ 75%]\nlib/matplotlib/tests/test_dates.py::test_DayLocator PASSED               [ 76%]\nlib/matplotlib/tests/test_dates.py::test_tz_utc PASSED                   [ 77%]\nlib/matplotlib/tests/test_dates.py::test_num2timedelta[1-tdelta0] PASSED [ 78%]\nlib/matplotlib/tests/test_dates.py::test_num2timedelta[x1-tdelta1] PASSED [ 79%]\nlib/matplotlib/tests/test_dates.py::test_datetime64_in_list PASSED       [ 80%]\nlib/matplotlib/tests/test_dates.py::test_change_epoch PASSED             [ 82%]\nlib/matplotlib/tests/test_dates.py::test_warn_notintervals PASSED        [ 83%]\nlib/matplotlib/tests/test_dates.py::test_change_converter PASSED         [ 84%]\nlib/matplotlib/tests/test_dates.py::test_change_interval_multiples PASSED [ 85%]\nlib/matplotlib/tests/test_dates.py::test_epoch2num PASSED                [ 86%]\nlib/matplotlib/tests/test_dates.py::test_julian2num PASSED               [ 87%]\nlib/matplotlib/tests/test_dates.py::test_DateLocator PASSED              [ 88%]\nlib/matplotlib/tests/test_dates.py::test_datestr2num PASSED              [ 89%]\nlib/matplotlib/tests/test_dates.py::test_concise_formatter_exceptions PASSED [ 91%]\nlib/matplotlib/tests/test_dates.py::test_concise_formatter_call PASSED   [ 92%]\nlib/matplotlib/tests/test_dates.py::test_date_ticker_factory[0.02-MinuteLocator] PASSED [ 93%]\nlib/matplotlib/tests/test_dates.py::test_date_ticker_factory[1-HourLocator] PASSED [ 94%]\nlib/matplotlib/tests/test_dates.py::test_date_ticker_factory[19-DayLocator] PASSED [ 95%]\nlib/matplotlib/tests/test_dates.py::test_date_ticker_factory[40-WeekdayLocator] PASSED [ 96%]\nlib/matplotlib/tests/test_dates.py::test_date_ticker_factory[200-MonthLocator] PASSED [ 97%]\nlib/matplotlib/tests/test_dates.py::test_date_ticker_factory[2000-YearLocator] PASSED [ 98%]\nlib/matplotlib/tests/test_dates.py::test_usetex_newline PASSED           [100%]\n\n============================== 89 passed in 9.02s ==============================\n\n",
          "test_files_run": [
            "lib/matplotlib/tests/test_dates.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "matplotlib__matplotlib-23299",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://34.41.233.120:8080",
      "duration": 23.756175756454468,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 204,
          "failed": 3,
          "errors": 0,
          "collected": 208,
          "duration": 10.6,
          "log_tail": "lib/matplotlib/tests/test_rcparams.py::test_validate_fontstretch[stretch7-ValueError] PASSED [ 97%]\nlib/matplotlib/tests/test_rcparams.py::test_keymaps PASSED               [ 97%]\nlib/matplotlib/tests/test_rcparams.py::test_no_backend_reset_rccontext FAILED [ 98%]\nlib/matplotlib/tests/test_rcparams.py::test_rcparams_reset_after_fail PASSED [ 98%]\nlib/matplotlib/tests/test_rcparams.py::test_backend_fallback_headless PASSED [ 99%]\nlib/matplotlib/tests/test_rcparams.py::test_backend_fallback_headful SKIPPED [ 99%]\nlib/matplotlib/tests/test_rcparams.py::test_deprecation PASSED           [100%]\n\n=================================== FAILURES ===================================\n_____________________________ test_rcparams_update _____________________________\nlib/matplotlib/tests/test_rcparams.py:111: in test_rcparams_update\n    rc.update(bad_dict)\n<frozen _collections_abc>:949: in update\n    ???\nlib/matplotlib/__init__.py:651: in __setitem__\n    raise ValueError(f\"Key {key}: {ve}\") from None\nE   ValueError: Key figure.figsize: Expected 2 values, but there are 3 values in (3.5, 42, 1)\n\nDuring handling of the above exception, another exception occurred:\nlib/matplotlib/tests/test_rcparams.py:109: in test_rcparams_update\n    with pytest.raises(ValueError), \\\nE   Failed: DID NOT WARN. No warnings of type (<class 'UserWarning'>,) were emitted.\nE    Emitted warnings: [].\n______________________________ test_rcparams_init ______________________________\nlib/matplotlib/tests/test_rcparams.py:117: in test_rcparams_init\n    mpl.RcParams({'figure.figsize': (3.5, 42, 1)})\nlib/matplotlib/__init__.py:626: in __init__\n    self.update(*args, **kwargs)\n<frozen _collections_abc>:949: in update\n    ???\nlib/matplotlib/__init__.py:651: in __setitem__\n    raise ValueError(f\"Key {key}: {ve}\") from None\nE   ValueError: Key figure.figsize: Expected 2 values, but there are 3 values in (3.5, 42, 1)\n\nDuring handling of the above exception, another exception occurred:\nlib/matplotlib/tests/test_rcparams.py:115: in test_rcparams_init\n    with pytest.raises(ValueError), \\\nE   Failed: DID NOT WARN. No warnings of type (<class 'UserWarning'>,) were emitted.\nE    Emitted warnings: [].\n_______________________ test_no_backend_reset_rccontext ________________________\nlib/matplotlib/tests/test_rcparams.py:503: in test_no_backend_reset_rccontext\n    assert mpl.rcParams['backend'] == 'module://aardvark'\nE   AssertionError: assert 'agg' == 'module://aardvark'\nE     \nE     - module://aardvark\nE     + agg\n=================== 3 failed, 204 passed, 1 skipped in 7.55s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_rcparams.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_rcparams.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 205,
          "failed": 2,
          "errors": 0,
          "collected": 208,
          "duration": 11.52,
          "log_tail": "lib/matplotlib/tests/test_rcparams.py::test_validate_fontstretch[expanded-expanded] PASSED [ 93%]\nlib/matplotlib/tests/test_rcparams.py::test_validate_fontstretch[EXPANDED-ValueError] PASSED [ 94%]\nlib/matplotlib/tests/test_rcparams.py::test_validate_fontstretch[100-100_0] PASSED [ 94%]\nlib/matplotlib/tests/test_rcparams.py::test_validate_fontstretch[100-100_1] PASSED [ 95%]\nlib/matplotlib/tests/test_rcparams.py::test_validate_fontstretch[stretch4-100] PASSED [ 95%]\nlib/matplotlib/tests/test_rcparams.py::test_validate_fontstretch[20.6-20] PASSED [ 96%]\nlib/matplotlib/tests/test_rcparams.py::test_validate_fontstretch[20.6-ValueError] PASSED [ 96%]\nlib/matplotlib/tests/test_rcparams.py::test_validate_fontstretch[stretch7-ValueError] PASSED [ 97%]\nlib/matplotlib/tests/test_rcparams.py::test_keymaps PASSED               [ 97%]\nlib/matplotlib/tests/test_rcparams.py::test_no_backend_reset_rccontext PASSED [ 98%]\nlib/matplotlib/tests/test_rcparams.py::test_rcparams_reset_after_fail PASSED [ 98%]\nlib/matplotlib/tests/test_rcparams.py::test_backend_fallback_headless PASSED [ 99%]\nlib/matplotlib/tests/test_rcparams.py::test_backend_fallback_headful SKIPPED [ 99%]\nlib/matplotlib/tests/test_rcparams.py::test_deprecation PASSED           [100%]\n\n=================================== FAILURES ===================================\n_____________________________ test_rcparams_update _____________________________\nlib/matplotlib/tests/test_rcparams.py:111: in test_rcparams_update\n    rc.update(bad_dict)\n<frozen _collections_abc>:949: in update\n    ???\nlib/matplotlib/__init__.py:651: in __setitem__\n    raise ValueError(f\"Key {key}: {ve}\") from None\nE   ValueError: Key figure.figsize: Expected 2 values, but there are 3 values in (3.5, 42, 1)\n\nDuring handling of the above exception, another exception occurred:\nlib/matplotlib/tests/test_rcparams.py:109: in test_rcparams_update\n    with pytest.raises(ValueError), \\\nE   Failed: DID NOT WARN. No warnings of type (<class 'UserWarning'>,) were emitted.\nE    Emitted warnings: [].\n______________________________ test_rcparams_init ______________________________\nlib/matplotlib/tests/test_rcparams.py:117: in test_rcparams_init\n    mpl.RcParams({'figure.figsize': (3.5, 42, 1)})\nlib/matplotlib/__init__.py:626: in __init__\n    self.update(*args, **kwargs)\n<frozen _collections_abc>:949: in update\n    ???\nlib/matplotlib/__init__.py:651: in __setitem__\n    raise ValueError(f\"Key {key}: {ve}\") from None\nE   ValueError: Key figure.figsize: Expected 2 values, but there are 3 values in (3.5, 42, 1)\n\nDuring handling of the above exception, another exception occurred:\nlib/matplotlib/tests/test_rcparams.py:115: in test_rcparams_init\n    with pytest.raises(ValueError), \\\nE   Failed: DID NOT WARN. No warnings of type (<class 'UserWarning'>,) were emitted.\nE    Emitted warnings: [].\n=================== 2 failed, 205 passed, 1 skipped in 7.92s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_rcparams.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_rcparams.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "matplotlib__matplotlib-23314",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://34.41.233.120:8080",
      "error": "HTTPConnectionPool(host='34.41.233.120', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "matplotlib__matplotlib-23412",
      "repo": "matplotlib/matplotlib",
      "valid": true,
      "worker": "http://34.41.233.120:8080",
      "duration": 25.157899141311646,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 46,
          "failed": 1,
          "errors": 0,
          "collected": 55,
          "duration": 11.33,
          "log_tail": "lib/matplotlib/tests/test_patches.py::test_patch_custom_linestyle[svg] SKIPPED [ 34%]\nlib/matplotlib/tests/test_patches.py::test_patch_linestyle_accents PASSED [ 36%]\nlib/matplotlib/tests/test_patches.py::test_patch_linestyle_none[png] PASSED [ 38%]\nlib/matplotlib/tests/test_patches.py::test_wedge_movement PASSED         [ 40%]\nlib/matplotlib/tests/test_patches.py::test_wedge_range[png] PASSED       [ 41%]\nlib/matplotlib/tests/test_patches.py::test_wedge_range[pdf] PASSED       [ 43%]\nlib/matplotlib/tests/test_patches.py::test_wedge_range[svg] SKIPPED      [ 45%]\nlib/matplotlib/tests/test_patches.py::test_patch_str PASSED              [ 47%]\nlib/matplotlib/tests/test_patches.py::test_multi_color_hatch[png] PASSED [ 49%]\nlib/matplotlib/tests/test_patches.py::test_multi_color_hatch[pdf] PASSED [ 50%]\nlib/matplotlib/tests/test_patches.py::test_multi_color_hatch[svg] SKIPPED [ 52%]\nlib/matplotlib/tests/test_patches.py::test_units_rectangle[png] PASSED   [ 54%]\nlib/matplotlib/tests/test_patches.py::test_connection_patch[png] PASSED  [ 56%]\nlib/matplotlib/tests/test_patches.py::test_connection_patch_fig[png] PASSED [ 58%]\nlib/matplotlib/tests/test_patches.py::test_datetime_rectangle PASSED     [ 60%]\nlib/matplotlib/tests/test_patches.py::test_datetime_datetime_fails PASSED [ 61%]\nlib/matplotlib/tests/test_patches.py::test_contains_point PASSED         [ 63%]\nlib/matplotlib/tests/test_patches.py::test_contains_points PASSED        [ 65%]\nlib/matplotlib/tests/test_patches.py::test_shadow[png] PASSED            [ 67%]\nlib/matplotlib/tests/test_patches.py::test_fancyarrow_units PASSED       [ 69%]\nlib/matplotlib/tests/test_patches.py::test_fancyarrow_setdata PASSED     [ 70%]\nlib/matplotlib/tests/test_patches.py::test_large_arc[svg] SKIPPED (C...) [ 72%]\nlib/matplotlib/tests/test_patches.py::test_rotated_arcs[svg] SKIPPED     [ 74%]\nlib/matplotlib/tests/test_patches.py::test_fancyarrow_shape_error PASSED [ 76%]\nlib/matplotlib/tests/test_patches.py::test_boxstyle_errors[foo-Unknown style: 'foo'] PASSED [ 78%]\nlib/matplotlib/tests/test_patches.py::test_boxstyle_errors[Round,foo-Incorrect style argument: 'Round,foo'] PASSED [ 80%]\nlib/matplotlib/tests/test_patches.py::test_annulus[png] PASSED           [ 81%]\nlib/matplotlib/tests/test_patches.py::test_annulus_setters[png] PASSED   [ 83%]\nlib/matplotlib/tests/test_patches.py::test_annulus_setters2[png] PASSED  [ 85%]\nlib/matplotlib/tests/test_patches.py::test_degenerate_polygon PASSED     [ 87%]\nlib/matplotlib/tests/test_patches.py::test_color_override_warning[edgecolor] PASSED [ 89%]\nlib/matplotlib/tests/test_patches.py::test_color_override_warning[facecolor] PASSED [ 90%]\nlib/matplotlib/tests/test_patches.py::test_empty_verts PASSED            [ 92%]\nlib/matplotlib/tests/test_patches.py::test_default_antialiased PASSED    [ 94%]\nlib/matplotlib/tests/test_patches.py::test_default_linestyle PASSED      [ 96%]\nlib/matplotlib/tests/test_patches.py::test_default_capstyle PASSED       [ 98%]\nlib/matplotlib/tests/test_patches.py::test_default_joinstyle PASSED      [100%]\n\n=================================== FAILURES ===================================\n_______________________ test_dash_offset_patch_draw[png] _______________________\nlib/matplotlib/testing/decorators.py:478: in wrapper\n    _raise_on_image_difference(\nE   matplotlib.testing.exceptions.ImageComparisonFailure: images not close (RMS 24.315):\nE   \tresult_images/test_patches/test_dash_offset_patch_draw[png].png\nE   \tresult_images/test_patches/test_dash_offset_patch_draw[png]-expected.png\nE   \tresult_images/test_patches/test_dash_offset_patch_draw[png]-failed-diff.png\n=================== 1 failed, 46 passed, 8 skipped in 8.04s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_patches.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_patches.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 47,
          "failed": 0,
          "errors": 0,
          "collected": 55,
          "duration": 12.29,
          "log_tail": "lib/matplotlib/tests/test_patches.py::test_patch_alpha_coloring[png] PASSED [ 18%]\nlib/matplotlib/tests/test_patches.py::test_patch_alpha_coloring[pdf] PASSED [ 20%]\nlib/matplotlib/tests/test_patches.py::test_patch_alpha_coloring[svg] SKIPPED [ 21%]\nlib/matplotlib/tests/test_patches.py::test_patch_alpha_override[png] PASSED [ 23%]\nlib/matplotlib/tests/test_patches.py::test_patch_alpha_override[pdf] PASSED [ 25%]\nlib/matplotlib/tests/test_patches.py::test_patch_alpha_override[svg] SKIPPED [ 27%]\nlib/matplotlib/tests/test_patches.py::test_patch_color_none PASSED       [ 29%]\nlib/matplotlib/tests/test_patches.py::test_patch_custom_linestyle[png] PASSED [ 30%]\nlib/matplotlib/tests/test_patches.py::test_patch_custom_linestyle[pdf] PASSED [ 32%]\nlib/matplotlib/tests/test_patches.py::test_patch_custom_linestyle[svg] SKIPPED [ 34%]\nlib/matplotlib/tests/test_patches.py::test_patch_linestyle_accents PASSED [ 36%]\nlib/matplotlib/tests/test_patches.py::test_patch_linestyle_none[png] PASSED [ 38%]\nlib/matplotlib/tests/test_patches.py::test_wedge_movement PASSED         [ 40%]\nlib/matplotlib/tests/test_patches.py::test_wedge_range[png] PASSED       [ 41%]\nlib/matplotlib/tests/test_patches.py::test_wedge_range[pdf] PASSED       [ 43%]\nlib/matplotlib/tests/test_patches.py::test_wedge_range[svg] SKIPPED      [ 45%]\nlib/matplotlib/tests/test_patches.py::test_patch_str PASSED              [ 47%]\nlib/matplotlib/tests/test_patches.py::test_multi_color_hatch[png] PASSED [ 49%]\nlib/matplotlib/tests/test_patches.py::test_multi_color_hatch[pdf] PASSED [ 50%]\nlib/matplotlib/tests/test_patches.py::test_multi_color_hatch[svg] SKIPPED [ 52%]\nlib/matplotlib/tests/test_patches.py::test_units_rectangle[png] PASSED   [ 54%]\nlib/matplotlib/tests/test_patches.py::test_connection_patch[png] PASSED  [ 56%]\nlib/matplotlib/tests/test_patches.py::test_connection_patch_fig[png] PASSED [ 58%]\nlib/matplotlib/tests/test_patches.py::test_datetime_rectangle PASSED     [ 60%]\nlib/matplotlib/tests/test_patches.py::test_datetime_datetime_fails PASSED [ 61%]\nlib/matplotlib/tests/test_patches.py::test_contains_point PASSED         [ 63%]\nlib/matplotlib/tests/test_patches.py::test_contains_points PASSED        [ 65%]\nlib/matplotlib/tests/test_patches.py::test_shadow[png] PASSED            [ 67%]\nlib/matplotlib/tests/test_patches.py::test_fancyarrow_units PASSED       [ 69%]\nlib/matplotlib/tests/test_patches.py::test_fancyarrow_setdata PASSED     [ 70%]\nlib/matplotlib/tests/test_patches.py::test_large_arc[svg] SKIPPED (C...) [ 72%]\nlib/matplotlib/tests/test_patches.py::test_rotated_arcs[svg] SKIPPED     [ 74%]\nlib/matplotlib/tests/test_patches.py::test_fancyarrow_shape_error PASSED [ 76%]\nlib/matplotlib/tests/test_patches.py::test_boxstyle_errors[foo-Unknown style: 'foo'] PASSED [ 78%]\nlib/matplotlib/tests/test_patches.py::test_boxstyle_errors[Round,foo-Incorrect style argument: 'Round,foo'] PASSED [ 80%]\nlib/matplotlib/tests/test_patches.py::test_annulus[png] PASSED           [ 81%]\nlib/matplotlib/tests/test_patches.py::test_annulus_setters[png] PASSED   [ 83%]\nlib/matplotlib/tests/test_patches.py::test_annulus_setters2[png] PASSED  [ 85%]\nlib/matplotlib/tests/test_patches.py::test_degenerate_polygon PASSED     [ 87%]\nlib/matplotlib/tests/test_patches.py::test_color_override_warning[edgecolor] PASSED [ 89%]\nlib/matplotlib/tests/test_patches.py::test_color_override_warning[facecolor] PASSED [ 90%]\nlib/matplotlib/tests/test_patches.py::test_empty_verts PASSED            [ 92%]\nlib/matplotlib/tests/test_patches.py::test_default_antialiased PASSED    [ 94%]\nlib/matplotlib/tests/test_patches.py::test_default_linestyle PASSED      [ 96%]\nlib/matplotlib/tests/test_patches.py::test_default_capstyle PASSED       [ 98%]\nlib/matplotlib/tests/test_patches.py::test_default_joinstyle PASSED      [100%]\n\n======================== 47 passed, 8 skipped in 8.27s =========================\n\n",
          "test_files_run": [
            "lib/matplotlib/tests/test_patches.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "matplotlib__matplotlib-23476",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://34.41.233.120:8080",
      "error": "HTTPConnectionPool(host='34.41.233.120', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "matplotlib__matplotlib-24026",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://34.41.233.120:8080",
      "error": "HTTPConnectionPool(host='34.41.233.120', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "matplotlib__matplotlib-24149",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://34.41.233.120:8080",
      "error": "HTTPConnectionPool(host='34.41.233.120', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "matplotlib__matplotlib-24177",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://34.41.233.120:8080",
      "error": "HTTPConnectionPool(host='34.41.233.120', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "matplotlib__matplotlib-24570",
      "repo": "matplotlib/matplotlib",
      "valid": true,
      "worker": "http://34.41.233.120:8080",
      "duration": 23.07774519920349,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 275,
          "failed": 2,
          "errors": 0,
          "collected": 278,
          "duration": 10.65,
          "log_tail": "lib/matplotlib/tests/test_offsetbox.py::test_picking[axes points-text] PASSED [ 95%]\nlib/matplotlib/tests/test_offsetbox.py::test_picking[data-draw] PASSED   [ 95%]\nlib/matplotlib/tests/test_offsetbox.py::test_picking[data-image] PASSED  [ 96%]\nlib/matplotlib/tests/test_offsetbox.py::test_picking[data-text] PASSED   [ 96%]\nlib/matplotlib/tests/test_offsetbox.py::test_anchoredtext_horizontal_alignment[png] PASSED [ 96%]\nlib/matplotlib/tests/test_offsetbox.py::test_annotationbbox_extents PASSED [ 97%]\nlib/matplotlib/tests/test_offsetbox.py::test_zorder PASSED               [ 97%]\nlib/matplotlib/tests/test_offsetbox.py::test_arrowprops_copied PASSED    [ 97%]\nlib/matplotlib/tests/test_offsetbox.py::test_packers[baseline] PASSED    [ 98%]\nlib/matplotlib/tests/test_offsetbox.py::test_packers[bottom] FAILED      [ 98%]\nlib/matplotlib/tests/test_offsetbox.py::test_packers[top] FAILED         [ 98%]\nlib/matplotlib/tests/test_offsetbox.py::test_packers[left] PASSED        [ 99%]\nlib/matplotlib/tests/test_offsetbox.py::test_packers[right] PASSED       [ 99%]\nlib/matplotlib/tests/test_offsetbox.py::test_packers[center] PASSED      [100%]\n\n=================================== FAILURES ===================================\n_____________________________ test_packers[bottom] _____________________________\nlib/matplotlib/tests/test_offsetbox.py:366: in test_packers\n    assert_allclose([(0, y_height), (x1, 0)], offset_pairs)\n/opt/miniconda3/envs/testbed/lib/python3.11/contextlib.py:81: in inner\n    return func(*args, **kwds)\nE   AssertionError: \nE   Not equal to tolerance rtol=1e-07, atol=0\nE   \nE   Mismatched elements: 1 / 4 (25%)\nE   Max absolute difference: 30.\nE   Max relative difference: 1.\nE    x: array([[ 0,  0],\nE          [10,  0]])\nE    y: array([[ 0., 30.],\nE          [10.,  0.]])\n______________________________ test_packers[top] _______________________________\nlib/matplotlib/tests/test_offsetbox.py:366: in test_packers\n    assert_allclose([(0, y_height), (x1, 0)], offset_pairs)\n/opt/miniconda3/envs/testbed/lib/python3.11/contextlib.py:81: in inner\n    return func(*args, **kwds)\nE   AssertionError: \nE   Not equal to tolerance rtol=1e-07, atol=0\nE   \nE   Mismatched elements: 1 / 4 (25%)\nE   Max absolute difference: 30.\nE   Max relative difference: 0.\nE    x: array([[ 0, 30],\nE          [10,  0]])\nE    y: array([[ 0.,  0.],\nE          [10.,  0.]])\n=================== 2 failed, 275 passed, 1 skipped in 7.02s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_offsetbox.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_offsetbox.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 277,
          "failed": 0,
          "errors": 0,
          "collected": 278,
          "duration": 10.86,
          "log_tail": "lib/matplotlib/tests/test_offsetbox.py::test_get_packed_offsets[equal--1-100-widths2] PASSED [ 83%]\nlib/matplotlib/tests/test_offsetbox.py::test_get_packed_offsets[equal--1-100-widths3] PASSED [ 84%]\nlib/matplotlib/tests/test_offsetbox.py::test_get_packed_offsets[equal--1-0-widths0] PASSED [ 84%]\nlib/matplotlib/tests/test_offsetbox.py::test_get_packed_offsets[equal--1-0-widths1] PASSED [ 84%]\nlib/matplotlib/tests/test_offsetbox.py::test_get_packed_offsets[equal--1-0-widths2] PASSED [ 85%]\nlib/matplotlib/tests/test_offsetbox.py::test_get_packed_offsets[equal--1-0-widths3] PASSED [ 85%]\nlib/matplotlib/tests/test_offsetbox.py::test_get_packed_offsets[equal--1--1-widths0] PASSED [ 85%]\nlib/matplotlib/tests/test_offsetbox.py::test_get_packed_offsets[equal--1--1-widths1] PASSED [ 86%]\nlib/matplotlib/tests/test_offsetbox.py::test_get_packed_offsets[equal--1--1-widths2] PASSED [ 86%]\nlib/matplotlib/tests/test_offsetbox.py::test_get_packed_offsets[equal--1--1-widths3] PASSED [ 87%]\nlib/matplotlib/tests/test_offsetbox.py::test_get_packed_offsets[equal--1-None-widths0] PASSED [ 87%]\nlib/matplotlib/tests/test_offsetbox.py::test_get_packed_offsets[equal--1-None-widths1] PASSED [ 87%]\nlib/matplotlib/tests/test_offsetbox.py::test_get_packed_offsets[equal--1-None-widths2] PASSED [ 88%]\nlib/matplotlib/tests/test_offsetbox.py::test_get_packed_offsets[equal--1-None-widths3] PASSED [ 88%]\nlib/matplotlib/tests/test_offsetbox.py::test_get_packed_offsets_fixed[widths0-None-1-expected0] PASSED [ 88%]\nlib/matplotlib/tests/test_offsetbox.py::test_get_packed_offsets_fixed[widths1-10-1-expected1] PASSED [ 89%]\nlib/matplotlib/tests/test_offsetbox.py::test_get_packed_offsets_fixed[widths2-5-1-expected2] PASSED [ 89%]\nlib/matplotlib/tests/test_offsetbox.py::test_get_packed_offsets_expand[widths0-None-None-expected0] PASSED [ 89%]\nlib/matplotlib/tests/test_offsetbox.py::test_get_packed_offsets_expand[widths1-10-1-expected1] PASSED [ 90%]\nlib/matplotlib/tests/test_offsetbox.py::test_get_packed_offsets_expand[widths2-5-1-expected2] PASSED [ 90%]\nlib/matplotlib/tests/test_offsetbox.py::test_get_packed_offsets_equal[widths0-6-None-expected0] PASSED [ 91%]\nlib/matplotlib/tests/test_offsetbox.py::test_get_packed_offsets_equal[widths1-2-None-expected1] PASSED [ 91%]\nlib/matplotlib/tests/test_offsetbox.py::test_get_packed_offsets_equal[widths2-None-1-expected2] PASSED [ 91%]\nlib/matplotlib/tests/test_offsetbox.py::test_get_packed_offsets_equal_total_none_sep_none PASSED [ 92%]\nlib/matplotlib/tests/test_offsetbox.py::test_picking[axes fraction-draw] PASSED [ 92%]\nlib/matplotlib/tests/test_offsetbox.py::test_picking[axes fraction-image] PASSED [ 92%]\nlib/matplotlib/tests/test_offsetbox.py::test_picking[axes fraction-text] PASSED [ 93%]\nlib/matplotlib/tests/test_offsetbox.py::test_picking[axes pixels-draw] PASSED [ 93%]\nlib/matplotlib/tests/test_offsetbox.py::test_picking[axes pixels-image] PASSED [ 93%]\nlib/matplotlib/tests/test_offsetbox.py::test_picking[axes pixels-text] PASSED [ 94%]\nlib/matplotlib/tests/test_offsetbox.py::test_picking[axes points-draw] PASSED [ 94%]\nlib/matplotlib/tests/test_offsetbox.py::test_picking[axes points-image] PASSED [ 94%]\nlib/matplotlib/tests/test_offsetbox.py::test_picking[axes points-text] PASSED [ 95%]\nlib/matplotlib/tests/test_offsetbox.py::test_picking[data-draw] PASSED   [ 95%]\nlib/matplotlib/tests/test_offsetbox.py::test_picking[data-image] PASSED  [ 96%]\nlib/matplotlib/tests/test_offsetbox.py::test_picking[data-text] PASSED   [ 96%]\nlib/matplotlib/tests/test_offsetbox.py::test_anchoredtext_horizontal_alignment[png] PASSED [ 96%]\nlib/matplotlib/tests/test_offsetbox.py::test_annotationbbox_extents PASSED [ 97%]\nlib/matplotlib/tests/test_offsetbox.py::test_zorder PASSED               [ 97%]\nlib/matplotlib/tests/test_offsetbox.py::test_arrowprops_copied PASSED    [ 97%]\nlib/matplotlib/tests/test_offsetbox.py::test_packers[baseline] PASSED    [ 98%]\nlib/matplotlib/tests/test_offsetbox.py::test_packers[bottom] PASSED      [ 98%]\nlib/matplotlib/tests/test_offsetbox.py::test_packers[top] PASSED         [ 98%]\nlib/matplotlib/tests/test_offsetbox.py::test_packers[left] PASSED        [ 99%]\nlib/matplotlib/tests/test_offsetbox.py::test_packers[right] PASSED       [ 99%]\nlib/matplotlib/tests/test_offsetbox.py::test_packers[center] PASSED      [100%]\n\n======================== 277 passed, 1 skipped in 7.09s ========================\n\n",
          "test_files_run": [
            "lib/matplotlib/tests/test_offsetbox.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "matplotlib__matplotlib-24627",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://34.41.233.120:8080",
      "error": "HTTPConnectionPool(host='34.41.233.120', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "matplotlib__matplotlib-24637",
      "repo": "matplotlib/matplotlib",
      "valid": true,
      "worker": "http://34.41.233.120:8080",
      "duration": 29.265553951263428,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 30,
          "failed": 1,
          "errors": 0,
          "collected": 50,
          "duration": 14.56,
          "log_tail": "lib/matplotlib/tests/test_backend_svg.py::test_rasterized[svg] SKIPPED   [ 22%]\nlib/matplotlib/tests/test_backend_svg.py::test_rasterized_ordering[png] PASSED [ 24%]\nlib/matplotlib/tests/test_backend_svg.py::test_rasterized_ordering[pdf] PASSED [ 26%]\nlib/matplotlib/tests/test_backend_svg.py::test_rasterized_ordering[svg] SKIPPED [ 28%]\nlib/matplotlib/tests/test_backend_svg.py::test_prevent_rasterization[svg] SKIPPED [ 30%]\nlib/matplotlib/tests/test_backend_svg.py::test_prevent_rasterization[pdf] PASSED [ 32%]\nlib/matplotlib/tests/test_backend_svg.py::test_count_bitmaps PASSED      [ 34%]\nlib/matplotlib/tests/test_backend_svg.py::test_unicode_won PASSED        [ 36%]\nlib/matplotlib/tests/test_backend_svg.py::test_svgnone_with_data_coordinates PASSED [ 38%]\nlib/matplotlib/tests/test_backend_svg.py::test_gid PASSED                [ 40%]\nlib/matplotlib/tests/test_backend_svg.py::test_savefig_tight PASSED      [ 42%]\nlib/matplotlib/tests/test_backend_svg.py::test_url PASSED                [ 44%]\nlib/matplotlib/tests/test_backend_svg.py::test_url_tick PASSED           [ 46%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_default_metadata PASSED [ 48%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_clear_default_metadata PASSED [ 50%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_clear_all_metadata PASSED [ 52%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_metadata PASSED       [ 54%]\nlib/matplotlib/tests/test_backend_svg.py::test_multi_font_type3[svg] SKIPPED [ 56%]\nlib/matplotlib/tests/test_backend_svg.py::test_multi_font_type42[svg] SKIPPED [ 58%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_incorrect_metadata[metadata0-TypeError-Invalid type for Date metadata. Expected str] PASSED [ 60%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_incorrect_metadata[metadata1-TypeError-Invalid type for Date metadata. Expected iterable] PASSED [ 62%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_incorrect_metadata[metadata2-TypeError-Invalid type for Keywords metadata. Expected str] PASSED [ 64%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_incorrect_metadata[metadata3-TypeError-Invalid type for Keywords metadata. Expected iterable] PASSED [ 66%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_incorrect_metadata[metadata4-TypeError-Invalid type for Creator metadata. Expected str] PASSED [ 68%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_incorrect_metadata[metadata5-TypeError-Invalid type for Creator metadata. Expected iterable] PASSED [ 70%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_incorrect_metadata[metadata6-TypeError-Invalid type for Title metadata. Expected str] PASSED [ 72%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_incorrect_metadata[metadata7-TypeError-Invalid type for Format metadata. Expected str] PASSED [ 74%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_incorrect_metadata[metadata8-ValueError-Unknown metadata key] PASSED [ 76%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_escape PASSED         [ 78%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_font_string[True-'DejaVu Sans', 'WenQuanYi Zen Hei', 'Arial', sans-serif] SKIPPED [ 80%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_font_string[True-'DejaVu Serif', 'WenQuanYi Zen Hei', 'Times New Roman', serif] SKIPPED [ 82%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_font_string[True-'Arial', 'WenQuanYi Zen Hei', cursive] SKIPPED [ 84%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_font_string[True-'Impact', 'WenQuanYi Zen Hei', fantasy] SKIPPED [ 86%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_font_string[True-'DejaVu Sans Mono', 'WenQuanYi Zen Hei', 'Courier New', monospace] SKIPPED [ 88%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_font_string[False-'DejaVu Sans', 'WenQuanYi Zen Hei', 'Arial', sans-serif] SKIPPED [ 90%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_font_string[False-'DejaVu Serif', 'WenQuanYi Zen Hei', 'Times New Roman', serif] SKIPPED [ 92%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_font_string[False-'Arial', 'WenQuanYi Zen Hei', cursive] SKIPPED [ 94%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_font_string[False-'Impact', 'WenQuanYi Zen Hei', fantasy] SKIPPED [ 96%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_font_string[False-'DejaVu Sans Mono', 'WenQuanYi Zen Hei', 'Courier New', monospace] SKIPPED [ 98%]\nlib/matplotlib/tests/test_backend_svg.py::test_annotationbbox_gid FAILED [100%]\n\n=================================== FAILURES ===================================\n___________________________ test_annotationbbox_gid ____________________________\nlib/matplotlib/tests/test_backend_svg.py:643: in test_annotationbbox_gid\n    assert expected in buf\nE   assert '<g id=\"a test for issue 20044\">' in '<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"576pt\" height=\"432pt\" viewBox=\"0 0 576 432\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\\n <metadata>\\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\\n   <cc:Work>\\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\\n    <dc:date>2025-08-10T06:14:12.304636</dc:date>\\n    <dc:format>image/svg+xml</dc:format>\\n    <dc:creator>\\n     <cc:Agent>\\n      <dc:title>Matplotlib v3.7.0.dev1017+ga9ba9d5d3f.d20250810, https://matplotlib.org/</dc:title>\\n     </cc:Agent>\\n    </dc:creator>\\n   </cc:Work>\\n  </rdf:RDF>\\n </metadata>\\n <defs>\\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\\n </defs>\\n <g id=\"figure_1\">\\n  <g id=\"patch_1\">\\n   <path d=\"M 0 432 \\nL 576 432 \\nL 576 0 \\nL 0 0 \\nz\\n\" style=\"fill: #ffffff\"/>\\n  </g>\\n  <g id=\"axes_1\">\\n   <g id=\"patch_2\">\\n    <path d=\"M 72 388.8 \\nL 518.4 388.8 \\nL 518.4 43.2 \\...yle=\"stroke: #000000; stroke-width: 0.5\"/>\\n      </g>\\n     </g>\\n     <g id=\"text_12\">\\n      <!-- 1.0 -->\\n      <g transform=\"translate(48.91625 47.759062) scale(0.12 -0.12)\">\\n       <use xlink:href=\"#DejaVuSans-31\"/>\\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\\n      </g>\\n     </g>\\n    </g>\\n   </g>\\n   <g id=\"patch_7\">\\n    <path d=\"M 314.617098 278.72 \\nL 208.92 278.72 \\nQ 205.92 278.72 205.92 275.72 \\nL 205.92 201.835409 \\n\" style=\"fill: none; stroke: #000000; stroke-linecap: round\"/>\\n    <path d=\"M 203.04 207.595409 \\nL 205.92 201.835409 \\nL 208.8 207.595409 \\n\" style=\"fill: none; stroke: #000000; stroke-linecap: round\"/>\\n   </g>\\n   <g id=\"patch_8\">\\n    <path d=\"M 317.12 287.52 \\nL 334.72 287.52 \\nL 334.72 269.92 \\nL 317.12 269.92 \\nz\\n\" style=\"fill: #ffffff; stroke: #000000; stroke-linejoin: miter\"/>\\n   </g>\\n   <image xlink:href=\"data:image/png;base64,\\niVBORw0KGgoAAAANSUhEUgAAAAUAAAAFCAYAAACNbyblAAAAFUlEQVR4nGNkYKj/z4AGmNAFqCAIAJmrAYgL+X2mAAAAAElFTkSuQmCC\" id=\"image6ba1e21e23\" transform=\"scale(1 -1) translate(0 -3.6)\" x=\"324.32\" y=\"-276.72\" width=\"3.6\" height=\"3.6\"/>\\n  </g>\\n </g>\\n</svg>\\n'\n================== 1 failed, 30 passed, 19 skipped in 11.07s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_backend_svg.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_backend_svg.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 31,
          "failed": 0,
          "errors": 0,
          "collected": 50,
          "duration": 13.23,
          "log_tail": "lib/matplotlib/tests/test_backend_svg.py::test_noscale[svg] SKIPPED      [ 10%]\nlib/matplotlib/tests/test_backend_svg.py::test_text_urls PASSED          [ 12%]\nlib/matplotlib/tests/test_backend_svg.py::test_bold_font_output[svg] SKIPPED [ 14%]\nlib/matplotlib/tests/test_backend_svg.py::test_bold_font_output_with_none_fonttype[svg] SKIPPED [ 16%]\nlib/matplotlib/tests/test_backend_svg.py::test_rasterized[png] PASSED    [ 18%]\nlib/matplotlib/tests/test_backend_svg.py::test_rasterized[pdf] PASSED    [ 20%]\nlib/matplotlib/tests/test_backend_svg.py::test_rasterized[svg] SKIPPED   [ 22%]\nlib/matplotlib/tests/test_backend_svg.py::test_rasterized_ordering[png] PASSED [ 24%]\nlib/matplotlib/tests/test_backend_svg.py::test_rasterized_ordering[pdf] PASSED [ 26%]\nlib/matplotlib/tests/test_backend_svg.py::test_rasterized_ordering[svg] SKIPPED [ 28%]\nlib/matplotlib/tests/test_backend_svg.py::test_prevent_rasterization[svg] SKIPPED [ 30%]\nlib/matplotlib/tests/test_backend_svg.py::test_prevent_rasterization[pdf] PASSED [ 32%]\nlib/matplotlib/tests/test_backend_svg.py::test_count_bitmaps PASSED      [ 34%]\nlib/matplotlib/tests/test_backend_svg.py::test_unicode_won PASSED        [ 36%]\nlib/matplotlib/tests/test_backend_svg.py::test_svgnone_with_data_coordinates PASSED [ 38%]\nlib/matplotlib/tests/test_backend_svg.py::test_gid PASSED                [ 40%]\nlib/matplotlib/tests/test_backend_svg.py::test_savefig_tight PASSED      [ 42%]\nlib/matplotlib/tests/test_backend_svg.py::test_url PASSED                [ 44%]\nlib/matplotlib/tests/test_backend_svg.py::test_url_tick PASSED           [ 46%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_default_metadata PASSED [ 48%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_clear_default_metadata PASSED [ 50%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_clear_all_metadata PASSED [ 52%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_metadata PASSED       [ 54%]\nlib/matplotlib/tests/test_backend_svg.py::test_multi_font_type3[svg] SKIPPED [ 56%]\nlib/matplotlib/tests/test_backend_svg.py::test_multi_font_type42[svg] SKIPPED [ 58%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_incorrect_metadata[metadata0-TypeError-Invalid type for Date metadata. Expected str] PASSED [ 60%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_incorrect_metadata[metadata1-TypeError-Invalid type for Date metadata. Expected iterable] PASSED [ 62%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_incorrect_metadata[metadata2-TypeError-Invalid type for Keywords metadata. Expected str] PASSED [ 64%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_incorrect_metadata[metadata3-TypeError-Invalid type for Keywords metadata. Expected iterable] PASSED [ 66%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_incorrect_metadata[metadata4-TypeError-Invalid type for Creator metadata. Expected str] PASSED [ 68%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_incorrect_metadata[metadata5-TypeError-Invalid type for Creator metadata. Expected iterable] PASSED [ 70%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_incorrect_metadata[metadata6-TypeError-Invalid type for Title metadata. Expected str] PASSED [ 72%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_incorrect_metadata[metadata7-TypeError-Invalid type for Format metadata. Expected str] PASSED [ 74%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_incorrect_metadata[metadata8-ValueError-Unknown metadata key] PASSED [ 76%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_escape PASSED         [ 78%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_font_string[True-'DejaVu Sans', 'WenQuanYi Zen Hei', 'Arial', sans-serif] SKIPPED [ 80%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_font_string[True-'DejaVu Serif', 'WenQuanYi Zen Hei', 'Times New Roman', serif] SKIPPED [ 82%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_font_string[True-'Arial', 'WenQuanYi Zen Hei', cursive] SKIPPED [ 84%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_font_string[True-'Impact', 'WenQuanYi Zen Hei', fantasy] SKIPPED [ 86%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_font_string[True-'DejaVu Sans Mono', 'WenQuanYi Zen Hei', 'Courier New', monospace] SKIPPED [ 88%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_font_string[False-'DejaVu Sans', 'WenQuanYi Zen Hei', 'Arial', sans-serif] SKIPPED [ 90%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_font_string[False-'DejaVu Serif', 'WenQuanYi Zen Hei', 'Times New Roman', serif] SKIPPED [ 92%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_font_string[False-'Arial', 'WenQuanYi Zen Hei', cursive] SKIPPED [ 94%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_font_string[False-'Impact', 'WenQuanYi Zen Hei', fantasy] SKIPPED [ 96%]\nlib/matplotlib/tests/test_backend_svg.py::test_svg_font_string[False-'DejaVu Sans Mono', 'WenQuanYi Zen Hei', 'Courier New', monospace] SKIPPED [ 98%]\nlib/matplotlib/tests/test_backend_svg.py::test_annotationbbox_gid PASSED [100%]\n\n======================== 31 passed, 19 skipped in 9.73s ========================\n\n",
          "test_files_run": [
            "lib/matplotlib/tests/test_backend_svg.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "matplotlib__matplotlib-24870",
      "repo": "matplotlib/matplotlib",
      "valid": true,
      "worker": "http://34.41.233.120:8080",
      "duration": 27.489903688430786,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 65,
          "failed": 1,
          "errors": 0,
          "collected": 67,
          "duration": 13.78,
          "log_tail": "lib/matplotlib/tests/test_contour.py::test_label_nonagg PASSED           [ 55%]\nlib/matplotlib/tests/test_contour.py::test_contour_closed_line_loop[png] PASSED [ 56%]\nlib/matplotlib/tests/test_contour.py::test_quadcontourset_reuse PASSED   [ 58%]\nlib/matplotlib/tests/test_contour.py::test_contour_manual[png] PASSED    [ 59%]\nlib/matplotlib/tests/test_contour.py::test_contour_line_start_on_corner_edge[png] PASSED [ 61%]\nlib/matplotlib/tests/test_contour.py::test_find_nearest_contour PASSED   [ 62%]\nlib/matplotlib/tests/test_contour.py::test_find_nearest_contour_no_filled PASSED [ 64%]\nlib/matplotlib/tests/test_contour.py::test_contour_autolabel_beyond_powerlimits PASSED [ 65%]\nlib/matplotlib/tests/test_contour.py::test_contourf_legend_elements PASSED [ 67%]\nlib/matplotlib/tests/test_contour.py::test_contour_legend_elements PASSED [ 68%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_name[mpl2005-Mpl2005ContourGenerator] PASSED [ 70%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_name[mpl2014-Mpl2014ContourGenerator] PASSED [ 71%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_name[serial-SerialContourGenerator] PASSED [ 73%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_name[threaded-ThreadedContourGenerator] PASSED [ 74%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_name[invalid-None] PASSED [ 76%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_supports_corner_mask[mpl2005] PASSED [ 77%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_supports_corner_mask[mpl2014] PASSED [ 79%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_supports_corner_mask[serial] PASSED [ 80%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_supports_corner_mask[threaded] PASSED [ 82%]\nlib/matplotlib/tests/test_contour.py::test_all_algorithms[png] PASSED    [ 83%]\nlib/matplotlib/tests/test_contour.py::test_subfigure_clabel PASSED       [ 85%]\nlib/matplotlib/tests/test_contour.py::test_linestyles[solid] PASSED      [ 86%]\nlib/matplotlib/tests/test_contour.py::test_linestyles[dashed] PASSED     [ 88%]\nlib/matplotlib/tests/test_contour.py::test_linestyles[dashdot] PASSED    [ 89%]\nlib/matplotlib/tests/test_contour.py::test_linestyles[dotted] PASSED     [ 91%]\nlib/matplotlib/tests/test_contour.py::test_negative_linestyles[solid] PASSED [ 92%]\nlib/matplotlib/tests/test_contour.py::test_negative_linestyles[dashed] PASSED [ 94%]\nlib/matplotlib/tests/test_contour.py::test_negative_linestyles[dashdot] PASSED [ 95%]\nlib/matplotlib/tests/test_contour.py::test_negative_linestyles[dotted] PASSED [ 97%]\nlib/matplotlib/tests/test_contour.py::test_contour_remove PASSED         [ 98%]\nlib/matplotlib/tests/test_contour.py::test_bool_autolevel FAILED         [100%]\n\n=================================== FAILURES ===================================\n_____________________________ test_bool_autolevel ______________________________\nlib/matplotlib/tests/test_contour.py:702: in test_bool_autolevel\n    assert plt.contour(z.tolist()).levels.tolist() == [.5]\nE   AssertionError: assert [0.0, 0.15000...00000001, ...] == [0.5]\nE     \nE     At index 0 diff: 0.0 != 0.5\nE     Left contains 7 more items, first extra item: 0.15000000000000002\nE     \nE     Full diff:\nE       [\nE     -     0.5,...\nE     \nE     ...Full output truncated (11 lines hidden), use '-vv' to show\n=================== 1 failed, 65 passed, 1 skipped in 10.01s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_contour.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_contour.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 66,
          "failed": 0,
          "errors": 0,
          "collected": 67,
          "duration": 12.04,
          "log_tail": "lib/matplotlib/tests/test_contour.py::test_labels[png] PASSED            [ 32%]\nlib/matplotlib/tests/test_contour.py::test_corner_mask[png] PASSED       [ 34%]\nlib/matplotlib/tests/test_contour.py::test_contourf_decreasing_levels PASSED [ 35%]\nlib/matplotlib/tests/test_contour.py::test_contourf_symmetric_locator PASSED [ 37%]\nlib/matplotlib/tests/test_contour.py::test_circular_contour_warning PASSED [ 38%]\nlib/matplotlib/tests/test_contour.py::test_clabel_zorder[True-123-1234] PASSED [ 40%]\nlib/matplotlib/tests/test_contour.py::test_clabel_zorder[False-123-1234] PASSED [ 41%]\nlib/matplotlib/tests/test_contour.py::test_clabel_zorder[True-123-None] PASSED [ 43%]\nlib/matplotlib/tests/test_contour.py::test_clabel_zorder[False-123-None] PASSED [ 44%]\nlib/matplotlib/tests/test_contour.py::test_contourf_log_extension[png] PASSED [ 46%]\nlib/matplotlib/tests/test_contour.py::test_contour_addlines[png] PASSED  [ 47%]\nlib/matplotlib/tests/test_contour.py::test_contour_uneven[png] PASSED    [ 49%]\nlib/matplotlib/tests/test_contour.py::test_contour_linewidth[1.23-None-None-1.23] PASSED [ 50%]\nlib/matplotlib/tests/test_contour.py::test_contour_linewidth[1.23-4.24-None-4.24] PASSED [ 52%]\nlib/matplotlib/tests/test_contour.py::test_contour_linewidth[1.23-4.24-5.02-5.02] PASSED [ 53%]\nlib/matplotlib/tests/test_contour.py::test_label_nonagg PASSED           [ 55%]\nlib/matplotlib/tests/test_contour.py::test_contour_closed_line_loop[png] PASSED [ 56%]\nlib/matplotlib/tests/test_contour.py::test_quadcontourset_reuse PASSED   [ 58%]\nlib/matplotlib/tests/test_contour.py::test_contour_manual[png] PASSED    [ 59%]\nlib/matplotlib/tests/test_contour.py::test_contour_line_start_on_corner_edge[png] PASSED [ 61%]\nlib/matplotlib/tests/test_contour.py::test_find_nearest_contour PASSED   [ 62%]\nlib/matplotlib/tests/test_contour.py::test_find_nearest_contour_no_filled PASSED [ 64%]\nlib/matplotlib/tests/test_contour.py::test_contour_autolabel_beyond_powerlimits PASSED [ 65%]\nlib/matplotlib/tests/test_contour.py::test_contourf_legend_elements PASSED [ 67%]\nlib/matplotlib/tests/test_contour.py::test_contour_legend_elements PASSED [ 68%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_name[mpl2005-Mpl2005ContourGenerator] PASSED [ 70%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_name[mpl2014-Mpl2014ContourGenerator] PASSED [ 71%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_name[serial-SerialContourGenerator] PASSED [ 73%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_name[threaded-ThreadedContourGenerator] PASSED [ 74%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_name[invalid-None] PASSED [ 76%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_supports_corner_mask[mpl2005] PASSED [ 77%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_supports_corner_mask[mpl2014] PASSED [ 79%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_supports_corner_mask[serial] PASSED [ 80%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_supports_corner_mask[threaded] PASSED [ 82%]\nlib/matplotlib/tests/test_contour.py::test_all_algorithms[png] PASSED    [ 83%]\nlib/matplotlib/tests/test_contour.py::test_subfigure_clabel PASSED       [ 85%]\nlib/matplotlib/tests/test_contour.py::test_linestyles[solid] PASSED      [ 86%]\nlib/matplotlib/tests/test_contour.py::test_linestyles[dashed] PASSED     [ 88%]\nlib/matplotlib/tests/test_contour.py::test_linestyles[dashdot] PASSED    [ 89%]\nlib/matplotlib/tests/test_contour.py::test_linestyles[dotted] PASSED     [ 91%]\nlib/matplotlib/tests/test_contour.py::test_negative_linestyles[solid] PASSED [ 92%]\nlib/matplotlib/tests/test_contour.py::test_negative_linestyles[dashed] PASSED [ 94%]\nlib/matplotlib/tests/test_contour.py::test_negative_linestyles[dashdot] PASSED [ 95%]\nlib/matplotlib/tests/test_contour.py::test_negative_linestyles[dotted] PASSED [ 97%]\nlib/matplotlib/tests/test_contour.py::test_contour_remove PASSED         [ 98%]\nlib/matplotlib/tests/test_contour.py::test_bool_autolevel PASSED         [100%]\n\n======================== 66 passed, 1 skipped in 8.45s =========================\n\n",
          "test_files_run": [
            "lib/matplotlib/tests/test_contour.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "matplotlib__matplotlib-24970",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://34.41.233.120:8080",
      "duration": 27.39351511001587,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 253,
          "failed": 2,
          "errors": 0,
          "collected": 256,
          "duration": 13.54,
          "log_tail": "lib/matplotlib/tests/test_colors.py::test_has_alpha_channel PASSED       [ 88%]\nlib/matplotlib/tests/test_colors.py::test_cn PASSED                      [ 88%]\nlib/matplotlib/tests/test_colors.py::test_conversions PASSED             [ 89%]\nlib/matplotlib/tests/test_colors.py::test_conversions_masked PASSED      [ 89%]\nlib/matplotlib/tests/test_colors.py::test_to_rgba_array_single_str PASSED [ 89%]\nlib/matplotlib/tests/test_colors.py::test_to_rgba_array_alpha_array PASSED [ 90%]\nlib/matplotlib/tests/test_colors.py::test_failed_conversions PASSED      [ 90%]\nlib/matplotlib/tests/test_colors.py::test_grey_gray PASSED               [ 91%]\nlib/matplotlib/tests/test_colors.py::test_tableau_order PASSED           [ 91%]\nlib/matplotlib/tests/test_colors.py::test_ndarray_subclass_norm PASSED   [ 91%]\nlib/matplotlib/tests/test_colors.py::test_same_color PASSED              [ 92%]\nlib/matplotlib/tests/test_colors.py::test_hex_shorthand_notation PASSED  [ 92%]\nlib/matplotlib/tests/test_colors.py::test_repr_png PASSED                [ 92%]\nlib/matplotlib/tests/test_colors.py::test_repr_html PASSED               [ 93%]\nlib/matplotlib/tests/test_colors.py::test_get_under_over_bad PASSED      [ 93%]\nlib/matplotlib/tests/test_colors.py::test_non_mutable_get_values[over] PASSED [ 94%]\nlib/matplotlib/tests/test_colors.py::test_non_mutable_get_values[under] PASSED [ 94%]\nlib/matplotlib/tests/test_colors.py::test_non_mutable_get_values[bad] PASSED [ 94%]\nlib/matplotlib/tests/test_colors.py::test_colormap_alpha_array PASSED    [ 95%]\nlib/matplotlib/tests/test_colors.py::test_colormap_bad_data_with_alpha PASSED [ 95%]\nlib/matplotlib/tests/test_colors.py::test_2d_to_rgba PASSED              [ 96%]\nlib/matplotlib/tests/test_colors.py::test_set_dict_to_rgba PASSED        [ 96%]\nlib/matplotlib/tests/test_colors.py::test_norm_deepcopy PASSED           [ 96%]\nlib/matplotlib/tests/test_colors.py::test_norm_callback PASSED           [ 97%]\nlib/matplotlib/tests/test_colors.py::test_scalarmappable_norm_update PASSED [ 97%]\nlib/matplotlib/tests/test_colors.py::test_norm_update_figs[png] PASSED   [ 98%]\nlib/matplotlib/tests/test_colors.py::test_norm_update_figs[pdf] PASSED   [ 98%]\nlib/matplotlib/tests/test_colors.py::test_norm_update_figs[svg] SKIPPED  [ 98%]\nlib/matplotlib/tests/test_colors.py::test_make_norm_from_scale_name PASSED [ 99%]\nlib/matplotlib/tests/test_colors.py::test_color_sequences PASSED         [ 99%]\nlib/matplotlib/tests/test_colors.py::test_cm_set_cmap_error PASSED       [100%]\n\n=================================== FAILURES ===================================\n___________________________ test_index_dtype[uint8] ____________________________\nlib/matplotlib/tests/test_colors.py:37: in test_index_dtype\n    assert_array_equal(cm(dtype(0)), cm(0))\nlib/matplotlib/colors.py:730: in __call__\n    xa[xa > self.N - 1] = self._i_over\nE   DeprecationWarning: NumPy will stop allowing conversion of out-of-bound Python integers to integer arrays.  The conversion of 257 to uint8 will fail in the future.\nE   For the old behavior, usually:\nE       np.array(value).astype(dtype)\nE   will give the desired result (the cast overflows).\n______________________ test_double_register_builtin_cmap _______________________\nlib/matplotlib/tests/test_colors.py:149: in test_double_register_builtin_cmap\n    with pytest.warns(UserWarning):\nE   matplotlib._api.deprecation.MatplotlibDeprecationWarning: The register_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps.register(name)`` instead.\n=================== 2 failed, 253 passed, 1 skipped in 9.85s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_colors.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_colors.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 254,
          "failed": 1,
          "errors": 0,
          "collected": 256,
          "duration": 12.22,
          "log_tail": "lib/matplotlib/tests/test_colors.py::test_colormap_reversing[turbo_r] PASSED [ 84%]\nlib/matplotlib/tests/test_colors.py::test_colormap_reversing[twilight] PASSED [ 85%]\nlib/matplotlib/tests/test_colors.py::test_colormap_reversing[twilight_r] PASSED [ 85%]\nlib/matplotlib/tests/test_colors.py::test_colormap_reversing[twilight_shifted] PASSED [ 85%]\nlib/matplotlib/tests/test_colors.py::test_colormap_reversing[twilight_shifted_r] PASSED [ 86%]\nlib/matplotlib/tests/test_colors.py::test_colormap_reversing[viridis] PASSED [ 86%]\nlib/matplotlib/tests/test_colors.py::test_colormap_reversing[viridis_r] PASSED [ 87%]\nlib/matplotlib/tests/test_colors.py::test_colormap_reversing[winter] PASSED [ 87%]\nlib/matplotlib/tests/test_colors.py::test_colormap_reversing[winter_r] PASSED [ 87%]\nlib/matplotlib/tests/test_colors.py::test_has_alpha_channel PASSED       [ 88%]\nlib/matplotlib/tests/test_colors.py::test_cn PASSED                      [ 88%]\nlib/matplotlib/tests/test_colors.py::test_conversions PASSED             [ 89%]\nlib/matplotlib/tests/test_colors.py::test_conversions_masked PASSED      [ 89%]\nlib/matplotlib/tests/test_colors.py::test_to_rgba_array_single_str PASSED [ 89%]\nlib/matplotlib/tests/test_colors.py::test_to_rgba_array_alpha_array PASSED [ 90%]\nlib/matplotlib/tests/test_colors.py::test_failed_conversions PASSED      [ 90%]\nlib/matplotlib/tests/test_colors.py::test_grey_gray PASSED               [ 91%]\nlib/matplotlib/tests/test_colors.py::test_tableau_order PASSED           [ 91%]\nlib/matplotlib/tests/test_colors.py::test_ndarray_subclass_norm PASSED   [ 91%]\nlib/matplotlib/tests/test_colors.py::test_same_color PASSED              [ 92%]\nlib/matplotlib/tests/test_colors.py::test_hex_shorthand_notation PASSED  [ 92%]\nlib/matplotlib/tests/test_colors.py::test_repr_png PASSED                [ 92%]\nlib/matplotlib/tests/test_colors.py::test_repr_html PASSED               [ 93%]\nlib/matplotlib/tests/test_colors.py::test_get_under_over_bad PASSED      [ 93%]\nlib/matplotlib/tests/test_colors.py::test_non_mutable_get_values[over] PASSED [ 94%]\nlib/matplotlib/tests/test_colors.py::test_non_mutable_get_values[under] PASSED [ 94%]\nlib/matplotlib/tests/test_colors.py::test_non_mutable_get_values[bad] PASSED [ 94%]\nlib/matplotlib/tests/test_colors.py::test_colormap_alpha_array PASSED    [ 95%]\nlib/matplotlib/tests/test_colors.py::test_colormap_bad_data_with_alpha PASSED [ 95%]\nlib/matplotlib/tests/test_colors.py::test_2d_to_rgba PASSED              [ 96%]\nlib/matplotlib/tests/test_colors.py::test_set_dict_to_rgba PASSED        [ 96%]\nlib/matplotlib/tests/test_colors.py::test_norm_deepcopy PASSED           [ 96%]\nlib/matplotlib/tests/test_colors.py::test_norm_callback PASSED           [ 97%]\nlib/matplotlib/tests/test_colors.py::test_scalarmappable_norm_update PASSED [ 97%]\nlib/matplotlib/tests/test_colors.py::test_norm_update_figs[png] PASSED   [ 98%]\nlib/matplotlib/tests/test_colors.py::test_norm_update_figs[pdf] PASSED   [ 98%]\nlib/matplotlib/tests/test_colors.py::test_norm_update_figs[svg] SKIPPED  [ 98%]\nlib/matplotlib/tests/test_colors.py::test_make_norm_from_scale_name PASSED [ 99%]\nlib/matplotlib/tests/test_colors.py::test_color_sequences PASSED         [ 99%]\nlib/matplotlib/tests/test_colors.py::test_cm_set_cmap_error PASSED       [100%]\n\n=================================== FAILURES ===================================\n______________________ test_double_register_builtin_cmap _______________________\nlib/matplotlib/tests/test_colors.py:149: in test_double_register_builtin_cmap\n    with pytest.warns(UserWarning):\nE   matplotlib._api.deprecation.MatplotlibDeprecationWarning: The register_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps.register(name)`` instead.\n=================== 1 failed, 254 passed, 1 skipped in 8.31s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_colors.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_colors.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "matplotlib__matplotlib-25122",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://34.41.233.120:8080",
      "error": "HTTPConnectionPool(host='34.41.233.120', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "matplotlib__matplotlib-25287",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://34.41.233.120:8080",
      "error": "HTTPConnectionPool(host='34.41.233.120', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "matplotlib__matplotlib-25311",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://34.41.233.120:8080",
      "duration": 24.939837217330933,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 181,
          "failed": 2,
          "errors": 0,
          "collected": 183,
          "duration": 10.9,
          "log_tail": "lib/matplotlib/tests/test_pickle.py::test_cmap[cmap147] PASSED           [ 87%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap148] PASSED           [ 87%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap149] PASSED           [ 88%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap150] PASSED           [ 89%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap151] PASSED           [ 89%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap152] PASSED           [ 90%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap153] PASSED           [ 90%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap154] PASSED           [ 91%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap155] PASSED           [ 91%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap156] PASSED           [ 92%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap157] PASSED           [ 92%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap158] PASSED           [ 93%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap159] PASSED           [ 93%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap160] PASSED           [ 94%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap161] PASSED           [ 95%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap162] PASSED           [ 95%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap163] PASSED           [ 96%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap164] PASSED           [ 96%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap165] PASSED           [ 97%]\nlib/matplotlib/tests/test_pickle.py::test_unpickle_canvas PASSED         [ 97%]\nlib/matplotlib/tests/test_pickle.py::test_mpl_toolkits PASSED            [ 98%]\nlib/matplotlib/tests/test_pickle.py::test_standard_norm PASSED           [ 98%]\nlib/matplotlib/tests/test_pickle.py::test_dynamic_norm PASSED            [ 99%]\nlib/matplotlib/tests/test_pickle.py::test_vertexselector PASSED          [100%]\n\n=================================== FAILURES ===================================\n______________________________ test_complete[png] ______________________________\nlib/matplotlib/testing/decorators.py:472: in wrapper\n    func(*args, fig_test=fig_test, fig_ref=fig_ref, **kwargs)\nlib/matplotlib/tests/test_pickle.py:105: in test_complete\n    assert \"FigureCanvasAgg\" not in [arg for op, arg, pos in pickletools.genops(pkl)]\nE   AssertionError: assert 'FigureCanvasAgg' not in [5, 65538, 'matplotlib.figure', None, 'Figure', None, ...]\n------------------------------ Captured log call -------------------------------\nWARNING  matplotlib.legend:legend.py:1330 No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n____________________ test_pickle_load_from_subprocess[png] _____________________\nlib/matplotlib/testing/decorators.py:472: in wrapper\n    func(*args, fig_test=fig_test, fig_ref=fig_ref, **kwargs)\nlib/matplotlib/tests/test_pickle.py:145: in test_pickle_load_from_subprocess\n    loaded_fig = pickle.loads(ast.literal_eval(proc.stdout))\nlib/matplotlib/figure.py:3184: in __setstate__\n    _api.warn_external(\nlib/matplotlib/_api/__init__.py:388: in warn_external\n    warnings.warn(message, category, stacklevel)\nE   UserWarning: This figure was saved with matplotlib version 3.8.0.dev441+g430fb1db88.d19700101 and is unlikely to function correctly.\n------------------------------ Captured log call -------------------------------\nWARNING  matplotlib.legend:legend.py:1330 No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n======================== 2 failed, 181 passed in 7.26s =========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_pickle.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_pickle.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 182,
          "failed": 1,
          "errors": 0,
          "collected": 183,
          "duration": 12.53,
          "log_tail": "lib/matplotlib/tests/test_pickle.py::test_cmap[cmap139] PASSED           [ 83%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap140] PASSED           [ 83%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap141] PASSED           [ 84%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap142] PASSED           [ 84%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap143] PASSED           [ 85%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap144] PASSED           [ 85%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap145] PASSED           [ 86%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap146] PASSED           [ 86%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap147] PASSED           [ 87%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap148] PASSED           [ 87%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap149] PASSED           [ 88%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap150] PASSED           [ 89%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap151] PASSED           [ 89%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap152] PASSED           [ 90%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap153] PASSED           [ 90%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap154] PASSED           [ 91%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap155] PASSED           [ 91%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap156] PASSED           [ 92%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap157] PASSED           [ 92%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap158] PASSED           [ 93%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap159] PASSED           [ 93%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap160] PASSED           [ 94%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap161] PASSED           [ 95%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap162] PASSED           [ 95%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap163] PASSED           [ 96%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap164] PASSED           [ 96%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap165] PASSED           [ 97%]\nlib/matplotlib/tests/test_pickle.py::test_unpickle_canvas PASSED         [ 97%]\nlib/matplotlib/tests/test_pickle.py::test_mpl_toolkits PASSED            [ 98%]\nlib/matplotlib/tests/test_pickle.py::test_standard_norm PASSED           [ 98%]\nlib/matplotlib/tests/test_pickle.py::test_dynamic_norm PASSED            [ 99%]\nlib/matplotlib/tests/test_pickle.py::test_vertexselector PASSED          [100%]\n\n=================================== FAILURES ===================================\n____________________ test_pickle_load_from_subprocess[png] _____________________\nlib/matplotlib/testing/decorators.py:472: in wrapper\n    func(*args, fig_test=fig_test, fig_ref=fig_ref, **kwargs)\nlib/matplotlib/tests/test_pickle.py:145: in test_pickle_load_from_subprocess\n    loaded_fig = pickle.loads(ast.literal_eval(proc.stdout))\nlib/matplotlib/figure.py:3184: in __setstate__\n    _api.warn_external(\nlib/matplotlib/_api/__init__.py:388: in warn_external\n    warnings.warn(message, category, stacklevel)\nE   UserWarning: This figure was saved with matplotlib version 3.8.0.dev441+g430fb1db88.d19700101 and is unlikely to function correctly.\n------------------------------ Captured log call -------------------------------\nWARNING  matplotlib.legend:legend.py:1330 No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n======================== 1 failed, 182 passed in 8.59s =========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_pickle.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_pickle.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "matplotlib__matplotlib-25332",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://34.41.233.120:8080",
      "duration": 23.28343105316162,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 181,
          "failed": 2,
          "errors": 0,
          "collected": 183,
          "duration": 9.94,
          "log_tail": "lib/matplotlib/tests/test_pickle.py::test_cmap[cmap139] PASSED           [ 83%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap140] PASSED           [ 83%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap141] PASSED           [ 84%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap142] PASSED           [ 84%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap143] PASSED           [ 85%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap144] PASSED           [ 85%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap145] PASSED           [ 86%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap146] PASSED           [ 86%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap147] PASSED           [ 87%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap148] PASSED           [ 87%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap149] PASSED           [ 88%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap150] PASSED           [ 89%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap151] PASSED           [ 89%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap152] PASSED           [ 90%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap153] PASSED           [ 90%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap154] PASSED           [ 91%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap155] PASSED           [ 91%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap156] PASSED           [ 92%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap157] PASSED           [ 92%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap158] PASSED           [ 93%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap159] PASSED           [ 93%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap160] PASSED           [ 94%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap161] PASSED           [ 95%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap162] PASSED           [ 95%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap163] PASSED           [ 96%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap164] PASSED           [ 96%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap165] PASSED           [ 97%]\nlib/matplotlib/tests/test_pickle.py::test_unpickle_canvas PASSED         [ 97%]\nlib/matplotlib/tests/test_pickle.py::test_mpl_toolkits PASSED            [ 98%]\nlib/matplotlib/tests/test_pickle.py::test_standard_norm PASSED           [ 98%]\nlib/matplotlib/tests/test_pickle.py::test_dynamic_norm PASSED            [ 99%]\nlib/matplotlib/tests/test_pickle.py::test_vertexselector PASSED          [100%]\n\n=================================== FAILURES ===================================\n______________________________ test_complete[png] ______________________________\nlib/matplotlib/testing/decorators.py:472: in wrapper\n    func(*args, fig_test=fig_test, fig_ref=fig_ref, **kwargs)\nlib/matplotlib/tests/test_pickle.py:103: in test_complete\n    pickle.dump(fig_ref, pkl, pickle.HIGHEST_PROTOCOL)\nE   TypeError: cannot pickle 'weakref.ReferenceType' object\n____________________ test_pickle_load_from_subprocess[png] _____________________\nlib/matplotlib/testing/decorators.py:472: in wrapper\n    func(*args, fig_test=fig_test, fig_ref=fig_ref, **kwargs)\nlib/matplotlib/tests/test_pickle.py:134: in test_pickle_load_from_subprocess\n    pickle.dump(fig_ref, file, pickle.HIGHEST_PROTOCOL)\nE   TypeError: cannot pickle 'weakref.ReferenceType' object\n======================== 2 failed, 181 passed in 6.25s =========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_pickle.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_pickle.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 182,
          "failed": 1,
          "errors": 0,
          "collected": 183,
          "duration": 11.78,
          "log_tail": "lib/matplotlib/tests/test_pickle.py::test_cmap[cmap137] PASSED           [ 81%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap138] PASSED           [ 82%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap139] PASSED           [ 83%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap140] PASSED           [ 83%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap141] PASSED           [ 84%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap142] PASSED           [ 84%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap143] PASSED           [ 85%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap144] PASSED           [ 85%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap145] PASSED           [ 86%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap146] PASSED           [ 86%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap147] PASSED           [ 87%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap148] PASSED           [ 87%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap149] PASSED           [ 88%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap150] PASSED           [ 89%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap151] PASSED           [ 89%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap152] PASSED           [ 90%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap153] PASSED           [ 90%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap154] PASSED           [ 91%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap155] PASSED           [ 91%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap156] PASSED           [ 92%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap157] PASSED           [ 92%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap158] PASSED           [ 93%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap159] PASSED           [ 93%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap160] PASSED           [ 94%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap161] PASSED           [ 95%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap162] PASSED           [ 95%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap163] PASSED           [ 96%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap164] PASSED           [ 96%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap165] PASSED           [ 97%]\nlib/matplotlib/tests/test_pickle.py::test_unpickle_canvas PASSED         [ 97%]\nlib/matplotlib/tests/test_pickle.py::test_mpl_toolkits PASSED            [ 98%]\nlib/matplotlib/tests/test_pickle.py::test_standard_norm PASSED           [ 98%]\nlib/matplotlib/tests/test_pickle.py::test_dynamic_norm PASSED            [ 99%]\nlib/matplotlib/tests/test_pickle.py::test_vertexselector PASSED          [100%]\n\n=================================== FAILURES ===================================\n____________________ test_pickle_load_from_subprocess[png] _____________________\nlib/matplotlib/testing/decorators.py:472: in wrapper\n    func(*args, fig_test=fig_test, fig_ref=fig_ref, **kwargs)\nlib/matplotlib/tests/test_pickle.py:143: in test_pickle_load_from_subprocess\n    loaded_fig = pickle.loads(ast.literal_eval(proc.stdout))\nlib/matplotlib/figure.py:3184: in __setstate__\n    _api.warn_external(\nlib/matplotlib/_api/__init__.py:388: in warn_external\n    warnings.warn(message, category, stacklevel)\nE   UserWarning: This figure was saved with matplotlib version 3.8.0.dev452+g66ba515e67.d19700101 and is unlikely to function correctly.\n======================== 1 failed, 182 passed in 7.97s =========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_pickle.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_pickle.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "matplotlib__matplotlib-25479",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://34.41.233.120:8080",
      "duration": 26.259581804275513,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 263,
          "failed": 3,
          "errors": 0,
          "collected": 267,
          "duration": 12.36,
          "log_tail": "lib/matplotlib/tests/test_colors.py::test_to_rgba_accepts_color_alpha_tuple[rgba_alpha3] PASSED [ 89%]\nlib/matplotlib/tests/test_colors.py::test_to_rgba_explicit_alpha_overrides_tuple_alpha PASSED [ 89%]\nlib/matplotlib/tests/test_colors.py::test_to_rgba_error_with_color_invalid_alpha_tuple PASSED [ 90%]\nlib/matplotlib/tests/test_colors.py::test_failed_conversions PASSED      [ 90%]\nlib/matplotlib/tests/test_colors.py::test_grey_gray PASSED               [ 91%]\nlib/matplotlib/tests/test_colors.py::test_tableau_order PASSED           [ 91%]\nlib/matplotlib/tests/test_colors.py::test_ndarray_subclass_norm PASSED   [ 91%]\nlib/matplotlib/tests/test_colors.py::test_same_color PASSED              [ 92%]\nlib/matplotlib/tests/test_colors.py::test_hex_shorthand_notation PASSED  [ 92%]\nlib/matplotlib/tests/test_colors.py::test_repr_png PASSED                [ 92%]\nlib/matplotlib/tests/test_colors.py::test_repr_html PASSED               [ 93%]\nlib/matplotlib/tests/test_colors.py::test_get_under_over_bad PASSED      [ 93%]\nlib/matplotlib/tests/test_colors.py::test_non_mutable_get_values[over] PASSED [ 94%]\nlib/matplotlib/tests/test_colors.py::test_non_mutable_get_values[under] PASSED [ 94%]\nlib/matplotlib/tests/test_colors.py::test_non_mutable_get_values[bad] PASSED [ 94%]\nlib/matplotlib/tests/test_colors.py::test_colormap_alpha_array PASSED    [ 95%]\nlib/matplotlib/tests/test_colors.py::test_colormap_bad_data_with_alpha PASSED [ 95%]\nlib/matplotlib/tests/test_colors.py::test_2d_to_rgba PASSED              [ 95%]\nlib/matplotlib/tests/test_colors.py::test_set_dict_to_rgba PASSED        [ 96%]\nlib/matplotlib/tests/test_colors.py::test_norm_deepcopy PASSED           [ 96%]\nlib/matplotlib/tests/test_colors.py::test_norm_callback PASSED           [ 97%]\nlib/matplotlib/tests/test_colors.py::test_scalarmappable_norm_update PASSED [ 97%]\nlib/matplotlib/tests/test_colors.py::test_norm_update_figs[png] PASSED   [ 97%]\nlib/matplotlib/tests/test_colors.py::test_norm_update_figs[pdf] PASSED   [ 98%]\nlib/matplotlib/tests/test_colors.py::test_norm_update_figs[svg] SKIPPED  [ 98%]\nlib/matplotlib/tests/test_colors.py::test_make_norm_from_scale_name PASSED [ 98%]\nlib/matplotlib/tests/test_colors.py::test_color_sequences PASSED         [ 99%]\nlib/matplotlib/tests/test_colors.py::test_cm_set_cmap_error PASSED       [ 99%]\nlib/matplotlib/tests/test_colors.py::test_set_cmap_mismatched_name FAILED [100%]\n\n=================================== FAILURES ===================================\n______________________ test_double_register_builtin_cmap _______________________\nlib/matplotlib/tests/test_colors.py:150: in test_double_register_builtin_cmap\n    with pytest.warns(UserWarning):\nE   matplotlib._api.deprecation.MatplotlibDeprecationWarning: The register_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps.register(name)`` instead.\n_____________________________ test_colormap_equals _____________________________\nlib/matplotlib/tests/test_colors.py:201: in test_colormap_equals\n    assert cm_copy == cmap\nE   assert <matplotlib.colors.ListedColormap object at 0x79933d7696d0> == <matplotlib.colors.ListedColormap object at 0x799330561ed0>\n________________________ test_set_cmap_mismatched_name _________________________\nlib/matplotlib/tests/test_colors.py:1663: in test_set_cmap_mismatched_name\n    assert cmap_returned.name == \"wrong-cmap\"\nE   AssertionError: assert 'test-cmap' == 'wrong-cmap'\nE     \nE     - wrong-cmap\nE     + test-cmap\n=================== 3 failed, 263 passed, 1 skipped in 8.69s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_colors.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_colors.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 265,
          "failed": 1,
          "errors": 0,
          "collected": 267,
          "duration": 12.17,
          "log_tail": "lib/matplotlib/tests/test_colors.py::test_conversions PASSED             [ 85%]\nlib/matplotlib/tests/test_colors.py::test_conversions_masked PASSED      [ 85%]\nlib/matplotlib/tests/test_colors.py::test_to_rgba_array_single_str PASSED [ 86%]\nlib/matplotlib/tests/test_colors.py::test_to_rgba_array_alpha_array PASSED [ 86%]\nlib/matplotlib/tests/test_colors.py::test_to_rgba_array_accepts_color_alpha_tuple PASSED [ 86%]\nlib/matplotlib/tests/test_colors.py::test_to_rgba_array_explicit_alpha_overrides_tuple_alpha PASSED [ 87%]\nlib/matplotlib/tests/test_colors.py::test_to_rgba_array_accepts_color_alpha_tuple_with_multiple_colors PASSED [ 87%]\nlib/matplotlib/tests/test_colors.py::test_to_rgba_array_error_with_color_invalid_alpha_tuple PASSED [ 88%]\nlib/matplotlib/tests/test_colors.py::test_to_rgba_accepts_color_alpha_tuple[rgba_alpha0] PASSED [ 88%]\nlib/matplotlib/tests/test_colors.py::test_to_rgba_accepts_color_alpha_tuple[rgba_alpha1] PASSED [ 88%]\nlib/matplotlib/tests/test_colors.py::test_to_rgba_accepts_color_alpha_tuple[rgba_alpha2] PASSED [ 89%]\nlib/matplotlib/tests/test_colors.py::test_to_rgba_accepts_color_alpha_tuple[rgba_alpha3] PASSED [ 89%]\nlib/matplotlib/tests/test_colors.py::test_to_rgba_explicit_alpha_overrides_tuple_alpha PASSED [ 89%]\nlib/matplotlib/tests/test_colors.py::test_to_rgba_error_with_color_invalid_alpha_tuple PASSED [ 90%]\nlib/matplotlib/tests/test_colors.py::test_failed_conversions PASSED      [ 90%]\nlib/matplotlib/tests/test_colors.py::test_grey_gray PASSED               [ 91%]\nlib/matplotlib/tests/test_colors.py::test_tableau_order PASSED           [ 91%]\nlib/matplotlib/tests/test_colors.py::test_ndarray_subclass_norm PASSED   [ 91%]\nlib/matplotlib/tests/test_colors.py::test_same_color PASSED              [ 92%]\nlib/matplotlib/tests/test_colors.py::test_hex_shorthand_notation PASSED  [ 92%]\nlib/matplotlib/tests/test_colors.py::test_repr_png PASSED                [ 92%]\nlib/matplotlib/tests/test_colors.py::test_repr_html PASSED               [ 93%]\nlib/matplotlib/tests/test_colors.py::test_get_under_over_bad PASSED      [ 93%]\nlib/matplotlib/tests/test_colors.py::test_non_mutable_get_values[over] PASSED [ 94%]\nlib/matplotlib/tests/test_colors.py::test_non_mutable_get_values[under] PASSED [ 94%]\nlib/matplotlib/tests/test_colors.py::test_non_mutable_get_values[bad] PASSED [ 94%]\nlib/matplotlib/tests/test_colors.py::test_colormap_alpha_array PASSED    [ 95%]\nlib/matplotlib/tests/test_colors.py::test_colormap_bad_data_with_alpha PASSED [ 95%]\nlib/matplotlib/tests/test_colors.py::test_2d_to_rgba PASSED              [ 95%]\nlib/matplotlib/tests/test_colors.py::test_set_dict_to_rgba PASSED        [ 96%]\nlib/matplotlib/tests/test_colors.py::test_norm_deepcopy PASSED           [ 96%]\nlib/matplotlib/tests/test_colors.py::test_norm_callback PASSED           [ 97%]\nlib/matplotlib/tests/test_colors.py::test_scalarmappable_norm_update PASSED [ 97%]\nlib/matplotlib/tests/test_colors.py::test_norm_update_figs[png] PASSED   [ 97%]\nlib/matplotlib/tests/test_colors.py::test_norm_update_figs[pdf] PASSED   [ 98%]\nlib/matplotlib/tests/test_colors.py::test_norm_update_figs[svg] SKIPPED  [ 98%]\nlib/matplotlib/tests/test_colors.py::test_make_norm_from_scale_name PASSED [ 98%]\nlib/matplotlib/tests/test_colors.py::test_color_sequences PASSED         [ 99%]\nlib/matplotlib/tests/test_colors.py::test_cm_set_cmap_error PASSED       [ 99%]\nlib/matplotlib/tests/test_colors.py::test_set_cmap_mismatched_name PASSED [100%]\n\n=================================== FAILURES ===================================\n______________________ test_double_register_builtin_cmap _______________________\nlib/matplotlib/tests/test_colors.py:150: in test_double_register_builtin_cmap\n    with pytest.warns(UserWarning):\nE   matplotlib._api.deprecation.MatplotlibDeprecationWarning: The register_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps.register(name)`` instead.\n=================== 1 failed, 265 passed, 1 skipped in 8.54s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_colors.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_colors.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "matplotlib__matplotlib-25775",
      "repo": "matplotlib/matplotlib",
      "valid": true,
      "worker": "http://34.41.233.120:8080",
      "duration": 43.84276103973389,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 92,
          "failed": 9,
          "errors": 0,
          "collected": 109,
          "duration": 23.83,
          "log_tail": "    func(*args, fig_test=fig_test, fig_ref=fig_ref, **kwargs)\nlib/matplotlib/tests/test_text.py:961: in test_text_antialiased_on_default_vs_manual\n    fig_test.text(0.5, 0.5, '6 inches x 2 inches', antialiased=True)\nlib/matplotlib/figure.py:1185: in text\n    text = Text(x=x, y=y, text=s, **effective_kwargs)\nlib/matplotlib/text.py:153: in __init__\n    self.update(kwargs)\nlib/matplotlib/text.py:201: in update\n    super().update(kwargs)\nlib/matplotlib/artist.py:1208: in update\n    return self._update_props(\nlib/matplotlib/artist.py:1192: in _update_props\n    raise AttributeError(\nE   AttributeError: 'Text' object has no property 'antialiased'\n_______________ test_text_antialiased_on_default_vs_manual[pdf] ________________\nlib/matplotlib/testing/decorators.py:411: in wrapper\n    func(*args, fig_test=fig_test, fig_ref=fig_ref, **kwargs)\nlib/matplotlib/tests/test_text.py:961: in test_text_antialiased_on_default_vs_manual\n    fig_test.text(0.5, 0.5, '6 inches x 2 inches', antialiased=True)\nlib/matplotlib/figure.py:1185: in text\n    text = Text(x=x, y=y, text=s, **effective_kwargs)\nlib/matplotlib/text.py:153: in __init__\n    self.update(kwargs)\nlib/matplotlib/text.py:201: in update\n    super().update(kwargs)\nlib/matplotlib/artist.py:1208: in update\n    return self._update_props(\nlib/matplotlib/artist.py:1192: in _update_props\n    raise AttributeError(\nE   AttributeError: 'Text' object has no property 'antialiased'\n_______________ test_text_antialiased_on_default_vs_manual[svg] ________________\nlib/matplotlib/testing/decorators.py:411: in wrapper\n    func(*args, fig_test=fig_test, fig_ref=fig_ref, **kwargs)\nlib/matplotlib/tests/test_text.py:961: in test_text_antialiased_on_default_vs_manual\n    fig_test.text(0.5, 0.5, '6 inches x 2 inches', antialiased=True)\nlib/matplotlib/figure.py:1185: in text\n    text = Text(x=x, y=y, text=s, **effective_kwargs)\nlib/matplotlib/text.py:153: in __init__\n    self.update(kwargs)\nlib/matplotlib/text.py:201: in update\n    super().update(kwargs)\nlib/matplotlib/artist.py:1208: in update\n    return self._update_props(\nlib/matplotlib/artist.py:1192: in _update_props\n    raise AttributeError(\nE   AttributeError: 'Text' object has no property 'antialiased'\n=================== 9 failed, 92 passed, 8 skipped in 20.16s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_text.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_text.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 99,
          "failed": 0,
          "errors": 0,
          "collected": 109,
          "duration": 18.57,
          "log_tail": "lib/matplotlib/tests/test_text.py::test_validate_linespacing PASSED      [ 58%]\nlib/matplotlib/tests/test_text.py::test_nonfinite_pos PASSED             [ 59%]\nlib/matplotlib/tests/test_text.py::test_hinting_factor_backends PASSED   [ 60%]\nlib/matplotlib/tests/test_text.py::test_usetex_is_copied PASSED          [ 61%]\nlib/matplotlib/tests/test_text.py::test_single_artist_usetex PASSED      [ 62%]\nlib/matplotlib/tests/test_text.py::test_single_artist_usenotex[png] PASSED [ 63%]\nlib/matplotlib/tests/test_text.py::test_single_artist_usenotex[pdf] PASSED [ 64%]\nlib/matplotlib/tests/test_text.py::test_single_artist_usenotex[svg] PASSED [ 65%]\nlib/matplotlib/tests/test_text.py::test_text_as_path_opacity[svg] SKIPPED [ 66%]\nlib/matplotlib/tests/test_text.py::test_text_as_text_opacity[svg] SKIPPED [ 66%]\nlib/matplotlib/tests/test_text.py::test_text_repr PASSED                 [ 67%]\nlib/matplotlib/tests/test_text.py::test_annotation_update PASSED         [ 68%]\nlib/matplotlib/tests/test_text.py::test_annotation_units[png] PASSED     [ 69%]\nlib/matplotlib/tests/test_text.py::test_large_subscript_title[png] PASSED [ 70%]\nlib/matplotlib/tests/test_text.py::test_wrap[0.7-0-left] PASSED          [ 71%]\nlib/matplotlib/tests/test_text.py::test_wrap[0.5-95-left] PASSED         [ 72%]\nlib/matplotlib/tests/test_text.py::test_wrap[0.3-0-right] PASSED         [ 73%]\nlib/matplotlib/tests/test_text.py::test_wrap[0.3-185-left] PASSED        [ 74%]\nlib/matplotlib/tests/test_text.py::test_mathwrap PASSED                  [ 75%]\nlib/matplotlib/tests/test_text.py::test_get_window_extent_wrapped PASSED [ 76%]\nlib/matplotlib/tests/test_text.py::test_long_word_wrap PASSED            [ 77%]\nlib/matplotlib/tests/test_text.py::test_wrap_no_wrap PASSED              [ 77%]\nlib/matplotlib/tests/test_text.py::test_buffer_size[png] PASSED          [ 78%]\nlib/matplotlib/tests/test_text.py::test_fontproperties_kwarg_precedence PASSED [ 79%]\nlib/matplotlib/tests/test_text.py::test_transform_rotates_text PASSED    [ 80%]\nlib/matplotlib/tests/test_text.py::test_update_mutate_input PASSED       [ 81%]\nlib/matplotlib/tests/test_text.py::test_invalid_rotation_values[invalid string] PASSED [ 82%]\nlib/matplotlib/tests/test_text.py::test_invalid_rotation_values[rotation1] PASSED [ 83%]\nlib/matplotlib/tests/test_text.py::test_invalid_color PASSED             [ 84%]\nlib/matplotlib/tests/test_text.py::test_pdf_kerning[pdf] PASSED          [ 85%]\nlib/matplotlib/tests/test_text.py::test_unsupported_script PASSED        [ 86%]\nlib/matplotlib/tests/test_text.py::test_parse_math PASSED                [ 87%]\nlib/matplotlib/tests/test_text.py::test_parse_math_rcparams PASSED       [ 88%]\nlib/matplotlib/tests/test_text.py::test_pdf_font42_kerning[pdf] PASSED   [ 88%]\nlib/matplotlib/tests/test_text.py::test_pdf_chars_beyond_bmp[pdf] PASSED [ 89%]\nlib/matplotlib/tests/test_text.py::test_metrics_cache PASSED             [ 90%]\nlib/matplotlib/tests/test_text.py::test_annotate_offset_fontsize PASSED  [ 91%]\nlib/matplotlib/tests/test_text.py::test_set_antialiased PASSED           [ 92%]\nlib/matplotlib/tests/test_text.py::test_get_antialiased PASSED           [ 93%]\nlib/matplotlib/tests/test_text.py::test_annotation_antialiased PASSED    [ 94%]\nlib/matplotlib/tests/test_text.py::test_text_antialiased_off_default_vs_manual[png] PASSED [ 95%]\nlib/matplotlib/tests/test_text.py::test_text_antialiased_off_default_vs_manual[pdf] PASSED [ 96%]\nlib/matplotlib/tests/test_text.py::test_text_antialiased_off_default_vs_manual[svg] SKIPPED [ 97%]\nlib/matplotlib/tests/test_text.py::test_text_antialiased_on_default_vs_manual[png] PASSED [ 98%]\nlib/matplotlib/tests/test_text.py::test_text_antialiased_on_default_vs_manual[pdf] PASSED [ 99%]\nlib/matplotlib/tests/test_text.py::test_text_antialiased_on_default_vs_manual[svg] SKIPPED [100%]\n\n======================= 99 passed, 10 skipped in 15.44s ========================\n\n",
          "test_files_run": [
            "lib/matplotlib/tests/test_text.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "matplotlib__matplotlib-25960",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://34.41.233.120:8080",
      "error": "HTTPConnectionPool(host='34.41.233.120', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "matplotlib__matplotlib-26113",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://34.41.233.120:8080",
      "error": "HTTPConnectionPool(host='34.41.233.120', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "matplotlib__matplotlib-26208",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://34.41.233.120:8080",
      "error": "HTTPConnectionPool(host='34.41.233.120', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "matplotlib__matplotlib-26291",
      "repo": "matplotlib/matplotlib",
      "valid": true,
      "worker": "http://34.41.233.120:8080",
      "duration": 32.62386393547058,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 49,
          "failed": 1,
          "errors": 0,
          "collected": 50,
          "duration": 17.62,
          "log_tail": "lib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_picking_callbacks_overlap[host-host-big] PASSED [ 42%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_picking_callbacks_overlap[host-host-small] PASSED [ 44%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_picking_callbacks_overlap[host-parasite-big] PASSED [ 46%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_picking_callbacks_overlap[host-parasite-small] PASSED [ 48%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_picking_callbacks_overlap[parasite-host-big] PASSED [ 50%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_picking_callbacks_overlap[parasite-host-small] PASSED [ 52%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_picking_callbacks_overlap[parasite-parasite-big] PASSED [ 54%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_picking_callbacks_overlap[parasite-parasite-small] PASSED [ 56%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_anchored_artists[png] PASSED [ 58%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_hbox_divider PASSED [ 60%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_vbox_divider PASSED [ 62%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_axes_class_tuple PASSED [ 64%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_grid_axes_lists PASSED [ 66%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_grid_axes_position[row] PASSED [ 68%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_grid_axes_position[column] PASSED [ 70%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_grid_errors[rect0-None-TypeError-Incorrect rect format] PASSED [ 72%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_grid_errors[111--1-ValueError-ngrids must be positive] PASSED [ 74%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_grid_errors[111-7-ValueError-ngrids must be positive] PASSED [ 76%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_divider_errors[None-TypeError-anchor must be str] PASSED [ 78%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_divider_errors[CC-ValueError-'CC' is not a valid value for anchor] PASSED [ 80%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_divider_errors[anchor2-TypeError-anchor must be str] PASSED [ 82%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_mark_inset_unstales_viewlim[png] PASSED [ 84%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_auto_adjustable PASSED [ 86%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_rgb_axes[png] PASSED [ 88%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_insetposition[png] PASSED [ 90%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_imagegrid_cbar_mode_edge[png] PASSED [ 92%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_imagegrid PASSED [ 94%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_removal PASSED [ 96%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_anchored_locator_base_call[png] PASSED [ 98%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_grid_with_axes_class_not_overriding_axis PASSED [100%]\n\n=================================== FAILURES ===================================\n____________________________ test_inset_axes_tight _____________________________\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py:257: in test_inset_axes_tight\n    fig.savefig(f, bbox_inches=\"tight\")\nlib/matplotlib/figure.py:3379: in savefig\n    self.canvas.print_figure(fname, **kwargs)\nlib/matplotlib/backend_bases.py:2168: in print_figure\n    restore_bbox = _tight_bbox.adjust_bbox(\nlib/matplotlib/_tight_bbox.py:28: in adjust_bbox\n    ax.apply_aspect(locator(ax, None))\nlib/mpl_toolkits/axes_grid1/inset_locator.py:73: in __call__\n    bbox = self.get_window_extent(renderer)\nlib/matplotlib/offsetbox.py:398: in get_window_extent\n    renderer = self.figure._get_renderer()\nE   AttributeError: 'NoneType' object has no attribute '_get_renderer'\n======================== 1 failed, 49 passed in 10.86s =========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py` failed. (See above for error)",
          "test_files_run": [
            "lib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 50,
          "failed": 0,
          "errors": 0,
          "collected": 50,
          "duration": 14.02,
          "log_tail": "lib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_inset_locator[png] PASSED [ 10%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_inset_axes[png] PASSED [ 12%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_inset_axes_complete PASSED [ 14%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_inset_axes_tight PASSED [ 16%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_fill_facecolor[png] PASSED [ 18%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_zooming_with_inverted_axes[png] PASSED [ 20%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_anchored_direction_arrows[png] PASSED [ 22%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_anchored_direction_arrows_many_args[png] PASSED [ 24%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_axes_locatable_position PASSED [ 26%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_image_grid_each_left_label_mode_all[png] PASSED [ 28%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_image_grid_single_bottom[png] PASSED [ 30%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_image_grid_label_mode_deprecation_warning PASSED [ 32%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_image_grid[png] PASSED [ 34%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_gettightbbox PASSED [ 36%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_picking_callbacks_overlap[gca-gca-big] PASSED [ 38%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_picking_callbacks_overlap[gca-gca-small] PASSED [ 40%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_picking_callbacks_overlap[host-host-big] PASSED [ 42%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_picking_callbacks_overlap[host-host-small] PASSED [ 44%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_picking_callbacks_overlap[host-parasite-big] PASSED [ 46%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_picking_callbacks_overlap[host-parasite-small] PASSED [ 48%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_picking_callbacks_overlap[parasite-host-big] PASSED [ 50%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_picking_callbacks_overlap[parasite-host-small] PASSED [ 52%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_picking_callbacks_overlap[parasite-parasite-big] PASSED [ 54%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_picking_callbacks_overlap[parasite-parasite-small] PASSED [ 56%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_anchored_artists[png] PASSED [ 58%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_hbox_divider PASSED [ 60%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_vbox_divider PASSED [ 62%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_axes_class_tuple PASSED [ 64%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_grid_axes_lists PASSED [ 66%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_grid_axes_position[row] PASSED [ 68%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_grid_axes_position[column] PASSED [ 70%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_grid_errors[rect0-None-TypeError-Incorrect rect format] PASSED [ 72%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_grid_errors[111--1-ValueError-ngrids must be positive] PASSED [ 74%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_grid_errors[111-7-ValueError-ngrids must be positive] PASSED [ 76%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_divider_errors[None-TypeError-anchor must be str] PASSED [ 78%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_divider_errors[CC-ValueError-'CC' is not a valid value for anchor] PASSED [ 80%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_divider_errors[anchor2-TypeError-anchor must be str] PASSED [ 82%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_mark_inset_unstales_viewlim[png] PASSED [ 84%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_auto_adjustable PASSED [ 86%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_rgb_axes[png] PASSED [ 88%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_insetposition[png] PASSED [ 90%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_imagegrid_cbar_mode_edge[png] PASSED [ 92%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_imagegrid PASSED [ 94%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_removal PASSED [ 96%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_anchored_locator_base_call[png] PASSED [ 98%]\nlib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py::test_grid_with_axes_class_not_overriding_axis PASSED [100%]\n\n============================== 50 passed in 7.88s ==============================\n\n",
          "test_files_run": [
            "lib/mpl_toolkits/axes_grid1/tests/test_axes_grid1.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "matplotlib__matplotlib-26342",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://34.41.233.120:8080",
      "duration": 31.068580150604248,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 81,
          "failed": 2,
          "errors": 0,
          "collected": 87,
          "duration": 17.06,
          "log_tail": "lib/matplotlib/tests/test_contour.py::test_contour_line_start_on_corner_edge[png-True] PASSED [ 64%]\nlib/matplotlib/tests/test_contour.py::test_find_nearest_contour PASSED   [ 65%]\nlib/matplotlib/tests/test_contour.py::test_find_nearest_contour_no_filled PASSED [ 66%]\nlib/matplotlib/tests/test_contour.py::test_contour_autolabel_beyond_powerlimits PASSED [ 67%]\nlib/matplotlib/tests/test_contour.py::test_contourf_legend_elements PASSED [ 68%]\nlib/matplotlib/tests/test_contour.py::test_contour_legend_elements PASSED [ 70%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_name[mpl2005-Mpl2005ContourGenerator] PASSED [ 71%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_name[mpl2014-Mpl2014ContourGenerator] PASSED [ 72%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_name[serial-SerialContourGenerator] PASSED [ 73%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_name[threaded-ThreadedContourGenerator] PASSED [ 74%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_name[invalid-None] PASSED [ 75%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_supports_corner_mask[mpl2005] PASSED [ 77%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_supports_corner_mask[mpl2014] PASSED [ 78%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_supports_corner_mask[serial] PASSED [ 79%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_supports_corner_mask[threaded] PASSED [ 80%]\nlib/matplotlib/tests/test_contour.py::test_all_algorithms[png-False] PASSED [ 81%]\nlib/matplotlib/tests/test_contour.py::test_all_algorithms[png-True] PASSED [ 82%]\nlib/matplotlib/tests/test_contour.py::test_subfigure_clabel PASSED       [ 83%]\nlib/matplotlib/tests/test_contour.py::test_linestyles[solid] PASSED      [ 85%]\nlib/matplotlib/tests/test_contour.py::test_linestyles[dashed] PASSED     [ 86%]\nlib/matplotlib/tests/test_contour.py::test_linestyles[dashdot] PASSED    [ 87%]\nlib/matplotlib/tests/test_contour.py::test_linestyles[dotted] PASSED     [ 88%]\nlib/matplotlib/tests/test_contour.py::test_negative_linestyles[solid] PASSED [ 89%]\nlib/matplotlib/tests/test_contour.py::test_negative_linestyles[dashed] PASSED [ 90%]\nlib/matplotlib/tests/test_contour.py::test_negative_linestyles[dashdot] PASSED [ 91%]\nlib/matplotlib/tests/test_contour.py::test_negative_linestyles[dotted] PASSED [ 93%]\nlib/matplotlib/tests/test_contour.py::test_contour_remove PASSED         [ 94%]\nlib/matplotlib/tests/test_contour.py::test_contour_no_args PASSED        [ 95%]\nlib/matplotlib/tests/test_contour.py::test_contour_clip_path PASSED      [ 96%]\nlib/matplotlib/tests/test_contour.py::test_bool_autolevel PASSED         [ 97%]\nlib/matplotlib/tests/test_contour.py::test_all_nan PASSED                [ 98%]\nlib/matplotlib/tests/test_contour.py::test_deprecated_apis FAILED        [100%]\n\n=================================== FAILURES ===================================\n_________________________ test_contour_set_paths[png] __________________________\nlib/matplotlib/testing/decorators.py:411: in wrapper\n    func(*args, fig_test=fig_test, fig_ref=fig_ref, **kwargs)\nlib/matplotlib/tests/test_contour.py:108: in test_contour_set_paths\n    cs_test.set_paths(cs_ref.get_paths())\nlib/matplotlib/collections.py:210: in set_paths\n    raise NotImplementedError\nE   NotImplementedError\n_____________________________ test_deprecated_apis _____________________________\nlib/matplotlib/tests/test_contour.py:826: in test_deprecated_apis\n    with pytest.warns(PendingDeprecationWarning, match=\"allsegs\"):\nE   matplotlib._api.deprecation.MatplotlibDeprecationWarning: The collections attribute was deprecated in Matplotlib 3.8 and will be removed two minor releases later.\n=================== 2 failed, 81 passed, 4 skipped in 13.01s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_contour.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_contour.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 82,
          "failed": 1,
          "errors": 0,
          "collected": 87,
          "duration": 13.0,
          "log_tail": "lib/matplotlib/tests/test_contour.py::test_contour_linewidth[1.23-4.24-5.02-5.02] PASSED [ 55%]\nlib/matplotlib/tests/test_contour.py::test_label_nonagg PASSED           [ 56%]\nlib/matplotlib/tests/test_contour.py::test_contour_closed_line_loop[png-False] PASSED [ 57%]\nlib/matplotlib/tests/test_contour.py::test_contour_closed_line_loop[png-True] PASSED [ 58%]\nlib/matplotlib/tests/test_contour.py::test_quadcontourset_reuse PASSED   [ 59%]\nlib/matplotlib/tests/test_contour.py::test_contour_manual[png-False] PASSED [ 60%]\nlib/matplotlib/tests/test_contour.py::test_contour_manual[png-True] PASSED [ 62%]\nlib/matplotlib/tests/test_contour.py::test_contour_line_start_on_corner_edge[png-False] PASSED [ 63%]\nlib/matplotlib/tests/test_contour.py::test_contour_line_start_on_corner_edge[png-True] PASSED [ 64%]\nlib/matplotlib/tests/test_contour.py::test_find_nearest_contour PASSED   [ 65%]\nlib/matplotlib/tests/test_contour.py::test_find_nearest_contour_no_filled PASSED [ 66%]\nlib/matplotlib/tests/test_contour.py::test_contour_autolabel_beyond_powerlimits PASSED [ 67%]\nlib/matplotlib/tests/test_contour.py::test_contourf_legend_elements PASSED [ 68%]\nlib/matplotlib/tests/test_contour.py::test_contour_legend_elements PASSED [ 70%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_name[mpl2005-Mpl2005ContourGenerator] PASSED [ 71%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_name[mpl2014-Mpl2014ContourGenerator] PASSED [ 72%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_name[serial-SerialContourGenerator] PASSED [ 73%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_name[threaded-ThreadedContourGenerator] PASSED [ 74%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_name[invalid-None] PASSED [ 75%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_supports_corner_mask[mpl2005] PASSED [ 77%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_supports_corner_mask[mpl2014] PASSED [ 78%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_supports_corner_mask[serial] PASSED [ 79%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_supports_corner_mask[threaded] PASSED [ 80%]\nlib/matplotlib/tests/test_contour.py::test_all_algorithms[png-False] PASSED [ 81%]\nlib/matplotlib/tests/test_contour.py::test_all_algorithms[png-True] PASSED [ 82%]\nlib/matplotlib/tests/test_contour.py::test_subfigure_clabel PASSED       [ 83%]\nlib/matplotlib/tests/test_contour.py::test_linestyles[solid] PASSED      [ 85%]\nlib/matplotlib/tests/test_contour.py::test_linestyles[dashed] PASSED     [ 86%]\nlib/matplotlib/tests/test_contour.py::test_linestyles[dashdot] PASSED    [ 87%]\nlib/matplotlib/tests/test_contour.py::test_linestyles[dotted] PASSED     [ 88%]\nlib/matplotlib/tests/test_contour.py::test_negative_linestyles[solid] PASSED [ 89%]\nlib/matplotlib/tests/test_contour.py::test_negative_linestyles[dashed] PASSED [ 90%]\nlib/matplotlib/tests/test_contour.py::test_negative_linestyles[dashdot] PASSED [ 91%]\nlib/matplotlib/tests/test_contour.py::test_negative_linestyles[dotted] PASSED [ 93%]\nlib/matplotlib/tests/test_contour.py::test_contour_remove PASSED         [ 94%]\nlib/matplotlib/tests/test_contour.py::test_contour_no_args PASSED        [ 95%]\nlib/matplotlib/tests/test_contour.py::test_contour_clip_path PASSED      [ 96%]\nlib/matplotlib/tests/test_contour.py::test_bool_autolevel PASSED         [ 97%]\nlib/matplotlib/tests/test_contour.py::test_all_nan PASSED                [ 98%]\nlib/matplotlib/tests/test_contour.py::test_deprecated_apis FAILED        [100%]\n\n=================================== FAILURES ===================================\n_____________________________ test_deprecated_apis _____________________________\nlib/matplotlib/tests/test_contour.py:826: in test_deprecated_apis\n    with pytest.warns(PendingDeprecationWarning, match=\"allsegs\"):\nE   matplotlib._api.deprecation.MatplotlibDeprecationWarning: The collections attribute was deprecated in Matplotlib 3.8 and will be removed two minor releases later.\n=================== 1 failed, 82 passed, 4 skipped in 9.62s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_contour.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_contour.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "matplotlib__matplotlib-26466",
      "repo": "matplotlib/matplotlib",
      "valid": true,
      "worker": "http://34.41.233.120:8080",
      "duration": 44.19193387031555,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 103,
          "failed": 1,
          "errors": 0,
          "collected": 116,
          "duration": 24.27,
          "log_tail": "lib/matplotlib/tests/test_text.py::test_wrap[0.3-0-right] PASSED         [ 68%]\nlib/matplotlib/tests/test_text.py::test_wrap[0.3-185-left] PASSED        [ 69%]\nlib/matplotlib/tests/test_text.py::test_mathwrap PASSED                  [ 70%]\nlib/matplotlib/tests/test_text.py::test_get_window_extent_wrapped PASSED [ 71%]\nlib/matplotlib/tests/test_text.py::test_long_word_wrap PASSED            [ 72%]\nlib/matplotlib/tests/test_text.py::test_wrap_no_wrap PASSED              [ 73%]\nlib/matplotlib/tests/test_text.py::test_buffer_size[png] PASSED          [ 74%]\nlib/matplotlib/tests/test_text.py::test_fontproperties_kwarg_precedence PASSED [ 75%]\nlib/matplotlib/tests/test_text.py::test_transform_rotates_text PASSED    [ 75%]\nlib/matplotlib/tests/test_text.py::test_update_mutate_input PASSED       [ 76%]\nlib/matplotlib/tests/test_text.py::test_invalid_rotation_values[invalid string] PASSED [ 77%]\nlib/matplotlib/tests/test_text.py::test_invalid_rotation_values[rotation1] PASSED [ 78%]\nlib/matplotlib/tests/test_text.py::test_invalid_color PASSED             [ 79%]\nlib/matplotlib/tests/test_text.py::test_pdf_kerning[pdf] PASSED          [ 80%]\nlib/matplotlib/tests/test_text.py::test_unsupported_script PASSED        [ 81%]\nlib/matplotlib/tests/test_text.py::test_parse_math PASSED                [ 81%]\nlib/matplotlib/tests/test_text.py::test_parse_math_rcparams PASSED       [ 82%]\nlib/matplotlib/tests/test_text.py::test_pdf_font42_kerning[pdf] PASSED   [ 83%]\nlib/matplotlib/tests/test_text.py::test_pdf_chars_beyond_bmp[pdf] PASSED [ 84%]\nlib/matplotlib/tests/test_text.py::test_metrics_cache PASSED             [ 85%]\nlib/matplotlib/tests/test_text.py::test_annotate_offset_fontsize PASSED  [ 86%]\nlib/matplotlib/tests/test_text.py::test_set_antialiased PASSED           [ 87%]\nlib/matplotlib/tests/test_text.py::test_get_antialiased PASSED           [ 87%]\nlib/matplotlib/tests/test_text.py::test_annotation_antialiased PASSED    [ 88%]\nlib/matplotlib/tests/test_text.py::test_text_antialiased_off_default_vs_manual[png] PASSED [ 89%]\nlib/matplotlib/tests/test_text.py::test_text_antialiased_off_default_vs_manual[pdf] PASSED [ 90%]\nlib/matplotlib/tests/test_text.py::test_text_antialiased_off_default_vs_manual[svg] SKIPPED [ 91%]\nlib/matplotlib/tests/test_text.py::test_text_antialiased_on_default_vs_manual[png] PASSED [ 92%]\nlib/matplotlib/tests/test_text.py::test_text_antialiased_on_default_vs_manual[pdf] PASSED [ 93%]\nlib/matplotlib/tests/test_text.py::test_text_antialiased_on_default_vs_manual[svg] SKIPPED [ 93%]\nlib/matplotlib/tests/test_text.py::test_text_math_antialiased_on_default_vs_manual[png] PASSED [ 94%]\nlib/matplotlib/tests/test_text.py::test_text_math_antialiased_on_default_vs_manual[pdf] PASSED [ 95%]\nlib/matplotlib/tests/test_text.py::test_text_math_antialiased_on_default_vs_manual[svg] SKIPPED [ 96%]\nlib/matplotlib/tests/test_text.py::test_text_math_antialiased_off_default_vs_manual[png] PASSED [ 97%]\nlib/matplotlib/tests/test_text.py::test_text_math_antialiased_off_default_vs_manual[pdf] PASSED [ 98%]\nlib/matplotlib/tests/test_text.py::test_text_math_antialiased_off_default_vs_manual[svg] SKIPPED [ 99%]\nlib/matplotlib/tests/test_text.py::test_annotate_and_offsetfrom_copy_input[png] FAILED [100%]\n\n=================================== FAILURES ===================================\n_________________ test_annotate_and_offsetfrom_copy_input[png] _________________\nlib/matplotlib/testing/decorators.py:422: in wrapper\n    _raise_on_image_difference(\nE   matplotlib.testing.exceptions.ImageComparisonFailure: images not close (RMS 3.353):\nE   \tresult_images/test_text/test_annotate_and_offsetfrom_copy_input[png].png\nE   \tresult_images/test_text/test_annotate_and_offsetfrom_copy_input[png]-expected.png\nE   \tresult_images/test_text/test_annotate_and_offsetfrom_copy_input[png]-failed-diff.png\n================== 1 failed, 103 passed, 12 skipped in 20.72s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_text.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_text.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 104,
          "failed": 0,
          "errors": 0,
          "collected": 116,
          "duration": 18.94,
          "log_tail": "lib/matplotlib/tests/test_text.py::test_single_artist_usenotex[svg] PASSED [ 61%]\nlib/matplotlib/tests/test_text.py::test_text_as_path_opacity[svg] SKIPPED [ 62%]\nlib/matplotlib/tests/test_text.py::test_text_as_text_opacity[svg] SKIPPED [ 62%]\nlib/matplotlib/tests/test_text.py::test_text_repr PASSED                 [ 63%]\nlib/matplotlib/tests/test_text.py::test_annotation_update PASSED         [ 64%]\nlib/matplotlib/tests/test_text.py::test_annotation_units[png] PASSED     [ 65%]\nlib/matplotlib/tests/test_text.py::test_large_subscript_title[png] PASSED [ 66%]\nlib/matplotlib/tests/test_text.py::test_wrap[0.7-0-left] PASSED          [ 67%]\nlib/matplotlib/tests/test_text.py::test_wrap[0.5-95-left] PASSED         [ 68%]\nlib/matplotlib/tests/test_text.py::test_wrap[0.3-0-right] PASSED         [ 68%]\nlib/matplotlib/tests/test_text.py::test_wrap[0.3-185-left] PASSED        [ 69%]\nlib/matplotlib/tests/test_text.py::test_mathwrap PASSED                  [ 70%]\nlib/matplotlib/tests/test_text.py::test_get_window_extent_wrapped PASSED [ 71%]\nlib/matplotlib/tests/test_text.py::test_long_word_wrap PASSED            [ 72%]\nlib/matplotlib/tests/test_text.py::test_wrap_no_wrap PASSED              [ 73%]\nlib/matplotlib/tests/test_text.py::test_buffer_size[png] PASSED          [ 74%]\nlib/matplotlib/tests/test_text.py::test_fontproperties_kwarg_precedence PASSED [ 75%]\nlib/matplotlib/tests/test_text.py::test_transform_rotates_text PASSED    [ 75%]\nlib/matplotlib/tests/test_text.py::test_update_mutate_input PASSED       [ 76%]\nlib/matplotlib/tests/test_text.py::test_invalid_rotation_values[invalid string] PASSED [ 77%]\nlib/matplotlib/tests/test_text.py::test_invalid_rotation_values[rotation1] PASSED [ 78%]\nlib/matplotlib/tests/test_text.py::test_invalid_color PASSED             [ 79%]\nlib/matplotlib/tests/test_text.py::test_pdf_kerning[pdf] PASSED          [ 80%]\nlib/matplotlib/tests/test_text.py::test_unsupported_script PASSED        [ 81%]\nlib/matplotlib/tests/test_text.py::test_parse_math PASSED                [ 81%]\nlib/matplotlib/tests/test_text.py::test_parse_math_rcparams PASSED       [ 82%]\nlib/matplotlib/tests/test_text.py::test_pdf_font42_kerning[pdf] PASSED   [ 83%]\nlib/matplotlib/tests/test_text.py::test_pdf_chars_beyond_bmp[pdf] PASSED [ 84%]\nlib/matplotlib/tests/test_text.py::test_metrics_cache PASSED             [ 85%]\nlib/matplotlib/tests/test_text.py::test_annotate_offset_fontsize PASSED  [ 86%]\nlib/matplotlib/tests/test_text.py::test_set_antialiased PASSED           [ 87%]\nlib/matplotlib/tests/test_text.py::test_get_antialiased PASSED           [ 87%]\nlib/matplotlib/tests/test_text.py::test_annotation_antialiased PASSED    [ 88%]\nlib/matplotlib/tests/test_text.py::test_text_antialiased_off_default_vs_manual[png] PASSED [ 89%]\nlib/matplotlib/tests/test_text.py::test_text_antialiased_off_default_vs_manual[pdf] PASSED [ 90%]\nlib/matplotlib/tests/test_text.py::test_text_antialiased_off_default_vs_manual[svg] SKIPPED [ 91%]\nlib/matplotlib/tests/test_text.py::test_text_antialiased_on_default_vs_manual[png] PASSED [ 92%]\nlib/matplotlib/tests/test_text.py::test_text_antialiased_on_default_vs_manual[pdf] PASSED [ 93%]\nlib/matplotlib/tests/test_text.py::test_text_antialiased_on_default_vs_manual[svg] SKIPPED [ 93%]\nlib/matplotlib/tests/test_text.py::test_text_math_antialiased_on_default_vs_manual[png] PASSED [ 94%]\nlib/matplotlib/tests/test_text.py::test_text_math_antialiased_on_default_vs_manual[pdf] PASSED [ 95%]\nlib/matplotlib/tests/test_text.py::test_text_math_antialiased_on_default_vs_manual[svg] SKIPPED [ 96%]\nlib/matplotlib/tests/test_text.py::test_text_math_antialiased_off_default_vs_manual[png] PASSED [ 97%]\nlib/matplotlib/tests/test_text.py::test_text_math_antialiased_off_default_vs_manual[pdf] PASSED [ 98%]\nlib/matplotlib/tests/test_text.py::test_text_math_antialiased_off_default_vs_manual[svg] SKIPPED [ 99%]\nlib/matplotlib/tests/test_text.py::test_annotate_and_offsetfrom_copy_input[png] PASSED [100%]\n\n======================= 104 passed, 12 skipped in 15.87s =======================\n\n",
          "test_files_run": [
            "lib/matplotlib/tests/test_text.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sphinx-doc__sphinx-10323",
      "repo": "sphinx-doc/sphinx",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 12.993596076965332,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 40,
          "failed": 1,
          "errors": 0,
          "collected": 41,
          "duration": 5.13,
          "log_tail": "tests/test_directive_code.py::test_LiteralIncludeReader_lines_and_lineno_match3 PASSED [ 26%]\ntests/test_directive_code.py::test_LiteralIncludeReader_start_at PASSED  [ 29%]\ntests/test_directive_code.py::test_LiteralIncludeReader_start_after PASSED [ 31%]\ntests/test_directive_code.py::test_LiteralIncludeReader_start_after_and_lines PASSED [ 34%]\ntests/test_directive_code.py::test_LiteralIncludeReader_start_at_and_lines PASSED [ 36%]\ntests/test_directive_code.py::test_LiteralIncludeReader_missing_start_and_end PASSED [ 39%]\ntests/test_directive_code.py::test_LiteralIncludeReader_end_before PASSED [ 41%]\ntests/test_directive_code.py::test_LiteralIncludeReader_prepend PASSED   [ 43%]\ntests/test_directive_code.py::test_LiteralIncludeReader_dedent PASSED    [ 46%]\ntests/test_directive_code.py::test_LiteralIncludeReader_dedent_and_append_and_prepend FAILED [ 48%]\ntests/test_directive_code.py::test_LiteralIncludeReader_tabwidth PASSED  [ 51%]\ntests/test_directive_code.py::test_LiteralIncludeReader_tabwidth_dedent PASSED [ 53%]\ntests/test_directive_code.py::test_LiteralIncludeReader_diff PASSED      [ 56%]\ntests/test_directive_code.py::test_code_block PASSED                     [ 58%]\ntests/test_directive_code.py::test_force_option PASSED                   [ 60%]\ntests/test_directive_code.py::test_code_block_caption_html PASSED        [ 63%]\ntests/test_directive_code.py::test_code_block_caption_latex PASSED       [ 65%]\ntests/test_directive_code.py::test_code_block_namedlink_latex PASSED     [ 68%]\ntests/test_directive_code.py::test_code_block_emphasize_latex PASSED     [ 70%]\ntests/test_directive_code.py::test_literal_include PASSED                [ 73%]\ntests/test_directive_code.py::test_literal_include_block_start_with_comment_or_brank PASSED [ 75%]\ntests/test_directive_code.py::test_literal_include_linenos PASSED        [ 78%]\ntests/test_directive_code.py::test_literalinclude_file_whole_of_emptyline PASSED [ 80%]\ntests/test_directive_code.py::test_literalinclude_caption_html PASSED    [ 82%]\ntests/test_directive_code.py::test_literalinclude_caption_latex PASSED   [ 85%]\ntests/test_directive_code.py::test_literalinclude_namedlink_latex PASSED [ 87%]\ntests/test_directive_code.py::test_literalinclude_classes PASSED         [ 90%]\ntests/test_directive_code.py::test_literalinclude_pydecorators PASSED    [ 92%]\ntests/test_directive_code.py::test_code_block_highlighted PASSED         [ 95%]\ntests/test_directive_code.py::test_linenothreshold PASSED                [ 97%]\ntests/test_directive_code.py::test_code_block_dedent PASSED              [100%]\n\n=================================== FAILURES ===================================\n___________ test_LiteralIncludeReader_dedent_and_append_and_prepend ____________\ntests/test_directive_code.py:260: in test_LiteralIncludeReader_dedent_and_append_and_prepend\n    assert content == (\"class Foo:\\n\"\nE   AssertionError: assert 'ass Foo:\\n  ...\\n\\ncomment\\n' == 'class Foo:\\n...\\n# comment\\n'\nE     \nE     - class Foo:\nE     ? --\nE     + ass Foo:\nE         def baz():\nE             pass\nE       ...\nE     \nE     ...Full output truncated (3 lines hidden), use '-vv' to show\n========================= 1 failed, 40 passed in 2.31s =========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_directive_code.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_directive_code.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 41,
          "failed": 0,
          "errors": 0,
          "collected": 41,
          "duration": 6.31,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 41 items\n\ntests/test_directive_code.py::test_LiteralIncludeReader PASSED           [  2%]\ntests/test_directive_code.py::test_LiteralIncludeReader_lineno_start PASSED [  4%]\ntests/test_directive_code.py::test_LiteralIncludeReader_pyobject1 PASSED [  7%]\ntests/test_directive_code.py::test_LiteralIncludeReader_pyobject2 PASSED [  9%]\ntests/test_directive_code.py::test_LiteralIncludeReader_pyobject3 PASSED [ 12%]\ntests/test_directive_code.py::test_LiteralIncludeReader_pyobject_and_lines PASSED [ 14%]\ntests/test_directive_code.py::test_LiteralIncludeReader_lines1 PASSED    [ 17%]\ntests/test_directive_code.py::test_LiteralIncludeReader_lines2 PASSED    [ 19%]\ntests/test_directive_code.py::test_LiteralIncludeReader_lines_and_lineno_match1 PASSED [ 21%]\ntests/test_directive_code.py::test_LiteralIncludeReader_lines_and_lineno_match2 PASSED [ 24%]\ntests/test_directive_code.py::test_LiteralIncludeReader_lines_and_lineno_match3 PASSED [ 26%]\ntests/test_directive_code.py::test_LiteralIncludeReader_start_at PASSED  [ 29%]\ntests/test_directive_code.py::test_LiteralIncludeReader_start_after PASSED [ 31%]\ntests/test_directive_code.py::test_LiteralIncludeReader_start_after_and_lines PASSED [ 34%]\ntests/test_directive_code.py::test_LiteralIncludeReader_start_at_and_lines PASSED [ 36%]\ntests/test_directive_code.py::test_LiteralIncludeReader_missing_start_and_end PASSED [ 39%]\ntests/test_directive_code.py::test_LiteralIncludeReader_end_before PASSED [ 41%]\ntests/test_directive_code.py::test_LiteralIncludeReader_prepend PASSED   [ 43%]\ntests/test_directive_code.py::test_LiteralIncludeReader_dedent PASSED    [ 46%]\ntests/test_directive_code.py::test_LiteralIncludeReader_dedent_and_append_and_prepend PASSED [ 48%]\ntests/test_directive_code.py::test_LiteralIncludeReader_tabwidth PASSED  [ 51%]\ntests/test_directive_code.py::test_LiteralIncludeReader_tabwidth_dedent PASSED [ 53%]\ntests/test_directive_code.py::test_LiteralIncludeReader_diff PASSED      [ 56%]\ntests/test_directive_code.py::test_code_block PASSED                     [ 58%]\ntests/test_directive_code.py::test_force_option PASSED                   [ 60%]\ntests/test_directive_code.py::test_code_block_caption_html PASSED        [ 63%]\ntests/test_directive_code.py::test_code_block_caption_latex PASSED       [ 65%]\ntests/test_directive_code.py::test_code_block_namedlink_latex PASSED     [ 68%]\ntests/test_directive_code.py::test_code_block_emphasize_latex PASSED     [ 70%]\ntests/test_directive_code.py::test_literal_include PASSED                [ 73%]\ntests/test_directive_code.py::test_literal_include_block_start_with_comment_or_brank PASSED [ 75%]\ntests/test_directive_code.py::test_literal_include_linenos PASSED        [ 78%]\ntests/test_directive_code.py::test_literalinclude_file_whole_of_emptyline PASSED [ 80%]\ntests/test_directive_code.py::test_literalinclude_caption_html PASSED    [ 82%]\ntests/test_directive_code.py::test_literalinclude_caption_latex PASSED   [ 85%]\ntests/test_directive_code.py::test_literalinclude_namedlink_latex PASSED [ 87%]\ntests/test_directive_code.py::test_literalinclude_classes PASSED         [ 90%]\ntests/test_directive_code.py::test_literalinclude_pydecorators PASSED    [ 92%]\ntests/test_directive_code.py::test_code_block_highlighted PASSED         [ 95%]\ntests/test_directive_code.py::test_linenothreshold PASSED                [ 97%]\ntests/test_directive_code.py::test_code_block_dedent PASSED              [100%]\n\n============================== 41 passed in 3.14s ==============================\n\n",
          "test_files_run": [
            "tests/test_directive_code.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sphinx-doc__sphinx-10435",
      "repo": "sphinx-doc/sphinx",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 24.340500116348267,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 74,
          "failed": 1,
          "errors": 0,
          "collected": 83,
          "duration": 11.93,
          "log_tail": "tests/test_build_latex.py::test_latex_glossary PASSED                    [ 86%]\ntests/test_build_latex.py::test_latex_labels PASSED                      [ 87%]\ntests/test_build_latex.py::test_latex_figure_in_admonition PASSED        [ 89%]\ntests/test_build_latex.py::test_default_latex_documents PASSED           [ 90%]\ntests/test_build_latex.py::test_includegraphics_oversized SKIPPED (n...) [ 91%]\ntests/test_build_latex.py::test_index_on_title PASSED                    [ 92%]\ntests/test_build_latex.py::test_texescape_for_non_unicode_supported_engine PASSED [ 93%]\ntests/test_build_latex.py::test_texescape_for_unicode_supported_engine PASSED [ 95%]\ntests/test_build_latex.py::test_latex_elements_extrapackages PASSED      [ 96%]\ntests/test_build_latex.py::test_latex_nested_tables PASSED               [ 97%]\ntests/test_build_latex.py::test_latex_container PASSED                   [ 98%]\ntests/test_build_latex.py::test_latex_code_role FAILED                   [100%]\n\n=================================== FAILURES ===================================\n_____________________________ test_latex_code_role _____________________________\ntests/test_build_latex.py:1626: in test_latex_code_role\n    assert (r'Inline \\sphinxcode{\\sphinxupquote{%' + '\\n' +\nE   assert ((('Inline \\\\sphinxcode{\\\\sphinxupquote{%' + '\\n') + '\\\\PYG{k}{def} \\\\PYG{n+nf}{foo}\\\\PYG{p}{(}\\\\PYG{l+m+mi}{1} \\\\PYG{o}{+} \\\\PYG{l+m+mi}{2} \\\\PYG{o}{+} \\\\PYG{k+kc}{None} \\\\PYG{o}{+} \\\\PYG{l+s+s2}{\\\\PYGZdq{}}\\\\PYG{l+s+s2}{abc}\\\\PYG{l+s+s2}{\\\\PYGZdq{}}\\\\PYG{p}{)}\\\\PYG{p}{:} \\\\PYG{k}{pass}') + '%\\n}} code block') in '%% Generated by Sphinx.\\n\\\\def\\\\sphinxdocclass{report}\\n\\\\documentclass[letterpaper,10pt,english]{sphinxmanual}\\n\\\\ifdefined\\\\pdfpxdimen\\n   \\\\let\\\\sphinxpxdimen\\\\pdfpxdimen\\\\else\\\\newdimen\\\\sphinxpxdimen\\n\\\\fi \\\\sphinxpxdimen=.75bp\\\\relax\\n\\\\ifdefined\\\\pdfimageresolution\\n    \\\\pdfimageresolution= \\\\numexpr \\\\dimexpr1in\\\\relax/\\\\sphinxpxdimen\\\\relax\\n\\\\fi\\n%% let collapsible pdf bookmarks panel have high depth per default\\n\\\\PassOptionsToPackage{bookmarksdepth=5}{hyperref}\\n\\n\\\\PassOptionsToPackage{warn}{textcomp}\\n\\\\usepackage[utf8]{inputenc}\\n\\\\ifdefined\\\\DeclareUnicodeCharacter\\n% support both utf8 and utf8x syntaxes\\n  \\\\ifdefined\\\\DeclareUnicodeCharacterAsOptional\\n    \\\\def\\\\sphinxDUC#1{\\\\DeclareUnicodeCharacter{\"#1}}\\n  \\\\else\\n    \\\\let\\\\sphinxDUC\\\\DeclareUnicodeCharacter\\n  \\\\fi\\n  \\\\sphinxDUC{00A0}{\\\\nobreakspace}\\n  \\\\sphinxDUC{2500}{\\\\sphinxunichar{2500}}\\n  \\\\sphinxDUC{2502}{\\\\sphinxunichar{2502}}\\n  \\\\sphinxDUC{2514}{\\\\sphinxunichar{2514}}\\n  \\\\sphinxDUC{251C}{\\\\sphinxunichar{251C}}\\n  \\\\sphinxDUC{2572}{\\\\textbackslash}\\n\\\\fi\\n\\\\usepackage{cmap}\\n\\\\usepackage[T1]{fontenc}\\n\\\\usepackage{amsmath,amssymb,amstext}\\n\\\\usepackage{babel}\\n\\n\\n\\n\\\\usepackage{tgtermes}\\n\\\\...phinxmessages}\\n\\n\\n\\n\\n\\\\title{Python}\\n\\\\date{Aug 10, 2025}\\n\\\\release{}\\n\\\\author{unknown}\\n\\\\newcommand{\\\\sphinxlogo}{\\\\vbox{}}\\n\\\\renewcommand{\\\\releasename}{}\\n\\\\makeindex\\n\\\\begin{document}\\n\\n\\\\ifdefined\\\\shorthandoff\\n  \\\\ifnum\\\\catcode`\\\\=\\\\string=\\\\active\\\\shorthandoff{=}\\\\fi\\n  \\\\ifnum\\\\catcode`\\\\\"=\\\\active\\\\shorthandoff{\"}\\\\fi\\n\\\\fi\\n\\n\\\\pagestyle{empty}\\n\\\\sphinxmaketitle\\n\\\\pagestyle{plain}\\n\\\\sphinxtableofcontents\\n\\\\pagestyle{normal}\\n\\\\phantomsection\\\\label{\\\\detokenize{index::doc}}\\n\\\\sphinxAtStartPar\\nInline \\\\sphinxcode{\\\\sphinxupquote{\\n\\\\PYG{k}{def} \\\\PYG{n+nf}{foo}\\\\PYG{p}{(}\\\\PYG{l+m+mi}{1} \\\\PYG{o}{+} \\\\PYG{l+m+mi}{2} \\\\PYG{o}{+} \\\\PYG{k+kc}{None} \\\\PYG{o}{+} \\\\PYG{l+s+s2}{\\\\PYGZdq{}}\\\\PYG{l+s+s2}{abc}\\\\PYG{l+s+s2}{\\\\PYGZdq{}}\\\\PYG{p}{)}\\\\PYG{p}{:} \\\\PYG{k}{pass}\\n}} code block\\n\\n\\\\begin{sphinxVerbatim}[commandchars=\\\\\\\\\\\\{\\\\}]\\n\\\\PYG{k}{def} \\\\PYG{n+nf}{foo}\\\\PYG{p}{(}\\\\PYG{l+m+mi}{1} \\\\PYG{o}{+} \\\\PYG{l+m+mi}{2} \\\\PYG{o}{+} \\\\PYG{k+kc}{None} \\\\PYG{o}{+} \\\\PYG{l+s+s2}{\\\\PYGZdq{}}\\\\PYG{l+s+s2}{abc}\\\\PYG{l+s+s2}{\\\\PYGZdq{}}\\\\PYG{p}{)}\\\\PYG{p}{:} \\\\PYG{k}{pass}\\n\\\\end{sphinxVerbatim}\\n\\n\\n\\n\\\\renewcommand{\\\\indexname}{Index}\\n\\\\printindex\\n\\\\end{document}'\n--------------------------- Captured stdout teardown ---------------------------\n# testroot: root\n# builder: latex\n# srcdir: /tmp/pytest-of-root/pytest-0/reST-code-role\n# outdir: /tmp/pytest-of-root/pytest-0/reST-code-role/_build/latex\n# status: \n\u001b[01mRunning Sphinx v5.0.0+/f1061c012\u001b[39;49;00m\n\u001b[01mbuilding [mo]: \u001b[39;49;00mtargets for 0 po files that are out of date\n\u001b[01mbuilding [latex]: \u001b[39;49;00mall documents\n\u001b[01mupdating environment: \u001b[39;49;00m[new config] 1 added, 0 changed, 0 removed\n\u001b[01mreading sources... \u001b[39;49;00m[100%] \u001b[35mindex\u001b[39;49;00m                                                \n\u001b[01mlooking for now-outdated files... \u001b[39;49;00mnone found\n\u001b[01mpickling environment... \u001b[39;49;00mdone\n\u001b[01mchecking consistency... \u001b[39;49;00mdone\n\u001b[01mprocessing python.tex... \u001b[39;49;00m\u001b[32mindex\u001b[39;49;00m \nresolving references...\ndone\n\u001b[01mwriting... \u001b[39;49;00mdone\n\u001b[01mcopying TeX support files... \u001b[39;49;00m\u001b[01mcopying TeX support files...\u001b[39;49;00m\ndone\n\u001b[01mbuild succeeded.\u001b[39;49;00m\n\nThe LaTeX files are in ../tmp/pytest-of-root/pytest-0/reST-code-role/_build/latex.\nRun 'make' in that directory to run these through (pdf)latex\n(use `make latexpdf' here to do that automatically).\n\n# warning: \n\n=================== 1 failed, 74 passed, 8 skipped in 8.98s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_build_latex.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_build_latex.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 75,
          "failed": 0,
          "errors": 0,
          "collected": 83,
          "duration": 10.88,
          "log_tail": "tests/test_build_latex.py::test_footnote PASSED                          [ 45%]\ntests/test_build_latex.py::test_reference_in_caption_and_codeblock_in_footnote PASSED [ 46%]\ntests/test_build_latex.py::test_footnote_referred_multiple_times PASSED  [ 48%]\ntests/test_build_latex.py::test_latex_show_urls_is_inline PASSED         [ 49%]\ntests/test_build_latex.py::test_latex_show_urls_is_footnote PASSED       [ 50%]\ntests/test_build_latex.py::test_latex_show_urls_is_no PASSED             [ 51%]\ntests/test_build_latex.py::test_latex_show_urls_footnote_and_substitutions PASSED [ 53%]\ntests/test_build_latex.py::test_image_in_section PASSED                  [ 54%]\ntests/test_build_latex.py::test_latex_logo_if_not_found PASSED           [ 55%]\ntests/test_build_latex.py::test_toctree_maxdepth_manual PASSED           [ 56%]\ntests/test_build_latex.py::test_toctree_maxdepth_howto PASSED            [ 57%]\ntests/test_build_latex.py::test_toctree_not_found PASSED                 [ 59%]\ntests/test_build_latex.py::test_toctree_without_maxdepth PASSED          [ 60%]\ntests/test_build_latex.py::test_toctree_with_deeper_maxdepth PASSED      [ 61%]\ntests/test_build_latex.py::test_latex_toplevel_sectioning_is_None PASSED [ 62%]\ntests/test_build_latex.py::test_latex_toplevel_sectioning_is_part PASSED [ 63%]\ntests/test_build_latex.py::test_latex_toplevel_sectioning_is_part_with_howto PASSED [ 65%]\ntests/test_build_latex.py::test_latex_toplevel_sectioning_is_chapter PASSED [ 66%]\ntests/test_build_latex.py::test_latex_toplevel_sectioning_is_chapter_with_howto PASSED [ 67%]\ntests/test_build_latex.py::test_latex_toplevel_sectioning_is_section PASSED [ 68%]\ntests/test_build_latex.py::test_maxlistdepth_at_ten SKIPPED (not run...) [ 69%]\ntests/test_build_latex.py::test_latex_table_tabulars PASSED              [ 71%]\ntests/test_build_latex.py::test_latex_table_longtable PASSED             [ 72%]\ntests/test_build_latex.py::test_latex_table_complex_tables PASSED        [ 73%]\ntests/test_build_latex.py::test_latex_table_custom_template_caseA PASSED [ 74%]\ntests/test_build_latex.py::test_latex_table_custom_template_caseB PASSED [ 75%]\ntests/test_build_latex.py::test_latex_table_custom_template_caseC PASSED [ 77%]\ntests/test_build_latex.py::test_latex_raw_directive PASSED               [ 78%]\ntests/test_build_latex.py::test_latex_images PASSED                      [ 79%]\ntests/test_build_latex.py::test_latex_index PASSED                       [ 80%]\ntests/test_build_latex.py::test_latex_equations PASSED                   [ 81%]\ntests/test_build_latex.py::test_latex_image_in_parsed_literal PASSED     [ 83%]\ntests/test_build_latex.py::test_latex_nested_enumerated_list PASSED      [ 84%]\ntests/test_build_latex.py::test_latex_thebibliography PASSED             [ 85%]\ntests/test_build_latex.py::test_latex_glossary PASSED                    [ 86%]\ntests/test_build_latex.py::test_latex_labels PASSED                      [ 87%]\ntests/test_build_latex.py::test_latex_figure_in_admonition PASSED        [ 89%]\ntests/test_build_latex.py::test_default_latex_documents PASSED           [ 90%]\ntests/test_build_latex.py::test_includegraphics_oversized SKIPPED (n...) [ 91%]\ntests/test_build_latex.py::test_index_on_title PASSED                    [ 92%]\ntests/test_build_latex.py::test_texescape_for_non_unicode_supported_engine PASSED [ 93%]\ntests/test_build_latex.py::test_texescape_for_unicode_supported_engine PASSED [ 95%]\ntests/test_build_latex.py::test_latex_elements_extrapackages PASSED      [ 96%]\ntests/test_build_latex.py::test_latex_nested_tables PASSED               [ 97%]\ntests/test_build_latex.py::test_latex_container PASSED                   [ 98%]\ntests/test_build_latex.py::test_latex_code_role PASSED                   [100%]\n\n======================== 75 passed, 8 skipped in 7.89s =========================\n\n",
          "test_files_run": [
            "tests/test_build_latex.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sphinx-doc__sphinx-10449",
      "repo": "sphinx-doc/sphinx",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 12.772915840148926,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 30,
          "failed": 1,
          "errors": 0,
          "collected": 31,
          "duration": 5.09,
          "log_tail": "tests/test_ext_autodoc_configs.py::test_autodoc_type_aliases PASSED      [ 77%]\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_and_type_aliases PASSED [ 80%]\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_format_fully_qualified PASSED [ 83%]\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_format_fully_qualified_for_class_alias PASSED [ 87%]\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_format_fully_qualified_for_generic_alias PASSED [ 90%]\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_format_fully_qualified_for_newtype_alias PASSED [ 93%]\ntests/test_ext_autodoc_configs.py::test_autodoc_default_options PASSED   [ 96%]\ntests/test_ext_autodoc_configs.py::test_autodoc_default_options_with_values PASSED [100%]\n\n=================================== FAILURES ===================================\n___________ test_autodoc_typehints_description_with_documented_init ____________\ntests/test_ext_autodoc_configs.py:1037: in test_autodoc_typehints_description_with_documented_init\n    assert ('class target.typehints._ClassWithDocumentedInit(x)\\n'\nE   AssertionError: assert 'class target...       None\\n' == 'class target...       None\\n'\nE     \nE       class target.typehints._ClassWithDocumentedInit(x)\nE       \nE          Class docstring.\nE       \nE          Parameters:\nE             **x** (*int*) --...\nE     \nE     ...Full output truncated (13 lines hidden), use '-vv' to show\n--------------------------- Captured stdout teardown ---------------------------\n# testroot: root\n# builder: text\n# srcdir: /tmp/pytest-of-root/pytest-0/ext-autodoc\n# outdir: /tmp/pytest-of-root/pytest-0/ext-autodoc/_build/text\n# status: \n\u001b[01mRunning Sphinx v5.1.0+/36367765f\u001b[39;49;00m\n\u001b[01mloading pickled environment... \u001b[39;49;00mdone\n\u001b[01mbuilding [mo]: \u001b[39;49;00mtargets for 0 po files that are out of date\n\u001b[01mbuilding [text]: \u001b[39;49;00mtargets for 1 source files that are out of date\n\u001b[01mupdating environment: \u001b[39;49;00m[config changed ('autodoc_typehints_description_target')] 1 added, 0 changed, 0 removed\n\u001b[01mreading sources... \u001b[39;49;00m[100%] \u001b[35mindex\u001b[39;49;00m                                                \n\u001b[01mlooking for now-outdated files... \u001b[39;49;00mnone found\n\u001b[01mpickling environment... \u001b[39;49;00mdone\n\u001b[01mchecking consistency... \u001b[39;49;00mdone\n\u001b[01mpreparing documents... \u001b[39;49;00mdone\n\u001b[01mwriting output... \u001b[39;49;00m[100%] \u001b[32mindex\u001b[39;49;00m                                                 \n\u001b[01mbuild succeeded.\u001b[39;49;00m\n\nThe text files are in ../tmp/pytest-of-root/pytest-0/ext-autodoc/_build/text.\n\n# warning: \n\n========================= 1 failed, 30 passed in 2.31s =========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_ext_autodoc_configs.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_ext_autodoc_configs.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 31,
          "failed": 0,
          "errors": 0,
          "collected": 31,
          "duration": 6.03,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 31 items\n\ntests/test_ext_autodoc_configs.py::test_autoclass_content_class PASSED   [  3%]\ntests/test_ext_autodoc_configs.py::test_autoclass_content_init PASSED    [  6%]\ntests/test_ext_autodoc_configs.py::test_autodoc_class_signature_mixed PASSED [  9%]\ntests/test_ext_autodoc_configs.py::test_autodoc_class_signature_separated_init PASSED [ 12%]\ntests/test_ext_autodoc_configs.py::test_autodoc_class_signature_separated_new PASSED [ 16%]\ntests/test_ext_autodoc_configs.py::test_autoclass_content_both PASSED    [ 19%]\ntests/test_ext_autodoc_configs.py::test_autodoc_inherit_docstrings PASSED [ 22%]\ntests/test_ext_autodoc_configs.py::test_autodoc_docstring_signature PASSED [ 25%]\ntests/test_ext_autodoc_configs.py::test_autoclass_content_and_docstring_signature_class PASSED [ 29%]\ntests/test_ext_autodoc_configs.py::test_autoclass_content_and_docstring_signature_init PASSED [ 32%]\ntests/test_ext_autodoc_configs.py::test_autoclass_content_and_docstring_signature_both PASSED [ 35%]\ntests/test_ext_autodoc_configs.py::test_mocked_module_imports PASSED     [ 38%]\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_signature PASSED [ 41%]\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_none PASSED    [ 45%]\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_none_for_overload PASSED [ 48%]\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description PASSED [ 51%]\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_no_undoc PASSED [ 54%]\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_no_undoc_doc_rtype PASSED [ 58%]\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_with_documented_init PASSED [ 61%]\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_with_documented_init_no_undoc PASSED [ 64%]\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_with_documented_init_no_undoc_doc_rtype PASSED [ 67%]\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_for_invalid_node PASSED [ 70%]\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_both PASSED    [ 74%]\ntests/test_ext_autodoc_configs.py::test_autodoc_type_aliases PASSED      [ 77%]\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_and_type_aliases PASSED [ 80%]\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_format_fully_qualified PASSED [ 83%]\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_format_fully_qualified_for_class_alias PASSED [ 87%]\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_format_fully_qualified_for_generic_alias PASSED [ 90%]\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_format_fully_qualified_for_newtype_alias PASSED [ 93%]\ntests/test_ext_autodoc_configs.py::test_autodoc_default_options PASSED   [ 96%]\ntests/test_ext_autodoc_configs.py::test_autodoc_default_options_with_values PASSED [100%]\n\n============================== 31 passed in 2.78s ==============================\n\n",
          "test_files_run": [
            "tests/test_ext_autodoc_configs.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sphinx-doc__sphinx-10466",
      "repo": "sphinx-doc/sphinx",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 14.031300067901611,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 6,
          "failed": 1,
          "errors": 0,
          "collected": 8,
          "duration": 5.83,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 8 items\n\ntests/test_build_gettext.py::test_Catalog_duplicated_message FAILED      [ 12%]\ntests/test_build_gettext.py::test_build_gettext PASSED                   [ 25%]\ntests/test_build_gettext.py::test_msgfmt SKIPPED                         [ 37%]\ntests/test_build_gettext.py::test_gettext_index_entries PASSED           [ 50%]\ntests/test_build_gettext.py::test_gettext_disable_index_entries PASSED   [ 62%]\ntests/test_build_gettext.py::test_gettext_template PASSED                [ 75%]\ntests/test_build_gettext.py::test_gettext_template_msgid_order_in_sphinxpot PASSED [ 87%]\ntests/test_build_gettext.py::test_build_single_pot PASSED                [100%]\n\n=================================== FAILURES ===================================\n_______________________ test_Catalog_duplicated_message ________________________\ntests/test_build_gettext.py:27: in test_Catalog_duplicated_message\n    assert msg1.locations == [('/path/to/filename', 1),\nE   AssertionError: assert [('/path/to/f...tanother', 1)] == [('/path/to/f...tanother', 1)]\nE     \nE     At index 1 diff: ('/path/to/filename', 1) != ('/path/to/filename', 2)\nE     Left contains one more item: ('/path/to/yetanother', 1)\nE     \nE     Full diff:\nE       [\nE     +     (...\nE     \nE     ...Full output truncated (16 lines hidden), use '-vv' to show\n==================== 1 failed, 6 passed, 1 skipped in 3.08s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_build_gettext.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_build_gettext.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 7,
          "failed": 0,
          "errors": 0,
          "collected": 8,
          "duration": 6.59,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 8 items\n\ntests/test_build_gettext.py::test_Catalog_duplicated_message PASSED      [ 12%]\ntests/test_build_gettext.py::test_build_gettext PASSED                   [ 25%]\ntests/test_build_gettext.py::test_msgfmt SKIPPED                         [ 37%]\ntests/test_build_gettext.py::test_gettext_index_entries PASSED           [ 50%]\ntests/test_build_gettext.py::test_gettext_disable_index_entries PASSED   [ 62%]\ntests/test_build_gettext.py::test_gettext_template PASSED                [ 75%]\ntests/test_build_gettext.py::test_gettext_template_msgid_order_in_sphinxpot PASSED [ 87%]\ntests/test_build_gettext.py::test_build_single_pot PASSED                [100%]\n\n========================= 7 passed, 1 skipped in 3.44s =========================\n\n",
          "test_files_run": [
            "tests/test_build_gettext.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sphinx-doc__sphinx-10614",
      "repo": "sphinx-doc/sphinx",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 11.82300591468811,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 5,
          "failed": 1,
          "errors": 0,
          "collected": 6,
          "duration": 4.57,
          "log_tail": "tests/test_ext_inheritance_diagram.py::test_inheritance_diagram PASSED   [ 16%]\ntests/test_ext_inheritance_diagram.py::test_inheritance_diagram_png_html PASSED [ 33%]\ntests/test_ext_inheritance_diagram.py::test_inheritance_diagram_svg_html FAILED [ 50%]\ntests/test_ext_inheritance_diagram.py::test_inheritance_diagram_latex PASSED [ 66%]\ntests/test_ext_inheritance_diagram.py::test_inheritance_diagram_latex_alias PASSED [ 83%]\ntests/test_ext_inheritance_diagram.py::test_import_classes PASSED        [100%]\n\n=================================== FAILURES ===================================\n______________________ test_inheritance_diagram_svg_html _______________________\ntests/test_ext_inheritance_diagram.py:246: in test_inheritance_diagram_svg_html\n    assert abs_uri.exists()\nE   AssertionError: assert False\nE    +  where False = exists()\nE    +    where exists = PosixPath('/tmp/pytest-of-root/pytest-0/ext-inheritance_diagram/_build/index.html').exists\n--------------------------- Captured stdout teardown ---------------------------\n# testroot: root\n# builder: html\n# srcdir: /tmp/pytest-of-root/pytest-0/ext-inheritance_diagram\n# outdir: /tmp/pytest-of-root/pytest-0/ext-inheritance_diagram/_build/html\n# status: \n\u001b[01mRunning Sphinx v7.2.0+/ac2b7599d\u001b[39;49;00m\n\u001b[01mloading pickled environment... \u001b[39;49;00mdone\nloading intersphinx inventory from /tmp/pytest-of-root/pytest-0/test_inheritance_diagram_svg_h0/inventory...\n\u001b[01mbuilding [mo]: \u001b[39;49;00mall of 0 po files\n\u001b[01mwriting output... \u001b[39;49;00m\n\u001b[01mbuilding [html]: \u001b[39;49;00mall source files\n\u001b[01mupdating environment: \u001b[39;49;00m[config changed ('intersphinx_mapping')] 2 added, 0 changed, 0 removed\n\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 50%] \u001b[35mindex\u001b[39;49;00m\n\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[100%] \u001b[35msubdir/index\u001b[39;49;00m\n\u001b[01mlooking for now-outdated files... \u001b[39;49;00mnone found\n\u001b[01mpickling environment... \u001b[39;49;00mdone\n\u001b[01mchecking consistency... \u001b[39;49;00mdone\n\u001b[01mpreparing documents... \u001b[39;49;00mdone\n\u001b[01mcopying assets... \u001b[39;49;00m\u001b[01mcopying static files... \u001b[39;49;00mdone\n\u001b[01mcopying extra files... \u001b[39;49;00mdone\ndone\n\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 50%] \u001b[32mindex\u001b[39;49;00m\n\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[100%] \u001b[32msubdir/index\u001b[39;49;00m\n\u001b[01mgenerating indices... \u001b[39;49;00mgenindex done\n\u001b[01mwriting additional pages... \u001b[39;49;00msearch done\n\u001b[01mdumping search index in English (code: en)... \u001b[39;49;00mdone\n\u001b[01mdumping object inventory... \u001b[39;49;00mdone\n\n# warning: \n\u001b[91m/tmp/pytest-of-root/pytest-0/ext-inheritance_diagram/subdir/index.rst: WARNING: document isn't included in any toctree\u001b[39;49;00m\n\n========================= 1 failed, 5 passed in 1.89s ==========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/roots/test-ext-inheritance_diagram/conf.py tests/roots/test-ext-inheritance_diagram/subdir/other.py tests/roots/test-ext-inheritance_diagram/test.py tests/test_ext_inheritance_diagram.py` failed. (See above for error)",
          "test_files_run": [
            "tests/roots/test-ext-inheritance_diagram/conf.py",
            "tests/roots/test-ext-inheritance_diagram/subdir/other.py",
            "tests/roots/test-ext-inheritance_diagram/test.py",
            "tests/test_ext_inheritance_diagram.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 6,
          "failed": 0,
          "errors": 0,
          "collected": 6,
          "duration": 5.73,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 6 items\n\ntests/test_ext_inheritance_diagram.py::test_inheritance_diagram PASSED   [ 16%]\ntests/test_ext_inheritance_diagram.py::test_inheritance_diagram_png_html PASSED [ 33%]\ntests/test_ext_inheritance_diagram.py::test_inheritance_diagram_svg_html PASSED [ 50%]\ntests/test_ext_inheritance_diagram.py::test_inheritance_diagram_latex PASSED [ 66%]\ntests/test_ext_inheritance_diagram.py::test_inheritance_diagram_latex_alias PASSED [ 83%]\ntests/test_ext_inheritance_diagram.py::test_import_classes PASSED        [100%]\n\n============================== 6 passed in 2.33s ===============================\n\n",
          "test_files_run": [
            "tests/roots/test-ext-inheritance_diagram/conf.py",
            "tests/roots/test-ext-inheritance_diagram/subdir/other.py",
            "tests/roots/test-ext-inheritance_diagram/test.py",
            "tests/test_ext_inheritance_diagram.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sphinx-doc__sphinx-10673",
      "repo": "sphinx-doc/sphinx",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 8.967106103897095,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 9,
          "failed": 1,
          "errors": 0,
          "collected": 10,
          "duration": 3.69,
          "log_tail": "\ntests/test_environment_toctree.py::test_process_doc PASSED               [ 10%]\ntests/test_environment_toctree.py::test_glob PASSED                      [ 20%]\ntests/test_environment_toctree.py::test_get_toc_for PASSED               [ 30%]\ntests/test_environment_toctree.py::test_get_toc_for_only PASSED          [ 40%]\ntests/test_environment_toctree.py::test_get_toc_for_tocdepth PASSED      [ 50%]\ntests/test_environment_toctree.py::test_get_toctree_for PASSED           [ 60%]\ntests/test_environment_toctree.py::test_get_toctree_for_collapse PASSED  [ 70%]\ntests/test_environment_toctree.py::test_get_toctree_for_maxdepth PASSED  [ 80%]\ntests/test_environment_toctree.py::test_get_toctree_for_includehidden PASSED [ 90%]\ntests/test_environment_toctree.py::test_toctree_index FAILED             [100%]\n\n=================================== FAILURES ===================================\n______________________________ test_toctree_index ______________________________\ntests/test_environment_toctree.py:359: in test_toctree_index\n    assert_node(toctree[0][1][1], addnodes.toctree,\nsphinx/testing/util.py:74: in assert_node\n    assert node[key] == value, \\\nE   AssertionError: The node[entries] is not [(None, 'genindex'), (None, 'modindex'), (None, 'search')]: []\n--------------------------- Captured stdout teardown ---------------------------\n# testroot: root\n# builder: xml\n# srcdir: /tmp/pytest-of-root/pytest-0/toctree-index\n# outdir: /tmp/pytest-of-root/pytest-0/toctree-index/_build/xml\n# status: \n\u001b[01mRunning Sphinx v5.2.0+/f35d2a6cc\u001b[39;49;00m\n\u001b[01mbuilding [mo]: \u001b[39;49;00mtargets for 0 po files that are out of date\n\u001b[01mbuilding [xml]: \u001b[39;49;00mtargets for 2 source files that are out of date\n\u001b[01mupdating environment: \u001b[39;49;00m[new config] 2 added, 0 changed, 0 removed\n\u001b[01mreading sources... \u001b[39;49;00m[ 50%] \u001b[35mfoo\u001b[39;49;00m                                                  \n\u001b[01mreading sources... \u001b[39;49;00m[100%] \u001b[35mindex\u001b[39;49;00m                                                \n\u001b[01mlooking for now-outdated files... \u001b[39;49;00mnone found\n\u001b[01mpickling environment... \u001b[39;49;00mdone\n\u001b[01mchecking consistency... \u001b[39;49;00mdone\n\u001b[01mpreparing documents... \u001b[39;49;00mdone\n\u001b[01mwriting output... \u001b[39;49;00m[ 50%] \u001b[32mfoo\u001b[39;49;00m                                                   \n\u001b[01mwriting output... \u001b[39;49;00m[100%] \u001b[32mindex\u001b[39;49;00m                                                 \n\u001b[01mbuild succeeded, 3 warnings.\u001b[39;49;00m\n\nThe XML files are in ../tmp/pytest-of-root/pytest-0/toctree-index/_build/xml.\n\n# warning: \n\u001b[91m/tmp/pytest-of-root/pytest-0/toctree-index/index.rst:9: WARNING: toctree contains reference to nonexisting document 'genindex'\u001b[39;49;00m\n\u001b[91m/tmp/pytest-of-root/pytest-0/toctree-index/index.rst:9: WARNING: toctree contains reference to nonexisting document 'modindex'\u001b[39;49;00m\n\u001b[91m/tmp/pytest-of-root/pytest-0/toctree-index/index.rst:9: WARNING: toctree contains reference to nonexisting document 'search'\u001b[39;49;00m\n\n========================= 1 failed, 9 passed in 0.92s ==========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/roots/test-toctree-index/conf.py tests/test_environment_toctree.py` failed. (See above for error)",
          "test_files_run": [
            "tests/roots/test-toctree-index/conf.py",
            "tests/test_environment_toctree.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 10,
          "failed": 0,
          "errors": 0,
          "collected": 10,
          "duration": 3.83,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 10 items\n\ntests/test_environment_toctree.py::test_process_doc PASSED               [ 10%]\ntests/test_environment_toctree.py::test_glob PASSED                      [ 20%]\ntests/test_environment_toctree.py::test_get_toc_for PASSED               [ 30%]\ntests/test_environment_toctree.py::test_get_toc_for_only PASSED          [ 40%]\ntests/test_environment_toctree.py::test_get_toc_for_tocdepth PASSED      [ 50%]\ntests/test_environment_toctree.py::test_get_toctree_for PASSED           [ 60%]\ntests/test_environment_toctree.py::test_get_toctree_for_collapse PASSED  [ 70%]\ntests/test_environment_toctree.py::test_get_toctree_for_maxdepth PASSED  [ 80%]\ntests/test_environment_toctree.py::test_get_toctree_for_includehidden PASSED [ 90%]\ntests/test_environment_toctree.py::test_toctree_index PASSED             [100%]\n\n============================== 10 passed in 0.82s ==============================\n\n",
          "test_files_run": [
            "tests/roots/test-toctree-index/conf.py",
            "tests/test_environment_toctree.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sphinx-doc__sphinx-11445",
      "repo": "sphinx-doc/sphinx",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 7.96504020690918,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 8,
          "failed": 2,
          "errors": 0,
          "collected": 10,
          "duration": 3.29,
          "log_tail": "___________ test_prepend_prolog_with_roles_in_sections_with_newline ____________\ntests/test_util_rst.py:112: in test_prepend_prolog_with_roles_in_sections_with_newline\n    assert list(content.xitems()) == [('<rst_prolog>', 0, 'this is rst_prolog'),\nE   AssertionError: assert [('dummy.rst'...------'), ...] == [('<rst_prolo..., 2, ''), ...]\nE     \nE     At index 0 diff: ('dummy.rst', 0, ':mod:`foo`') != ('<rst_prolog>', 0, 'this is rst_prolog')\nE     Left contains one more item: ('dummy.rst', 3, 'hello')\nE     \nE     Full diff:\nE       [\nE     +     (...\nE     \nE     ...Full output truncated (45 lines hidden), use '-vv' to show\n--------------------------- Captured stdout teardown ---------------------------\n# testroot: root\n# builder: html\n# srcdir: /tmp/pytest-of-root/pytest-0/root\n# outdir: /tmp/pytest-of-root/pytest-0/root/_build/html\n# status: \n\u001b[01mRunning Sphinx v7.1.0+/71db08c05\u001b[39;49;00m\n\n# warning: \n\n__________ test_prepend_prolog_with_roles_in_sections_without_newline __________\ntests/test_util_rst.py:127: in test_prepend_prolog_with_roles_in_sections_without_newline\n    assert list(content.xitems()) == [('<rst_prolog>', 0, 'this is rst_prolog'),\nE   AssertionError: assert [('dummy.rst'...------'), ...] == [('<rst_prolo..., 2, ''), ...]\nE     \nE     At index 0 diff: ('dummy.rst', 0, ':mod:`foo`') != ('<rst_prolog>', 0, 'this is rst_prolog')\nE     Left contains one more item: ('dummy.rst', 3, 'hello')\nE     \nE     Full diff:\nE       [\nE     +     (...\nE     \nE     ...Full output truncated (45 lines hidden), use '-vv' to show\n--------------------------- Captured stdout teardown ---------------------------\n# testroot: root\n# builder: html\n# srcdir: /tmp/pytest-of-root/pytest-0/root\n# outdir: /tmp/pytest-of-root/pytest-0/root/_build/html\n# status: \n\u001b[01mRunning Sphinx v7.1.0+/71db08c05\u001b[39;49;00m\n\n# warning: \n\n========================= 2 failed, 8 passed in 0.64s ==========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_util_rst.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_util_rst.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 10,
          "failed": 0,
          "errors": 0,
          "collected": 10,
          "duration": 3.73,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 10 items\n\ntests/test_util_rst.py::test_escape PASSED                               [ 10%]\ntests/test_util_rst.py::test_append_epilog PASSED                        [ 20%]\ntests/test_util_rst.py::test_prepend_prolog PASSED                       [ 30%]\ntests/test_util_rst.py::test_prepend_prolog_with_CR PASSED               [ 40%]\ntests/test_util_rst.py::test_prepend_prolog_without_CR PASSED            [ 50%]\ntests/test_util_rst.py::test_prepend_prolog_with_roles_in_sections PASSED [ 60%]\ntests/test_util_rst.py::test_prepend_prolog_with_roles_in_sections_with_newline PASSED [ 70%]\ntests/test_util_rst.py::test_prepend_prolog_with_roles_in_sections_without_newline PASSED [ 80%]\ntests/test_util_rst.py::test_textwidth PASSED                            [ 90%]\ntests/test_util_rst.py::test_heading PASSED                              [100%]\n\n============================== 10 passed in 0.73s ==============================\n\n",
          "test_files_run": [
            "tests/test_util_rst.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sphinx-doc__sphinx-11510",
      "repo": "sphinx-doc/sphinx",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 8.900874376296997,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 7,
          "failed": 2,
          "errors": 0,
          "collected": 9,
          "duration": 3.5,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 9 items\n\ntests/test_directive_other.py::test_toctree PASSED                       [ 11%]\ntests/test_directive_other.py::test_relative_toctree PASSED              [ 22%]\ntests/test_directive_other.py::test_toctree_urls_and_titles PASSED       [ 33%]\ntests/test_directive_other.py::test_toctree_glob PASSED                  [ 44%]\ntests/test_directive_other.py::test_toctree_glob_and_url PASSED          [ 55%]\ntests/test_directive_other.py::test_reversed_toctree PASSED              [ 66%]\ntests/test_directive_other.py::test_toctree_twice PASSED                 [ 77%]\ntests/test_directive_other.py::test_include_source_read_event FAILED     [ 88%]\ntests/test_directive_other.py::test_include_source_read_event_nested_includes FAILED [100%]\n\n=================================== FAILURES ===================================\n________________________ test_include_source_read_event ________________________\ntests/test_directive_other.py:169: in test_include_source_read_event\n    assert \"baz/baz\" in sources_reported\nE   AssertionError: assert 'baz/baz' in {'index': '.. include:: baz/baz.rst\\n   :start-line: 4\\n\\n.. include:: text.txt\\n   :literal:    \\n'}\n--------------------------- Captured stdout teardown ---------------------------\n# testroot: root\n# builder: html\n# srcdir: /tmp/pytest-of-root/pytest-0/directive-include\n# outdir: /tmp/pytest-of-root/pytest-0/directive-include/_build/html\n# status: \n\u001b[01mRunning Sphinx v7.2.0+/6cb783c00\u001b[39;49;00m\n\n# warning: \n\n________________ test_include_source_read_event_nested_includes ________________\ntests/test_directive_other.py:187: in test_include_source_read_event_nested_includes\n    assert doctree.children[1].rawsource == \"The amazing foo.\"\nE   AssertionError: assert 'The #magical foo.' == 'The amazing foo.'\nE     \nE     - The amazing foo.\nE     + The #magical foo.\n--------------------------- Captured stdout teardown ---------------------------\n# testroot: root\n# builder: html\n# srcdir: /tmp/pytest-of-root/pytest-0/directive-include\n# outdir: /tmp/pytest-of-root/pytest-0/directive-include/_build/html\n# status: \n\u001b[01mRunning Sphinx v7.2.0+/6cb783c00\u001b[39;49;00m\n\n# warning: \n\n========================= 2 failed, 7 passed in 0.83s ==========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/roots/test-directive-include/conf.py tests/test_directive_other.py` failed. (See above for error)",
          "test_files_run": [
            "tests/roots/test-directive-include/conf.py",
            "tests/test_directive_other.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 9,
          "failed": 0,
          "errors": 0,
          "collected": 9,
          "duration": 3.84,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 9 items\n\ntests/test_directive_other.py::test_toctree PASSED                       [ 11%]\ntests/test_directive_other.py::test_relative_toctree PASSED              [ 22%]\ntests/test_directive_other.py::test_toctree_urls_and_titles PASSED       [ 33%]\ntests/test_directive_other.py::test_toctree_glob PASSED                  [ 44%]\ntests/test_directive_other.py::test_toctree_glob_and_url PASSED          [ 55%]\ntests/test_directive_other.py::test_reversed_toctree PASSED              [ 66%]\ntests/test_directive_other.py::test_toctree_twice PASSED                 [ 77%]\ntests/test_directive_other.py::test_include_source_read_event PASSED     [ 88%]\ntests/test_directive_other.py::test_include_source_read_event_nested_includes PASSED [100%]\n\n============================== 9 passed in 0.88s ===============================\n\n",
          "test_files_run": [
            "tests/roots/test-directive-include/conf.py",
            "tests/test_directive_other.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sphinx-doc__sphinx-7440",
      "repo": "sphinx-doc/sphinx",
      "valid": false,
      "worker": "http://34.44.241.183:8080",
      "duration": 9.918617010116577,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 12,
          "failed": 2,
          "errors": 0,
          "collected": 14,
          "duration": 3.89,
          "log_tail": "tests/test_domain_std.py::test_productionlist\ntests/test_domain_std.py::test_productionlist\n  /testbed/sphinx/environment/adapters/toctree.py:313: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in toc.traverse(nodes.reference):\n\ntests/test_domain_std.py: 10 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:114: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n    _gaq.push(['_setAllowLinker', true]);\n\ntests/test_domain_std.py: 10 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:70: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_std.py: 10 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:99: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_std.py: 10 warnings\n  /testbed/sphinx/environment/adapters/toctree.py:327: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for toctreenode in doctree.traverse(addnodes.toctree):\n\ntests/test_domain_std.py: 77 warnings\n  /testbed/sphinx/environment/adapters/toctree.py:204: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for subtocnode in toc.traverse(addnodes.toctree):\n\ntests/test_domain_std.py: 11 warnings\n  /testbed/sphinx/environment/adapters/toctree.py:262: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for refnode in newnode.traverse(nodes.reference):\n\ntests/test_domain_std.py: 10 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:215: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_std.py: 10 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:238: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_std.py::test_productionlist\n  <template>:33: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_std.py::test_productionlist\n  <template>:224: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_std.py::test_productionlist\n  <template>:386: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_std.py::test_productionlist\n  <template>:401: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================= 2 failed, 12 passed, 1008 warnings in 1.05s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_domain_std.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_domain_std.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 13,
          "failed": 1,
          "errors": 0,
          "collected": 14,
          "duration": 4.52,
          "log_tail": "tests/test_domain_std.py::test_productionlist\ntests/test_domain_std.py::test_productionlist\n  /testbed/sphinx/environment/adapters/toctree.py:313: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in toc.traverse(nodes.reference):\n\ntests/test_domain_std.py: 10 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:114: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n    _gaq.push(['_setAllowLinker', true]);\n\ntests/test_domain_std.py: 10 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:70: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_std.py: 10 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:99: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_std.py: 10 warnings\n  /testbed/sphinx/environment/adapters/toctree.py:327: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for toctreenode in doctree.traverse(addnodes.toctree):\n\ntests/test_domain_std.py: 77 warnings\n  /testbed/sphinx/environment/adapters/toctree.py:204: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for subtocnode in toc.traverse(addnodes.toctree):\n\ntests/test_domain_std.py: 11 warnings\n  /testbed/sphinx/environment/adapters/toctree.py:262: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for refnode in newnode.traverse(nodes.reference):\n\ntests/test_domain_std.py: 10 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:215: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_std.py: 10 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:238: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_std.py::test_productionlist\n  <template>:33: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_std.py::test_productionlist\n  <template>:224: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_std.py::test_productionlist\n  <template>:386: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_std.py::test_productionlist\n  <template>:401: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================= 1 failed, 13 passed, 1008 warnings in 1.26s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_domain_std.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_domain_std.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sphinx-doc__sphinx-7454",
      "repo": "sphinx-doc/sphinx",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 10.595943927764893,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 27,
          "failed": 1,
          "errors": 0,
          "collected": 28,
          "duration": 4.21,
          "log_tail": "\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  /testbed/sphinx/environment/adapters/toctree.py:327: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for toctreenode in doctree.traverse(addnodes.toctree):\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:215: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:238: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  <template>:33: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  <template>:224: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  <template>:386: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  <template>:401: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 24 warnings\n  /testbed/sphinx/ext/todo.py:98: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for todo in document.traverse(todo_node):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================= 1 failed, 27 passed, 1084 warnings in 1.36s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_domain_py.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_domain_py.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 28,
          "failed": 0,
          "errors": 0,
          "collected": 28,
          "duration": 4.92,
          "log_tail": "  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:99: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  /testbed/sphinx/environment/adapters/toctree.py:327: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for toctreenode in doctree.traverse(addnodes.toctree):\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:215: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:238: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  <template>:33: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  <template>:224: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  <template>:386: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  <template>:401: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 24 warnings\n  /testbed/sphinx/ext/todo.py:98: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for todo in document.traverse(todo_node):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n====================== 28 passed, 1084 warnings in 1.71s =======================\n\n",
          "test_files_run": [
            "tests/test_domain_py.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sphinx-doc__sphinx-7462",
      "repo": "sphinx-doc/sphinx",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 11.500518083572388,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 65,
          "failed": 2,
          "errors": 0,
          "collected": 67,
          "duration": 4.5,
          "log_tail": "\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  /testbed/sphinx/environment/adapters/toctree.py:327: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for toctreenode in doctree.traverse(addnodes.toctree):\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:215: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:238: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  <template>:33: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  <template>:224: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  <template>:386: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  <template>:401: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 24 warnings\n  /testbed/sphinx/ext/todo.py:98: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for todo in document.traverse(todo_node):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================= 2 failed, 65 passed, 1084 warnings in 1.55s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_domain_py.py tests/test_pycode_ast.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_domain_py.py",
            "tests/test_pycode_ast.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 67,
          "failed": 0,
          "errors": 0,
          "collected": 67,
          "duration": 5.47,
          "log_tail": "  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:99: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  /testbed/sphinx/environment/adapters/toctree.py:327: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for toctreenode in doctree.traverse(addnodes.toctree):\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:215: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:238: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  <template>:33: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  <template>:224: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  <template>:386: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  <template>:401: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 24 warnings\n  /testbed/sphinx/ext/todo.py:98: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for todo in document.traverse(todo_node):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n====================== 67 passed, 1084 warnings in 1.86s =======================\n\n",
          "test_files_run": [
            "tests/test_domain_py.py",
            "tests/test_pycode_ast.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sphinx-doc__sphinx-7590",
      "repo": "sphinx-doc/sphinx",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 20.943657159805298,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 24,
          "failed": 1,
          "errors": 0,
          "collected": 25,
          "duration": 9.82,
          "log_tail": "tests/test_domain_cpp.py::test_build_domain_cpp_with_add_function_parentheses_is_False\ntests/test_domain_cpp.py::test_xref_consistency\n  <template>:33: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_cpp.py::test_build_domain_cpp_multi_decl_lookup\ntests/test_domain_cpp.py::test_build_domain_cpp_warn_template_param_qualified_name\ntests/test_domain_cpp.py::test_build_domain_cpp_backslash_ok\ntests/test_domain_cpp.py::test_build_domain_cpp_semicolon\ntests/test_domain_cpp.py::test_build_domain_cpp_anon_dup_decl\ntests/test_domain_cpp.py::test_build_domain_cpp_misuse_of_roles\ntests/test_domain_cpp.py::test_build_domain_cpp_with_add_function_parentheses_is_True\ntests/test_domain_cpp.py::test_build_domain_cpp_with_add_function_parentheses_is_False\ntests/test_domain_cpp.py::test_xref_consistency\n  <template>:224: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_cpp.py::test_build_domain_cpp_multi_decl_lookup\ntests/test_domain_cpp.py::test_build_domain_cpp_warn_template_param_qualified_name\ntests/test_domain_cpp.py::test_build_domain_cpp_backslash_ok\ntests/test_domain_cpp.py::test_build_domain_cpp_semicolon\ntests/test_domain_cpp.py::test_build_domain_cpp_anon_dup_decl\ntests/test_domain_cpp.py::test_build_domain_cpp_misuse_of_roles\ntests/test_domain_cpp.py::test_build_domain_cpp_with_add_function_parentheses_is_True\ntests/test_domain_cpp.py::test_build_domain_cpp_with_add_function_parentheses_is_False\ntests/test_domain_cpp.py::test_xref_consistency\n  <template>:386: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_cpp.py::test_build_domain_cpp_multi_decl_lookup\ntests/test_domain_cpp.py::test_build_domain_cpp_warn_template_param_qualified_name\ntests/test_domain_cpp.py::test_build_domain_cpp_backslash_ok\ntests/test_domain_cpp.py::test_build_domain_cpp_semicolon\ntests/test_domain_cpp.py::test_build_domain_cpp_anon_dup_decl\ntests/test_domain_cpp.py::test_build_domain_cpp_misuse_of_roles\ntests/test_domain_cpp.py::test_build_domain_cpp_with_add_function_parentheses_is_True\ntests/test_domain_cpp.py::test_build_domain_cpp_with_add_function_parentheses_is_False\ntests/test_domain_cpp.py::test_xref_consistency\n  <template>:401: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_cpp.py: 234 warnings\n  /testbed/sphinx/util/nodes.py:348: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for img in node.traverse(nodes.image):\n\ntests/test_domain_cpp.py: 234 warnings\n  /testbed/sphinx/util/nodes.py:350: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for raw in node.traverse(nodes.raw):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================= 1 failed, 24 passed, 6261 warnings in 6.72s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_domain_cpp.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_domain_cpp.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 25,
          "failed": 0,
          "errors": 0,
          "collected": 25,
          "duration": 9.57,
          "log_tail": "tests/test_domain_cpp.py::test_build_domain_cpp_with_add_function_parentheses_is_True\ntests/test_domain_cpp.py::test_build_domain_cpp_with_add_function_parentheses_is_False\ntests/test_domain_cpp.py::test_xref_consistency\n  <template>:33: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_cpp.py::test_build_domain_cpp_multi_decl_lookup\ntests/test_domain_cpp.py::test_build_domain_cpp_warn_template_param_qualified_name\ntests/test_domain_cpp.py::test_build_domain_cpp_backslash_ok\ntests/test_domain_cpp.py::test_build_domain_cpp_semicolon\ntests/test_domain_cpp.py::test_build_domain_cpp_anon_dup_decl\ntests/test_domain_cpp.py::test_build_domain_cpp_misuse_of_roles\ntests/test_domain_cpp.py::test_build_domain_cpp_with_add_function_parentheses_is_True\ntests/test_domain_cpp.py::test_build_domain_cpp_with_add_function_parentheses_is_False\ntests/test_domain_cpp.py::test_xref_consistency\n  <template>:224: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_cpp.py::test_build_domain_cpp_multi_decl_lookup\ntests/test_domain_cpp.py::test_build_domain_cpp_warn_template_param_qualified_name\ntests/test_domain_cpp.py::test_build_domain_cpp_backslash_ok\ntests/test_domain_cpp.py::test_build_domain_cpp_semicolon\ntests/test_domain_cpp.py::test_build_domain_cpp_anon_dup_decl\ntests/test_domain_cpp.py::test_build_domain_cpp_misuse_of_roles\ntests/test_domain_cpp.py::test_build_domain_cpp_with_add_function_parentheses_is_True\ntests/test_domain_cpp.py::test_build_domain_cpp_with_add_function_parentheses_is_False\ntests/test_domain_cpp.py::test_xref_consistency\n  <template>:386: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_cpp.py::test_build_domain_cpp_multi_decl_lookup\ntests/test_domain_cpp.py::test_build_domain_cpp_warn_template_param_qualified_name\ntests/test_domain_cpp.py::test_build_domain_cpp_backslash_ok\ntests/test_domain_cpp.py::test_build_domain_cpp_semicolon\ntests/test_domain_cpp.py::test_build_domain_cpp_anon_dup_decl\ntests/test_domain_cpp.py::test_build_domain_cpp_misuse_of_roles\ntests/test_domain_cpp.py::test_build_domain_cpp_with_add_function_parentheses_is_True\ntests/test_domain_cpp.py::test_build_domain_cpp_with_add_function_parentheses_is_False\ntests/test_domain_cpp.py::test_xref_consistency\n  <template>:401: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_cpp.py: 234 warnings\n  /testbed/sphinx/util/nodes.py:348: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for img in node.traverse(nodes.image):\n\ntests/test_domain_cpp.py: 234 warnings\n  /testbed/sphinx/util/nodes.py:350: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for raw in node.traverse(nodes.raw):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n====================== 25 passed, 6685 warnings in 6.19s =======================\n\n",
          "test_files_run": [
            "tests/test_domain_cpp.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sphinx-doc__sphinx-7748",
      "repo": "sphinx-doc/sphinx",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 10.865169048309326,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 12,
          "failed": 2,
          "errors": 0,
          "collected": 14,
          "duration": 4.38,
          "log_tail": "tests/test_ext_autodoc_configs.py::test_autodoc_typehints_description\n  /testbed/sphinx/transforms/i18n.py:484: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for inline in self.document.traverse(matcher):  # type: nodes.inline\n\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description\n  /testbed/sphinx/domains/cpp.py:6877: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(AliasNode):\n\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description\n  /testbed/sphinx/transforms/post_transforms/__init__.py:71: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(addnodes.pending_xref):\n\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description\n  /testbed/sphinx/util/nodes.py:596: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in document.traverse(addnodes.only):\n\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description\n  /testbed/sphinx/transforms/post_transforms/images.py:35: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(nodes.image):\n\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description\n  /testbed/sphinx/transforms/post_transforms/__init__.py:215: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(addnodes.desc_sig_element):\n\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description\n  /testbed/sphinx/builders/latex/transforms.py:595: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(nodes.title):\n\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description\n  /testbed/sphinx/transforms/post_transforms/code.py:44: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(addnodes.highlightlang):\n\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description\n  /testbed/sphinx/transforms/post_transforms/code.py:99: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for lbnode in self.document.traverse(nodes.literal_block):  # type: nodes.literal_block\n\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description\n  /testbed/sphinx/transforms/post_transforms/code.py:103: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for dbnode in self.document.traverse(nodes.doctest_block):  # type: nodes.doctest_block\n\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description\n  /testbed/sphinx/environment/__init__.py:541: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for toctreenode in doctree.traverse(addnodes.toctree):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================== 2 failed, 12 passed, 41 warnings in 1.24s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/roots/test-ext-autodoc/target/docstring_signature.py tests/test_ext_autodoc_configs.py` failed. (See above for error)",
          "test_files_run": [
            "tests/roots/test-ext-autodoc/target/docstring_signature.py",
            "tests/test_ext_autodoc_configs.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 14,
          "failed": 0,
          "errors": 0,
          "collected": 14,
          "duration": 4.98,
          "log_tail": "\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description\n  /testbed/sphinx/transforms/i18n.py:484: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for inline in self.document.traverse(matcher):  # type: nodes.inline\n\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description\n  /testbed/sphinx/domains/cpp.py:6877: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(AliasNode):\n\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description\n  /testbed/sphinx/transforms/post_transforms/__init__.py:71: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(addnodes.pending_xref):\n\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description\n  /testbed/sphinx/util/nodes.py:596: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in document.traverse(addnodes.only):\n\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description\n  /testbed/sphinx/transforms/post_transforms/images.py:35: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(nodes.image):\n\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description\n  /testbed/sphinx/transforms/post_transforms/__init__.py:215: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(addnodes.desc_sig_element):\n\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description\n  /testbed/sphinx/builders/latex/transforms.py:595: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(nodes.title):\n\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description\n  /testbed/sphinx/transforms/post_transforms/code.py:44: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(addnodes.highlightlang):\n\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description\n  /testbed/sphinx/transforms/post_transforms/code.py:99: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for lbnode in self.document.traverse(nodes.literal_block):  # type: nodes.literal_block\n\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description\n  /testbed/sphinx/transforms/post_transforms/code.py:103: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for dbnode in self.document.traverse(nodes.doctest_block):  # type: nodes.doctest_block\n\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description\n  /testbed/sphinx/environment/__init__.py:541: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for toctreenode in doctree.traverse(addnodes.toctree):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================= 14 passed, 41 warnings in 1.45s ========================\n\n",
          "test_files_run": [
            "tests/roots/test-ext-autodoc/target/docstring_signature.py",
            "tests/test_ext_autodoc_configs.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sphinx-doc__sphinx-7757",
      "repo": "sphinx-doc/sphinx",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 10.282107830047607,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 33,
          "failed": 1,
          "errors": 0,
          "collected": 34,
          "duration": 4.01,
          "log_tail": "tests/test_util_inspect.py::test_dictionary_sorting PASSED               [ 52%]\ntests/test_util_inspect.py::test_set_sorting PASSED                      [ 55%]\ntests/test_util_inspect.py::test_set_sorting_fallback PASSED             [ 58%]\ntests/test_util_inspect.py::test_frozenset_sorting PASSED                [ 61%]\ntests/test_util_inspect.py::test_frozenset_sorting_fallback PASSED       [ 64%]\ntests/test_util_inspect.py::test_dict_customtype PASSED                  [ 67%]\ntests/test_util_inspect.py::test_isclassmethod PASSED                    [ 70%]\ntests/test_util_inspect.py::test_isstaticmethod PASSED                   [ 73%]\ntests/test_util_inspect.py::test_iscoroutinefunction PASSED              [ 76%]\ntests/test_util_inspect.py::test_isfunction PASSED                       [ 79%]\ntests/test_util_inspect.py::test_isbuiltin PASSED                        [ 82%]\ntests/test_util_inspect.py::test_isdescriptor PASSED                     [ 85%]\ntests/test_util_inspect.py::test_isattributedescriptor PASSED            [ 88%]\ntests/test_util_inspect.py::test_isproperty PASSED                       [ 91%]\ntests/test_util_inspect.py::test_unpartial PASSED                        [ 94%]\ntests/test_util_inspect.py::test_getdoc_inherited_decorated_method PASSED [ 97%]\ntests/test_util_inspect.py::test_is_builtin_class_method PASSED          [100%]\n\n=================================== FAILURES ===================================\n________________ test_signature_from_str_positionaly_only_args _________________\ntests/test_util_inspect.py:343: in test_signature_from_str_positionaly_only_args\n    assert sig.parameters['b'].default == '0'\nE   assert <class 'inspect._empty'> == '0'\nE    +  where <class 'inspect._empty'> = <Parameter \"b\">.default\n=============================== warnings summary ===============================\nsphinx/util/docutils.py:45\n  /testbed/sphinx/util/docutils.py:45: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    __version_info__ = tuple(LooseVersion(docutils.__version__).version)\n\nsphinx/registry.py:22\n  /testbed/sphinx/registry.py:22: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    from pkg_resources import iter_entry_points\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n    declare_namespace(pkg)\n\nsphinx/directives/patches.py:15\n  /testbed/sphinx/directives/patches.py:15: DeprecationWarning: The `docutils.parsers.rst.directive.html` module will be removed in Docutils 2.0. Since Docutils 0.18, the \"Meta\" node is defined in `docutils.parsers.rst.directives.misc`.\n    from docutils.parsers.rst.directives import images, html, tables\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=================== 1 failed, 33 passed, 7 warnings in 0.98s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_util_inspect.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_util_inspect.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 34,
          "failed": 0,
          "errors": 0,
          "collected": 34,
          "duration": 4.51,
          "log_tail": "tests/test_util_inspect.py::test_signature_from_str_kwonly_args PASSED   [ 32%]\ntests/test_util_inspect.py::test_signature_from_str_positionaly_only_args PASSED [ 35%]\ntests/test_util_inspect.py::test_signature_from_str_invalid PASSED       [ 38%]\ntests/test_util_inspect.py::test_safe_getattr_with_default PASSED        [ 41%]\ntests/test_util_inspect.py::test_safe_getattr_with_exception PASSED      [ 44%]\ntests/test_util_inspect.py::test_safe_getattr_with_property_exception PASSED [ 47%]\ntests/test_util_inspect.py::test_safe_getattr_with___dict___override PASSED [ 50%]\ntests/test_util_inspect.py::test_dictionary_sorting PASSED               [ 52%]\ntests/test_util_inspect.py::test_set_sorting PASSED                      [ 55%]\ntests/test_util_inspect.py::test_set_sorting_fallback PASSED             [ 58%]\ntests/test_util_inspect.py::test_frozenset_sorting PASSED                [ 61%]\ntests/test_util_inspect.py::test_frozenset_sorting_fallback PASSED       [ 64%]\ntests/test_util_inspect.py::test_dict_customtype PASSED                  [ 67%]\ntests/test_util_inspect.py::test_isclassmethod PASSED                    [ 70%]\ntests/test_util_inspect.py::test_isstaticmethod PASSED                   [ 73%]\ntests/test_util_inspect.py::test_iscoroutinefunction PASSED              [ 76%]\ntests/test_util_inspect.py::test_isfunction PASSED                       [ 79%]\ntests/test_util_inspect.py::test_isbuiltin PASSED                        [ 82%]\ntests/test_util_inspect.py::test_isdescriptor PASSED                     [ 85%]\ntests/test_util_inspect.py::test_isattributedescriptor PASSED            [ 88%]\ntests/test_util_inspect.py::test_isproperty PASSED                       [ 91%]\ntests/test_util_inspect.py::test_unpartial PASSED                        [ 94%]\ntests/test_util_inspect.py::test_getdoc_inherited_decorated_method PASSED [ 97%]\ntests/test_util_inspect.py::test_is_builtin_class_method PASSED          [100%]\n\n=============================== warnings summary ===============================\nsphinx/util/docutils.py:45\n  /testbed/sphinx/util/docutils.py:45: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    __version_info__ = tuple(LooseVersion(docutils.__version__).version)\n\nsphinx/registry.py:22\n  /testbed/sphinx/registry.py:22: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    from pkg_resources import iter_entry_points\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n    declare_namespace(pkg)\n\nsphinx/directives/patches.py:15\n  /testbed/sphinx/directives/patches.py:15: DeprecationWarning: The `docutils.parsers.rst.directive.html` module will be removed in Docutils 2.0. Since Docutils 0.18, the \"Meta\" node is defined in `docutils.parsers.rst.directives.misc`.\n    from docutils.parsers.rst.directives import images, html, tables\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================== 34 passed, 7 warnings in 1.01s ========================\n\n",
          "test_files_run": [
            "tests/test_util_inspect.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sphinx-doc__sphinx-7889",
      "repo": "sphinx-doc/sphinx",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 7.986423969268799,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 5,
          "failed": 1,
          "errors": 0,
          "collected": 6,
          "duration": 3.11,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 6 items\n\ntests/test_ext_autodoc_mock.py::test_MockModule PASSED                   [ 16%]\ntests/test_ext_autodoc_mock.py::test_MockObject FAILED                   [ 33%]\ntests/test_ext_autodoc_mock.py::test_mock PASSED                         [ 50%]\ntests/test_ext_autodoc_mock.py::test_mock_does_not_follow_upper_modules PASSED [ 66%]\ntests/test_ext_autodoc_mock.py::test_abc_MockObject PASSED               [ 83%]\ntests/test_ext_autodoc_mock.py::test_mock_decorator PASSED               [100%]\n\n=================================== FAILURES ===================================\n_______________________________ test_MockObject ________________________________\ntests/test_ext_autodoc_mock.py:59: in test_MockObject\n    class SubClass2(mock.SomeClass[T]):\nsphinx/ext/autodoc/mock.py:56: in __getitem__\n    return _make_subclass(key, self.__display_name__, self.__class__)()\nsphinx/ext/autodoc/mock.py:73: in _make_subclass\n    attrs = {'__module__': module, '__display_name__': module + '.' + name}\nE   TypeError: can only concatenate str (not \"TypeVar\") to str\n=============================== warnings summary ===============================\nsphinx/util/docutils.py:45\n  /testbed/sphinx/util/docutils.py:45: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    __version_info__ = tuple(LooseVersion(docutils.__version__).version)\n\nsphinx/registry.py:22\n  /testbed/sphinx/registry.py:22: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    from pkg_resources import iter_entry_points\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n    declare_namespace(pkg)\n\nsphinx/directives/patches.py:15\n  /testbed/sphinx/directives/patches.py:15: DeprecationWarning: The `docutils.parsers.rst.directive.html` module will be removed in Docutils 2.0. Since Docutils 0.18, the \"Meta\" node is defined in `docutils.parsers.rst.directives.misc`.\n    from docutils.parsers.rst.directives import images, html, tables\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=================== 1 failed, 5 passed, 7 warnings in 0.13s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_ext_autodoc_mock.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_ext_autodoc_mock.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 6,
          "failed": 0,
          "errors": 0,
          "collected": 6,
          "duration": 3.35,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 6 items\n\ntests/test_ext_autodoc_mock.py::test_MockModule PASSED                   [ 16%]\ntests/test_ext_autodoc_mock.py::test_MockObject PASSED                   [ 33%]\ntests/test_ext_autodoc_mock.py::test_mock PASSED                         [ 50%]\ntests/test_ext_autodoc_mock.py::test_mock_does_not_follow_upper_modules PASSED [ 66%]\ntests/test_ext_autodoc_mock.py::test_abc_MockObject PASSED               [ 83%]\ntests/test_ext_autodoc_mock.py::test_mock_decorator PASSED               [100%]\n\n=============================== warnings summary ===============================\nsphinx/util/docutils.py:45\n  /testbed/sphinx/util/docutils.py:45: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    __version_info__ = tuple(LooseVersion(docutils.__version__).version)\n\nsphinx/registry.py:22\n  /testbed/sphinx/registry.py:22: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    from pkg_resources import iter_entry_points\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n    declare_namespace(pkg)\n\nsphinx/directives/patches.py:15\n  /testbed/sphinx/directives/patches.py:15: DeprecationWarning: The `docutils.parsers.rst.directive.html` module will be removed in Docutils 2.0. Since Docutils 0.18, the \"Meta\" node is defined in `docutils.parsers.rst.directives.misc`.\n    from docutils.parsers.rst.directives import images, html, tables\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================== 6 passed, 7 warnings in 0.12s =========================\n\n",
          "test_files_run": [
            "tests/test_ext_autodoc_mock.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sphinx-doc__sphinx-7910",
      "repo": "sphinx-doc/sphinx",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 8.356488943099976,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 16,
          "failed": 1,
          "errors": 0,
          "collected": 17,
          "duration": 3.25,
          "log_tail": "tests/test_ext_napoleon.py::SetupTest::test_add_config_values PASSED     [ 11%]\ntests/test_ext_napoleon.py::SetupTest::test_unknown_app_type PASSED      [ 17%]\ntests/test_ext_napoleon.py::SkipMemberTest::test_class_decorated_doc FAILED [ 23%]\ntests/test_ext_napoleon.py::SkipMemberTest::test_class_private_doc PASSED [ 29%]\ntests/test_ext_napoleon.py::SkipMemberTest::test_class_private_undoc PASSED [ 35%]\ntests/test_ext_napoleon.py::SkipMemberTest::test_class_special_doc PASSED [ 41%]\ntests/test_ext_napoleon.py::SkipMemberTest::test_class_special_undoc PASSED [ 47%]\ntests/test_ext_napoleon.py::SkipMemberTest::test_exception_private_doc PASSED [ 52%]\ntests/test_ext_napoleon.py::SkipMemberTest::test_exception_private_undoc PASSED [ 58%]\ntests/test_ext_napoleon.py::SkipMemberTest::test_exception_special_doc PASSED [ 64%]\ntests/test_ext_napoleon.py::SkipMemberTest::test_exception_special_undoc PASSED [ 70%]\ntests/test_ext_napoleon.py::SkipMemberTest::test_module_private_doc PASSED [ 76%]\ntests/test_ext_napoleon.py::SkipMemberTest::test_module_private_undoc PASSED [ 82%]\ntests/test_ext_napoleon.py::SkipMemberTest::test_module_special_doc PASSED [ 88%]\ntests/test_ext_napoleon.py::SkipMemberTest::test_module_special_undoc PASSED [ 94%]\ntests/test_ext_napoleon.py::SkipMemberTest::test_namedtuple PASSED       [100%]\n\n=================================== FAILURES ===================================\n___________________ SkipMemberTest.test_class_decorated_doc ____________________\ntests/test_ext_napoleon.py:180: in test_class_decorated_doc\n    self.assertSkip('class', '__decorated_func__',\ntests/test_ext_napoleon.py:139: in assertSkip\n    self.assertIs(_skip_member(app, what, member, obj, skip,\nE   AssertionError: None is not False\n=============================== warnings summary ===============================\nsphinx/util/docutils.py:45\n  /testbed/sphinx/util/docutils.py:45: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    __version_info__ = tuple(LooseVersion(docutils.__version__).version)\n\nsphinx/registry.py:22\n  /testbed/sphinx/registry.py:22: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    from pkg_resources import iter_entry_points\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n    declare_namespace(pkg)\n\nsphinx/directives/patches.py:15\n  /testbed/sphinx/directives/patches.py:15: DeprecationWarning: The `docutils.parsers.rst.directive.html` module will be removed in Docutils 2.0. Since Docutils 0.18, the \"Meta\" node is defined in `docutils.parsers.rst.directives.misc`.\n    from docutils.parsers.rst.directives import images, html, tables\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=================== 1 failed, 16 passed, 7 warnings in 0.14s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sphinx/testing/util.py tests/test_ext_napoleon.py` failed. (See above for error)",
          "test_files_run": [
            "sphinx/testing/util.py",
            "tests/test_ext_napoleon.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 17,
          "failed": 0,
          "errors": 0,
          "collected": 17,
          "duration": 3.61,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 17 items\n\ntests/test_ext_napoleon.py::ProcessDocstringTest::test_modify_in_place PASSED [  5%]\ntests/test_ext_napoleon.py::SetupTest::test_add_config_values PASSED     [ 11%]\ntests/test_ext_napoleon.py::SetupTest::test_unknown_app_type PASSED      [ 17%]\ntests/test_ext_napoleon.py::SkipMemberTest::test_class_decorated_doc PASSED [ 23%]\ntests/test_ext_napoleon.py::SkipMemberTest::test_class_private_doc PASSED [ 29%]\ntests/test_ext_napoleon.py::SkipMemberTest::test_class_private_undoc PASSED [ 35%]\ntests/test_ext_napoleon.py::SkipMemberTest::test_class_special_doc PASSED [ 41%]\ntests/test_ext_napoleon.py::SkipMemberTest::test_class_special_undoc PASSED [ 47%]\ntests/test_ext_napoleon.py::SkipMemberTest::test_exception_private_doc PASSED [ 52%]\ntests/test_ext_napoleon.py::SkipMemberTest::test_exception_private_undoc PASSED [ 58%]\ntests/test_ext_napoleon.py::SkipMemberTest::test_exception_special_doc PASSED [ 64%]\ntests/test_ext_napoleon.py::SkipMemberTest::test_exception_special_undoc PASSED [ 70%]\ntests/test_ext_napoleon.py::SkipMemberTest::test_module_private_doc PASSED [ 76%]\ntests/test_ext_napoleon.py::SkipMemberTest::test_module_private_undoc PASSED [ 82%]\ntests/test_ext_napoleon.py::SkipMemberTest::test_module_special_doc PASSED [ 88%]\ntests/test_ext_napoleon.py::SkipMemberTest::test_module_special_undoc PASSED [ 94%]\ntests/test_ext_napoleon.py::SkipMemberTest::test_namedtuple PASSED       [100%]\n\n=============================== warnings summary ===============================\nsphinx/util/docutils.py:45\n  /testbed/sphinx/util/docutils.py:45: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    __version_info__ = tuple(LooseVersion(docutils.__version__).version)\n\nsphinx/registry.py:22\n  /testbed/sphinx/registry.py:22: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    from pkg_resources import iter_entry_points\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n    declare_namespace(pkg)\n\nsphinx/directives/patches.py:15\n  /testbed/sphinx/directives/patches.py:15: DeprecationWarning: The `docutils.parsers.rst.directive.html` module will be removed in Docutils 2.0. Since Docutils 0.18, the \"Meta\" node is defined in `docutils.parsers.rst.directives.misc`.\n    from docutils.parsers.rst.directives import images, html, tables\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================== 17 passed, 7 warnings in 0.16s ========================\n\n",
          "test_files_run": [
            "sphinx/testing/util.py",
            "tests/test_ext_napoleon.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sphinx-doc__sphinx-7985",
      "repo": "sphinx-doc/sphinx",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 11.270256042480469,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 3,
          "failed": 2,
          "errors": 0,
          "collected": 5,
          "duration": 4.75,
          "log_tail": "tests/test_build_linkcheck.py::test_auth\ntests/test_build_linkcheck.py::test_linkcheck_request_headers\n  /testbed/sphinx/transforms/post_transforms/code.py:44: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(addnodes.highlightlang):\n\ntests/test_build_linkcheck.py::test_defaults\ntests/test_build_linkcheck.py::test_defaults_json\ntests/test_build_linkcheck.py::test_anchors_ignored\ntests/test_build_linkcheck.py::test_auth\ntests/test_build_linkcheck.py::test_linkcheck_request_headers\n  /testbed/sphinx/transforms/post_transforms/code.py:99: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for lbnode in self.document.traverse(nodes.literal_block):  # type: nodes.literal_block\n\ntests/test_build_linkcheck.py::test_defaults\ntests/test_build_linkcheck.py::test_defaults_json\ntests/test_build_linkcheck.py::test_anchors_ignored\ntests/test_build_linkcheck.py::test_auth\ntests/test_build_linkcheck.py::test_linkcheck_request_headers\n  /testbed/sphinx/transforms/post_transforms/code.py:103: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for dbnode in self.document.traverse(nodes.doctest_block):  # type: nodes.doctest_block\n\ntests/test_build_linkcheck.py::test_defaults\ntests/test_build_linkcheck.py::test_defaults_json\ntests/test_build_linkcheck.py::test_anchors_ignored\ntests/test_build_linkcheck.py::test_auth\ntests/test_build_linkcheck.py::test_linkcheck_request_headers\n  /testbed/sphinx/environment/__init__.py:542: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for toctreenode in doctree.traverse(addnodes.toctree):\n\ntests/test_build_linkcheck.py::test_defaults\ntests/test_build_linkcheck.py::test_defaults_json\ntests/test_build_linkcheck.py::test_anchors_ignored\ntests/test_build_linkcheck.py::test_auth\ntests/test_build_linkcheck.py::test_linkcheck_request_headers\n  /testbed/sphinx/builders/linkcheck.py:316: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for refnode in doctree.traverse(nodes.reference):\n\ntests/test_build_linkcheck.py::test_defaults\ntests/test_build_linkcheck.py::test_defaults_json\ntests/test_build_linkcheck.py::test_anchors_ignored\ntests/test_build_linkcheck.py::test_auth\ntests/test_build_linkcheck.py::test_linkcheck_request_headers\n  /testbed/sphinx/builders/linkcheck.py:325: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for imgnode in doctree.traverse(nodes.image):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================== 2 failed, 3 passed, 192 warnings in 1.42s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_build_linkcheck.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_build_linkcheck.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 5,
          "failed": 0,
          "errors": 0,
          "collected": 5,
          "duration": 5.43,
          "log_tail": "tests/test_build_linkcheck.py::test_anchors_ignored\ntests/test_build_linkcheck.py::test_auth\ntests/test_build_linkcheck.py::test_linkcheck_request_headers\n  /testbed/sphinx/transforms/post_transforms/code.py:44: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(addnodes.highlightlang):\n\ntests/test_build_linkcheck.py::test_defaults\ntests/test_build_linkcheck.py::test_defaults_json\ntests/test_build_linkcheck.py::test_anchors_ignored\ntests/test_build_linkcheck.py::test_auth\ntests/test_build_linkcheck.py::test_linkcheck_request_headers\n  /testbed/sphinx/transforms/post_transforms/code.py:99: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for lbnode in self.document.traverse(nodes.literal_block):  # type: nodes.literal_block\n\ntests/test_build_linkcheck.py::test_defaults\ntests/test_build_linkcheck.py::test_defaults_json\ntests/test_build_linkcheck.py::test_anchors_ignored\ntests/test_build_linkcheck.py::test_auth\ntests/test_build_linkcheck.py::test_linkcheck_request_headers\n  /testbed/sphinx/transforms/post_transforms/code.py:103: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for dbnode in self.document.traverse(nodes.doctest_block):  # type: nodes.doctest_block\n\ntests/test_build_linkcheck.py::test_defaults\ntests/test_build_linkcheck.py::test_defaults_json\ntests/test_build_linkcheck.py::test_anchors_ignored\ntests/test_build_linkcheck.py::test_auth\ntests/test_build_linkcheck.py::test_linkcheck_request_headers\n  /testbed/sphinx/environment/__init__.py:542: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for toctreenode in doctree.traverse(addnodes.toctree):\n\ntests/test_build_linkcheck.py::test_defaults\ntests/test_build_linkcheck.py::test_defaults_json\ntests/test_build_linkcheck.py::test_anchors_ignored\ntests/test_build_linkcheck.py::test_auth\ntests/test_build_linkcheck.py::test_linkcheck_request_headers\n  /testbed/sphinx/builders/linkcheck.py:329: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for refnode in doctree.traverse(nodes.reference):\n\ntests/test_build_linkcheck.py::test_defaults\ntests/test_build_linkcheck.py::test_defaults_json\ntests/test_build_linkcheck.py::test_anchors_ignored\ntests/test_build_linkcheck.py::test_auth\ntests/test_build_linkcheck.py::test_linkcheck_request_headers\n  /testbed/sphinx/builders/linkcheck.py:338: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for imgnode in doctree.traverse(nodes.image):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================= 5 passed, 192 warnings in 1.73s ========================\n\n",
          "test_files_run": [
            "tests/test_build_linkcheck.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sphinx-doc__sphinx-8035",
      "repo": "sphinx-doc/sphinx",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 9.212687015533447,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 2,
          "failed": 1,
          "errors": 0,
          "collected": 3,
          "duration": 3.86,
          "log_tail": "_____________________________ test_private_members _____________________________\ntests/test_ext_autodoc_private_members.py:71: in test_private_members\n    assert list(actual) == [\nE   AssertionError: assert ['', '.. py:m...private', ...] == ['', '.. py:m...private', ...]\nE     \nE     Left contains 8 more items, first extra item: ''\nE     \nE     Full diff:\nE       [\nE           '',\nE           '.. py:module:: target.private',...\nE     \nE     ...Full output truncated (18 lines hidden), use '-vv' to show\n--------------------------- Captured stdout teardown ---------------------------\n# testroot: root\n# builder: html\n# srcdir: /tmp/pytest-of-root/pytest-0/ext-autodoc\n# outdir: /tmp/pytest-of-root/pytest-0/ext-autodoc/_build/html\n# status: \n\u001b[01mRunning Sphinx v3.2.0\u001b[39;49;00m\n\n# warning: \n\u001b[91mWARNING: while setting up extension sphinx.addnodes: node class 'meta' is already registered, its visitors will be overridden\u001b[39;49;00m\n\n=============================== warnings summary ===============================\nsphinx/util/docutils.py:45\n  /testbed/sphinx/util/docutils.py:45: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    __version_info__ = tuple(LooseVersion(docutils.__version__).version)\n\nsphinx/registry.py:22\n  /testbed/sphinx/registry.py:22: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    from pkg_resources import iter_entry_points\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n    declare_namespace(pkg)\n\nsphinx/directives/patches.py:15\n  /testbed/sphinx/directives/patches.py:15: DeprecationWarning: The `docutils.parsers.rst.directive.html` module will be removed in Docutils 2.0. Since Docutils 0.18, the \"Meta\" node is defined in `docutils.parsers.rst.directives.misc`.\n    from docutils.parsers.rst.directives import images, html, tables\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=================== 1 failed, 2 passed, 7 warnings in 0.66s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_ext_autodoc_private_members.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_ext_autodoc_private_members.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 3,
          "failed": 0,
          "errors": 0,
          "collected": 3,
          "duration": 4.3,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 3 items\n\ntests/test_ext_autodoc_private_members.py::test_private_field PASSED     [ 33%]\ntests/test_ext_autodoc_private_members.py::test_private_field_and_private_members PASSED [ 66%]\ntests/test_ext_autodoc_private_members.py::test_private_members PASSED   [100%]\n\n=============================== warnings summary ===============================\nsphinx/util/docutils.py:45\n  /testbed/sphinx/util/docutils.py:45: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    __version_info__ = tuple(LooseVersion(docutils.__version__).version)\n\nsphinx/registry.py:22\n  /testbed/sphinx/registry.py:22: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    from pkg_resources import iter_entry_points\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n    declare_namespace(pkg)\n\nsphinx/directives/patches.py:15\n  /testbed/sphinx/directives/patches.py:15: DeprecationWarning: The `docutils.parsers.rst.directive.html` module will be removed in Docutils 2.0. Since Docutils 0.18, the \"Meta\" node is defined in `docutils.parsers.rst.directives.misc`.\n    from docutils.parsers.rst.directives import images, html, tables\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================== 3 passed, 7 warnings in 0.86s =========================\n\n",
          "test_files_run": [
            "tests/test_ext_autodoc_private_members.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sphinx-doc__sphinx-8056",
      "repo": "sphinx-doc/sphinx",
      "valid": false,
      "worker": "http://34.44.241.183:8080",
      "duration": 9.108101844787598,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 40,
          "failed": 2,
          "errors": 0,
          "collected": 42,
          "duration": 3.8,
          "log_tail": "E   ?         ++++\nE   - :param x2: Input arrays, description of ``x1``, ``x2``.\nE   - :type x2: :class:`array_like`\n__________________ TestNumpyDocstring.test_token_type_invalid __________________\ntests/test_ext_napoleon_docstring.py:2264: in test_token_type_invalid\n    _token_type(token)\n/opt/miniconda3/envs/testbed/lib/python3.9/contextlib.py:126: in __exit__\n    next(self.gen)\ntests/test_ext_napoleon_docstring.py:2240: in warns\n    assert len(warnings) == 1 and all(match_re.match(w) for w in warnings)\nE   assert (2 == 1)\nE    +  where 2 = len([\"\\x1b[91mWARNING: while setting up extension sphinx.addnodes: node class 'meta' is already registered, its visitors will be overridden\\x1b[39;49;00m\", '\\x1b[91mWARNING: invalid value set (missing closing brace): {1, 2\\x1b[39;49;00m'])\n--------------------------- Captured stdout teardown ---------------------------\n# testroot: root\n# builder: html\n# srcdir: /tmp/pytest-of-root/pytest-0/root\n# outdir: /tmp/pytest-of-root/pytest-0/root/_build/html\n# status: \n\u001b[01mRunning Sphinx v3.2.0\u001b[39;49;00m\n\n# warning: \n\u001b[91mWARNING: while setting up extension sphinx.addnodes: node class 'meta' is already registered, its visitors will be overridden\u001b[39;49;00m\n\u001b[91mWARNING: invalid value set (missing closing brace): {1, 2\u001b[39;49;00m\n\n=============================== warnings summary ===============================\nsphinx/util/docutils.py:45\n  /testbed/sphinx/util/docutils.py:45: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    __version_info__ = tuple(LooseVersion(docutils.__version__).version)\n\nsphinx/registry.py:22\n  /testbed/sphinx/registry.py:22: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    from pkg_resources import iter_entry_points\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n    declare_namespace(pkg)\n\nsphinx/directives/patches.py:15\n  /testbed/sphinx/directives/patches.py:15: DeprecationWarning: The `docutils.parsers.rst.directive.html` module will be removed in Docutils 2.0. Since Docutils 0.18, the \"Meta\" node is defined in `docutils.parsers.rst.directives.misc`.\n    from docutils.parsers.rst.directives import images, html, tables\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=================== 2 failed, 40 passed, 7 warnings in 0.69s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_ext_napoleon_docstring.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_ext_napoleon_docstring.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 41,
          "failed": 1,
          "errors": 0,
          "collected": 42,
          "duration": 4.15,
          "log_tail": "tests/test_ext_napoleon_docstring.py::TestNumpyDocstring::test_escape_args_and_kwargs[*x, **y-\\\\*x, \\\\*\\\\*y] PASSED [100%]\n\n=================================== FAILURES ===================================\n__________________ TestNumpyDocstring.test_token_type_invalid __________________\ntests/test_ext_napoleon_docstring.py:2264: in test_token_type_invalid\n    _token_type(token)\n/opt/miniconda3/envs/testbed/lib/python3.9/contextlib.py:126: in __exit__\n    next(self.gen)\ntests/test_ext_napoleon_docstring.py:2240: in warns\n    assert len(warnings) == 1 and all(match_re.match(w) for w in warnings)\nE   assert (2 == 1)\nE    +  where 2 = len([\"\\x1b[91mWARNING: while setting up extension sphinx.addnodes: node class 'meta' is already registered, its visitors will be overridden\\x1b[39;49;00m\", '\\x1b[91mWARNING: invalid value set (missing closing brace): {1, 2\\x1b[39;49;00m'])\n--------------------------- Captured stdout teardown ---------------------------\n# testroot: root\n# builder: html\n# srcdir: /tmp/pytest-of-root/pytest-0/root\n# outdir: /tmp/pytest-of-root/pytest-0/root/_build/html\n# status: \n\u001b[01mRunning Sphinx v3.2.0\u001b[39;49;00m\n\n# warning: \n\u001b[91mWARNING: while setting up extension sphinx.addnodes: node class 'meta' is already registered, its visitors will be overridden\u001b[39;49;00m\n\u001b[91mWARNING: invalid value set (missing closing brace): {1, 2\u001b[39;49;00m\n\n=============================== warnings summary ===============================\nsphinx/util/docutils.py:45\n  /testbed/sphinx/util/docutils.py:45: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    __version_info__ = tuple(LooseVersion(docutils.__version__).version)\n\nsphinx/registry.py:22\n  /testbed/sphinx/registry.py:22: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    from pkg_resources import iter_entry_points\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n    declare_namespace(pkg)\n\nsphinx/directives/patches.py:15\n  /testbed/sphinx/directives/patches.py:15: DeprecationWarning: The `docutils.parsers.rst.directive.html` module will be removed in Docutils 2.0. Since Docutils 0.18, the \"Meta\" node is defined in `docutils.parsers.rst.directives.misc`.\n    from docutils.parsers.rst.directives import images, html, tables\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=================== 1 failed, 41 passed, 7 warnings in 0.68s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_ext_napoleon_docstring.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_ext_napoleon_docstring.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sphinx-doc__sphinx-8120",
      "repo": "sphinx-doc/sphinx",
      "valid": false,
      "worker": "http://34.44.241.183:8080",
      "duration": 19.18672823905945,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 44,
          "failed": 5,
          "errors": 0,
          "collected": 49,
          "duration": 9.74,
          "log_tail": "\ntests/test_intl.py: 56 warnings\n  /testbed/sphinx/environment/adapters/toctree.py:313: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in toc.traverse(nodes.reference):\n\ntests/test_intl.py: 62 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:114: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n    _gaq.push(['_setAllowLinker', true]);\n\ntests/test_intl.py: 62 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:70: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_intl.py: 62 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:99: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_intl.py: 62 warnings\n  /testbed/sphinx/environment/adapters/toctree.py:327: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for toctreenode in doctree.traverse(addnodes.toctree):\n\ntests/test_intl.py: 62 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:215: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_intl.py: 62 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:238: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_intl.py::test_html_meta\ntests/test_intl.py::test_additional_targets_should_be_translated\n  <template>:33: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_intl.py::test_html_meta\ntests/test_intl.py::test_additional_targets_should_be_translated\n  <template>:224: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_intl.py::test_html_meta\ntests/test_intl.py::test_additional_targets_should_be_translated\n  <template>:386: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_intl.py::test_html_meta\ntests/test_intl.py::test_additional_targets_should_be_translated\n  <template>:401: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_intl.py: 28 warnings\n  /testbed/sphinx/builders/xml.py:79: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in doctree.traverse(nodes.Element):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================= 5 failed, 44 passed, 12363 warnings in 6.44s =================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_intl.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_intl.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 45,
          "failed": 4,
          "errors": 0,
          "collected": 49,
          "duration": 8.4,
          "log_tail": "\ntests/test_intl.py: 65 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:114: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n    _gaq.push(['_setAllowLinker', true]);\n\ntests/test_intl.py: 65 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:70: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_intl.py: 65 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:99: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_intl.py: 65 warnings\n  /testbed/sphinx/environment/adapters/toctree.py:327: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for toctreenode in doctree.traverse(addnodes.toctree):\n\ntests/test_intl.py: 65 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:215: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_intl.py: 65 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:238: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_intl.py::test_html_meta\ntests/test_intl.py::test_additional_targets_should_be_translated\ntests/test_intl.py::test_customize_system_message\n  <template>:33: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_intl.py::test_html_meta\ntests/test_intl.py::test_additional_targets_should_be_translated\ntests/test_intl.py::test_customize_system_message\n  <template>:224: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_intl.py::test_html_meta\ntests/test_intl.py::test_additional_targets_should_be_translated\ntests/test_intl.py::test_customize_system_message\n  <template>:386: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_intl.py::test_html_meta\ntests/test_intl.py::test_additional_targets_should_be_translated\ntests/test_intl.py::test_customize_system_message\n  <template>:401: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_intl.py: 28 warnings\n  /testbed/sphinx/builders/xml.py:79: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in doctree.traverse(nodes.Element):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================= 4 failed, 45 passed, 12504 warnings in 5.14s =================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_intl.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_intl.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sphinx-doc__sphinx-8265",
      "repo": "sphinx-doc/sphinx",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 8.019526720046997,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 38,
          "failed": 1,
          "errors": 0,
          "collected": 39,
          "duration": 3.11,
          "log_tail": "tests/test_pycode_ast.py::test_unparse[not a-not a] PASSED               [ 66%]\ntests/test_pycode_ast.py::test_unparse[a or b-a or b] PASSED             [ 69%]\ntests/test_pycode_ast.py::test_unparse[a ** b-a ** b] PASSED             [ 71%]\ntests/test_pycode_ast.py::test_unparse[a >> b-a >> b] PASSED             [ 74%]\ntests/test_pycode_ast.py::test_unparse[{1, 2, 3}-{1, 2, 3}] PASSED       [ 76%]\ntests/test_pycode_ast.py::test_unparse[a - b-a - b] PASSED               [ 79%]\ntests/test_pycode_ast.py::test_unparse['str'-'str'] PASSED               [ 82%]\ntests/test_pycode_ast.py::test_unparse[+ a-+ a] PASSED                   [ 84%]\ntests/test_pycode_ast.py::test_unparse[- 1-- 1] PASSED                   [ 87%]\ntests/test_pycode_ast.py::test_unparse[- a-- a] PASSED                   [ 89%]\ntests/test_pycode_ast.py::test_unparse[(1, 2, 3)-(1, 2, 3)] FAILED       [ 92%]\ntests/test_pycode_ast.py::test_unparse[()-()] PASSED                     [ 94%]\ntests/test_pycode_ast.py::test_unparse_None PASSED                       [ 97%]\ntests/test_pycode_ast.py::test_unparse_py38 PASSED                       [100%]\n\n=================================== FAILURES ===================================\n______________________ test_unparse[(1, 2, 3)-(1, 2, 3)] _______________________\ntests/test_pycode_ast.py:61: in test_unparse\n    assert ast.unparse(module.body[0].value) == expected\nE   AssertionError: assert '1, 2, 3' == '(1, 2, 3)'\nE     \nE     - (1, 2, 3)\nE     ? -       -\nE     + 1, 2, 3\n=============================== warnings summary ===============================\nsphinx/util/docutils.py:45\n  /testbed/sphinx/util/docutils.py:45: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    __version_info__ = tuple(LooseVersion(docutils.__version__).version)\n\nsphinx/registry.py:22\n  /testbed/sphinx/registry.py:22: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    from pkg_resources import iter_entry_points\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n    declare_namespace(pkg)\n\nsphinx/directives/patches.py:15\n  /testbed/sphinx/directives/patches.py:15: DeprecationWarning: The `docutils.parsers.rst.directive.html` module will be removed in Docutils 2.0. Since Docutils 0.18, the \"Meta\" node is defined in `docutils.parsers.rst.directives.misc`.\n    from docutils.parsers.rst.directives import images, html, tables\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=================== 1 failed, 38 passed, 7 warnings in 0.10s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_pycode_ast.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_pycode_ast.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 39,
          "failed": 0,
          "errors": 0,
          "collected": 39,
          "duration": 3.62,
          "log_tail": "tests/test_pycode_ast.py::test_unparse[Tuple[int, int]-Tuple[int, int]] PASSED [ 41%]\ntests/test_pycode_ast.py::test_unparse[~ 1-~ 1] PASSED                   [ 43%]\ntests/test_pycode_ast.py::test_unparse[lambda x, y: x + y-lambda x, y: ...] PASSED [ 46%]\ntests/test_pycode_ast.py::test_unparse[[1, 2, 3]-[1, 2, 3]] PASSED       [ 48%]\ntests/test_pycode_ast.py::test_unparse[a << b-a << b] PASSED             [ 51%]\ntests/test_pycode_ast.py::test_unparse[a @ b-a @ b] PASSED               [ 53%]\ntests/test_pycode_ast.py::test_unparse[a % b-a % b] PASSED               [ 56%]\ntests/test_pycode_ast.py::test_unparse[a * b-a * b] PASSED               [ 58%]\ntests/test_pycode_ast.py::test_unparse[sys-sys] PASSED                   [ 61%]\ntests/test_pycode_ast.py::test_unparse[1234-1234_1] PASSED               [ 64%]\ntests/test_pycode_ast.py::test_unparse[not a-not a] PASSED               [ 66%]\ntests/test_pycode_ast.py::test_unparse[a or b-a or b] PASSED             [ 69%]\ntests/test_pycode_ast.py::test_unparse[a ** b-a ** b] PASSED             [ 71%]\ntests/test_pycode_ast.py::test_unparse[a >> b-a >> b] PASSED             [ 74%]\ntests/test_pycode_ast.py::test_unparse[{1, 2, 3}-{1, 2, 3}] PASSED       [ 76%]\ntests/test_pycode_ast.py::test_unparse[a - b-a - b] PASSED               [ 79%]\ntests/test_pycode_ast.py::test_unparse['str'-'str'] PASSED               [ 82%]\ntests/test_pycode_ast.py::test_unparse[+ a-+ a] PASSED                   [ 84%]\ntests/test_pycode_ast.py::test_unparse[- 1-- 1] PASSED                   [ 87%]\ntests/test_pycode_ast.py::test_unparse[- a-- a] PASSED                   [ 89%]\ntests/test_pycode_ast.py::test_unparse[(1, 2, 3)-(1, 2, 3)] PASSED       [ 92%]\ntests/test_pycode_ast.py::test_unparse[()-()] PASSED                     [ 94%]\ntests/test_pycode_ast.py::test_unparse_None PASSED                       [ 97%]\ntests/test_pycode_ast.py::test_unparse_py38 PASSED                       [100%]\n\n=============================== warnings summary ===============================\nsphinx/util/docutils.py:45\n  /testbed/sphinx/util/docutils.py:45: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    __version_info__ = tuple(LooseVersion(docutils.__version__).version)\n\nsphinx/registry.py:22\n  /testbed/sphinx/registry.py:22: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    from pkg_resources import iter_entry_points\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n    declare_namespace(pkg)\n\nsphinx/directives/patches.py:15\n  /testbed/sphinx/directives/patches.py:15: DeprecationWarning: The `docutils.parsers.rst.directive.html` module will be removed in Docutils 2.0. Since Docutils 0.18, the \"Meta\" node is defined in `docutils.parsers.rst.directives.misc`.\n    from docutils.parsers.rst.directives import images, html, tables\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================== 39 passed, 7 warnings in 0.11s ========================\n\n",
          "test_files_run": [
            "tests/test_pycode_ast.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sphinx-doc__sphinx-8269",
      "repo": "sphinx-doc/sphinx",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 11.101893186569214,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 5,
          "failed": 1,
          "errors": 0,
          "collected": 6,
          "duration": 4.92,
          "log_tail": "tests/test_build_linkcheck.py::test_defaults\ntests/test_build_linkcheck.py::test_defaults_json\ntests/test_build_linkcheck.py::test_anchors_ignored\ntests/test_build_linkcheck.py::test_raises_for_invalid_status\ntests/test_build_linkcheck.py::test_auth\ntests/test_build_linkcheck.py::test_linkcheck_request_headers\n  /testbed/sphinx/transforms/post_transforms/code.py:96: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for lbnode in self.document.traverse(nodes.literal_block):  # type: nodes.literal_block\n\ntests/test_build_linkcheck.py::test_defaults\ntests/test_build_linkcheck.py::test_defaults_json\ntests/test_build_linkcheck.py::test_anchors_ignored\ntests/test_build_linkcheck.py::test_raises_for_invalid_status\ntests/test_build_linkcheck.py::test_auth\ntests/test_build_linkcheck.py::test_linkcheck_request_headers\n  /testbed/sphinx/transforms/post_transforms/code.py:100: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for dbnode in self.document.traverse(nodes.doctest_block):  # type: nodes.doctest_block\n\ntests/test_build_linkcheck.py::test_defaults\ntests/test_build_linkcheck.py::test_defaults_json\ntests/test_build_linkcheck.py::test_anchors_ignored\ntests/test_build_linkcheck.py::test_raises_for_invalid_status\ntests/test_build_linkcheck.py::test_auth\ntests/test_build_linkcheck.py::test_linkcheck_request_headers\n  /testbed/sphinx/environment/__init__.py:542: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for toctreenode in doctree.traverse(addnodes.toctree):\n\ntests/test_build_linkcheck.py::test_defaults\ntests/test_build_linkcheck.py::test_defaults_json\ntests/test_build_linkcheck.py::test_anchors_ignored\ntests/test_build_linkcheck.py::test_raises_for_invalid_status\ntests/test_build_linkcheck.py::test_auth\ntests/test_build_linkcheck.py::test_linkcheck_request_headers\n  /testbed/sphinx/builders/linkcheck.py:329: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for refnode in doctree.traverse(nodes.reference):\n\ntests/test_build_linkcheck.py::test_defaults\ntests/test_build_linkcheck.py::test_defaults_json\ntests/test_build_linkcheck.py::test_anchors_ignored\ntests/test_build_linkcheck.py::test_raises_for_invalid_status\ntests/test_build_linkcheck.py::test_auth\ntests/test_build_linkcheck.py::test_linkcheck_request_headers\n  /testbed/sphinx/builders/linkcheck.py:338: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for imgnode in doctree.traverse(nodes.image):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================== 1 failed, 5 passed, 229 warnings in 1.82s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/roots/test-linkcheck-localserver/conf.py tests/test_build_linkcheck.py` failed. (See above for error)",
          "test_files_run": [
            "tests/roots/test-linkcheck-localserver/conf.py",
            "tests/test_build_linkcheck.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 6,
          "failed": 0,
          "errors": 0,
          "collected": 6,
          "duration": 5.1,
          "log_tail": "\ntests/test_build_linkcheck.py::test_defaults\ntests/test_build_linkcheck.py::test_defaults_json\ntests/test_build_linkcheck.py::test_anchors_ignored\ntests/test_build_linkcheck.py::test_raises_for_invalid_status\ntests/test_build_linkcheck.py::test_auth\ntests/test_build_linkcheck.py::test_linkcheck_request_headers\n  /testbed/sphinx/transforms/post_transforms/code.py:96: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for lbnode in self.document.traverse(nodes.literal_block):  # type: nodes.literal_block\n\ntests/test_build_linkcheck.py::test_defaults\ntests/test_build_linkcheck.py::test_defaults_json\ntests/test_build_linkcheck.py::test_anchors_ignored\ntests/test_build_linkcheck.py::test_raises_for_invalid_status\ntests/test_build_linkcheck.py::test_auth\ntests/test_build_linkcheck.py::test_linkcheck_request_headers\n  /testbed/sphinx/transforms/post_transforms/code.py:100: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for dbnode in self.document.traverse(nodes.doctest_block):  # type: nodes.doctest_block\n\ntests/test_build_linkcheck.py::test_defaults\ntests/test_build_linkcheck.py::test_defaults_json\ntests/test_build_linkcheck.py::test_anchors_ignored\ntests/test_build_linkcheck.py::test_raises_for_invalid_status\ntests/test_build_linkcheck.py::test_auth\ntests/test_build_linkcheck.py::test_linkcheck_request_headers\n  /testbed/sphinx/environment/__init__.py:542: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for toctreenode in doctree.traverse(addnodes.toctree):\n\ntests/test_build_linkcheck.py::test_defaults\ntests/test_build_linkcheck.py::test_defaults_json\ntests/test_build_linkcheck.py::test_anchors_ignored\ntests/test_build_linkcheck.py::test_raises_for_invalid_status\ntests/test_build_linkcheck.py::test_auth\ntests/test_build_linkcheck.py::test_linkcheck_request_headers\n  /testbed/sphinx/builders/linkcheck.py:330: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for refnode in doctree.traverse(nodes.reference):\n\ntests/test_build_linkcheck.py::test_defaults\ntests/test_build_linkcheck.py::test_defaults_json\ntests/test_build_linkcheck.py::test_anchors_ignored\ntests/test_build_linkcheck.py::test_raises_for_invalid_status\ntests/test_build_linkcheck.py::test_auth\ntests/test_build_linkcheck.py::test_linkcheck_request_headers\n  /testbed/sphinx/builders/linkcheck.py:339: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for imgnode in doctree.traverse(nodes.image):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================= 6 passed, 229 warnings in 1.62s ========================\n\n",
          "test_files_run": [
            "tests/roots/test-linkcheck-localserver/conf.py",
            "tests/test_build_linkcheck.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sphinx-doc__sphinx-8459",
      "repo": "sphinx-doc/sphinx",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 10.81413722038269,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 17,
          "failed": 1,
          "errors": 0,
          "collected": 18,
          "duration": 5.02,
          "log_tail": "  /testbed/sphinx/transforms/post_transforms/images.py:33: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(nodes.image):\n\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_and_type_aliases\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_and_type_aliases\n  /testbed/sphinx/transforms/post_transforms/__init__.py:216: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(addnodes.desc_sig_element):\n\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_and_type_aliases\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_and_type_aliases\n  /testbed/sphinx/builders/latex/transforms.py:48: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(nodes.substitution_definition):\n\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_and_type_aliases\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_and_type_aliases\n  /testbed/sphinx/builders/latex/transforms.py:606: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(nodes.title):\n\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_and_type_aliases\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_and_type_aliases\n  /testbed/sphinx/transforms/post_transforms/code.py:43: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(addnodes.highlightlang):\n\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_and_type_aliases\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_and_type_aliases\n  /testbed/sphinx/transforms/post_transforms/code.py:95: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for lbnode in self.document.traverse(nodes.literal_block):  # type: nodes.literal_block\n\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_and_type_aliases\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_and_type_aliases\n  /testbed/sphinx/transforms/post_transforms/code.py:99: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for dbnode in self.document.traverse(nodes.doctest_block):  # type: nodes.doctest_block\n\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_and_type_aliases\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_and_type_aliases\n  /testbed/sphinx/environment/__init__.py:540: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for toctreenode in doctree.traverse(addnodes.toctree):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================== 1 failed, 17 passed, 134 warnings in 1.74s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_ext_autodoc_configs.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_ext_autodoc_configs.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 18,
          "failed": 0,
          "errors": 0,
          "collected": 18,
          "duration": 4.7,
          "log_tail": "tests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_and_type_aliases\n  /testbed/sphinx/transforms/post_transforms/images.py:33: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(nodes.image):\n\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_and_type_aliases\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_and_type_aliases\n  /testbed/sphinx/transforms/post_transforms/__init__.py:216: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(addnodes.desc_sig_element):\n\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_and_type_aliases\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_and_type_aliases\n  /testbed/sphinx/builders/latex/transforms.py:48: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(nodes.substitution_definition):\n\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_and_type_aliases\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_and_type_aliases\n  /testbed/sphinx/builders/latex/transforms.py:606: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(nodes.title):\n\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_and_type_aliases\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_and_type_aliases\n  /testbed/sphinx/transforms/post_transforms/code.py:43: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(addnodes.highlightlang):\n\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_and_type_aliases\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_and_type_aliases\n  /testbed/sphinx/transforms/post_transforms/code.py:95: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for lbnode in self.document.traverse(nodes.literal_block):  # type: nodes.literal_block\n\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_and_type_aliases\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_and_type_aliases\n  /testbed/sphinx/transforms/post_transforms/code.py:99: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for dbnode in self.document.traverse(nodes.doctest_block):  # type: nodes.doctest_block\n\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_and_type_aliases\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_and_type_aliases\n  /testbed/sphinx/environment/__init__.py:540: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for toctreenode in doctree.traverse(addnodes.toctree):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================= 18 passed, 134 warnings in 1.40s =======================\n\n",
          "test_files_run": [
            "tests/test_ext_autodoc_configs.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sphinx-doc__sphinx-8475",
      "repo": "sphinx-doc/sphinx",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 12.52176809310913,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 17,
          "failed": 1,
          "errors": 0,
          "collected": 18,
          "duration": 5.76,
          "log_tail": "\ntests/test_build_linkcheck.py: 18 warnings\n  /testbed/sphinx/util/nodes.py:598: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in document.traverse(addnodes.only):\n\ntests/test_build_linkcheck.py: 36 warnings\n  /testbed/sphinx/transforms/post_transforms/images.py:33: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(nodes.image):\n\ntests/test_build_linkcheck.py: 18 warnings\n  /testbed/sphinx/transforms/post_transforms/__init__.py:216: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(addnodes.desc_sig_element):\n\ntests/test_build_linkcheck.py: 18 warnings\n  /testbed/sphinx/builders/latex/transforms.py:48: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(nodes.substitution_definition):\n\ntests/test_build_linkcheck.py: 18 warnings\n  /testbed/sphinx/builders/latex/transforms.py:606: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(nodes.title):\n\ntests/test_build_linkcheck.py: 18 warnings\n  /testbed/sphinx/transforms/post_transforms/code.py:43: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(addnodes.highlightlang):\n\ntests/test_build_linkcheck.py: 18 warnings\n  /testbed/sphinx/transforms/post_transforms/code.py:95: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for lbnode in self.document.traverse(nodes.literal_block):  # type: nodes.literal_block\n\ntests/test_build_linkcheck.py: 18 warnings\n  /testbed/sphinx/transforms/post_transforms/code.py:99: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for dbnode in self.document.traverse(nodes.doctest_block):  # type: nodes.doctest_block\n\ntests/test_build_linkcheck.py: 18 warnings\n  /testbed/sphinx/environment/__init__.py:540: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for toctreenode in doctree.traverse(addnodes.toctree):\n\ntests/test_build_linkcheck.py: 18 warnings\n  /testbed/sphinx/builders/linkcheck.py:323: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for refnode in doctree.traverse(nodes.reference):\n\ntests/test_build_linkcheck.py: 18 warnings\n  /testbed/sphinx/builders/linkcheck.py:332: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for imgnode in doctree.traverse(nodes.image):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================== 1 failed, 17 passed, 673 warnings in 2.50s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_build_linkcheck.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_build_linkcheck.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 18,
          "failed": 0,
          "errors": 0,
          "collected": 18,
          "duration": 5.72,
          "log_tail": "    for node in self.document.traverse(addnodes.pending_xref):\n\ntests/test_build_linkcheck.py: 18 warnings\n  /testbed/sphinx/util/nodes.py:598: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in document.traverse(addnodes.only):\n\ntests/test_build_linkcheck.py: 36 warnings\n  /testbed/sphinx/transforms/post_transforms/images.py:33: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(nodes.image):\n\ntests/test_build_linkcheck.py: 18 warnings\n  /testbed/sphinx/transforms/post_transforms/__init__.py:216: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(addnodes.desc_sig_element):\n\ntests/test_build_linkcheck.py: 18 warnings\n  /testbed/sphinx/builders/latex/transforms.py:48: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(nodes.substitution_definition):\n\ntests/test_build_linkcheck.py: 18 warnings\n  /testbed/sphinx/builders/latex/transforms.py:606: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(nodes.title):\n\ntests/test_build_linkcheck.py: 18 warnings\n  /testbed/sphinx/transforms/post_transforms/code.py:43: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(addnodes.highlightlang):\n\ntests/test_build_linkcheck.py: 18 warnings\n  /testbed/sphinx/transforms/post_transforms/code.py:95: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for lbnode in self.document.traverse(nodes.literal_block):  # type: nodes.literal_block\n\ntests/test_build_linkcheck.py: 18 warnings\n  /testbed/sphinx/transforms/post_transforms/code.py:99: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for dbnode in self.document.traverse(nodes.doctest_block):  # type: nodes.doctest_block\n\ntests/test_build_linkcheck.py: 18 warnings\n  /testbed/sphinx/environment/__init__.py:540: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for toctreenode in doctree.traverse(addnodes.toctree):\n\ntests/test_build_linkcheck.py: 18 warnings\n  /testbed/sphinx/builders/linkcheck.py:323: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for refnode in doctree.traverse(nodes.reference):\n\ntests/test_build_linkcheck.py: 18 warnings\n  /testbed/sphinx/builders/linkcheck.py:332: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for imgnode in doctree.traverse(nodes.image):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================= 18 passed, 673 warnings in 2.17s =======================\n\n",
          "test_files_run": [
            "tests/test_build_linkcheck.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sphinx-doc__sphinx-8548",
      "repo": "sphinx-doc/sphinx",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 9.651249885559082,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 5,
          "failed": 1,
          "errors": 0,
          "collected": 6,
          "duration": 4.25,
          "log_tail": "_______________________ test_inherited_instance_variable _______________________\ntests/test_ext_autodoc_autoclass.py:83: in test_inherited_instance_variable\n    assert list(actual) == [\nE   AssertionError: assert ['', '.. py:c...r.attr2', ...] == ['', '.. py:c...r.attr1', ...]\nE     \nE     At index 5 diff: '   .. py:attribute:: Bar.attr2' != '   .. py:attribute:: Bar.attr1'\nE     Right contains 6 more items, first extra item: ''\nE     \nE     Full diff:\nE       [\nE           '',...\nE     \nE     ...Full output truncated (22 lines hidden), use '-vv' to show\n--------------------------- Captured stdout teardown ---------------------------\n# testroot: root\n# builder: html\n# srcdir: /tmp/pytest-of-root/pytest-0/ext-autodoc\n# outdir: /tmp/pytest-of-root/pytest-0/ext-autodoc/_build/html\n# status: \n\u001b[01mRunning Sphinx v3.4.0+/dd1615c59\u001b[39;49;00m\n\n# warning: \n\u001b[91mWARNING: while setting up extension sphinx.addnodes: node class 'meta' is already registered, its visitors will be overridden\u001b[39;49;00m\n\n=============================== warnings summary ===============================\nsphinx/util/docutils.py:45\n  /testbed/sphinx/util/docutils.py:45: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    __version_info__ = tuple(LooseVersion(docutils.__version__).version)\n\nsphinx/registry.py:22\n  /testbed/sphinx/registry.py:22: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    from pkg_resources import iter_entry_points\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n    declare_namespace(pkg)\n\nsphinx/directives/patches.py:14\n  /testbed/sphinx/directives/patches.py:14: DeprecationWarning: The `docutils.parsers.rst.directive.html` module will be removed in Docutils 2.0. Since Docutils 0.18, the \"Meta\" node is defined in `docutils.parsers.rst.directives.misc`.\n    from docutils.parsers.rst.directives import html, images, tables\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=================== 1 failed, 5 passed, 7 warnings in 1.04s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/roots/test-ext-autodoc/target/instance_variable.py tests/test_ext_autodoc_autoclass.py` failed. (See above for error)",
          "test_files_run": [
            "tests/roots/test-ext-autodoc/target/instance_variable.py",
            "tests/test_ext_autodoc_autoclass.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 6,
          "failed": 0,
          "errors": 0,
          "collected": 6,
          "duration": 4.38,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 6 items\n\ntests/test_ext_autodoc_autoclass.py::test_classes PASSED                 [ 16%]\ntests/test_ext_autodoc_autoclass.py::test_instance_variable PASSED       [ 33%]\ntests/test_ext_autodoc_autoclass.py::test_inherited_instance_variable PASSED [ 50%]\ntests/test_ext_autodoc_autoclass.py::test_decorators PASSED              [ 66%]\ntests/test_ext_autodoc_autoclass.py::test_slots_attribute PASSED         [ 83%]\ntests/test_ext_autodoc_autoclass.py::test_show_inheritance_for_subclass_of_generic_type PASSED [100%]\n\n=============================== warnings summary ===============================\nsphinx/util/docutils.py:45\n  /testbed/sphinx/util/docutils.py:45: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    __version_info__ = tuple(LooseVersion(docutils.__version__).version)\n\nsphinx/registry.py:22\n  /testbed/sphinx/registry.py:22: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    from pkg_resources import iter_entry_points\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n    declare_namespace(pkg)\n\nsphinx/directives/patches.py:14\n  /testbed/sphinx/directives/patches.py:14: DeprecationWarning: The `docutils.parsers.rst.directive.html` module will be removed in Docutils 2.0. Since Docutils 0.18, the \"Meta\" node is defined in `docutils.parsers.rst.directives.misc`.\n    from docutils.parsers.rst.directives import html, images, tables\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================== 6 passed, 7 warnings in 1.01s =========================\n\n",
          "test_files_run": [
            "tests/roots/test-ext-autodoc/target/instance_variable.py",
            "tests/test_ext_autodoc_autoclass.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sphinx-doc__sphinx-8551",
      "repo": "sphinx-doc/sphinx",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 12.088163137435913,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 32,
          "failed": 1,
          "errors": 0,
          "collected": 33,
          "duration": 5.61,
          "log_tail": "tests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  /testbed/sphinx/environment/adapters/toctree.py:326: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for toctreenode in doctree.traverse(addnodes.toctree):\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:215: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:238: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  <template>:33: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  <template>:224: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  <template>:386: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  <template>:401: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 29 warnings\n  /testbed/sphinx/ext/todo.py:97: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for todo in document.traverse(todo_node):\n\ntests/test_domain_py.py::test_warn_missing_reference\n  /testbed/sphinx/domains/std.py:756: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    toctree = next(iter(node.traverse(addnodes.toctree)), None)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================= 1 failed, 32 passed, 1244 warnings in 2.12s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_domain_py.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_domain_py.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 33,
          "failed": 0,
          "errors": 0,
          "collected": 33,
          "duration": 5.2,
          "log_tail": "tests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  /testbed/sphinx/environment/adapters/toctree.py:326: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for toctreenode in doctree.traverse(addnodes.toctree):\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:215: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:238: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  <template>:33: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  <template>:224: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  <template>:386: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  <template>:401: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 29 warnings\n  /testbed/sphinx/ext/todo.py:97: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for todo in document.traverse(todo_node):\n\ntests/test_domain_py.py::test_warn_missing_reference\n  /testbed/sphinx/domains/std.py:756: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    toctree = next(iter(node.traverse(addnodes.toctree)), None)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n====================== 33 passed, 1244 warnings in 1.58s =======================\n\n",
          "test_files_run": [
            "tests/test_domain_py.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sphinx-doc__sphinx-8593",
      "repo": "sphinx-doc/sphinx",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 9.875233888626099,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 1,
          "failed": 2,
          "errors": 0,
          "collected": 3,
          "duration": 4.64,
          "log_tail": "_____________________________ test_private_members _____________________________\ntests/test_ext_autodoc_private_members.py:92: in test_private_members\n    assert list(actual) == [\nE   AssertionError: assert ['', '.. py:m...private', ...] == ['', '.. py:m...private', ...]\nE     \nE     At index 4 diff: '.. py:data:: PRIVATE_CONSTANT' != '.. py:data:: _PUBLIC_CONSTANT'\nE     Left contains 7 more items, first extra item: '.. py:function:: _public_function(name)'\nE     \nE     Full diff:\nE       [\nE           '',...\nE     \nE     ...Full output truncated (25 lines hidden), use '-vv' to show\n--------------------------- Captured stdout teardown ---------------------------\n# testroot: root\n# builder: html\n# srcdir: /tmp/pytest-of-root/pytest-0/ext-autodoc\n# outdir: /tmp/pytest-of-root/pytest-0/ext-autodoc/_build/html\n# status: \n\u001b[01mRunning Sphinx v3.5.0+/07983a5a8\u001b[39;49;00m\n\n# warning: \n\u001b[91mWARNING: while setting up extension sphinx.addnodes: node class 'meta' is already registered, its visitors will be overridden\u001b[39;49;00m\n\n=============================== warnings summary ===============================\nsphinx/util/docutils.py:45\n  /testbed/sphinx/util/docutils.py:45: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    __version_info__ = tuple(LooseVersion(docutils.__version__).version)\n\nsphinx/registry.py:22\n  /testbed/sphinx/registry.py:22: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    from pkg_resources import iter_entry_points\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n    declare_namespace(pkg)\n\nsphinx/directives/patches.py:14\n  /testbed/sphinx/directives/patches.py:14: DeprecationWarning: The `docutils.parsers.rst.directive.html` module will be removed in Docutils 2.0. Since Docutils 0.18, the \"Meta\" node is defined in `docutils.parsers.rst.directives.misc`.\n    from docutils.parsers.rst.directives import html, images, tables\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=================== 2 failed, 1 passed, 7 warnings in 0.96s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/roots/test-ext-autodoc/target/private.py tests/test_ext_autodoc_private_members.py` failed. (See above for error)",
          "test_files_run": [
            "tests/roots/test-ext-autodoc/target/private.py",
            "tests/test_ext_autodoc_private_members.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 3,
          "failed": 0,
          "errors": 0,
          "collected": 3,
          "duration": 4.14,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 3 items\n\ntests/test_ext_autodoc_private_members.py::test_private_field PASSED     [ 33%]\ntests/test_ext_autodoc_private_members.py::test_private_field_and_private_members PASSED [ 66%]\ntests/test_ext_autodoc_private_members.py::test_private_members PASSED   [100%]\n\n=============================== warnings summary ===============================\nsphinx/util/docutils.py:45\n  /testbed/sphinx/util/docutils.py:45: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    __version_info__ = tuple(LooseVersion(docutils.__version__).version)\n\nsphinx/registry.py:22\n  /testbed/sphinx/registry.py:22: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    from pkg_resources import iter_entry_points\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n    declare_namespace(pkg)\n\nsphinx/directives/patches.py:14\n  /testbed/sphinx/directives/patches.py:14: DeprecationWarning: The `docutils.parsers.rst.directive.html` module will be removed in Docutils 2.0. Since Docutils 0.18, the \"Meta\" node is defined in `docutils.parsers.rst.directives.misc`.\n    from docutils.parsers.rst.directives import html, images, tables\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================== 3 passed, 7 warnings in 0.69s =========================\n\n",
          "test_files_run": [
            "tests/roots/test-ext-autodoc/target/private.py",
            "tests/test_ext_autodoc_private_members.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sphinx-doc__sphinx-8595",
      "repo": "sphinx-doc/sphinx",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 9.640594244003296,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 1,
          "errors": 0,
          "collected": 1,
          "duration": 4.45,
          "log_tail": "________________________________ test_empty_all ________________________________\ntests/test_ext_autodoc_automodule.py:21: in test_empty_all\n    assert list(actual) == [\nE   AssertionError: assert ['', '.. py:m..., '', '', ...] == ['', '.. py:m... module.', '']\nE     \nE     Left contains 18 more items, first extra item: ''\nE     \nE     Full diff:\nE       [\nE           '',\nE           '.. py:module:: target.empty_all',...\nE     \nE     ...Full output truncated (22 lines hidden), use '-vv' to show\n--------------------------- Captured stdout teardown ---------------------------\n# testroot: root\n# builder: html\n# srcdir: /tmp/pytest-of-root/pytest-0/ext-autodoc\n# outdir: /tmp/pytest-of-root/pytest-0/ext-autodoc/_build/html\n# status: \n\u001b[01mRunning Sphinx v3.5.0+/b19bce971\u001b[39;49;00m\n\n# warning: \n\u001b[91mWARNING: while setting up extension sphinx.addnodes: node class 'meta' is already registered, its visitors will be overridden\u001b[39;49;00m\n\n=============================== warnings summary ===============================\nsphinx/util/docutils.py:45\n  /testbed/sphinx/util/docutils.py:45: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    __version_info__ = tuple(LooseVersion(docutils.__version__).version)\n\nsphinx/registry.py:22\n  /testbed/sphinx/registry.py:22: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    from pkg_resources import iter_entry_points\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n    declare_namespace(pkg)\n\nsphinx/directives/patches.py:14\n  /testbed/sphinx/directives/patches.py:14: DeprecationWarning: The `docutils.parsers.rst.directive.html` module will be removed in Docutils 2.0. Since Docutils 0.18, the \"Meta\" node is defined in `docutils.parsers.rst.directives.misc`.\n    from docutils.parsers.rst.directives import html, images, tables\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================== 1 failed, 7 warnings in 0.78s =========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/roots/test-ext-autodoc/target/empty_all.py tests/test_ext_autodoc_automodule.py` failed. (See above for error)",
          "test_files_run": [
            "tests/roots/test-ext-autodoc/target/empty_all.py",
            "tests/test_ext_autodoc_automodule.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 1,
          "failed": 0,
          "errors": 0,
          "collected": 1,
          "duration": 4.22,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 1 item\n\ntests/test_ext_autodoc_automodule.py::test_empty_all PASSED              [100%]\n\n=============================== warnings summary ===============================\nsphinx/util/docutils.py:45\n  /testbed/sphinx/util/docutils.py:45: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    __version_info__ = tuple(LooseVersion(docutils.__version__).version)\n\nsphinx/registry.py:22\n  /testbed/sphinx/registry.py:22: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    from pkg_resources import iter_entry_points\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n    declare_namespace(pkg)\n\nsphinx/directives/patches.py:14\n  /testbed/sphinx/directives/patches.py:14: DeprecationWarning: The `docutils.parsers.rst.directive.html` module will be removed in Docutils 2.0. Since Docutils 0.18, the \"Meta\" node is defined in `docutils.parsers.rst.directives.misc`.\n    from docutils.parsers.rst.directives import html, images, tables\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================== 1 passed, 7 warnings in 0.68s =========================\n\n",
          "test_files_run": [
            "tests/roots/test-ext-autodoc/target/empty_all.py",
            "tests/test_ext_autodoc_automodule.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sphinx-doc__sphinx-8621",
      "repo": "sphinx-doc/sphinx",
      "valid": false,
      "worker": "http://34.44.241.183:8080",
      "duration": 11.502208709716797,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 31,
          "failed": 4,
          "errors": 0,
          "collected": 35,
          "duration": 5.9,
          "log_tail": "tests/test_markup.py::test_rst_prolog\ntests/test_markup.py::test_rst_prolog\ntests/test_markup.py::test_keep_warnings_is_True\ntests/test_markup.py::test_keep_warnings_is_False\ntests/test_markup.py::test_compact_refonly_bullet_list\ntests/test_markup.py::test_default_role1\ntests/test_markup.py::test_default_role1\ntests/test_markup.py::test_default_role2\ntests/test_markup.py::test_default_role2\n  /testbed/sphinx/builders/latex/transforms.py:608: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for i, index in enumerate(node.traverse(addnodes.index)):\n\ntests/test_markup.py: 10 warnings\n  /testbed/sphinx/transforms/post_transforms/code.py:43: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(addnodes.highlightlang):\n\ntests/test_markup.py: 10 warnings\n  /testbed/sphinx/transforms/post_transforms/code.py:95: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for lbnode in self.document.traverse(nodes.literal_block):  # type: nodes.literal_block\n\ntests/test_markup.py: 10 warnings\n  /testbed/sphinx/transforms/post_transforms/code.py:99: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for dbnode in self.document.traverse(nodes.doctest_block):  # type: nodes.doctest_block\n\ntests/test_markup.py: 10 warnings\n  /testbed/sphinx/environment/__init__.py:540: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for toctreenode in doctree.traverse(addnodes.toctree):\n\ntests/test_markup.py::test_rst_prolog\ntests/test_markup.py::test_rst_prolog\n  /testbed/sphinx/environment/adapters/toctree.py:203: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for subtocnode in toc.traverse(addnodes.toctree):\n\ntests/test_markup.py::test_rst_prolog\n  /testbed/sphinx/environment/adapters/toctree.py:261: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for refnode in newnode.traverse(nodes.reference):\n\ntests/test_markup.py::test_compact_refonly_bullet_list\n  /testbed/sphinx/transforms/compact_bullet_list.py:77: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(nodes.bullet_list):\n\ntests/test_markup.py::test_compact_refonly_bullet_list\n  /testbed/sphinx/transforms/compact_bullet_list.py:79: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for item in node.traverse(nodes.list_item):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================= 4 failed, 31 passed, 3175 warnings in 1.89s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_markup.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_markup.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 33,
          "failed": 2,
          "errors": 0,
          "collected": 35,
          "duration": 4.61,
          "log_tail": "tests/test_markup.py::test_rst_prolog\ntests/test_markup.py::test_rst_prolog\ntests/test_markup.py::test_keep_warnings_is_True\ntests/test_markup.py::test_keep_warnings_is_False\ntests/test_markup.py::test_compact_refonly_bullet_list\ntests/test_markup.py::test_default_role1\ntests/test_markup.py::test_default_role1\ntests/test_markup.py::test_default_role2\ntests/test_markup.py::test_default_role2\n  /testbed/sphinx/builders/latex/transforms.py:608: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for i, index in enumerate(node.traverse(addnodes.index)):\n\ntests/test_markup.py: 10 warnings\n  /testbed/sphinx/transforms/post_transforms/code.py:43: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(addnodes.highlightlang):\n\ntests/test_markup.py: 10 warnings\n  /testbed/sphinx/transforms/post_transforms/code.py:95: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for lbnode in self.document.traverse(nodes.literal_block):  # type: nodes.literal_block\n\ntests/test_markup.py: 10 warnings\n  /testbed/sphinx/transforms/post_transforms/code.py:99: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for dbnode in self.document.traverse(nodes.doctest_block):  # type: nodes.doctest_block\n\ntests/test_markup.py: 10 warnings\n  /testbed/sphinx/environment/__init__.py:540: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for toctreenode in doctree.traverse(addnodes.toctree):\n\ntests/test_markup.py::test_rst_prolog\ntests/test_markup.py::test_rst_prolog\n  /testbed/sphinx/environment/adapters/toctree.py:203: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for subtocnode in toc.traverse(addnodes.toctree):\n\ntests/test_markup.py::test_rst_prolog\n  /testbed/sphinx/environment/adapters/toctree.py:261: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for refnode in newnode.traverse(nodes.reference):\n\ntests/test_markup.py::test_compact_refonly_bullet_list\n  /testbed/sphinx/transforms/compact_bullet_list.py:77: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(nodes.bullet_list):\n\ntests/test_markup.py::test_compact_refonly_bullet_list\n  /testbed/sphinx/transforms/compact_bullet_list.py:79: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for item in node.traverse(nodes.list_item):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================= 2 failed, 33 passed, 3177 warnings in 1.43s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_markup.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_markup.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sphinx-doc__sphinx-8638",
      "repo": "sphinx-doc/sphinx",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 11.28925895690918,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 34,
          "failed": 1,
          "errors": 0,
          "collected": 35,
          "duration": 5.5,
          "log_tail": "tests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  /testbed/sphinx/environment/adapters/toctree.py:325: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for toctreenode in doctree.traverse(addnodes.toctree):\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:215: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:238: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  <template>:33: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  <template>:224: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  <template>:386: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  <template>:401: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 31 warnings\n  /testbed/sphinx/ext/todo.py:94: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for todo in document.traverse(todo_node):\n\ntests/test_domain_py.py::test_warn_missing_reference\n  /testbed/sphinx/domains/std.py:741: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    toctree = next(iter(node.traverse(addnodes.toctree)), None)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================= 1 failed, 34 passed, 1255 warnings in 1.98s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_domain_py.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_domain_py.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 35,
          "failed": 0,
          "errors": 0,
          "collected": 35,
          "duration": 4.78,
          "log_tail": "tests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  /testbed/sphinx/environment/adapters/toctree.py:325: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for toctreenode in doctree.traverse(addnodes.toctree):\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:215: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:238: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  <template>:33: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  <template>:224: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  <template>:386: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_resolve_xref_for_properties\n  <template>:401: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 31 warnings\n  /testbed/sphinx/ext/todo.py:94: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for todo in document.traverse(todo_node):\n\ntests/test_domain_py.py::test_warn_missing_reference\n  /testbed/sphinx/domains/std.py:741: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    toctree = next(iter(node.traverse(addnodes.toctree)), None)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n====================== 35 passed, 1255 warnings in 1.54s =======================\n\n",
          "test_files_run": [
            "tests/test_domain_py.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sphinx-doc__sphinx-8721",
      "repo": "sphinx-doc/sphinx",
      "valid": false,
      "worker": "http://34.44.241.183:8080",
      "duration": 11.766630172729492,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 3,
          "failed": 2,
          "errors": 0,
          "collected": 5,
          "duration": 5.84,
          "log_tail": "tests/test_ext_viewcode.py::test_linkcode\ntests/test_ext_viewcode.py::test_local_source_files\n  <template>:401: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_ext_viewcode.py: 10 warnings\n  /testbed/sphinx/util/nodes.py:350: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for img in node.traverse(nodes.image):\n\ntests/test_ext_viewcode.py: 10 warnings\n  /testbed/sphinx/util/nodes.py:352: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for raw in node.traverse(nodes.raw):\n\ntests/test_ext_viewcode.py::test_viewcode_epub_default\ntests/test_ext_viewcode.py::test_viewcode_epub_default\ntests/test_ext_viewcode.py::test_viewcode_epub_enabled\ntests/test_ext_viewcode.py::test_viewcode_epub_enabled\n  /testbed/sphinx/builders/_epub_base.py:275: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for reference in tree.traverse(nodes.reference):\n\ntests/test_ext_viewcode.py::test_viewcode_epub_default\ntests/test_ext_viewcode.py::test_viewcode_epub_default\ntests/test_ext_viewcode.py::test_viewcode_epub_enabled\ntests/test_ext_viewcode.py::test_viewcode_epub_enabled\n  /testbed/sphinx/builders/_epub_base.py:283: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for target in tree.traverse(nodes.target):\n\ntests/test_ext_viewcode.py::test_viewcode_epub_default\ntests/test_ext_viewcode.py::test_viewcode_epub_default\ntests/test_ext_viewcode.py::test_viewcode_epub_enabled\ntests/test_ext_viewcode.py::test_viewcode_epub_enabled\n  /testbed/sphinx/builders/_epub_base.py:290: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for desc_signature in tree.traverse(addnodes.desc_signature):\n\ntests/test_ext_viewcode.py::test_viewcode_epub_default\ntests/test_ext_viewcode.py::test_viewcode_epub_default\ntests/test_ext_viewcode.py::test_viewcode_epub_enabled\ntests/test_ext_viewcode.py::test_viewcode_epub_enabled\n  /testbed/sphinx/builders/_epub_base.py:340: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in tree.traverse(nodes.reference):\n\ntests/test_ext_viewcode.py::test_linkcode\ntests/test_ext_viewcode.py::test_linkcode\n  /testbed/sphinx/ext/linkcode.py:42: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for objnode in doctree.traverse(addnodes.desc):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================== 2 failed, 3 passed, 999 warnings in 2.00s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_ext_viewcode.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_ext_viewcode.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 4,
          "failed": 1,
          "errors": 0,
          "collected": 5,
          "duration": 4.94,
          "log_tail": "tests/test_ext_viewcode.py::test_linkcode\ntests/test_ext_viewcode.py::test_local_source_files\n  <template>:401: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_ext_viewcode.py: 10 warnings\n  /testbed/sphinx/util/nodes.py:350: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for img in node.traverse(nodes.image):\n\ntests/test_ext_viewcode.py: 10 warnings\n  /testbed/sphinx/util/nodes.py:352: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for raw in node.traverse(nodes.raw):\n\ntests/test_ext_viewcode.py::test_viewcode_epub_default\ntests/test_ext_viewcode.py::test_viewcode_epub_default\ntests/test_ext_viewcode.py::test_viewcode_epub_enabled\ntests/test_ext_viewcode.py::test_viewcode_epub_enabled\n  /testbed/sphinx/builders/_epub_base.py:275: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for reference in tree.traverse(nodes.reference):\n\ntests/test_ext_viewcode.py::test_viewcode_epub_default\ntests/test_ext_viewcode.py::test_viewcode_epub_default\ntests/test_ext_viewcode.py::test_viewcode_epub_enabled\ntests/test_ext_viewcode.py::test_viewcode_epub_enabled\n  /testbed/sphinx/builders/_epub_base.py:283: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for target in tree.traverse(nodes.target):\n\ntests/test_ext_viewcode.py::test_viewcode_epub_default\ntests/test_ext_viewcode.py::test_viewcode_epub_default\ntests/test_ext_viewcode.py::test_viewcode_epub_enabled\ntests/test_ext_viewcode.py::test_viewcode_epub_enabled\n  /testbed/sphinx/builders/_epub_base.py:290: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for desc_signature in tree.traverse(addnodes.desc_signature):\n\ntests/test_ext_viewcode.py::test_viewcode_epub_default\ntests/test_ext_viewcode.py::test_viewcode_epub_default\ntests/test_ext_viewcode.py::test_viewcode_epub_enabled\ntests/test_ext_viewcode.py::test_viewcode_epub_enabled\n  /testbed/sphinx/builders/_epub_base.py:340: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in tree.traverse(nodes.reference):\n\ntests/test_ext_viewcode.py::test_linkcode\ntests/test_ext_viewcode.py::test_linkcode\n  /testbed/sphinx/ext/linkcode.py:42: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for objnode in doctree.traverse(addnodes.desc):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================== 1 failed, 4 passed, 999 warnings in 1.68s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_ext_viewcode.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_ext_viewcode.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sphinx-doc__sphinx-9229",
      "repo": "sphinx-doc/sphinx",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 10.495961904525757,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 13,
          "failed": 1,
          "errors": 0,
          "collected": 14,
          "duration": 4.81,
          "log_tail": "=================================== FAILURES ===================================\n______________________ test_class_alias_having_doccomment ______________________\ntests/test_ext_autodoc_autoclass.py:334: in test_class_alias_having_doccomment\n    assert list(actual) == [\nE   AssertionError: assert ['', '.. py:a...ing', '', ...] == ['', '.. py:a...ocstring', '']\nE     \nE     Left contains one more item: '   alias of :class:`target.classes.Bar`'\nE     \nE     Full diff:\nE       [\nE           '',\nE           '.. py:attribute:: OtherAlias',...\nE     \nE     ...Full output truncated (6 lines hidden), use '-vv' to show\n--------------------------- Captured stdout teardown ---------------------------\n# testroot: root\n# builder: html\n# srcdir: /tmp/pytest-of-root/pytest-0/root\n# outdir: /tmp/pytest-of-root/pytest-0/root/_build/html\n# status: \n\u001b[01mRunning Sphinx v4.1.0\u001b[39;49;00m\n\n# warning: \n\n=============================== warnings summary ===============================\nsphinx/util/docutils.py:44\n  /testbed/sphinx/util/docutils.py:44: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    __version_info__ = tuple(LooseVersion(docutils.__version__).version)\n\nsphinx/highlighting.py:67\n  /testbed/sphinx/highlighting.py:67: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if tuple(LooseVersion(pygmentsversion).version) <= (2, 7, 4):\n\nsphinx/registry.py:24\n  /testbed/sphinx/registry.py:24: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    from pkg_resources import iter_entry_points\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n    declare_namespace(pkg)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=================== 1 failed, 13 passed, 7 warnings in 1.32s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/roots/test-ext-autodoc/target/classes.py tests/test_ext_autodoc_autoclass.py` failed. (See above for error)",
          "test_files_run": [
            "tests/roots/test-ext-autodoc/target/classes.py",
            "tests/test_ext_autodoc_autoclass.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 14,
          "failed": 0,
          "errors": 0,
          "collected": 14,
          "duration": 4.47,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 14 items\n\ntests/test_ext_autodoc_autoclass.py::test_classes PASSED                 [  7%]\ntests/test_ext_autodoc_autoclass.py::test_instance_variable PASSED       [ 14%]\ntests/test_ext_autodoc_autoclass.py::test_inherited_instance_variable PASSED [ 21%]\ntests/test_ext_autodoc_autoclass.py::test_uninitialized_attributes PASSED [ 28%]\ntests/test_ext_autodoc_autoclass.py::test_undocumented_uninitialized_attributes PASSED [ 35%]\ntests/test_ext_autodoc_autoclass.py::test_decorators PASSED              [ 42%]\ntests/test_ext_autodoc_autoclass.py::test_properties PASSED              [ 50%]\ntests/test_ext_autodoc_autoclass.py::test_slots_attribute PASSED         [ 57%]\ntests/test_ext_autodoc_autoclass.py::test_show_inheritance_for_subclass_of_generic_type PASSED [ 64%]\ntests/test_ext_autodoc_autoclass.py::test_class_doc_from_class PASSED    [ 71%]\ntests/test_ext_autodoc_autoclass.py::test_class_doc_from_init PASSED     [ 78%]\ntests/test_ext_autodoc_autoclass.py::test_class_doc_from_both PASSED     [ 85%]\ntests/test_ext_autodoc_autoclass.py::test_class_alias PASSED             [ 92%]\ntests/test_ext_autodoc_autoclass.py::test_class_alias_having_doccomment PASSED [100%]\n\n=============================== warnings summary ===============================\nsphinx/util/docutils.py:44\n  /testbed/sphinx/util/docutils.py:44: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    __version_info__ = tuple(LooseVersion(docutils.__version__).version)\n\nsphinx/highlighting.py:67\n  /testbed/sphinx/highlighting.py:67: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if tuple(LooseVersion(pygmentsversion).version) <= (2, 7, 4):\n\nsphinx/registry.py:24\n  /testbed/sphinx/registry.py:24: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    from pkg_resources import iter_entry_points\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n    declare_namespace(pkg)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================== 14 passed, 7 warnings in 1.06s ========================\n\n",
          "test_files_run": [
            "tests/roots/test-ext-autodoc/target/classes.py",
            "tests/test_ext_autodoc_autoclass.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sphinx-doc__sphinx-9230",
      "repo": "sphinx-doc/sphinx",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 12.85576605796814,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 44,
          "failed": 1,
          "errors": 0,
          "collected": 45,
          "duration": 6.56,
          "log_tail": "\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:114: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n    _gaq.push(['_setAllowLinker', true]);\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:70: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:99: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:215: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:238: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:33: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:224: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:386: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:401: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================== 1 failed, 44 passed, 192 warnings in 3.17s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_domain_py.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_domain_py.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 45,
          "failed": 0,
          "errors": 0,
          "collected": 45,
          "duration": 5.34,
          "log_tail": "    declare_namespace(pkg)\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:114: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n    _gaq.push(['_setAllowLinker', true]);\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:70: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:99: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:215: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:238: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:33: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:224: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:386: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:401: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================= 45 passed, 192 warnings in 2.38s =======================\n\n",
          "test_files_run": [
            "tests/test_domain_py.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sphinx-doc__sphinx-9258",
      "repo": "sphinx-doc/sphinx",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 12.955365657806396,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 45,
          "failed": 1,
          "errors": 0,
          "collected": 46,
          "duration": 6.72,
          "log_tail": "\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:114: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n    _gaq.push(['_setAllowLinker', true]);\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:70: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:99: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:215: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:238: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:33: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:224: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:386: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:401: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================== 1 failed, 45 passed, 192 warnings in 3.11s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_domain_py.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_domain_py.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 46,
          "failed": 0,
          "errors": 0,
          "collected": 46,
          "duration": 5.27,
          "log_tail": "    declare_namespace(pkg)\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:114: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n    _gaq.push(['_setAllowLinker', true]);\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:70: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:99: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:215: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:238: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:33: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:224: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:386: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:401: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================= 46 passed, 192 warnings in 2.37s =======================\n\n",
          "test_files_run": [
            "tests/test_domain_py.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sphinx-doc__sphinx-9281",
      "repo": "sphinx-doc/sphinx",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 9.816221952438354,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 38,
          "failed": 1,
          "errors": 0,
          "collected": 39,
          "duration": 4.46,
          "log_tail": "tests/test_util_inspect.py::test_object_description_enum FAILED          [ 66%]\ntests/test_util_inspect.py::test_getslots PASSED                         [ 69%]\ntests/test_util_inspect.py::test_isclassmethod PASSED                    [ 71%]\ntests/test_util_inspect.py::test_isstaticmethod PASSED                   [ 74%]\ntests/test_util_inspect.py::test_iscoroutinefunction PASSED              [ 76%]\ntests/test_util_inspect.py::test_isfunction PASSED                       [ 79%]\ntests/test_util_inspect.py::test_isbuiltin PASSED                        [ 82%]\ntests/test_util_inspect.py::test_isdescriptor PASSED                     [ 84%]\ntests/test_util_inspect.py::test_isattributedescriptor PASSED            [ 87%]\ntests/test_util_inspect.py::test_isproperty PASSED                       [ 89%]\ntests/test_util_inspect.py::test_isgenericalias PASSED                   [ 92%]\ntests/test_util_inspect.py::test_unpartial PASSED                        [ 94%]\ntests/test_util_inspect.py::test_getdoc_inherited_decorated_method PASSED [ 97%]\ntests/test_util_inspect.py::test_is_builtin_class_method PASSED          [100%]\n\n=================================== FAILURES ===================================\n_________________________ test_object_description_enum _________________________\ntests/test_util_inspect.py:525: in test_object_description_enum\n    assert inspect.object_description(MyEnum.FOO) == \"MyEnum.FOO\"\nE   AssertionError: assert '<MyEnum.FOO: 1>' == 'MyEnum.FOO'\nE     \nE     - MyEnum.FOO\nE     + <MyEnum.FOO: 1>\nE     ? +          ++++\n=============================== warnings summary ===============================\nsphinx/util/docutils.py:44\n  /testbed/sphinx/util/docutils.py:44: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    __version_info__ = tuple(LooseVersion(docutils.__version__).version)\n\nsphinx/highlighting.py:67\n  /testbed/sphinx/highlighting.py:67: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if tuple(LooseVersion(pygmentsversion).version) <= (2, 7, 4):\n\nsphinx/registry.py:24\n  /testbed/sphinx/registry.py:24: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    from pkg_resources import iter_entry_points\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n    declare_namespace(pkg)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=================== 1 failed, 38 passed, 7 warnings in 0.94s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_util_inspect.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_util_inspect.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 39,
          "failed": 0,
          "errors": 0,
          "collected": 39,
          "duration": 4.17,
          "log_tail": "tests/test_util_inspect.py::test_safe_getattr_with_default PASSED        [ 41%]\ntests/test_util_inspect.py::test_safe_getattr_with_exception PASSED      [ 43%]\ntests/test_util_inspect.py::test_safe_getattr_with_property_exception PASSED [ 46%]\ntests/test_util_inspect.py::test_safe_getattr_with___dict___override PASSED [ 48%]\ntests/test_util_inspect.py::test_dictionary_sorting PASSED               [ 51%]\ntests/test_util_inspect.py::test_set_sorting PASSED                      [ 53%]\ntests/test_util_inspect.py::test_set_sorting_fallback PASSED             [ 56%]\ntests/test_util_inspect.py::test_frozenset_sorting PASSED                [ 58%]\ntests/test_util_inspect.py::test_frozenset_sorting_fallback PASSED       [ 61%]\ntests/test_util_inspect.py::test_dict_customtype PASSED                  [ 64%]\ntests/test_util_inspect.py::test_object_description_enum PASSED          [ 66%]\ntests/test_util_inspect.py::test_getslots PASSED                         [ 69%]\ntests/test_util_inspect.py::test_isclassmethod PASSED                    [ 71%]\ntests/test_util_inspect.py::test_isstaticmethod PASSED                   [ 74%]\ntests/test_util_inspect.py::test_iscoroutinefunction PASSED              [ 76%]\ntests/test_util_inspect.py::test_isfunction PASSED                       [ 79%]\ntests/test_util_inspect.py::test_isbuiltin PASSED                        [ 82%]\ntests/test_util_inspect.py::test_isdescriptor PASSED                     [ 84%]\ntests/test_util_inspect.py::test_isattributedescriptor PASSED            [ 87%]\ntests/test_util_inspect.py::test_isproperty PASSED                       [ 89%]\ntests/test_util_inspect.py::test_isgenericalias PASSED                   [ 92%]\ntests/test_util_inspect.py::test_unpartial PASSED                        [ 94%]\ntests/test_util_inspect.py::test_getdoc_inherited_decorated_method PASSED [ 97%]\ntests/test_util_inspect.py::test_is_builtin_class_method PASSED          [100%]\n\n=============================== warnings summary ===============================\nsphinx/util/docutils.py:44\n  /testbed/sphinx/util/docutils.py:44: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    __version_info__ = tuple(LooseVersion(docutils.__version__).version)\n\nsphinx/highlighting.py:67\n  /testbed/sphinx/highlighting.py:67: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if tuple(LooseVersion(pygmentsversion).version) <= (2, 7, 4):\n\nsphinx/registry.py:24\n  /testbed/sphinx/registry.py:24: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    from pkg_resources import iter_entry_points\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n    declare_namespace(pkg)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================== 39 passed, 7 warnings in 0.80s ========================\n\n",
          "test_files_run": [
            "tests/test_util_inspect.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sphinx-doc__sphinx-9320",
      "repo": "sphinx-doc/sphinx",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 9.40014386177063,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 9,
          "failed": 1,
          "errors": 0,
          "collected": 10,
          "duration": 4.34,
          "log_tail": "../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n    declare_namespace(pkg)\n\ntests/test_quickstart.py::test_quickstart_and_build\ntests/test_quickstart.py::test_quickstart_and_build\ntests/test_quickstart.py::test_quickstart_and_build\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:114: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n    _gaq.push(['_setAllowLinker', true]);\n\ntests/test_quickstart.py::test_quickstart_and_build\ntests/test_quickstart.py::test_quickstart_and_build\ntests/test_quickstart.py::test_quickstart_and_build\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:70: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_quickstart.py::test_quickstart_and_build\ntests/test_quickstart.py::test_quickstart_and_build\ntests/test_quickstart.py::test_quickstart_and_build\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:99: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_quickstart.py::test_quickstart_and_build\ntests/test_quickstart.py::test_quickstart_and_build\ntests/test_quickstart.py::test_quickstart_and_build\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:215: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_quickstart.py::test_quickstart_and_build\ntests/test_quickstart.py::test_quickstart_and_build\ntests/test_quickstart.py::test_quickstart_and_build\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:238: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_quickstart.py::test_quickstart_and_build\n  <template>:33: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_quickstart.py::test_quickstart_and_build\n  <template>:224: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_quickstart.py::test_quickstart_and_build\n  <template>:386: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_quickstart.py::test_quickstart_and_build\n  <template>:401: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=================== 1 failed, 9 passed, 26 warnings in 0.85s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_quickstart.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_quickstart.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 10,
          "failed": 0,
          "errors": 0,
          "collected": 10,
          "duration": 3.91,
          "log_tail": "../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n    declare_namespace(pkg)\n\ntests/test_quickstart.py::test_quickstart_and_build\ntests/test_quickstart.py::test_quickstart_and_build\ntests/test_quickstart.py::test_quickstart_and_build\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:114: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n    _gaq.push(['_setAllowLinker', true]);\n\ntests/test_quickstart.py::test_quickstart_and_build\ntests/test_quickstart.py::test_quickstart_and_build\ntests/test_quickstart.py::test_quickstart_and_build\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:70: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_quickstart.py::test_quickstart_and_build\ntests/test_quickstart.py::test_quickstart_and_build\ntests/test_quickstart.py::test_quickstart_and_build\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:99: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_quickstart.py::test_quickstart_and_build\ntests/test_quickstart.py::test_quickstart_and_build\ntests/test_quickstart.py::test_quickstart_and_build\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:215: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_quickstart.py::test_quickstart_and_build\ntests/test_quickstart.py::test_quickstart_and_build\ntests/test_quickstart.py::test_quickstart_and_build\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:238: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_quickstart.py::test_quickstart_and_build\n  <template>:33: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_quickstart.py::test_quickstart_and_build\n  <template>:224: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_quickstart.py::test_quickstart_and_build\n  <template>:386: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_quickstart.py::test_quickstart_and_build\n  <template>:401: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================= 10 passed, 26 warnings in 0.68s ========================\n\n",
          "test_files_run": [
            "tests/test_quickstart.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sphinx-doc__sphinx-9367",
      "repo": "sphinx-doc/sphinx",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 8.31068205833435,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 41,
          "failed": 1,
          "errors": 0,
          "collected": 42,
          "duration": 3.72,
          "log_tail": "tests/test_pycode_ast.py::test_unparse[a >> b-a >> b] PASSED             [ 69%]\ntests/test_pycode_ast.py::test_unparse[{1, 2, 3}-{1, 2, 3}] PASSED       [ 71%]\ntests/test_pycode_ast.py::test_unparse[a - b-a - b] PASSED               [ 73%]\ntests/test_pycode_ast.py::test_unparse['str'-'str'] PASSED               [ 76%]\ntests/test_pycode_ast.py::test_unparse[+ a-+ a] PASSED                   [ 78%]\ntests/test_pycode_ast.py::test_unparse[- 1-- 1] PASSED                   [ 80%]\ntests/test_pycode_ast.py::test_unparse[- a-- a] PASSED                   [ 83%]\ntests/test_pycode_ast.py::test_unparse[(1, 2, 3)-(1, 2, 3)] PASSED       [ 85%]\ntests/test_pycode_ast.py::test_unparse[()-()] PASSED                     [ 88%]\ntests/test_pycode_ast.py::test_unparse[(1,)-(1,)] FAILED                 [ 90%]\ntests/test_pycode_ast.py::test_unparse_None PASSED                       [ 92%]\ntests/test_pycode_ast.py::test_unparse_py38[lambda x=0, /, y=1, *args, z, **kwargs: x + y + z-lambda x=0, /, y=1, *args, z, **kwargs: ...] PASSED [ 95%]\ntests/test_pycode_ast.py::test_unparse_py38[0x1234-0x1234] PASSED        [ 97%]\ntests/test_pycode_ast.py::test_unparse_py38[1_000_000-1_000_000] PASSED  [100%]\n\n=================================== FAILURES ===================================\n___________________________ test_unparse[(1,)-(1,)] ____________________________\ntests/test_pycode_ast.py:62: in test_unparse\n    assert ast.unparse(module.body[0].value, source) == expected\nE   AssertionError: assert '(1)' == '(1,)'\nE     \nE     - (1,)\nE     ?   -\nE     + (1)\n=============================== warnings summary ===============================\nsphinx/util/docutils.py:44\n  /testbed/sphinx/util/docutils.py:44: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    __version_info__ = tuple(LooseVersion(docutils.__version__).version)\n\nsphinx/highlighting.py:67\n  /testbed/sphinx/highlighting.py:67: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if tuple(LooseVersion(pygmentsversion).version) <= (2, 7, 4):\n\nsphinx/registry.py:24\n  /testbed/sphinx/registry.py:24: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    from pkg_resources import iter_entry_points\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n    declare_namespace(pkg)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=================== 1 failed, 41 passed, 7 warnings in 0.20s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_pycode_ast.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_pycode_ast.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 42,
          "failed": 0,
          "errors": 0,
          "collected": 42,
          "duration": 3.31,
          "log_tail": "tests/test_pycode_ast.py::test_unparse[[1, 2, 3]-[1, 2, 3]] PASSED       [ 45%]\ntests/test_pycode_ast.py::test_unparse[a << b-a << b] PASSED             [ 47%]\ntests/test_pycode_ast.py::test_unparse[a @ b-a @ b] PASSED               [ 50%]\ntests/test_pycode_ast.py::test_unparse[a % b-a % b] PASSED               [ 52%]\ntests/test_pycode_ast.py::test_unparse[a * b-a * b] PASSED               [ 54%]\ntests/test_pycode_ast.py::test_unparse[sys-sys] PASSED                   [ 57%]\ntests/test_pycode_ast.py::test_unparse[1234-1234_1] PASSED               [ 59%]\ntests/test_pycode_ast.py::test_unparse[not a-not a] PASSED               [ 61%]\ntests/test_pycode_ast.py::test_unparse[a or b-a or b] PASSED             [ 64%]\ntests/test_pycode_ast.py::test_unparse[a ** b-a ** b] PASSED             [ 66%]\ntests/test_pycode_ast.py::test_unparse[a >> b-a >> b] PASSED             [ 69%]\ntests/test_pycode_ast.py::test_unparse[{1, 2, 3}-{1, 2, 3}] PASSED       [ 71%]\ntests/test_pycode_ast.py::test_unparse[a - b-a - b] PASSED               [ 73%]\ntests/test_pycode_ast.py::test_unparse['str'-'str'] PASSED               [ 76%]\ntests/test_pycode_ast.py::test_unparse[+ a-+ a] PASSED                   [ 78%]\ntests/test_pycode_ast.py::test_unparse[- 1-- 1] PASSED                   [ 80%]\ntests/test_pycode_ast.py::test_unparse[- a-- a] PASSED                   [ 83%]\ntests/test_pycode_ast.py::test_unparse[(1, 2, 3)-(1, 2, 3)] PASSED       [ 85%]\ntests/test_pycode_ast.py::test_unparse[()-()] PASSED                     [ 88%]\ntests/test_pycode_ast.py::test_unparse[(1,)-(1,)] PASSED                 [ 90%]\ntests/test_pycode_ast.py::test_unparse_None PASSED                       [ 92%]\ntests/test_pycode_ast.py::test_unparse_py38[lambda x=0, /, y=1, *args, z, **kwargs: x + y + z-lambda x=0, /, y=1, *args, z, **kwargs: ...] PASSED [ 95%]\ntests/test_pycode_ast.py::test_unparse_py38[0x1234-0x1234] PASSED        [ 97%]\ntests/test_pycode_ast.py::test_unparse_py38[1_000_000-1_000_000] PASSED  [100%]\n\n=============================== warnings summary ===============================\nsphinx/util/docutils.py:44\n  /testbed/sphinx/util/docutils.py:44: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    __version_info__ = tuple(LooseVersion(docutils.__version__).version)\n\nsphinx/highlighting.py:67\n  /testbed/sphinx/highlighting.py:67: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if tuple(LooseVersion(pygmentsversion).version) <= (2, 7, 4):\n\nsphinx/registry.py:24\n  /testbed/sphinx/registry.py:24: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    from pkg_resources import iter_entry_points\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n    declare_namespace(pkg)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================== 42 passed, 7 warnings in 0.08s ========================\n\n",
          "test_files_run": [
            "tests/test_pycode_ast.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sphinx-doc__sphinx-9461",
      "repo": "sphinx-doc/sphinx",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 14.406461954116821,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 59,
          "failed": 3,
          "errors": 0,
          "collected": 62,
          "duration": 7.59,
          "log_tail": "\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:114: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n    _gaq.push(['_setAllowLinker', true]);\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:70: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:99: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:215: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:238: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:33: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:224: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:386: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:401: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================== 3 failed, 59 passed, 192 warnings in 3.92s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/roots/test-ext-autodoc/target/properties.py tests/test_domain_py.py tests/test_ext_autodoc_autoclass.py tests/test_ext_autodoc_autoproperty.py` failed. (See above for error)",
          "test_files_run": [
            "tests/roots/test-ext-autodoc/target/properties.py",
            "tests/test_domain_py.py",
            "tests/test_ext_autodoc_autoclass.py",
            "tests/test_ext_autodoc_autoproperty.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 62,
          "failed": 0,
          "errors": 0,
          "collected": 62,
          "duration": 5.82,
          "log_tail": "    declare_namespace(pkg)\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:114: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n    _gaq.push(['_setAllowLinker', true]);\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:70: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:99: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:215: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:238: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:33: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:224: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:386: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:401: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================= 62 passed, 192 warnings in 3.06s =======================\n\n",
          "test_files_run": [
            "tests/roots/test-ext-autodoc/target/properties.py",
            "tests/test_domain_py.py",
            "tests/test_ext_autodoc_autoclass.py",
            "tests/test_ext_autodoc_autoproperty.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sphinx-doc__sphinx-9591",
      "repo": "sphinx-doc/sphinx",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 13.044248104095459,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 44,
          "failed": 1,
          "errors": 0,
          "collected": 45,
          "duration": 6.71,
          "log_tail": "\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:114: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n    _gaq.push(['_setAllowLinker', true]);\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:70: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:99: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:215: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:238: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:33: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:224: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:386: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:401: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================== 1 failed, 44 passed, 192 warnings in 3.16s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_domain_py.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_domain_py.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 45,
          "failed": 0,
          "errors": 0,
          "collected": 45,
          "duration": 5.41,
          "log_tail": "    declare_namespace(pkg)\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:114: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n    _gaq.push(['_setAllowLinker', true]);\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:70: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:99: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:215: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:238: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:33: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:224: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:386: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:401: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================= 45 passed, 192 warnings in 2.42s =======================\n\n",
          "test_files_run": [
            "tests/test_domain_py.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sphinx-doc__sphinx-9602",
      "repo": "sphinx-doc/sphinx",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 13.513267993927002,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 45,
          "failed": 1,
          "errors": 0,
          "collected": 46,
          "duration": 7.27,
          "log_tail": "\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:114: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n    _gaq.push(['_setAllowLinker', true]);\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:70: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:99: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:215: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:238: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:33: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:224: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:386: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:401: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================== 1 failed, 45 passed, 192 warnings in 3.37s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_domain_py.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_domain_py.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 46,
          "failed": 0,
          "errors": 0,
          "collected": 46,
          "duration": 5.18,
          "log_tail": "    declare_namespace(pkg)\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:114: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n    _gaq.push(['_setAllowLinker', true]);\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:70: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:99: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:215: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:238: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:33: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:224: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:386: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:401: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================= 46 passed, 192 warnings in 2.37s =======================\n\n",
          "test_files_run": [
            "tests/test_domain_py.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sphinx-doc__sphinx-9658",
      "repo": "sphinx-doc/sphinx",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 7.928765773773193,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 24,
          "failed": 1,
          "errors": 0,
          "collected": 27,
          "duration": 3.58,
          "log_tail": "tests/test_util_typing.py::test_stringify PASSED                         [ 51%]\ntests/test_util_typing.py::test_stringify_type_hints_containers PASSED   [ 55%]\ntests/test_util_typing.py::test_stringify_type_hints_pep_585 PASSED      [ 59%]\ntests/test_util_typing.py::test_stringify_Annotated PASSED               [ 62%]\ntests/test_util_typing.py::test_stringify_type_hints_string PASSED       [ 66%]\ntests/test_util_typing.py::test_stringify_type_hints_Callable PASSED     [ 70%]\ntests/test_util_typing.py::test_stringify_type_hints_Union PASSED        [ 74%]\ntests/test_util_typing.py::test_stringify_type_hints_typevars PASSED     [ 77%]\ntests/test_util_typing.py::test_stringify_type_hints_custom_class PASSED [ 81%]\ntests/test_util_typing.py::test_stringify_type_hints_alias PASSED        [ 85%]\ntests/test_util_typing.py::test_stringify_type_Literal PASSED            [ 88%]\ntests/test_util_typing.py::test_stringify_type_union_operator SKIPPED    [ 92%]\ntests/test_util_typing.py::test_stringify_broken_type_hints PASSED       [ 96%]\ntests/test_util_typing.py::test_stringify_mock PASSED                    [100%]\n\n=================================== FAILURES ===================================\n______________________________ test_restify_mock _______________________________\ntests/test_util_typing.py:177: in test_restify_mock\n    assert restify(unknown.secret.Class) == ':py:class:`unknown.secret.Class`'\nE   AssertionError: assert ':py:class:`unknown.secret.`' == ':py:class:`u...secret.Class`'\nE     \nE     - :py:class:`unknown.secret.Class`\nE     ?                           -----\nE     + :py:class:`unknown.secret.`\n=============================== warnings summary ===============================\nsphinx/util/docutils.py:44\n  /testbed/sphinx/util/docutils.py:44: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    __version_info__ = tuple(LooseVersion(docutils.__version__).version)\n\nsphinx/highlighting.py:67\n  /testbed/sphinx/highlighting.py:67: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if tuple(LooseVersion(pygmentsversion).version) <= (2, 7, 4):\n\nsphinx/registry.py:24\n  /testbed/sphinx/registry.py:24: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    from pkg_resources import iter_entry_points\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n    declare_namespace(pkg)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n============= 1 failed, 24 passed, 2 skipped, 7 warnings in 0.18s ==============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_util_typing.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_util_typing.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 25,
          "failed": 0,
          "errors": 0,
          "collected": 27,
          "duration": 3.24,
          "log_tail": "tests/test_util_typing.py::test_restify_type_hints_Union PASSED          [ 14%]\ntests/test_util_typing.py::test_restify_type_hints_typevars PASSED       [ 18%]\ntests/test_util_typing.py::test_restify_type_hints_custom_class PASSED   [ 22%]\ntests/test_util_typing.py::test_restify_type_hints_alias PASSED          [ 25%]\ntests/test_util_typing.py::test_restify_type_ForwardRef PASSED           [ 29%]\ntests/test_util_typing.py::test_restify_type_Literal PASSED              [ 33%]\ntests/test_util_typing.py::test_restify_pep_585 PASSED                   [ 37%]\ntests/test_util_typing.py::test_restify_type_union_operator SKIPPED      [ 40%]\ntests/test_util_typing.py::test_restify_broken_type_hints PASSED         [ 44%]\ntests/test_util_typing.py::test_restify_mock PASSED                      [ 48%]\ntests/test_util_typing.py::test_stringify PASSED                         [ 51%]\ntests/test_util_typing.py::test_stringify_type_hints_containers PASSED   [ 55%]\ntests/test_util_typing.py::test_stringify_type_hints_pep_585 PASSED      [ 59%]\ntests/test_util_typing.py::test_stringify_Annotated PASSED               [ 62%]\ntests/test_util_typing.py::test_stringify_type_hints_string PASSED       [ 66%]\ntests/test_util_typing.py::test_stringify_type_hints_Callable PASSED     [ 70%]\ntests/test_util_typing.py::test_stringify_type_hints_Union PASSED        [ 74%]\ntests/test_util_typing.py::test_stringify_type_hints_typevars PASSED     [ 77%]\ntests/test_util_typing.py::test_stringify_type_hints_custom_class PASSED [ 81%]\ntests/test_util_typing.py::test_stringify_type_hints_alias PASSED        [ 85%]\ntests/test_util_typing.py::test_stringify_type_Literal PASSED            [ 88%]\ntests/test_util_typing.py::test_stringify_type_union_operator SKIPPED    [ 92%]\ntests/test_util_typing.py::test_stringify_broken_type_hints PASSED       [ 96%]\ntests/test_util_typing.py::test_stringify_mock PASSED                    [100%]\n\n=============================== warnings summary ===============================\nsphinx/util/docutils.py:44\n  /testbed/sphinx/util/docutils.py:44: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    __version_info__ = tuple(LooseVersion(docutils.__version__).version)\n\nsphinx/highlighting.py:67\n  /testbed/sphinx/highlighting.py:67: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if tuple(LooseVersion(pygmentsversion).version) <= (2, 7, 4):\n\nsphinx/registry.py:24\n  /testbed/sphinx/registry.py:24: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    from pkg_resources import iter_entry_points\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n    declare_namespace(pkg)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================== 25 passed, 2 skipped, 7 warnings in 0.15s ===================\n\n",
          "test_files_run": [
            "tests/test_util_typing.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sphinx-doc__sphinx-9673",
      "repo": "sphinx-doc/sphinx",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 10.778845071792603,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 24,
          "failed": 1,
          "errors": 0,
          "collected": 25,
          "duration": 5.33,
          "log_tail": "E   AssertionError: assert 'target.typehints.incr(a, b=1)\\n\\ntarget.typehints.decr(a, b=1)\\n\\n   Returns:\\n      decremented number\\n\\n   Return type:\\n      int\\n\\ntarget.typehints.tuple_args(x)\\n\\n   Parameters:\\n      **x** (*Tuple**[**int**, **Union**[**int**, **str**]**]*) -- arg\\n\\n   Returns:\\n      another tuple\\n\\n   Return type:\\n      Tuple[int, int]\\n' in 'target.typehints.incr(a, b=1)\\n\\ntarget.typehints.decr(a, b=1)\\n\\n   Returns:\\n      decremented number\\n\\ntarget.typehints.tuple_args(x)\\n\\n   Parameters:\\n      **x** (*Tuple**[**int**, **Union**[**int**, **str**]**]*) -- arg\\n\\n   Returns:\\n      another tuple\\n\\n   Return type:\\n      Tuple[int, int]\\n'\n--------------------------- Captured stdout teardown ---------------------------\n# testroot: root\n# builder: text\n# srcdir: /tmp/pytest-of-root/pytest-0/ext-autodoc\n# outdir: /tmp/pytest-of-root/pytest-0/ext-autodoc/_build/text\n# status: \n\u001b[01mRunning Sphinx v4.3.0+/5fb51fb14\u001b[39;49;00m\n\u001b[01mloading pickled environment... \u001b[39;49;00mdone\n\u001b[01mbuilding [mo]: \u001b[39;49;00mtargets for 0 po files that are out of date\n\u001b[01mbuilding [text]: \u001b[39;49;00mtargets for 1 source files that are out of date\n\u001b[01mupdating environment: \u001b[39;49;00m[config changed ('autodoc_typehints_description_target')] 1 added, 0 changed, 0 removed\n\u001b[01mreading sources... \u001b[39;49;00m[100%] \u001b[35mindex\u001b[39;49;00m                                                \n\u001b[01mlooking for now-outdated files... \u001b[39;49;00mnone found\n\u001b[01mpickling environment... \u001b[39;49;00mdone\n\u001b[01mchecking consistency... \u001b[39;49;00mdone\n\u001b[01mpreparing documents... \u001b[39;49;00mdone\n\u001b[01mwriting output... \u001b[39;49;00m[100%] \u001b[32mindex\u001b[39;49;00m                                                 \n\u001b[01mbuild succeeded.\u001b[39;49;00m\n\nThe text files are in ../tmp/pytest-of-root/pytest-0/ext-autodoc/_build/text.\n\n# warning: \n\n=============================== warnings summary ===============================\nsphinx/util/docutils.py:44\n  /testbed/sphinx/util/docutils.py:44: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    __version_info__ = tuple(LooseVersion(docutils.__version__).version)\n\nsphinx/highlighting.py:67\n  /testbed/sphinx/highlighting.py:67: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if tuple(LooseVersion(pygmentsversion).version) <= (2, 7, 4):\n\nsphinx/registry.py:24\n  /testbed/sphinx/registry.py:24: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    from pkg_resources import iter_entry_points\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n    declare_namespace(pkg)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=================== 1 failed, 24 passed, 7 warnings in 1.85s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_ext_autodoc_configs.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_ext_autodoc_configs.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 25,
          "failed": 0,
          "errors": 0,
          "collected": 25,
          "duration": 4.45,
          "log_tail": "tests/test_ext_autodoc_configs.py::test_autoclass_content_init PASSED    [  8%]\ntests/test_ext_autodoc_configs.py::test_autodoc_class_signature_mixed PASSED [ 12%]\ntests/test_ext_autodoc_configs.py::test_autodoc_class_signature_separated_init PASSED [ 16%]\ntests/test_ext_autodoc_configs.py::test_autodoc_class_signature_separated_new PASSED [ 20%]\ntests/test_ext_autodoc_configs.py::test_autoclass_content_both PASSED    [ 24%]\ntests/test_ext_autodoc_configs.py::test_autodoc_inherit_docstrings PASSED [ 28%]\ntests/test_ext_autodoc_configs.py::test_autodoc_docstring_signature PASSED [ 32%]\ntests/test_ext_autodoc_configs.py::test_autoclass_content_and_docstring_signature_class PASSED [ 36%]\ntests/test_ext_autodoc_configs.py::test_autoclass_content_and_docstring_signature_init PASSED [ 40%]\ntests/test_ext_autodoc_configs.py::test_autoclass_content_and_docstring_signature_both PASSED [ 44%]\ntests/test_ext_autodoc_configs.py::test_mocked_module_imports PASSED     [ 48%]\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_signature PASSED [ 52%]\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_none PASSED    [ 56%]\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_none_for_overload PASSED [ 60%]\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description PASSED [ 64%]\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_no_undoc PASSED [ 68%]\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_with_documented_init PASSED [ 72%]\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_with_documented_init_no_undoc PASSED [ 76%]\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_for_invalid_node PASSED [ 80%]\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_both PASSED    [ 84%]\ntests/test_ext_autodoc_configs.py::test_autodoc_type_aliases PASSED      [ 88%]\ntests/test_ext_autodoc_configs.py::test_autodoc_typehints_description_and_type_aliases PASSED [ 92%]\ntests/test_ext_autodoc_configs.py::test_autodoc_default_options PASSED   [ 96%]\ntests/test_ext_autodoc_configs.py::test_autodoc_default_options_with_values PASSED [100%]\n\n=============================== warnings summary ===============================\nsphinx/util/docutils.py:44\n  /testbed/sphinx/util/docutils.py:44: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    __version_info__ = tuple(LooseVersion(docutils.__version__).version)\n\nsphinx/highlighting.py:67\n  /testbed/sphinx/highlighting.py:67: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if tuple(LooseVersion(pygmentsversion).version) <= (2, 7, 4):\n\nsphinx/registry.py:24\n  /testbed/sphinx/registry.py:24: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    from pkg_resources import iter_entry_points\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n    declare_namespace(pkg)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================== 25 passed, 7 warnings in 1.50s ========================\n\n",
          "test_files_run": [
            "tests/test_ext_autodoc_configs.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sphinx-doc__sphinx-9698",
      "repo": "sphinx-doc/sphinx",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 12.920270919799805,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 45,
          "failed": 1,
          "errors": 0,
          "collected": 46,
          "duration": 6.6,
          "log_tail": "\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:114: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n    _gaq.push(['_setAllowLinker', true]);\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:70: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:99: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:215: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:238: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:33: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:224: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:386: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:401: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================== 1 failed, 45 passed, 192 warnings in 3.10s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_domain_py.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_domain_py.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 46,
          "failed": 0,
          "errors": 0,
          "collected": 46,
          "duration": 5.27,
          "log_tail": "    declare_namespace(pkg)\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:114: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n    _gaq.push(['_setAllowLinker', true]);\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:70: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:99: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:215: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py: 33 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:238: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:33: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:224: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:386: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_py.py::test_domain_py_xrefs_abbreviations\ntests/test_domain_py.py::test_resolve_xref_for_properties\ntests/test_domain_py.py::test_domain_py_canonical\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names\ntests/test_domain_py.py::test_python_python_use_unqualified_type_names_disabled\n  <template>:401: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================= 46 passed, 192 warnings in 2.44s =======================\n\n",
          "test_files_run": [
            "tests/test_domain_py.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sphinx-doc__sphinx-9711",
      "repo": "sphinx-doc/sphinx",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 8.531883955001831,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 1,
          "errors": 0,
          "collected": 1,
          "duration": 3.92,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 1 item\n\ntests/test_extension.py::test_needs_extensions FAILED                    [100%]\n\n=================================== FAILURES ===================================\n____________________________ test_needs_extensions _____________________________\ntests/test_extension.py:25: in test_needs_extensions\n    verify_needs_extensions(app, app.config)\nsphinx/extension.py:55: in verify_needs_extensions\n    raise VersionRequirementError(__('This project needs the extension %s at least in '\nE   sphinx.errors.VersionRequirementError: This project needs the extension test.extension at least in version 3.9 and therefore cannot be built with the loaded version (3.10).\n--------------------------- Captured stdout teardown ---------------------------\n# testroot: root\n# builder: html\n# srcdir: /tmp/pytest-of-root/pytest-0/root\n# outdir: /tmp/pytest-of-root/pytest-0/root/_build/html\n# status: \n\u001b[01mRunning Sphinx v4.3.0+/81a4fd973\u001b[39;49;00m\n\n# warning: \n\n=============================== warnings summary ===============================\nsphinx/util/docutils.py:44\n  /testbed/sphinx/util/docutils.py:44: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    __version_info__ = tuple(LooseVersion(docutils.__version__).version)\n\nsphinx/highlighting.py:67\n  /testbed/sphinx/highlighting.py:67: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if tuple(LooseVersion(pygmentsversion).version) <= (2, 7, 4):\n\nsphinx/registry.py:24\n  /testbed/sphinx/registry.py:24: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    from pkg_resources import iter_entry_points\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n    declare_namespace(pkg)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================== 1 failed, 7 warnings in 0.57s =========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_extension.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_extension.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 1,
          "failed": 0,
          "errors": 0,
          "collected": 1,
          "duration": 3.58,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 1 item\n\ntests/test_extension.py::test_needs_extensions PASSED                    [100%]\n\n=============================== warnings summary ===============================\nsphinx/util/docutils.py:44\n  /testbed/sphinx/util/docutils.py:44: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    __version_info__ = tuple(LooseVersion(docutils.__version__).version)\n\nsphinx/highlighting.py:67\n  /testbed/sphinx/highlighting.py:67: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if tuple(LooseVersion(pygmentsversion).version) <= (2, 7, 4):\n\nsphinx/registry.py:24\n  /testbed/sphinx/registry.py:24: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    from pkg_resources import iter_entry_points\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n    declare_namespace(pkg)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================== 1 passed, 7 warnings in 0.46s =========================\n\n",
          "test_files_run": [
            "tests/test_extension.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "scikit-learn__scikit-learn-10297",
      "repo": "scikit-learn/scikit-learn",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10ce61790>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-10844",
      "repo": "scikit-learn/scikit-learn",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10cee5640>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-10908",
      "repo": "scikit-learn/scikit-learn",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10d004980>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-11310",
      "repo": "scikit-learn/scikit-learn",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10d046a20>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-11578",
      "repo": "scikit-learn/scikit-learn",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10cf17c20>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-12585",
      "repo": "scikit-learn/scikit-learn",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10cf2ecf0>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-12682",
      "repo": "scikit-learn/scikit-learn",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10cdfd1f0>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-12973",
      "repo": "scikit-learn/scikit-learn",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10cecc350>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-13124",
      "repo": "scikit-learn/scikit-learn",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10d0041a0>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-13135",
      "repo": "scikit-learn/scikit-learn",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10cdc8dd0>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-13142",
      "repo": "scikit-learn/scikit-learn",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10d0064b0>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-13328",
      "repo": "scikit-learn/scikit-learn",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10ce18530>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-13439",
      "repo": "scikit-learn/scikit-learn",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10cf61610>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-13496",
      "repo": "scikit-learn/scikit-learn",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10cecc950>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-13779",
      "repo": "scikit-learn/scikit-learn",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10ceccb30>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-14053",
      "repo": "scikit-learn/scikit-learn",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10ce3d550>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-14087",
      "repo": "scikit-learn/scikit-learn",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10d047170>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-14141",
      "repo": "scikit-learn/scikit-learn",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10cf2c470>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-14496",
      "repo": "scikit-learn/scikit-learn",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10d045f10>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-14629",
      "repo": "scikit-learn/scikit-learn",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10ce3e150>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-14710",
      "repo": "scikit-learn/scikit-learn",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10d046f00>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-14894",
      "repo": "scikit-learn/scikit-learn",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10cf95370>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-14983",
      "repo": "scikit-learn/scikit-learn",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10cdc9940>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-15100",
      "repo": "scikit-learn/scikit-learn",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10cdab9e0>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-25102",
      "repo": "scikit-learn/scikit-learn",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10cfae210>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-25232",
      "repo": "scikit-learn/scikit-learn",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10cffa270>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-25747",
      "repo": "scikit-learn/scikit-learn",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10d046cc0>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-25931",
      "repo": "scikit-learn/scikit-learn",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10cf2f3e0>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-25973",
      "repo": "scikit-learn/scikit-learn",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10cf17c50>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-26194",
      "repo": "scikit-learn/scikit-learn",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10cf2e2a0>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-26323",
      "repo": "scikit-learn/scikit-learn",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10d005ee0>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 0
    },
    {
      "instance_id": "scikit-learn__scikit-learn-9288",
      "repo": "scikit-learn/scikit-learn",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10cee6750>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 0
    },
    {
      "instance_id": "astropy__astropy-12907",
      "repo": "astropy/astropy",
      "valid": true,
      "worker": "http://34.59.30.169:8080",
      "duration": 11.094218969345093,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 13,
          "failed": 2,
          "errors": 0,
          "collected": 15,
          "duration": 4.52,
          "log_tail": "Internet access disabled\n============================= test session starts ==============================\ncollecting ... collected 15 items\n\nastropy/modeling/tests/test_separable.py::test_coord_matrix PASSED       [  6%]\nastropy/modeling/tests/test_separable.py::test_cdot PASSED               [ 13%]\nastropy/modeling/tests/test_separable.py::test_cstack PASSED             [ 20%]\nastropy/modeling/tests/test_separable.py::test_arith_oper PASSED         [ 26%]\nastropy/modeling/tests/test_separable.py::test_separable[compound_model0-result0] PASSED [ 33%]\nastropy/modeling/tests/test_separable.py::test_separable[compound_model1-result1] PASSED [ 40%]\nastropy/modeling/tests/test_separable.py::test_separable[compound_model2-result2] PASSED [ 46%]\nastropy/modeling/tests/test_separable.py::test_separable[compound_model3-result3] PASSED [ 53%]\nastropy/modeling/tests/test_separable.py::test_separable[compound_model4-result4] PASSED [ 60%]\nastropy/modeling/tests/test_separable.py::test_separable[compound_model5-result5] PASSED [ 66%]\nastropy/modeling/tests/test_separable.py::test_separable[compound_model6-result6] FAILED [ 73%]\nastropy/modeling/tests/test_separable.py::test_separable[compound_model7-result7] PASSED [ 80%]\nastropy/modeling/tests/test_separable.py::test_separable[compound_model8-result8] PASSED [ 86%]\nastropy/modeling/tests/test_separable.py::test_separable[compound_model9-result9] FAILED [ 93%]\nastropy/modeling/tests/test_separable.py::test_custom_model_separable PASSED [100%]\n\n=================================== FAILURES ===================================\n___________________ test_separable[compound_model6-result6] ____________________\nastropy/modeling/tests/test_separable.py:151: in test_separable\n    assert_allclose(is_separable(compound_model), result[0])\n/opt/miniconda3/envs/testbed/lib/python3.9/contextlib.py:79: in inner\n    return func(*args, **kwds)\nE   AssertionError: \nE   Not equal to tolerance rtol=1e-07, atol=0\nE   \nE   Mismatched elements: 2 / 4 (50%)\nE    x: array([False, False, False, False])\nE    y: array([False, False,  True,  True])\n___________________ test_separable[compound_model9-result9] ____________________\nastropy/modeling/tests/test_separable.py:151: in test_separable\n    assert_allclose(is_separable(compound_model), result[0])\n/opt/miniconda3/envs/testbed/lib/python3.9/contextlib.py:79: in inner\n    return func(*args, **kwds)\nE   AssertionError: \nE   Not equal to tolerance rtol=1e-07, atol=0\nE   \nE   Mismatched elements: 2 / 5 (40%)\nE    x: array([False, False,  True, False, False])\nE    y: array([False, False,  True,  True,  True])\n========================= 2 failed, 13 passed in 0.49s =========================\n\n\n<frozen importlib._bootstrap>:228: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 80 from C header, got 96 from PyObject\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/modeling/tests/test_separable.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/modeling/tests/test_separable.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 15,
          "failed": 0,
          "errors": 0,
          "collected": 15,
          "duration": 5.48,
          "log_tail": "Internet access disabled\n============================= test session starts ==============================\ncollecting ... collected 15 items\n\nastropy/modeling/tests/test_separable.py::test_coord_matrix PASSED       [  6%]\nastropy/modeling/tests/test_separable.py::test_cdot PASSED               [ 13%]\nastropy/modeling/tests/test_separable.py::test_cstack PASSED             [ 20%]\nastropy/modeling/tests/test_separable.py::test_arith_oper PASSED         [ 26%]\nastropy/modeling/tests/test_separable.py::test_separable[compound_model0-result0] PASSED [ 33%]\nastropy/modeling/tests/test_separable.py::test_separable[compound_model1-result1] PASSED [ 40%]\nastropy/modeling/tests/test_separable.py::test_separable[compound_model2-result2] PASSED [ 46%]\nastropy/modeling/tests/test_separable.py::test_separable[compound_model3-result3] PASSED [ 53%]\nastropy/modeling/tests/test_separable.py::test_separable[compound_model4-result4] PASSED [ 60%]\nastropy/modeling/tests/test_separable.py::test_separable[compound_model5-result5] PASSED [ 66%]\nastropy/modeling/tests/test_separable.py::test_separable[compound_model6-result6] PASSED [ 73%]\nastropy/modeling/tests/test_separable.py::test_separable[compound_model7-result7] PASSED [ 80%]\nastropy/modeling/tests/test_separable.py::test_separable[compound_model8-result8] PASSED [ 86%]\nastropy/modeling/tests/test_separable.py::test_separable[compound_model9-result9] PASSED [ 93%]\nastropy/modeling/tests/test_separable.py::test_custom_model_separable PASSED [100%]\n\n============================== 15 passed in 0.44s ==============================\n\n\n<frozen importlib._bootstrap>:228: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 80 from C header, got 96 from PyObject\n",
          "test_files_run": [
            "astropy/modeling/tests/test_separable.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "astropy__astropy-13033",
      "repo": "astropy/astropy",
      "valid": false,
      "worker": "http://34.59.30.169:8080",
      "duration": 11.24806022644043,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 20,
          "failed": 2,
          "errors": 0,
          "collected": 25,
          "duration": 4.56,
          "log_tail": "astropy/timeseries/tests/test_sampled.py::test_initialization_n_samples PASSED [ 48%]\nastropy/timeseries/tests/test_sampled.py::test_initialization_length_mismatch PASSED [ 52%]\nastropy/timeseries/tests/test_sampled.py::test_initialization_invalid_both_time_and_time_delta PASSED [ 56%]\nastropy/timeseries/tests/test_sampled.py::test_fold PASSED               [ 60%]\nastropy/timeseries/tests/test_sampled.py::test_fold_invalid_options PASSED [ 64%]\nastropy/timeseries/tests/test_sampled.py::test_pandas SKIPPED (could...) [ 68%]\nastropy/timeseries/tests/test_sampled.py::test_read_time_missing PASSED  [ 72%]\nastropy/timeseries/tests/test_sampled.py::test_read_time_wrong PASSED    [ 76%]\nastropy/timeseries/tests/test_sampled.py::test_read PASSED               [ 80%]\nastropy/timeseries/tests/test_sampled.py::test_kepler_astropy SKIPPED    [ 84%]\nastropy/timeseries/tests/test_sampled.py::test_tess_astropy SKIPPED      [ 88%]\nastropy/timeseries/tests/test_sampled.py::test_required_columns FAILED   [ 92%]\nastropy/timeseries/tests/test_sampled.py::test_periodogram[BoxLeastSquares] PASSED [ 96%]\nastropy/timeseries/tests/test_sampled.py::test_periodogram[LombScargle] PASSED [100%]\n\n=================================== FAILURES ===================================\n_____________________ test_initialization_with_time_delta ______________________\nastropy/time/core.py:2824: in update_leap_seconds\n    table = iers.LeapSeconds.auto_open(files)\nastropy/utils/iers/iers.py:1032: in auto_open\n    warn('leap-second file is expired.', IERSStaleWarning)\nE   astropy.utils.iers.iers.IERSStaleWarning: leap-second file is expired.\n\nDuring handling of the above exception, another exception occurred:\nastropy/timeseries/tests/test_sampled.py:67: in test_initialization_with_time_delta\n    ts = TimeSeries(time_start=datetime(2018, 7, 1, 10, 10, 10),\nastropy/timeseries/sampled.py:122: in __init__\n    time = time_start + time_delta\nastropy/time/core.py:2208: in __add__\n    out._set_scale('tai')\nastropy/time/core.py:554: in _set_scale\n    _check_leapsec()\nastropy/time/core.py:2795: in _check_leapsec\n    update_leap_seconds()\nastropy/time/core.py:2828: in update_leap_seconds\n    warn(\"leap-second auto-update failed due to the following \"\nE   astropy.utils.exceptions.AstropyWarning: leap-second auto-update failed due to the following exception: IERSStaleWarning('leap-second file is expired.')\n____________________________ test_required_columns _____________________________\nastropy/timeseries/tests/test_sampled.py:403: in test_required_columns\n    assert exc.value.args[0] == (\"TimeSeries object is invalid - expected \"\nE   assert \"TimeSeries o... found 'time'\" == \"TimeSeries o...['time', 'b']\"\nE     - TimeSeries object is invalid - expected ['time', 'a'] as the first columns but found ['time', 'b']\nE     ?                                         -      ------                                -      ------\nE     + TimeSeries object is invalid - expected 'time' as the first columns but found 'time'\n=================== 2 failed, 20 passed, 3 skipped in 0.38s ====================\n\n\n<frozen importlib._bootstrap>:228: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 80 from C header, got 96 from PyObject\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/timeseries/tests/test_sampled.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/timeseries/tests/test_sampled.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 21,
          "failed": 1,
          "errors": 0,
          "collected": 25,
          "duration": 5.21,
          "log_tail": "astropy/timeseries/tests/test_sampled.py::test_initialize_only_data PASSED [ 20%]\nastropy/timeseries/tests/test_sampled.py::test_initialization_with_table PASSED [ 24%]\nastropy/timeseries/tests/test_sampled.py::test_initialization_with_time_delta FAILED [ 28%]\nastropy/timeseries/tests/test_sampled.py::test_initialization_missing_time_delta PASSED [ 32%]\nastropy/timeseries/tests/test_sampled.py::test_initialization_invalid_time_and_time_start PASSED [ 36%]\nastropy/timeseries/tests/test_sampled.py::test_initialization_invalid_time_delta PASSED [ 40%]\nastropy/timeseries/tests/test_sampled.py::test_initialization_with_time_in_data PASSED [ 44%]\nastropy/timeseries/tests/test_sampled.py::test_initialization_n_samples PASSED [ 48%]\nastropy/timeseries/tests/test_sampled.py::test_initialization_length_mismatch PASSED [ 52%]\nastropy/timeseries/tests/test_sampled.py::test_initialization_invalid_both_time_and_time_delta PASSED [ 56%]\nastropy/timeseries/tests/test_sampled.py::test_fold PASSED               [ 60%]\nastropy/timeseries/tests/test_sampled.py::test_fold_invalid_options PASSED [ 64%]\nastropy/timeseries/tests/test_sampled.py::test_pandas SKIPPED (could...) [ 68%]\nastropy/timeseries/tests/test_sampled.py::test_read_time_missing PASSED  [ 72%]\nastropy/timeseries/tests/test_sampled.py::test_read_time_wrong PASSED    [ 76%]\nastropy/timeseries/tests/test_sampled.py::test_read PASSED               [ 80%]\nastropy/timeseries/tests/test_sampled.py::test_kepler_astropy SKIPPED    [ 84%]\nastropy/timeseries/tests/test_sampled.py::test_tess_astropy SKIPPED      [ 88%]\nastropy/timeseries/tests/test_sampled.py::test_required_columns PASSED   [ 92%]\nastropy/timeseries/tests/test_sampled.py::test_periodogram[BoxLeastSquares] PASSED [ 96%]\nastropy/timeseries/tests/test_sampled.py::test_periodogram[LombScargle] PASSED [100%]\n\n=================================== FAILURES ===================================\n_____________________ test_initialization_with_time_delta ______________________\nastropy/time/core.py:2824: in update_leap_seconds\n    table = iers.LeapSeconds.auto_open(files)\nastropy/utils/iers/iers.py:1032: in auto_open\n    warn('leap-second file is expired.', IERSStaleWarning)\nE   astropy.utils.iers.iers.IERSStaleWarning: leap-second file is expired.\n\nDuring handling of the above exception, another exception occurred:\nastropy/timeseries/tests/test_sampled.py:67: in test_initialization_with_time_delta\n    ts = TimeSeries(time_start=datetime(2018, 7, 1, 10, 10, 10),\nastropy/timeseries/sampled.py:122: in __init__\n    time = time_start + time_delta\nastropy/time/core.py:2208: in __add__\n    out._set_scale('tai')\nastropy/time/core.py:554: in _set_scale\n    _check_leapsec()\nastropy/time/core.py:2795: in _check_leapsec\n    update_leap_seconds()\nastropy/time/core.py:2828: in update_leap_seconds\n    warn(\"leap-second auto-update failed due to the following \"\nE   astropy.utils.exceptions.AstropyWarning: leap-second auto-update failed due to the following exception: IERSStaleWarning('leap-second file is expired.')\n=================== 1 failed, 21 passed, 3 skipped in 0.32s ====================\n\n\n<frozen importlib._bootstrap>:228: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 80 from C header, got 96 from PyObject\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/timeseries/tests/test_sampled.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/timeseries/tests/test_sampled.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "astropy__astropy-13236",
      "repo": "astropy/astropy",
      "valid": false,
      "worker": "http://34.59.30.169:8080",
      "duration": 19.38363480567932,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 644,
          "failed": 4,
          "errors": 0,
          "collected": 674,
          "duration": 9.28,
          "log_tail": "astropy/table/tests/test_table.py::test_remove_columns_invalid_names_messages PASSED [ 99%]\nastropy/table/tests/test_table.py::test_read_write_tilde_path[str] PASSED [ 99%]\nastropy/table/tests/test_table.py::test_read_write_tilde_path[Path] PASSED [100%]\n\n=================================== FAILURES ===================================\n_________________________ test_skycoord_representation _________________________\nastropy/table/tests/test_mixin.py:688: in test_skycoord_representation\n    assert t.pformat() == ['  col0  ',\nastropy/table/table.py:1806: in pformat\n    lines, outs = self.formatter._pformat_table(\nastropy/table/pprint.py:563: in _pformat_table\n    show_unit = any(col.info.unit for col in table.columns.values())\nastropy/table/pprint.py:563: in <genexpr>\n    show_unit = any(col.info.unit for col in table.columns.values())\nastropy/coordinates/sky_coordinate.py:52: in unit\n    repr_data = self._repr_data\nastropy/coordinates/sky_coordinate.py:67: in _repr_data\n    repr_data = sc.represent_as(sc.representation_type,\nastropy/coordinates/baseframe.py:1078: in represent_as\n    data = self.data.represent_as(representation_cls)\nastropy/coordinates/representation.py:873: in represent_as\n    new_rep = other_class.from_cartesian(self.to_cartesian())\nastropy/coordinates/representation.py:1606: in from_cartesian\n    p = cart.get_xyz(xyz_axis=-1)\nastropy/coordinates/representation.py:1351: in get_xyz\n    return np.stack([self._x, self._y, self._z], axis=xyz_axis)\nastropy/units/quantity.py:1683: in __array_function__\n    return super().__array_function__(function, types, args, kwargs)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/shape_base.py:456: in stack\n    return _nx.concatenate(expanded_arrays, axis=axis, out=out,\nastropy/units/quantity.py:1688: in __array_function__\n    args, kwargs, unit, out = function_helper(*args, **kwargs)\nE   TypeError: concatenate() got an unexpected keyword argument 'dtype'\n__________________________ test_ndarray_mixin[False] ___________________________\nastropy/table/tests/test_mixin.py:731: in test_ndarray_mixin\n    assert isinstance(t['a'], class_exp)\nE   AssertionError: assert False\nE    +  where False = isinstance(NdarrayMixin([(1, 'a'), (2, 'b'), (3, 'c'), (4, 'd')],\\n             dtype=[('f0', '<i4'), ('f1', '<U1')]), <class 'astropy.table.column.Column'>)\n___________________________ test_values_equal_part1 ____________________________\nastropy/table/tests/test_table.py:1497: in test_values_equal_part1\n    t1.values_equal(2)\nE   Failed: DID NOT RAISE <class 'ValueError'>\n________________________ test_structured_masked_column _________________________\nastropy/table/tests/test_table.py:2928: in test_structured_masked_column\n    assert np.all(t['a']['z'].mask == [False, False])\nE   AttributeError: 'NdarrayMixin' object has no attribute 'mask'\n============= 4 failed, 644 passed, 25 skipped, 1 xfailed in 4.82s =============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/table/tests/test_mixin.py astropy/table/tests/test_table.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/table/tests/test_mixin.py",
            "astropy/table/tests/test_table.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 646,
          "failed": 2,
          "errors": 0,
          "collected": 674,
          "duration": 8.54,
          "log_tail": "astropy/table/tests/test_table.py::test_structured_masked_column PASSED  [ 98%]\nastropy/table/tests/test_table.py::test_rows_with_mixins PASSED          [ 98%]\nastropy/table/tests/test_table.py::test_iterrows PASSED                  [ 98%]\nastropy/table/tests/test_table.py::test_values_and_types PASSED          [ 98%]\nastropy/table/tests/test_table.py::test_items PASSED                     [ 98%]\nastropy/table/tests/test_table.py::test_read_write_not_replaceable PASSED [ 99%]\nastropy/table/tests/test_table.py::test_keep_columns_with_generator PASSED [ 99%]\nastropy/table/tests/test_table.py::test_remove_columns_with_generator PASSED [ 99%]\nastropy/table/tests/test_table.py::test_keep_columns_invalid_names_messages PASSED [ 99%]\nastropy/table/tests/test_table.py::test_remove_columns_invalid_names_messages PASSED [ 99%]\nastropy/table/tests/test_table.py::test_read_write_tilde_path[str] PASSED [ 99%]\nastropy/table/tests/test_table.py::test_read_write_tilde_path[Path] PASSED [100%]\n\n=================================== FAILURES ===================================\n_________________________ test_skycoord_representation _________________________\nastropy/table/tests/test_mixin.py:688: in test_skycoord_representation\n    assert t.pformat() == ['  col0  ',\nastropy/table/table.py:1799: in pformat\n    lines, outs = self.formatter._pformat_table(\nastropy/table/pprint.py:563: in _pformat_table\n    show_unit = any(col.info.unit for col in table.columns.values())\nastropy/table/pprint.py:563: in <genexpr>\n    show_unit = any(col.info.unit for col in table.columns.values())\nastropy/coordinates/sky_coordinate.py:52: in unit\n    repr_data = self._repr_data\nastropy/coordinates/sky_coordinate.py:67: in _repr_data\n    repr_data = sc.represent_as(sc.representation_type,\nastropy/coordinates/baseframe.py:1078: in represent_as\n    data = self.data.represent_as(representation_cls)\nastropy/coordinates/representation.py:873: in represent_as\n    new_rep = other_class.from_cartesian(self.to_cartesian())\nastropy/coordinates/representation.py:1606: in from_cartesian\n    p = cart.get_xyz(xyz_axis=-1)\nastropy/coordinates/representation.py:1351: in get_xyz\n    return np.stack([self._x, self._y, self._z], axis=xyz_axis)\nastropy/units/quantity.py:1683: in __array_function__\n    return super().__array_function__(function, types, args, kwargs)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/shape_base.py:456: in stack\n    return _nx.concatenate(expanded_arrays, axis=axis, out=out,\nastropy/units/quantity.py:1688: in __array_function__\n    args, kwargs, unit, out = function_helper(*args, **kwargs)\nE   TypeError: concatenate() got an unexpected keyword argument 'dtype'\n___________________________ test_values_equal_part1 ____________________________\nastropy/table/tests/test_table.py:1497: in test_values_equal_part1\n    t1.values_equal(2)\nE   Failed: DID NOT RAISE <class 'ValueError'>\n============= 2 failed, 646 passed, 25 skipped, 1 xfailed in 3.70s =============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/table/tests/test_mixin.py astropy/table/tests/test_table.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/table/tests/test_mixin.py",
            "astropy/table/tests/test_table.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "astropy__astropy-13398",
      "repo": "astropy/astropy",
      "valid": false,
      "worker": "http://34.59.30.169:8080",
      "duration": 15.685515880584717,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 68,
          "failed": 5,
          "errors": 0,
          "collected": 76,
          "duration": 6.86,
          "log_tail": "    cirsnod = inod.transform_to(cframe1)  # uses the default time\nastropy/coordinates/baseframe.py:1202: in transform_to\n    return trans(self, new_frame)\nastropy/coordinates/transformations.py:1478: in __call__\n    curr_coord = t(curr_coord, curr_toframe)\nastropy/coordinates/transformations.py:1079: in __call__\n    return supcall(fromcoord, toframe)\nastropy/coordinates/builtin_frames/icrs_cirs_transforms.py:35: in icrs_to_cirs\n    astrom = erfa_astrom.get().apco(cirs_frame)\nastropy/coordinates/erfa_astrom.py:50: in apco\n    xp, yp = get_polar_motion(obstime)\nastropy/coordinates/builtin_frames/utils.py:47: in get_polar_motion\n    xp, yp, status = iers_table.pm_xy(time, return_status=True)\nastropy/utils/iers/iers.py:365: in pm_xy\n    return self._interpolate(jd1, jd2, ['PM_x', 'PM_y'],\nastropy/utils/iers/iers.py:392: in _interpolate\n    mjd, utc = self.mjd_utc(jd1, jd2)\nastropy/utils/iers/iers.py:271: in mjd_utc\n    mjd = np.floor(jd1 - MJD_ZERO + jd2)\nE   TypeError: unsupported operand type(s) for -: 'Time' and 'float'\n___________________ test_itrs_topo_to_altaz_with_refraction ____________________\nastropy/coordinates/tests/test_intermediate_transformations.py:207: in test_itrs_topo_to_altaz_with_refraction\n    itrs_frame = ITRS(location=loc)\nastropy/coordinates/baseframe.py:319: in __init__\n    raise TypeError(\nE   TypeError: Coordinate frame ITRS got unexpected keywords: ['location']\n___________________ test_itrs_topo_to_hadec_with_refraction ____________________\nastropy/coordinates/tests/test_intermediate_transformations.py:262: in test_itrs_topo_to_hadec_with_refraction\n    itrs_frame = ITRS(location=loc)\nastropy/coordinates/baseframe.py:319: in __init__\n    raise TypeError(\nE   TypeError: Coordinate frame ITRS got unexpected keywords: ['location']\n_____________________________ test_cirs_itrs_topo ______________________________\nastropy/coordinates/tests/test_intermediate_transformations.py:359: in test_cirs_itrs_topo\n    cirs2 = cirs.transform_to(ITRS(location=loc)).transform_to(cirs)\nastropy/coordinates/baseframe.py:319: in __init__\n    raise TypeError(\nE   TypeError: Coordinate frame ITRS got unexpected keywords: ['location']\n_________________________ test_itrs_straight_overhead __________________________\nastropy/coordinates/tests/test_intermediate_transformations.py:957: in test_itrs_straight_overhead\n    itrs_topo = ITRS(itrs_repr, obstime=t, location=home)\nastropy/coordinates/baseframe.py:319: in __init__\n    raise TypeError(\nE   TypeError: Coordinate frame ITRS got unexpected keywords: ['location']\n=================== 5 failed, 68 passed, 3 skipped in 2.54s ====================\n\n\n<frozen importlib._bootstrap>:228: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 80 from C header, got 96 from PyObject\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/coordinates/tests/test_intermediate_transformations.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/coordinates/tests/test_intermediate_transformations.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 72,
          "failed": 1,
          "errors": 0,
          "collected": 76,
          "duration": 7.1,
          "log_tail": "astropy/coordinates/tests/test_intermediate_transformations.py::test_icrs_gcrscirs_sunish[testframe4] PASSED [ 75%]\nastropy/coordinates/tests/test_intermediate_transformations.py::test_icrs_altaz_moonish[testframe0] PASSED [ 76%]\nastropy/coordinates/tests/test_intermediate_transformations.py::test_icrs_altaz_moonish[testframe1] PASSED [ 77%]\nastropy/coordinates/tests/test_intermediate_transformations.py::test_icrs_altaz_moonish[testframe2] PASSED [ 78%]\nastropy/coordinates/tests/test_intermediate_transformations.py::test_icrs_altaz_moonish[testframe3] PASSED [ 80%]\nastropy/coordinates/tests/test_intermediate_transformations.py::test_icrs_altaz_moonish[testframe4] PASSED [ 81%]\nastropy/coordinates/tests/test_intermediate_transformations.py::test_gcrs_self_transform_closeby PASSED [ 82%]\nastropy/coordinates/tests/test_intermediate_transformations.py::test_teme_itrf PASSED [ 84%]\nastropy/coordinates/tests/test_intermediate_transformations.py::test_precessedgeocentric_loopback PASSED [ 85%]\nastropy/coordinates/tests/test_intermediate_transformations.py::test_teme_loopback PASSED [ 86%]\nastropy/coordinates/tests/test_intermediate_transformations.py::test_earth_orientation_table SKIPPED [ 88%]\nastropy/coordinates/tests/test_intermediate_transformations.py::test_ephemerides SKIPPED [ 89%]\nastropy/coordinates/tests/test_intermediate_transformations.py::test_tete_transforms PASSED [ 90%]\nastropy/coordinates/tests/test_intermediate_transformations.py::test_straight_overhead PASSED [ 92%]\nastropy/coordinates/tests/test_intermediate_transformations.py::test_itrs_straight_overhead PASSED [ 93%]\nastropy/coordinates/tests/test_intermediate_transformations.py::test_aa_hd_high_precision SKIPPED [ 94%]\nastropy/coordinates/tests/test_intermediate_transformations.py::test_aa_high_precision_nodata PASSED [ 96%]\nastropy/coordinates/tests/test_intermediate_transformations.py::TestGetLocationGCRS::test_get_gcrs_posvel PASSED [ 97%]\nastropy/coordinates/tests/test_intermediate_transformations.py::TestGetLocationGCRS::test_tete_quick PASSED [ 98%]\nastropy/coordinates/tests/test_intermediate_transformations.py::TestGetLocationGCRS::test_cirs_quick PASSED [100%]\n\n=================================== FAILURES ===================================\n________________________________ test_icrs_cirs ________________________________\nastropy/coordinates/tests/test_intermediate_transformations.py:49: in test_icrs_cirs\n    cirsnod = inod.transform_to(cframe1)  # uses the default time\nastropy/coordinates/baseframe.py:1202: in transform_to\n    return trans(self, new_frame)\nastropy/coordinates/transformations.py:1478: in __call__\n    curr_coord = t(curr_coord, curr_toframe)\nastropy/coordinates/transformations.py:1079: in __call__\n    return supcall(fromcoord, toframe)\nastropy/coordinates/builtin_frames/icrs_cirs_transforms.py:35: in icrs_to_cirs\n    astrom = erfa_astrom.get().apco(cirs_frame)\nastropy/coordinates/erfa_astrom.py:50: in apco\n    xp, yp = get_polar_motion(obstime)\nastropy/coordinates/builtin_frames/utils.py:47: in get_polar_motion\n    xp, yp, status = iers_table.pm_xy(time, return_status=True)\nastropy/utils/iers/iers.py:365: in pm_xy\n    return self._interpolate(jd1, jd2, ['PM_x', 'PM_y'],\nastropy/utils/iers/iers.py:392: in _interpolate\n    mjd, utc = self.mjd_utc(jd1, jd2)\nastropy/utils/iers/iers.py:271: in mjd_utc\n    mjd = np.floor(jd1 - MJD_ZERO + jd2)\nE   TypeError: unsupported operand type(s) for -: 'Time' and 'float'\n=================== 1 failed, 72 passed, 3 skipped in 2.38s ====================\n\n\n<frozen importlib._bootstrap>:228: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 80 from C header, got 96 from PyObject\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/coordinates/tests/test_intermediate_transformations.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/coordinates/tests/test_intermediate_transformations.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "astropy__astropy-13453",
      "repo": "astropy/astropy",
      "valid": true,
      "worker": "http://34.59.30.169:8080",
      "duration": 10.85347318649292,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 9,
          "failed": 1,
          "errors": 0,
          "collected": 26,
          "duration": 4.52,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 26 items\n\nastropy/io/ascii/tests/test_html.py::test_soupstring SKIPPED (condit...) [  3%]\nastropy/io/ascii/tests/test_html.py::test_listwriter PASSED              [  7%]\nastropy/io/ascii/tests/test_html.py::test_identify_table SKIPPED (co...) [ 11%]\nastropy/io/ascii/tests/test_html.py::test_missing_data SKIPPED (cond...) [ 15%]\nastropy/io/ascii/tests/test_html.py::test_rename_cols SKIPPED (condi...) [ 19%]\nastropy/io/ascii/tests/test_html.py::test_no_names SKIPPED (conditio...) [ 23%]\nastropy/io/ascii/tests/test_html.py::test_identify_table_fail SKIPPED    [ 26%]\nastropy/io/ascii/tests/test_html.py::test_backend_parsers SKIPPED (c...) [ 30%]\nastropy/io/ascii/tests/test_html.py::test_htmlinputter_no_bs4 PASSED     [ 34%]\nastropy/io/ascii/tests/test_html.py::test_htmlinputter SKIPPED (cond...) [ 38%]\nastropy/io/ascii/tests/test_html.py::test_htmlsplitter SKIPPED (cond...) [ 42%]\nastropy/io/ascii/tests/test_html.py::test_htmlheader_start SKIPPED (...) [ 46%]\nastropy/io/ascii/tests/test_html.py::test_htmldata SKIPPED (conditio...) [ 50%]\nastropy/io/ascii/tests/test_html.py::test_multicolumn_write PASSED       [ 53%]\nastropy/io/ascii/tests/test_html.py::test_multicolumn_write_escape SKIPPED [ 57%]\nastropy/io/ascii/tests/test_html.py::test_write_no_multicols PASSED      [ 61%]\nastropy/io/ascii/tests/test_html.py::test_multicolumn_read SKIPPED (...) [ 65%]\nastropy/io/ascii/tests/test_html.py::test_raw_html_write SKIPPED (co...) [ 69%]\nastropy/io/ascii/tests/test_html.py::test_raw_html_write_clean SKIPPED   [ 73%]\nastropy/io/ascii/tests/test_html.py::test_write_table_html_fill_values PASSED [ 76%]\nastropy/io/ascii/tests/test_html.py::test_write_table_html_fill_values_optional_columns PASSED [ 80%]\nastropy/io/ascii/tests/test_html.py::test_write_table_html_fill_values_masked PASSED [ 84%]\nastropy/io/ascii/tests/test_html.py::test_multicolumn_table_html_fill_values PASSED [ 88%]\nastropy/io/ascii/tests/test_html.py::test_multi_column_write_table_html_fill_values_masked PASSED [ 92%]\nastropy/io/ascii/tests/test_html.py::test_write_table_formatted_columns FAILED [ 96%]\nastropy/io/ascii/tests/test_html.py::test_read_html_unicode SKIPPED      [100%]\n\n=================================== FAILURES ===================================\n______________________ test_write_table_formatted_columns ______________________\n/testbed/astropy/io/ascii/tests/test_html.py:760: in test_write_table_formatted_columns\n    assert out == expected.strip()\nE   assert '<html>\\n <he...ody>\\n</html>' == '<html>\\n <he...ody>\\n</html>'\nE       <html>\nE        <head>\nE         <meta charset=\"utf-8\"/>\nE         <meta content=\"text/html;charset=UTF-8\" http-equiv=\"Content-type\"/>\nE        </head>\nE        <body>\nE         <table>...\nE     \nE     ...Full output truncated (24 lines hidden), use '-vv' to show\n=================== 1 failed, 9 passed, 16 skipped in 0.16s ====================\n\n\n<frozen importlib._bootstrap>:228: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 80 from C header, got 96 from PyObject\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/io/ascii/tests/test_html.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/io/ascii/tests/test_html.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 10,
          "failed": 0,
          "errors": 0,
          "collected": 26,
          "duration": 4.82,
          "log_tail": "Internet access disabled\n============================= test session starts ==============================\ncollecting ... collected 26 items\n\nastropy/io/ascii/tests/test_html.py::test_soupstring SKIPPED (condit...) [  3%]\nastropy/io/ascii/tests/test_html.py::test_listwriter PASSED              [  7%]\nastropy/io/ascii/tests/test_html.py::test_identify_table SKIPPED (co...) [ 11%]\nastropy/io/ascii/tests/test_html.py::test_missing_data SKIPPED (cond...) [ 15%]\nastropy/io/ascii/tests/test_html.py::test_rename_cols SKIPPED (condi...) [ 19%]\nastropy/io/ascii/tests/test_html.py::test_no_names SKIPPED (conditio...) [ 23%]\nastropy/io/ascii/tests/test_html.py::test_identify_table_fail SKIPPED    [ 26%]\nastropy/io/ascii/tests/test_html.py::test_backend_parsers SKIPPED (c...) [ 30%]\nastropy/io/ascii/tests/test_html.py::test_htmlinputter_no_bs4 PASSED     [ 34%]\nastropy/io/ascii/tests/test_html.py::test_htmlinputter SKIPPED (cond...) [ 38%]\nastropy/io/ascii/tests/test_html.py::test_htmlsplitter SKIPPED (cond...) [ 42%]\nastropy/io/ascii/tests/test_html.py::test_htmlheader_start SKIPPED (...) [ 46%]\nastropy/io/ascii/tests/test_html.py::test_htmldata SKIPPED (conditio...) [ 50%]\nastropy/io/ascii/tests/test_html.py::test_multicolumn_write PASSED       [ 53%]\nastropy/io/ascii/tests/test_html.py::test_multicolumn_write_escape SKIPPED [ 57%]\nastropy/io/ascii/tests/test_html.py::test_write_no_multicols PASSED      [ 61%]\nastropy/io/ascii/tests/test_html.py::test_multicolumn_read SKIPPED (...) [ 65%]\nastropy/io/ascii/tests/test_html.py::test_raw_html_write SKIPPED (co...) [ 69%]\nastropy/io/ascii/tests/test_html.py::test_raw_html_write_clean SKIPPED   [ 73%]\nastropy/io/ascii/tests/test_html.py::test_write_table_html_fill_values PASSED [ 76%]\nastropy/io/ascii/tests/test_html.py::test_write_table_html_fill_values_optional_columns PASSED [ 80%]\nastropy/io/ascii/tests/test_html.py::test_write_table_html_fill_values_masked PASSED [ 84%]\nastropy/io/ascii/tests/test_html.py::test_multicolumn_table_html_fill_values PASSED [ 88%]\nastropy/io/ascii/tests/test_html.py::test_multi_column_write_table_html_fill_values_masked PASSED [ 92%]\nastropy/io/ascii/tests/test_html.py::test_write_table_formatted_columns PASSED [ 96%]\nastropy/io/ascii/tests/test_html.py::test_read_html_unicode SKIPPED      [100%]\n\n======================== 10 passed, 16 skipped in 0.15s ========================\n\n\n<frozen importlib._bootstrap>:228: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 80 from C header, got 96 from PyObject\n",
          "test_files_run": [
            "astropy/io/ascii/tests/test_html.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "astropy__astropy-13579",
      "repo": "astropy/astropy",
      "valid": false,
      "worker": "http://34.59.30.169:8080",
      "duration": 14.154977798461914,
      "test_only": {
        "passed": true,
        "stats": {
          "passed": 40,
          "failed": 0,
          "errors": 0,
          "collected": 41,
          "duration": 6.25,
          "log_tail": "astropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_sanitize_slice[item2-10-expected2] PASSED [  9%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_ellipsis PASSED [ 12%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_pixel_to_world_broadcasting PASSED [ 14%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_world_to_pixel_broadcasting PASSED [ 17%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_spectral_slice PASSED [ 19%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_spectral_range PASSED [ 21%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_celestial_slice PASSED [ 24%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_celestial_range PASSED [ 26%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_celestial_range_rot PASSED [ 29%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_no_array_shape PASSED [ 31%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_ellipsis_none_types PASSED [ 34%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice10-slice20-expected0] PASSED [ 36%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice11-slice21-expected1] PASSED [ 39%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice12-slice22-expected2] PASSED [ 41%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice13-slice23-expected3] PASSED [ 43%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice14-slice24-expected4] PASSED [ 46%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice15-slice25-expected5] PASSED [ 48%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice16-slice26-expected6] PASSED [ 51%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice17-slice27-expected7] PASSED [ 53%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice18-slice28-expected8] PASSED [ 56%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice19-slice29-expected9] PASSED [ 58%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice110-slice210-expected10] PASSED [ 60%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice111-slice211-expected11] PASSED [ 63%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice112-slice212-expected12] PASSED [ 65%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice113-slice213-expected13] PASSED [ 68%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice114-slice214-expected14] PASSED [ 70%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice115-slice215-expected15] PASSED [ 73%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice116-3-3] PASSED [ 75%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice117-3-5] PASSED [ 78%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice118-3-3] PASSED [ 80%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice119-3-5] PASSED [ 82%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_nested_slicing PASSED [ 85%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_too_much_slicing PASSED [ 87%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_1d_sliced_low_level PASSED [ 90%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_dropped_dimensions PASSED [ 92%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_dropped_dimensions_4d PASSED [ 95%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_pixel_to_world_values_different_int_types PASSED [ 97%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_coupled_world_slicing FAILED [100%]\n\n=================================== FAILURES ===================================\n__________________________ test_coupled_world_slicing __________________________\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py:937: in test_coupled_world_slicing\n    assert np.allclose(out_pix[0], 0)\nE   assert False\nE    +  where False = <function allclose at 0x70e1a8bdeeb0>(array(1.81818182e+11), 0)\nE    +    where <function allclose at 0x70e1a8bdeeb0> = np.allclose\n========================= 1 failed, 40 passed in 1.36s =========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 41,
          "failed": 0,
          "errors": 0,
          "collected": 41,
          "duration": 6.33,
          "log_tail": "Internet access disabled\n============================= test session starts ==============================\ncollecting ... collected 41 items\n\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_invalid_slices PASSED [  2%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_sanitize_slice[item0-4-expected0] PASSED [  4%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_sanitize_slice[item1-5-expected1] PASSED [  7%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_sanitize_slice[item2-10-expected2] PASSED [  9%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_ellipsis PASSED [ 12%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_pixel_to_world_broadcasting PASSED [ 14%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_world_to_pixel_broadcasting PASSED [ 17%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_spectral_slice PASSED [ 19%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_spectral_range PASSED [ 21%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_celestial_slice PASSED [ 24%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_celestial_range PASSED [ 26%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_celestial_range_rot PASSED [ 29%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_no_array_shape PASSED [ 31%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_ellipsis_none_types PASSED [ 34%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice10-slice20-expected0] PASSED [ 36%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice11-slice21-expected1] PASSED [ 39%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice12-slice22-expected2] PASSED [ 41%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice13-slice23-expected3] PASSED [ 43%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice14-slice24-expected4] PASSED [ 46%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice15-slice25-expected5] PASSED [ 48%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice16-slice26-expected6] PASSED [ 51%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice17-slice27-expected7] PASSED [ 53%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice18-slice28-expected8] PASSED [ 56%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice19-slice29-expected9] PASSED [ 58%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice110-slice210-expected10] PASSED [ 60%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice111-slice211-expected11] PASSED [ 63%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice112-slice212-expected12] PASSED [ 65%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice113-slice213-expected13] PASSED [ 68%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice114-slice214-expected14] PASSED [ 70%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice115-slice215-expected15] PASSED [ 73%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice116-3-3] PASSED [ 75%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice117-3-5] PASSED [ 78%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice118-3-3] PASSED [ 80%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice119-3-5] PASSED [ 82%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_nested_slicing PASSED [ 85%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_too_much_slicing PASSED [ 87%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_1d_sliced_low_level PASSED [ 90%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_dropped_dimensions PASSED [ 92%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_dropped_dimensions_4d PASSED [ 95%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_pixel_to_world_values_different_int_types PASSED [ 97%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_coupled_world_slicing PASSED [100%]\n\n============================== 41 passed in 1.38s ==============================\n\n",
          "test_files_run": [
            "astropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got True\u2192True"
    },
    {
      "instance_id": "astropy__astropy-13977",
      "repo": "astropy/astropy",
      "valid": true,
      "worker": "http://34.59.30.169:8080",
      "duration": 15.830617189407349,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 322,
          "failed": 20,
          "errors": 0,
          "collected": 347,
          "duration": 8.2,
          "log_tail": "\u001b[31m\u001b[1m_ TestUfuncReturnsNotImplemented.TestBinaryUfuncs.test_full[empty-duck_quantity1-quantity0-multiply] _\u001b[0m\n\u001b[1m\u001b[31mastropy/units/tests/test_quantity_ufuncs.py\u001b[0m:1409: in test_full\n    result = ufunc(quantity, duck_quantity, out=out)\n\u001b[1m\u001b[31mastropy/units/quantity.py\u001b[0m:652: in __array_ufunc__\n    out_array = check_output(out, unit, inputs, function=function)\n\u001b[1m\u001b[31mastropy/units/quantity_helper/converters.py\u001b[0m:384: in check_output\n    raise UnitTypeError(\n\u001b[1m\u001b[31mE   astropy.units.core.UnitTypeError: Cannot store quantity with dimension resulting from multiply function in a non-Quantity instance.\u001b[0m\n\u001b[31m\u001b[1m_ TestUfuncReturnsNotImplemented.TestBinaryUfuncs.test_full[empty-duck_quantity1-quantity0-less] _\u001b[0m\n\u001b[1m\u001b[31mastropy/units/tests/test_quantity_ufuncs.py\u001b[0m:1409: in test_full\n    result = ufunc(quantity, duck_quantity, out=out)\n\u001b[1m\u001b[31mastropy/units/quantity.py\u001b[0m:670: in __array_ufunc__\n    arrays.append(converter(input_) if converter else input_)\n\u001b[1m\u001b[31mastropy/units/core.py\u001b[0m:1073: in <lambda>\n    return lambda val: scale * _condition_arg(val)\n\u001b[1m\u001b[31mastropy/units/core.py\u001b[0m:2629: in _condition_arg\n    raise ValueError(\n\u001b[1m\u001b[31mE   ValueError: Value not scalar compatible or convertible to an int, float, or complex array\u001b[0m\n\u001b[31m\u001b[1m_ TestUfuncReturnsNotImplemented.TestBinaryUfuncs.test_full[empty-duck_quantity1-quantity1-add] _\u001b[0m\n\u001b[1m\u001b[31mastropy/units/tests/test_quantity_ufuncs.py\u001b[0m:1409: in test_full\n    result = ufunc(quantity, duck_quantity, out=out)\n\u001b[1m\u001b[31mastropy/units/quantity.py\u001b[0m:652: in __array_ufunc__\n    out_array = check_output(out, unit, inputs, function=function)\n\u001b[1m\u001b[31mastropy/units/quantity_helper/converters.py\u001b[0m:384: in check_output\n    raise UnitTypeError(\n\u001b[1m\u001b[31mE   astropy.units.core.UnitTypeError: Cannot store quantity with dimension resulting from add function in a non-Quantity instance.\u001b[0m\n\u001b[31m\u001b[1m_ TestUfuncReturnsNotImplemented.TestBinaryUfuncs.test_full[empty-duck_quantity1-quantity1-multiply] _\u001b[0m\n\u001b[1m\u001b[31mastropy/units/tests/test_quantity_ufuncs.py\u001b[0m:1409: in test_full\n    result = ufunc(quantity, duck_quantity, out=out)\n\u001b[1m\u001b[31mastropy/units/quantity.py\u001b[0m:652: in __array_ufunc__\n    out_array = check_output(out, unit, inputs, function=function)\n\u001b[1m\u001b[31mastropy/units/quantity_helper/converters.py\u001b[0m:384: in check_output\n    raise UnitTypeError(\n\u001b[1m\u001b[31mE   astropy.units.core.UnitTypeError: Cannot store quantity with dimension resulting from multiply function in a non-Quantity instance.\u001b[0m\n\u001b[31m\u001b[1m_ TestUfuncReturnsNotImplemented.TestBinaryUfuncs.test_full[empty-duck_quantity1-quantity1-less] _\u001b[0m\n\u001b[1m\u001b[31mastropy/units/tests/test_quantity_ufuncs.py\u001b[0m:1409: in test_full\n    result = ufunc(quantity, duck_quantity, out=out)\n\u001b[1m\u001b[31mastropy/units/quantity.py\u001b[0m:670: in __array_ufunc__\n    arrays.append(converter(input_) if converter else input_)\n\u001b[1m\u001b[31mastropy/units/core.py\u001b[0m:1073: in <lambda>\n    return lambda val: scale * _condition_arg(val)\n\u001b[1m\u001b[31mastropy/units/core.py\u001b[0m:2629: in _condition_arg\n    raise ValueError(\n\u001b[1m\u001b[31mE   ValueError: Value not scalar compatible or convertible to an int, float, or complex array\u001b[0m\n\u001b[31m============= \u001b[31m\u001b[1m20 failed\u001b[0m, \u001b[32m322 passed\u001b[0m, \u001b[33m4 skipped\u001b[0m, \u001b[33m1 xfailed\u001b[0m\u001b[31m in 3.73s\u001b[0m\u001b[31m =============\u001b[0m\n\n\n<frozen importlib._bootstrap>:228: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 80 from C header, got 96 from PyObject\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/units/tests/test_quantity.py astropy/units/tests/test_quantity_ufuncs.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/units/tests/test_quantity.py",
            "astropy/units/tests/test_quantity_ufuncs.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 342,
          "failed": 0,
          "errors": 0,
          "collected": 347,
          "duration": 6.15,
          "log_tail": "astropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestUnaryUfuncs::test_full[None-duck_quantity0-negative] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestUnaryUfuncs::test_full[None-duck_quantity0-absolute] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestUnaryUfuncs::test_full[None-duck_quantity1-negative] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestUnaryUfuncs::test_full[None-duck_quantity1-absolute] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestUnaryUfuncs::test_full[empty-duck_quantity0-negative] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestUnaryUfuncs::test_full[empty-duck_quantity0-absolute] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestUnaryUfuncs::test_full[empty-duck_quantity1-negative] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestUnaryUfuncs::test_full[empty-duck_quantity1-absolute] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestBinaryUfuncs::test_basic[duck_quantity0-quantity0-add] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestBinaryUfuncs::test_basic[duck_quantity0-quantity0-multiply] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestBinaryUfuncs::test_basic[duck_quantity0-quantity0-less] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestBinaryUfuncs::test_basic[duck_quantity0-quantity1-add] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestBinaryUfuncs::test_basic[duck_quantity0-quantity1-multiply] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestBinaryUfuncs::test_basic[duck_quantity0-quantity1-less] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestBinaryUfuncs::test_basic[duck_quantity1-quantity0-add] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestBinaryUfuncs::test_basic[duck_quantity1-quantity0-multiply] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestBinaryUfuncs::test_basic[duck_quantity1-quantity0-less] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestBinaryUfuncs::test_basic[duck_quantity1-quantity1-add] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestBinaryUfuncs::test_basic[duck_quantity1-quantity1-multiply] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestBinaryUfuncs::test_basic[duck_quantity1-quantity1-less] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestBinaryUfuncs::test_full[None-duck_quantity0-quantity0-add] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestBinaryUfuncs::test_full[None-duck_quantity0-quantity0-multiply] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestBinaryUfuncs::test_full[None-duck_quantity0-quantity0-less] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestBinaryUfuncs::test_full[None-duck_quantity0-quantity1-add] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestBinaryUfuncs::test_full[None-duck_quantity0-quantity1-multiply] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestBinaryUfuncs::test_full[None-duck_quantity0-quantity1-less] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestBinaryUfuncs::test_full[None-duck_quantity1-quantity0-add] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestBinaryUfuncs::test_full[None-duck_quantity1-quantity0-multiply] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestBinaryUfuncs::test_full[None-duck_quantity1-quantity0-less] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestBinaryUfuncs::test_full[None-duck_quantity1-quantity1-add] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestBinaryUfuncs::test_full[None-duck_quantity1-quantity1-multiply] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestBinaryUfuncs::test_full[None-duck_quantity1-quantity1-less] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestBinaryUfuncs::test_full[empty-duck_quantity0-quantity0-add] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestBinaryUfuncs::test_full[empty-duck_quantity0-quantity0-multiply] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestBinaryUfuncs::test_full[empty-duck_quantity0-quantity0-less] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestBinaryUfuncs::test_full[empty-duck_quantity0-quantity1-add] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestBinaryUfuncs::test_full[empty-duck_quantity0-quantity1-multiply] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestBinaryUfuncs::test_full[empty-duck_quantity0-quantity1-less] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestBinaryUfuncs::test_full[empty-duck_quantity1-quantity0-add] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestBinaryUfuncs::test_full[empty-duck_quantity1-quantity0-multiply] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestBinaryUfuncs::test_full[empty-duck_quantity1-quantity0-less] \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestBinaryUfuncs::test_full[empty-duck_quantity1-quantity1-add] \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestBinaryUfuncs::test_full[empty-duck_quantity1-quantity1-multiply] \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\nastropy/units/tests/test_quantity_ufuncs.py::TestUfuncReturnsNotImplemented::TestBinaryUfuncs::test_full[empty-duck_quantity1-quantity1-less] \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n\n\u001b[32m================== \u001b[32m\u001b[1m342 passed\u001b[0m, \u001b[33m4 skipped\u001b[0m, \u001b[33m1 xfailed\u001b[0m\u001b[32m in 1.40s\u001b[0m\u001b[32m ===================\u001b[0m\n\n\n<frozen importlib._bootstrap>:228: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 80 from C header, got 96 from PyObject\n",
          "test_files_run": [
            "astropy/units/tests/test_quantity.py",
            "astropy/units/tests/test_quantity_ufuncs.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "astropy__astropy-14096",
      "repo": "astropy/astropy",
      "valid": false,
      "worker": "http://34.59.30.169:8080",
      "duration": 19.70702290534973,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 426,
          "failed": 2,
          "errors": 0,
          "collected": 432,
          "duration": 10.09,
          "log_tail": "\u001b[31m\u001b[1m_______________________________ test_repr_altaz ________________________________\u001b[0m\n\u001b[1m\u001b[31mastropy/time/core.py\u001b[0m:3311: in update_leap_seconds\n    table = iers.LeapSeconds.auto_open(files)\n\u001b[1m\u001b[31mastropy/utils/iers/iers.py\u001b[0m:1142: in auto_open\n    warn(\"leap-second file is expired.\", IERSStaleWarning)\n\u001b[1m\u001b[31mE   astropy.utils.iers.iers.IERSStaleWarning: leap-second file is expired.\u001b[0m\n\n\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\n\u001b[1m\u001b[31mastropy/coordinates/tests/test_sky_coord.py\u001b[0m:783: in test_repr_altaz\n    sc4 = sc2.transform_to(AltAz(location=loc, obstime=time))\n\u001b[1m\u001b[31mastropy/coordinates/sky_coordinate.py\u001b[0m:704: in transform_to\n    new_coord = trans(self.frame, generic_frame)\n\u001b[1m\u001b[31mastropy/coordinates/transformations.py\u001b[0m:1575: in __call__\n    curr_coord = t(curr_coord, curr_toframe)\n\u001b[1m\u001b[31mastropy/coordinates/transformations.py\u001b[0m:1144: in __call__\n    return supcall(fromcoord, toframe)\n\u001b[1m\u001b[31mastropy/coordinates/builtin_frames/icrs_observed_transforms.py\u001b[0m:33: in icrs_to_observed\n    astrom = erfa_astrom.get().apco(observed_frame)\n\u001b[1m\u001b[31mastropy/coordinates/erfa_astrom.py\u001b[0m:52: in apco\n    jd1_tt, jd2_tt = get_jd12(obstime, \"tt\")\n\u001b[1m\u001b[31mastropy/coordinates/builtin_frames/utils.py\u001b[0m:115: in get_jd12\n    newtime = getattr(time, scale)\n\u001b[1m\u001b[31mastropy/time/core.py\u001b[0m:1635: in __getattr__\n    tm._set_scale(attr)\n\u001b[1m\u001b[31mastropy/time/core.py\u001b[0m:742: in _set_scale\n    _check_leapsec()\n\u001b[1m\u001b[31mastropy/time/core.py\u001b[0m:3282: in _check_leapsec\n    update_leap_seconds()\n\u001b[1m\u001b[31mastropy/time/core.py\u001b[0m:3315: in update_leap_seconds\n    warn(\n\u001b[1m\u001b[31mE   astropy.utils.exceptions.AstropyWarning: leap-second auto-update failed due to the following exception: IERSStaleWarning('leap-second file is expired.')\u001b[0m\n\u001b[31m\u001b[1m____________________ test_subclass_property_exception_error ____________________\u001b[0m\n\u001b[1m\u001b[31mastropy/coordinates/tests/test_sky_coord.py\u001b[0m:2185: in test_subclass_property_exception_error\n    c.prop\n\u001b[1m\u001b[31mastropy/coordinates/sky_coordinate.py\u001b[0m:898: in __getattr__\n    raise AttributeError(\n\u001b[1m\u001b[31mE   AttributeError: 'custom_coord' object has no attribute 'prop'\u001b[0m\n\n\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\n\u001b[1m\u001b[31mastropy/coordinates/tests/test_sky_coord.py\u001b[0m:2185: in test_subclass_property_exception_error\n    c.prop\n\u001b[1m\u001b[31mE   AssertionError: Regex pattern did not match.\u001b[0m\n\u001b[1m\u001b[31mE    Regex: 'random_attr'\u001b[0m\n\u001b[1m\u001b[31mE    Input: \"'custom_coord' object has no attribute 'prop'\"\u001b[0m\n\u001b[31m============= \u001b[31m\u001b[1m2 failed\u001b[0m, \u001b[32m426 passed\u001b[0m, \u001b[33m3 skipped\u001b[0m, \u001b[33m1 xfailed\u001b[0m\u001b[31m in 5.40s\u001b[0m\u001b[31m ==============\u001b[0m\n\n\n<frozen importlib._bootstrap>:228: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 80 from C header, got 96 from PyObject\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/coordinates/tests/test_sky_coord.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/coordinates/tests/test_sky_coord.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 427,
          "failed": 1,
          "errors": 0,
          "collected": 432,
          "duration": 8.22,
          "log_tail": "astropy/coordinates/tests/test_sky_coord.py::test_extra_attributes \u001b[32mPASSED\u001b[0m\u001b[31m [ 97%]\u001b[0m\nastropy/coordinates/tests/test_sky_coord.py::test_apply_space_motion \u001b[32mPASSED\u001b[0m\u001b[31m [ 97%]\u001b[0m\nastropy/coordinates/tests/test_sky_coord.py::test_custom_frame_skycoord \u001b[32mPASSED\u001b[0m\u001b[31m [ 98%]\u001b[0m\nastropy/coordinates/tests/test_sky_coord.py::test_user_friendly_pm_error \u001b[32mPASSED\u001b[0m\u001b[31m [ 98%]\u001b[0m\nastropy/coordinates/tests/test_sky_coord.py::test_contained_by \u001b[32mPASSED\u001b[0m\u001b[31m    [ 98%]\u001b[0m\nastropy/coordinates/tests/test_sky_coord.py::test_none_differential_type \u001b[32mPASSED\u001b[0m\u001b[31m [ 98%]\u001b[0m\nastropy/coordinates/tests/test_sky_coord.py::test_multiple_aliases \u001b[32mPASSED\u001b[0m\u001b[31m [ 99%]\u001b[0m\nastropy/coordinates/tests/test_sky_coord.py::test_passing_inconsistent_coordinates_and_units_raises_helpful_error[kwargs0-Unit 'deg' \\\\(angle\\\\) could not be applied to 'distance'. ] \u001b[32mPASSED\u001b[0m\u001b[31m [ 99%]\u001b[0m\nastropy/coordinates/tests/test_sky_coord.py::test_passing_inconsistent_coordinates_and_units_raises_helpful_error[kwargs1-Unit 'deg' \\\\(angle\\\\) could not be applied to 'rho'. ] \u001b[32mPASSED\u001b[0m\u001b[31m [ 99%]\u001b[0m\nastropy/coordinates/tests/test_sky_coord.py::test_match_to_catalog_3d_and_sky \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 99%]\u001b[0m\nastropy/coordinates/tests/test_sky_coord.py::test_subclass_property_exception_error \u001b[32mPASSED\u001b[0m\u001b[31m [100%]\u001b[0m\n\n=================================== FAILURES ===================================\n\u001b[31m\u001b[1m_______________________________ test_repr_altaz ________________________________\u001b[0m\n\u001b[1m\u001b[31mastropy/time/core.py\u001b[0m:3311: in update_leap_seconds\n    table = iers.LeapSeconds.auto_open(files)\n\u001b[1m\u001b[31mastropy/utils/iers/iers.py\u001b[0m:1142: in auto_open\n    warn(\"leap-second file is expired.\", IERSStaleWarning)\n\u001b[1m\u001b[31mE   astropy.utils.iers.iers.IERSStaleWarning: leap-second file is expired.\u001b[0m\n\n\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\n\u001b[1m\u001b[31mastropy/coordinates/tests/test_sky_coord.py\u001b[0m:783: in test_repr_altaz\n    sc4 = sc2.transform_to(AltAz(location=loc, obstime=time))\n\u001b[1m\u001b[31mastropy/coordinates/sky_coordinate.py\u001b[0m:704: in transform_to\n    new_coord = trans(self.frame, generic_frame)\n\u001b[1m\u001b[31mastropy/coordinates/transformations.py\u001b[0m:1575: in __call__\n    curr_coord = t(curr_coord, curr_toframe)\n\u001b[1m\u001b[31mastropy/coordinates/transformations.py\u001b[0m:1144: in __call__\n    return supcall(fromcoord, toframe)\n\u001b[1m\u001b[31mastropy/coordinates/builtin_frames/icrs_observed_transforms.py\u001b[0m:33: in icrs_to_observed\n    astrom = erfa_astrom.get().apco(observed_frame)\n\u001b[1m\u001b[31mastropy/coordinates/erfa_astrom.py\u001b[0m:52: in apco\n    jd1_tt, jd2_tt = get_jd12(obstime, \"tt\")\n\u001b[1m\u001b[31mastropy/coordinates/builtin_frames/utils.py\u001b[0m:115: in get_jd12\n    newtime = getattr(time, scale)\n\u001b[1m\u001b[31mastropy/time/core.py\u001b[0m:1635: in __getattr__\n    tm._set_scale(attr)\n\u001b[1m\u001b[31mastropy/time/core.py\u001b[0m:742: in _set_scale\n    _check_leapsec()\n\u001b[1m\u001b[31mastropy/time/core.py\u001b[0m:3282: in _check_leapsec\n    update_leap_seconds()\n\u001b[1m\u001b[31mastropy/time/core.py\u001b[0m:3315: in update_leap_seconds\n    warn(\n\u001b[1m\u001b[31mE   astropy.utils.exceptions.AstropyWarning: leap-second auto-update failed due to the following exception: IERSStaleWarning('leap-second file is expired.')\u001b[0m\n\u001b[31m============= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m427 passed\u001b[0m, \u001b[33m3 skipped\u001b[0m, \u001b[33m1 xfailed\u001b[0m\u001b[31m in 3.91s\u001b[0m\u001b[31m ==============\u001b[0m\n\n\n<frozen importlib._bootstrap>:228: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 80 from C header, got 96 from PyObject\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/coordinates/tests/test_sky_coord.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/coordinates/tests/test_sky_coord.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "astropy__astropy-14182",
      "repo": "astropy/astropy",
      "valid": true,
      "worker": "http://34.59.30.169:8080",
      "duration": 10.914284229278564,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 9,
          "failed": 1,
          "errors": 0,
          "collected": 10,
          "duration": 4.87,
          "log_tail": "Internet access disabled\n\u001b[1m============================= test session starts ==============================\u001b[0m\n\u001b[1mcollecting ... \u001b[0mcollected 10 items\n\nastropy/io/ascii/tests/test_rst.py::test_read_normal \u001b[32mPASSED\u001b[0m\u001b[32m              [ 10%]\u001b[0m\nastropy/io/ascii/tests/test_rst.py::test_read_normal_names \u001b[32mPASSED\u001b[0m\u001b[32m        [ 20%]\u001b[0m\nastropy/io/ascii/tests/test_rst.py::test_read_normal_names_include \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\nastropy/io/ascii/tests/test_rst.py::test_read_normal_exclude \u001b[32mPASSED\u001b[0m\u001b[32m      [ 40%]\u001b[0m\nastropy/io/ascii/tests/test_rst.py::test_read_unbounded_right_column \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\nastropy/io/ascii/tests/test_rst.py::test_read_unbounded_right_column_header \u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\nastropy/io/ascii/tests/test_rst.py::test_read_right_indented_table \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\nastropy/io/ascii/tests/test_rst.py::test_trailing_spaces_in_row_definition \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\nastropy/io/ascii/tests/test_rst.py::test_write_normal \u001b[32mPASSED\u001b[0m\u001b[32m             [ 90%]\u001b[0m\nastropy/io/ascii/tests/test_rst.py::test_rst_with_header_rows \u001b[31mFAILED\u001b[0m\u001b[31m     [100%]\u001b[0m\n\n=================================== FAILURES ===================================\n\u001b[31m\u001b[1m__________________________ test_rst_with_header_rows ___________________________\u001b[0m\n\u001b[1m\u001b[31mastropy/io/ascii/tests/test_rst.py\u001b[0m:206: in test_rst_with_header_rows\n    tbl = QTable.read(lines, format=\"ascii.rst\", header_rows=[\"name\", \"unit\", \"dtype\"])\n\u001b[1m\u001b[31mastropy/table/connect.py\u001b[0m:62: in __call__\n    out = self.registry.read(cls, *args, **kwargs)\n\u001b[1m\u001b[31mastropy/io/registry/core.py\u001b[0m:219: in read\n    data = reader(*args, **kwargs)\n\u001b[1m\u001b[31mastropy/io/ascii/connect.py\u001b[0m:19: in io_read\n    return read(filename, **kwargs)\n\u001b[1m\u001b[31mastropy/io/ascii/ui.py\u001b[0m:425: in read\n    reader = get_reader(**new_kwargs)\n\u001b[1m\u001b[31mastropy/io/ascii/ui.py\u001b[0m:183: in get_reader\n    reader = core._get_reader(Reader, Inputter=Inputter, Outputter=Outputter, **kwargs)\n\u001b[1m\u001b[31mastropy/io/ascii/core.py\u001b[0m:1692: in _get_reader\n    reader = Reader(**reader_kwargs)\n\u001b[1m\u001b[31mE   TypeError: __init__() got an unexpected keyword argument 'header_rows'\u001b[0m\n\u001b[31m========================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m9 passed\u001b[0m\u001b[31m in 0.08s\u001b[0m\u001b[31m ==========================\u001b[0m\n\n\n<frozen importlib._bootstrap>:228: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 80 from C header, got 96 from PyObject\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/io/ascii/tests/test_rst.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/io/ascii/tests/test_rst.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 10,
          "failed": 0,
          "errors": 0,
          "collected": 10,
          "duration": 4.54,
          "log_tail": "Internet access disabled\n\u001b[1m============================= test session starts ==============================\u001b[0m\n\u001b[1mcollecting ... \u001b[0mcollected 10 items\n\nastropy/io/ascii/tests/test_rst.py::test_read_normal \u001b[32mPASSED\u001b[0m\u001b[32m              [ 10%]\u001b[0m\nastropy/io/ascii/tests/test_rst.py::test_read_normal_names \u001b[32mPASSED\u001b[0m\u001b[32m        [ 20%]\u001b[0m\nastropy/io/ascii/tests/test_rst.py::test_read_normal_names_include \u001b[32mPASSED\u001b[0m\u001b[32m [ 30%]\u001b[0m\nastropy/io/ascii/tests/test_rst.py::test_read_normal_exclude \u001b[32mPASSED\u001b[0m\u001b[32m      [ 40%]\u001b[0m\nastropy/io/ascii/tests/test_rst.py::test_read_unbounded_right_column \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\nastropy/io/ascii/tests/test_rst.py::test_read_unbounded_right_column_header \u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\nastropy/io/ascii/tests/test_rst.py::test_read_right_indented_table \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\nastropy/io/ascii/tests/test_rst.py::test_trailing_spaces_in_row_definition \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\nastropy/io/ascii/tests/test_rst.py::test_write_normal \u001b[32mPASSED\u001b[0m\u001b[32m             [ 90%]\u001b[0m\nastropy/io/ascii/tests/test_rst.py::test_rst_with_header_rows \u001b[32mPASSED\u001b[0m\u001b[32m     [100%]\u001b[0m\n\n\u001b[32m============================== \u001b[32m\u001b[1m10 passed\u001b[0m\u001b[32m in 0.04s\u001b[0m\u001b[32m ==============================\u001b[0m\n\n\n<frozen importlib._bootstrap>:228: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 80 from C header, got 96 from PyObject\n",
          "test_files_run": [
            "astropy/io/ascii/tests/test_rst.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "astropy__astropy-14309",
      "repo": "astropy/astropy",
      "valid": true,
      "worker": "http://34.59.30.169:8080",
      "duration": 17.387204885482788,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 141,
          "failed": 1,
          "errors": 0,
          "collected": 155,
          "duration": 8.62,
          "log_tail": "astropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[Table-name_col17] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[Table-name_col18] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[Table-name_col19] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 78%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[Table-name_col20] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 79%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col3] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col5] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col6] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col7] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col9] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col10] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col11] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col12] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col14] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col16] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col17] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col18] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col19] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 92%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col20] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 92%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_unsupported_mixin[name_col0] \u001b[33mXFAIL\u001b[0m\u001b[32m [ 93%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_unsupported_mixin[name_col1] \u001b[33mXFAIL\u001b[0m\u001b[32m [ 94%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_unsupported_mixin[name_col2] \u001b[33mXFAIL\u001b[0m\u001b[32m [ 94%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_unsupported_mixin[name_col3] \u001b[33mXFAIL\u001b[0m\u001b[32m [ 95%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_unsupported_mixin[name_col4] \u001b[33mXFAIL\u001b[0m\u001b[32m [ 96%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_info_attributes_with_no_mixins \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_round_trip_masked_table_serialize_mask[set_cols] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_round_trip_masked_table_serialize_mask[names] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_round_trip_masked_table_serialize_mask[class] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_meta_not_modified \u001b[32mPASSED\u001b[0m\u001b[32m     [ 99%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_is_fits_gh_14305 \u001b[31mFAILED\u001b[0m\u001b[31m      [100%]\u001b[0m\n\n=================================== FAILURES ===================================\n\u001b[31m\u001b[1m____________________________ test_is_fits_gh_14305 _____________________________\u001b[0m\n\u001b[1m\u001b[31mastropy/io/fits/tests/test_connect.py\u001b[0m:1016: in test_is_fits_gh_14305\n    assert not connect.is_fits(\"\", \"foo.bar\", None)\n\u001b[1m\u001b[31mastropy/io/fits/connect.py\u001b[0m:72: in is_fits\n    return isinstance(args[0], (HDUList, TableHDU, BinTableHDU, GroupsHDU))\n\u001b[1m\u001b[31mE   IndexError: tuple index out of range\u001b[0m\n\u001b[31m============= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m141 passed\u001b[0m, \u001b[33m8 skipped\u001b[0m, \u001b[33m5 xfailed\u001b[0m\u001b[31m in 3.94s\u001b[0m\u001b[31m ==============\u001b[0m\n\n\n<frozen importlib._bootstrap>:228: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 80 from C header, got 96 from PyObject\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/io/fits/tests/test_connect.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/io/fits/tests/test_connect.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 142,
          "failed": 0,
          "errors": 0,
          "collected": 155,
          "duration": 7.21,
          "log_tail": "astropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[Table-name_col9] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 72%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[Table-name_col10] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 72%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[Table-name_col11] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 73%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[Table-name_col12] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 74%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[Table-name_col13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 74%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[Table-name_col14] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[Table-name_col15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[Table-name_col16] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[Table-name_col17] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[Table-name_col18] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[Table-name_col19] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 78%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[Table-name_col20] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 79%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col3] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col5] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col6] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col7] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col9] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col10] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col11] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col12] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col14] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col15] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col16] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col17] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col18] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col19] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 92%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_mixins_per_column[QTable-name_col20] \u001b[33mSKIPPED\u001b[0m\u001b[32m [ 92%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_unsupported_mixin[name_col0] \u001b[33mXFAIL\u001b[0m\u001b[32m [ 93%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_unsupported_mixin[name_col1] \u001b[33mXFAIL\u001b[0m\u001b[32m [ 94%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_unsupported_mixin[name_col2] \u001b[33mXFAIL\u001b[0m\u001b[32m [ 94%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_unsupported_mixin[name_col3] \u001b[33mXFAIL\u001b[0m\u001b[32m [ 95%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_fits_unsupported_mixin[name_col4] \u001b[33mXFAIL\u001b[0m\u001b[32m [ 96%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_info_attributes_with_no_mixins \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_round_trip_masked_table_serialize_mask[set_cols] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_round_trip_masked_table_serialize_mask[names] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_round_trip_masked_table_serialize_mask[class] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_meta_not_modified \u001b[32mPASSED\u001b[0m\u001b[32m     [ 99%]\u001b[0m\nastropy/io/fits/tests/test_connect.py::test_is_fits_gh_14305 \u001b[32mPASSED\u001b[0m\u001b[32m      [100%]\u001b[0m\n\n\u001b[32m================== \u001b[32m\u001b[1m142 passed\u001b[0m, \u001b[33m8 skipped\u001b[0m, \u001b[33m5 xfailed\u001b[0m\u001b[32m in 2.95s\u001b[0m\u001b[32m ===================\u001b[0m\n\n\n<frozen importlib._bootstrap>:228: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 80 from C header, got 96 from PyObject\n",
          "test_files_run": [
            "astropy/io/fits/tests/test_connect.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "astropy__astropy-14365",
      "repo": "astropy/astropy",
      "valid": true,
      "worker": "http://34.59.30.169:8080",
      "duration": 11.378222703933716,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 8,
          "failed": 1,
          "errors": 0,
          "collected": 9,
          "duration": 5.14,
          "log_tail": "Internet access disabled\n\u001b[1m============================= test session starts ==============================\u001b[0m\n\u001b[1mcollecting ... \u001b[0mcollected 9 items\n\nastropy/io/ascii/tests/test_qdp.py::test_get_tables_from_qdp_file \u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\nastropy/io/ascii/tests/test_qdp.py::test_roundtrip[False] \u001b[32mPASSED\u001b[0m\u001b[32m         [ 22%]\u001b[0m\nastropy/io/ascii/tests/test_qdp.py::test_roundtrip[True] \u001b[31mFAILED\u001b[0m\u001b[31m          [ 33%]\u001b[0m\nastropy/io/ascii/tests/test_qdp.py::test_read_example \u001b[32mPASSED\u001b[0m\u001b[31m             [ 44%]\u001b[0m\nastropy/io/ascii/tests/test_qdp.py::test_roundtrip_example \u001b[32mPASSED\u001b[0m\u001b[31m        [ 55%]\u001b[0m\nastropy/io/ascii/tests/test_qdp.py::test_roundtrip_example_comma \u001b[32mPASSED\u001b[0m\u001b[31m  [ 66%]\u001b[0m\nastropy/io/ascii/tests/test_qdp.py::test_read_write_simple \u001b[32mPASSED\u001b[0m\u001b[31m        [ 77%]\u001b[0m\nastropy/io/ascii/tests/test_qdp.py::test_read_write_simple_specify_name \u001b[32mPASSED\u001b[0m\u001b[31m [ 88%]\u001b[0m\nastropy/io/ascii/tests/test_qdp.py::test_get_lines_from_qdp \u001b[32mPASSED\u001b[0m\u001b[31m       [100%]\u001b[0m\n\n=================================== FAILURES ===================================\n\u001b[31m\u001b[1m_____________________________ test_roundtrip[True] _____________________________\u001b[0m\n\u001b[1m\u001b[31mastropy/io/ascii/tests/test_qdp.py\u001b[0m:93: in test_roundtrip\n    table = _read_table_qdp(path, names=[\"MJD\", \"Rate\"], table_id=0)\n\u001b[1m\u001b[31mastropy/io/ascii/qdp.py\u001b[0m:418: in _read_table_qdp\n    tables = _get_tables_from_qdp_file(\n\u001b[1m\u001b[31mastropy/io/ascii/qdp.py\u001b[0m:259: in _get_tables_from_qdp_file\n    contents, ncol = _get_type_from_list_of_lines(lines, delimiter=delimiter)\n\u001b[1m\u001b[31mastropy/io/ascii/qdp.py\u001b[0m:122: in _get_type_from_list_of_lines\n    types = [_line_type(line, delimiter=delimiter) for line in lines]\n\u001b[1m\u001b[31mastropy/io/ascii/qdp.py\u001b[0m:122: in <listcomp>\n    types = [_line_type(line, delimiter=delimiter) for line in lines]\n\u001b[1m\u001b[31mastropy/io/ascii/qdp.py\u001b[0m:78: in _line_type\n    raise ValueError(f\"Unrecognized QDP line: {line}\")\n\u001b[1m\u001b[31mE   ValueError: Unrecognized QDP line: read terr 1\u001b[0m\n\u001b[31m========================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m8 passed\u001b[0m\u001b[31m in 0.17s\u001b[0m\u001b[31m ==========================\u001b[0m\n\n\n<frozen importlib._bootstrap>:228: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 80 from C header, got 96 from PyObject\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/io/ascii/tests/test_qdp.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/io/ascii/tests/test_qdp.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 9,
          "failed": 0,
          "errors": 0,
          "collected": 9,
          "duration": 4.71,
          "log_tail": "Internet access disabled\n\u001b[1m============================= test session starts ==============================\u001b[0m\n\u001b[1mcollecting ... \u001b[0mcollected 9 items\n\nastropy/io/ascii/tests/test_qdp.py::test_get_tables_from_qdp_file \u001b[32mPASSED\u001b[0m\u001b[32m [ 11%]\u001b[0m\nastropy/io/ascii/tests/test_qdp.py::test_roundtrip[False] \u001b[32mPASSED\u001b[0m\u001b[32m         [ 22%]\u001b[0m\nastropy/io/ascii/tests/test_qdp.py::test_roundtrip[True] \u001b[32mPASSED\u001b[0m\u001b[32m          [ 33%]\u001b[0m\nastropy/io/ascii/tests/test_qdp.py::test_read_example \u001b[32mPASSED\u001b[0m\u001b[32m             [ 44%]\u001b[0m\nastropy/io/ascii/tests/test_qdp.py::test_roundtrip_example \u001b[32mPASSED\u001b[0m\u001b[32m        [ 55%]\u001b[0m\nastropy/io/ascii/tests/test_qdp.py::test_roundtrip_example_comma \u001b[32mPASSED\u001b[0m\u001b[32m  [ 66%]\u001b[0m\nastropy/io/ascii/tests/test_qdp.py::test_read_write_simple \u001b[32mPASSED\u001b[0m\u001b[32m        [ 77%]\u001b[0m\nastropy/io/ascii/tests/test_qdp.py::test_read_write_simple_specify_name \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\nastropy/io/ascii/tests/test_qdp.py::test_get_lines_from_qdp \u001b[32mPASSED\u001b[0m\u001b[32m       [100%]\u001b[0m\n\n\u001b[32m============================== \u001b[32m\u001b[1m9 passed\u001b[0m\u001b[32m in 0.08s\u001b[0m\u001b[32m ===============================\u001b[0m\n\n\n<frozen importlib._bootstrap>:228: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 80 from C header, got 96 from PyObject\n",
          "test_files_run": [
            "astropy/io/ascii/tests/test_qdp.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "astropy__astropy-14369",
      "repo": "astropy/astropy",
      "valid": true,
      "worker": "http://34.59.30.169:8080",
      "duration": 14.370269298553467,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 735,
          "failed": 3,
          "errors": 0,
          "collected": 738,
          "duration": 6.94,
          "log_tail": "astropy/units/tests/test_format.py::test_unicode[\\xc5-unit14] \u001b[32mPASSED\u001b[0m\u001b[31m     [ 96%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode[A\\u030a-unit15] \u001b[32mPASSED\u001b[0m\u001b[31m  [ 97%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode[m\\u212b-unit16] \u001b[32mPASSED\u001b[0m\u001b[31m  [ 97%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode[\\xb0C-unit17] \u001b[32mPASSED\u001b[0m\u001b[31m    [ 97%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode[\\xb0-unit18] \u001b[32mPASSED\u001b[0m\u001b[31m     [ 97%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode[M\\u2299-unit19] \u001b[32mPASSED\u001b[0m\u001b[31m  [ 97%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode[L\\u2609-unit20] \u001b[32mPASSED\u001b[0m\u001b[31m  [ 97%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode[M\\u2295-unit21] \u001b[32mPASSED\u001b[0m\u001b[31m  [ 97%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode[M\\u2641-unit22] \u001b[32mPASSED\u001b[0m\u001b[31m  [ 97%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode[R\\u2643-unit23] \u001b[32mPASSED\u001b[0m\u001b[31m  [ 98%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode[\\u2032-unit24] \u001b[32mPASSED\u001b[0m\u001b[31m   [ 98%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode[R\\u221e-unit25] \u001b[32mPASSED\u001b[0m\u001b[31m  [ 98%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode[M\\u209a-unit26] \u001b[32mPASSED\u001b[0m\u001b[31m  [ 98%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode_failures[g\\xb5] \u001b[32mPASSED\u001b[0m\u001b[31m  [ 98%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode_failures[g\\u2212] \u001b[32mPASSED\u001b[0m\u001b[31m [ 98%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode_failures[m\\u207b1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 98%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode_failures[m+\\xb9] \u001b[32mPASSED\u001b[0m\u001b[31m [ 99%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode_failures[m\\u2212\\xb9] \u001b[32mPASSED\u001b[0m\u001b[31m [ 99%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode_failures[k\\u212b] \u001b[32mPASSED\u001b[0m\u001b[31m [ 99%]\u001b[0m\nastropy/units/tests/test_format.py::test_parse_error_message_for_output_only_format[unicode] \u001b[32mPASSED\u001b[0m\u001b[31m [ 99%]\u001b[0m\nastropy/units/tests/test_format.py::test_parse_error_message_for_output_only_format[latex] \u001b[32mPASSED\u001b[0m\u001b[31m [ 99%]\u001b[0m\nastropy/units/tests/test_format.py::test_parse_error_message_for_output_only_format[latex_inline] \u001b[32mPASSED\u001b[0m\u001b[31m [ 99%]\u001b[0m\nastropy/units/tests/test_format.py::test_unknown_parser \u001b[32mPASSED\u001b[0m\u001b[31m           [ 99%]\u001b[0m\nastropy/units/tests/test_format.py::test_celsius_fits \u001b[32mPASSED\u001b[0m\u001b[31m             [100%]\u001b[0m\n\n=================================== FAILURES ===================================\n\u001b[31m\u001b[1m_______________________ test_cds_grammar[strings4-unit4] _______________________\u001b[0m\n\u001b[1m\u001b[31mastropy/units/tests/test_format.py\u001b[0m:103: in test_cds_grammar\n    assert unit2 == unit\n\u001b[1m\u001b[31mE   assert Unit(\"km Mpc / s\") == Unit(\"km / (Mpc s)\")\u001b[0m\n----------------------------- Captured stdout call -----------------------------\nkm/s/Mpc\n\u001b[31m\u001b[1m_______________________ test_cds_grammar[strings6-unit6] _______________________\u001b[0m\n\u001b[1m\u001b[31mastropy/units/tests/test_format.py\u001b[0m:103: in test_cds_grammar\n    assert unit2 == unit\n\u001b[1m\u001b[31mE   assert Unit(\"1000 J s / (kpc2 m)\") == Unit(\"1000 W / (kpc2 m)\")\u001b[0m\n----------------------------- Captured stdout call -----------------------------\n10+3J/m/s/kpc2\n\u001b[31m\u001b[1m______________________ test_cds_grammar_fail[km/s.Mpc-1] _______________________\u001b[0m\n\u001b[1m\u001b[31mastropy/units/tests/test_format.py\u001b[0m:136: in test_cds_grammar_fail\n    u_format.CDS.parse(string)\n\u001b[1m\u001b[31mE   Failed: DID NOT RAISE <class 'ValueError'>\u001b[0m\n----------------------------- Captured stdout call -----------------------------\nkm/s.Mpc-1\n\u001b[31m======================== \u001b[31m\u001b[1m3 failed\u001b[0m, \u001b[32m735 passed\u001b[0m\u001b[31m in 1.99s\u001b[0m\u001b[31m =========================\u001b[0m\n\n\n<frozen importlib._bootstrap>:228: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 80 from C header, got 96 from PyObject\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/units/tests/test_format.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/units/tests/test_format.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 738,
          "failed": 0,
          "errors": 0,
          "collected": 738,
          "duration": 5.95,
          "log_tail": "astropy/units/tests/test_format.py::test_powers[0.6666666666666666-m(2/3)] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\nastropy/units/tests/test_format.py::test_powers[0.6363636363636364-m(7/11)] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\nastropy/units/tests/test_format.py::test_powers[-0.015625-1 / m(1/64)] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\nastropy/units/tests/test_format.py::test_powers[0.01-m(1/100)] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 94%]\u001b[0m\nastropy/units/tests/test_format.py::test_powers[0.019801980198019802-m(0.019801980198019802)] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\nastropy/units/tests/test_format.py::test_powers[power9-m(2/101)] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 94%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode[\\xb5g-unit0] \u001b[32mPASSED\u001b[0m\u001b[32m     [ 94%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode[\\u03bcg-unit1] \u001b[32mPASSED\u001b[0m\u001b[32m   [ 95%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode[g\\u22121-unit2] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 95%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode[m\\u207b\\xb9-unit3] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode[m s\\u207b\\xb9-unit4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode[m\\xb2-unit5] \u001b[32mPASSED\u001b[0m\u001b[32m     [ 95%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode[m\\u207a\\xb2-unit6] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode[m\\xb3-unit7] \u001b[32mPASSED\u001b[0m\u001b[32m     [ 95%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode[m\\xb9\\u2070-unit8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode[\\u03a9-unit9] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 96%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode[\\u2126-unit10] \u001b[32mPASSED\u001b[0m\u001b[32m   [ 96%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode[\\xb5\\u03a9-unit11] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode[\\u212b-unit12] \u001b[32mPASSED\u001b[0m\u001b[32m   [ 96%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode[\\u212b \\u2126-unit13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode[\\xc5-unit14] \u001b[32mPASSED\u001b[0m\u001b[32m     [ 96%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode[A\\u030a-unit15] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 97%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode[m\\u212b-unit16] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 97%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode[\\xb0C-unit17] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 97%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode[\\xb0-unit18] \u001b[32mPASSED\u001b[0m\u001b[32m     [ 97%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode[M\\u2299-unit19] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 97%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode[L\\u2609-unit20] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 97%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode[M\\u2295-unit21] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 97%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode[M\\u2641-unit22] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 97%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode[R\\u2643-unit23] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 98%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode[\\u2032-unit24] \u001b[32mPASSED\u001b[0m\u001b[32m   [ 98%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode[R\\u221e-unit25] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 98%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode[M\\u209a-unit26] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 98%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode_failures[g\\xb5] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 98%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode_failures[g\\u2212] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode_failures[m\\u207b1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode_failures[m+\\xb9] \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode_failures[m\\u2212\\xb9] \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\nastropy/units/tests/test_format.py::test_unicode_failures[k\\u212b] \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\nastropy/units/tests/test_format.py::test_parse_error_message_for_output_only_format[unicode] \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\nastropy/units/tests/test_format.py::test_parse_error_message_for_output_only_format[latex] \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\nastropy/units/tests/test_format.py::test_parse_error_message_for_output_only_format[latex_inline] \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\nastropy/units/tests/test_format.py::test_unknown_parser \u001b[32mPASSED\u001b[0m\u001b[32m           [ 99%]\u001b[0m\nastropy/units/tests/test_format.py::test_celsius_fits \u001b[32mPASSED\u001b[0m\u001b[32m             [100%]\u001b[0m\n\n\u001b[32m============================= \u001b[32m\u001b[1m738 passed\u001b[0m\u001b[32m in 1.50s\u001b[0m\u001b[32m ==============================\u001b[0m\n\n\n<frozen importlib._bootstrap>:228: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 80 from C header, got 96 from PyObject\n",
          "test_files_run": [
            "astropy/units/tests/test_format.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "astropy__astropy-14508",
      "repo": "astropy/astropy",
      "valid": true,
      "worker": "http://34.59.30.169:8080",
      "duration": 13.550917863845825,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 174,
          "failed": 1,
          "errors": 0,
          "collected": 175,
          "duration": 6.4,
          "log_tail": "astropy/io/fits/tests/test_header.py::TestHeaderFunctions::test_update_invalid_card \u001b[32mPASSED\u001b[0m\u001b[31m [ 82%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestHeaderFunctions::test_index_numpy_int \u001b[32mPASSED\u001b[0m\u001b[31m [ 82%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestHeaderFunctions::test_header_data_size \u001b[32mPASSED\u001b[0m\u001b[31m [ 83%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_initialize_rvkc \u001b[32mPASSED\u001b[0m\u001b[31m [ 84%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_parse_field_specifier \u001b[32mPASSED\u001b[0m\u001b[31m [ 84%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_update_field_specifier \u001b[32mPASSED\u001b[0m\u001b[31m [ 85%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_field_specifier_case_senstivity \u001b[32mPASSED\u001b[0m\u001b[31m [ 85%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_get_rvkc_by_index \u001b[32mPASSED\u001b[0m\u001b[31m [ 86%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_get_rvkc_by_keyword \u001b[32mPASSED\u001b[0m\u001b[31m [ 86%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_get_rvkc_by_keyword_and_field_specifier \u001b[32mPASSED\u001b[0m\u001b[31m [ 87%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_access_nonexistent_rvkc \u001b[32mPASSED\u001b[0m\u001b[31m [ 88%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_update_rvkc \u001b[32mPASSED\u001b[0m\u001b[31m [ 88%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_update_rvkc_2 \u001b[32mPASSED\u001b[0m\u001b[31m [ 89%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_raw_keyword_value \u001b[32mPASSED\u001b[0m\u001b[31m [ 89%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_rvkc_insert_after \u001b[32mPASSED\u001b[0m\u001b[31m [ 90%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_rvkc_delete \u001b[32mPASSED\u001b[0m\u001b[31m [ 90%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_pattern_matching_keys \u001b[32mPASSED\u001b[0m\u001b[31m [ 91%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_pattern_matching_key_deletion \u001b[32mPASSED\u001b[0m\u001b[31m [ 92%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_successive_pattern_matching \u001b[32mPASSED\u001b[0m\u001b[31m [ 92%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_rvkc_in_cardlist_keys \u001b[32mPASSED\u001b[0m\u001b[31m [ 93%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_rvkc_in_cardlist_values \u001b[32mPASSED\u001b[0m\u001b[31m [ 93%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_rvkc_value_attribute \u001b[32mPASSED\u001b[0m\u001b[31m [ 94%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_overly_permissive_parsing \u001b[32mPASSED\u001b[0m\u001b[31m [ 94%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_overly_aggressive_rvkc_lookup \u001b[32mPASSED\u001b[0m\u001b[31m [ 95%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_fitsheader_script \u001b[32mPASSED\u001b[0m\u001b[31m [ 96%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_fitsheader_compressed_from_primary_image_ext \u001b[32mPASSED\u001b[0m\u001b[31m [ 96%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_fitsheader_table_feature \u001b[32mPASSED\u001b[0m\u001b[31m [ 97%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_hdu_writeto_mode[wb] \u001b[32mPASSED\u001b[0m\u001b[31m [ 97%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_hdu_writeto_mode[wb+] \u001b[32mPASSED\u001b[0m\u001b[31m [ 98%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_hdu_writeto_mode[ab] \u001b[32mPASSED\u001b[0m\u001b[31m [ 98%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_hdu_writeto_mode[ab+] \u001b[32mPASSED\u001b[0m\u001b[31m [ 99%]\u001b[0m\nastropy/io/fits/tests/test_header.py::test_subclass \u001b[32mPASSED\u001b[0m\u001b[31m               [100%]\u001b[0m\n\n=================================== FAILURES ===================================\n\u001b[31m\u001b[1m______ TestHeaderFunctions.test_floating_point_string_representation_card ______\u001b[0m\n\u001b[1m\u001b[31mastropy/io/fits/tests/test_header.py\u001b[0m:151: in test_floating_point_string_representation_card\n    assert str(c)[: len(expected_str)] == expected_str\n\u001b[1m\u001b[31mastropy/io/fits/card.py\u001b[0m:213: in __str__\n    return self.image\n\u001b[1m\u001b[31mastropy/io/fits/card.py\u001b[0m:530: in image\n    self._image = self._format_image()\n\u001b[1m\u001b[31mastropy/io/fits/card.py\u001b[0m:1038: in _format_image\n    warnings.warn(\n\u001b[1m\u001b[31mE   astropy.io.fits.verify.VerifyWarning: Card is too long, comment will be truncated.\u001b[0m\n\u001b[31m======================== \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m174 passed\u001b[0m\u001b[31m in 1.53s\u001b[0m\u001b[31m =========================\u001b[0m\n\n\n<frozen importlib._bootstrap>:228: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 80 from C header, got 96 from PyObject\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/io/fits/tests/test_header.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/io/fits/tests/test_header.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 175,
          "failed": 0,
          "errors": 0,
          "collected": 175,
          "duration": 5.7,
          "log_tail": "astropy/io/fits/tests/test_header.py::TestHeaderFunctions::test_header_strip_whitespace \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestHeaderFunctions::test_keep_duplicate_history_in_orig_header \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestHeaderFunctions::test_invalid_keyword_cards \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestHeaderFunctions::test_fix_hierarch_with_invalid_value \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestHeaderFunctions::test_assign_inf_nan \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestHeaderFunctions::test_update_bool \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestHeaderFunctions::test_update_numeric \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestHeaderFunctions::test_newlines_in_commentary \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestHeaderFunctions::test_long_commentary_card_appended_to_header \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestHeaderFunctions::test_header_fromstring_bytes \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestHeaderFunctions::test_set_keyword_with_space \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestHeaderFunctions::test_strip \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestHeaderFunctions::test_update_invalid_card \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestHeaderFunctions::test_index_numpy_int \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestHeaderFunctions::test_header_data_size \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_initialize_rvkc \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_parse_field_specifier \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_update_field_specifier \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_field_specifier_case_senstivity \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_get_rvkc_by_index \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_get_rvkc_by_keyword \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_get_rvkc_by_keyword_and_field_specifier \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_access_nonexistent_rvkc \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_update_rvkc \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_update_rvkc_2 \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_raw_keyword_value \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_rvkc_insert_after \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_rvkc_delete \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_pattern_matching_keys \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_pattern_matching_key_deletion \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_successive_pattern_matching \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_rvkc_in_cardlist_keys \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_rvkc_in_cardlist_values \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_rvkc_value_attribute \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_overly_permissive_parsing \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_overly_aggressive_rvkc_lookup \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_fitsheader_script \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_fitsheader_compressed_from_primary_image_ext \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_fitsheader_table_feature \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_hdu_writeto_mode[wb] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_hdu_writeto_mode[wb+] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_hdu_writeto_mode[ab] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_hdu_writeto_mode[ab+] \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\nastropy/io/fits/tests/test_header.py::test_subclass \u001b[32mPASSED\u001b[0m\u001b[32m               [100%]\u001b[0m\n\n\u001b[32m============================= \u001b[32m\u001b[1m175 passed\u001b[0m\u001b[32m in 1.19s\u001b[0m\u001b[32m ==============================\u001b[0m\n\n\n<frozen importlib._bootstrap>:228: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 80 from C header, got 96 from PyObject\n",
          "test_files_run": [
            "astropy/io/fits/tests/test_header.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "astropy__astropy-14539",
      "repo": "astropy/astropy",
      "valid": true,
      "worker": "http://34.59.30.169:8080",
      "duration": 12.52908706665039,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 46,
          "failed": 2,
          "errors": 0,
          "collected": 48,
          "duration": 6.04,
          "log_tail": "astropy/io/fits/tests/test_diff.py::TestDiff::test_identical_tables \u001b[31mFAILED\u001b[0m\u001b[31m [ 56%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_diff_empty_tables \u001b[32mPASSED\u001b[0m\u001b[31m [ 58%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_ignore_table_fields \u001b[32mPASSED\u001b[0m\u001b[31m [ 60%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_different_table_field_names \u001b[32mPASSED\u001b[0m\u001b[31m [ 62%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_different_table_field_counts \u001b[32mPASSED\u001b[0m\u001b[31m [ 64%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_different_table_rows \u001b[32mPASSED\u001b[0m\u001b[31m [ 66%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_different_table_data \u001b[31mFAILED\u001b[0m\u001b[31m [ 68%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_identical_files_basic \u001b[32mPASSED\u001b[0m\u001b[31m [ 70%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_partially_identical_files1 \u001b[32mPASSED\u001b[0m\u001b[31m [ 72%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_partially_identical_files2 \u001b[32mPASSED\u001b[0m\u001b[31m [ 75%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_partially_identical_files3 \u001b[32mPASSED\u001b[0m\u001b[31m [ 77%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_diff_nans \u001b[32mPASSED\u001b[0m\u001b[31m      [ 79%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_file_output_from_path_string \u001b[32mPASSED\u001b[0m\u001b[31m [ 81%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_file_output_overwrite_safety \u001b[32mPASSED\u001b[0m\u001b[31m [ 83%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_file_output_overwrite_success \u001b[32mPASSED\u001b[0m\u001b[31m [ 85%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_rawdatadiff_nodiff \u001b[32mPASSED\u001b[0m\u001b[31m [ 87%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_rawdatadiff_dimsdiff \u001b[32mPASSED\u001b[0m\u001b[31m [ 89%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_rawdatadiff_bytesdiff \u001b[32mPASSED\u001b[0m\u001b[31m [ 91%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::test_fitsdiff_hdu_name \u001b[32mPASSED\u001b[0m\u001b[31m        [ 93%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::test_fitsdiff_no_hdu_name \u001b[32mPASSED\u001b[0m\u001b[31m     [ 95%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::test_fitsdiff_with_names \u001b[32mPASSED\u001b[0m\u001b[31m      [ 97%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::test_rawdatadiff_diff_with_rtol \u001b[32mPASSED\u001b[0m\u001b[31m [100%]\u001b[0m\n\n=================================== FAILURES ===================================\n\u001b[31m\u001b[1m________________________ TestDiff.test_identical_tables ________________________\u001b[0m\n\u001b[1m\u001b[31mastropy/io/fits/tests/test_diff.py\u001b[0m:416: in test_identical_tables\n    diff = TableDataDiff(ta.data, tb.data)\n\u001b[1m\u001b[31mastropy/io/fits/diff.py\u001b[0m:1342: in __init__\n    super().__init__(a, b)\n\u001b[1m\u001b[31mastropy/io/fits/diff.py\u001b[0m:87: in __init__\n    self._diff()\n\u001b[1m\u001b[31mastropy/io/fits/diff.py\u001b[0m:1463: in _diff\n    diffs = np.where(arra != arrb)\n\u001b[1m\u001b[31mE   ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\u001b[0m\n\u001b[31m\u001b[1m______________________ TestDiff.test_different_table_data ______________________\u001b[0m\n\u001b[1m\u001b[31mastropy/io/fits/tests/test_diff.py\u001b[0m:574: in test_different_table_data\n    diff = TableDataDiff(ta.data, tb.data, numdiffs=20)\n\u001b[1m\u001b[31mastropy/io/fits/diff.py\u001b[0m:1342: in __init__\n    super().__init__(a, b)\n\u001b[1m\u001b[31mastropy/io/fits/diff.py\u001b[0m:87: in __init__\n    self._diff()\n\u001b[1m\u001b[31mastropy/io/fits/diff.py\u001b[0m:1463: in _diff\n    diffs = np.where(arra != arrb)\n\u001b[1m\u001b[31mE   ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\u001b[0m\n\u001b[31m========================= \u001b[31m\u001b[1m2 failed\u001b[0m, \u001b[32m46 passed\u001b[0m\u001b[31m in 0.75s\u001b[0m\u001b[31m =========================\u001b[0m\n\n\n<frozen importlib._bootstrap>:228: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 80 from C header, got 96 from PyObject\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/io/fits/tests/test_diff.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/io/fits/tests/test_diff.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 48,
          "failed": 0,
          "errors": 0,
          "collected": 48,
          "duration": 4.95,
          "log_tail": "astropy/io/fits/tests/test_diff.py::TestDiff::test_different_keywords \u001b[32mPASSED\u001b[0m\u001b[32m [ 10%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_different_keyword_values \u001b[32mPASSED\u001b[0m\u001b[32m [ 12%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_different_keyword_comments \u001b[32mPASSED\u001b[0m\u001b[32m [ 14%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_different_keyword_values_with_duplicate \u001b[32mPASSED\u001b[0m\u001b[32m [ 16%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_asymmetric_duplicate_keywords \u001b[32mPASSED\u001b[0m\u001b[32m [ 18%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_floating_point_rtol \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_floating_point_atol \u001b[32mPASSED\u001b[0m\u001b[32m [ 22%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_ignore_blanks \u001b[32mPASSED\u001b[0m\u001b[32m  [ 25%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_ignore_blank_cards[HeaderDiff] \u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_ignore_blank_cards[HDUDiff] \u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_ignore_blank_cards[FITSDiff] \u001b[32mPASSED\u001b[0m\u001b[32m [ 31%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_ignore_hdus \u001b[32mPASSED\u001b[0m\u001b[32m    [ 33%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_ignore_keyword_values \u001b[32mPASSED\u001b[0m\u001b[32m [ 35%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_ignore_keyword_comments \u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_trivial_identical_images \u001b[32mPASSED\u001b[0m\u001b[32m [ 39%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_identical_within_relative_tolerance \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_identical_within_absolute_tolerance \u001b[32mPASSED\u001b[0m\u001b[32m [ 43%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_identical_within_rtol_and_atol \u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_not_identical_within_rtol_and_atol \u001b[32mPASSED\u001b[0m\u001b[32m [ 47%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_identical_comp_image_hdus \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_different_dimensions \u001b[32mPASSED\u001b[0m\u001b[32m [ 52%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_different_pixels \u001b[32mPASSED\u001b[0m\u001b[32m [ 54%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_identical_tables \u001b[32mPASSED\u001b[0m\u001b[32m [ 56%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_diff_empty_tables \u001b[32mPASSED\u001b[0m\u001b[32m [ 58%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_ignore_table_fields \u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_different_table_field_names \u001b[32mPASSED\u001b[0m\u001b[32m [ 62%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_different_table_field_counts \u001b[32mPASSED\u001b[0m\u001b[32m [ 64%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_different_table_rows \u001b[32mPASSED\u001b[0m\u001b[32m [ 66%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_different_table_data \u001b[32mPASSED\u001b[0m\u001b[32m [ 68%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_identical_files_basic \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_partially_identical_files1 \u001b[32mPASSED\u001b[0m\u001b[32m [ 72%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_partially_identical_files2 \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_partially_identical_files3 \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_diff_nans \u001b[32mPASSED\u001b[0m\u001b[32m      [ 79%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_file_output_from_path_string \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_file_output_overwrite_safety \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_file_output_overwrite_success \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_rawdatadiff_nodiff \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_rawdatadiff_dimsdiff \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::TestDiff::test_rawdatadiff_bytesdiff \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::test_fitsdiff_hdu_name \u001b[32mPASSED\u001b[0m\u001b[32m        [ 93%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::test_fitsdiff_no_hdu_name \u001b[32mPASSED\u001b[0m\u001b[32m     [ 95%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::test_fitsdiff_with_names \u001b[32mPASSED\u001b[0m\u001b[32m      [ 97%]\u001b[0m\nastropy/io/fits/tests/test_diff.py::test_rawdatadiff_diff_with_rtol \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n\n\u001b[32m============================== \u001b[32m\u001b[1m48 passed\u001b[0m\u001b[32m in 0.46s\u001b[0m\u001b[32m ==============================\u001b[0m\n\n\n<frozen importlib._bootstrap>:228: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 80 from C header, got 96 from PyObject\n",
          "test_files_run": [
            "astropy/io/fits/tests/test_diff.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "astropy__astropy-14598",
      "repo": "astropy/astropy",
      "valid": true,
      "worker": "http://34.59.30.169:8080",
      "duration": 14.043748140335083,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 175,
          "failed": 1,
          "errors": 0,
          "collected": 176,
          "duration": 6.96,
          "log_tail": "astropy/io/fits/tests/test_header.py::TestHeaderFunctions::test_header_fromstring_bytes \u001b[32mPASSED\u001b[0m\u001b[31m [ 80%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestHeaderFunctions::test_set_keyword_with_space \u001b[32mPASSED\u001b[0m\u001b[31m [ 81%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestHeaderFunctions::test_strip \u001b[32mPASSED\u001b[0m\u001b[31m [ 81%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestHeaderFunctions::test_update_invalid_card \u001b[32mPASSED\u001b[0m\u001b[31m [ 82%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestHeaderFunctions::test_index_numpy_int \u001b[32mPASSED\u001b[0m\u001b[31m [ 82%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestHeaderFunctions::test_header_data_size \u001b[32mPASSED\u001b[0m\u001b[31m [ 83%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_initialize_rvkc \u001b[32mPASSED\u001b[0m\u001b[31m [ 84%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_parse_field_specifier \u001b[32mPASSED\u001b[0m\u001b[31m [ 84%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_update_field_specifier \u001b[32mPASSED\u001b[0m\u001b[31m [ 85%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_field_specifier_case_senstivity \u001b[32mPASSED\u001b[0m\u001b[31m [ 85%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_get_rvkc_by_index \u001b[32mPASSED\u001b[0m\u001b[31m [ 86%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_get_rvkc_by_keyword \u001b[32mPASSED\u001b[0m\u001b[31m [ 86%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_get_rvkc_by_keyword_and_field_specifier \u001b[32mPASSED\u001b[0m\u001b[31m [ 87%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_access_nonexistent_rvkc \u001b[32mPASSED\u001b[0m\u001b[31m [ 88%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_update_rvkc \u001b[32mPASSED\u001b[0m\u001b[31m [ 88%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_update_rvkc_2 \u001b[32mPASSED\u001b[0m\u001b[31m [ 89%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_raw_keyword_value \u001b[32mPASSED\u001b[0m\u001b[31m [ 89%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_rvkc_insert_after \u001b[32mPASSED\u001b[0m\u001b[31m [ 90%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_rvkc_delete \u001b[32mPASSED\u001b[0m\u001b[31m [ 90%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_pattern_matching_keys \u001b[32mPASSED\u001b[0m\u001b[31m [ 91%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_pattern_matching_key_deletion \u001b[32mPASSED\u001b[0m\u001b[31m [ 92%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_successive_pattern_matching \u001b[32mPASSED\u001b[0m\u001b[31m [ 92%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_rvkc_in_cardlist_keys \u001b[32mPASSED\u001b[0m\u001b[31m [ 93%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_rvkc_in_cardlist_values \u001b[32mPASSED\u001b[0m\u001b[31m [ 93%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_rvkc_value_attribute \u001b[32mPASSED\u001b[0m\u001b[31m [ 94%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_overly_permissive_parsing \u001b[32mPASSED\u001b[0m\u001b[31m [ 94%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_overly_aggressive_rvkc_lookup \u001b[32mPASSED\u001b[0m\u001b[31m [ 95%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_fitsheader_script \u001b[32mPASSED\u001b[0m\u001b[31m [ 96%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_fitsheader_compressed_from_primary_image_ext \u001b[32mPASSED\u001b[0m\u001b[31m [ 96%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_fitsheader_table_feature \u001b[32mPASSED\u001b[0m\u001b[31m [ 97%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_hdu_writeto_mode[wb] \u001b[32mPASSED\u001b[0m\u001b[31m [ 97%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_hdu_writeto_mode[wb+] \u001b[32mPASSED\u001b[0m\u001b[31m [ 98%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_hdu_writeto_mode[ab] \u001b[32mPASSED\u001b[0m\u001b[31m [ 98%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_hdu_writeto_mode[ab+] \u001b[32mPASSED\u001b[0m\u001b[31m [ 99%]\u001b[0m\nastropy/io/fits/tests/test_header.py::test_subclass \u001b[32mPASSED\u001b[0m\u001b[31m               [100%]\u001b[0m\n\n=================================== FAILURES ===================================\n\u001b[31m\u001b[1m____________ TestHeaderFunctions.test_long_string_value_with_quotes ____________\u001b[0m\n\u001b[1m\u001b[31mastropy/io/fits/tests/test_header.py\u001b[0m:589: in test_long_string_value_with_quotes\n    assert c.value == testval\n\u001b[1m\u001b[31mE   assert \"xxxxxxxxxxxx...xxxxxxxxxxxx'\" == \"xxxxxxxxxxxx...xxxxxxxxxxx''\"\u001b[0m\n\u001b[1m\u001b[31mE     - xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx''\u001b[0m\n\u001b[1m\u001b[31mE     ?                                                                                                      -\u001b[0m\n\u001b[1m\u001b[31mE     + xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'\u001b[0m\n\u001b[31m======================== \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m175 passed\u001b[0m\u001b[31m in 1.71s\u001b[0m\u001b[31m =========================\u001b[0m\n\n\n<frozen importlib._bootstrap>:228: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 80 from C header, got 96 from PyObject\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/io/fits/tests/test_header.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/io/fits/tests/test_header.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 176,
          "failed": 0,
          "errors": 0,
          "collected": 176,
          "duration": 5.68,
          "log_tail": "astropy/io/fits/tests/test_header.py::TestHeaderFunctions::test_header_strip_whitespace \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestHeaderFunctions::test_keep_duplicate_history_in_orig_header \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestHeaderFunctions::test_invalid_keyword_cards \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestHeaderFunctions::test_fix_hierarch_with_invalid_value \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestHeaderFunctions::test_assign_inf_nan \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestHeaderFunctions::test_update_bool \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestHeaderFunctions::test_update_numeric \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestHeaderFunctions::test_newlines_in_commentary \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestHeaderFunctions::test_long_commentary_card_appended_to_header \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestHeaderFunctions::test_header_fromstring_bytes \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestHeaderFunctions::test_set_keyword_with_space \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestHeaderFunctions::test_strip \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestHeaderFunctions::test_update_invalid_card \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestHeaderFunctions::test_index_numpy_int \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestHeaderFunctions::test_header_data_size \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_initialize_rvkc \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_parse_field_specifier \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_update_field_specifier \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_field_specifier_case_senstivity \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_get_rvkc_by_index \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_get_rvkc_by_keyword \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_get_rvkc_by_keyword_and_field_specifier \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_access_nonexistent_rvkc \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_update_rvkc \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_update_rvkc_2 \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_raw_keyword_value \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_rvkc_insert_after \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_rvkc_delete \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_pattern_matching_keys \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_pattern_matching_key_deletion \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_successive_pattern_matching \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_rvkc_in_cardlist_keys \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_rvkc_in_cardlist_values \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_rvkc_value_attribute \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_overly_permissive_parsing \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_overly_aggressive_rvkc_lookup \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_fitsheader_script \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_fitsheader_compressed_from_primary_image_ext \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_fitsheader_table_feature \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_hdu_writeto_mode[wb] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_hdu_writeto_mode[wb+] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_hdu_writeto_mode[ab] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\nastropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_hdu_writeto_mode[ab+] \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\nastropy/io/fits/tests/test_header.py::test_subclass \u001b[32mPASSED\u001b[0m\u001b[32m               [100%]\u001b[0m\n\n\u001b[32m============================= \u001b[32m\u001b[1m176 passed\u001b[0m\u001b[32m in 1.09s\u001b[0m\u001b[32m ==============================\u001b[0m\n\n\n<frozen importlib._bootstrap>:228: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 80 from C header, got 96 from PyObject\n",
          "test_files_run": [
            "astropy/io/fits/tests/test_header.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "astropy__astropy-14995",
      "repo": "astropy/astropy",
      "valid": true,
      "worker": "http://34.59.30.169:8080",
      "duration": 13.158317804336548,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 179,
          "failed": 1,
          "errors": 0,
          "collected": 180,
          "duration": 6.34,
          "log_tail": "astropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_varianceuncertainty_with_units[uncert111-uncert211] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_inversevarianceuncertainty_with_units[uncert10-None] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_inversevarianceuncertainty_with_units[uncert11-None] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_inversevarianceuncertainty_with_units[None-uncert22] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_inversevarianceuncertainty_with_units[None-uncert23] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_inversevarianceuncertainty_with_units[uncert14-uncert24] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_inversevarianceuncertainty_with_units[uncert15-uncert25] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_inversevarianceuncertainty_with_units[uncert16-uncert26] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_inversevarianceuncertainty_with_units[uncert17-uncert27] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_inversevarianceuncertainty_with_units[uncert18-uncert28] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_inversevarianceuncertainty_with_units[uncert19-uncert29] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_inversevarianceuncertainty_with_units[uncert110-uncert210] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_inversevarianceuncertainty_with_units[uncert111-uncert211] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_handle_switches[ff] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_handle_switches[first_found] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_meta_func \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_wcs_func \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_mask_func \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_two_argument_useage[add] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_two_argument_useage[subtract] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_two_argument_useage[divide] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_two_argument_useage[multiply] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_two_argument_useage_non_nddata_first_arg[add] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_two_argument_useage_non_nddata_first_arg[subtract] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_two_argument_useage_non_nddata_first_arg[divide] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_two_argument_useage_non_nddata_first_arg[multiply] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_unknown_uncertainties \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_psf_warning \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_raise_method_not_supported \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_nddata_bitmask_arithmetic \u001b[31mFAILED\u001b[0m\u001b[31m [100%]\u001b[0m\n\n=================================== FAILURES ===================================\n\u001b[31m\u001b[1m________________________ test_nddata_bitmask_arithmetic ________________________\u001b[0m\n\u001b[1m\u001b[31mastropy/nddata/mixins/tests/test_ndarithmetic.py\u001b[0m:1332: in test_nddata_bitmask_arithmetic\n    nref_masked.multiply(1.0, handle_mask=np.bitwise_or).mask, mask\n\u001b[1m\u001b[31mastropy/nddata/mixins/ndarithmetic.py\u001b[0m:618: in multiply\n    return self._prepare_then_do_arithmetic(\n\u001b[1m\u001b[31mastropy/nddata/mixins/ndarithmetic.py\u001b[0m:731: in _prepare_then_do_arithmetic\n    result, init_kwds = operand._arithmetic(operation, operand2, **kwargs)\n\u001b[1m\u001b[31mastropy/nddata/mixins/ndarithmetic.py\u001b[0m:335: in _arithmetic\n    kwargs[\"mask\"] = self._arithmetic_mask(\n\u001b[1m\u001b[31mastropy/nddata/mixins/ndarithmetic.py\u001b[0m:527: in _arithmetic_mask\n    return handle_mask(self.mask, operand.mask, **kwds)\n\u001b[1m\u001b[31mE   TypeError: unsupported operand type(s) for |: 'int' and 'NoneType'\u001b[0m\n\u001b[31m======================== \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m179 passed\u001b[0m\u001b[31m in 1.19s\u001b[0m\u001b[31m =========================\u001b[0m\n\n\n<frozen importlib._bootstrap>:228: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 80 from C header, got 96 from PyObject\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/nddata/mixins/tests/test_ndarithmetic.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/nddata/mixins/tests/test_ndarithmetic.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 180,
          "failed": 0,
          "errors": 0,
          "collected": 180,
          "duration": 5.41,
          "log_tail": "astropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_stddevuncertainty_with_units[uncert19-uncert29] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_stddevuncertainty_with_units[uncert110-uncert210] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_stddevuncertainty_with_units[uncert111-uncert211] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_varianceuncertainty_with_units[uncert10-None] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_varianceuncertainty_with_units[uncert11-None] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_varianceuncertainty_with_units[None-uncert22] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_varianceuncertainty_with_units[None-uncert23] \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_varianceuncertainty_with_units[uncert14-uncert24] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_varianceuncertainty_with_units[uncert15-uncert25] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_varianceuncertainty_with_units[uncert16-uncert26] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_varianceuncertainty_with_units[uncert17-uncert27] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_varianceuncertainty_with_units[uncert18-uncert28] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_varianceuncertainty_with_units[uncert19-uncert29] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_varianceuncertainty_with_units[uncert110-uncert210] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_varianceuncertainty_with_units[uncert111-uncert211] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_inversevarianceuncertainty_with_units[uncert10-None] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_inversevarianceuncertainty_with_units[uncert11-None] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_inversevarianceuncertainty_with_units[None-uncert22] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_inversevarianceuncertainty_with_units[None-uncert23] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_inversevarianceuncertainty_with_units[uncert14-uncert24] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_inversevarianceuncertainty_with_units[uncert15-uncert25] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_inversevarianceuncertainty_with_units[uncert16-uncert26] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_inversevarianceuncertainty_with_units[uncert17-uncert27] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_inversevarianceuncertainty_with_units[uncert18-uncert28] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_inversevarianceuncertainty_with_units[uncert19-uncert29] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_inversevarianceuncertainty_with_units[uncert110-uncert210] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_inversevarianceuncertainty_with_units[uncert111-uncert211] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_handle_switches[ff] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_handle_switches[first_found] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_meta_func \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_wcs_func \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_mask_func \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_two_argument_useage[add] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_two_argument_useage[subtract] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_two_argument_useage[divide] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_two_argument_useage[multiply] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_two_argument_useage_non_nddata_first_arg[add] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_two_argument_useage_non_nddata_first_arg[subtract] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_two_argument_useage_non_nddata_first_arg[divide] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_two_argument_useage_non_nddata_first_arg[multiply] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_arithmetics_unknown_uncertainties \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_psf_warning \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_raise_method_not_supported \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\nastropy/nddata/mixins/tests/test_ndarithmetic.py::test_nddata_bitmask_arithmetic \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n\n\u001b[32m============================= \u001b[32m\u001b[1m180 passed\u001b[0m\u001b[32m in 0.95s\u001b[0m\u001b[32m ==============================\u001b[0m\n\n\n<frozen importlib._bootstrap>:228: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 80 from C header, got 96 from PyObject\n",
          "test_files_run": [
            "astropy/nddata/mixins/tests/test_ndarithmetic.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "astropy__astropy-7166",
      "repo": "astropy/astropy",
      "valid": false,
      "worker": "http://34.59.30.169:8080",
      "duration": 8.612598896026611,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 3.96,
          "log_tail": "\nusage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/setup.cfg\n  rootdir: /testbed\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/utils/tests/test_misc.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/utils/tests/test_misc.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 3.61,
          "log_tail": "\nusage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/setup.cfg\n  rootdir: /testbed\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/utils/tests/test_misc.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/utils/tests/test_misc.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "astropy__astropy-7336",
      "repo": "astropy/astropy",
      "valid": false,
      "worker": "http://34.59.30.169:8080",
      "duration": 8.378651142120361,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 3.78,
          "log_tail": "\nusage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/setup.cfg\n  rootdir: /testbed\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/units/tests/py3_test_quantity_annotations.py astropy/units/tests/test_quantity_decorator.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/units/tests/py3_test_quantity_annotations.py",
            "astropy/units/tests/test_quantity_decorator.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 3.54,
          "log_tail": "\nusage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/setup.cfg\n  rootdir: /testbed\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/units/tests/py3_test_quantity_annotations.py astropy/units/tests/test_quantity_decorator.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/units/tests/py3_test_quantity_annotations.py",
            "astropy/units/tests/test_quantity_decorator.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "astropy__astropy-7606",
      "repo": "astropy/astropy",
      "valid": false,
      "worker": "http://34.59.30.169:8080",
      "duration": 8.796245098114014,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 4.03,
          "log_tail": "\nusage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/setup.cfg\n  rootdir: /testbed\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/units/tests/test_units.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/units/tests/test_units.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 3.74,
          "log_tail": "\nusage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/setup.cfg\n  rootdir: /testbed\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/units/tests/test_units.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/units/tests/test_units.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "astropy__astropy-7671",
      "repo": "astropy/astropy",
      "valid": false,
      "worker": "http://34.59.30.169:8080",
      "duration": 8.520373821258545,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 3.95,
          "log_tail": "\nusage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/setup.cfg\n  rootdir: /testbed\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/utils/tests/test_introspection.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/utils/tests/test_introspection.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 3.56,
          "log_tail": "\nusage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/setup.cfg\n  rootdir: /testbed\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/utils/tests/test_introspection.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/utils/tests/test_introspection.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "astropy__astropy-8707",
      "repo": "astropy/astropy",
      "valid": false,
      "worker": "http://34.59.30.169:8080",
      "error": "HTTPConnectionPool(host='34.59.30.169', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "astropy__astropy-8872",
      "repo": "astropy/astropy",
      "valid": false,
      "worker": "http://34.59.30.169:8080",
      "duration": 14.184581279754639,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 80,
          "failed": 5,
          "errors": 3,
          "collected": 89,
          "duration": 7.17,
          "log_tail": "astropy/table/__init__.py:41: in <module>\n    from .column import Column, MaskedColumn, StringTruncateWarning, ColumnInfo\nastropy/table/column.py:28: in <module>\n    from .np_utils import fix_column_name\nastropy/table/np_utils.py:16: in <module>\n    from . import _np_utils\nastropy/table/_np_utils.pyx:15: in init astropy.table._np_utils\n    DTYPE = np.int\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/__init__.py:319: in __getattr__\n    raise AttributeError(__former_attrs__[attr])\nE   AttributeError: module 'numpy' has no attribute 'int'.\nE   `np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nE   The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\nE       https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n_________________________________ test_insert __________________________________\nastropy/units/tests/test_quantity.py:1462: in test_insert\n    if minversion(np, '1.8.0'):\nastropy/utils/introspection.py:152: in minversion\n    return LooseVersion(have_version) >= LooseVersion(version)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/setuptools/_distutils/version.py:55: in __init__\n    warnings.warn(\nE   DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n_____________________ TestQuantityMatplotlib.test_scatter ______________________\nastropy/units/tests/test_quantity.py:1584: in test_scatter\n    plt.scatter(x, y)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/matplotlib/pyplot.py:3903: in scatter\n    __ret = gca().scatter(\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/matplotlib/__init__.py:1473: in inner\n    return func(\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/matplotlib/axes/_axes.py:4815: in scatter\n    cbook._combine_masks(\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/matplotlib/cbook.py:1093: in _combine_masks\n    x = safe_masked_invalid(x)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/matplotlib/cbook.py:740: in safe_masked_invalid\n    xm = np.ma.masked_where(~(np.isfinite(x)), x, copy=False)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/ma/core.py:1936: in masked_where\n    cond = mask_or(cond, a._mask)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/ma/core.py:1746: in mask_or\n    return make_mask(m1, copy=copy, shrink=shrink, dtype=dtype)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/ma/core.py:1640: in make_mask\n    result = _shrink_mask(result)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/ma/core.py:1549: in _shrink_mask\n    if m.dtype.names is None and not m.any():\nastropy/units/quantity.py:1540: in any\n    raise NotImplementedError(\"cannot evaluate truth value of quantities. \"\nE   NotImplementedError: cannot evaluate truth value of quantities. Evaluate array with q.value.any(...)\n============== 5 failed, 80 passed, 1 xfailed, 3 errors in 2.81s ===============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/units/tests/test_quantity.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/units/tests/test_quantity.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 81,
          "failed": 4,
          "errors": 3,
          "collected": 89,
          "duration": 6.02,
          "log_tail": "astropy/table/__init__.py:41: in <module>\n    from .column import Column, MaskedColumn, StringTruncateWarning, ColumnInfo\nastropy/table/column.py:28: in <module>\n    from .np_utils import fix_column_name\nastropy/table/np_utils.py:16: in <module>\n    from . import _np_utils\nastropy/table/_np_utils.pyx:15: in init astropy.table._np_utils\n    DTYPE = np.int\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/__init__.py:319: in __getattr__\n    raise AttributeError(__former_attrs__[attr])\nE   AttributeError: module 'numpy' has no attribute 'int'.\nE   `np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nE   The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\nE       https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n_________________________________ test_insert __________________________________\nastropy/units/tests/test_quantity.py:1462: in test_insert\n    if minversion(np, '1.8.0'):\nastropy/utils/introspection.py:152: in minversion\n    return LooseVersion(have_version) >= LooseVersion(version)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/setuptools/_distutils/version.py:55: in __init__\n    warnings.warn(\nE   DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n_____________________ TestQuantityMatplotlib.test_scatter ______________________\nastropy/units/tests/test_quantity.py:1584: in test_scatter\n    plt.scatter(x, y)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/matplotlib/pyplot.py:3903: in scatter\n    __ret = gca().scatter(\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/matplotlib/__init__.py:1473: in inner\n    return func(\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/matplotlib/axes/_axes.py:4815: in scatter\n    cbook._combine_masks(\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/matplotlib/cbook.py:1093: in _combine_masks\n    x = safe_masked_invalid(x)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/matplotlib/cbook.py:740: in safe_masked_invalid\n    xm = np.ma.masked_where(~(np.isfinite(x)), x, copy=False)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/ma/core.py:1936: in masked_where\n    cond = mask_or(cond, a._mask)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/ma/core.py:1746: in mask_or\n    return make_mask(m1, copy=copy, shrink=shrink, dtype=dtype)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/ma/core.py:1640: in make_mask\n    result = _shrink_mask(result)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/ma/core.py:1549: in _shrink_mask\n    if m.dtype.names is None and not m.any():\nastropy/units/quantity.py:1537: in any\n    raise NotImplementedError(\"cannot evaluate truth value of quantities. \"\nE   NotImplementedError: cannot evaluate truth value of quantities. Evaluate array with q.value.any(...)\n============== 4 failed, 81 passed, 1 xfailed, 3 errors in 2.31s ===============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/units/tests/test_quantity.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/units/tests/test_quantity.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "pydata__xarray-2905",
      "repo": "pydata/xarray",
      "valid": false,
      "worker": "http://34.123.9.23:8080",
      "error": "HTTPConnectionPool(host='34.123.9.23', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "pydata__xarray-3095",
      "repo": "pydata/xarray",
      "valid": true,
      "worker": "http://34.123.9.23:8080",
      "duration": 22.41901683807373,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 253,
          "failed": 1,
          "errors": 0,
          "collected": 265,
          "duration": 10.69,
          "log_tail": "\nxarray/plot/utils.py:17\nxarray/plot/utils.py:17\n  /testbed/xarray/plot/utils.py:17: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(nc_time_axis.__version__) < LooseVersion('1.2.0'):\n\nxarray/plot/plot.py:243\n  /testbed/xarray/plot/plot.py:243: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if args is ():\n\nxarray/core/pdcompat.py:46\n  /testbed/xarray/core/pdcompat.py:46: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(pd.__version__) < '0.25.0':\n\n../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345: 2 warnings\nxarray/tests/test_variable.py: 104 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    other = LooseVersion(other)\n\nxarray/tests/__init__.py:57: 15 warnings\n  /testbed/xarray/tests/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    return version.LooseVersion(vstring)\n\nxarray/tests/test_variable.py: 12 warnings\n  /testbed/xarray/core/variable.py:1596: DeprecationWarning: the `interpolation=` argument to nanpercentile was renamed to `method=`, which has additional options.\n  Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n    qs = np.nanpercentile(self.data, q * 100., axis=axis,\n\nxarray/tests/test_variable.py: 102 warnings\n  /testbed/xarray/core/variable.py:900: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(dask.__version__) > '1.2.2':\n\nxarray/tests/test_variable.py::TestVariableWithDask::test_eq_all_dtypes\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/dask/core.py:119: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n    return func(*(_execute_task(a, cache) for a in args))\n\nxarray/tests/test_variable.py::TestVariableWithDask::test_equals_all_dtypes\n  /testbed/xarray/tests/test_variable.py:1803: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if '0.18.2' <= LooseVersion(dask.__version__) < '0.19.1':\n\nxarray/tests/test_variable.py::test_raise_no_warning_for_nan_in_binary_ops\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/_pytest/python.py:194: PytestRemovedIn8Warning: Passing None has been deprecated.\n  See https://docs.pytest.org/en/latest/how-to/capture-warnings.html#additional-use-cases-of-warnings-in-tests for alternatives in common use cases.\n    result = testfunction(**testargs)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=========== 1 failed, 253 passed, 11 xfailed, 248 warnings in 7.70s ============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN xarray/tests/test_variable.py` failed. (See above for error)",
          "test_files_run": [
            "xarray/tests/test_variable.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 254,
          "failed": 0,
          "errors": 0,
          "collected": 265,
          "duration": 10.28,
          "log_tail": "    if LooseVersion(dask_version) > LooseVersion('0.19.2'):\n\nxarray/plot/utils.py:17\nxarray/plot/utils.py:17\n  /testbed/xarray/plot/utils.py:17: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(nc_time_axis.__version__) < LooseVersion('1.2.0'):\n\nxarray/plot/plot.py:243\n  /testbed/xarray/plot/plot.py:243: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if args is ():\n\nxarray/core/pdcompat.py:46\n  /testbed/xarray/core/pdcompat.py:46: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(pd.__version__) < '0.25.0':\n\n../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345: 2 warnings\nxarray/tests/test_variable.py: 104 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    other = LooseVersion(other)\n\nxarray/tests/__init__.py:57: 15 warnings\n  /testbed/xarray/tests/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    return version.LooseVersion(vstring)\n\nxarray/tests/test_variable.py: 12 warnings\n  /testbed/xarray/core/variable.py:1596: DeprecationWarning: the `interpolation=` argument to nanpercentile was renamed to `method=`, which has additional options.\n  Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n    qs = np.nanpercentile(self.data, q * 100., axis=axis,\n\nxarray/tests/test_variable.py: 102 warnings\n  /testbed/xarray/core/variable.py:900: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(dask.__version__) > '1.2.2':\n\nxarray/tests/test_variable.py::TestVariableWithDask::test_eq_all_dtypes\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/dask/core.py:119: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n    return func(*(_execute_task(a, cache) for a in args))\n\nxarray/tests/test_variable.py::TestVariableWithDask::test_equals_all_dtypes\n  /testbed/xarray/tests/test_variable.py:1803: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if '0.18.2' <= LooseVersion(dask.__version__) < '0.19.1':\n\nxarray/tests/test_variable.py::test_raise_no_warning_for_nan_in_binary_ops\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/_pytest/python.py:194: PytestRemovedIn8Warning: Passing None has been deprecated.\n  See https://docs.pytest.org/en/latest/how-to/capture-warnings.html#additional-use-cases-of-warnings-in-tests for alternatives in common use cases.\n    result = testfunction(**testargs)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================ 254 passed, 11 xfailed, 248 warnings in 6.86s =================\n\n",
          "test_files_run": [
            "xarray/tests/test_variable.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "pydata__xarray-3151",
      "repo": "pydata/xarray",
      "valid": true,
      "worker": "http://34.123.9.23:8080",
      "duration": 18.543551921844482,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 66,
          "failed": 1,
          "errors": 0,
          "collected": 68,
          "duration": 8.57,
          "log_tail": "xarray/core/combine.py:509: in combine_by_coords\n    raise ValueError(\"Resulting object does not have monotonic\"\nE   ValueError: Resulting object does not have monotonic global indexes along dimension y\n=============================== warnings summary ===============================\nxarray/core/dask_array_ops.py:11\nxarray/core/dask_array_ops.py:11\n  /testbed/xarray/core/dask_array_ops.py:11: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(dask.__version__) <= LooseVersion('0.18.2'):\n\nxarray/core/npcompat.py:135\nxarray/core/npcompat.py:135\n  /testbed/xarray/core/npcompat.py:135: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(np.__version__) >= LooseVersion('1.13'):\n\nxarray/core/dask_array_compat.py:43\nxarray/core/dask_array_compat.py:43\n  /testbed/xarray/core/dask_array_compat.py:43: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(dask_version) > LooseVersion('0.19.2'):\n\nxarray/plot/utils.py:17\nxarray/plot/utils.py:17\n  /testbed/xarray/plot/utils.py:17: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(nc_time_axis.__version__) < LooseVersion('1.2.0'):\n\nxarray/plot/plot.py:243\n  /testbed/xarray/plot/plot.py:243: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if args is ():\n\nxarray/core/pdcompat.py:46\n  /testbed/xarray/core/pdcompat.py:46: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(pd.__version__) < '0.25.0':\n\n../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345\n../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    other = LooseVersion(other)\n\nxarray/tests/__init__.py:57: 15 warnings\n  /testbed/xarray/tests/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    return version.LooseVersion(vstring)\n\nxarray/tests/test_combine.py: 14 warnings\n  /testbed/xarray/core/alignment.py:125: FutureWarning: Index.__or__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__or__.  Use index.union(other) instead.\n    index = joiner(matching_indexes)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n============= 1 failed, 66 passed, 1 xfailed, 41 warnings in 5.36s =============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN xarray/tests/test_combine.py` failed. (See above for error)",
          "test_files_run": [
            "xarray/tests/test_combine.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 67,
          "failed": 0,
          "errors": 0,
          "collected": 68,
          "duration": 8.99,
          "log_tail": "xarray/tests/test_combine.py::TestAutoCombineDeprecation::test_auto_combine_with_merge_and_concat PASSED [ 97%]\nxarray/tests/test_combine.py::TestAutoCombineDeprecation::test_auto_combine_with_coords PASSED [ 98%]\nxarray/tests/test_combine.py::TestAutoCombineDeprecation::test_auto_combine_without_coords PASSED [100%]\n\n=============================== warnings summary ===============================\nxarray/core/dask_array_ops.py:11\nxarray/core/dask_array_ops.py:11\n  /testbed/xarray/core/dask_array_ops.py:11: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(dask.__version__) <= LooseVersion('0.18.2'):\n\nxarray/core/npcompat.py:135\nxarray/core/npcompat.py:135\n  /testbed/xarray/core/npcompat.py:135: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(np.__version__) >= LooseVersion('1.13'):\n\nxarray/core/dask_array_compat.py:43\nxarray/core/dask_array_compat.py:43\n  /testbed/xarray/core/dask_array_compat.py:43: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(dask_version) > LooseVersion('0.19.2'):\n\nxarray/plot/utils.py:17\nxarray/plot/utils.py:17\n  /testbed/xarray/plot/utils.py:17: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(nc_time_axis.__version__) < LooseVersion('1.2.0'):\n\nxarray/plot/plot.py:243\n  /testbed/xarray/plot/plot.py:243: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if args is ():\n\nxarray/core/pdcompat.py:46\n  /testbed/xarray/core/pdcompat.py:46: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(pd.__version__) < '0.25.0':\n\n../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345\n../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    other = LooseVersion(other)\n\nxarray/tests/__init__.py:57: 15 warnings\n  /testbed/xarray/tests/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    return version.LooseVersion(vstring)\n\nxarray/tests/test_combine.py: 14 warnings\n  /testbed/xarray/core/alignment.py:125: FutureWarning: Index.__or__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__or__.  Use index.union(other) instead.\n    index = joiner(matching_indexes)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================== 67 passed, 1 xfailed, 41 warnings in 5.53s ==================\n\n",
          "test_files_run": [
            "xarray/tests/test_combine.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "pydata__xarray-3305",
      "repo": "pydata/xarray",
      "valid": true,
      "worker": "http://34.123.9.23:8080",
      "duration": 29.01333475112915,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 664,
          "failed": 1,
          "errors": 0,
          "collected": 669,
          "duration": 13.89,
          "log_tail": "xarray/tests/test_dataarray.py::TestDataArray::test_upsample_interpolate\nxarray/tests/test_dataarray.py::TestDataArray::test_upsample_interpolate_bug_2197\nxarray/tests/test_dataarray.py::TestDataArray::test_upsample_interpolate_regression_1605\nxarray/tests/test_dataarray.py::TestDataArray::test_upsample_interpolate_dask\nxarray/tests/test_dataarray.py::TestDataArray::test_upsample_interpolate_dask\nxarray/tests/test_dataarray.py::TestDataArray::test_upsample_interpolate_dask\n  /testbed/xarray/core/missing.py:450: FutureWarning: Passing method to DatetimeIndex.get_loc is deprecated and will raise in a future version. Use index.get_indexer([item], method=...) instead.\n    imax = index.get_loc(np.max(new_x.values), method=\"nearest\")\n\nxarray/tests/test_dataarray.py::TestDataArray::test_upsample\n  /testbed/xarray/tests/test_dataarray.py:2890: FutureWarning: pad is deprecated and will be removed in a future version. Use ffill instead.\n    expected = DataArray(array.to_series().resample(\"3H\").pad())\n\nxarray/tests/test_dataarray.py::TestDataArray::test_to_and_from_empty_series\n  /testbed/xarray/tests/test_dataarray.py:3428: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n    expected = pd.Series([])\n\nxarray/tests/test_dataarray.py::TestDataArray::test_to_and_from_cdms2_classic\nxarray/tests/test_dataarray.py::TestIrisConversion::test_to_and_from_iris\nxarray/tests/test_dataarray.py::TestIrisConversion::test_to_and_from_iris\nxarray/tests/test_dataarray.py::TestIrisConversion::test_to_and_from_iris_dask\nxarray/tests/test_dataarray.py::TestIrisConversion::test_to_and_from_iris_dask\n  /testbed/xarray/coding/times.py:238: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(pd.__version__) < \"0.25.0\":\n\nxarray/tests/test_dataarray.py::TestDataArray::test_to_and_from_cdms2_sgrid\nxarray/tests/test_dataarray.py::TestDataArray::test_to_and_from_cdms2_sgrid\nxarray/tests/test_dataarray.py::TestDataArray::test_to_and_from_cdms2_sgrid\nxarray/tests/test_dataarray.py::TestDataArray::test_to_and_from_cdms2_sgrid\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/numpy/ma/core.py:7939: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n    if not np.all(xinf == filled(np.isinf(y), False)):\n\nxarray/tests/test_dataarray.py: 1952 warnings\n  /testbed/xarray/core/rolling.py:76: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    LooseVersion(bottleneck.__version__) < LooseVersion(\"1.0\")\n\nxarray/tests/test_dataarray.py: 386 warnings\n  /testbed/xarray/core/rolling.py:336: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    LooseVersion(np.__version__) < LooseVersion(\"1.13\")\n\nxarray/tests/test_dataarray.py::test_raise_no_warning_for_nan_in_binary_ops\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/_pytest/python.py:194: PytestRemovedIn8Warning: Passing None has been deprecated.\n  See https://docs.pytest.org/en/latest/how-to/capture-warnings.html#additional-use-cases-of-warnings-in-tests for alternatives in common use cases.\n    result = testfunction(**testargs)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n===== 1 failed, 664 passed, 2 skipped, 2 xpassed, 2657 warnings in 10.54s ======\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN xarray/tests/test_dataarray.py` failed. (See above for error)",
          "test_files_run": [
            "xarray/tests/test_dataarray.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 665,
          "failed": 0,
          "errors": 0,
          "collected": 669,
          "duration": 13.68,
          "log_tail": "xarray/tests/test_dataarray.py::TestDataArray::test_upsample_interpolate\nxarray/tests/test_dataarray.py::TestDataArray::test_upsample_interpolate\nxarray/tests/test_dataarray.py::TestDataArray::test_upsample_interpolate_bug_2197\nxarray/tests/test_dataarray.py::TestDataArray::test_upsample_interpolate_regression_1605\nxarray/tests/test_dataarray.py::TestDataArray::test_upsample_interpolate_dask\nxarray/tests/test_dataarray.py::TestDataArray::test_upsample_interpolate_dask\nxarray/tests/test_dataarray.py::TestDataArray::test_upsample_interpolate_dask\n  /testbed/xarray/core/missing.py:450: FutureWarning: Passing method to DatetimeIndex.get_loc is deprecated and will raise in a future version. Use index.get_indexer([item], method=...) instead.\n    imax = index.get_loc(np.max(new_x.values), method=\"nearest\")\n\nxarray/tests/test_dataarray.py::TestDataArray::test_upsample\n  /testbed/xarray/tests/test_dataarray.py:2890: FutureWarning: pad is deprecated and will be removed in a future version. Use ffill instead.\n    expected = DataArray(array.to_series().resample(\"3H\").pad())\n\nxarray/tests/test_dataarray.py::TestDataArray::test_to_and_from_empty_series\n  /testbed/xarray/tests/test_dataarray.py:3428: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n    expected = pd.Series([])\n\nxarray/tests/test_dataarray.py::TestDataArray::test_to_and_from_cdms2_classic\nxarray/tests/test_dataarray.py::TestIrisConversion::test_to_and_from_iris\nxarray/tests/test_dataarray.py::TestIrisConversion::test_to_and_from_iris\nxarray/tests/test_dataarray.py::TestIrisConversion::test_to_and_from_iris_dask\nxarray/tests/test_dataarray.py::TestIrisConversion::test_to_and_from_iris_dask\n  /testbed/xarray/coding/times.py:238: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(pd.__version__) < \"0.25.0\":\n\nxarray/tests/test_dataarray.py::TestDataArray::test_to_and_from_cdms2_sgrid\nxarray/tests/test_dataarray.py::TestDataArray::test_to_and_from_cdms2_sgrid\nxarray/tests/test_dataarray.py::TestDataArray::test_to_and_from_cdms2_sgrid\nxarray/tests/test_dataarray.py::TestDataArray::test_to_and_from_cdms2_sgrid\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/numpy/ma/core.py:7939: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n    if not np.all(xinf == filled(np.isinf(y), False)):\n\nxarray/tests/test_dataarray.py: 1952 warnings\n  /testbed/xarray/core/rolling.py:76: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    LooseVersion(bottleneck.__version__) < LooseVersion(\"1.0\")\n\nxarray/tests/test_dataarray.py: 386 warnings\n  /testbed/xarray/core/rolling.py:336: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    LooseVersion(np.__version__) < LooseVersion(\"1.13\")\n\nxarray/tests/test_dataarray.py::test_raise_no_warning_for_nan_in_binary_ops\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/_pytest/python.py:194: PytestRemovedIn8Warning: Passing None has been deprecated.\n  See https://docs.pytest.org/en/latest/how-to/capture-warnings.html#additional-use-cases-of-warnings-in-tests for alternatives in common use cases.\n    result = testfunction(**testargs)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n========== 665 passed, 2 skipped, 2 xpassed, 2667 warnings in 10.12s ===========\n\n",
          "test_files_run": [
            "xarray/tests/test_dataarray.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "pydata__xarray-3677",
      "repo": "pydata/xarray",
      "valid": true,
      "worker": "http://34.123.9.23:8080",
      "duration": 17.935383796691895,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 21,
          "failed": 1,
          "errors": 0,
          "collected": 22,
          "duration": 8.33,
          "log_tail": "    coerced = coerce_pandas_values(objects)\nxarray/core/merge.py:394: in coerce_pandas_values\n    for k, v in obj.items():\nxarray/core/common.py:232: in __getattr__\n    raise AttributeError(\nE   AttributeError: 'DataArray' object has no attribute 'items'. Did you mean: 'item'?\n=============================== warnings summary ===============================\nxarray/core/dask_array_compat.py:13\nxarray/core/dask_array_compat.py:13\n  /testbed/xarray/core/dask_array_compat.py:13: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(dask_version) >= LooseVersion(\"2.0.0\"):\n\nxarray/core/dask_array_compat.py:100\nxarray/core/dask_array_compat.py:100\n  /testbed/xarray/core/dask_array_compat.py:100: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(dask_version) >= LooseVersion(\"2.8.1\"):\n\nxarray/core/dask_array_compat.py:137\nxarray/core/dask_array_compat.py:137\n  /testbed/xarray/core/dask_array_compat.py:137: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(dask_version) > LooseVersion(\"2.9.0\"):\n\nxarray/core/formatting_html.py:6\n  /testbed/xarray/core/formatting_html.py:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    import pkg_resources\n\nxarray/core/pdcompat.py:45\n  /testbed/xarray/core/pdcompat.py:45: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(pd.__version__) < \"0.25.0\":\n\n../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    other = LooseVersion(other)\n\nxarray/tests/test_merge.py: 17 warnings\n  /testbed/xarray/core/alignment.py:298: FutureWarning: Index.__or__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__or__.  Use index.union(other) instead.\n    index = joiner(matching_indexes)\n\nxarray/tests/test_merge.py::TestMergeFunction::test_merge_no_conflicts_single_var\nxarray/tests/test_merge.py::TestMergeMethod::test_merge_auto_align\nxarray/tests/test_merge.py::TestMergeMethod::test_merge_auto_align\nxarray/tests/test_merge.py::TestMergeMethod::test_merge_no_conflicts\n  /testbed/xarray/core/alignment.py:298: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n    index = joiner(matching_indexes)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================== 1 failed, 21 passed, 30 warnings in 5.07s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN xarray/tests/test_merge.py` failed. (See above for error)",
          "test_files_run": [
            "xarray/tests/test_merge.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 22,
          "failed": 0,
          "errors": 0,
          "collected": 22,
          "duration": 8.12,
          "log_tail": "xarray/tests/test_merge.py::TestMergeMethod::test_merge_auto_align PASSED [ 77%]\nxarray/tests/test_merge.py::TestMergeMethod::test_merge_fill_value[fill_value0] PASSED [ 81%]\nxarray/tests/test_merge.py::TestMergeMethod::test_merge_fill_value[2] PASSED [ 86%]\nxarray/tests/test_merge.py::TestMergeMethod::test_merge_fill_value[2.0] PASSED [ 90%]\nxarray/tests/test_merge.py::TestMergeMethod::test_merge_no_conflicts PASSED [ 95%]\nxarray/tests/test_merge.py::TestMergeMethod::test_merge_dataarray PASSED [100%]\n\n=============================== warnings summary ===============================\nxarray/core/dask_array_compat.py:13\nxarray/core/dask_array_compat.py:13\n  /testbed/xarray/core/dask_array_compat.py:13: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(dask_version) >= LooseVersion(\"2.0.0\"):\n\nxarray/core/dask_array_compat.py:100\nxarray/core/dask_array_compat.py:100\n  /testbed/xarray/core/dask_array_compat.py:100: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(dask_version) >= LooseVersion(\"2.8.1\"):\n\nxarray/core/dask_array_compat.py:137\nxarray/core/dask_array_compat.py:137\n  /testbed/xarray/core/dask_array_compat.py:137: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(dask_version) > LooseVersion(\"2.9.0\"):\n\nxarray/core/formatting_html.py:6\n  /testbed/xarray/core/formatting_html.py:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    import pkg_resources\n\nxarray/core/pdcompat.py:45\n  /testbed/xarray/core/pdcompat.py:45: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(pd.__version__) < \"0.25.0\":\n\n../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    other = LooseVersion(other)\n\nxarray/tests/test_merge.py: 17 warnings\n  /testbed/xarray/core/alignment.py:298: FutureWarning: Index.__or__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__or__.  Use index.union(other) instead.\n    index = joiner(matching_indexes)\n\nxarray/tests/test_merge.py::TestMergeFunction::test_merge_no_conflicts_single_var\nxarray/tests/test_merge.py::TestMergeMethod::test_merge_auto_align\nxarray/tests/test_merge.py::TestMergeMethod::test_merge_auto_align\nxarray/tests/test_merge.py::TestMergeMethod::test_merge_no_conflicts\n  /testbed/xarray/core/alignment.py:298: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n    index = joiner(matching_indexes)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================= 22 passed, 30 warnings in 4.49s ========================\n\n",
          "test_files_run": [
            "xarray/tests/test_merge.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "pydata__xarray-3993",
      "repo": "pydata/xarray",
      "valid": false,
      "worker": "http://34.123.9.23:8080",
      "error": "HTTPConnectionPool(host='34.123.9.23', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "pydata__xarray-4075",
      "repo": "pydata/xarray",
      "valid": true,
      "worker": "http://34.123.9.23:8080",
      "duration": 26.573909997940063,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 958,
          "failed": 2,
          "errors": 0,
          "collected": 962,
          "duration": 12.53,
          "log_tail": "E       array(1)\nE   R\nE       array(2.)\n=============================== warnings summary ===============================\nxarray/__init__.py:1\n  /testbed/xarray/__init__.py:1: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    import pkg_resources\n\nxarray/core/dask_array_compat.py:16\nxarray/core/dask_array_compat.py:16\n  /testbed/xarray/core/dask_array_compat.py:16: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(dask_version) >= LooseVersion(\"2.0.0\"):\n\nxarray/core/dask_array_compat.py:149\nxarray/core/dask_array_compat.py:149\n  /testbed/xarray/core/dask_array_compat.py:149: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(dask_version) >= LooseVersion(\"2.8.1\"):\n\nxarray/core/dask_array_compat.py:186\nxarray/core/dask_array_compat.py:186\n  /testbed/xarray/core/dask_array_compat.py:186: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(dask_version) > LooseVersion(\"2.9.0\"):\n\nxarray/core/pdcompat.py:45\n  /testbed/xarray/core/pdcompat.py:45: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(pd.__version__) < \"0.25.0\":\n\n../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    other = LooseVersion(other)\n\nxarray/tests/__init__.py:54\nxarray/tests/__init__.py:54\n  /testbed/xarray/tests/__init__.py:54: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    return version.LooseVersion(vstring)\n\nxarray/tests/test_weighted.py: 18 warnings\n  /testbed/xarray/core/alignment.py:304: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n    index = joiner(matching_indexes)\n\nxarray/tests/test_weighted.py: 10 warnings\n  /testbed/xarray/core/formatting.py:143: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n  Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n    elif isinstance(x, (float, np.float)):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n============ 2 failed, 958 passed, 2 xfailed, 39 warnings in 9.20s =============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN xarray/tests/test_weighted.py` failed. (See above for error)",
          "test_files_run": [
            "xarray/tests/test_weighted.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 960,
          "failed": 0,
          "errors": 0,
          "collected": 962,
          "duration": 12.62,
          "log_tail": "xarray/tests/test_weighted.py::test_weighted_operations_keep_attr[None-False-mean] PASSED [ 99%]\nxarray/tests/test_weighted.py::test_weighted_operations_keep_attr_da_in_ds[sum] XFAIL [ 99%]\nxarray/tests/test_weighted.py::test_weighted_operations_keep_attr_da_in_ds[mean] XFAIL [100%]\n\n=============================== warnings summary ===============================\nxarray/__init__.py:1\n  /testbed/xarray/__init__.py:1: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    import pkg_resources\n\nxarray/core/dask_array_compat.py:16\nxarray/core/dask_array_compat.py:16\n  /testbed/xarray/core/dask_array_compat.py:16: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(dask_version) >= LooseVersion(\"2.0.0\"):\n\nxarray/core/dask_array_compat.py:149\nxarray/core/dask_array_compat.py:149\n  /testbed/xarray/core/dask_array_compat.py:149: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(dask_version) >= LooseVersion(\"2.8.1\"):\n\nxarray/core/dask_array_compat.py:186\nxarray/core/dask_array_compat.py:186\n  /testbed/xarray/core/dask_array_compat.py:186: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(dask_version) > LooseVersion(\"2.9.0\"):\n\nxarray/core/pdcompat.py:45\n  /testbed/xarray/core/pdcompat.py:45: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(pd.__version__) < \"0.25.0\":\n\n../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    other = LooseVersion(other)\n\nxarray/tests/__init__.py:54\nxarray/tests/__init__.py:54\n  /testbed/xarray/tests/__init__.py:54: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    return version.LooseVersion(vstring)\n\nxarray/tests/test_weighted.py: 18 warnings\n  /testbed/xarray/core/alignment.py:304: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n    index = joiner(matching_indexes)\n\nxarray/tests/test_weighted.py: 10 warnings\n  /testbed/xarray/core/formatting.py:143: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n  Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n    elif isinstance(x, (float, np.float)):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================= 960 passed, 2 xfailed, 39 warnings in 9.28s ==================\n\n",
          "test_files_run": [
            "xarray/tests/test_weighted.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "pydata__xarray-4094",
      "repo": "pydata/xarray",
      "valid": false,
      "worker": "http://34.123.9.23:8080",
      "duration": 44.771284341812134,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 866,
          "failed": 5,
          "errors": 0,
          "collected": 889,
          "duration": 23.18,
          "log_tail": "xarray/tests/test_dataset.py::TestDataset::test_resample_loffset\n  /testbed/xarray/tests/test_dataset.py:3786: FutureWarning: 'loffset' in .resample() and in Grouper() is deprecated.\n  \n  >>> df.resample(freq=\"3s\", loffset=\"8H\")\n  \n  becomes:\n  \n  >>> from pandas.tseries.frequencies import to_offset\n  >>> df = df.resample(freq=\"3s\").mean()\n  >>> df.index = df.index.to_timestamp() + to_offset(\"8H\")\n  \n    ds.bar.to_series().resample(\"24H\", loffset=\"-12H\").mean()\n\nxarray/tests/test_dataset.py::TestDataset::test_resample_drop_nondim_coords\n  /testbed/xarray/core/missing.py:563: FutureWarning: Passing method to DatetimeIndex.get_loc is deprecated and will raise in a future version. Use index.get_indexer([item], method=...) instead.\n    imin = index.get_loc(np.min(new_x.values), method=\"nearest\")\n\nxarray/tests/test_dataset.py::TestDataset::test_resample_drop_nondim_coords\n  /testbed/xarray/core/missing.py:564: FutureWarning: Passing method to DatetimeIndex.get_loc is deprecated and will raise in a future version. Use index.get_indexer([item], method=...) instead.\n    imax = index.get_loc(np.max(new_x.values), method=\"nearest\")\n\nxarray/tests/test_dataset.py::TestDataset::test_from_dataframe_sparse\n  /testbed/xarray/core/dataset.py:4553: FutureWarning: MultiIndex.is_lexsorted is deprecated as a public function, users should use MultiIndex.is_monotonic_increasing instead.\n    is_sorted = idx.is_lexsorted()\n\nxarray/tests/test_dataset.py: 64 warnings\n  /testbed/xarray/core/variable.py:1793: DeprecationWarning: the `interpolation=` argument to nanquantile was renamed to `method=`, which has additional options.\n  Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n    return np.moveaxis(_quantile_func(npa, **kwargs), 0, -1)\n\nxarray/tests/test_dataset.py: 64 warnings\n  /testbed/xarray/core/variable.py:1793: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n  Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n    return np.moveaxis(_quantile_func(npa, **kwargs), 0, -1)\n\nxarray/tests/test_dataset.py::test_coarsen_coords[1-True]\nxarray/tests/test_dataset.py::test_coarsen_coords[1-False]\n  /testbed/xarray/tests/test_dataset.py:5763: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n    coords={\"time\": pd.date_range(\"15/12/1999\", periods=364)},\n\nxarray/tests/test_dataset.py::test_trapz_datetime[np-True]\nxarray/tests/test_dataset.py::test_trapz_datetime[cftime-True]\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/dask/array/core.py:1706: FutureWarning: The `numpy.trapz` function is not implemented by Dask array. You may want to use the da.map_blocks function or something similar to silence this warning. Your code may stop working in a future release.\n    warnings.warn(\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n= 5 failed, 866 passed, 16 skipped, 1 xfailed, 1 xpassed, 2926 warnings in 19.44s =\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN xarray/tests/test_dataset.py` failed. (See above for error)",
          "test_files_run": [
            "xarray/tests/test_dataset.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 867,
          "failed": 4,
          "errors": 0,
          "collected": 889,
          "duration": 20.12,
          "log_tail": "xarray/tests/test_dataset.py::TestDataset::test_resample_loffset\n  /testbed/xarray/tests/test_dataset.py:3786: FutureWarning: 'loffset' in .resample() and in Grouper() is deprecated.\n  \n  >>> df.resample(freq=\"3s\", loffset=\"8H\")\n  \n  becomes:\n  \n  >>> from pandas.tseries.frequencies import to_offset\n  >>> df = df.resample(freq=\"3s\").mean()\n  >>> df.index = df.index.to_timestamp() + to_offset(\"8H\")\n  \n    ds.bar.to_series().resample(\"24H\", loffset=\"-12H\").mean()\n\nxarray/tests/test_dataset.py::TestDataset::test_resample_drop_nondim_coords\n  /testbed/xarray/core/missing.py:563: FutureWarning: Passing method to DatetimeIndex.get_loc is deprecated and will raise in a future version. Use index.get_indexer([item], method=...) instead.\n    imin = index.get_loc(np.min(new_x.values), method=\"nearest\")\n\nxarray/tests/test_dataset.py::TestDataset::test_resample_drop_nondim_coords\n  /testbed/xarray/core/missing.py:564: FutureWarning: Passing method to DatetimeIndex.get_loc is deprecated and will raise in a future version. Use index.get_indexer([item], method=...) instead.\n    imax = index.get_loc(np.max(new_x.values), method=\"nearest\")\n\nxarray/tests/test_dataset.py::TestDataset::test_from_dataframe_sparse\n  /testbed/xarray/core/dataset.py:4553: FutureWarning: MultiIndex.is_lexsorted is deprecated as a public function, users should use MultiIndex.is_monotonic_increasing instead.\n    is_sorted = idx.is_lexsorted()\n\nxarray/tests/test_dataset.py: 64 warnings\n  /testbed/xarray/core/variable.py:1793: DeprecationWarning: the `interpolation=` argument to nanquantile was renamed to `method=`, which has additional options.\n  Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n    return np.moveaxis(_quantile_func(npa, **kwargs), 0, -1)\n\nxarray/tests/test_dataset.py: 64 warnings\n  /testbed/xarray/core/variable.py:1793: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n  Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n    return np.moveaxis(_quantile_func(npa, **kwargs), 0, -1)\n\nxarray/tests/test_dataset.py::test_coarsen_coords[1-True]\nxarray/tests/test_dataset.py::test_coarsen_coords[1-False]\n  /testbed/xarray/tests/test_dataset.py:5763: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n    coords={\"time\": pd.date_range(\"15/12/1999\", periods=364)},\n\nxarray/tests/test_dataset.py::test_trapz_datetime[np-True]\nxarray/tests/test_dataset.py::test_trapz_datetime[cftime-True]\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/dask/array/core.py:1706: FutureWarning: The `numpy.trapz` function is not implemented by Dask array. You may want to use the da.map_blocks function or something similar to silence this warning. Your code may stop working in a future release.\n    warnings.warn(\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n= 4 failed, 867 passed, 16 skipped, 1 xfailed, 1 xpassed, 2926 warnings in 16.55s =\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN xarray/tests/test_dataset.py` failed. (See above for error)",
          "test_files_run": [
            "xarray/tests/test_dataset.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "pydata__xarray-4356",
      "repo": "pydata/xarray",
      "valid": true,
      "worker": "http://34.123.9.23:8080",
      "duration": 34.86526083946228,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 596,
          "failed": 16,
          "errors": 0,
          "collected": 820,
          "duration": 18.68,
          "log_tail": "\nxarray/core/dask_array_compat.py:16\nxarray/core/dask_array_compat.py:16\n  /testbed/xarray/core/dask_array_compat.py:16: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(dask_version) >= LooseVersion(\"2.0.0\"):\n\nxarray/core/dask_array_compat.py:149\nxarray/core/dask_array_compat.py:149\n  /testbed/xarray/core/dask_array_compat.py:149: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(dask_version) >= LooseVersion(\"2.8.1\"):\n\nxarray/core/dask_array_compat.py:186\nxarray/core/dask_array_compat.py:186\n  /testbed/xarray/core/dask_array_compat.py:186: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(dask_version) > LooseVersion(\"2.9.0\"):\n\nxarray/core/pdcompat.py:45\n  /testbed/xarray/core/pdcompat.py:45: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(pd.__version__) < \"0.25.0\":\n\n../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345\nxarray/tests/test_duck_array_ops.py::test_cftime_datetime_mean_dask_error\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    other = LooseVersion(other)\n\nxarray/tests/__init__.py:58\nxarray/tests/__init__.py:58\n  /testbed/xarray/tests/__init__.py:58: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    return version.LooseVersion(vstring)\n\nxarray/tests/test_duck_array_ops.py::test_cftime_datetime_mean\nxarray/tests/test_duck_array_ops.py::test_cftime_datetime_mean\nxarray/tests/test_duck_array_ops.py::test_cftime_datetime_mean_dask_error\nxarray/tests/test_duck_array_ops.py::test_cftime_datetime_mean_dask_error\nxarray/tests/test_duck_array_ops.py::test_datetime_to_numeric_cftime\nxarray/tests/test_duck_array_ops.py::test_datetime_to_numeric_cftime\nxarray/tests/test_duck_array_ops.py::test_datetime_to_numeric_potential_overflow\nxarray/tests/test_duck_array_ops.py::test_datetime_to_numeric_potential_overflow\n  /testbed/xarray/coding/cftimeindex.py:122: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(cftime.__version__) < LooseVersion(\"1.0.4\"):\n\nxarray/tests/test_duck_array_ops.py::test_cftime_datetime_mean_dask_error\n  /testbed/xarray/core/variable.py:1043: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(dask.__version__) < \"2.0.0\":\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n========== 16 failed, 596 passed, 208 skipped, 21 warnings in 15.24s ===========\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN xarray/tests/test_duck_array_ops.py` failed. (See above for error)",
          "test_files_run": [
            "xarray/tests/test_duck_array_ops.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 612,
          "failed": 0,
          "errors": 0,
          "collected": 820,
          "duration": 14.75,
          "log_tail": "    import pkg_resources\n\nxarray/core/dask_array_compat.py:16\nxarray/core/dask_array_compat.py:16\n  /testbed/xarray/core/dask_array_compat.py:16: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(dask_version) >= LooseVersion(\"2.0.0\"):\n\nxarray/core/dask_array_compat.py:149\nxarray/core/dask_array_compat.py:149\n  /testbed/xarray/core/dask_array_compat.py:149: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(dask_version) >= LooseVersion(\"2.8.1\"):\n\nxarray/core/dask_array_compat.py:186\nxarray/core/dask_array_compat.py:186\n  /testbed/xarray/core/dask_array_compat.py:186: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(dask_version) > LooseVersion(\"2.9.0\"):\n\nxarray/core/pdcompat.py:45\n  /testbed/xarray/core/pdcompat.py:45: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(pd.__version__) < \"0.25.0\":\n\n../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345\nxarray/tests/test_duck_array_ops.py::test_cftime_datetime_mean_dask_error\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    other = LooseVersion(other)\n\nxarray/tests/__init__.py:58\nxarray/tests/__init__.py:58\n  /testbed/xarray/tests/__init__.py:58: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    return version.LooseVersion(vstring)\n\nxarray/tests/test_duck_array_ops.py::test_cftime_datetime_mean\nxarray/tests/test_duck_array_ops.py::test_cftime_datetime_mean\nxarray/tests/test_duck_array_ops.py::test_cftime_datetime_mean_dask_error\nxarray/tests/test_duck_array_ops.py::test_cftime_datetime_mean_dask_error\nxarray/tests/test_duck_array_ops.py::test_datetime_to_numeric_cftime\nxarray/tests/test_duck_array_ops.py::test_datetime_to_numeric_cftime\nxarray/tests/test_duck_array_ops.py::test_datetime_to_numeric_potential_overflow\nxarray/tests/test_duck_array_ops.py::test_datetime_to_numeric_potential_overflow\n  /testbed/xarray/coding/cftimeindex.py:122: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(cftime.__version__) < LooseVersion(\"1.0.4\"):\n\nxarray/tests/test_duck_array_ops.py::test_cftime_datetime_mean_dask_error\n  /testbed/xarray/core/variable.py:1043: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(dask.__version__) < \"2.0.0\":\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================ 612 passed, 208 skipped, 21 warnings in 11.27s ================\n\n",
          "test_files_run": [
            "xarray/tests/test_duck_array_ops.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "pydata__xarray-4629",
      "repo": "pydata/xarray",
      "valid": true,
      "worker": "http://34.123.9.23:8080",
      "duration": 18.097471952438354,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 32,
          "failed": 1,
          "errors": 0,
          "collected": 33,
          "duration": 8.61,
          "log_tail": "xarray/tests/test_merge.py::TestMergeFunction::test_merge_no_conflicts_multi_var PASSED [ 63%]\nxarray/tests/test_merge.py::TestMergeFunction::test_merge_no_conflicts_preserve_attrs PASSED [ 66%]\nxarray/tests/test_merge.py::TestMergeFunction::test_merge_no_conflicts_broadcast PASSED [ 69%]\nxarray/tests/test_merge.py::TestMergeMethod::test_merge PASSED           [ 72%]\nxarray/tests/test_merge.py::TestMergeMethod::test_merge_broadcast_equals PASSED [ 75%]\nxarray/tests/test_merge.py::TestMergeMethod::test_merge_compat PASSED    [ 78%]\nxarray/tests/test_merge.py::TestMergeMethod::test_merge_auto_align PASSED [ 81%]\nxarray/tests/test_merge.py::TestMergeMethod::test_merge_fill_value[fill_value0] PASSED [ 84%]\nxarray/tests/test_merge.py::TestMergeMethod::test_merge_fill_value[2] PASSED [ 87%]\nxarray/tests/test_merge.py::TestMergeMethod::test_merge_fill_value[2.0] PASSED [ 90%]\nxarray/tests/test_merge.py::TestMergeMethod::test_merge_fill_value[fill_value3] PASSED [ 93%]\nxarray/tests/test_merge.py::TestMergeMethod::test_merge_no_conflicts PASSED [ 96%]\nxarray/tests/test_merge.py::TestMergeMethod::test_merge_dataarray PASSED [100%]\n\n=================================== FAILURES ===================================\n_______________ TestMergeFunction.test_merge_attrs_override_copy _______________\n/testbed/xarray/tests/test_merge.py:117: in test_merge_attrs_override_copy\n    assert ds1.x == 0\nE   assert 2 == 0\nE    +  where 2 = <xarray.Dataset>\\nDimensions:  ()\\nData variables:\\n    *empty*\\nAttributes:\\n    x:        2.x\n=============================== warnings summary ===============================\nxarray/__init__.py:1\n  /testbed/xarray/__init__.py:1: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    import pkg_resources\n\nxarray/core/dask_array_compat.py:61\nxarray/core/dask_array_compat.py:61\n  /testbed/xarray/core/dask_array_compat.py:61: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(dask_version) > LooseVersion(\"2.9.0\"):\n\nxarray/core/pdcompat.py:45\n  /testbed/xarray/core/pdcompat.py:45: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(pd.__version__) < \"0.25.0\":\n\n../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    other = LooseVersion(other)\n\nxarray/tests/__init__.py:59\nxarray/tests/__init__.py:59\nxarray/tests/__init__.py:59\nxarray/tests/__init__.py:59\n  /testbed/xarray/tests/__init__.py:59: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    return version.LooseVersion(vstring)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=================== 1 failed, 32 passed, 9 warnings in 5.06s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN xarray/tests/test_merge.py` failed. (See above for error)",
          "test_files_run": [
            "xarray/tests/test_merge.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 33,
          "failed": 0,
          "errors": 0,
          "collected": 33,
          "duration": 7.94,
          "log_tail": "xarray/tests/test_merge.py::TestMergeFunction::test_merge_attrs_override_copy PASSED [ 42%]\nxarray/tests/test_merge.py::TestMergeFunction::test_merge_dicts_simple PASSED [ 45%]\nxarray/tests/test_merge.py::TestMergeFunction::test_merge_dicts_dims PASSED [ 48%]\nxarray/tests/test_merge.py::TestMergeFunction::test_merge_error PASSED   [ 51%]\nxarray/tests/test_merge.py::TestMergeFunction::test_merge_alignment_error PASSED [ 54%]\nxarray/tests/test_merge.py::TestMergeFunction::test_merge_wrong_input_error PASSED [ 57%]\nxarray/tests/test_merge.py::TestMergeFunction::test_merge_no_conflicts_single_var PASSED [ 60%]\nxarray/tests/test_merge.py::TestMergeFunction::test_merge_no_conflicts_multi_var PASSED [ 63%]\nxarray/tests/test_merge.py::TestMergeFunction::test_merge_no_conflicts_preserve_attrs PASSED [ 66%]\nxarray/tests/test_merge.py::TestMergeFunction::test_merge_no_conflicts_broadcast PASSED [ 69%]\nxarray/tests/test_merge.py::TestMergeMethod::test_merge PASSED           [ 72%]\nxarray/tests/test_merge.py::TestMergeMethod::test_merge_broadcast_equals PASSED [ 75%]\nxarray/tests/test_merge.py::TestMergeMethod::test_merge_compat PASSED    [ 78%]\nxarray/tests/test_merge.py::TestMergeMethod::test_merge_auto_align PASSED [ 81%]\nxarray/tests/test_merge.py::TestMergeMethod::test_merge_fill_value[fill_value0] PASSED [ 84%]\nxarray/tests/test_merge.py::TestMergeMethod::test_merge_fill_value[2] PASSED [ 87%]\nxarray/tests/test_merge.py::TestMergeMethod::test_merge_fill_value[2.0] PASSED [ 90%]\nxarray/tests/test_merge.py::TestMergeMethod::test_merge_fill_value[fill_value3] PASSED [ 93%]\nxarray/tests/test_merge.py::TestMergeMethod::test_merge_no_conflicts PASSED [ 96%]\nxarray/tests/test_merge.py::TestMergeMethod::test_merge_dataarray PASSED [100%]\n\n=============================== warnings summary ===============================\nxarray/__init__.py:1\n  /testbed/xarray/__init__.py:1: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    import pkg_resources\n\nxarray/core/dask_array_compat.py:61\nxarray/core/dask_array_compat.py:61\n  /testbed/xarray/core/dask_array_compat.py:61: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(dask_version) > LooseVersion(\"2.9.0\"):\n\nxarray/core/pdcompat.py:45\n  /testbed/xarray/core/pdcompat.py:45: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(pd.__version__) < \"0.25.0\":\n\n../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    other = LooseVersion(other)\n\nxarray/tests/__init__.py:59\nxarray/tests/__init__.py:59\nxarray/tests/__init__.py:59\nxarray/tests/__init__.py:59\n  /testbed/xarray/tests/__init__.py:59: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    return version.LooseVersion(vstring)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================== 33 passed, 9 warnings in 4.50s ========================\n\n",
          "test_files_run": [
            "xarray/tests/test_merge.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "pydata__xarray-4687",
      "repo": "pydata/xarray",
      "valid": false,
      "worker": "http://34.123.9.23:8080",
      "error": "HTTPConnectionPool(host='34.123.9.23', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "pydata__xarray-4695",
      "repo": "pydata/xarray",
      "valid": false,
      "worker": "http://34.123.9.23:8080",
      "duration": 43.3337779045105,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 876,
          "failed": 2,
          "errors": 0,
          "collected": 885,
          "duration": 22.75,
          "log_tail": "  /testbed/xarray/core/dataset.py:4861: FutureWarning: MultiIndex.is_lexsorted is deprecated as a public function, users should use MultiIndex.is_monotonic_increasing instead.\n    is_sorted = idx.is_lexsorted()\n\nxarray/tests/test_dataarray.py::TestDataArray::test_to_and_from_cdms2_classic\nxarray/tests/test_dataarray.py::TestIrisConversion::test_to_and_from_iris\nxarray/tests/test_dataarray.py::TestIrisConversion::test_to_and_from_iris\nxarray/tests/test_dataarray.py::TestIrisConversion::test_to_and_from_iris_dask\nxarray/tests/test_dataarray.py::TestIrisConversion::test_to_and_from_iris_dask\n  /testbed/xarray/coding/times.py:236: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(pd.__version__) < \"0.25.0\":\n\nxarray/tests/test_dataarray.py::TestDataArray::test_to_and_from_cdms2_sgrid\nxarray/tests/test_dataarray.py::TestDataArray::test_to_and_from_cdms2_sgrid\nxarray/tests/test_dataarray.py::TestDataArray::test_to_and_from_cdms2_sgrid\nxarray/tests/test_dataarray.py::TestDataArray::test_to_and_from_cdms2_sgrid\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/numpy/ma/core.py:7939: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n    if not np.all(xinf == filled(np.isinf(y), False)):\n\nxarray/tests/test_dataarray.py::TestDataArray::test_polyfit[True-True]\nxarray/tests/test_dataarray.py::TestDataArray::test_polyfit[True-False]\nxarray/tests/test_dataarray.py::TestDataArray::test_polyfit[False-True]\nxarray/tests/test_dataarray.py::TestDataArray::test_polyfit[False-False]\n  /testbed/xarray/core/missing.py:265: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n    if not index.is_monotonic:\n\nxarray/tests/test_dataarray.py::TestDataArray::test_polyfit[True-True]\nxarray/tests/test_dataarray.py::TestDataArray::test_polyfit[True-False]\nxarray/tests/test_dataarray.py::TestDataArray::test_polyfit[False-True]\nxarray/tests/test_dataarray.py::TestDataArray::test_polyfit[False-False]\n  /testbed/xarray/core/dataset.py:6258: RuntimeWarning: overflow encountered in multiply\n    scale = np.sqrt((lhs * lhs).sum(axis=0))\n\nxarray/tests/test_dataarray.py: 12 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n\nxarray/tests/test_dataarray.py::test_coarsen_keep_attrs\n  /testbed/xarray/tests/test_dataarray.py:6235: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n    coords={\"time\": pd.date_range(\"15/12/1999\", periods=364)},\n\nxarray/tests/test_dataarray.py::test_raise_no_warning_for_nan_in_binary_ops\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/_pytest/python.py:194: PytestRemovedIn8Warning: Passing None has been deprecated.\n  See https://docs.pytest.org/en/latest/how-to/capture-warnings.html#additional-use-cases-of-warnings-in-tests for alternatives in common use cases.\n    result = testfunction(**testargs)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n= 2 failed, 876 passed, 1 skipped, 5 xfailed, 1 xpassed, 259 warnings in 18.85s =\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN xarray/tests/test_dataarray.py` failed. (See above for error)",
          "test_files_run": [
            "xarray/tests/test_dataarray.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 877,
          "failed": 1,
          "errors": 0,
          "collected": 885,
          "duration": 19.07,
          "log_tail": "  /testbed/xarray/core/dataset.py:4861: FutureWarning: MultiIndex.is_lexsorted is deprecated as a public function, users should use MultiIndex.is_monotonic_increasing instead.\n    is_sorted = idx.is_lexsorted()\n\nxarray/tests/test_dataarray.py::TestDataArray::test_to_and_from_cdms2_classic\nxarray/tests/test_dataarray.py::TestIrisConversion::test_to_and_from_iris\nxarray/tests/test_dataarray.py::TestIrisConversion::test_to_and_from_iris\nxarray/tests/test_dataarray.py::TestIrisConversion::test_to_and_from_iris_dask\nxarray/tests/test_dataarray.py::TestIrisConversion::test_to_and_from_iris_dask\n  /testbed/xarray/coding/times.py:236: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(pd.__version__) < \"0.25.0\":\n\nxarray/tests/test_dataarray.py::TestDataArray::test_to_and_from_cdms2_sgrid\nxarray/tests/test_dataarray.py::TestDataArray::test_to_and_from_cdms2_sgrid\nxarray/tests/test_dataarray.py::TestDataArray::test_to_and_from_cdms2_sgrid\nxarray/tests/test_dataarray.py::TestDataArray::test_to_and_from_cdms2_sgrid\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/numpy/ma/core.py:7939: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n    if not np.all(xinf == filled(np.isinf(y), False)):\n\nxarray/tests/test_dataarray.py::TestDataArray::test_polyfit[True-True]\nxarray/tests/test_dataarray.py::TestDataArray::test_polyfit[True-False]\nxarray/tests/test_dataarray.py::TestDataArray::test_polyfit[False-True]\nxarray/tests/test_dataarray.py::TestDataArray::test_polyfit[False-False]\n  /testbed/xarray/core/missing.py:265: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n    if not index.is_monotonic:\n\nxarray/tests/test_dataarray.py::TestDataArray::test_polyfit[True-True]\nxarray/tests/test_dataarray.py::TestDataArray::test_polyfit[True-False]\nxarray/tests/test_dataarray.py::TestDataArray::test_polyfit[False-True]\nxarray/tests/test_dataarray.py::TestDataArray::test_polyfit[False-False]\n  /testbed/xarray/core/dataset.py:6258: RuntimeWarning: overflow encountered in multiply\n    scale = np.sqrt((lhs * lhs).sum(axis=0))\n\nxarray/tests/test_dataarray.py: 12 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n\nxarray/tests/test_dataarray.py::test_coarsen_keep_attrs\n  /testbed/xarray/tests/test_dataarray.py:6235: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n    coords={\"time\": pd.date_range(\"15/12/1999\", periods=364)},\n\nxarray/tests/test_dataarray.py::test_raise_no_warning_for_nan_in_binary_ops\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/_pytest/python.py:194: PytestRemovedIn8Warning: Passing None has been deprecated.\n  See https://docs.pytest.org/en/latest/how-to/capture-warnings.html#additional-use-cases-of-warnings-in-tests for alternatives in common use cases.\n    result = testfunction(**testargs)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n= 1 failed, 877 passed, 1 skipped, 5 xfailed, 1 xpassed, 259 warnings in 15.73s =\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN xarray/tests/test_dataarray.py` failed. (See above for error)",
          "test_files_run": [
            "xarray/tests/test_dataarray.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "pydata__xarray-4966",
      "repo": "pydata/xarray",
      "valid": true,
      "worker": "http://34.123.9.23:8080",
      "duration": 16.985501050949097,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 21,
          "failed": 4,
          "errors": 0,
          "collected": 25,
          "duration": 7.88,
          "log_tail": "E    +  where dtype('uint32') = <xarray.Variable (x: 1)>\\narray([4294967295], dtype=uint32).dtype\n_____________________ test_decode_signed_from_unsigned[8] ______________________\n/testbed/xarray/tests/test_coding.py:146: in test_decode_signed_from_unsigned\n    assert decoded.dtype == signed_dtype\nE   AssertionError: assert dtype('uint64') == dtype('int64')\nE    +  where dtype('uint64') = <xarray.Variable (x: 1)>\\narray([18446744073709551615], dtype=uint64).dtype\n=============================== warnings summary ===============================\nxarray/__init__.py:1\n  /testbed/xarray/__init__.py:1: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    import pkg_resources\n\nxarray/core/dask_array_compat.py:61\nxarray/core/dask_array_compat.py:61\n  /testbed/xarray/core/dask_array_compat.py:61: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(dask_version) > LooseVersion(\"2.9.0\"):\n\nxarray/core/pdcompat.py:45\n  /testbed/xarray/core/pdcompat.py:45: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(pd.__version__) < \"0.25.0\":\n\n../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345\nxarray/tests/test_coding.py::test_CFMaskCoder_encode_missing_fill_values_conflict[times-with-dtype]\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    other = LooseVersion(other)\n\nxarray/tests/__init__.py:59\nxarray/tests/__init__.py:59\nxarray/tests/__init__.py:59\nxarray/tests/__init__.py:59\nxarray/tests/__init__.py:59\nxarray/tests/__init__.py:59\n  /testbed/xarray/tests/__init__.py:59: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    return version.LooseVersion(vstring)\n\nxarray/tests/test_coding.py::test_CFMaskCoder_encode_missing_fill_values_conflict[times-with-dtype]\n  /testbed/xarray/coding/times.py:265: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(pd.__version__) < \"0.25.0\":\n\nxarray/tests/test_coding.py::test_decode_signed_from_unsigned[1]\nxarray/tests/test_coding.py::test_decode_signed_from_unsigned[2]\nxarray/tests/test_coding.py::test_decode_signed_from_unsigned[4]\nxarray/tests/test_coding.py::test_decode_signed_from_unsigned[8]\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/_pytest/python.py:194: SerializationWarning: variable None has _Unsigned attribute but is not of integer type. Ignoring attribute.\n    result = testfunction(**testargs)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================== 4 failed, 21 passed, 17 warnings in 4.26s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN xarray/tests/test_coding.py` failed. (See above for error)",
          "test_files_run": [
            "xarray/tests/test_coding.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 25,
          "failed": 0,
          "errors": 0,
          "collected": 25,
          "duration": 7.57,
          "log_tail": "xarray/tests/test_coding.py::test_scaling_converts_to_float32[f4] PASSED [ 52%]\nxarray/tests/test_coding.py::test_scaling_offset_as_list[0.1-10] PASSED  [ 56%]\nxarray/tests/test_coding.py::test_scaling_offset_as_list[0.1-scale_factor1] PASSED [ 60%]\nxarray/tests/test_coding.py::test_scaling_offset_as_list[add_offset1-10] PASSED [ 64%]\nxarray/tests/test_coding.py::test_scaling_offset_as_list[add_offset1-scale_factor1] PASSED [ 68%]\nxarray/tests/test_coding.py::test_decode_unsigned_from_signed[1] PASSED  [ 72%]\nxarray/tests/test_coding.py::test_decode_unsigned_from_signed[2] PASSED  [ 76%]\nxarray/tests/test_coding.py::test_decode_unsigned_from_signed[4] PASSED  [ 80%]\nxarray/tests/test_coding.py::test_decode_unsigned_from_signed[8] PASSED  [ 84%]\nxarray/tests/test_coding.py::test_decode_signed_from_unsigned[1] PASSED  [ 88%]\nxarray/tests/test_coding.py::test_decode_signed_from_unsigned[2] PASSED  [ 92%]\nxarray/tests/test_coding.py::test_decode_signed_from_unsigned[4] PASSED  [ 96%]\nxarray/tests/test_coding.py::test_decode_signed_from_unsigned[8] PASSED  [100%]\n\n=============================== warnings summary ===============================\nxarray/__init__.py:1\n  /testbed/xarray/__init__.py:1: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    import pkg_resources\n\nxarray/core/dask_array_compat.py:61\nxarray/core/dask_array_compat.py:61\n  /testbed/xarray/core/dask_array_compat.py:61: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(dask_version) > LooseVersion(\"2.9.0\"):\n\nxarray/core/pdcompat.py:45\n  /testbed/xarray/core/pdcompat.py:45: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(pd.__version__) < \"0.25.0\":\n\n../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345\nxarray/tests/test_coding.py::test_CFMaskCoder_encode_missing_fill_values_conflict[times-with-dtype]\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    other = LooseVersion(other)\n\nxarray/tests/__init__.py:59\nxarray/tests/__init__.py:59\nxarray/tests/__init__.py:59\nxarray/tests/__init__.py:59\nxarray/tests/__init__.py:59\nxarray/tests/__init__.py:59\n  /testbed/xarray/tests/__init__.py:59: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    return version.LooseVersion(vstring)\n\nxarray/tests/test_coding.py::test_CFMaskCoder_encode_missing_fill_values_conflict[times-with-dtype]\n  /testbed/xarray/coding/times.py:265: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(pd.__version__) < \"0.25.0\":\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================= 25 passed, 13 warnings in 3.94s ========================\n\n",
          "test_files_run": [
            "xarray/tests/test_coding.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "pydata__xarray-6461",
      "repo": "pydata/xarray",
      "valid": true,
      "worker": "http://34.123.9.23:8080",
      "duration": 30.115899085998535,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 247,
          "failed": 1,
          "errors": 0,
          "collected": 249,
          "duration": 14.78,
          "log_tail": "xarray/tests/test_computation.py::test_vectorize_dask_new_output_dims PASSED [ 89%]\nxarray/tests/test_computation.py::test_output_wrong_number PASSED        [ 89%]\nxarray/tests/test_computation.py::test_output_wrong_dims PASSED          [ 89%]\nxarray/tests/test_computation.py::test_output_wrong_dim_size PASSED      [ 90%]\nxarray/tests/test_computation.py::test_dot[True] PASSED                  [ 90%]\nxarray/tests/test_computation.py::test_dot[False] PASSED                 [ 91%]\nxarray/tests/test_computation.py::test_dot_align_coords[True] PASSED     [ 91%]\nxarray/tests/test_computation.py::test_dot_align_coords[False] PASSED    [ 91%]\nxarray/tests/test_computation.py::test_where PASSED                      [ 92%]\nxarray/tests/test_computation.py::test_where_attrs FAILED                [ 92%]\nxarray/tests/test_computation.py::test_polyval[True-True] PASSED         [ 93%]\nxarray/tests/test_computation.py::test_polyval[True-False] PASSED        [ 93%]\nxarray/tests/test_computation.py::test_polyval[False-True] PASSED        [ 93%]\nxarray/tests/test_computation.py::test_polyval[False-False] PASSED       [ 94%]\nxarray/tests/test_computation.py::test_cross[a0-b0-ae0-be0-dim_0--1-False] PASSED [ 94%]\nxarray/tests/test_computation.py::test_cross[a0-b0-ae0-be0-dim_0--1-True] PASSED [ 95%]\nxarray/tests/test_computation.py::test_cross[a1-b1-ae1-be1-dim_0--1-False] PASSED [ 95%]\nxarray/tests/test_computation.py::test_cross[a1-b1-ae1-be1-dim_0--1-True] PASSED [ 95%]\nxarray/tests/test_computation.py::test_cross[a2-b2-ae2-be2-dim_0--1-False] PASSED [ 96%]\nxarray/tests/test_computation.py::test_cross[a2-b2-ae2-be2-dim_0--1-True] PASSED [ 96%]\nxarray/tests/test_computation.py::test_cross[a3-b3-ae3-be3-dim_0--1-False] PASSED [ 97%]\nxarray/tests/test_computation.py::test_cross[a3-b3-ae3-be3-dim_0--1-True] PASSED [ 97%]\nxarray/tests/test_computation.py::test_cross[a4-b4-ae4-be4-cartesian-1-False] PASSED [ 97%]\nxarray/tests/test_computation.py::test_cross[a4-b4-ae4-be4-cartesian-1-True] PASSED [ 98%]\nxarray/tests/test_computation.py::test_cross[a5-b5-ae5-be5-cartesian--1-False] PASSED [ 98%]\nxarray/tests/test_computation.py::test_cross[a5-b5-ae5-be5-cartesian--1-True] PASSED [ 99%]\nxarray/tests/test_computation.py::test_cross[a6-b6-ae6-be6-cartesian--1-False] PASSED [ 99%]\nxarray/tests/test_computation.py::test_cross[a6-b6-ae6-be6-cartesian--1-True] PASSED [100%]\n\n=================================== FAILURES ===================================\n_______________________________ test_where_attrs _______________________________\n/testbed/xarray/tests/test_computation.py:1932: in test_where_attrs\n    actual = xr.where(cond, 1, 0, keep_attrs=True)\n/testbed/xarray/core/computation.py:1835: in where\n    return apply_ufunc(\n/testbed/xarray/core/computation.py:1179: in apply_ufunc\n    return apply_dataarray_vfunc(\n/testbed/xarray/core/computation.py:293: in apply_dataarray_vfunc\n    result_var = func(*data_vars)\n/testbed/xarray/core/computation.py:763: in apply_variable_ufunc\n    attrs = merge_attrs(\n/testbed/xarray/core/merge.py:611: in merge_attrs\n    return combine_attrs(variable_attrs, context=context)\n/testbed/xarray/core/computation.py:1832: in <lambda>\n    keep_attrs = lambda attrs, context: attrs[1]\nE   IndexError: list index out of range\n=================== 1 failed, 247 passed, 1 skipped in 8.42s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN xarray/tests/test_computation.py` failed. (See above for error)",
          "test_files_run": [
            "xarray/tests/test_computation.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 248,
          "failed": 0,
          "errors": 0,
          "collected": 249,
          "duration": 13.84,
          "log_tail": "xarray/tests/test_computation.py::test_autocov[None-da_a2] PASSED        [ 81%]\nxarray/tests/test_computation.py::test_autocov[None-da_a3] PASSED        [ 82%]\nxarray/tests/test_computation.py::test_autocov[None-da_a4] PASSED        [ 82%]\nxarray/tests/test_computation.py::test_autocov[time-da_a0] PASSED        [ 83%]\nxarray/tests/test_computation.py::test_autocov[time-da_a1] PASSED        [ 83%]\nxarray/tests/test_computation.py::test_autocov[time-da_a2] PASSED        [ 83%]\nxarray/tests/test_computation.py::test_autocov[time-da_a3] PASSED        [ 84%]\nxarray/tests/test_computation.py::test_autocov[time-da_a4] PASSED        [ 84%]\nxarray/tests/test_computation.py::test_autocov[x-da_a0] PASSED           [ 85%]\nxarray/tests/test_computation.py::test_autocov[x-da_a1] PASSED           [ 85%]\nxarray/tests/test_computation.py::test_autocov[x-da_a2] PASSED           [ 85%]\nxarray/tests/test_computation.py::test_autocov[x-da_a3] PASSED           [ 86%]\nxarray/tests/test_computation.py::test_autocov[x-da_a4] PASSED           [ 86%]\nxarray/tests/test_computation.py::test_autocov[dim3-da_a0] PASSED        [ 87%]\nxarray/tests/test_computation.py::test_autocov[dim3-da_a1] PASSED        [ 87%]\nxarray/tests/test_computation.py::test_autocov[dim3-da_a2] PASSED        [ 87%]\nxarray/tests/test_computation.py::test_autocov[dim3-da_a3] PASSED        [ 88%]\nxarray/tests/test_computation.py::test_autocov[dim3-da_a4] PASSED        [ 88%]\nxarray/tests/test_computation.py::test_vectorize_dask_new_output_dims PASSED [ 89%]\nxarray/tests/test_computation.py::test_output_wrong_number PASSED        [ 89%]\nxarray/tests/test_computation.py::test_output_wrong_dims PASSED          [ 89%]\nxarray/tests/test_computation.py::test_output_wrong_dim_size PASSED      [ 90%]\nxarray/tests/test_computation.py::test_dot[True] PASSED                  [ 90%]\nxarray/tests/test_computation.py::test_dot[False] PASSED                 [ 91%]\nxarray/tests/test_computation.py::test_dot_align_coords[True] PASSED     [ 91%]\nxarray/tests/test_computation.py::test_dot_align_coords[False] PASSED    [ 91%]\nxarray/tests/test_computation.py::test_where PASSED                      [ 92%]\nxarray/tests/test_computation.py::test_where_attrs PASSED                [ 92%]\nxarray/tests/test_computation.py::test_polyval[True-True] PASSED         [ 93%]\nxarray/tests/test_computation.py::test_polyval[True-False] PASSED        [ 93%]\nxarray/tests/test_computation.py::test_polyval[False-True] PASSED        [ 93%]\nxarray/tests/test_computation.py::test_polyval[False-False] PASSED       [ 94%]\nxarray/tests/test_computation.py::test_cross[a0-b0-ae0-be0-dim_0--1-False] PASSED [ 94%]\nxarray/tests/test_computation.py::test_cross[a0-b0-ae0-be0-dim_0--1-True] PASSED [ 95%]\nxarray/tests/test_computation.py::test_cross[a1-b1-ae1-be1-dim_0--1-False] PASSED [ 95%]\nxarray/tests/test_computation.py::test_cross[a1-b1-ae1-be1-dim_0--1-True] PASSED [ 95%]\nxarray/tests/test_computation.py::test_cross[a2-b2-ae2-be2-dim_0--1-False] PASSED [ 96%]\nxarray/tests/test_computation.py::test_cross[a2-b2-ae2-be2-dim_0--1-True] PASSED [ 96%]\nxarray/tests/test_computation.py::test_cross[a3-b3-ae3-be3-dim_0--1-False] PASSED [ 97%]\nxarray/tests/test_computation.py::test_cross[a3-b3-ae3-be3-dim_0--1-True] PASSED [ 97%]\nxarray/tests/test_computation.py::test_cross[a4-b4-ae4-be4-cartesian-1-False] PASSED [ 97%]\nxarray/tests/test_computation.py::test_cross[a4-b4-ae4-be4-cartesian-1-True] PASSED [ 98%]\nxarray/tests/test_computation.py::test_cross[a5-b5-ae5-be5-cartesian--1-False] PASSED [ 98%]\nxarray/tests/test_computation.py::test_cross[a5-b5-ae5-be5-cartesian--1-True] PASSED [ 99%]\nxarray/tests/test_computation.py::test_cross[a6-b6-ae6-be6-cartesian--1-False] PASSED [ 99%]\nxarray/tests/test_computation.py::test_cross[a6-b6-ae6-be6-cartesian--1-True] PASSED [100%]\n\n======================== 248 passed, 1 skipped in 7.40s ========================\n\n",
          "test_files_run": [
            "xarray/tests/test_computation.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "pydata__xarray-6599",
      "repo": "pydata/xarray",
      "valid": true,
      "worker": "http://34.123.9.23:8080",
      "duration": 30.098798036575317,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 263,
          "failed": 2,
          "errors": 0,
          "collected": 266,
          "duration": 14.91,
          "log_tail": "xarray/tests/test_computation.py::test_polyval[dataset-dataset-True] PASSED [ 92%]\nxarray/tests/test_computation.py::test_polyval[datetime-False] PASSED    [ 93%]\nxarray/tests/test_computation.py::test_polyval[datetime-True] PASSED     [ 93%]\nxarray/tests/test_computation.py::test_polyval[timedelta-False] FAILED   [ 93%]\nxarray/tests/test_computation.py::test_polyval[timedelta-True] FAILED    [ 94%]\nxarray/tests/test_computation.py::test_polyval_degree_dim_checks PASSED  [ 94%]\nxarray/tests/test_computation.py::test_cross[a0-b0-ae0-be0-dim_0--1-False] PASSED [ 95%]\nxarray/tests/test_computation.py::test_cross[a0-b0-ae0-be0-dim_0--1-True] PASSED [ 95%]\nxarray/tests/test_computation.py::test_cross[a1-b1-ae1-be1-dim_0--1-False] PASSED [ 95%]\nxarray/tests/test_computation.py::test_cross[a1-b1-ae1-be1-dim_0--1-True] PASSED [ 96%]\nxarray/tests/test_computation.py::test_cross[a2-b2-ae2-be2-dim_0--1-False] PASSED [ 96%]\nxarray/tests/test_computation.py::test_cross[a2-b2-ae2-be2-dim_0--1-True] PASSED [ 96%]\nxarray/tests/test_computation.py::test_cross[a3-b3-ae3-be3-dim_0--1-False] PASSED [ 97%]\nxarray/tests/test_computation.py::test_cross[a3-b3-ae3-be3-dim_0--1-True] PASSED [ 97%]\nxarray/tests/test_computation.py::test_cross[a4-b4-ae4-be4-cartesian-1-False] PASSED [ 98%]\nxarray/tests/test_computation.py::test_cross[a4-b4-ae4-be4-cartesian-1-True] PASSED [ 98%]\nxarray/tests/test_computation.py::test_cross[a5-b5-ae5-be5-cartesian--1-False] PASSED [ 98%]\nxarray/tests/test_computation.py::test_cross[a5-b5-ae5-be5-cartesian--1-True] PASSED [ 99%]\nxarray/tests/test_computation.py::test_cross[a6-b6-ae6-be6-cartesian--1-False] PASSED [ 99%]\nxarray/tests/test_computation.py::test_cross[a6-b6-ae6-be6-cartesian--1-True] PASSED [100%]\n\n=================================== FAILURES ===================================\n________________________ test_polyval[timedelta-False] _________________________\n/testbed/xarray/tests/test_computation.py:2035: in test_polyval\n    actual = xr.polyval(coord=x, coeffs=coeffs)  # type: ignore\n/testbed/xarray/core/computation.py:1908: in polyval\n    coord = _ensure_numeric(coord)  # type: ignore # https://github.com/python/mypy/issues/1533 ?\n/testbed/xarray/core/computation.py:1949: in _ensure_numeric\n    return to_floatable(data)\n/testbed/xarray/core/computation.py:1938: in to_floatable\n    data=datetime_to_numeric(\n/testbed/xarray/core/duck_array_ops.py:434: in datetime_to_numeric\n    array = array - offset\nE   numpy.core._exceptions._UFuncBinaryResolutionError: ufunc 'subtract' cannot use operands with types dtype('<m8[ns]') and dtype('<M8[D]')\n_________________________ test_polyval[timedelta-True] _________________________\n/testbed/xarray/tests/test_computation.py:2035: in test_polyval\n    actual = xr.polyval(coord=x, coeffs=coeffs)  # type: ignore\n/testbed/xarray/core/computation.py:1908: in polyval\n    coord = _ensure_numeric(coord)  # type: ignore # https://github.com/python/mypy/issues/1533 ?\n/testbed/xarray/core/computation.py:1949: in _ensure_numeric\n    return to_floatable(data)\n/testbed/xarray/core/computation.py:1938: in to_floatable\n    data=datetime_to_numeric(\n/testbed/xarray/core/duck_array_ops.py:434: in datetime_to_numeric\n    array = array - offset\nE   TypeError: operand type(s) all returned NotImplemented from __array_ufunc__(<ufunc 'subtract'>, '__call__', dask.array<xarray-<this-array>, shape=(3,), dtype=timedelta64[ns], chunksize=(2,), chunktype=numpy.ndarray>, numpy.datetime64('1970-01-01')): 'Array', 'datetime64'\n=================== 2 failed, 263 passed, 1 skipped in 8.57s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN xarray/tests/test_computation.py` failed. (See above for error)",
          "test_files_run": [
            "xarray/tests/test_computation.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 265,
          "failed": 0,
          "errors": 0,
          "collected": 266,
          "duration": 13.77,
          "log_tail": "xarray/tests/test_computation.py::test_autocov[dim3-da_a4] PASSED        [ 83%]\nxarray/tests/test_computation.py::test_vectorize_dask_new_output_dims PASSED [ 83%]\nxarray/tests/test_computation.py::test_output_wrong_number PASSED        [ 83%]\nxarray/tests/test_computation.py::test_output_wrong_dims PASSED          [ 84%]\nxarray/tests/test_computation.py::test_output_wrong_dim_size PASSED      [ 84%]\nxarray/tests/test_computation.py::test_dot[True] PASSED                  [ 84%]\nxarray/tests/test_computation.py::test_dot[False] PASSED                 [ 85%]\nxarray/tests/test_computation.py::test_dot_align_coords[True] PASSED     [ 85%]\nxarray/tests/test_computation.py::test_dot_align_coords[False] PASSED    [ 86%]\nxarray/tests/test_computation.py::test_where PASSED                      [ 86%]\nxarray/tests/test_computation.py::test_where_attrs PASSED                [ 86%]\nxarray/tests/test_computation.py::test_polyval[simple-False] PASSED      [ 87%]\nxarray/tests/test_computation.py::test_polyval[simple-True] PASSED       [ 87%]\nxarray/tests/test_computation.py::test_polyval[broadcast-x-False] PASSED [ 87%]\nxarray/tests/test_computation.py::test_polyval[broadcast-x-True] PASSED  [ 88%]\nxarray/tests/test_computation.py::test_polyval[shared-dim-False] PASSED  [ 88%]\nxarray/tests/test_computation.py::test_polyval[shared-dim-True] PASSED   [ 89%]\nxarray/tests/test_computation.py::test_polyval[reordered-index-False] PASSED [ 89%]\nxarray/tests/test_computation.py::test_polyval[reordered-index-True] PASSED [ 89%]\nxarray/tests/test_computation.py::test_polyval[sparse-index-False] PASSED [ 90%]\nxarray/tests/test_computation.py::test_polyval[sparse-index-True] PASSED [ 90%]\nxarray/tests/test_computation.py::test_polyval[array-dataset-False] PASSED [ 90%]\nxarray/tests/test_computation.py::test_polyval[array-dataset-True] PASSED [ 91%]\nxarray/tests/test_computation.py::test_polyval[dataset-array-False] PASSED [ 91%]\nxarray/tests/test_computation.py::test_polyval[dataset-array-True] PASSED [ 92%]\nxarray/tests/test_computation.py::test_polyval[dataset-dataset-False] PASSED [ 92%]\nxarray/tests/test_computation.py::test_polyval[dataset-dataset-True] PASSED [ 92%]\nxarray/tests/test_computation.py::test_polyval[datetime-False] PASSED    [ 93%]\nxarray/tests/test_computation.py::test_polyval[datetime-True] PASSED     [ 93%]\nxarray/tests/test_computation.py::test_polyval[timedelta-False] PASSED   [ 93%]\nxarray/tests/test_computation.py::test_polyval[timedelta-True] PASSED    [ 94%]\nxarray/tests/test_computation.py::test_polyval_degree_dim_checks PASSED  [ 94%]\nxarray/tests/test_computation.py::test_cross[a0-b0-ae0-be0-dim_0--1-False] PASSED [ 95%]\nxarray/tests/test_computation.py::test_cross[a0-b0-ae0-be0-dim_0--1-True] PASSED [ 95%]\nxarray/tests/test_computation.py::test_cross[a1-b1-ae1-be1-dim_0--1-False] PASSED [ 95%]\nxarray/tests/test_computation.py::test_cross[a1-b1-ae1-be1-dim_0--1-True] PASSED [ 96%]\nxarray/tests/test_computation.py::test_cross[a2-b2-ae2-be2-dim_0--1-False] PASSED [ 96%]\nxarray/tests/test_computation.py::test_cross[a2-b2-ae2-be2-dim_0--1-True] PASSED [ 96%]\nxarray/tests/test_computation.py::test_cross[a3-b3-ae3-be3-dim_0--1-False] PASSED [ 97%]\nxarray/tests/test_computation.py::test_cross[a3-b3-ae3-be3-dim_0--1-True] PASSED [ 97%]\nxarray/tests/test_computation.py::test_cross[a4-b4-ae4-be4-cartesian-1-False] PASSED [ 98%]\nxarray/tests/test_computation.py::test_cross[a4-b4-ae4-be4-cartesian-1-True] PASSED [ 98%]\nxarray/tests/test_computation.py::test_cross[a5-b5-ae5-be5-cartesian--1-False] PASSED [ 98%]\nxarray/tests/test_computation.py::test_cross[a5-b5-ae5-be5-cartesian--1-True] PASSED [ 99%]\nxarray/tests/test_computation.py::test_cross[a6-b6-ae6-be6-cartesian--1-False] PASSED [ 99%]\nxarray/tests/test_computation.py::test_cross[a6-b6-ae6-be6-cartesian--1-True] PASSED [100%]\n\n======================== 265 passed, 1 skipped in 7.47s ========================\n\n",
          "test_files_run": [
            "xarray/tests/test_computation.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "pydata__xarray-6721",
      "repo": "pydata/xarray",
      "valid": false,
      "worker": "http://34.123.9.23:8080",
      "error": "HTTPConnectionPool(host='34.123.9.23', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "pydata__xarray-6744",
      "repo": "pydata/xarray",
      "valid": false,
      "worker": "http://34.123.9.23:8080",
      "error": "HTTPConnectionPool(host='34.123.9.23', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "pydata__xarray-6938",
      "repo": "pydata/xarray",
      "valid": true,
      "worker": "http://34.123.9.23:8080",
      "duration": 40.0946900844574,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 430,
          "failed": 1,
          "errors": 0,
          "collected": 527,
          "duration": 20.9,
          "log_tail": "xarray/tests/test_variable.py::TestAsCompatibleData::test_full_like_dask PASSED [ 95%]\nxarray/tests/test_variable.py::TestAsCompatibleData::test_zeros_like PASSED [ 96%]\nxarray/tests/test_variable.py::TestAsCompatibleData::test_ones_like PASSED [ 96%]\nxarray/tests/test_variable.py::TestAsCompatibleData::test_unsupported_type PASSED [ 96%]\nxarray/tests/test_variable.py::test_raise_no_warning_for_nan_in_binary_ops PASSED [ 96%]\nxarray/tests/test_variable.py::TestBackendIndexing::test_NumpyIndexingAdapter PASSED [ 96%]\nxarray/tests/test_variable.py::TestBackendIndexing::test_LazilyIndexedArray PASSED [ 96%]\nxarray/tests/test_variable.py::TestBackendIndexing::test_CopyOnWriteArray PASSED [ 97%]\nxarray/tests/test_variable.py::TestBackendIndexing::test_MemoryCachedArray PASSED [ 97%]\nxarray/tests/test_variable.py::TestBackendIndexing::test_DaskIndexingAdapter PASSED [ 97%]\nxarray/tests/test_variable.py::test_clip PASSED                          [ 97%]\nxarray/tests/test_variable.py::TestNumpyCoercion::test_from_numpy[Variable] PASSED [ 97%]\nxarray/tests/test_variable.py::TestNumpyCoercion::test_from_numpy[IndexVariable] PASSED [ 98%]\nxarray/tests/test_variable.py::TestNumpyCoercion::test_from_dask[Variable] PASSED [ 98%]\nxarray/tests/test_variable.py::TestNumpyCoercion::test_from_dask[IndexVariable] PASSED [ 98%]\nxarray/tests/test_variable.py::TestNumpyCoercion::test_from_pint[Variable] PASSED [ 98%]\nxarray/tests/test_variable.py::TestNumpyCoercion::test_from_pint[IndexVariable] PASSED [ 98%]\nxarray/tests/test_variable.py::TestNumpyCoercion::test_from_sparse[Variable] PASSED [ 99%]\nxarray/tests/test_variable.py::TestNumpyCoercion::test_from_sparse[IndexVariable] SKIPPED [ 99%]\nxarray/tests/test_variable.py::TestNumpyCoercion::test_from_cupy[Variable] SKIPPED [ 99%]\nxarray/tests/test_variable.py::TestNumpyCoercion::test_from_cupy[IndexVariable] SKIPPED [ 99%]\nxarray/tests/test_variable.py::TestNumpyCoercion::test_from_pint_wrapping_dask[Variable] PASSED [ 99%]\nxarray/tests/test_variable.py::TestNumpyCoercion::test_from_pint_wrapping_dask[IndexVariable] PASSED [100%]\n\n=================================== FAILURES ===================================\n________________ TestIndexVariable.test_to_index_variable_copy _________________\n/testbed/xarray/tests/test_variable.py:2430: in test_to_index_variable_copy\n    assert a is not b\nE   AssertionError: assert <xarray.IndexVariable 'x' (x: 1)>\\narray(['a'], dtype='<U1') is not <xarray.IndexVariable 'x' (x: 1)>\\narray(['a'], dtype='<U1')\n=============================== warnings summary ===============================\nxarray/tests/test_variable.py::TestVariableWithDask::test_eq_all_dtypes\nxarray/tests/test_variable.py::TestVariableWithDask::test_eq_all_dtypes\nxarray/tests/test_variable.py::TestVariableWithDask::test_eq_all_dtypes\nxarray/tests/test_variable.py::TestVariableWithDask::test_eq_all_dtypes\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/dask/core.py:119: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n    return func(*(_execute_task(a, cache) for a in args))\n\nxarray/tests/test_variable.py::TestNumpyCoercion::test_from_sparse[Variable]\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/sparse/_coo/core.py:216: DeprecationWarning: coords should be an ndarray. This will raise a ValueError in the future.\n    warnings.warn(\n\nxarray/tests/test_variable.py::TestNumpyCoercion::test_from_sparse[Variable]\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/sparse/_coo/core.py:245: DeprecationWarning: shape should be provided. This will raise a ValueError in the future.\n    warnings.warn(\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n= 1 failed, 430 passed, 58 skipped, 15 xfailed, 23 xpassed, 6 warnings in 14.29s =\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN xarray/tests/test_variable.py` failed. (See above for error)",
          "test_files_run": [
            "xarray/tests/test_variable.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 431,
          "failed": 0,
          "errors": 0,
          "collected": 527,
          "duration": 17.65,
          "log_tail": "xarray/tests/test_variable.py::TestIndexVariable::test_to_index_variable_copy PASSED [ 94%]\nxarray/tests/test_variable.py::TestAsCompatibleData::test_unchanged_types PASSED [ 94%]\nxarray/tests/test_variable.py::TestAsCompatibleData::test_converted_types PASSED [ 95%]\nxarray/tests/test_variable.py::TestAsCompatibleData::test_masked_array PASSED [ 95%]\nxarray/tests/test_variable.py::TestAsCompatibleData::test_datetime PASSED [ 95%]\nxarray/tests/test_variable.py::TestAsCompatibleData::test_full_like PASSED [ 95%]\nxarray/tests/test_variable.py::TestAsCompatibleData::test_full_like_dask PASSED [ 95%]\nxarray/tests/test_variable.py::TestAsCompatibleData::test_zeros_like PASSED [ 96%]\nxarray/tests/test_variable.py::TestAsCompatibleData::test_ones_like PASSED [ 96%]\nxarray/tests/test_variable.py::TestAsCompatibleData::test_unsupported_type PASSED [ 96%]\nxarray/tests/test_variable.py::test_raise_no_warning_for_nan_in_binary_ops PASSED [ 96%]\nxarray/tests/test_variable.py::TestBackendIndexing::test_NumpyIndexingAdapter PASSED [ 96%]\nxarray/tests/test_variable.py::TestBackendIndexing::test_LazilyIndexedArray PASSED [ 96%]\nxarray/tests/test_variable.py::TestBackendIndexing::test_CopyOnWriteArray PASSED [ 97%]\nxarray/tests/test_variable.py::TestBackendIndexing::test_MemoryCachedArray PASSED [ 97%]\nxarray/tests/test_variable.py::TestBackendIndexing::test_DaskIndexingAdapter PASSED [ 97%]\nxarray/tests/test_variable.py::test_clip PASSED                          [ 97%]\nxarray/tests/test_variable.py::TestNumpyCoercion::test_from_numpy[Variable] PASSED [ 97%]\nxarray/tests/test_variable.py::TestNumpyCoercion::test_from_numpy[IndexVariable] PASSED [ 98%]\nxarray/tests/test_variable.py::TestNumpyCoercion::test_from_dask[Variable] PASSED [ 98%]\nxarray/tests/test_variable.py::TestNumpyCoercion::test_from_dask[IndexVariable] PASSED [ 98%]\nxarray/tests/test_variable.py::TestNumpyCoercion::test_from_pint[Variable] PASSED [ 98%]\nxarray/tests/test_variable.py::TestNumpyCoercion::test_from_pint[IndexVariable] PASSED [ 98%]\nxarray/tests/test_variable.py::TestNumpyCoercion::test_from_sparse[Variable] PASSED [ 99%]\nxarray/tests/test_variable.py::TestNumpyCoercion::test_from_sparse[IndexVariable] SKIPPED [ 99%]\nxarray/tests/test_variable.py::TestNumpyCoercion::test_from_cupy[Variable] SKIPPED [ 99%]\nxarray/tests/test_variable.py::TestNumpyCoercion::test_from_cupy[IndexVariable] SKIPPED [ 99%]\nxarray/tests/test_variable.py::TestNumpyCoercion::test_from_pint_wrapping_dask[Variable] PASSED [ 99%]\nxarray/tests/test_variable.py::TestNumpyCoercion::test_from_pint_wrapping_dask[IndexVariable] PASSED [100%]\n\n=============================== warnings summary ===============================\nxarray/tests/test_variable.py::TestVariableWithDask::test_eq_all_dtypes\nxarray/tests/test_variable.py::TestVariableWithDask::test_eq_all_dtypes\nxarray/tests/test_variable.py::TestVariableWithDask::test_eq_all_dtypes\nxarray/tests/test_variable.py::TestVariableWithDask::test_eq_all_dtypes\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/dask/core.py:119: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n    return func(*(_execute_task(a, cache) for a in args))\n\nxarray/tests/test_variable.py::TestNumpyCoercion::test_from_sparse[Variable]\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/sparse/_coo/core.py:216: DeprecationWarning: coords should be an ndarray. This will raise a ValueError in the future.\n    warnings.warn(\n\nxarray/tests/test_variable.py::TestNumpyCoercion::test_from_sparse[Variable]\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/sparse/_coo/core.py:245: DeprecationWarning: shape should be provided. This will raise a ValueError in the future.\n    warnings.warn(\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n===== 431 passed, 58 skipped, 15 xfailed, 23 xpassed, 6 warnings in 11.75s =====\n\n",
          "test_files_run": [
            "xarray/tests/test_variable.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "pydata__xarray-6992",
      "repo": "pydata/xarray",
      "valid": false,
      "worker": "http://34.123.9.23:8080",
      "error": "HTTPConnectionPool(host='34.123.9.23', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "pydata__xarray-7229",
      "repo": "pydata/xarray",
      "valid": true,
      "worker": "http://34.123.9.23:8080",
      "duration": 31.480114936828613,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 280,
          "failed": 1,
          "errors": 0,
          "collected": 282,
          "duration": 15.77,
          "log_tail": "xarray/tests/test_computation.py::test_polyfit_polyval_integration[1D-simple-dask] PASSED [ 91%]\nxarray/tests/test_computation.py::test_polyfit_polyval_integration[1D-datetime-nodask] PASSED [ 91%]\nxarray/tests/test_computation.py::test_polyfit_polyval_integration[1D-datetime-dask] PASSED [ 92%]\nxarray/tests/test_computation.py::test_polyfit_polyval_integration[1D-timedelta-nodask] PASSED [ 92%]\nxarray/tests/test_computation.py::test_polyfit_polyval_integration[1D-timedelta-dask] PASSED [ 92%]\nxarray/tests/test_computation.py::test_polyfit_polyval_integration[2D-simple-nodask] PASSED [ 93%]\nxarray/tests/test_computation.py::test_polyfit_polyval_integration[2D-simple-dask] PASSED [ 93%]\nxarray/tests/test_computation.py::test_polyfit_polyval_integration[2D-datetime-nodask] PASSED [ 93%]\nxarray/tests/test_computation.py::test_polyfit_polyval_integration[2D-datetime-dask] PASSED [ 94%]\nxarray/tests/test_computation.py::test_polyfit_polyval_integration[2D-timedelta-nodask] PASSED [ 94%]\nxarray/tests/test_computation.py::test_polyfit_polyval_integration[2D-timedelta-dask] PASSED [ 95%]\nxarray/tests/test_computation.py::test_cross[a0-b0-ae0-be0-dim_0--1-False] PASSED [ 95%]\nxarray/tests/test_computation.py::test_cross[a0-b0-ae0-be0-dim_0--1-True] PASSED [ 95%]\nxarray/tests/test_computation.py::test_cross[a1-b1-ae1-be1-dim_0--1-False] PASSED [ 96%]\nxarray/tests/test_computation.py::test_cross[a1-b1-ae1-be1-dim_0--1-True] PASSED [ 96%]\nxarray/tests/test_computation.py::test_cross[a2-b2-ae2-be2-dim_0--1-False] PASSED [ 96%]\nxarray/tests/test_computation.py::test_cross[a2-b2-ae2-be2-dim_0--1-True] PASSED [ 97%]\nxarray/tests/test_computation.py::test_cross[a3-b3-ae3-be3-dim_0--1-False] PASSED [ 97%]\nxarray/tests/test_computation.py::test_cross[a3-b3-ae3-be3-dim_0--1-True] PASSED [ 97%]\nxarray/tests/test_computation.py::test_cross[a4-b4-ae4-be4-cartesian-1-False] PASSED [ 98%]\nxarray/tests/test_computation.py::test_cross[a4-b4-ae4-be4-cartesian-1-True] PASSED [ 98%]\nxarray/tests/test_computation.py::test_cross[a5-b5-ae5-be5-cartesian--1-False] PASSED [ 98%]\nxarray/tests/test_computation.py::test_cross[a5-b5-ae5-be5-cartesian--1-True] PASSED [ 99%]\nxarray/tests/test_computation.py::test_cross[a6-b6-ae6-be6-cartesian--1-False] PASSED [ 99%]\nxarray/tests/test_computation.py::test_cross[a6-b6-ae6-be6-cartesian--1-True] PASSED [100%]\n\n=================================== FAILURES ===================================\n_______________________________ test_where_attrs _______________________________\n/testbed/xarray/tests/test_computation.py:1939: in test_where_attrs\n    assert_identical(expected, actual)\nE   AssertionError: Left and right DataArray objects are not identical\nE   \nE   Differing coordinates:\nE   L * a        (a) int64 0 1\nE       attr: x_coord\nE   R * a        (a) int64 0 1\nE       attr: x_da\n=============================== warnings summary ===============================\nxarray/tests/test_computation.py::test_polyval_cftime[1970-01-01-nodask]\nxarray/tests/test_computation.py::test_polyval_cftime[1970-01-01-dask]\nxarray/tests/test_computation.py::test_polyval_cftime[0753-04-21-nodask]\nxarray/tests/test_computation.py::test_polyval_cftime[0753-04-21-dask]\n  /testbed/xarray/coding/cftime_offsets.py:1134: FutureWarning: Argument `closed` is deprecated in favor of `inclusive`.\n    return pd.date_range(\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n============= 1 failed, 280 passed, 1 skipped, 4 warnings in 9.48s =============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN xarray/tests/test_computation.py` failed. (See above for error)",
          "test_files_run": [
            "xarray/tests/test_computation.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 281,
          "failed": 0,
          "errors": 0,
          "collected": 282,
          "duration": 14.25,
          "log_tail": "xarray/tests/test_computation.py::test_polyval[dataset-dataset-nodask] PASSED [ 87%]\nxarray/tests/test_computation.py::test_polyval[dataset-dataset-dask] PASSED [ 87%]\nxarray/tests/test_computation.py::test_polyval[datetime-nodask] PASSED   [ 87%]\nxarray/tests/test_computation.py::test_polyval[datetime-dask] PASSED     [ 88%]\nxarray/tests/test_computation.py::test_polyval[timedelta-nodask] PASSED  [ 88%]\nxarray/tests/test_computation.py::test_polyval[timedelta-dask] PASSED    [ 89%]\nxarray/tests/test_computation.py::test_polyval_cftime[1970-01-01-nodask] PASSED [ 89%]\nxarray/tests/test_computation.py::test_polyval_cftime[1970-01-01-dask] PASSED [ 89%]\nxarray/tests/test_computation.py::test_polyval_cftime[0753-04-21-nodask] PASSED [ 90%]\nxarray/tests/test_computation.py::test_polyval_cftime[0753-04-21-dask] PASSED [ 90%]\nxarray/tests/test_computation.py::test_polyval_degree_dim_checks PASSED  [ 90%]\nxarray/tests/test_computation.py::test_polyfit_polyval_integration[1D-simple-nodask] PASSED [ 91%]\nxarray/tests/test_computation.py::test_polyfit_polyval_integration[1D-simple-dask] PASSED [ 91%]\nxarray/tests/test_computation.py::test_polyfit_polyval_integration[1D-datetime-nodask] PASSED [ 91%]\nxarray/tests/test_computation.py::test_polyfit_polyval_integration[1D-datetime-dask] PASSED [ 92%]\nxarray/tests/test_computation.py::test_polyfit_polyval_integration[1D-timedelta-nodask] PASSED [ 92%]\nxarray/tests/test_computation.py::test_polyfit_polyval_integration[1D-timedelta-dask] PASSED [ 92%]\nxarray/tests/test_computation.py::test_polyfit_polyval_integration[2D-simple-nodask] PASSED [ 93%]\nxarray/tests/test_computation.py::test_polyfit_polyval_integration[2D-simple-dask] PASSED [ 93%]\nxarray/tests/test_computation.py::test_polyfit_polyval_integration[2D-datetime-nodask] PASSED [ 93%]\nxarray/tests/test_computation.py::test_polyfit_polyval_integration[2D-datetime-dask] PASSED [ 94%]\nxarray/tests/test_computation.py::test_polyfit_polyval_integration[2D-timedelta-nodask] PASSED [ 94%]\nxarray/tests/test_computation.py::test_polyfit_polyval_integration[2D-timedelta-dask] PASSED [ 95%]\nxarray/tests/test_computation.py::test_cross[a0-b0-ae0-be0-dim_0--1-False] PASSED [ 95%]\nxarray/tests/test_computation.py::test_cross[a0-b0-ae0-be0-dim_0--1-True] PASSED [ 95%]\nxarray/tests/test_computation.py::test_cross[a1-b1-ae1-be1-dim_0--1-False] PASSED [ 96%]\nxarray/tests/test_computation.py::test_cross[a1-b1-ae1-be1-dim_0--1-True] PASSED [ 96%]\nxarray/tests/test_computation.py::test_cross[a2-b2-ae2-be2-dim_0--1-False] PASSED [ 96%]\nxarray/tests/test_computation.py::test_cross[a2-b2-ae2-be2-dim_0--1-True] PASSED [ 97%]\nxarray/tests/test_computation.py::test_cross[a3-b3-ae3-be3-dim_0--1-False] PASSED [ 97%]\nxarray/tests/test_computation.py::test_cross[a3-b3-ae3-be3-dim_0--1-True] PASSED [ 97%]\nxarray/tests/test_computation.py::test_cross[a4-b4-ae4-be4-cartesian-1-False] PASSED [ 98%]\nxarray/tests/test_computation.py::test_cross[a4-b4-ae4-be4-cartesian-1-True] PASSED [ 98%]\nxarray/tests/test_computation.py::test_cross[a5-b5-ae5-be5-cartesian--1-False] PASSED [ 98%]\nxarray/tests/test_computation.py::test_cross[a5-b5-ae5-be5-cartesian--1-True] PASSED [ 99%]\nxarray/tests/test_computation.py::test_cross[a6-b6-ae6-be6-cartesian--1-False] PASSED [ 99%]\nxarray/tests/test_computation.py::test_cross[a6-b6-ae6-be6-cartesian--1-True] PASSED [100%]\n\n=============================== warnings summary ===============================\nxarray/tests/test_computation.py::test_polyval_cftime[1970-01-01-nodask]\nxarray/tests/test_computation.py::test_polyval_cftime[1970-01-01-dask]\nxarray/tests/test_computation.py::test_polyval_cftime[0753-04-21-nodask]\nxarray/tests/test_computation.py::test_polyval_cftime[0753-04-21-dask]\n  /testbed/xarray/coding/cftime_offsets.py:1134: FutureWarning: Argument `closed` is deprecated in favor of `inclusive`.\n    return pd.date_range(\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================== 281 passed, 1 skipped, 4 warnings in 8.10s ==================\n\n",
          "test_files_run": [
            "xarray/tests/test_computation.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "pydata__xarray-7233",
      "repo": "pydata/xarray",
      "valid": true,
      "worker": "http://34.123.9.23:8080",
      "duration": 21.35968804359436,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 189,
          "failed": 1,
          "errors": 0,
          "collected": 198,
          "duration": 10.23,
          "log_tail": "xarray/tests/test_coarsen.py::test_coarsen_da_reduce[numpy-max-4-2] PASSED [ 82%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-sum-1-1] PASSED [ 82%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-sum-1-2] SKIPPED [ 83%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-sum-2-1] PASSED [ 83%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-sum-2-2] PASSED [ 84%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-sum-3-1] PASSED [ 84%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-sum-3-2] PASSED [ 85%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-sum-4-1] PASSED [ 85%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-sum-4-2] PASSED [ 86%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-mean-1-1] PASSED [ 86%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-mean-1-2] SKIPPED [ 87%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-mean-2-1] PASSED [ 87%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-mean-2-2] PASSED [ 88%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-mean-3-1] PASSED [ 88%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-mean-3-2] PASSED [ 89%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-mean-4-1] PASSED [ 89%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-mean-4-2] PASSED [ 90%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-std-1-1] PASSED [ 90%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-std-1-2] SKIPPED [ 91%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-std-2-1] PASSED [ 91%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-std-2-2] PASSED [ 92%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-std-3-1] PASSED [ 92%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-std-3-2] PASSED [ 93%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-std-4-1] PASSED [ 93%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-std-4-2] PASSED [ 94%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-max-1-1] PASSED [ 94%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-max-1-2] SKIPPED [ 95%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-max-2-1] PASSED [ 95%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-max-2-2] PASSED [ 96%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-max-3-1] PASSED [ 96%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-max-3-2] PASSED [ 97%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-max-4-1] PASSED [ 97%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-max-4-2] PASSED [ 98%]\nxarray/tests/test_coarsen.py::TestCoarsenConstruct::test_coarsen_construct[True] PASSED [ 98%]\nxarray/tests/test_coarsen.py::TestCoarsenConstruct::test_coarsen_construct[False] PASSED [ 99%]\nxarray/tests/test_coarsen.py::TestCoarsenConstruct::test_coarsen_construct_keeps_all_coords FAILED [100%]\n\n=================================== FAILURES ===================================\n_________ TestCoarsenConstruct.test_coarsen_construct_keeps_all_coords _________\n/testbed/xarray/tests/test_coarsen.py:340: in test_coarsen_construct_keeps_all_coords\n    assert list(da.coords) == list(result.coords)\nE   AssertionError: assert ['day'] == []\nE     Left contains one more item: 'day'\nE     Full diff:\nE     - []\nE     + ['day']\n=================== 1 failed, 189 passed, 8 skipped in 3.76s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN xarray/tests/test_coarsen.py` failed. (See above for error)",
          "test_files_run": [
            "xarray/tests/test_coarsen.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 190,
          "failed": 0,
          "errors": 0,
          "collected": 198,
          "duration": 9.62,
          "log_tail": "xarray/tests/test_coarsen.py::test_coarsen_da_reduce[numpy-std-3-2] PASSED [ 77%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[numpy-std-4-1] PASSED [ 77%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[numpy-std-4-2] PASSED [ 78%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[numpy-max-1-1] PASSED [ 78%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[numpy-max-1-2] SKIPPED [ 79%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[numpy-max-2-1] PASSED [ 79%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[numpy-max-2-2] PASSED [ 80%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[numpy-max-3-1] PASSED [ 80%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[numpy-max-3-2] PASSED [ 81%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[numpy-max-4-1] PASSED [ 81%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[numpy-max-4-2] PASSED [ 82%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-sum-1-1] PASSED [ 82%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-sum-1-2] SKIPPED [ 83%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-sum-2-1] PASSED [ 83%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-sum-2-2] PASSED [ 84%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-sum-3-1] PASSED [ 84%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-sum-3-2] PASSED [ 85%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-sum-4-1] PASSED [ 85%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-sum-4-2] PASSED [ 86%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-mean-1-1] PASSED [ 86%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-mean-1-2] SKIPPED [ 87%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-mean-2-1] PASSED [ 87%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-mean-2-2] PASSED [ 88%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-mean-3-1] PASSED [ 88%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-mean-3-2] PASSED [ 89%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-mean-4-1] PASSED [ 89%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-mean-4-2] PASSED [ 90%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-std-1-1] PASSED [ 90%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-std-1-2] SKIPPED [ 91%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-std-2-1] PASSED [ 91%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-std-2-2] PASSED [ 92%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-std-3-1] PASSED [ 92%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-std-3-2] PASSED [ 93%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-std-4-1] PASSED [ 93%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-std-4-2] PASSED [ 94%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-max-1-1] PASSED [ 94%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-max-1-2] SKIPPED [ 95%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-max-2-1] PASSED [ 95%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-max-2-2] PASSED [ 96%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-max-3-1] PASSED [ 96%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-max-3-2] PASSED [ 97%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-max-4-1] PASSED [ 97%]\nxarray/tests/test_coarsen.py::test_coarsen_da_reduce[dask-max-4-2] PASSED [ 98%]\nxarray/tests/test_coarsen.py::TestCoarsenConstruct::test_coarsen_construct[True] PASSED [ 98%]\nxarray/tests/test_coarsen.py::TestCoarsenConstruct::test_coarsen_construct[False] PASSED [ 99%]\nxarray/tests/test_coarsen.py::TestCoarsenConstruct::test_coarsen_construct_keeps_all_coords PASSED [100%]\n\n======================== 190 passed, 8 skipped in 3.46s ========================\n\n",
          "test_files_run": [
            "xarray/tests/test_coarsen.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "pydata__xarray-7393",
      "repo": "pydata/xarray",
      "valid": true,
      "worker": "http://34.123.9.23:8080",
      "duration": 17.380507230758667,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 71,
          "failed": 2,
          "errors": 0,
          "collected": 73,
          "duration": 8.13,
          "log_tail": "xarray/tests/test_indexes.py::TestPandasMultiIndex::test_stack_non_unique PASSED [ 57%]\nxarray/tests/test_indexes.py::TestPandasMultiIndex::test_unstack PASSED  [ 58%]\nxarray/tests/test_indexes.py::TestPandasMultiIndex::test_create_variables PASSED [ 60%]\nxarray/tests/test_indexes.py::TestPandasMultiIndex::test_sel PASSED      [ 61%]\nxarray/tests/test_indexes.py::TestPandasMultiIndex::test_join PASSED     [ 63%]\nxarray/tests/test_indexes.py::TestPandasMultiIndex::test_rename PASSED   [ 64%]\nxarray/tests/test_indexes.py::TestPandasMultiIndex::test_copy PASSED     [ 65%]\nxarray/tests/test_indexes.py::TestIndexes::test_interface[pd_index] PASSED [ 67%]\nxarray/tests/test_indexes.py::TestIndexes::test_interface[xr_index] PASSED [ 68%]\nxarray/tests/test_indexes.py::TestIndexes::test_variables[pd_index] PASSED [ 69%]\nxarray/tests/test_indexes.py::TestIndexes::test_variables[xr_index] PASSED [ 71%]\nxarray/tests/test_indexes.py::TestIndexes::test_dims[pd_index] PASSED    [ 72%]\nxarray/tests/test_indexes.py::TestIndexes::test_dims[xr_index] PASSED    [ 73%]\nxarray/tests/test_indexes.py::TestIndexes::test_get_unique[pd_index] PASSED [ 75%]\nxarray/tests/test_indexes.py::TestIndexes::test_get_unique[xr_index] PASSED [ 76%]\nxarray/tests/test_indexes.py::TestIndexes::test_is_multi[pd_index] PASSED [ 78%]\nxarray/tests/test_indexes.py::TestIndexes::test_is_multi[xr_index] PASSED [ 79%]\nxarray/tests/test_indexes.py::TestIndexes::test_get_all_coords[pd_index] PASSED [ 80%]\nxarray/tests/test_indexes.py::TestIndexes::test_get_all_coords[xr_index] PASSED [ 82%]\nxarray/tests/test_indexes.py::TestIndexes::test_get_all_dims[pd_index] PASSED [ 83%]\nxarray/tests/test_indexes.py::TestIndexes::test_get_all_dims[xr_index] PASSED [ 84%]\nxarray/tests/test_indexes.py::TestIndexes::test_group_by_index[pd_index] PASSED [ 86%]\nxarray/tests/test_indexes.py::TestIndexes::test_group_by_index[xr_index] PASSED [ 87%]\nxarray/tests/test_indexes.py::TestIndexes::test_to_pandas_indexes[pd_index] PASSED [ 89%]\nxarray/tests/test_indexes.py::TestIndexes::test_to_pandas_indexes[xr_index] PASSED [ 90%]\nxarray/tests/test_indexes.py::TestIndexes::test_copy_indexes[pd_index] PASSED [ 91%]\nxarray/tests/test_indexes.py::TestIndexes::test_copy_indexes[xr_index] PASSED [ 93%]\nxarray/tests/test_indexes.py::test_safe_cast_to_index PASSED             [ 94%]\nxarray/tests/test_indexes.py::test_safe_cast_to_index_cftimeindex PASSED [ 95%]\nxarray/tests/test_indexes.py::test_safe_cast_to_index_datetime_datetime PASSED [ 97%]\nxarray/tests/test_indexes.py::test_restore_dtype_on_multiindexes[int32] FAILED [ 98%]\nxarray/tests/test_indexes.py::test_restore_dtype_on_multiindexes[float32] FAILED [100%]\n\n=================================== FAILURES ===================================\n__________________ test_restore_dtype_on_multiindexes[int32] ___________________\n/testbed/xarray/tests/test_indexes.py:706: in test_restore_dtype_on_multiindexes\n    assert str(foo[\"bar\"].values.dtype) == dtype\nE   AssertionError: assert 'int64' == 'int32'\nE     - int32\nE     + int64\n_________________ test_restore_dtype_on_multiindexes[float32] __________________\n/testbed/xarray/tests/test_indexes.py:706: in test_restore_dtype_on_multiindexes\n    assert str(foo[\"bar\"].values.dtype) == dtype\nE   AssertionError: assert 'float64' == 'float32'\nE     - float32\nE     + float64\n========================= 2 failed, 71 passed in 1.73s =========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN xarray/tests/test_indexes.py` failed. (See above for error)",
          "test_files_run": [
            "xarray/tests/test_indexes.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 73,
          "failed": 0,
          "errors": 0,
          "collected": 73,
          "duration": 7.74,
          "log_tail": "xarray/tests/test_indexes.py::TestPandasIndex::test_sel PASSED           [ 38%]\nxarray/tests/test_indexes.py::TestPandasIndex::test_sel_boolean PASSED   [ 39%]\nxarray/tests/test_indexes.py::TestPandasIndex::test_sel_datetime PASSED  [ 41%]\nxarray/tests/test_indexes.py::TestPandasIndex::test_sel_unsorted_datetime_index_raises PASSED [ 42%]\nxarray/tests/test_indexes.py::TestPandasIndex::test_equals PASSED        [ 43%]\nxarray/tests/test_indexes.py::TestPandasIndex::test_join PASSED          [ 45%]\nxarray/tests/test_indexes.py::TestPandasIndex::test_reindex_like PASSED  [ 46%]\nxarray/tests/test_indexes.py::TestPandasIndex::test_rename PASSED        [ 47%]\nxarray/tests/test_indexes.py::TestPandasIndex::test_copy PASSED          [ 49%]\nxarray/tests/test_indexes.py::TestPandasIndex::test_getitem PASSED       [ 50%]\nxarray/tests/test_indexes.py::TestPandasMultiIndex::test_constructor PASSED [ 52%]\nxarray/tests/test_indexes.py::TestPandasMultiIndex::test_from_variables PASSED [ 53%]\nxarray/tests/test_indexes.py::TestPandasMultiIndex::test_concat PASSED   [ 54%]\nxarray/tests/test_indexes.py::TestPandasMultiIndex::test_stack PASSED    [ 56%]\nxarray/tests/test_indexes.py::TestPandasMultiIndex::test_stack_non_unique PASSED [ 57%]\nxarray/tests/test_indexes.py::TestPandasMultiIndex::test_unstack PASSED  [ 58%]\nxarray/tests/test_indexes.py::TestPandasMultiIndex::test_create_variables PASSED [ 60%]\nxarray/tests/test_indexes.py::TestPandasMultiIndex::test_sel PASSED      [ 61%]\nxarray/tests/test_indexes.py::TestPandasMultiIndex::test_join PASSED     [ 63%]\nxarray/tests/test_indexes.py::TestPandasMultiIndex::test_rename PASSED   [ 64%]\nxarray/tests/test_indexes.py::TestPandasMultiIndex::test_copy PASSED     [ 65%]\nxarray/tests/test_indexes.py::TestIndexes::test_interface[pd_index] PASSED [ 67%]\nxarray/tests/test_indexes.py::TestIndexes::test_interface[xr_index] PASSED [ 68%]\nxarray/tests/test_indexes.py::TestIndexes::test_variables[pd_index] PASSED [ 69%]\nxarray/tests/test_indexes.py::TestIndexes::test_variables[xr_index] PASSED [ 71%]\nxarray/tests/test_indexes.py::TestIndexes::test_dims[pd_index] PASSED    [ 72%]\nxarray/tests/test_indexes.py::TestIndexes::test_dims[xr_index] PASSED    [ 73%]\nxarray/tests/test_indexes.py::TestIndexes::test_get_unique[pd_index] PASSED [ 75%]\nxarray/tests/test_indexes.py::TestIndexes::test_get_unique[xr_index] PASSED [ 76%]\nxarray/tests/test_indexes.py::TestIndexes::test_is_multi[pd_index] PASSED [ 78%]\nxarray/tests/test_indexes.py::TestIndexes::test_is_multi[xr_index] PASSED [ 79%]\nxarray/tests/test_indexes.py::TestIndexes::test_get_all_coords[pd_index] PASSED [ 80%]\nxarray/tests/test_indexes.py::TestIndexes::test_get_all_coords[xr_index] PASSED [ 82%]\nxarray/tests/test_indexes.py::TestIndexes::test_get_all_dims[pd_index] PASSED [ 83%]\nxarray/tests/test_indexes.py::TestIndexes::test_get_all_dims[xr_index] PASSED [ 84%]\nxarray/tests/test_indexes.py::TestIndexes::test_group_by_index[pd_index] PASSED [ 86%]\nxarray/tests/test_indexes.py::TestIndexes::test_group_by_index[xr_index] PASSED [ 87%]\nxarray/tests/test_indexes.py::TestIndexes::test_to_pandas_indexes[pd_index] PASSED [ 89%]\nxarray/tests/test_indexes.py::TestIndexes::test_to_pandas_indexes[xr_index] PASSED [ 90%]\nxarray/tests/test_indexes.py::TestIndexes::test_copy_indexes[pd_index] PASSED [ 91%]\nxarray/tests/test_indexes.py::TestIndexes::test_copy_indexes[xr_index] PASSED [ 93%]\nxarray/tests/test_indexes.py::test_safe_cast_to_index PASSED             [ 94%]\nxarray/tests/test_indexes.py::test_safe_cast_to_index_cftimeindex PASSED [ 95%]\nxarray/tests/test_indexes.py::test_safe_cast_to_index_datetime_datetime PASSED [ 97%]\nxarray/tests/test_indexes.py::test_restore_dtype_on_multiindexes[int32] PASSED [ 98%]\nxarray/tests/test_indexes.py::test_restore_dtype_on_multiindexes[float32] PASSED [100%]\n\n============================== 73 passed in 1.63s ==============================\n\n",
          "test_files_run": [
            "xarray/tests/test_indexes.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "psf__requests-1142",
      "repo": "psf/requests",
      "valid": false,
      "worker": "http://34.123.9.23:8080",
      "duration": 8.372575998306274,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 5,
          "failed": 22,
          "errors": 0,
          "collected": 27,
          "duration": 3.53,
          "log_tail": "    return request('get', url, **kwargs)\nrequests/api.py:44: in request\n    return session.request(method=method, url=url, **kwargs)\nrequests/sessions.py:280: in request\n    resp = self.send(prep, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)\nrequests/sessions.py:373: in send\n    r = adapter.send(request, **kwargs)\nrequests/adapters.py:161: in send\n    resp = conn.urlopen(\nrequests/packages/urllib3/connectionpool.py:416: in urlopen\n    conn = self._get_conn(timeout=pool_timeout)\nrequests/packages/urllib3/connectionpool.py:231: in _get_conn\n    return conn or self._new_conn()\nrequests/packages/urllib3/connectionpool.py:196: in _new_conn\n    return HTTPConnection(host=self.host,\nE   TypeError: __init__() got an unexpected keyword argument 'strict'\n__________________ RequestsTestCase.test_user_agent_transfers __________________\ntest_requests.py:120: in test_user_agent_transfers\n    r = requests.get(httpbin('user-agent'), headers=heads)\nrequests/api.py:55: in get\n    return request('get', url, **kwargs)\nrequests/api.py:44: in request\n    return session.request(method=method, url=url, **kwargs)\nrequests/sessions.py:280: in request\n    resp = self.send(prep, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)\nrequests/sessions.py:373: in send\n    r = adapter.send(request, **kwargs)\nrequests/adapters.py:161: in send\n    resp = conn.urlopen(\nrequests/packages/urllib3/connectionpool.py:416: in urlopen\n    conn = self._get_conn(timeout=pool_timeout)\nrequests/packages/urllib3/connectionpool.py:231: in _get_conn\n    return conn or self._new_conn()\nrequests/packages/urllib3/connectionpool.py:196: in _new_conn\n    return HTTPConnection(host=self.host,\nE   TypeError: __init__() got an unexpected keyword argument 'strict'\n=============================== warnings summary ===============================\nrequests/packages/urllib3/_collections.py:7\n  /testbed/requests/packages/urllib3/_collections.py:7: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import MutableMapping\n\ntest_requests.py::RequestsTestCase::test_BASICAUTH_TUPLE_HTTP_200_OK_GET\n  /testbed/requests/models.py:140: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    if isinstance(hook, collections.Callable):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=================== 22 failed, 5 passed, 2 warnings in 0.70s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN test_requests.py` failed. (See above for error)",
          "test_files_run": [
            "test_requests.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 6,
          "failed": 21,
          "errors": 0,
          "collected": 27,
          "duration": 3.36,
          "log_tail": "    resp = conn.urlopen(\nrequests/packages/urllib3/connectionpool.py:416: in urlopen\n    conn = self._get_conn(timeout=pool_timeout)\nrequests/packages/urllib3/connectionpool.py:231: in _get_conn\n    return conn or self._new_conn()\nrequests/packages/urllib3/connectionpool.py:196: in _new_conn\n    return HTTPConnection(host=self.host,\nE   TypeError: __init__() got an unexpected keyword argument 'strict'\n__________________ RequestsTestCase.test_user_agent_transfers __________________\ntest_requests.py:120: in test_user_agent_transfers\n    r = requests.get(httpbin('user-agent'), headers=heads)\nrequests/api.py:55: in get\n    return request('get', url, **kwargs)\nrequests/api.py:44: in request\n    return session.request(method=method, url=url, **kwargs)\nrequests/sessions.py:280: in request\n    resp = self.send(prep, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)\nrequests/sessions.py:373: in send\n    r = adapter.send(request, **kwargs)\nrequests/adapters.py:161: in send\n    resp = conn.urlopen(\nrequests/packages/urllib3/connectionpool.py:416: in urlopen\n    conn = self._get_conn(timeout=pool_timeout)\nrequests/packages/urllib3/connectionpool.py:231: in _get_conn\n    return conn or self._new_conn()\nrequests/packages/urllib3/connectionpool.py:196: in _new_conn\n    return HTTPConnection(host=self.host,\nE   TypeError: __init__() got an unexpected keyword argument 'strict'\n=============================== warnings summary ===============================\nrequests/packages/urllib3/_collections.py:7\n  /testbed/requests/packages/urllib3/_collections.py:7: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import MutableMapping\n\nrequests/models.py:608\n  /testbed/requests/models.py:608: DeprecationWarning: invalid escape sequence \\*\n    \"\"\"Returns the json-encoded content of a response, if any.\n\nrequests/models.py:561\n  /testbed/requests/models.py:561: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.status_code is 0:\n\ntest_requests.py::RequestsTestCase::test_BASICAUTH_TUPLE_HTTP_200_OK_GET\n  /testbed/requests/models.py:140: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    if isinstance(hook, collections.Callable):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=================== 21 failed, 6 passed, 4 warnings in 0.58s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN test_requests.py` failed. (See above for error)",
          "test_files_run": [
            "test_requests.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "psf__requests-1724",
      "repo": "psf/requests",
      "valid": false,
      "worker": "http://34.123.9.23:8080",
      "error": "HTTPConnectionPool(host='34.123.9.23', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "psf__requests-1766",
      "repo": "psf/requests",
      "valid": false,
      "worker": "http://34.123.9.23:8080",
      "duration": 49.65864586830139,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 89,
          "failed": 2,
          "errors": 0,
          "collected": 91,
          "duration": 25.58,
          "log_tail": "test_requests.py::TestContentEncodingDetection::test_precedence PASSED   [ 76%]\ntest_requests.py::TestContentEncodingDetection::test_xhtml_pragma PASSED [ 78%]\ntest_requests.py::TestContentEncodingDetection::test_xml PASSED          [ 79%]\ntest_requests.py::TestCaseInsensitiveDict::test_contains PASSED          [ 80%]\ntest_requests.py::TestCaseInsensitiveDict::test_delitem PASSED           [ 81%]\ntest_requests.py::TestCaseInsensitiveDict::test_docstring_example PASSED [ 82%]\ntest_requests.py::TestCaseInsensitiveDict::test_equality PASSED          [ 83%]\ntest_requests.py::TestCaseInsensitiveDict::test_fixes_649 PASSED         [ 84%]\ntest_requests.py::TestCaseInsensitiveDict::test_get PASSED               [ 85%]\ntest_requests.py::TestCaseInsensitiveDict::test_getitem PASSED           [ 86%]\ntest_requests.py::TestCaseInsensitiveDict::test_iter PASSED              [ 87%]\ntest_requests.py::TestCaseInsensitiveDict::test_iterable_init PASSED     [ 89%]\ntest_requests.py::TestCaseInsensitiveDict::test_kwargs_init PASSED       [ 90%]\ntest_requests.py::TestCaseInsensitiveDict::test_len PASSED               [ 91%]\ntest_requests.py::TestCaseInsensitiveDict::test_lower_items PASSED       [ 92%]\ntest_requests.py::TestCaseInsensitiveDict::test_mapping_init PASSED      [ 93%]\ntest_requests.py::TestCaseInsensitiveDict::test_preserve_key_case PASSED [ 94%]\ntest_requests.py::TestCaseInsensitiveDict::test_preserve_last_key_case PASSED [ 95%]\ntest_requests.py::TestCaseInsensitiveDict::test_setdefault PASSED        [ 96%]\ntest_requests.py::TestCaseInsensitiveDict::test_update PASSED            [ 97%]\ntest_requests.py::TestCaseInsensitiveDict::test_update_retains_unchanged PASSED [ 98%]\ntest_requests.py::UtilsTestCase::test_super_len_io_streams PASSED        [100%]\n\n=================================== FAILURES ===================================\n______________ RequestsTestCase.test_DIGESTAUTH_QUOTES_QOP_VALUE _______________\ntest_requests.py:329: in test_DIGESTAUTH_QUOTES_QOP_VALUE\n    assert '\"auth\"' in r.request.headers['Authorization']\nE   assert '\"auth\"' in 'Digest username=\"user\", realm=\"me@kennethreitz.com\", nonce=\"4bcc2dd6f7bc4332321f5d7ef095181a\", uri=\"/digest-auth/auth/user/pass\", response=\"678ffc5093c68445e1994d4c06832e9d\", opaque=\"6ef54be63dcd4bd0d51fdff91500b80d\", algorithm=\"MD5\", qop=auth, nc=00000001, cnonce=\"62546750e15d7247\"'\n________________ RequestsTestCase.test_conflicting_post_params _________________\ntest_requests.py:370: in test_conflicting_post_params\n    pytest.raises(ValueError, \"requests.post(url, data='[{\\\"some\\\": \\\"data\\\"}]', files={'some': f})\")\nE   TypeError: 'requests.post(url, data=\\'[{\"some\": \"data\"}]\\', files={\\'some\\': f})' object (type: <class 'str'>) must be callable\n=============================== warnings summary ===============================\nrequests/packages/urllib3/_collections.py:7\n  /testbed/requests/packages/urllib3/_collections.py:7: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import MutableMapping\n\nrequests/sessions.py:12\n  /testbed/requests/sessions.py:12: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping\n\ntest_requests.py::RequestsTestCase::test_BASICAUTH_TUPLE_HTTP_200_OK_GET\n  /testbed/requests/models.py:156: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    if isinstance(hook, collections.Callable):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================== 2 failed, 89 passed, 3 warnings in 22.92s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN test_requests.py` failed. (See above for error)",
          "test_files_run": [
            "test_requests.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 90,
          "failed": 1,
          "errors": 0,
          "collected": 91,
          "duration": 23.21,
          "log_tail": "test_requests.py::RequestsTestCase::test_user_agent_transfers PASSED     [ 72%]\ntest_requests.py::TestContentEncodingDetection::test_html4_pragma PASSED [ 73%]\ntest_requests.py::TestContentEncodingDetection::test_html_charset PASSED [ 74%]\ntest_requests.py::TestContentEncodingDetection::test_none PASSED         [ 75%]\ntest_requests.py::TestContentEncodingDetection::test_precedence PASSED   [ 76%]\ntest_requests.py::TestContentEncodingDetection::test_xhtml_pragma PASSED [ 78%]\ntest_requests.py::TestContentEncodingDetection::test_xml PASSED          [ 79%]\ntest_requests.py::TestCaseInsensitiveDict::test_contains PASSED          [ 80%]\ntest_requests.py::TestCaseInsensitiveDict::test_delitem PASSED           [ 81%]\ntest_requests.py::TestCaseInsensitiveDict::test_docstring_example PASSED [ 82%]\ntest_requests.py::TestCaseInsensitiveDict::test_equality PASSED          [ 83%]\ntest_requests.py::TestCaseInsensitiveDict::test_fixes_649 PASSED         [ 84%]\ntest_requests.py::TestCaseInsensitiveDict::test_get PASSED               [ 85%]\ntest_requests.py::TestCaseInsensitiveDict::test_getitem PASSED           [ 86%]\ntest_requests.py::TestCaseInsensitiveDict::test_iter PASSED              [ 87%]\ntest_requests.py::TestCaseInsensitiveDict::test_iterable_init PASSED     [ 89%]\ntest_requests.py::TestCaseInsensitiveDict::test_kwargs_init PASSED       [ 90%]\ntest_requests.py::TestCaseInsensitiveDict::test_len PASSED               [ 91%]\ntest_requests.py::TestCaseInsensitiveDict::test_lower_items PASSED       [ 92%]\ntest_requests.py::TestCaseInsensitiveDict::test_mapping_init PASSED      [ 93%]\ntest_requests.py::TestCaseInsensitiveDict::test_preserve_key_case PASSED [ 94%]\ntest_requests.py::TestCaseInsensitiveDict::test_preserve_last_key_case PASSED [ 95%]\ntest_requests.py::TestCaseInsensitiveDict::test_setdefault PASSED        [ 96%]\ntest_requests.py::TestCaseInsensitiveDict::test_update PASSED            [ 97%]\ntest_requests.py::TestCaseInsensitiveDict::test_update_retains_unchanged PASSED [ 98%]\ntest_requests.py::UtilsTestCase::test_super_len_io_streams PASSED        [100%]\n\n=================================== FAILURES ===================================\n________________ RequestsTestCase.test_conflicting_post_params _________________\ntest_requests.py:370: in test_conflicting_post_params\n    pytest.raises(ValueError, \"requests.post(url, data='[{\\\"some\\\": \\\"data\\\"}]', files={'some': f})\")\nE   TypeError: 'requests.post(url, data=\\'[{\"some\": \"data\"}]\\', files={\\'some\\': f})' object (type: <class 'str'>) must be callable\n=============================== warnings summary ===============================\nrequests/packages/urllib3/_collections.py:7\n  /testbed/requests/packages/urllib3/_collections.py:7: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import MutableMapping\n\nrequests/sessions.py:12\n  /testbed/requests/sessions.py:12: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping\n\ntest_requests.py::RequestsTestCase::test_BASICAUTH_TUPLE_HTTP_200_OK_GET\n  /testbed/requests/models.py:156: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    if isinstance(hook, collections.Callable):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================== 1 failed, 90 passed, 3 warnings in 20.95s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN test_requests.py` failed. (See above for error)",
          "test_files_run": [
            "test_requests.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "psf__requests-1921",
      "repo": "psf/requests",
      "valid": false,
      "worker": "http://34.123.9.23:8080",
      "error": "HTTPConnectionPool(host='34.123.9.23', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "psf__requests-2317",
      "repo": "psf/requests",
      "valid": false,
      "worker": "http://34.123.9.23:8080",
      "error": "Worker returned 504: {\"detail\":\"Test execution timed-out\"}",
      "retry_count": 0
    },
    {
      "instance_id": "psf__requests-2931",
      "repo": "psf/requests",
      "valid": false,
      "worker": "http://34.123.9.23:8080",
      "duration": 7.979304790496826,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 85,
          "failed": 1,
          "errors": 81,
          "collected": 168,
          "duration": 3.39,
          "log_tail": "requests/api.py:137\n  /testbed/requests/api.py:137: DeprecationWarning: invalid escape sequence \\*\n    \"\"\"Sends a DELETE request.\n\nrequests/sessions.py:473\n  /testbed/requests/sessions.py:473: DeprecationWarning: invalid escape sequence \\*\n    \"\"\"Sends a GET request. Returns :class:`Response` object.\n\nrequests/sessions.py:483\n  /testbed/requests/sessions.py:483: DeprecationWarning: invalid escape sequence \\*\n    \"\"\"Sends a OPTIONS request. Returns :class:`Response` object.\n\nrequests/sessions.py:493\n  /testbed/requests/sessions.py:493: DeprecationWarning: invalid escape sequence \\*\n    \"\"\"Sends a HEAD request. Returns :class:`Response` object.\n\nrequests/sessions.py:503\n  /testbed/requests/sessions.py:503: DeprecationWarning: invalid escape sequence \\*\n    \"\"\"Sends a POST request. Returns :class:`Response` object.\n\nrequests/sessions.py:514\n  /testbed/requests/sessions.py:514: DeprecationWarning: invalid escape sequence \\*\n    \"\"\"Sends a PUT request. Returns :class:`Response` object.\n\nrequests/sessions.py:524\n  /testbed/requests/sessions.py:524: DeprecationWarning: invalid escape sequence \\*\n    \"\"\"Sends a PATCH request. Returns :class:`Response` object.\n\nrequests/sessions.py:534\n  /testbed/requests/sessions.py:534: DeprecationWarning: invalid escape sequence \\*\n    \"\"\"Sends a DELETE request. Returns :class:`Response` object.\n\ntest_requests.py::TestRequests::test_invalid_url\n  /testbed/requests/models.py:168: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    if isinstance(hook, collections.Callable):\n\ntest_requests.py::TestContentEncodingDetection::test_html4_pragma\ntest_requests.py::TestContentEncodingDetection::test_html_charset\ntest_requests.py::TestContentEncodingDetection::test_none\ntest_requests.py::TestContentEncodingDetection::test_precedence\ntest_requests.py::TestContentEncodingDetection::test_xhtml_pragma\ntest_requests.py::TestContentEncodingDetection::test_xml\n  /testbed/requests/utils.py:315: DeprecationWarning: In requests 3.0, get_encodings_from_content will be removed. For more information, please see the discussion on issue #2266. (This warning should only appear once.)\n    warnings.warn((\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======= 1 failed, 85 passed, 1 xfailed, 28 warnings, 81 errors in 0.82s ========\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN test_requests.py` failed. (See above for error)",
          "test_files_run": [
            "test_requests.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 86,
          "failed": 0,
          "errors": 81,
          "collected": 168,
          "duration": 3.63,
          "log_tail": "requests/api.py:137\n  /testbed/requests/api.py:137: DeprecationWarning: invalid escape sequence \\*\n    \"\"\"Sends a DELETE request.\n\nrequests/sessions.py:473\n  /testbed/requests/sessions.py:473: DeprecationWarning: invalid escape sequence \\*\n    \"\"\"Sends a GET request. Returns :class:`Response` object.\n\nrequests/sessions.py:483\n  /testbed/requests/sessions.py:483: DeprecationWarning: invalid escape sequence \\*\n    \"\"\"Sends a OPTIONS request. Returns :class:`Response` object.\n\nrequests/sessions.py:493\n  /testbed/requests/sessions.py:493: DeprecationWarning: invalid escape sequence \\*\n    \"\"\"Sends a HEAD request. Returns :class:`Response` object.\n\nrequests/sessions.py:503\n  /testbed/requests/sessions.py:503: DeprecationWarning: invalid escape sequence \\*\n    \"\"\"Sends a POST request. Returns :class:`Response` object.\n\nrequests/sessions.py:514\n  /testbed/requests/sessions.py:514: DeprecationWarning: invalid escape sequence \\*\n    \"\"\"Sends a PUT request. Returns :class:`Response` object.\n\nrequests/sessions.py:524\n  /testbed/requests/sessions.py:524: DeprecationWarning: invalid escape sequence \\*\n    \"\"\"Sends a PATCH request. Returns :class:`Response` object.\n\nrequests/sessions.py:534\n  /testbed/requests/sessions.py:534: DeprecationWarning: invalid escape sequence \\*\n    \"\"\"Sends a DELETE request. Returns :class:`Response` object.\n\ntest_requests.py::TestRequests::test_invalid_url\n  /testbed/requests/models.py:168: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    if isinstance(hook, collections.Callable):\n\ntest_requests.py::TestContentEncodingDetection::test_html4_pragma\ntest_requests.py::TestContentEncodingDetection::test_html_charset\ntest_requests.py::TestContentEncodingDetection::test_none\ntest_requests.py::TestContentEncodingDetection::test_precedence\ntest_requests.py::TestContentEncodingDetection::test_xhtml_pragma\ntest_requests.py::TestContentEncodingDetection::test_xml\n  /testbed/requests/utils.py:315: DeprecationWarning: In requests 3.0, get_encodings_from_content will be removed. For more information, please see the discussion on issue #2266. (This warning should only appear once.)\n    warnings.warn((\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n============ 86 passed, 1 xfailed, 28 warnings, 81 errors in 0.87s =============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN test_requests.py` failed. (See above for error)",
          "test_files_run": [
            "test_requests.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "psf__requests-5414",
      "repo": "psf/requests",
      "valid": false,
      "worker": "http://34.123.9.23:8080",
      "duration": 9.246701002120972,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 130,
          "failed": 1,
          "errors": 158,
          "collected": 290,
          "duration": 4.07,
          "log_tail": "  @pytest.fixture\n  def httpbin(httpbin):\nE       recursive dependency involving fixture 'httpbin' detected\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, httpbin, httpbin_secure, monkeypatch, nosan_server, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/testbed/tests/conftest.py:28\n=================================== FAILURES ===================================\n________ TestRequests.test_invalid_url[InvalidURL-http://.example.com] _________\ntests/test_requests.py:89: in test_invalid_url\n    requests.get(url)\nrequests/api.py:75: in get\n    return request('get', url, params=params, **kwargs)\nrequests/api.py:61: in request\n    return session.request(method=method, url=url, **kwargs)\nrequests/sessions.py:529: in request\n    resp = self.send(prep, **send_kwargs)\nrequests/sessions.py:645: in send\n    r = adapter.send(request, **kwargs)\nrequests/adapters.py:440: in send\n    resp = conn.urlopen(\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/urllib3/connectionpool.py:716: in urlopen\n    httplib_response = self._make_request(\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/urllib3/connectionpool.py:416: in _make_request\n    conn.request(method, url, **httplib_request_kw)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/urllib3/connection.py:244: in request\n    super(HTTPConnection, self).request(method, url, body=body, headers=headers)\n/opt/miniconda3/envs/testbed/lib/python3.9/http/client.py:1285: in request\n    self._send_request(method, url, body, headers, encode_chunked)\n/opt/miniconda3/envs/testbed/lib/python3.9/http/client.py:1331: in _send_request\n    self.endheaders(body, encode_chunked=encode_chunked)\n/opt/miniconda3/envs/testbed/lib/python3.9/http/client.py:1280: in endheaders\n    self._send_output(message_body, encode_chunked=encode_chunked)\n/opt/miniconda3/envs/testbed/lib/python3.9/http/client.py:1040: in _send_output\n    self.send(msg)\n/opt/miniconda3/envs/testbed/lib/python3.9/http/client.py:980: in send\n    self.connect()\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/urllib3/connection.py:205: in connect\n    conn = self._new_conn()\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/urllib3/connection.py:174: in _new_conn\n    conn = connection.create_connection(\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/urllib3/util/connection.py:68: in create_connection\n    return six.raise_from(\n<string>:3: in raise_from\n    ???\nE   urllib3.exceptions.LocationParseError: Failed to parse: '.example.com', label empty or too long\n============= 1 failed, 130 passed, 1 xfailed, 158 errors in 1.35s =============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_requests.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_requests.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 131,
          "failed": 0,
          "errors": 158,
          "collected": 290,
          "duration": 4.23,
          "log_tail": "  @pytest.fixture\n  def httpbin(httpbin):\nE       recursive dependency involving fixture 'httpbin' detected\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, httpbin, httpbin_secure, monkeypatch, nosan_server, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/testbed/tests/conftest.py:28\n_ ERROR at setup of TestPreparingURLs.test_redirecting_to_bad_url[http://localhost:-1-InvalidURL] _\nfile /testbed/tests/test_requests.py, line 2501\n      @pytest.mark.parametrize(\n          'url, exception',\n          (\n              ('http://localhost:-1', InvalidURL),\n          )\n      )\n      def test_redirecting_to_bad_url(self, httpbin, url, exception):\nfile /testbed/tests/conftest.py, line 28\n  @pytest.fixture\n  def httpbin(httpbin):\nE       recursive dependency involving fixture 'httpbin' detected\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, httpbin, httpbin_secure, monkeypatch, nosan_server, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/testbed/tests/conftest.py:28\n____________ ERROR at setup of TestPreparingURLs.test_post_json_nan ____________\nfile /testbed/tests/test_requests.py, line 2581\n      def test_post_json_nan(self, httpbin):\nfile /testbed/tests/conftest.py, line 28\n  @pytest.fixture\n  def httpbin(httpbin):\nE       recursive dependency involving fixture 'httpbin' detected\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, httpbin, httpbin_secure, monkeypatch, nosan_server, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/testbed/tests/conftest.py:28\n______ ERROR at setup of TestPreparingURLs.test_json_decode_compatibility ______\nfile /testbed/tests/test_requests.py, line 2586\n      def test_json_decode_compatibility(self, httpbin):\nfile /testbed/tests/conftest.py, line 28\n  @pytest.fixture\n  def httpbin(httpbin):\nE       recursive dependency involving fixture 'httpbin' detected\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, httpbin, httpbin_secure, monkeypatch, nosan_server, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/testbed/tests/conftest.py:28\n================== 131 passed, 1 xfailed, 158 errors in 1.22s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_requests.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_requests.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "psf__requests-6028",
      "repo": "psf/requests",
      "valid": false,
      "worker": "http://34.123.9.23:8080",
      "duration": 7.220265865325928,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 193,
          "failed": 2,
          "errors": 8,
          "collected": 214,
          "duration": 3.15,
          "log_tail": "              ('http://user:pass@172.16.1.1:5000', '172.16.1.1'),\n              ('http://hostname/', 'hostname'),\n              ('http://hostname:5000/', 'hostname'),\n              ('http://user:pass@hostname', 'hostname'),\n              ('http://user:pass@hostname:5000', 'hostname'),\n      ))\n  def test_should_bypass_proxies_pass_only_hostname(url, expected, mocker):\nE       fixture 'mocker' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, httpbin, httpbin_secure, monkeypatch, nosan_server, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/testbed/tests/test_utils.py:663\n_ ERROR at setup of test_should_bypass_proxies_pass_only_hostname[http://user:pass@hostname:5000-hostname] _\nfile /testbed/tests/test_utils.py, line 663\n  @pytest.mark.parametrize(\n      'url, expected', (\n              ('http://172.16.1.1/', '172.16.1.1'),\n              ('http://172.16.1.1:5000/', '172.16.1.1'),\n              ('http://user:pass@172.16.1.1', '172.16.1.1'),\n              ('http://user:pass@172.16.1.1:5000', '172.16.1.1'),\n              ('http://hostname/', 'hostname'),\n              ('http://hostname:5000/', 'hostname'),\n              ('http://user:pass@hostname', 'hostname'),\n              ('http://user:pass@hostname:5000', 'hostname'),\n      ))\n  def test_should_bypass_proxies_pass_only_hostname(url, expected, mocker):\nE       fixture 'mocker' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, httpbin, httpbin_secure, monkeypatch, nosan_server, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/testbed/tests/test_utils.py:663\n=================================== FAILURES ===================================\n_ test_prepend_scheme_if_needed[http://user:pass@example.com/path?query-http://user:pass@example.com/path?query] _\ntests/test_utils.py:615: in test_prepend_scheme_if_needed\n    assert prepend_scheme_if_needed(value, 'http') == expected\nE   AssertionError: assert 'http://examp...om/path?query' == 'http://user:...om/path?query'\nE     - http://user:pass@example.com/path?query\nE     ?        ----------\nE     + http://example.com/path?query\n_ test_prepend_scheme_if_needed[http://user@example.com/path?query-http://user@example.com/path?query] _\ntests/test_utils.py:615: in test_prepend_scheme_if_needed\n    assert prepend_scheme_if_needed(value, 'http') == expected\nE   AssertionError: assert 'http://examp...om/path?query' == 'http://user@...om/path?query'\nE     - http://user@example.com/path?query\nE     ?        -----\nE     + http://example.com/path?query\n============= 2 failed, 193 passed, 11 skipped, 8 errors in 0.39s ==============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_utils.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_utils.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 195,
          "failed": 0,
          "errors": 8,
          "collected": 214,
          "duration": 3.06,
          "log_tail": "              ('http://user:pass@hostname:5000', 'hostname'),\n      ))\n  def test_should_bypass_proxies_pass_only_hostname(url, expected, mocker):\nE       fixture 'mocker' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, httpbin, httpbin_secure, monkeypatch, nosan_server, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/testbed/tests/test_utils.py:663\n_ ERROR at setup of test_should_bypass_proxies_pass_only_hostname[http://user:pass@hostname-hostname] _\nfile /testbed/tests/test_utils.py, line 663\n  @pytest.mark.parametrize(\n      'url, expected', (\n              ('http://172.16.1.1/', '172.16.1.1'),\n              ('http://172.16.1.1:5000/', '172.16.1.1'),\n              ('http://user:pass@172.16.1.1', '172.16.1.1'),\n              ('http://user:pass@172.16.1.1:5000', '172.16.1.1'),\n              ('http://hostname/', 'hostname'),\n              ('http://hostname:5000/', 'hostname'),\n              ('http://user:pass@hostname', 'hostname'),\n              ('http://user:pass@hostname:5000', 'hostname'),\n      ))\n  def test_should_bypass_proxies_pass_only_hostname(url, expected, mocker):\nE       fixture 'mocker' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, httpbin, httpbin_secure, monkeypatch, nosan_server, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/testbed/tests/test_utils.py:663\n_ ERROR at setup of test_should_bypass_proxies_pass_only_hostname[http://user:pass@hostname:5000-hostname] _\nfile /testbed/tests/test_utils.py, line 663\n  @pytest.mark.parametrize(\n      'url, expected', (\n              ('http://172.16.1.1/', '172.16.1.1'),\n              ('http://172.16.1.1:5000/', '172.16.1.1'),\n              ('http://user:pass@172.16.1.1', '172.16.1.1'),\n              ('http://user:pass@172.16.1.1:5000', '172.16.1.1'),\n              ('http://hostname/', 'hostname'),\n              ('http://hostname:5000/', 'hostname'),\n              ('http://user:pass@hostname', 'hostname'),\n              ('http://user:pass@hostname:5000', 'hostname'),\n      ))\n  def test_should_bypass_proxies_pass_only_hostname(url, expected, mocker):\nE       fixture 'mocker' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, httpbin, httpbin_secure, monkeypatch, nosan_server, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/testbed/tests/test_utils.py:663\n================== 195 passed, 11 skipped, 8 errors in 0.28s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_utils.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_utils.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "mwaskom__seaborn-3069",
      "repo": "mwaskom/seaborn",
      "valid": false,
      "worker": "http://34.123.9.23:8080",
      "error": "HTTPConnectionPool(host='34.123.9.23', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "mwaskom__seaborn-3187",
      "repo": "mwaskom/seaborn",
      "valid": false,
      "worker": "http://34.123.9.23:8080",
      "error": "HTTPConnectionPool(host='34.123.9.23', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 0
    },
    {
      "instance_id": "pytest-dev__pytest-10051",
      "repo": "pytest-dev/pytest",
      "valid": true,
      "worker": "http://34.70.1.155:8080",
      "duration": 5.984196901321411,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 15,
          "failed": 1,
          "errors": 0,
          "collected": 16,
          "duration": 2.5,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 16 items\n\ntesting/logging/test_fixture.py::test_change_level PASSED                [  6%]\ntesting/logging/test_fixture.py::test_with_statement PASSED              [ 12%]\ntesting/logging/test_fixture.py::test_log_access PASSED                  [ 18%]\ntesting/logging/test_fixture.py::test_messages PASSED                    [ 25%]\ntesting/logging/test_fixture.py::test_record_tuples PASSED               [ 31%]\ntesting/logging/test_fixture.py::test_unicode PASSED                     [ 37%]\ntesting/logging/test_fixture.py::test_clear PASSED                       [ 43%]\ntesting/logging/test_fixture.py::test_caplog_captures_for_all_stages PASSED [ 50%]\ntesting/logging/test_fixture.py::test_clear_for_call_stage FAILED        [ 56%]\ntesting/logging/test_fixture.py::test_fixture_help PASSED                [ 62%]\ntesting/logging/test_fixture.py::test_change_level_undo PASSED           [ 68%]\ntesting/logging/test_fixture.py::test_change_level_undos_handler_level PASSED [ 75%]\ntesting/logging/test_fixture.py::test_ini_controls_global_log_level PASSED [ 81%]\ntesting/logging/test_fixture.py::test_caplog_can_override_global_log_level PASSED [ 87%]\ntesting/logging/test_fixture.py::test_caplog_captures_despite_exception PASSED [ 93%]\ntesting/logging/test_fixture.py::test_log_report_captures_according_to_config_option_upon_failure PASSED [100%]\n\n=================================== FAILURES ===================================\n__________________________ test_clear_for_call_stage ___________________________\ntesting/logging/test_fixture.py:183: in test_clear_for_call_stage\n    assert caplog.get_records(\"call\") == []\nE   assert [<LogRecord: ...\"a_call_log\">] == []\nE     Left contains one more item: <LogRecord: test_fixture, 20, /testbed/testing/logging/test_fixture.py, 176, \"a_call_log\">\nE     Full diff:\nE     - []\nE     + [<LogRecord: test_fixture, 20, /testbed/testing/logging/test_fixture.py, 176, \"a_call_log\">]\n------------------------------ Captured log setup ------------------------------\nINFO     test_fixture:test_fixture.py:157 a_setup_log\n------------------------------ Captured log call -------------------------------\nINFO     test_fixture:test_fixture.py:176 a_call_log\n---------------------------- Captured log teardown -----------------------------\nINFO     test_fixture:test_fixture.py:159 a_teardown_log\n========================= 1 failed, 15 passed in 0.26s =========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/logging/test_fixture.py` failed. (See above for error)",
          "test_files_run": [
            "testing/logging/test_fixture.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 16,
          "failed": 0,
          "errors": 0,
          "collected": 16,
          "duration": 2.57,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 16 items\n\ntesting/logging/test_fixture.py::test_change_level PASSED                [  6%]\ntesting/logging/test_fixture.py::test_with_statement PASSED              [ 12%]\ntesting/logging/test_fixture.py::test_log_access PASSED                  [ 18%]\ntesting/logging/test_fixture.py::test_messages PASSED                    [ 25%]\ntesting/logging/test_fixture.py::test_record_tuples PASSED               [ 31%]\ntesting/logging/test_fixture.py::test_unicode PASSED                     [ 37%]\ntesting/logging/test_fixture.py::test_clear PASSED                       [ 43%]\ntesting/logging/test_fixture.py::test_caplog_captures_for_all_stages PASSED [ 50%]\ntesting/logging/test_fixture.py::test_clear_for_call_stage PASSED        [ 56%]\ntesting/logging/test_fixture.py::test_fixture_help PASSED                [ 62%]\ntesting/logging/test_fixture.py::test_change_level_undo PASSED           [ 68%]\ntesting/logging/test_fixture.py::test_change_level_undos_handler_level PASSED [ 75%]\ntesting/logging/test_fixture.py::test_ini_controls_global_log_level PASSED [ 81%]\ntesting/logging/test_fixture.py::test_caplog_can_override_global_log_level PASSED [ 87%]\ntesting/logging/test_fixture.py::test_caplog_captures_despite_exception PASSED [ 93%]\ntesting/logging/test_fixture.py::test_log_report_captures_according_to_config_option_upon_failure PASSED [100%]\n\n============================== 16 passed in 0.26s ==============================\n\n",
          "test_files_run": [
            "testing/logging/test_fixture.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "pytest-dev__pytest-10081",
      "repo": "pytest-dev/pytest",
      "valid": false,
      "worker": "http://34.70.1.155:8080",
      "duration": 11.610266923904419,
      "test_only": {
        "passed": true,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "collected": 73,
          "duration": 4.96,
          "log_tail": "testing/test_unittest.py::test_usefixtures_marker_on_unittest[builtins.object] PASSED [ 64%]\ntesting/test_unittest.py::test_usefixtures_marker_on_unittest[unittest.TestCase] PASSED [ 65%]\ntesting/test_unittest.py::test_testcase_handles_init_exceptions PASSED   [ 67%]\ntesting/test_unittest.py::test_error_message_with_parametrized_fixtures PASSED [ 68%]\ntesting/test_unittest.py::test_setup_inheritance_skipping[test_setup_skip.py-1 skipped] PASSED [ 69%]\ntesting/test_unittest.py::test_setup_inheritance_skipping[test_setup_skip_class.py-1 skipped] PASSED [ 71%]\ntesting/test_unittest.py::test_setup_inheritance_skipping[test_setup_skip_module.py-1 error] PASSED [ 72%]\ntesting/test_unittest.py::test_BdbQuit PASSED                            [ 73%]\ntesting/test_unittest.py::test_exit_outcome PASSED                       [ 75%]\ntesting/test_unittest.py::test_trace PASSED                              [ 76%]\ntesting/test_unittest.py::test_pdb_teardown_called PASSED                [ 78%]\ntesting/test_unittest.py::test_pdb_teardown_skipped_for_functions[@unittest.skip] PASSED [ 79%]\ntesting/test_unittest.py::test_pdb_teardown_skipped_for_functions[@pytest.mark.skip] PASSED [ 80%]\ntesting/test_unittest.py::test_pdb_teardown_skipped_for_classes[@unittest.skip] FAILED [ 82%]\ntesting/test_unittest.py::test_pdb_teardown_skipped_for_classes[@pytest.mark.skip] PASSED [ 83%]\ntesting/test_unittest.py::test_async_support PASSED                      [ 84%]\ntesting/test_unittest.py::test_asynctest_support SKIPPED (could not ...) [ 86%]\ntesting/test_unittest.py::test_do_class_cleanups_on_success PASSED       [ 87%]\ntesting/test_unittest.py::test_do_class_cleanups_on_setupclass_failure PASSED [ 89%]\ntesting/test_unittest.py::test_do_class_cleanups_on_teardownclass_failure PASSED [ 90%]\ntesting/test_unittest.py::test_do_cleanups_on_success PASSED             [ 91%]\ntesting/test_unittest.py::test_do_cleanups_on_setup_failure PASSED       [ 93%]\ntesting/test_unittest.py::test_do_cleanups_on_teardown_failure PASSED    [ 94%]\ntesting/test_unittest.py::test_traceback_pruning PASSED                  [ 95%]\ntesting/test_unittest.py::test_raising_unittest_skiptest_during_collection PASSED [ 97%]\ntesting/test_unittest.py::TestTrialUnittest::test_trial_pdb SKIPPED      [ 98%]\ntesting/test_unittest.py::test_plain_unittest_does_not_support_async PASSED [100%]\n\n=================================== FAILURES ===================================\n____________ test_pdb_teardown_skipped_for_classes[@unittest.skip] _____________\n/testbed/testing/test_unittest.py:1314: in test_pdb_teardown_skipped_for_classes\n    assert tracked == []\nE   AssertionError: assert ['tearDown:te...tCase.test_1'] == []\nE     Left contains one more item: 'tearDown:test_pdb_teardown_skipped_for_classes.MyTestCase.test_1'\nE     Full diff:\nE     - []\nE     + ['tearDown:test_pdb_teardown_skipped_for_classes.MyTestCase.test_1']\n----------------------------- Captured stdout call -----------------------------\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-7.2.0.dev173+gda9a2b584, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_pdb_teardown_skipped_for_classes0\ncollected 1 item\n\ntest_pdb_teardown_skipped_for_classes.py s                               [100%]\n\n============================== 1 skipped in 0.01s ==============================\n=================== 1 failed, 63 passed, 9 skipped in 2.62s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/test_unittest.py` failed. (See above for error)",
          "test_files_run": [
            "testing/test_unittest.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 64,
          "failed": 0,
          "errors": 0,
          "collected": 73,
          "duration": 5.19,
          "log_tail": "testing/test_unittest.py::TestTrialUnittest::test_trial_testcase_todo_property SKIPPED [ 38%]\ntesting/test_unittest.py::TestTrialUnittest::test_trial_testfunction_todo_property SKIPPED [ 39%]\ntesting/test_unittest.py::test_djangolike_testcase PASSED                [ 41%]\ntesting/test_unittest.py::test_unittest_not_shown_in_traceback PASSED    [ 42%]\ntesting/test_unittest.py::test_unorderable_types PASSED                  [ 43%]\ntesting/test_unittest.py::test_unittest_typerror_traceback PASSED        [ 45%]\ntesting/test_unittest.py::test_unittest_expected_failure_for_failing_test_is_xfail[pytest] PASSED [ 46%]\ntesting/test_unittest.py::test_unittest_expected_failure_for_failing_test_is_xfail[unittest] PASSED [ 47%]\ntesting/test_unittest.py::test_unittest_expected_failure_for_passing_test_is_fail[pytest] PASSED [ 49%]\ntesting/test_unittest.py::test_unittest_expected_failure_for_passing_test_is_fail[unittest] PASSED [ 50%]\ntesting/test_unittest.py::test_unittest_setup_interaction[return] PASSED [ 52%]\ntesting/test_unittest.py::test_unittest_setup_interaction[yield] PASSED  [ 53%]\ntesting/test_unittest.py::test_non_unittest_no_setupclass_support PASSED [ 54%]\ntesting/test_unittest.py::test_no_teardown_if_setupclass_failed PASSED   [ 56%]\ntesting/test_unittest.py::test_cleanup_functions PASSED                  [ 57%]\ntesting/test_unittest.py::test_issue333_result_clearing PASSED           [ 58%]\ntesting/test_unittest.py::test_unittest_raise_skip_issue748 PASSED       [ 60%]\ntesting/test_unittest.py::test_unittest_skip_issue1169 PASSED            [ 61%]\ntesting/test_unittest.py::test_class_method_containing_test_issue1558 PASSED [ 63%]\ntesting/test_unittest.py::test_usefixtures_marker_on_unittest[builtins.object] PASSED [ 64%]\ntesting/test_unittest.py::test_usefixtures_marker_on_unittest[unittest.TestCase] PASSED [ 65%]\ntesting/test_unittest.py::test_testcase_handles_init_exceptions PASSED   [ 67%]\ntesting/test_unittest.py::test_error_message_with_parametrized_fixtures PASSED [ 68%]\ntesting/test_unittest.py::test_setup_inheritance_skipping[test_setup_skip.py-1 skipped] PASSED [ 69%]\ntesting/test_unittest.py::test_setup_inheritance_skipping[test_setup_skip_class.py-1 skipped] PASSED [ 71%]\ntesting/test_unittest.py::test_setup_inheritance_skipping[test_setup_skip_module.py-1 error] PASSED [ 72%]\ntesting/test_unittest.py::test_BdbQuit PASSED                            [ 73%]\ntesting/test_unittest.py::test_exit_outcome PASSED                       [ 75%]\ntesting/test_unittest.py::test_trace PASSED                              [ 76%]\ntesting/test_unittest.py::test_pdb_teardown_called PASSED                [ 78%]\ntesting/test_unittest.py::test_pdb_teardown_skipped_for_functions[@unittest.skip] PASSED [ 79%]\ntesting/test_unittest.py::test_pdb_teardown_skipped_for_functions[@pytest.mark.skip] PASSED [ 80%]\ntesting/test_unittest.py::test_pdb_teardown_skipped_for_classes[@unittest.skip] PASSED [ 82%]\ntesting/test_unittest.py::test_pdb_teardown_skipped_for_classes[@pytest.mark.skip] PASSED [ 83%]\ntesting/test_unittest.py::test_async_support PASSED                      [ 84%]\ntesting/test_unittest.py::test_asynctest_support SKIPPED (could not ...) [ 86%]\ntesting/test_unittest.py::test_do_class_cleanups_on_success PASSED       [ 87%]\ntesting/test_unittest.py::test_do_class_cleanups_on_setupclass_failure PASSED [ 89%]\ntesting/test_unittest.py::test_do_class_cleanups_on_teardownclass_failure PASSED [ 90%]\ntesting/test_unittest.py::test_do_cleanups_on_success PASSED             [ 91%]\ntesting/test_unittest.py::test_do_cleanups_on_setup_failure PASSED       [ 93%]\ntesting/test_unittest.py::test_do_cleanups_on_teardown_failure PASSED    [ 94%]\ntesting/test_unittest.py::test_traceback_pruning PASSED                  [ 95%]\ntesting/test_unittest.py::test_raising_unittest_skiptest_during_collection PASSED [ 97%]\ntesting/test_unittest.py::TestTrialUnittest::test_trial_pdb SKIPPED      [ 98%]\ntesting/test_unittest.py::test_plain_unittest_does_not_support_async PASSED [100%]\n\n======================== 64 passed, 9 skipped in 2.76s =========================\n\n",
          "test_files_run": [
            "testing/test_unittest.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got True\u2192True"
    },
    {
      "instance_id": "pytest-dev__pytest-10356",
      "repo": "pytest-dev/pytest",
      "valid": true,
      "worker": "http://34.70.1.155:8080",
      "duration": 10.839348316192627,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 88,
          "failed": 1,
          "errors": 0,
          "collected": 90,
          "duration": 4.64,
          "log_tail": "testing/test_mark.py::TestFunctional::test_mark_closest PASSED           [ 64%]\ntesting/test_mark.py::TestFunctional::test_mark_with_wrong_marker PASSED [ 65%]\ntesting/test_mark.py::TestFunctional::test_mark_dynamically_in_funcarg PASSED [ 66%]\ntesting/test_mark.py::TestFunctional::test_no_marker_match_on_unmarked_names PASSED [ 67%]\ntesting/test_mark.py::TestFunctional::test_keywords_at_node_level PASSED [ 68%]\ntesting/test_mark.py::TestFunctional::test_keyword_added_for_session PASSED [ 70%]\ntesting/test_mark.py::TestFunctional::test_mark_from_parameters PASSED   [ 71%]\ntesting/test_mark.py::TestFunctional::test_reevaluate_dynamic_expr PASSED [ 72%]\ntesting/test_mark.py::TestKeywordSelection::test_select_simple PASSED    [ 73%]\ntesting/test_mark.py::TestKeywordSelection::test_select_extra_keywords[xxx] PASSED [ 74%]\ntesting/test_mark.py::TestKeywordSelection::test_select_extra_keywords[xxx and test_2] PASSED [ 75%]\ntesting/test_mark.py::TestKeywordSelection::test_select_extra_keywords[TestClass] PASSED [ 76%]\ntesting/test_mark.py::TestKeywordSelection::test_select_extra_keywords[xxx and not test_1] PASSED [ 77%]\ntesting/test_mark.py::TestKeywordSelection::test_select_extra_keywords[TestClass and test_2] PASSED [ 78%]\ntesting/test_mark.py::TestKeywordSelection::test_select_extra_keywords[xxx and TestClass and test_2] PASSED [ 80%]\ntesting/test_mark.py::TestKeywordSelection::test_keyword_extra PASSED    [ 81%]\ntesting/test_mark.py::TestKeywordSelection::test_keyword_extra_dash XFAIL [ 82%]\ntesting/test_mark.py::TestKeywordSelection::test_no_magic_values[__] PASSED [ 83%]\ntesting/test_mark.py::TestKeywordSelection::test_no_magic_values[+] PASSED [ 84%]\ntesting/test_mark.py::TestKeywordSelection::test_no_magic_values[..] PASSED [ 85%]\ntesting/test_mark.py::TestKeywordSelection::test_no_match_directories_outside_the_suite PASSED [ 86%]\ntesting/test_mark.py::test_parameterset_for_parametrize_marks[None] PASSED [ 87%]\ntesting/test_mark.py::test_parameterset_for_parametrize_marks[] PASSED   [ 88%]\ntesting/test_mark.py::test_parameterset_for_parametrize_marks[skip] PASSED [ 90%]\ntesting/test_mark.py::test_parameterset_for_parametrize_marks[xfail] PASSED [ 91%]\ntesting/test_mark.py::test_parameterset_for_fail_at_collect PASSED       [ 92%]\ntesting/test_mark.py::test_parameterset_for_parametrize_bad_markname PASSED [ 93%]\ntesting/test_mark.py::test_mark_expressions_no_smear PASSED              [ 94%]\ntesting/test_mark.py::test_addmarker_order PASSED                        [ 95%]\ntesting/test_mark.py::test_markers_from_parametrize PASSED               [ 96%]\ntesting/test_mark.py::test_marker_expr_eval_failure_handling[NOT internal_err] PASSED [ 97%]\ntesting/test_mark.py::test_marker_expr_eval_failure_handling[NOT (internal_err)] PASSED [ 98%]\ntesting/test_mark.py::test_marker_expr_eval_failure_handling[bogus=] PASSED [100%]\n\n=================================== FAILURES ===================================\n________________________________ test_mark_mro _________________________________\ntesting/test_mark.py:1133: in test_mark_mro\n    assert all_marks == [xfail(\"c\").mark, xfail(\"a\").mark, xfail(\"b\").mark]\nE   AssertionError: assert <generator ob...x7560d12444a0> == [Mark(name='x...), kwargs={})]\nE     Full diff:\nE     + <generator object normalize_mark_list at 0x7560d12444a0>\nE     - [\nE     -  Mark(name='xfail', args=('c',), kwargs={}),\nE     -  Mark(name='xfail', args=('a',), kwargs={}),\nE     -  Mark(name='xfail', args=('b',), kwargs={}),\nE     - ]\n=================== 1 failed, 88 passed, 1 xfailed in 2.33s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/test_mark.py` failed. (See above for error)",
          "test_files_run": [
            "testing/test_mark.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 89,
          "failed": 0,
          "errors": 0,
          "collected": 90,
          "duration": 4.76,
          "log_tail": "testing/test_mark.py::test_keyword_option_wrong_arguments[foo or or-at column 8: expected not OR left parenthesis OR identifier; got or] PASSED [ 50%]\ntesting/test_mark.py::test_keyword_option_wrong_arguments[(foo-at column 5: expected right parenthesis; got end of input] PASSED [ 51%]\ntesting/test_mark.py::test_keyword_option_wrong_arguments[foo bar-at column 5: expected end of input; got identifier] PASSED [ 52%]\ntesting/test_mark.py::test_keyword_option_wrong_arguments[or or-at column 1: expected not OR left parenthesis OR identifier; got or] PASSED [ 53%]\ntesting/test_mark.py::test_keyword_option_wrong_arguments[not or-at column 5: expected not OR left parenthesis OR identifier; got or] PASSED [ 54%]\ntesting/test_mark.py::test_parametrized_collected_from_command_line PASSED [ 55%]\ntesting/test_mark.py::test_parametrized_collect_with_wrong_args PASSED   [ 56%]\ntesting/test_mark.py::test_parametrized_with_kwargs PASSED               [ 57%]\ntesting/test_mark.py::test_parametrize_iterator PASSED                   [ 58%]\ntesting/test_mark.py::TestFunctional::test_merging_markers_deep PASSED   [ 60%]\ntesting/test_mark.py::TestFunctional::test_mark_decorator_subclass_does_not_propagate_to_base PASSED [ 61%]\ntesting/test_mark.py::TestFunctional::test_mark_should_not_pass_to_siebling_class PASSED [ 62%]\ntesting/test_mark.py::TestFunctional::test_mark_decorator_baseclasses_merged PASSED [ 63%]\ntesting/test_mark.py::TestFunctional::test_mark_closest PASSED           [ 64%]\ntesting/test_mark.py::TestFunctional::test_mark_with_wrong_marker PASSED [ 65%]\ntesting/test_mark.py::TestFunctional::test_mark_dynamically_in_funcarg PASSED [ 66%]\ntesting/test_mark.py::TestFunctional::test_no_marker_match_on_unmarked_names PASSED [ 67%]\ntesting/test_mark.py::TestFunctional::test_keywords_at_node_level PASSED [ 68%]\ntesting/test_mark.py::TestFunctional::test_keyword_added_for_session PASSED [ 70%]\ntesting/test_mark.py::TestFunctional::test_mark_from_parameters PASSED   [ 71%]\ntesting/test_mark.py::TestFunctional::test_reevaluate_dynamic_expr PASSED [ 72%]\ntesting/test_mark.py::TestKeywordSelection::test_select_simple PASSED    [ 73%]\ntesting/test_mark.py::TestKeywordSelection::test_select_extra_keywords[xxx] PASSED [ 74%]\ntesting/test_mark.py::TestKeywordSelection::test_select_extra_keywords[xxx and test_2] PASSED [ 75%]\ntesting/test_mark.py::TestKeywordSelection::test_select_extra_keywords[TestClass] PASSED [ 76%]\ntesting/test_mark.py::TestKeywordSelection::test_select_extra_keywords[xxx and not test_1] PASSED [ 77%]\ntesting/test_mark.py::TestKeywordSelection::test_select_extra_keywords[TestClass and test_2] PASSED [ 78%]\ntesting/test_mark.py::TestKeywordSelection::test_select_extra_keywords[xxx and TestClass and test_2] PASSED [ 80%]\ntesting/test_mark.py::TestKeywordSelection::test_keyword_extra PASSED    [ 81%]\ntesting/test_mark.py::TestKeywordSelection::test_keyword_extra_dash XFAIL [ 82%]\ntesting/test_mark.py::TestKeywordSelection::test_no_magic_values[__] PASSED [ 83%]\ntesting/test_mark.py::TestKeywordSelection::test_no_magic_values[+] PASSED [ 84%]\ntesting/test_mark.py::TestKeywordSelection::test_no_magic_values[..] PASSED [ 85%]\ntesting/test_mark.py::TestKeywordSelection::test_no_match_directories_outside_the_suite PASSED [ 86%]\ntesting/test_mark.py::test_parameterset_for_parametrize_marks[None] PASSED [ 87%]\ntesting/test_mark.py::test_parameterset_for_parametrize_marks[] PASSED   [ 88%]\ntesting/test_mark.py::test_parameterset_for_parametrize_marks[skip] PASSED [ 90%]\ntesting/test_mark.py::test_parameterset_for_parametrize_marks[xfail] PASSED [ 91%]\ntesting/test_mark.py::test_parameterset_for_fail_at_collect PASSED       [ 92%]\ntesting/test_mark.py::test_parameterset_for_parametrize_bad_markname PASSED [ 93%]\ntesting/test_mark.py::test_mark_expressions_no_smear PASSED              [ 94%]\ntesting/test_mark.py::test_addmarker_order PASSED                        [ 95%]\ntesting/test_mark.py::test_markers_from_parametrize PASSED               [ 96%]\ntesting/test_mark.py::test_marker_expr_eval_failure_handling[NOT internal_err] PASSED [ 97%]\ntesting/test_mark.py::test_marker_expr_eval_failure_handling[NOT (internal_err)] PASSED [ 98%]\ntesting/test_mark.py::test_marker_expr_eval_failure_handling[bogus=] PASSED [100%]\n\n======================== 89 passed, 1 xfailed in 2.41s =========================\n\n",
          "test_files_run": [
            "testing/test_mark.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "pytest-dev__pytest-5262",
      "repo": "pytest-dev/pytest",
      "valid": false,
      "worker": "http://34.70.1.155:8080",
      "duration": 5.466642141342163,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 2.3,
          "log_tail": "\nERROR: usage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/tox.ini\n  rootdir: /testbed\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/test_capture.py` failed. (See above for error)",
          "test_files_run": [
            "testing/test_capture.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 2.3,
          "log_tail": "\nERROR: usage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/tox.ini\n  rootdir: /testbed\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/test_capture.py` failed. (See above for error)",
          "test_files_run": [
            "testing/test_capture.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "pytest-dev__pytest-5631",
      "repo": "pytest-dev/pytest",
      "valid": false,
      "worker": "http://34.70.1.155:8080",
      "duration": 5.566595077514648,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 2.37,
          "log_tail": "\nERROR: usage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/tox.ini\n  rootdir: /testbed\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/python/integration.py` failed. (See above for error)",
          "test_files_run": [
            "testing/python/integration.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 2.3,
          "log_tail": "\nERROR: usage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/tox.ini\n  rootdir: /testbed\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/python/integration.py` failed. (See above for error)",
          "test_files_run": [
            "testing/python/integration.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "pytest-dev__pytest-5787",
      "repo": "pytest-dev/pytest",
      "valid": false,
      "worker": "http://34.70.1.155:8080",
      "duration": 5.871889114379883,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 2.4,
          "log_tail": "\nERROR: usage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/tox.ini\n  rootdir: /testbed\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/code/test_code.py testing/code/test_excinfo.py testing/conftest.py testing/test_reports.py` failed. (See above for error)",
          "test_files_run": [
            "testing/code/test_code.py",
            "testing/code/test_excinfo.py",
            "testing/conftest.py",
            "testing/test_reports.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 2.37,
          "log_tail": "\nERROR: usage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/tox.ini\n  rootdir: /testbed\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/code/test_code.py testing/code/test_excinfo.py testing/conftest.py testing/test_reports.py` failed. (See above for error)",
          "test_files_run": [
            "testing/code/test_code.py",
            "testing/code/test_excinfo.py",
            "testing/conftest.py",
            "testing/test_reports.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "pytest-dev__pytest-5809",
      "repo": "pytest-dev/pytest",
      "valid": false,
      "worker": "http://34.70.1.155:8080",
      "duration": 5.5206379890441895,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 2.33,
          "log_tail": "\nERROR: usage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/tox.ini\n  rootdir: /testbed\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/test_pastebin.py` failed. (See above for error)",
          "test_files_run": [
            "testing/test_pastebin.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 2.32,
          "log_tail": "\nERROR: usage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/tox.ini\n  rootdir: /testbed\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/test_pastebin.py` failed. (See above for error)",
          "test_files_run": [
            "testing/test_pastebin.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "pytest-dev__pytest-5840",
      "repo": "pytest-dev/pytest",
      "valid": false,
      "worker": "http://34.70.1.155:8080",
      "duration": 5.557519197463989,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 2.33,
          "log_tail": "\nERROR: usage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/tox.ini\n  rootdir: /testbed\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/test_conftest.py` failed. (See above for error)",
          "test_files_run": [
            "testing/test_conftest.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 2.37,
          "log_tail": "\nERROR: usage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/tox.ini\n  rootdir: /testbed\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/test_conftest.py` failed. (See above for error)",
          "test_files_run": [
            "testing/test_conftest.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "pytest-dev__pytest-6197",
      "repo": "pytest-dev/pytest",
      "valid": false,
      "worker": "http://34.70.1.155:8080",
      "duration": 5.628278017044067,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 2.35,
          "log_tail": "\nERROR: usage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/tox.ini\n  rootdir: /testbed\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/test_collection.py testing/test_skipping.py` failed. (See above for error)",
          "test_files_run": [
            "testing/test_collection.py",
            "testing/test_skipping.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 2.4,
          "log_tail": "\nERROR: usage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/tox.ini\n  rootdir: /testbed\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/test_collection.py testing/test_skipping.py` failed. (See above for error)",
          "test_files_run": [
            "testing/test_collection.py",
            "testing/test_skipping.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "pytest-dev__pytest-6202",
      "repo": "pytest-dev/pytest",
      "valid": false,
      "worker": "http://34.70.1.155:8080",
      "duration": 5.671682834625244,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 2.36,
          "log_tail": "\nERROR: usage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/tox.ini\n  rootdir: /testbed\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/test_collection.py` failed. (See above for error)",
          "test_files_run": [
            "testing/test_collection.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 2.42,
          "log_tail": "\nERROR: usage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/tox.ini\n  rootdir: /testbed\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/test_collection.py` failed. (See above for error)",
          "test_files_run": [
            "testing/test_collection.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "pytest-dev__pytest-7205",
      "repo": "pytest-dev/pytest",
      "valid": false,
      "worker": "http://34.70.1.155:8080",
      "duration": 5.735062837600708,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 2.38,
          "log_tail": "\nERROR: usage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/tox.ini\n  rootdir: /testbed\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/test_setuponly.py` failed. (See above for error)",
          "test_files_run": [
            "testing/test_setuponly.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 2.43,
          "log_tail": "\nERROR: usage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/tox.ini\n  rootdir: /testbed\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/test_setuponly.py` failed. (See above for error)",
          "test_files_run": [
            "testing/test_setuponly.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "pytest-dev__pytest-7236",
      "repo": "pytest-dev/pytest",
      "valid": false,
      "worker": "http://34.70.1.155:8080",
      "duration": 5.670080900192261,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 2.38,
          "log_tail": "\nERROR: usage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/tox.ini\n  rootdir: /testbed\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/test_unittest.py` failed. (See above for error)",
          "test_files_run": [
            "testing/test_unittest.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 2.36,
          "log_tail": "\nERROR: usage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/tox.ini\n  rootdir: /testbed\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/test_unittest.py` failed. (See above for error)",
          "test_files_run": [
            "testing/test_unittest.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "pytest-dev__pytest-7324",
      "repo": "pytest-dev/pytest",
      "valid": false,
      "worker": "http://34.70.1.155:8080",
      "duration": 5.773407936096191,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 2.43,
          "log_tail": "\nWARNING: Unknown config ini key: rsyncdirs\nERROR: usage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/tox.ini\n  rootdir: /testbed\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/test_mark_expression.py` failed. (See above for error)",
          "test_files_run": [
            "testing/test_mark_expression.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 2.46,
          "log_tail": "\nWARNING: Unknown config ini key: rsyncdirs\nERROR: usage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/tox.ini\n  rootdir: /testbed\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/test_mark_expression.py` failed. (See above for error)",
          "test_files_run": [
            "testing/test_mark_expression.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "pytest-dev__pytest-7432",
      "repo": "pytest-dev/pytest",
      "valid": false,
      "worker": "http://34.70.1.155:8080",
      "duration": 11.589056015014648,
      "test_only": {
        "passed": true,
        "stats": {
          "passed": 78,
          "failed": 0,
          "errors": 0,
          "collected": 79,
          "duration": 5.3,
          "log_tail": "testing/test_skipping.py::test_reportchars_error PASSED                  [ 78%]\ntesting/test_skipping.py::test_reportchars_all PASSED                    [ 79%]\ntesting/test_skipping.py::test_reportchars_all_error PASSED              [ 81%]\ntesting/test_skipping.py::test_errors_in_xfail_skip_expressions PASSED   [ 82%]\ntesting/test_skipping.py::test_xfail_skipif_with_globals PASSED          [ 83%]\ntesting/test_skipping.py::test_default_markers PASSED                    [ 84%]\ntesting/test_skipping.py::test_xfail_test_setup_exception PASSED         [ 86%]\ntesting/test_skipping.py::test_imperativeskip_on_xfail_test PASSED       [ 87%]\ntesting/test_skipping.py::TestBooleanCondition::test_skipif PASSED       [ 88%]\ntesting/test_skipping.py::TestBooleanCondition::test_skipif_noreason PASSED [ 89%]\ntesting/test_skipping.py::TestBooleanCondition::test_xfail PASSED        [ 91%]\ntesting/test_skipping.py::test_xfail_item PASSED                         [ 92%]\ntesting/test_skipping.py::test_module_level_skip_error PASSED            [ 93%]\ntesting/test_skipping.py::test_module_level_skip_with_allow_module_level PASSED [ 94%]\ntesting/test_skipping.py::test_invalid_skip_keyword_parameter PASSED     [ 96%]\ntesting/test_skipping.py::test_mark_xfail_item PASSED                    [ 97%]\ntesting/test_skipping.py::test_summary_list_after_errors PASSED          [ 98%]\ntesting/test_skipping.py::test_relpath_rootdir PASSED                    [100%]\n\n=================================== FAILURES ===================================\n________ TestXFail.test_xfail_run_with_skip_mark[test_input1-expected1] ________\n/testbed/testing/test_skipping.py:261: in test_xfail_run_with_skip_mark\n    result.stdout.fnmatch_lines(expected)\nE   Failed: nomatch: 'SKIPPED [1] test_sample.py:2: unconditional skip'\nE       and: '============================= test session starts =============================='\nE       and: 'platform linux -- Python 3.9.20, pytest-5.4.1.dev593+ge6e300e72, py-1.11.0, pluggy-0.13.1'\nE       and: 'rootdir: /tmp/pytest-of-root/pytest-0/test_xfail_run_with_skip_mark1'\nE       and: 'collected 1 item'\nE       and: ''\nE       and: 'test_sample.py s                                                         [100%]'\nE       and: ''\nE       and: '=========================== short test summary info ============================'\nE       and: 'SKIPPED [1] ../../../../testbed/src/_pytest/skipping.py:239: unconditional skip'\nE       and: '============================== 1 skipped in 0.00s =============================='\nE   remains unmatched: 'SKIPPED [1] test_sample.py:2: unconditional skip'\n----------------------------- Captured stdout call -----------------------------\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-5.4.1.dev593+ge6e300e72, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_xfail_run_with_skip_mark1\ncollected 1 item\n\ntest_sample.py s                                                         [100%]\n\n=========================== short test summary info ============================\nSKIPPED [1] ../../../../testbed/src/_pytest/skipping.py:239: unconditional skip\n============================== 1 skipped in 0.00s ==============================\n========================= 1 failed, 78 passed in 2.47s =========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/test_skipping.py` failed. (See above for error)",
          "test_files_run": [
            "testing/test_skipping.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 79,
          "failed": 0,
          "errors": 0,
          "collected": 79,
          "duration": 5.28,
          "log_tail": "testing/test_skipping.py::TestXFail::test_strict_xfail[True] PASSED      [ 43%]\ntesting/test_skipping.py::TestXFail::test_strict_xfail[False] PASSED     [ 44%]\ntesting/test_skipping.py::TestXFail::test_strict_xfail_condition[True] PASSED [ 45%]\ntesting/test_skipping.py::TestXFail::test_strict_xfail_condition[False] PASSED [ 46%]\ntesting/test_skipping.py::TestXFail::test_xfail_condition_keyword[True] PASSED [ 48%]\ntesting/test_skipping.py::TestXFail::test_xfail_condition_keyword[False] PASSED [ 49%]\ntesting/test_skipping.py::TestXFail::test_strict_xfail_default_from_file[true] PASSED [ 50%]\ntesting/test_skipping.py::TestXFail::test_strict_xfail_default_from_file[false] PASSED [ 51%]\ntesting/test_skipping.py::TestXFailwithSetupTeardown::test_failing_setup_issue9 PASSED [ 53%]\ntesting/test_skipping.py::TestXFailwithSetupTeardown::test_failing_teardown_issue9 PASSED [ 54%]\ntesting/test_skipping.py::TestSkip::test_skip_class PASSED               [ 55%]\ntesting/test_skipping.py::TestSkip::test_skips_on_false_string PASSED    [ 56%]\ntesting/test_skipping.py::TestSkip::test_arg_as_reason PASSED            [ 58%]\ntesting/test_skipping.py::TestSkip::test_skip_no_reason PASSED           [ 59%]\ntesting/test_skipping.py::TestSkip::test_skip_with_reason PASSED         [ 60%]\ntesting/test_skipping.py::TestSkip::test_only_skips_marked_test PASSED   [ 62%]\ntesting/test_skipping.py::TestSkip::test_strict_and_skip PASSED          [ 63%]\ntesting/test_skipping.py::TestSkipif::test_skipif_conditional PASSED     [ 64%]\ntesting/test_skipping.py::TestSkipif::test_skipif_reporting[\"hasattr(sys, 'platform')\"] PASSED [ 65%]\ntesting/test_skipping.py::TestSkipif::test_skipif_reporting[True, reason=\"invalid platform\"] PASSED [ 67%]\ntesting/test_skipping.py::TestSkipif::test_skipif_using_platform PASSED  [ 68%]\ntesting/test_skipping.py::TestSkipif::test_skipif_reporting_multiple[skipif-SKIP-skipped] PASSED [ 69%]\ntesting/test_skipping.py::TestSkipif::test_skipif_reporting_multiple[xfail-XPASS-xpassed] PASSED [ 70%]\ntesting/test_skipping.py::test_skip_not_report_default PASSED            [ 72%]\ntesting/test_skipping.py::test_skipif_class PASSED                       [ 73%]\ntesting/test_skipping.py::test_skipped_reasons_functional PASSED         [ 74%]\ntesting/test_skipping.py::test_skipped_folding PASSED                    [ 75%]\ntesting/test_skipping.py::test_reportchars PASSED                        [ 77%]\ntesting/test_skipping.py::test_reportchars_error PASSED                  [ 78%]\ntesting/test_skipping.py::test_reportchars_all PASSED                    [ 79%]\ntesting/test_skipping.py::test_reportchars_all_error PASSED              [ 81%]\ntesting/test_skipping.py::test_errors_in_xfail_skip_expressions PASSED   [ 82%]\ntesting/test_skipping.py::test_xfail_skipif_with_globals PASSED          [ 83%]\ntesting/test_skipping.py::test_default_markers PASSED                    [ 84%]\ntesting/test_skipping.py::test_xfail_test_setup_exception PASSED         [ 86%]\ntesting/test_skipping.py::test_imperativeskip_on_xfail_test PASSED       [ 87%]\ntesting/test_skipping.py::TestBooleanCondition::test_skipif PASSED       [ 88%]\ntesting/test_skipping.py::TestBooleanCondition::test_skipif_noreason PASSED [ 89%]\ntesting/test_skipping.py::TestBooleanCondition::test_xfail PASSED        [ 91%]\ntesting/test_skipping.py::test_xfail_item PASSED                         [ 92%]\ntesting/test_skipping.py::test_module_level_skip_error PASSED            [ 93%]\ntesting/test_skipping.py::test_module_level_skip_with_allow_module_level PASSED [ 94%]\ntesting/test_skipping.py::test_invalid_skip_keyword_parameter PASSED     [ 96%]\ntesting/test_skipping.py::test_mark_xfail_item PASSED                    [ 97%]\ntesting/test_skipping.py::test_summary_list_after_errors PASSED          [ 98%]\ntesting/test_skipping.py::test_relpath_rootdir PASSED                    [100%]\n\n============================== 79 passed in 2.46s ==============================\n\n",
          "test_files_run": [
            "testing/test_skipping.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got True\u2192True"
    },
    {
      "instance_id": "pytest-dev__pytest-7490",
      "repo": "pytest-dev/pytest",
      "valid": true,
      "worker": "http://34.70.1.155:8080",
      "duration": 12.062723875045776,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 1,
          "errors": 0,
          "collected": 81,
          "duration": 5.59,
          "log_tail": "E     \nE     ...Full output truncated (13 lines hidden), use '-vv' to show\n----------------------------- Captured stdout call -----------------------------\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-6.0.0rc2.dev33+g7f7a36478, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_dynamic_xfail_set_during_runtest_failed0\ncollected 1 item\n\ntest_dynamic_xfail_set_during_runtest_failed.py F                        [100%]\n\n=================================== FAILURES ===================================\n__________________________________ test_this ___________________________________\n\nrequest = <FixtureRequest for <Function test_this>>\n\n    def test_this(request):\n        request.node.add_marker(pytest.mark.xfail(reason=\"xfail\"))\n>       assert 0\nE       assert 0\n\ntest_dynamic_xfail_set_during_runtest_failed.py:4: AssertionError\n=========================== short test summary info ============================\nFAILED test_dynamic_xfail_set_during_runtest_failed.py::test_this - assert 0\n============================== 1 failed in 0.01s ===============================\n________ TestXFail.test_dynamic_xfail_set_during_runtest_passed_strict _________\n/testbed/testing/test_skipping.py:454: in test_dynamic_xfail_set_during_runtest_passed_strict\n    result.assert_outcomes(failed=1)\nE   AssertionError: assert {'errors': 0,...pped': 0, ...} == {'errors': 0,...pped': 0, ...}\nE     Omitting 4 identical items, use -vv to show\nE     Differing items:\nE     {'failed': 0} != {'failed': 1}\nE     {'passed': 1} != {'passed': 0}\nE     Full diff:\nE       {\nE        'errors': 0,...\nE     \nE     ...Full output truncated (13 lines hidden), use '-vv' to show\n----------------------------- Captured stdout call -----------------------------\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-6.0.0rc2.dev33+g7f7a36478, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_dynamic_xfail_set_during_runtest_passed_strict0\ncollected 1 item\n\ntest_dynamic_xfail_set_during_runtest_passed_strict.py .                 [100%]\n\n============================== 1 passed in 0.00s ===============================\n========================= 2 failed, 79 passed in 2.61s =========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/test_skipping.py` failed. (See above for error)",
          "test_files_run": [
            "testing/test_skipping.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 81,
          "failed": 0,
          "errors": 0,
          "collected": 81,
          "duration": 5.48,
          "log_tail": "testing/test_skipping.py::TestXFail::test_strict_xfail[True] PASSED      [ 44%]\ntesting/test_skipping.py::TestXFail::test_strict_xfail[False] PASSED     [ 45%]\ntesting/test_skipping.py::TestXFail::test_strict_xfail_condition[True] PASSED [ 46%]\ntesting/test_skipping.py::TestXFail::test_strict_xfail_condition[False] PASSED [ 48%]\ntesting/test_skipping.py::TestXFail::test_xfail_condition_keyword[True] PASSED [ 49%]\ntesting/test_skipping.py::TestXFail::test_xfail_condition_keyword[False] PASSED [ 50%]\ntesting/test_skipping.py::TestXFail::test_strict_xfail_default_from_file[true] PASSED [ 51%]\ntesting/test_skipping.py::TestXFail::test_strict_xfail_default_from_file[false] PASSED [ 53%]\ntesting/test_skipping.py::TestXFailwithSetupTeardown::test_failing_setup_issue9 PASSED [ 54%]\ntesting/test_skipping.py::TestXFailwithSetupTeardown::test_failing_teardown_issue9 PASSED [ 55%]\ntesting/test_skipping.py::TestSkip::test_skip_class PASSED               [ 56%]\ntesting/test_skipping.py::TestSkip::test_skips_on_false_string PASSED    [ 58%]\ntesting/test_skipping.py::TestSkip::test_arg_as_reason PASSED            [ 59%]\ntesting/test_skipping.py::TestSkip::test_skip_no_reason PASSED           [ 60%]\ntesting/test_skipping.py::TestSkip::test_skip_with_reason PASSED         [ 61%]\ntesting/test_skipping.py::TestSkip::test_only_skips_marked_test PASSED   [ 62%]\ntesting/test_skipping.py::TestSkip::test_strict_and_skip PASSED          [ 64%]\ntesting/test_skipping.py::TestSkipif::test_skipif_conditional PASSED     [ 65%]\ntesting/test_skipping.py::TestSkipif::test_skipif_reporting[\"hasattr(sys, 'platform')\"] PASSED [ 66%]\ntesting/test_skipping.py::TestSkipif::test_skipif_reporting[True, reason=\"invalid platform\"] PASSED [ 67%]\ntesting/test_skipping.py::TestSkipif::test_skipif_using_platform PASSED  [ 69%]\ntesting/test_skipping.py::TestSkipif::test_skipif_reporting_multiple[skipif-SKIP-skipped] PASSED [ 70%]\ntesting/test_skipping.py::TestSkipif::test_skipif_reporting_multiple[xfail-XPASS-xpassed] PASSED [ 71%]\ntesting/test_skipping.py::test_skip_not_report_default PASSED            [ 72%]\ntesting/test_skipping.py::test_skipif_class PASSED                       [ 74%]\ntesting/test_skipping.py::test_skipped_reasons_functional PASSED         [ 75%]\ntesting/test_skipping.py::test_skipped_folding PASSED                    [ 76%]\ntesting/test_skipping.py::test_reportchars PASSED                        [ 77%]\ntesting/test_skipping.py::test_reportchars_error PASSED                  [ 79%]\ntesting/test_skipping.py::test_reportchars_all PASSED                    [ 80%]\ntesting/test_skipping.py::test_reportchars_all_error PASSED              [ 81%]\ntesting/test_skipping.py::test_errors_in_xfail_skip_expressions PASSED   [ 82%]\ntesting/test_skipping.py::test_xfail_skipif_with_globals PASSED          [ 83%]\ntesting/test_skipping.py::test_default_markers PASSED                    [ 85%]\ntesting/test_skipping.py::test_xfail_test_setup_exception PASSED         [ 86%]\ntesting/test_skipping.py::test_imperativeskip_on_xfail_test PASSED       [ 87%]\ntesting/test_skipping.py::TestBooleanCondition::test_skipif PASSED       [ 88%]\ntesting/test_skipping.py::TestBooleanCondition::test_skipif_noreason PASSED [ 90%]\ntesting/test_skipping.py::TestBooleanCondition::test_xfail PASSED        [ 91%]\ntesting/test_skipping.py::test_xfail_item PASSED                         [ 92%]\ntesting/test_skipping.py::test_module_level_skip_error PASSED            [ 93%]\ntesting/test_skipping.py::test_module_level_skip_with_allow_module_level PASSED [ 95%]\ntesting/test_skipping.py::test_invalid_skip_keyword_parameter PASSED     [ 96%]\ntesting/test_skipping.py::test_mark_xfail_item PASSED                    [ 97%]\ntesting/test_skipping.py::test_summary_list_after_errors PASSED          [ 98%]\ntesting/test_skipping.py::test_relpath_rootdir PASSED                    [100%]\n\n============================== 81 passed in 2.54s ==============================\n\n",
          "test_files_run": [
            "testing/test_skipping.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "pytest-dev__pytest-7521",
      "repo": "pytest-dev/pytest",
      "valid": false,
      "worker": "http://34.70.1.155:8080",
      "duration": 19.760563850402832,
      "test_only": {
        "passed": true,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "collected": 129,
          "duration": 9.82,
          "log_tail": "testing/test_capture.py::TestStdCaptureFDinvalidFD::test_fdcapture_invalid_fd_with_fd_reuse PASSED [ 75%]\ntesting/test_capture.py::TestStdCaptureFDinvalidFD::test_fdcapture_invalid_fd_without_fd_reuse PASSED [ 76%]\ntesting/test_capture.py::test_capturing_and_logging_fundamentals[SysCapture(2)] PASSED [ 77%]\ntesting/test_capture.py::test_capturing_and_logging_fundamentals[SysCapture(2, tee=True)] PASSED [ 78%]\ntesting/test_capture.py::test_capturing_and_logging_fundamentals[FDCapture(2)] PASSED [ 79%]\ntesting/test_capture.py::test_error_attribute_issue555 PASSED            [ 79%]\ntesting/test_capture.py::test_dontreadfrominput_has_encoding PASSED      [ 80%]\ntesting/test_capture.py::test_typeerror_encodedfile_write PASSED         [ 81%]\ntesting/test_capture.py::test_encodedfile_writelines PASSED              [ 82%]\ntesting/test_capture.py::TestLoggingInteraction::test_logging_stream_ownership PASSED [ 82%]\ntesting/test_capture.py::TestLoggingInteraction::test_logging_and_immediate_setupteardown PASSED [ 83%]\ntesting/test_capture.py::TestLoggingInteraction::test_logging_and_crossscope_fixtures PASSED [ 84%]\ntesting/test_capture.py::TestLoggingInteraction::test_conftestlogging_is_shown PASSED [ 85%]\ntesting/test_capture.py::TestLoggingInteraction::test_conftestlogging_and_test_logging PASSED [ 86%]\ntesting/test_capture.py::TestLoggingInteraction::test_logging_after_cap_stopped PASSED [ 86%]\ntesting/test_capture.py::TestCaptureFixture::test_keyboardinterrupt_disables_capturing PASSED [ 87%]\ntesting/test_capture.py::TestCaptureFixture::test_capture_and_logging PASSED [ 88%]\ntesting/test_capture.py::TestCaptureFixture::test_disabled_capture_fixture[True-capsys] PASSED [ 89%]\ntesting/test_capture.py::TestCaptureFixture::test_disabled_capture_fixture[True-capfd] PASSED [ 89%]\ntesting/test_capture.py::TestCaptureFixture::test_disabled_capture_fixture[False-capsys] PASSED [ 90%]\ntesting/test_capture.py::TestCaptureFixture::test_disabled_capture_fixture[False-capfd] PASSED [ 91%]\ntesting/test_capture.py::TestCaptureFixture::test_fixture_use_by_other_fixtures[capsys] PASSED [ 92%]\ntesting/test_capture.py::TestCaptureFixture::test_fixture_use_by_other_fixtures[capfd] PASSED [ 93%]\ntesting/test_capture.py::test_error_during_readouterr PASSED             [ 93%]\ntesting/test_capture.py::TestStdCaptureFD::test_simple_only_fd PASSED    [ 94%]\ntesting/test_capture.py::TestStdCaptureFDinvalidFD::test_stdcapture_fd_invalid_fd PASSED [ 95%]\ntesting/test_capture.py::test_close_and_capture_again PASSED             [ 96%]\ntesting/test_capture.py::test_crash_on_closing_tmpfile_py27 PASSED       [ 96%]\ntesting/test_capture.py::test_global_capture_with_live_logging PASSED    [ 97%]\ntesting/test_capture.py::test_capture_with_live_logging[capsys] PASSED   [ 98%]\ntesting/test_capture.py::test_capture_with_live_logging[capfd] PASSED    [ 99%]\ntesting/test_capture.py::test_logging_while_collecting PASSED            [100%]\n\n=================================== FAILURES ===================================\n____________ TestCaptureFixture.test_cafd_preserves_newlines[\\r\\n] _____________\ntesting/test_capture.py:521: in test_cafd_preserves_newlines\n    assert out.endswith(nl)\nE   AssertionError: assert False\nE    +  where False = <built-in method endswith of str object at 0x7eddb7812df0>('\\r\\n')\nE    +    where <built-in method endswith of str object at 0x7eddb7812df0> = 'test\\n'.endswith\n_____________ TestCaptureFixture.test_cafd_preserves_newlines[\\r] ______________\ntesting/test_capture.py:521: in test_cafd_preserves_newlines\n    assert out.endswith(nl)\nE   AssertionError: assert False\nE    +  where False = <built-in method endswith of str object at 0x7eddb7529530>('\\r')\nE    +    where <built-in method endswith of str object at 0x7eddb7529530> = 'test\\n'.endswith\n============= 2 failed, 123 passed, 3 skipped, 1 xfailed in 7.13s ==============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/test_capture.py` failed. (See above for error)",
          "test_files_run": [
            "testing/test_capture.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 125,
          "failed": 0,
          "errors": 0,
          "collected": 129,
          "duration": 8.96,
          "log_tail": "testing/test_capture.py::TestCaptureFixture::test_capsysbinary PASSED    [ 65%]\ntesting/test_capture.py::TestCaptureFixture::test_partial_setup_failure PASSED [ 65%]\ntesting/test_capture.py::TestCaptureFixture::test_fixture_use_by_other_fixtures_teardown[capsys] PASSED [ 66%]\ntesting/test_capture.py::TestCaptureFixture::test_fixture_use_by_other_fixtures_teardown[capfd] PASSED [ 67%]\ntesting/test_capture.py::test_setup_failure_does_not_kill_capturing PASSED [ 68%]\ntesting/test_capture.py::test_capture_conftest_runtest_setup PASSED      [ 68%]\ntesting/test_capture.py::test_capture_badoutput_issue412 PASSED          [ 69%]\ntesting/test_capture.py::test_capture_early_option_parsing PASSED        [ 70%]\ntesting/test_capture.py::test_capture_binary_output PASSED               [ 71%]\ntesting/test_capture.py::TestFDCapture::test_simple PASSED               [ 72%]\ntesting/test_capture.py::TestFDCapture::test_simple_many PASSED          [ 72%]\ntesting/test_capture.py::TestFDCapture::test_simple_many_check_open_files SKIPPED [ 73%]\ntesting/test_capture.py::TestFDCapture::test_simple_fail_second_start PASSED [ 74%]\ntesting/test_capture.py::TestFDCapture::test_writeorg PASSED             [ 75%]\ntesting/test_capture.py::TestStdCaptureFDinvalidFD::test_fdcapture_invalid_fd_with_fd_reuse PASSED [ 75%]\ntesting/test_capture.py::TestStdCaptureFDinvalidFD::test_fdcapture_invalid_fd_without_fd_reuse PASSED [ 76%]\ntesting/test_capture.py::test_capturing_and_logging_fundamentals[SysCapture(2)] PASSED [ 77%]\ntesting/test_capture.py::test_capturing_and_logging_fundamentals[SysCapture(2, tee=True)] PASSED [ 78%]\ntesting/test_capture.py::test_capturing_and_logging_fundamentals[FDCapture(2)] PASSED [ 79%]\ntesting/test_capture.py::test_error_attribute_issue555 PASSED            [ 79%]\ntesting/test_capture.py::test_dontreadfrominput_has_encoding PASSED      [ 80%]\ntesting/test_capture.py::test_typeerror_encodedfile_write PASSED         [ 81%]\ntesting/test_capture.py::test_encodedfile_writelines PASSED              [ 82%]\ntesting/test_capture.py::TestLoggingInteraction::test_logging_stream_ownership PASSED [ 82%]\ntesting/test_capture.py::TestLoggingInteraction::test_logging_and_immediate_setupteardown PASSED [ 83%]\ntesting/test_capture.py::TestLoggingInteraction::test_logging_and_crossscope_fixtures PASSED [ 84%]\ntesting/test_capture.py::TestLoggingInteraction::test_conftestlogging_is_shown PASSED [ 85%]\ntesting/test_capture.py::TestLoggingInteraction::test_conftestlogging_and_test_logging PASSED [ 86%]\ntesting/test_capture.py::TestLoggingInteraction::test_logging_after_cap_stopped PASSED [ 86%]\ntesting/test_capture.py::TestCaptureFixture::test_keyboardinterrupt_disables_capturing PASSED [ 87%]\ntesting/test_capture.py::TestCaptureFixture::test_capture_and_logging PASSED [ 88%]\ntesting/test_capture.py::TestCaptureFixture::test_disabled_capture_fixture[True-capsys] PASSED [ 89%]\ntesting/test_capture.py::TestCaptureFixture::test_disabled_capture_fixture[True-capfd] PASSED [ 89%]\ntesting/test_capture.py::TestCaptureFixture::test_disabled_capture_fixture[False-capsys] PASSED [ 90%]\ntesting/test_capture.py::TestCaptureFixture::test_disabled_capture_fixture[False-capfd] PASSED [ 91%]\ntesting/test_capture.py::TestCaptureFixture::test_fixture_use_by_other_fixtures[capsys] PASSED [ 92%]\ntesting/test_capture.py::TestCaptureFixture::test_fixture_use_by_other_fixtures[capfd] PASSED [ 93%]\ntesting/test_capture.py::test_error_during_readouterr PASSED             [ 93%]\ntesting/test_capture.py::TestStdCaptureFD::test_simple_only_fd PASSED    [ 94%]\ntesting/test_capture.py::TestStdCaptureFDinvalidFD::test_stdcapture_fd_invalid_fd PASSED [ 95%]\ntesting/test_capture.py::test_close_and_capture_again PASSED             [ 96%]\ntesting/test_capture.py::test_crash_on_closing_tmpfile_py27 PASSED       [ 96%]\ntesting/test_capture.py::test_global_capture_with_live_logging PASSED    [ 97%]\ntesting/test_capture.py::test_capture_with_live_logging[capsys] PASSED   [ 98%]\ntesting/test_capture.py::test_capture_with_live_logging[capfd] PASSED    [ 99%]\ntesting/test_capture.py::test_logging_while_collecting PASSED            [100%]\n\n================== 125 passed, 3 skipped, 1 xfailed in 6.47s ===================\n\n",
          "test_files_run": [
            "testing/test_capture.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got True\u2192True"
    },
    {
      "instance_id": "pytest-dev__pytest-7571",
      "repo": "pytest-dev/pytest",
      "valid": true,
      "worker": "http://34.70.1.155:8080",
      "duration": 6.291527986526489,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 14,
          "failed": 1,
          "errors": 0,
          "collected": 15,
          "duration": 2.63,
          "log_tail": "    result.assert_outcomes(passed=3)\nE   AssertionError: assert {'errors': 0,...pped': 0, ...} == {'errors': 0,...pped': 0, ...}\nE     Omitting 4 identical items, use -vv to show\nE     Differing items:\nE     {'failed': 2} != {'failed': 0}\nE     {'passed': 1} != {'passed': 3}\nE     Full diff:\nE       {\nE        'errors': 0,...\nE     \nE     ...Full output truncated (13 lines hidden), use '-vv' to show\n----------------------------- Captured stdout call -----------------------------\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-6.0.0rc2.dev85+g422685d0b, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_change_level_undos_handler_level0\ncollected 3 items\n\ntest_change_level_undos_handler_level.py .FF                             [100%]\n\n=================================== FAILURES ===================================\n____________________________________ test2 _____________________________________\n\ncaplog = <_pytest.logging.LogCaptureFixture object at 0x7d62b763f2b0>\n\n    def test2(caplog):\n>       assert caplog.handler.level == 0\nE       assert 41 == 0\nE        +  where 41 = <LogCaptureHandler (Level 41)>.level\nE        +    where <LogCaptureHandler (Level 41)> = <_pytest.logging.LogCaptureFixture object at 0x7d62b763f2b0>.handler\n\ntest_change_level_undos_handler_level.py:9: AssertionError\n____________________________________ test3 _____________________________________\n\ncaplog = <_pytest.logging.LogCaptureFixture object at 0x7d62b763a040>\n\n    def test3(caplog):\n>       assert caplog.handler.level == 0\nE       assert 41 == 0\nE        +  where 41 = <LogCaptureHandler (Level 41)>.level\nE        +    where <LogCaptureHandler (Level 41)> = <_pytest.logging.LogCaptureFixture object at 0x7d62b763a040>.handler\n\ntest_change_level_undos_handler_level.py:12: AssertionError\n=========================== short test summary info ============================\nFAILED test_change_level_undos_handler_level.py::test2 - assert 41 == 0\nFAILED test_change_level_undos_handler_level.py::test3 - assert 41 == 0\n========================= 2 failed, 1 passed in 0.01s ==========================\n========================= 1 failed, 14 passed in 0.24s =========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/logging/test_fixture.py` failed. (See above for error)",
          "test_files_run": [
            "testing/logging/test_fixture.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 15,
          "failed": 0,
          "errors": 0,
          "collected": 15,
          "duration": 2.74,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 15 items\n\ntesting/logging/test_fixture.py::test_change_level PASSED                [  6%]\ntesting/logging/test_fixture.py::test_with_statement PASSED              [ 13%]\ntesting/logging/test_fixture.py::test_log_access PASSED                  [ 20%]\ntesting/logging/test_fixture.py::test_messages PASSED                    [ 26%]\ntesting/logging/test_fixture.py::test_record_tuples PASSED               [ 33%]\ntesting/logging/test_fixture.py::test_unicode PASSED                     [ 40%]\ntesting/logging/test_fixture.py::test_clear PASSED                       [ 46%]\ntesting/logging/test_fixture.py::test_caplog_captures_for_all_stages PASSED [ 53%]\ntesting/logging/test_fixture.py::test_fixture_help PASSED                [ 60%]\ntesting/logging/test_fixture.py::test_change_level_undo PASSED           [ 66%]\ntesting/logging/test_fixture.py::test_change_level_undos_handler_level PASSED [ 73%]\ntesting/logging/test_fixture.py::test_ini_controls_global_log_level PASSED [ 80%]\ntesting/logging/test_fixture.py::test_caplog_can_override_global_log_level PASSED [ 86%]\ntesting/logging/test_fixture.py::test_caplog_captures_despite_exception PASSED [ 93%]\ntesting/logging/test_fixture.py::test_log_report_captures_according_to_config_option_upon_failure PASSED [100%]\n\n============================== 15 passed in 0.23s ==============================\n\n",
          "test_files_run": [
            "testing/logging/test_fixture.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "pytest-dev__pytest-7982",
      "repo": "pytest-dev/pytest",
      "valid": false,
      "worker": "http://34.70.1.155:8080",
      "duration": 12.607173681259155,
      "test_only": {
        "passed": true,
        "stats": {
          "passed": 1,
          "failed": 0,
          "errors": 0,
          "collected": 80,
          "duration": 5.83,
          "log_tail": "testing/test_collection.py::test_fixture_scope_sibling_conftests PASSED  [ 73%]\ntesting/test_collection.py::test_collect_init_tests PASSED               [ 75%]\ntesting/test_collection.py::test_collect_invalid_signature_message PASSED [ 76%]\ntesting/test_collection.py::test_collect_handles_raising_on_dunder_class PASSED [ 77%]\ntesting/test_collection.py::test_collect_with_chdir_during_import PASSED [ 78%]\ntesting/test_collection.py::test_collect_symlink_file_arg PASSED         [ 80%]\ntesting/test_collection.py::test_collect_symlink_out_of_tree PASSED      [ 81%]\ntesting/test_collection.py::test_collect_symlink_dir FAILED              [ 82%]\ntesting/test_collection.py::test_collectignore_via_conftest PASSED       [ 83%]\ntesting/test_collection.py::test_collect_pkg_init_and_file_in_args PASSED [ 85%]\ntesting/test_collection.py::test_collect_pkg_init_only PASSED            [ 86%]\ntesting/test_collection.py::test_collect_sub_with_symlinks[True] PASSED  [ 87%]\ntesting/test_collection.py::test_collect_sub_with_symlinks[False] PASSED [ 88%]\ntesting/test_collection.py::test_collector_respects_tbstyle PASSED       [ 90%]\ntesting/test_collection.py::test_does_not_eagerly_collect_packages PASSED [ 91%]\ntesting/test_collection.py::test_does_not_put_src_on_path PASSED         [ 92%]\ntesting/test_collection.py::TestImportModeImportlib::test_collect_duplicate_names PASSED [ 93%]\ntesting/test_collection.py::TestImportModeImportlib::test_conftest PASSED [ 95%]\ntesting/test_collection.py::TestImportModeImportlib::test_modules_importable_as_side_effect PASSED [ 96%]\ntesting/test_collection.py::TestImportModeImportlib::test_modules_not_importable_as_side_effect PASSED [ 97%]\ntesting/test_collection.py::test_does_not_crash_on_error_from_decorated_function PASSED [ 98%]\ntesting/test_collection.py::test_collect_pyargs_with_testpaths PASSED    [100%]\n\n=================================== FAILURES ===================================\n___________________________ test_collect_symlink_dir ___________________________\n/testbed/testing/test_collection.py:1188: in test_collect_symlink_dir\n    result.assert_outcomes(passed=2)\nE   AssertionError: assert {'errors': 0,...pped': 0, ...} == {'errors': 0,...pped': 0, ...}\nE     Omitting 5 identical items, use -vv to show\nE     Differing items:\nE     {'passed': 1} != {'passed': 2}\nE     Full diff:\nE       {\nE        'errors': 0,\nE        'failed': 0,...\nE     \nE     ...Full output truncated (9 lines hidden), use '-vv' to show\n----------------------------- Captured stdout call -----------------------------\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-6.2.0.dev154+ga7e38c5c6, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_collect_symlink_dir0\ncollected 1 item\n\ndir/test_it.py .                                                         [100%]\n\n============================== 1 passed in 0.00s ===============================\n=================== 1 failed, 78 passed, 1 xfailed in 3.24s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/test_collection.py` failed. (See above for error)",
          "test_files_run": [
            "testing/test_collection.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 79,
          "failed": 0,
          "errors": 0,
          "collected": 80,
          "duration": 5.78,
          "log_tail": "testing/test_collection.py::TestCustomConftests::test_pytest_fs_collect_hooks_are_seen PASSED [ 43%]\ntesting/test_collection.py::TestCustomConftests::test_pytest_collect_file_from_sister_dir PASSED [ 45%]\ntesting/test_collection.py::TestSession::test_collect_topdir PASSED      [ 46%]\ntesting/test_collection.py::TestSession::test_collect_protocol_single_function PASSED [ 47%]\ntesting/test_collection.py::TestSession::test_collect_protocol_method PASSED [ 48%]\ntesting/test_collection.py::TestSession::test_collect_custom_nodes_multi_id PASSED [ 50%]\ntesting/test_collection.py::TestSession::test_collect_subdir_event_ordering PASSED [ 51%]\ntesting/test_collection.py::TestSession::test_collect_two_commandline_args PASSED [ 52%]\ntesting/test_collection.py::TestSession::test_serialization_byid PASSED  [ 53%]\ntesting/test_collection.py::TestSession::test_find_byid_without_instance_parents PASSED [ 55%]\ntesting/test_collection.py::Test_getinitialnodes::test_global_file PASSED [ 56%]\ntesting/test_collection.py::Test_getinitialnodes::test_pkgfile PASSED    [ 57%]\ntesting/test_collection.py::Test_genitems::test_check_collect_hashes PASSED [ 58%]\ntesting/test_collection.py::Test_genitems::test_example_items1 PASSED    [ 60%]\ntesting/test_collection.py::Test_genitems::test_class_and_functions_discovery_using_glob PASSED [ 61%]\ntesting/test_collection.py::test_matchnodes_two_collections_same_file PASSED [ 62%]\ntesting/test_collection.py::TestNodekeywords::test_no_under PASSED       [ 63%]\ntesting/test_collection.py::TestNodekeywords::test_issue345 PASSED       [ 65%]\ntesting/test_collection.py::TestNodekeywords::test_keyword_matching_is_case_insensitive_by_default PASSED [ 66%]\ntesting/test_collection.py::test_exit_on_collection_error PASSED         [ 67%]\ntesting/test_collection.py::test_exit_on_collection_with_maxfail_smaller_than_n_errors PASSED [ 68%]\ntesting/test_collection.py::test_exit_on_collection_with_maxfail_bigger_than_n_errors PASSED [ 70%]\ntesting/test_collection.py::test_continue_on_collection_errors PASSED    [ 71%]\ntesting/test_collection.py::test_continue_on_collection_errors_maxfail PASSED [ 72%]\ntesting/test_collection.py::test_fixture_scope_sibling_conftests PASSED  [ 73%]\ntesting/test_collection.py::test_collect_init_tests PASSED               [ 75%]\ntesting/test_collection.py::test_collect_invalid_signature_message PASSED [ 76%]\ntesting/test_collection.py::test_collect_handles_raising_on_dunder_class PASSED [ 77%]\ntesting/test_collection.py::test_collect_with_chdir_during_import PASSED [ 78%]\ntesting/test_collection.py::test_collect_symlink_file_arg PASSED         [ 80%]\ntesting/test_collection.py::test_collect_symlink_out_of_tree PASSED      [ 81%]\ntesting/test_collection.py::test_collect_symlink_dir PASSED              [ 82%]\ntesting/test_collection.py::test_collectignore_via_conftest PASSED       [ 83%]\ntesting/test_collection.py::test_collect_pkg_init_and_file_in_args PASSED [ 85%]\ntesting/test_collection.py::test_collect_pkg_init_only PASSED            [ 86%]\ntesting/test_collection.py::test_collect_sub_with_symlinks[True] PASSED  [ 87%]\ntesting/test_collection.py::test_collect_sub_with_symlinks[False] PASSED [ 88%]\ntesting/test_collection.py::test_collector_respects_tbstyle PASSED       [ 90%]\ntesting/test_collection.py::test_does_not_eagerly_collect_packages PASSED [ 91%]\ntesting/test_collection.py::test_does_not_put_src_on_path PASSED         [ 92%]\ntesting/test_collection.py::TestImportModeImportlib::test_collect_duplicate_names PASSED [ 93%]\ntesting/test_collection.py::TestImportModeImportlib::test_conftest PASSED [ 95%]\ntesting/test_collection.py::TestImportModeImportlib::test_modules_importable_as_side_effect PASSED [ 96%]\ntesting/test_collection.py::TestImportModeImportlib::test_modules_not_importable_as_side_effect PASSED [ 97%]\ntesting/test_collection.py::test_does_not_crash_on_error_from_decorated_function PASSED [ 98%]\ntesting/test_collection.py::test_collect_pyargs_with_testpaths PASSED    [100%]\n\n======================== 79 passed, 1 xfailed in 3.17s =========================\n\n",
          "test_files_run": [
            "testing/test_collection.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got True\u2192True"
    },
    {
      "instance_id": "pytest-dev__pytest-8399",
      "repo": "pytest-dev/pytest",
      "valid": false,
      "worker": "http://34.70.1.155:8080",
      "duration": 11.98324704170227,
      "test_only": {
        "passed": true,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "collected": 90,
          "duration": 5.45,
          "log_tail": "    fixture has finished. The ``raising`` parameter determines if a KeyError\n    or AttributeError will be raised if the set/deletion operation has no target.\n\nrecwarn\n    Return a :class:`WarningsRecorder` instance that records all warnings emitted by test functions.\n    \n    See http://docs.python.org/library/warnings.html for information\n    on warning categories.\n\ntmpdir_factory [session scope]\n    Return a :class:`_pytest.tmpdir.TempdirFactory` instance for the test session.\n\ntmp_path_factory [session scope]\n    Return a :class:`_pytest.tmpdir.TempPathFactory` instance for the test session.\n\ntmpdir\n    Return a temporary directory path object which is unique to each test\n    function invocation, created as a sub directory of the base temporary\n    directory.\n    \n    By default, a new base temporary directory is created each test session,\n    and old bases are removed after 3 sessions, to aid in debugging. If\n    ``--basetemp`` is used then it is cleared each session. See :ref:`base\n    temporary directory`.\n    \n    The returned object is a `py.path.local`_ path object.\n    \n    .. _`py.path.local`: https://py.readthedocs.io/en/latest/path.html\n\ntmp_path\n    Return a temporary directory path object which is unique to each test\n    function invocation, created as a sub directory of the base temporary\n    directory.\n    \n    By default, a new base temporary directory is created each test session,\n    and old bases are removed after 3 sessions, to aid in debugging. If\n    ``--basetemp`` is used then it is cleared each session. See :ref:`base\n    temporary directory`.\n    \n    The returned object is a :class:`pathlib.Path` object.\n\nunittest_setUpClass_fixture_MyTestCase [class scope]\n    /testbed/src/_pytest/unittest.py:144: no docstring available\n\n\n============================ no tests ran in 0.01s =============================\n=================== 1 failed, 59 passed, 30 skipped in 2.72s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/test_nose.py testing/test_unittest.py` failed. (See above for error)",
          "test_files_run": [
            "testing/test_nose.py",
            "testing/test_unittest.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 60,
          "failed": 0,
          "errors": 0,
          "collected": 90,
          "duration": 5.61,
          "log_tail": "testing/test_unittest.py::TestTrialUnittest::test_trial_exceptions_with_skips SKIPPED [ 50%]\ntesting/test_unittest.py::TestTrialUnittest::test_trial_error SKIPPED    [ 51%]\ntesting/test_unittest.py::TestTrialUnittest::test_trial_testcase_skip_property SKIPPED [ 52%]\ntesting/test_unittest.py::TestTrialUnittest::test_trial_testfunction_skip_property SKIPPED [ 53%]\ntesting/test_unittest.py::TestTrialUnittest::test_trial_testcase_todo_property SKIPPED [ 54%]\ntesting/test_unittest.py::TestTrialUnittest::test_trial_testfunction_todo_property SKIPPED [ 55%]\ntesting/test_unittest.py::test_djangolike_testcase PASSED                [ 56%]\ntesting/test_unittest.py::test_unittest_not_shown_in_traceback PASSED    [ 57%]\ntesting/test_unittest.py::test_unorderable_types PASSED                  [ 58%]\ntesting/test_unittest.py::test_unittest_typerror_traceback PASSED        [ 60%]\ntesting/test_unittest.py::test_unittest_expected_failure_for_failing_test_is_xfail[pytest] PASSED [ 61%]\ntesting/test_unittest.py::test_unittest_expected_failure_for_failing_test_is_xfail[unittest] PASSED [ 62%]\ntesting/test_unittest.py::test_unittest_expected_failure_for_passing_test_is_fail[pytest] PASSED [ 63%]\ntesting/test_unittest.py::test_unittest_expected_failure_for_passing_test_is_fail[unittest] PASSED [ 64%]\ntesting/test_unittest.py::test_unittest_setup_interaction[return] PASSED [ 65%]\ntesting/test_unittest.py::test_unittest_setup_interaction[yield] PASSED  [ 66%]\ntesting/test_unittest.py::test_non_unittest_no_setupclass_support PASSED [ 67%]\ntesting/test_unittest.py::test_no_teardown_if_setupclass_failed PASSED   [ 68%]\ntesting/test_unittest.py::test_cleanup_functions PASSED                  [ 70%]\ntesting/test_unittest.py::test_issue333_result_clearing PASSED           [ 71%]\ntesting/test_unittest.py::test_unittest_raise_skip_issue748 PASSED       [ 72%]\ntesting/test_unittest.py::test_unittest_skip_issue1169 PASSED            [ 73%]\ntesting/test_unittest.py::test_class_method_containing_test_issue1558 PASSED [ 74%]\ntesting/test_unittest.py::test_usefixtures_marker_on_unittest[builtins.object] PASSED [ 75%]\ntesting/test_unittest.py::test_usefixtures_marker_on_unittest[unittest.TestCase] PASSED [ 76%]\ntesting/test_unittest.py::test_testcase_handles_init_exceptions PASSED   [ 77%]\ntesting/test_unittest.py::test_error_message_with_parametrized_fixtures PASSED [ 78%]\ntesting/test_unittest.py::test_setup_inheritance_skipping[test_setup_skip.py-1 skipped] PASSED [ 80%]\ntesting/test_unittest.py::test_setup_inheritance_skipping[test_setup_skip_class.py-1 skipped] PASSED [ 81%]\ntesting/test_unittest.py::test_setup_inheritance_skipping[test_setup_skip_module.py-1 error] PASSED [ 82%]\ntesting/test_unittest.py::test_BdbQuit PASSED                            [ 83%]\ntesting/test_unittest.py::test_exit_outcome PASSED                       [ 84%]\ntesting/test_unittest.py::test_trace PASSED                              [ 85%]\ntesting/test_unittest.py::test_pdb_teardown_called PASSED                [ 86%]\ntesting/test_unittest.py::test_pdb_teardown_skipped[@unittest.skip] PASSED [ 87%]\ntesting/test_unittest.py::test_pdb_teardown_skipped[@pytest.mark.skip] PASSED [ 88%]\ntesting/test_unittest.py::test_async_support PASSED                      [ 90%]\ntesting/test_unittest.py::test_asynctest_support SKIPPED (could not ...) [ 91%]\ntesting/test_unittest.py::test_do_class_cleanups_on_success PASSED       [ 92%]\ntesting/test_unittest.py::test_do_class_cleanups_on_setupclass_failure PASSED [ 93%]\ntesting/test_unittest.py::test_do_class_cleanups_on_teardownclass_failure PASSED [ 94%]\ntesting/test_unittest.py::test_do_cleanups_on_success PASSED             [ 95%]\ntesting/test_unittest.py::test_do_cleanups_on_setup_failure PASSED       [ 96%]\ntesting/test_unittest.py::test_do_cleanups_on_teardown_failure PASSED    [ 97%]\ntesting/test_unittest.py::TestTrialUnittest::test_trial_pdb SKIPPED      [ 98%]\ntesting/test_unittest.py::test_plain_unittest_does_not_support_async PASSED [100%]\n\n======================== 60 passed, 30 skipped in 2.89s ========================\n\n",
          "test_files_run": [
            "testing/test_nose.py",
            "testing/test_unittest.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got True\u2192True"
    },
    {
      "instance_id": "pylint-dev__pylint-4551",
      "repo": "pylint-dev/pylint",
      "valid": true,
      "worker": "http://34.70.1.155:8080",
      "duration": 7.827760219573975,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 1,
          "collected": 0,
          "duration": 3.5,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 0 items / 1 error\n\n==================================== ERRORS ====================================\n_____________ ERROR collecting tests/unittest_pyreverse_writer.py ______________\nImportError while importing test module '/testbed/tests/unittest_pyreverse_writer.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/miniconda3/envs/testbed/lib/python3.9/importlib/__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests/unittest_pyreverse_writer.py:32: in <module>\n    from pylint.pyreverse.utils import get_annotation, get_visibility, infer_node\nE   ImportError: cannot import name 'get_annotation' from 'pylint.pyreverse.utils' (/testbed/pylint/pyreverse/utils.py)\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/interpreter/_import/util.py:6\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/interpreter/_import/util.py:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    import pkg_resources\n\n-- Docs: https://docs.pytest.org/en/stable/warnings.html\n!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n========================= 1 warning, 1 error in 0.11s ==========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/unittest_pyreverse_writer.py` failed. (See above for error)",
          "test_files_run": [
            "tests/unittest_pyreverse_writer.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 18,
          "failed": 0,
          "errors": 0,
          "collected": 18,
          "duration": 3.33,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 18 items\n\ntests/unittest_pyreverse_writer.py::test_dot_files[packages_No_Name.dot] PASSED [  5%]\ntests/unittest_pyreverse_writer.py::test_dot_files[classes_No_Name.dot] PASSED [ 11%]\ntests/unittest_pyreverse_writer.py::test_get_visibility[names0-special] PASSED [ 16%]\ntests/unittest_pyreverse_writer.py::test_get_visibility[names1-private] PASSED [ 22%]\ntests/unittest_pyreverse_writer.py::test_get_visibility[names2-public] PASSED [ 27%]\ntests/unittest_pyreverse_writer.py::test_get_visibility[names3-protected] PASSED [ 33%]\ntests/unittest_pyreverse_writer.py::test_get_annotation_annassign[a: str = None-Optional[str]] PASSED [ 38%]\ntests/unittest_pyreverse_writer.py::test_get_annotation_annassign[a: str = 'mystr'-str] PASSED [ 44%]\ntests/unittest_pyreverse_writer.py::test_get_annotation_annassign[a: Optional[str] = 'str'-Optional[str]] PASSED [ 50%]\ntests/unittest_pyreverse_writer.py::test_get_annotation_annassign[a: Optional[str] = None-Optional[str]] PASSED [ 55%]\ntests/unittest_pyreverse_writer.py::test_get_annotation_assignattr[def __init__(self, x: str):                   self.x = x-str] PASSED [ 61%]\ntests/unittest_pyreverse_writer.py::test_get_annotation_assignattr[def __init__(self, x: str = 'str'):           self.x = x-str] PASSED [ 66%]\ntests/unittest_pyreverse_writer.py::test_get_annotation_assignattr[def __init__(self, x: str = None):            self.x = x-Optional[str]] PASSED [ 72%]\ntests/unittest_pyreverse_writer.py::test_get_annotation_assignattr[def __init__(self, x: Optional[str]):         self.x = x-Optional[str]] PASSED [ 77%]\ntests/unittest_pyreverse_writer.py::test_get_annotation_assignattr[def __init__(self, x: Optional[str] = None):  self.x = x-Optional[str]] PASSED [ 83%]\ntests/unittest_pyreverse_writer.py::test_get_annotation_assignattr[def __init__(self, x: Optional[str] = 'str'): self.x = x-Optional[str]] PASSED [ 88%]\ntests/unittest_pyreverse_writer.py::test_infer_node_1 PASSED             [ 94%]\ntests/unittest_pyreverse_writer.py::test_infer_node_2 PASSED             [100%]\n\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/interpreter/_import/util.py:6\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/interpreter/_import/util.py:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    import pkg_resources\n\n-- Docs: https://docs.pytest.org/en/stable/warnings.html\n======================== 18 passed, 1 warning in 0.07s =========================\n\n",
          "test_files_run": [
            "tests/unittest_pyreverse_writer.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "pylint-dev__pylint-4604",
      "repo": "pylint-dev/pylint",
      "valid": true,
      "worker": "http://34.70.1.155:8080",
      "duration": 7.9951581954956055,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 1,
          "collected": 0,
          "duration": 3.3,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 0 items / 1 error\n\n==================================== ERRORS ====================================\n____________ ERROR collecting tests/checkers/unittest_variables.py _____________\nImportError while importing test module '/testbed/tests/checkers/unittest_variables.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/miniconda3/envs/testbed/lib/python3.9/importlib/__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests/checkers/unittest_variables.py:30: in <module>\n    from pylint.constants import IS_PYPY\nE   ImportError: cannot import name 'IS_PYPY' from 'pylint.constants' (/testbed/pylint/constants.py)\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/interpreter/_import/util.py:6\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/interpreter/_import/util.py:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    import pkg_resources\n\n-- Docs: https://docs.pytest.org/en/stable/warnings.html\n!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n========================= 1 warning, 1 error in 0.09s ==========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/checkers/unittest_variables.py` failed. (See above for error)",
          "test_files_run": [
            "tests/checkers/unittest_variables.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 21,
          "failed": 0,
          "errors": 0,
          "collected": 21,
          "duration": 3.79,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 21 items\n\ntests/checkers/unittest_variables.py::TestVariablesChecker::test_bitbucket_issue_78 PASSED [  4%]\ntests/checkers/unittest_variables.py::TestVariablesChecker::test_no_name_in_module_skipped PASSED [  9%]\ntests/checkers/unittest_variables.py::TestVariablesChecker::test_all_elements_without_parent PASSED [ 14%]\ntests/checkers/unittest_variables.py::TestVariablesChecker::test_redefined_builtin_ignored PASSED [ 19%]\ntests/checkers/unittest_variables.py::TestVariablesChecker::test_redefined_builtin_custom_modules PASSED [ 23%]\ntests/checkers/unittest_variables.py::TestVariablesChecker::test_redefined_builtin_modname_not_ignored PASSED [ 28%]\ntests/checkers/unittest_variables.py::TestVariablesChecker::test_redefined_builtin_in_function PASSED [ 33%]\ntests/checkers/unittest_variables.py::TestVariablesChecker::test_unassigned_global PASSED [ 38%]\ntests/checkers/unittest_variables.py::TestVariablesChecker::test_listcomp_in_decorator PASSED [ 42%]\ntests/checkers/unittest_variables.py::TestVariablesChecker::test_listcomp_in_ancestors PASSED [ 47%]\ntests/checkers/unittest_variables.py::TestVariablesChecker::test_return_type_annotation PASSED [ 52%]\ntests/checkers/unittest_variables.py::TestVariablesChecker::test_attribute_in_type_comment PASSED [ 57%]\ntests/checkers/unittest_variables.py::TestVariablesCheckerWithTearDown::test_custom_callback_string PASSED [ 61%]\ntests/checkers/unittest_variables.py::TestVariablesCheckerWithTearDown::test_redefined_builtin_modname_not_ignored PASSED [ 66%]\ntests/checkers/unittest_variables.py::TestVariablesCheckerWithTearDown::test_redefined_builtin_in_function PASSED [ 71%]\ntests/checkers/unittest_variables.py::TestVariablesCheckerWithTearDown::test_import_as_underscore PASSED [ 76%]\ntests/checkers/unittest_variables.py::TestVariablesCheckerWithTearDown::test_lambda_in_classdef PASSED [ 80%]\ntests/checkers/unittest_variables.py::TestVariablesCheckerWithTearDown::test_nested_lambda PASSED [ 85%]\ntests/checkers/unittest_variables.py::TestVariablesCheckerWithTearDown::test_ignored_argument_names_no_message PASSED [ 90%]\ntests/checkers/unittest_variables.py::TestVariablesCheckerWithTearDown::test_ignored_argument_names_starred_args PASSED [ 95%]\ntests/checkers/unittest_variables.py::TestMissingSubmodule::test_package_all PASSED [100%]\n\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/interpreter/_import/util.py:6\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/interpreter/_import/util.py:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    import pkg_resources\n\n-- Docs: https://docs.pytest.org/en/stable/warnings.html\n======================== 21 passed, 1 warning in 0.38s =========================\n\n",
          "test_files_run": [
            "tests/checkers/unittest_variables.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "pylint-dev__pylint-4661",
      "repo": "pylint-dev/pylint",
      "valid": false,
      "worker": "http://34.70.1.155:8080",
      "duration": 6.991508960723877,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 1,
          "collected": 0,
          "duration": 3.4,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 0 items / 1 error\n\n==================================== ERRORS ====================================\n_________________ ERROR collecting tests/lint/unittest_lint.py _________________\nImportError while importing test module '/testbed/tests/lint/unittest_lint.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/miniconda3/envs/testbed/lib/python3.9/importlib/__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests/lint/unittest_lint.py:49: in <module>\n    import appdirs\nE   ModuleNotFoundError: No module named 'appdirs'\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/interpreter/_import/util.py:6\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/interpreter/_import/util.py:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    import pkg_resources\n\n-- Docs: https://docs.pytest.org/en/stable/warnings.html\n!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n========================= 1 warning, 1 error in 0.18s ==========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/lint/unittest_lint.py` failed. (See above for error)",
          "test_files_run": [
            "tests/lint/unittest_lint.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 2.57,
          "log_tail": "\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:318: PluggyTeardownRaisedWarning: A plugin raised an exception during an old-style hookwrapper teardown.\nPlugin: helpconfig, Hook: pytest_cmdline_parse\nConftestImportFailure: ModuleNotFoundError: No module named 'appdirs' (from /testbed/tests/conftest.py)\nFor more information see https://pluggy.readthedocs.io/en/stable/api_reference.html#pluggy.PluggyTeardownRaisedWarning\n  config = pluginmanager.hook.pytest_cmdline_parse(\nImportError while loading conftest '/testbed/tests/conftest.py'.\ntests/conftest.py:8: in <module>\n    from pylint import checkers\npylint/checkers/__init__.py:49: in <module>\n    from pylint.checkers.base_checker import BaseChecker, BaseTokenChecker\npylint/checkers/base_checker.py:22: in <module>\n    from pylint.config import OptionsProviderMixIn\npylint/config/__init__.py:39: in <module>\n    import appdirs\nE   ModuleNotFoundError: No module named 'appdirs'\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/lint/unittest_lint.py` failed. (See above for error)",
          "test_files_run": [
            "tests/lint/unittest_lint.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "pylint-dev__pylint-4970",
      "repo": "pylint-dev/pylint",
      "valid": true,
      "worker": "http://34.70.1.155:8080",
      "duration": 7.55990195274353,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 17,
          "failed": 1,
          "errors": 0,
          "collected": 18,
          "duration": 3.29,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 18 items\n\ntests/checkers/unittest_similar.py::test_ignore_comments PASSED          [  5%]\ntests/checkers/unittest_similar.py::test_ignore_docstrings PASSED        [ 11%]\ntests/checkers/unittest_similar.py::test_ignore_imports PASSED           [ 16%]\ntests/checkers/unittest_similar.py::test_multiline_imports PASSED        [ 22%]\ntests/checkers/unittest_similar.py::test_ignore_multiline_imports PASSED [ 27%]\ntests/checkers/unittest_similar.py::test_ignore_signatures_fail PASSED   [ 33%]\ntests/checkers/unittest_similar.py::test_ignore_signatures_pass PASSED   [ 38%]\ntests/checkers/unittest_similar.py::test_ignore_signatures_class_methods_fail PASSED [ 44%]\ntests/checkers/unittest_similar.py::test_ignore_signatures_class_methods_pass PASSED [ 50%]\ntests/checkers/unittest_similar.py::test_ignore_signatures_empty_functions_fail PASSED [ 55%]\ntests/checkers/unittest_similar.py::test_ignore_signatures_empty_functions_pass PASSED [ 61%]\ntests/checkers/unittest_similar.py::test_no_hide_code_with_imports PASSED [ 66%]\ntests/checkers/unittest_similar.py::test_ignore_nothing PASSED           [ 72%]\ntests/checkers/unittest_similar.py::test_lines_without_meaningful_content_do_not_trigger_similarity PASSED [ 77%]\ntests/checkers/unittest_similar.py::test_help PASSED                     [ 83%]\ntests/checkers/unittest_similar.py::test_no_args PASSED                  [ 88%]\ntests/checkers/unittest_similar.py::test_get_map_data PASSED             [ 94%]\ntests/checkers/unittest_similar.py::test_set_duplicate_lines_to_zero FAILED [100%]\n\n=================================== FAILURES ===================================\n_______________________ test_set_duplicate_lines_to_zero _______________________\ntests/checkers/unittest_similar.py:512: in test_set_duplicate_lines_to_zero\n    assert output.getvalue() == \"\"\nE   AssertionError: assert 'TOTAL lines=...cent=0.00\\n\\n' == ''\nE     + TOTAL lines=62 duplicates=0 percent=0.00\nE     +\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/interpreter/_import/util.py:6\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/interpreter/_import/util.py:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    import pkg_resources\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/node_classes.py:90\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/node_classes.py:90: DeprecationWarning: The 'astroid.node_classes' module is deprecated and will be replaced by 'astroid.nodes' in astroid 3.0.0\n    warnings.warn(\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/scoped_nodes.py:26\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/scoped_nodes.py:26: DeprecationWarning: The 'astroid.scoped_nodes' module is deprecated and will be replaced by 'astroid.nodes' in astroid 3.0.0\n    warnings.warn(\n\n-- Docs: https://docs.pytest.org/en/stable/warnings.html\n=================== 1 failed, 17 passed, 3 warnings in 0.09s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/checkers/unittest_similar.py` failed. (See above for error)",
          "test_files_run": [
            "tests/checkers/unittest_similar.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 18,
          "failed": 0,
          "errors": 0,
          "collected": 18,
          "duration": 3.28,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 18 items\n\ntests/checkers/unittest_similar.py::test_ignore_comments PASSED          [  5%]\ntests/checkers/unittest_similar.py::test_ignore_docstrings PASSED        [ 11%]\ntests/checkers/unittest_similar.py::test_ignore_imports PASSED           [ 16%]\ntests/checkers/unittest_similar.py::test_multiline_imports PASSED        [ 22%]\ntests/checkers/unittest_similar.py::test_ignore_multiline_imports PASSED [ 27%]\ntests/checkers/unittest_similar.py::test_ignore_signatures_fail PASSED   [ 33%]\ntests/checkers/unittest_similar.py::test_ignore_signatures_pass PASSED   [ 38%]\ntests/checkers/unittest_similar.py::test_ignore_signatures_class_methods_fail PASSED [ 44%]\ntests/checkers/unittest_similar.py::test_ignore_signatures_class_methods_pass PASSED [ 50%]\ntests/checkers/unittest_similar.py::test_ignore_signatures_empty_functions_fail PASSED [ 55%]\ntests/checkers/unittest_similar.py::test_ignore_signatures_empty_functions_pass PASSED [ 61%]\ntests/checkers/unittest_similar.py::test_no_hide_code_with_imports PASSED [ 66%]\ntests/checkers/unittest_similar.py::test_ignore_nothing PASSED           [ 72%]\ntests/checkers/unittest_similar.py::test_lines_without_meaningful_content_do_not_trigger_similarity PASSED [ 77%]\ntests/checkers/unittest_similar.py::test_help PASSED                     [ 83%]\ntests/checkers/unittest_similar.py::test_no_args PASSED                  [ 88%]\ntests/checkers/unittest_similar.py::test_get_map_data PASSED             [ 94%]\ntests/checkers/unittest_similar.py::test_set_duplicate_lines_to_zero PASSED [100%]\n\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/interpreter/_import/util.py:6\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/interpreter/_import/util.py:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    import pkg_resources\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/node_classes.py:90\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/node_classes.py:90: DeprecationWarning: The 'astroid.node_classes' module is deprecated and will be replaced by 'astroid.nodes' in astroid 3.0.0\n    warnings.warn(\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/scoped_nodes.py:26\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/scoped_nodes.py:26: DeprecationWarning: The 'astroid.scoped_nodes' module is deprecated and will be replaced by 'astroid.nodes' in astroid 3.0.0\n    warnings.warn(\n\n-- Docs: https://docs.pytest.org/en/stable/warnings.html\n======================== 18 passed, 3 warnings in 0.06s ========================\n\n",
          "test_files_run": [
            "tests/checkers/unittest_similar.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "pylint-dev__pylint-6386",
      "repo": "pylint-dev/pylint",
      "valid": true,
      "worker": "http://34.70.1.155:8080",
      "duration": 8.637410879135132,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 7,
          "failed": 1,
          "errors": 0,
          "collected": 8,
          "duration": 3.88,
          "log_tail": "tests/config/test_config.py::test_unknown_yes_no PASSED                  [ 75%]\ntests/config/test_config.py::test_unknown_py_version PASSED              [ 87%]\ntests/config/test_config.py::test_short_verbose FAILED                   [100%]\n\n=================================== FAILURES ===================================\n______________________________ test_short_verbose ______________________________\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:1858: in parse_known_args\n    namespace, args = self._parse_known_args(args, namespace)\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:2067: in _parse_known_args\n    start_index = consume_optional(start_index)\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:1997: in consume_optional\n    arg_count = match_argument(action, selected_patterns)\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:2162: in _match_argument\n    raise ArgumentError(action, msg)\nE   argparse.ArgumentError: argument --verbose/-v: expected one argument\n\nDuring handling of the above exception, another exception occurred:\ntests/config/test_config.py:107: in test_short_verbose\n    Run([str(EMPTY_MODULE), \"-v\"], exit=False)\npylint/lint/run.py:135: in __init__\n    args = _config_initialization(\npylint/config/config_initialization.py:73: in _config_initialization\n    parsed_args_list = linter._parse_command_line_configuration(args_list)\npylint/config/arguments_manager.py:258: in _parse_command_line_configuration\n    self.config, parsed_args = self._arg_parser.parse_known_args(\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:1861: in parse_known_args\n    self.error(str(err))\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:2582: in error\n    self.exit(2, _('%(prog)s: error: %(message)s\\n') % args)\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:2569: in exit\n    _sys.exit(status)\nE   SystemExit: 2\n----------------------------- Captured stderr call -----------------------------\nusage: pylint [options]\npylint: error: argument --verbose/-v: expected one argument\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/interpreter/_import/util.py:6\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/interpreter/_import/util.py:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    import pkg_resources\n\npylint/checkers/utils.py:455: 146 warnings\ntests/config/test_config.py: 14 warnings\n  /testbed/pylint/checkers/utils.py:455: DeprecationWarning: utils.check_messages will be removed in favour of calling utils.only_required_for_messages in pylint 3.0\n    warnings.warn(\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================== 1 failed, 7 passed, 161 warnings in 0.45s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/config/test_config.py` failed. (See above for error)",
          "test_files_run": [
            "tests/config/test_config.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 8,
          "failed": 0,
          "errors": 0,
          "collected": 8,
          "duration": 3.86,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 8 items\n\ntests/config/test_config.py::test_can_read_toml_env_variable PASSED      [ 12%]\ntests/config/test_config.py::test_unknown_message_id PASSED              [ 25%]\ntests/config/test_config.py::test_unknown_option_name PASSED             [ 37%]\ntests/config/test_config.py::test_unknown_short_option_name PASSED       [ 50%]\ntests/config/test_config.py::test_unknown_confidence PASSED              [ 62%]\ntests/config/test_config.py::test_unknown_yes_no PASSED                  [ 75%]\ntests/config/test_config.py::test_unknown_py_version PASSED              [ 87%]\ntests/config/test_config.py::test_short_verbose PASSED                   [100%]\n\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/interpreter/_import/util.py:6\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/interpreter/_import/util.py:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    import pkg_resources\n\npylint/checkers/utils.py:455: 146 warnings\ntests/config/test_config.py: 14 warnings\n  /testbed/pylint/checkers/utils.py:455: DeprecationWarning: utils.check_messages will be removed in favour of calling utils.only_required_for_messages in pylint 3.0\n    warnings.warn(\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======================= 8 passed, 161 warnings in 0.30s ========================\n\n",
          "test_files_run": [
            "tests/config/test_config.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "pylint-dev__pylint-6528",
      "repo": "pylint-dev/pylint",
      "valid": false,
      "worker": "http://34.70.1.155:8080",
      "duration": 48.93670916557312,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 171,
          "failed": 6,
          "errors": 0,
          "collected": 178,
          "duration": 24.91,
          "log_tail": "E     ------------------------------------------------------------------\nE     Your code has been rated at 0.00/10 (previous run: 0.00/10, +0.00)\nE     \nE     \nE   assert 20 == 0\n________________ TestCallbackOptions.test_generate_toml_config _________________\ntests/test_self.py:1459: in test_generate_toml_config\n    assert \"[tool.pylint.master]\" in process.stdout\nE   assert '[tool.pylint.master]' in ''\nE    +  where '' = CompletedProcess(args=['/opt/miniconda3/envs/testbed/bin/python', '-m', 'pylint', '--rcfile=/testbed/pylint/testutils/testing_pylintrc', '--preferred-modules=a:b', '--generate-toml-config'], returncode=1, stdout='', stderr='Traceback (most recent call last):\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\\n    return _run_code(code, main_globals, None,\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/runpy.py\", line 87, in _run_code\\n    exec(code, run_globals)\\n  File \"/testbed/pylint/__main__.py\", line 10, in <module>\\n    pylint.run_pylint()\\n  File \"/testbed/pylint/__init__.py\", line 25, in run_pylint\\n    PylintRun(argv or sys.argv[1:])\\n  File \"/testbed/pylint/lint/run.py\", line 135, in __init__\\n    args = _config_initialization(\\n  File \"/testbed/pylint/config/config_initialization.py\", line 73, in _config_initialization\\n    parsed_args_list = linter._parse_command_line_configuration(args_list)\\n  File \"/testbed/pylint/config/arguments_manager.py\", line 258, in _parse_command_line_configuration\\n    self.config, parsed_args = self._arg_parser.parse_known_args(\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/argparse.... 2067, in _parse_known_args\\n    start_index = consume_optional(start_index)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py\", line 2007, in consume_optional\\n    take_action(action, args, option_string)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py\", line 1935, in take_action\\n    action(self, namespace, argument_values, option_string)\\n  File \"/testbed/pylint/config/callback_actions.py\", line 281, in __call__\\n    self.run.linter._generate_config_file()\\n  File \"/testbed/pylint/config/arguments_manager.py\", line 661, in _generate_config_file\\n    toml_doc.add(tomlkit.key([\"tool\", \"pylint\"]), pylint_tool_table)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py\", line 116, in add\\n    return self.append(key, item)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py\", line 171, in append\\n    self._handle_dotted_key(key, item)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py\", line 120, in _handle_dotted_key\\n    raise TOMLKitError(\"Can\\'t add a table to a dotted key\")\\ntomlkit.exceptions.TOMLKitError: Can\\'t add a table to a dotted key\\n').stdout\n_____ TestCallbackOptions.test_generate_toml_config_disable_symbolic_names _____\ntests/test_self.py:1479: in test_generate_toml_config_disable_symbolic_names\n    Run([\"--generate-toml-config\"])\npylint/testutils/_run.py:45: in __init__\n    super().__init__(args, reporter, exit, do_exit)\npylint/lint/run.py:135: in __init__\n    args = _config_initialization(\npylint/config/config_initialization.py:73: in _config_initialization\n    parsed_args_list = linter._parse_command_line_configuration(args_list)\npylint/config/arguments_manager.py:258: in _parse_command_line_configuration\n    self.config, parsed_args = self._arg_parser.parse_known_args(\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:1858: in parse_known_args\n    namespace, args = self._parse_known_args(args, namespace)\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:2067: in _parse_known_args\n    start_index = consume_optional(start_index)\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:2007: in consume_optional\n    take_action(action, args, option_string)\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:1935: in take_action\n    action(self, namespace, argument_values, option_string)\npylint/config/callback_actions.py:281: in __call__\n    self.run.linter._generate_config_file()\npylint/config/arguments_manager.py:661: in _generate_config_file\n    toml_doc.add(tomlkit.key([\"tool\", \"pylint\"]), pylint_tool_table)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py:116: in add\n    return self.append(key, item)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py:171: in append\n    self._handle_dotted_key(key, item)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py:120: in _handle_dotted_key\n    raise TOMLKitError(\"Can't add a table to a dotted key\")\nE   tomlkit.exceptions.TOMLKitError: Can't add a table to a dotted key\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/interpreter/_import/util.py:6\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/interpreter/_import/util.py:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    import pkg_resources\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n============= 6 failed, 171 passed, 1 xfailed, 1 warning in 20.12s =============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/lint/unittest_lint.py tests/regrtest_data/directory/ignored_subdirectory/failing.py tests/test_self.py` failed. (See above for error)",
          "test_files_run": [
            "tests/lint/unittest_lint.py",
            "tests/regrtest_data/directory/ignored_subdirectory/failing.py",
            "tests/test_self.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 175,
          "failed": 2,
          "errors": 0,
          "collected": 178,
          "duration": 23.19,
          "log_tail": "tests/test_self.py::TestCallbackOptions::test_errors_only PASSED         [ 98%]\ntests/test_self.py::TestCallbackOptions::test_verbose PASSED             [ 99%]\ntests/test_self.py::TestCallbackOptions::test_enable_all_extensions PASSED [100%]\n\n=================================== FAILURES ===================================\n________________ TestCallbackOptions.test_generate_toml_config _________________\ntests/test_self.py:1459: in test_generate_toml_config\n    assert \"[tool.pylint.master]\" in process.stdout\nE   assert '[tool.pylint.master]' in ''\nE    +  where '' = CompletedProcess(args=['/opt/miniconda3/envs/testbed/bin/python', '-m', 'pylint', '--rcfile=/testbed/pylint/testutils/testing_pylintrc', '--preferred-modules=a:b', '--generate-toml-config'], returncode=1, stdout='', stderr='Traceback (most recent call last):\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\\n    return _run_code(code, main_globals, None,\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/runpy.py\", line 87, in _run_code\\n    exec(code, run_globals)\\n  File \"/testbed/pylint/__main__.py\", line 10, in <module>\\n    pylint.run_pylint()\\n  File \"/testbed/pylint/__init__.py\", line 25, in run_pylint\\n    PylintRun(argv or sys.argv[1:])\\n  File \"/testbed/pylint/lint/run.py\", line 135, in __init__\\n    args = _config_initialization(\\n  File \"/testbed/pylint/config/config_initialization.py\", line 73, in _config_initialization\\n    parsed_args_list = linter._parse_command_line_configuration(args_list)\\n  File \"/testbed/pylint/config/arguments_manager.py\", line 258, in _parse_command_line_configuration\\n    self.config, parsed_args = self._arg_parser.parse_known_args(\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/argparse.... 2067, in _parse_known_args\\n    start_index = consume_optional(start_index)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py\", line 2007, in consume_optional\\n    take_action(action, args, option_string)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py\", line 1935, in take_action\\n    action(self, namespace, argument_values, option_string)\\n  File \"/testbed/pylint/config/callback_actions.py\", line 281, in __call__\\n    self.run.linter._generate_config_file()\\n  File \"/testbed/pylint/config/arguments_manager.py\", line 661, in _generate_config_file\\n    toml_doc.add(tomlkit.key([\"tool\", \"pylint\"]), pylint_tool_table)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py\", line 116, in add\\n    return self.append(key, item)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py\", line 171, in append\\n    self._handle_dotted_key(key, item)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py\", line 120, in _handle_dotted_key\\n    raise TOMLKitError(\"Can\\'t add a table to a dotted key\")\\ntomlkit.exceptions.TOMLKitError: Can\\'t add a table to a dotted key\\n').stdout\n_____ TestCallbackOptions.test_generate_toml_config_disable_symbolic_names _____\ntests/test_self.py:1479: in test_generate_toml_config_disable_symbolic_names\n    Run([\"--generate-toml-config\"])\npylint/testutils/_run.py:45: in __init__\n    super().__init__(args, reporter, exit, do_exit)\npylint/lint/run.py:135: in __init__\n    args = _config_initialization(\npylint/config/config_initialization.py:73: in _config_initialization\n    parsed_args_list = linter._parse_command_line_configuration(args_list)\npylint/config/arguments_manager.py:258: in _parse_command_line_configuration\n    self.config, parsed_args = self._arg_parser.parse_known_args(\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:1858: in parse_known_args\n    namespace, args = self._parse_known_args(args, namespace)\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:2067: in _parse_known_args\n    start_index = consume_optional(start_index)\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:2007: in consume_optional\n    take_action(action, args, option_string)\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:1935: in take_action\n    action(self, namespace, argument_values, option_string)\npylint/config/callback_actions.py:281: in __call__\n    self.run.linter._generate_config_file()\npylint/config/arguments_manager.py:661: in _generate_config_file\n    toml_doc.add(tomlkit.key([\"tool\", \"pylint\"]), pylint_tool_table)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py:116: in add\n    return self.append(key, item)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py:171: in append\n    self._handle_dotted_key(key, item)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py:120: in _handle_dotted_key\n    raise TOMLKitError(\"Can't add a table to a dotted key\")\nE   tomlkit.exceptions.TOMLKitError: Can't add a table to a dotted key\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/interpreter/_import/util.py:6\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/interpreter/_import/util.py:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    import pkg_resources\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n============= 2 failed, 175 passed, 1 xfailed, 1 warning in 18.69s =============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/lint/unittest_lint.py tests/regrtest_data/directory/ignored_subdirectory/failing.py tests/test_self.py` failed. (See above for error)",
          "test_files_run": [
            "tests/lint/unittest_lint.py",
            "tests/regrtest_data/directory/ignored_subdirectory/failing.py",
            "tests/test_self.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "pylint-dev__pylint-6903",
      "repo": "pylint-dev/pylint",
      "valid": true,
      "worker": "http://34.70.1.155:8080",
      "duration": 28.824294805526733,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 8,
          "failed": 1,
          "errors": 0,
          "collected": 9,
          "duration": 14.32,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 9 items\n\ntests/test_pylint_runners.py::test_runner[run_epylint] PASSED            [ 11%]\ntests/test_pylint_runners.py::test_runner[run_pylint] PASSED             [ 22%]\ntests/test_pylint_runners.py::test_runner[run_pyreverse] PASSED          [ 33%]\ntests/test_pylint_runners.py::test_runner[run_symilar] PASSED            [ 44%]\ntests/test_pylint_runners.py::test_runner_with_arguments[run_epylint] PASSED [ 55%]\ntests/test_pylint_runners.py::test_runner_with_arguments[run_pylint] PASSED [ 66%]\ntests/test_pylint_runners.py::test_runner_with_arguments[run_pyreverse] PASSED [ 77%]\ntests/test_pylint_runners.py::test_runner_with_arguments[run_symilar] PASSED [ 88%]\ntests/test_pylint_runners.py::test_pylint_run_jobs_equal_zero_dont_crash_with_cpu_fraction FAILED [100%]\n\n=================================== FAILURES ===================================\n_________ test_pylint_run_jobs_equal_zero_dont_crash_with_cpu_fraction _________\ntests/test_pylint_runners.py:76: in test_pylint_run_jobs_equal_zero_dont_crash_with_cpu_fraction\n    Run(testargs, reporter=Reporter())\npylint/lint/run.py:197: in __init__\n    linter.check(args)\npylint/lint/pylinter.py:654: in check\n    check_parallel(\npylint/lint/parallel.py:140: in check_parallel\n    with multiprocessing.Pool(\n/opt/miniconda3/envs/testbed/lib/python3.9/multiprocessing/context.py:119: in Pool\n    return Pool(processes, initializer, initargs, maxtasksperchild,\n/opt/miniconda3/envs/testbed/lib/python3.9/multiprocessing/pool.py:205: in __init__\n    raise ValueError(\"Number of processes must be at least 1\")\nE   ValueError: Number of processes must be at least 1\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/interpreter/_import/util.py:6\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/interpreter/_import/util.py:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    import pkg_resources\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=================== 1 failed, 8 passed, 1 warning in 10.00s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_pylint_runners.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_pylint_runners.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 9,
          "failed": 0,
          "errors": 0,
          "collected": 9,
          "duration": 13.63,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 9 items\n\ntests/test_pylint_runners.py::test_runner[run_epylint] PASSED            [ 11%]\ntests/test_pylint_runners.py::test_runner[run_pylint] PASSED             [ 22%]\ntests/test_pylint_runners.py::test_runner[run_pyreverse] PASSED          [ 33%]\ntests/test_pylint_runners.py::test_runner[run_symilar] PASSED            [ 44%]\ntests/test_pylint_runners.py::test_runner_with_arguments[run_epylint] PASSED [ 55%]\ntests/test_pylint_runners.py::test_runner_with_arguments[run_pylint] PASSED [ 66%]\ntests/test_pylint_runners.py::test_runner_with_arguments[run_pyreverse] PASSED [ 77%]\ntests/test_pylint_runners.py::test_runner_with_arguments[run_symilar] PASSED [ 88%]\ntests/test_pylint_runners.py::test_pylint_run_jobs_equal_zero_dont_crash_with_cpu_fraction PASSED [100%]\n\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/interpreter/_import/util.py:6\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/interpreter/_import/util.py:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    import pkg_resources\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n========================= 9 passed, 1 warning in 9.68s =========================\n\n",
          "test_files_run": [
            "tests/test_pylint_runners.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "pylint-dev__pylint-7080",
      "repo": "pylint-dev/pylint",
      "valid": false,
      "worker": "http://34.70.1.155:8080",
      "duration": 46.14290976524353,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 121,
          "failed": 3,
          "errors": 0,
          "collected": 125,
          "duration": 23.17,
          "log_tail": "E     -----------------------------------\nE     Your code has been rated at 0.00/10\nE     \nE     \nE   assert 20 == 0\n________________ TestCallbackOptions.test_generate_toml_config _________________\ntests/test_self.py:1493: in test_generate_toml_config\n    assert \"[tool.pylint.main]\" in process.stdout\nE   assert '[tool.pylint.main]' in ''\nE    +  where '' = CompletedProcess(args=['/opt/miniconda3/envs/testbed/bin/python', '-m', 'pylint', '--rcfile=/testbed/pylint/testutils/testing_pylintrc', '--preferred-modules=a:b', '--generate-toml-config'], returncode=1, stdout='', stderr='Traceback (most recent call last):\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\\n    return _run_code(code, main_globals, None,\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/runpy.py\", line 87, in _run_code\\n    exec(code, run_globals)\\n  File \"/testbed/pylint/__main__.py\", line 10, in <module>\\n    pylint.run_pylint()\\n  File \"/testbed/pylint/__init__.py\", line 25, in run_pylint\\n    PylintRun(argv or sys.argv[1:])\\n  File \"/testbed/pylint/lint/run.py\", line 161, in __init__\\n    args = _config_initialization(\\n  File \"/testbed/pylint/config/config_initialization.py\", line 73, in _config_initialization\\n    parsed_args_list = linter._parse_command_line_configuration(args_list)\\n  File \"/testbed/pylint/config/arguments_manager.py\", line 271, in _parse_command_line_configuration\\n    self.config, parsed_args = self._arg_parser.parse_known_args(\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/argparse....in _parse_known_args\\n    start_index = consume_optional(start_index)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py\", line 2007, in consume_optional\\n    take_action(action, args, option_string)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py\", line 1935, in take_action\\n    action(self, namespace, argument_values, option_string)\\n  File \"/testbed/pylint/config/callback_actions.py\", line 281, in __call__\\n    print(self.run.linter._generate_config_file())\\n  File \"/testbed/pylint/config/arguments_manager.py\", line 681, in _generate_config_file\\n    toml_doc.add(tomlkit.key([\"tool\", \"pylint\"]), pylint_tool_table)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py\", line 116, in add\\n    return self.append(key, item)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py\", line 171, in append\\n    self._handle_dotted_key(key, item)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py\", line 120, in _handle_dotted_key\\n    raise TOMLKitError(\"Can\\'t add a table to a dotted key\")\\ntomlkit.exceptions.TOMLKitError: Can\\'t add a table to a dotted key\\n').stdout\n_____ TestCallbackOptions.test_generate_toml_config_disable_symbolic_names _____\ntests/test_self.py:1528: in test_generate_toml_config_disable_symbolic_names\n    Run([\"--generate-toml-config\"])\npylint/testutils/_run.py:45: in __init__\n    super().__init__(args, reporter, exit, do_exit)\npylint/lint/run.py:161: in __init__\n    args = _config_initialization(\npylint/config/config_initialization.py:73: in _config_initialization\n    parsed_args_list = linter._parse_command_line_configuration(args_list)\npylint/config/arguments_manager.py:271: in _parse_command_line_configuration\n    self.config, parsed_args = self._arg_parser.parse_known_args(\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:1858: in parse_known_args\n    namespace, args = self._parse_known_args(args, namespace)\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:2067: in _parse_known_args\n    start_index = consume_optional(start_index)\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:2007: in consume_optional\n    take_action(action, args, option_string)\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:1935: in take_action\n    action(self, namespace, argument_values, option_string)\npylint/config/callback_actions.py:281: in __call__\n    print(self.run.linter._generate_config_file())\npylint/config/arguments_manager.py:681: in _generate_config_file\n    toml_doc.add(tomlkit.key([\"tool\", \"pylint\"]), pylint_tool_table)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py:116: in add\n    return self.append(key, item)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py:171: in append\n    self._handle_dotted_key(key, item)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py:120: in _handle_dotted_key\n    raise TOMLKitError(\"Can't add a table to a dotted key\")\nE   tomlkit.exceptions.TOMLKitError: Can't add a table to a dotted key\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/interpreter/_import/util.py:6\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/interpreter/_import/util.py:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    import pkg_resources\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n============= 3 failed, 121 passed, 1 xfailed, 1 warning in 18.57s =============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_self.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_self.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 122,
          "failed": 2,
          "errors": 0,
          "collected": 125,
          "duration": 22.14,
          "log_tail": "tests/test_self.py::TestCallbackOptions::test_errors_only_functions_as_disable PASSED [ 98%]\ntests/test_self.py::TestCallbackOptions::test_verbose PASSED             [ 99%]\ntests/test_self.py::TestCallbackOptions::test_enable_all_extensions PASSED [100%]\n\n=================================== FAILURES ===================================\n________________ TestCallbackOptions.test_generate_toml_config _________________\ntests/test_self.py:1493: in test_generate_toml_config\n    assert \"[tool.pylint.main]\" in process.stdout\nE   assert '[tool.pylint.main]' in ''\nE    +  where '' = CompletedProcess(args=['/opt/miniconda3/envs/testbed/bin/python', '-m', 'pylint', '--rcfile=/testbed/pylint/testutils/testing_pylintrc', '--preferred-modules=a:b', '--generate-toml-config'], returncode=1, stdout='', stderr='Traceback (most recent call last):\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\\n    return _run_code(code, main_globals, None,\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/runpy.py\", line 87, in _run_code\\n    exec(code, run_globals)\\n  File \"/testbed/pylint/__main__.py\", line 10, in <module>\\n    pylint.run_pylint()\\n  File \"/testbed/pylint/__init__.py\", line 25, in run_pylint\\n    PylintRun(argv or sys.argv[1:])\\n  File \"/testbed/pylint/lint/run.py\", line 161, in __init__\\n    args = _config_initialization(\\n  File \"/testbed/pylint/config/config_initialization.py\", line 73, in _config_initialization\\n    parsed_args_list = linter._parse_command_line_configuration(args_list)\\n  File \"/testbed/pylint/config/arguments_manager.py\", line 271, in _parse_command_line_configuration\\n    self.config, parsed_args = self._arg_parser.parse_known_args(\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/argparse....in _parse_known_args\\n    start_index = consume_optional(start_index)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py\", line 2007, in consume_optional\\n    take_action(action, args, option_string)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py\", line 1935, in take_action\\n    action(self, namespace, argument_values, option_string)\\n  File \"/testbed/pylint/config/callback_actions.py\", line 281, in __call__\\n    print(self.run.linter._generate_config_file())\\n  File \"/testbed/pylint/config/arguments_manager.py\", line 681, in _generate_config_file\\n    toml_doc.add(tomlkit.key([\"tool\", \"pylint\"]), pylint_tool_table)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py\", line 116, in add\\n    return self.append(key, item)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py\", line 171, in append\\n    self._handle_dotted_key(key, item)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py\", line 120, in _handle_dotted_key\\n    raise TOMLKitError(\"Can\\'t add a table to a dotted key\")\\ntomlkit.exceptions.TOMLKitError: Can\\'t add a table to a dotted key\\n').stdout\n_____ TestCallbackOptions.test_generate_toml_config_disable_symbolic_names _____\ntests/test_self.py:1528: in test_generate_toml_config_disable_symbolic_names\n    Run([\"--generate-toml-config\"])\npylint/testutils/_run.py:45: in __init__\n    super().__init__(args, reporter, exit, do_exit)\npylint/lint/run.py:161: in __init__\n    args = _config_initialization(\npylint/config/config_initialization.py:73: in _config_initialization\n    parsed_args_list = linter._parse_command_line_configuration(args_list)\npylint/config/arguments_manager.py:271: in _parse_command_line_configuration\n    self.config, parsed_args = self._arg_parser.parse_known_args(\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:1858: in parse_known_args\n    namespace, args = self._parse_known_args(args, namespace)\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:2067: in _parse_known_args\n    start_index = consume_optional(start_index)\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:2007: in consume_optional\n    take_action(action, args, option_string)\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:1935: in take_action\n    action(self, namespace, argument_values, option_string)\npylint/config/callback_actions.py:281: in __call__\n    print(self.run.linter._generate_config_file())\npylint/config/arguments_manager.py:681: in _generate_config_file\n    toml_doc.add(tomlkit.key([\"tool\", \"pylint\"]), pylint_tool_table)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py:116: in add\n    return self.append(key, item)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py:171: in append\n    self._handle_dotted_key(key, item)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py:120: in _handle_dotted_key\n    raise TOMLKitError(\"Can't add a table to a dotted key\")\nE   tomlkit.exceptions.TOMLKitError: Can't add a table to a dotted key\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/interpreter/_import/util.py:6\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/interpreter/_import/util.py:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    import pkg_resources\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n============= 2 failed, 122 passed, 1 xfailed, 1 warning in 17.84s =============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_self.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_self.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "pylint-dev__pylint-7277",
      "repo": "pylint-dev/pylint",
      "valid": false,
      "worker": "http://34.70.1.155:8080",
      "duration": 45.06036901473999,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 122,
          "failed": 3,
          "errors": 0,
          "collected": 126,
          "duration": 22.4,
          "log_tail": "    assert sys.path == paths\nE   AssertionError: assert ['/usr/local/...ite-packages'] == ['/do_not_rem...ite-packages']\nE     At index 0 diff: '/usr/local/lib/python39.zip' != '/do_not_remove'\nE     Right contains one more item: '/usr/local/lib/python3.9/site-packages'\nE     Full diff:\nE       [\nE     -  '/do_not_remove',\nE        '/usr/local/lib/python39.zip',\nE        '/usr/local/lib/python3.9',...\nE     \nE     ...Full output truncated (3 lines hidden), use '-vv' to show\n________________ TestCallbackOptions.test_generate_toml_config _________________\ntests/test_self.py:1312: in test_generate_toml_config\n    assert \"[tool.pylint.main]\" in process.stdout\nE   assert '[tool.pylint.main]' in ''\nE    +  where '' = CompletedProcess(args=['/opt/miniconda3/envs/testbed/bin/python', '-m', 'pylint', '--rcfile=/testbed/pylint/testutils/testing_pylintrc', '--preferred-modules=a:b', '--generate-toml-config'], returncode=1, stdout='', stderr='Traceback (most recent call last):\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\\n    return _run_code(code, main_globals, None,\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/runpy.py\", line 87, in _run_code\\n    exec(code, run_globals)\\n  File \"/testbed/pylint/__main__.py\", line 10, in <module>\\n    pylint.run_pylint()\\n  File \"/testbed/pylint/__init__.py\", line 35, in run_pylint\\n    PylintRun(argv or sys.argv[1:])\\n  File \"/testbed/pylint/lint/run.py\", line 161, in __init__\\n    args = _config_initialization(\\n  File \"/testbed/pylint/config/config_initialization.py\", line 73, in _config_initialization\\n    parsed_args_list = linter._parse_command_line_configuration(args_list)\\n  File \"/testbed/pylint/config/arguments_manager.py\", line 271, in _parse_command_line_configuration\\n    self.config, parsed_args = self._arg_parser.parse_known_args(\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/argparse....in _parse_known_args\\n    start_index = consume_optional(start_index)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py\", line 2007, in consume_optional\\n    take_action(action, args, option_string)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py\", line 1935, in take_action\\n    action(self, namespace, argument_values, option_string)\\n  File \"/testbed/pylint/config/callback_actions.py\", line 282, in __call__\\n    print(self.run.linter._generate_config_file())\\n  File \"/testbed/pylint/config/arguments_manager.py\", line 681, in _generate_config_file\\n    toml_doc.add(tomlkit.key([\"tool\", \"pylint\"]), pylint_tool_table)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py\", line 116, in add\\n    return self.append(key, item)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py\", line 171, in append\\n    self._handle_dotted_key(key, item)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py\", line 120, in _handle_dotted_key\\n    raise TOMLKitError(\"Can\\'t add a table to a dotted key\")\\ntomlkit.exceptions.TOMLKitError: Can\\'t add a table to a dotted key\\n').stdout\n_____ TestCallbackOptions.test_generate_toml_config_disable_symbolic_names _____\ntests/test_self.py:1348: in test_generate_toml_config_disable_symbolic_names\n    Run([\"--generate-toml-config\"])\npylint/testutils/_run.py:45: in __init__\n    super().__init__(args, reporter, exit, do_exit)\npylint/lint/run.py:161: in __init__\n    args = _config_initialization(\npylint/config/config_initialization.py:73: in _config_initialization\n    parsed_args_list = linter._parse_command_line_configuration(args_list)\npylint/config/arguments_manager.py:271: in _parse_command_line_configuration\n    self.config, parsed_args = self._arg_parser.parse_known_args(\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:1858: in parse_known_args\n    namespace, args = self._parse_known_args(args, namespace)\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:2067: in _parse_known_args\n    start_index = consume_optional(start_index)\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:2007: in consume_optional\n    take_action(action, args, option_string)\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:1935: in take_action\n    action(self, namespace, argument_values, option_string)\npylint/config/callback_actions.py:282: in __call__\n    print(self.run.linter._generate_config_file())\npylint/config/arguments_manager.py:681: in _generate_config_file\n    toml_doc.add(tomlkit.key([\"tool\", \"pylint\"]), pylint_tool_table)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py:116: in add\n    return self.append(key, item)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py:171: in append\n    self._handle_dotted_key(key, item)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py:120: in _handle_dotted_key\n    raise TOMLKitError(\"Can't add a table to a dotted key\")\nE   tomlkit.exceptions.TOMLKitError: Can't add a table to a dotted key\n================== 3 failed, 122 passed, 1 xfailed in 17.99s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_self.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_self.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 123,
          "failed": 2,
          "errors": 0,
          "collected": 126,
          "duration": 21.8,
          "log_tail": "tests/test_self.py::TestCallbackOptions::test_help_msg[args2---help-msg: expected at least one argumen-True] PASSED [ 93%]\ntests/test_self.py::TestCallbackOptions::test_generate_rcfile PASSED     [ 94%]\ntests/test_self.py::TestCallbackOptions::test_generate_config_disable_symbolic_names PASSED [ 95%]\ntests/test_self.py::TestCallbackOptions::test_generate_toml_config FAILED [ 96%]\ntests/test_self.py::TestCallbackOptions::test_generate_toml_config_disable_symbolic_names FAILED [ 96%]\ntests/test_self.py::TestCallbackOptions::test_errors_only PASSED         [ 97%]\ntests/test_self.py::TestCallbackOptions::test_errors_only_functions_as_disable PASSED [ 98%]\ntests/test_self.py::TestCallbackOptions::test_verbose PASSED             [ 99%]\ntests/test_self.py::TestCallbackOptions::test_enable_all_extensions PASSED [100%]\n\n=================================== FAILURES ===================================\n________________ TestCallbackOptions.test_generate_toml_config _________________\ntests/test_self.py:1312: in test_generate_toml_config\n    assert \"[tool.pylint.main]\" in process.stdout\nE   assert '[tool.pylint.main]' in ''\nE    +  where '' = CompletedProcess(args=['/opt/miniconda3/envs/testbed/bin/python', '-m', 'pylint', '--rcfile=/testbed/pylint/testutils/testing_pylintrc', '--preferred-modules=a:b', '--generate-toml-config'], returncode=1, stdout='', stderr='Traceback (most recent call last):\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\\n    return _run_code(code, main_globals, None,\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/runpy.py\", line 87, in _run_code\\n    exec(code, run_globals)\\n  File \"/testbed/pylint/__main__.py\", line 10, in <module>\\n    pylint.run_pylint()\\n  File \"/testbed/pylint/__init__.py\", line 35, in run_pylint\\n    PylintRun(argv or sys.argv[1:])\\n  File \"/testbed/pylint/lint/run.py\", line 161, in __init__\\n    args = _config_initialization(\\n  File \"/testbed/pylint/config/config_initialization.py\", line 73, in _config_initialization\\n    parsed_args_list = linter._parse_command_line_configuration(args_list)\\n  File \"/testbed/pylint/config/arguments_manager.py\", line 271, in _parse_command_line_configuration\\n    self.config, parsed_args = self._arg_parser.parse_known_args(\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/argparse....in _parse_known_args\\n    start_index = consume_optional(start_index)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py\", line 2007, in consume_optional\\n    take_action(action, args, option_string)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py\", line 1935, in take_action\\n    action(self, namespace, argument_values, option_string)\\n  File \"/testbed/pylint/config/callback_actions.py\", line 282, in __call__\\n    print(self.run.linter._generate_config_file())\\n  File \"/testbed/pylint/config/arguments_manager.py\", line 681, in _generate_config_file\\n    toml_doc.add(tomlkit.key([\"tool\", \"pylint\"]), pylint_tool_table)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py\", line 116, in add\\n    return self.append(key, item)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py\", line 171, in append\\n    self._handle_dotted_key(key, item)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py\", line 120, in _handle_dotted_key\\n    raise TOMLKitError(\"Can\\'t add a table to a dotted key\")\\ntomlkit.exceptions.TOMLKitError: Can\\'t add a table to a dotted key\\n').stdout\n_____ TestCallbackOptions.test_generate_toml_config_disable_symbolic_names _____\ntests/test_self.py:1348: in test_generate_toml_config_disable_symbolic_names\n    Run([\"--generate-toml-config\"])\npylint/testutils/_run.py:45: in __init__\n    super().__init__(args, reporter, exit, do_exit)\npylint/lint/run.py:161: in __init__\n    args = _config_initialization(\npylint/config/config_initialization.py:73: in _config_initialization\n    parsed_args_list = linter._parse_command_line_configuration(args_list)\npylint/config/arguments_manager.py:271: in _parse_command_line_configuration\n    self.config, parsed_args = self._arg_parser.parse_known_args(\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:1858: in parse_known_args\n    namespace, args = self._parse_known_args(args, namespace)\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:2067: in _parse_known_args\n    start_index = consume_optional(start_index)\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:2007: in consume_optional\n    take_action(action, args, option_string)\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:1935: in take_action\n    action(self, namespace, argument_values, option_string)\npylint/config/callback_actions.py:282: in __call__\n    print(self.run.linter._generate_config_file())\npylint/config/arguments_manager.py:681: in _generate_config_file\n    toml_doc.add(tomlkit.key([\"tool\", \"pylint\"]), pylint_tool_table)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py:116: in add\n    return self.append(key, item)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py:171: in append\n    self._handle_dotted_key(key, item)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py:120: in _handle_dotted_key\n    raise TOMLKitError(\"Can't add a table to a dotted key\")\nE   tomlkit.exceptions.TOMLKitError: Can't add a table to a dotted key\n================== 2 failed, 123 passed, 1 xfailed in 17.56s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_self.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_self.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "pylint-dev__pylint-8898",
      "repo": "pylint-dev/pylint",
      "valid": false,
      "worker": "http://34.70.1.155:8080",
      "duration": 13.096866130828857,
      "test_only": {
        "passed": true,
        "stats": {
          "passed": 18,
          "failed": 0,
          "errors": 0,
          "collected": 20,
          "duration": 6.35,
          "log_tail": "tests/config/test_config.py::test_unknown_message_id PASSED              [ 10%]\ntests/config/test_config.py::test_unknown_option_name PASSED             [ 15%]\ntests/config/test_config.py::test_unknown_short_option_name PASSED       [ 20%]\ntests/config/test_config.py::test_unknown_confidence PASSED              [ 25%]\ntests/config/test_config.py::test_empty_confidence PASSED                [ 30%]\ntests/config/test_config.py::test_unknown_yes_no PASSED                  [ 35%]\ntests/config/test_config.py::test_unknown_py_version PASSED              [ 40%]\ntests/config/test_config.py::test_csv_regex_comma_in_quantifier[foo-expected0] PASSED [ 45%]\ntests/config/test_config.py::test_csv_regex_comma_in_quantifier[foo,bar-expected1] PASSED [ 50%]\ntests/config/test_config.py::test_csv_regex_comma_in_quantifier[foo, bar-expected2] PASSED [ 55%]\ntests/config/test_config.py::test_csv_regex_comma_in_quantifier[foo, bar{1,3}-expected3] FAILED [ 60%]\ntests/config/test_config.py::test_regex_error PASSED                     [ 65%]\ntests/config/test_config.py::test_csv_regex_error FAILED                 [ 70%]\ntests/config/test_config.py::test_short_verbose PASSED                   [ 75%]\ntests/config/test_config.py::test_argument_separator PASSED              [ 80%]\ntests/config/test_config.py::test_clear_cache_post_run PASSED            [ 85%]\ntests/config/test_config.py::test_enable_all_disable_all_mutually_exclusive PASSED [ 90%]\ntests/config/test_config.py::test_disable_before_enable_all_takes_effect PASSED [ 95%]\ntests/config/test_config.py::test_enable_before_disable_all_takes_effect PASSED [100%]\n\n=================================== FAILURES ===================================\n_________ test_csv_regex_comma_in_quantifier[foo, bar{1,3}-expected3] __________\ntests/config/test_config.py:142: in test_csv_regex_comma_in_quantifier\n    assert _template_run(in_string) == [re.compile(regex) for regex in expected]\nE   AssertionError: assert [re.compile('...compile('3}')] == [re.compile('...e('bar{1,3}')]\nE     At index 1 diff: re.compile('bar{1') != re.compile('bar{1,3}')\nE     Left contains one more item: re.compile('3}')\nE     Full diff:\nE     - [re.compile('foo'), re.compile('bar{1,3}')]\nE     + [re.compile('foo'), re.compile('bar{1'), re.compile('3}')]\nE     ?                                      ++ +++++++++++++\n_____________________________ test_csv_regex_error _____________________________\ntests/config/test_config.py:171: in test_csv_regex_error\n    assert (\nE   AssertionError: assert 'Error in provided regular expression: (foo{1,} beginning at index 0: missing ), unterminated subpattern' in 'usage: pylint [options]\\npylint: error: argument --bad-names-rgxs: Error in provided regular expression: (foo{1 beginning at index 0: missing ), unterminated subpattern\\n'\nE    +  where 'usage: pylint [options]\\npylint: error: argument --bad-names-rgxs: Error in provided regular expression: (foo{1 beginning at index 0: missing ), unterminated subpattern\\n' = CaptureResult(out='', err='usage: pylint [options]\\npylint: error: argument --bad-names-rgxs: Error in provided regular expression: (foo{1 beginning at index 0: missing ), unterminated subpattern\\n').err\n========================= 2 failed, 18 passed in 2.66s =========================\n\n\nError processing line 1 of /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/distutils-precedence.pth:\n\n  Traceback (most recent call last):\n    File \"/opt/miniconda3/envs/testbed/lib/python3.9/site.py\", line 177, in addpackage\n      exec(line)\n    File \"<string>\", line 1, in <module>\n  ModuleNotFoundError: No module named '_distutils_hack'\n\nRemainder of file ignored\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/config/test_config.py` failed. (See above for error)",
          "test_files_run": [
            "tests/config/test_config.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 20,
          "failed": 0,
          "errors": 0,
          "collected": 20,
          "duration": 5.88,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 20 items\n\ntests/config/test_config.py::test_can_read_toml_env_variable PASSED      [  5%]\ntests/config/test_config.py::test_unknown_message_id PASSED              [ 10%]\ntests/config/test_config.py::test_unknown_option_name PASSED             [ 15%]\ntests/config/test_config.py::test_unknown_short_option_name PASSED       [ 20%]\ntests/config/test_config.py::test_unknown_confidence PASSED              [ 25%]\ntests/config/test_config.py::test_empty_confidence PASSED                [ 30%]\ntests/config/test_config.py::test_unknown_yes_no PASSED                  [ 35%]\ntests/config/test_config.py::test_unknown_py_version PASSED              [ 40%]\ntests/config/test_config.py::test_csv_regex_comma_in_quantifier[foo-expected0] PASSED [ 45%]\ntests/config/test_config.py::test_csv_regex_comma_in_quantifier[foo,bar-expected1] PASSED [ 50%]\ntests/config/test_config.py::test_csv_regex_comma_in_quantifier[foo, bar-expected2] PASSED [ 55%]\ntests/config/test_config.py::test_csv_regex_comma_in_quantifier[foo, bar{1,3}-expected3] PASSED [ 60%]\ntests/config/test_config.py::test_regex_error PASSED                     [ 65%]\ntests/config/test_config.py::test_csv_regex_error PASSED                 [ 70%]\ntests/config/test_config.py::test_short_verbose PASSED                   [ 75%]\ntests/config/test_config.py::test_argument_separator PASSED              [ 80%]\ntests/config/test_config.py::test_clear_cache_post_run PASSED            [ 85%]\ntests/config/test_config.py::test_enable_all_disable_all_mutually_exclusive PASSED [ 90%]\ntests/config/test_config.py::test_disable_before_enable_all_takes_effect PASSED [ 95%]\ntests/config/test_config.py::test_enable_before_disable_all_takes_effect PASSED [100%]\n\n============================== 20 passed in 2.49s ==============================\n\n\nError processing line 1 of /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/distutils-precedence.pth:\n\n  Traceback (most recent call last):\n    File \"/opt/miniconda3/envs/testbed/lib/python3.9/site.py\", line 177, in addpackage\n      exec(line)\n    File \"<string>\", line 1, in <module>\n  ModuleNotFoundError: No module named '_distutils_hack'\n\nRemainder of file ignored\n",
          "test_files_run": [
            "tests/config/test_config.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got True\u2192True"
    },
    {
      "instance_id": "pallets__flask-5014",
      "repo": "pallets/flask",
      "valid": true,
      "worker": "http://34.70.1.155:8080",
      "duration": 6.1616740226745605,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 59,
          "failed": 1,
          "errors": 0,
          "collected": 60,
          "duration": 2.75,
          "log_tail": "tests/test_blueprints.py::test_empty_name_not_allowed FAILED             [ 35%]\ntests/test_blueprints.py::test_dotted_names_from_app PASSED              [ 36%]\ntests/test_blueprints.py::test_empty_url_defaults PASSED                 [ 38%]\ntests/test_blueprints.py::test_route_decorator_custom_endpoint PASSED    [ 40%]\ntests/test_blueprints.py::test_route_decorator_custom_endpoint_with_dots PASSED [ 41%]\ntests/test_blueprints.py::test_endpoint_decorator PASSED                 [ 43%]\ntests/test_blueprints.py::test_template_filter PASSED                    [ 45%]\ntests/test_blueprints.py::test_add_template_filter PASSED                [ 46%]\ntests/test_blueprints.py::test_template_filter_with_name PASSED          [ 48%]\ntests/test_blueprints.py::test_add_template_filter_with_name PASSED      [ 50%]\ntests/test_blueprints.py::test_template_filter_with_template PASSED      [ 51%]\ntests/test_blueprints.py::test_template_filter_after_route_with_template PASSED [ 53%]\ntests/test_blueprints.py::test_add_template_filter_with_template PASSED  [ 55%]\ntests/test_blueprints.py::test_template_filter_with_name_and_template PASSED [ 56%]\ntests/test_blueprints.py::test_add_template_filter_with_name_and_template PASSED [ 58%]\ntests/test_blueprints.py::test_template_test PASSED                      [ 60%]\ntests/test_blueprints.py::test_add_template_test PASSED                  [ 61%]\ntests/test_blueprints.py::test_template_test_with_name PASSED            [ 63%]\ntests/test_blueprints.py::test_add_template_test_with_name PASSED        [ 65%]\ntests/test_blueprints.py::test_template_test_with_template PASSED        [ 66%]\ntests/test_blueprints.py::test_template_test_after_route_with_template PASSED [ 68%]\ntests/test_blueprints.py::test_add_template_test_with_template PASSED    [ 70%]\ntests/test_blueprints.py::test_template_test_with_name_and_template PASSED [ 71%]\ntests/test_blueprints.py::test_add_template_test_with_name_and_template PASSED [ 73%]\ntests/test_blueprints.py::test_context_processing PASSED                 [ 75%]\ntests/test_blueprints.py::test_template_global PASSED                    [ 76%]\ntests/test_blueprints.py::test_request_processing PASSED                 [ 78%]\ntests/test_blueprints.py::test_app_request_processing PASSED             [ 80%]\ntests/test_blueprints.py::test_app_url_processors PASSED                 [ 81%]\ntests/test_blueprints.py::test_nested_blueprint PASSED                   [ 83%]\ntests/test_blueprints.py::test_nested_callback_order PASSED              [ 85%]\ntests/test_blueprints.py::test_nesting_url_prefixes[/parent-/child-None-None] PASSED [ 86%]\ntests/test_blueprints.py::test_nesting_url_prefixes[/parent-None-None-/child] PASSED [ 88%]\ntests/test_blueprints.py::test_nesting_url_prefixes[None-None-/parent-/child] PASSED [ 90%]\ntests/test_blueprints.py::test_nesting_url_prefixes[/other-/something-/parent-/child] PASSED [ 91%]\ntests/test_blueprints.py::test_nesting_subdomains PASSED                 [ 93%]\ntests/test_blueprints.py::test_child_and_parent_subdomain PASSED         [ 95%]\ntests/test_blueprints.py::test_unique_blueprint_names PASSED             [ 96%]\ntests/test_blueprints.py::test_self_registration PASSED                  [ 98%]\ntests/test_blueprints.py::test_blueprint_renaming PASSED                 [100%]\n\n=================================== FAILURES ===================================\n_________________________ test_empty_name_not_allowed __________________________\ntests/test_blueprints.py:260: in test_empty_name_not_allowed\n    with pytest.raises(ValueError):\nE   Failed: DID NOT RAISE <class 'ValueError'>\n========================= 1 failed, 59 passed in 0.29s =========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_blueprints.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_blueprints.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 60,
          "failed": 0,
          "errors": 0,
          "collected": 60,
          "duration": 2.56,
          "log_tail": "tests/test_blueprints.py::test_blueprint_url_defaults PASSED             [ 25%]\ntests/test_blueprints.py::test_blueprint_url_processors PASSED           [ 26%]\ntests/test_blueprints.py::test_templates_and_static PASSED               [ 28%]\ntests/test_blueprints.py::test_default_static_max_age PASSED             [ 30%]\ntests/test_blueprints.py::test_templates_list PASSED                     [ 31%]\ntests/test_blueprints.py::test_dotted_name_not_allowed PASSED            [ 33%]\ntests/test_blueprints.py::test_empty_name_not_allowed PASSED             [ 35%]\ntests/test_blueprints.py::test_dotted_names_from_app PASSED              [ 36%]\ntests/test_blueprints.py::test_empty_url_defaults PASSED                 [ 38%]\ntests/test_blueprints.py::test_route_decorator_custom_endpoint PASSED    [ 40%]\ntests/test_blueprints.py::test_route_decorator_custom_endpoint_with_dots PASSED [ 41%]\ntests/test_blueprints.py::test_endpoint_decorator PASSED                 [ 43%]\ntests/test_blueprints.py::test_template_filter PASSED                    [ 45%]\ntests/test_blueprints.py::test_add_template_filter PASSED                [ 46%]\ntests/test_blueprints.py::test_template_filter_with_name PASSED          [ 48%]\ntests/test_blueprints.py::test_add_template_filter_with_name PASSED      [ 50%]\ntests/test_blueprints.py::test_template_filter_with_template PASSED      [ 51%]\ntests/test_blueprints.py::test_template_filter_after_route_with_template PASSED [ 53%]\ntests/test_blueprints.py::test_add_template_filter_with_template PASSED  [ 55%]\ntests/test_blueprints.py::test_template_filter_with_name_and_template PASSED [ 56%]\ntests/test_blueprints.py::test_add_template_filter_with_name_and_template PASSED [ 58%]\ntests/test_blueprints.py::test_template_test PASSED                      [ 60%]\ntests/test_blueprints.py::test_add_template_test PASSED                  [ 61%]\ntests/test_blueprints.py::test_template_test_with_name PASSED            [ 63%]\ntests/test_blueprints.py::test_add_template_test_with_name PASSED        [ 65%]\ntests/test_blueprints.py::test_template_test_with_template PASSED        [ 66%]\ntests/test_blueprints.py::test_template_test_after_route_with_template PASSED [ 68%]\ntests/test_blueprints.py::test_add_template_test_with_template PASSED    [ 70%]\ntests/test_blueprints.py::test_template_test_with_name_and_template PASSED [ 71%]\ntests/test_blueprints.py::test_add_template_test_with_name_and_template PASSED [ 73%]\ntests/test_blueprints.py::test_context_processing PASSED                 [ 75%]\ntests/test_blueprints.py::test_template_global PASSED                    [ 76%]\ntests/test_blueprints.py::test_request_processing PASSED                 [ 78%]\ntests/test_blueprints.py::test_app_request_processing PASSED             [ 80%]\ntests/test_blueprints.py::test_app_url_processors PASSED                 [ 81%]\ntests/test_blueprints.py::test_nested_blueprint PASSED                   [ 83%]\ntests/test_blueprints.py::test_nested_callback_order PASSED              [ 85%]\ntests/test_blueprints.py::test_nesting_url_prefixes[/parent-/child-None-None] PASSED [ 86%]\ntests/test_blueprints.py::test_nesting_url_prefixes[/parent-None-None-/child] PASSED [ 88%]\ntests/test_blueprints.py::test_nesting_url_prefixes[None-None-/parent-/child] PASSED [ 90%]\ntests/test_blueprints.py::test_nesting_url_prefixes[/other-/something-/parent-/child] PASSED [ 91%]\ntests/test_blueprints.py::test_nesting_subdomains PASSED                 [ 93%]\ntests/test_blueprints.py::test_child_and_parent_subdomain PASSED         [ 95%]\ntests/test_blueprints.py::test_unique_blueprint_names PASSED             [ 96%]\ntests/test_blueprints.py::test_self_registration PASSED                  [ 98%]\ntests/test_blueprints.py::test_blueprint_renaming PASSED                 [100%]\n\n============================== 60 passed in 0.25s ==============================\n\n",
          "test_files_run": [
            "tests/test_blueprints.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-11138",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.241.183:8080",
      "duration": 10.390738010406494,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 80,
          "failed": 4,
          "errors": 0,
          "duration": 4.81,
          "log_tail": "AssertionError: datet[38 chars]zinfo=<UTC>) != datet[38 chars]zinfo=datetime.timezone(datetime.timedelta(0, 25200), '+0700'))\n\n======================================================================\nFAIL: test_aware_datetime_with_microsecond (timezones.tests.SerializationTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/timezones/tests.py\", line 710, in test_aware_datetime_with_microsecond\n    self.assertEqual(obj.dt.replace(tzinfo=UTC), dt)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 822, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: datet[46 chars]zinfo=<UTC>) != datet[46 chars]zinfo=datetime.timezone(datetime.timedelta(0, 25200), '+0700'))\n\n======================================================================\nFAIL: test_query_convert_timezones (timezones.tests.NewDatabaseTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/timezones/tests.py\", line 340, in test_query_convert_timezones\n    self.assertEqual(Event.objects.filter(dt__date=event_datetime.date()).first(), event)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 822, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: None != <Event: Event object (1)>\n\n----------------------------------------------------------------------\nRan 84 tests in 0.307s\n\nFAILED (failures=4, skipped=8)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 timezones.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/timezones/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 81,
          "failed": 3,
          "errors": 0,
          "duration": 4.69,
          "log_tail": "AssertionError: datet[38 chars]zinfo=<UTC>) != datet[38 chars]zinfo=datetime.timezone(datetime.timedelta(0, 10800), '+0300'))\n\n======================================================================\nFAIL: test_aware_datetime_in_other_timezone (timezones.tests.SerializationTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/timezones/tests.py\", line 782, in test_aware_datetime_in_other_timezone\n    self.assertEqual(obj.dt.replace(tzinfo=UTC), dt)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 822, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: datet[38 chars]zinfo=<UTC>) != datet[38 chars]zinfo=datetime.timezone(datetime.timedelta(0, 25200), '+0700'))\n\n======================================================================\nFAIL: test_aware_datetime_with_microsecond (timezones.tests.SerializationTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/timezones/tests.py\", line 710, in test_aware_datetime_with_microsecond\n    self.assertEqual(obj.dt.replace(tzinfo=UTC), dt)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 822, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: datet[46 chars]zinfo=<UTC>) != datet[46 chars]zinfo=datetime.timezone(datetime.timedelta(0, 25200), '+0700'))\n\n----------------------------------------------------------------------\nRan 84 tests in 0.310s\n\nFAILED (failures=3, skipped=8)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 timezones.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/timezones/tests.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "django__django-11848",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.59.30.169:8080",
      "duration": 11.131076097488403,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 44,
          "failed": 1,
          "errors": 0,
          "duration": 5.97,
          "log_tail": "test_dict_containing_sequence_not_doseq (utils_tests.test_http.URLEncodeTests) ... ok\ntest_dict_containing_tuple_not_doseq (utils_tests.test_http.URLEncodeTests) ... ok\ntest_dict_with_bytearray (utils_tests.test_http.URLEncodeTests) ... ok\ntest_dict_with_bytes_values (utils_tests.test_http.URLEncodeTests) ... ok\ntest_dict_with_sequence_of_bytes (utils_tests.test_http.URLEncodeTests) ... ok\ntest_generator (utils_tests.test_http.URLEncodeTests) ... ok\ntest_multivaluedict (utils_tests.test_http.URLEncodeTests) ... ok\ntest_none (utils_tests.test_http.URLEncodeTests) ... ok\ntest_none_in_generator (utils_tests.test_http.URLEncodeTests) ... ok\ntest_none_in_sequence (utils_tests.test_http.URLEncodeTests) ... ok\ntest_tuples (utils_tests.test_http.URLEncodeTests) ... ok\ntest_quote (utils_tests.test_http.URLQuoteTests) ... ok\ntest_quote_plus (utils_tests.test_http.URLQuoteTests) ... ok\ntest_unquote (utils_tests.test_http.URLQuoteTests) ... ok\ntest_unquote_plus (utils_tests.test_http.URLQuoteTests) ... ok\ntest_http_date (utils_tests.test_http.HttpDateProcessingTests) ... ok\ntest_parsing_asctime (utils_tests.test_http.HttpDateProcessingTests) ... ok\ntest_parsing_rfc1123 (utils_tests.test_http.HttpDateProcessingTests) ... ok\ntest_parsing_rfc850 (utils_tests.test_http.HttpDateProcessingTests) ... test_parsing_year_less_than_70 (utils_tests.test_http.HttpDateProcessingTests) ... ok\ntest_allowed_hosts_str (utils_tests.test_http.IsSafeURLTests) ... ok\ntest_bad_urls (utils_tests.test_http.IsSafeURLTests) ... ok\ntest_basic_auth (utils_tests.test_http.IsSafeURLTests) ... ok\ntest_good_urls (utils_tests.test_http.IsSafeURLTests) ... ok\ntest_is_safe_url_deprecated (utils_tests.test_http.IsSafeURLTests) ... ok\ntest_no_allowed_hosts (utils_tests.test_http.IsSafeURLTests) ... ok\ntest_secure_param_https_urls (utils_tests.test_http.IsSafeURLTests) ... ok\ntest_secure_param_non_https_urls (utils_tests.test_http.IsSafeURLTests) ... ok\n\n======================================================================\nFAIL: test_parsing_rfc850 (utils_tests.test_http.HttpDateProcessingTests) [<object object at 0x7a72cb500ac0>] (rfc850str='Wednesday, 31-Dec-70 08:49:37 GMT')\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 523, in subTest\n    yield\n  File \"/testbed/tests/utils_tests/test_http.py\", line 340, in test_parsing_rfc850\n    self.assertEqual(datetime.utcfromtimestamp(parsed), expected_date)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 822, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: datetime.datetime(1970, 12, 31, 8, 49, 37) != datetime.datetime(2070, 12, 31, 8, 49, 37)\n\n----------------------------------------------------------------------\nRan 45 tests in 0.201s\n\nFAILED (failures=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 utils_tests.test_http` failed. (See above for error)",
          "test_files_run": [
            "tests/utils_tests/test_http.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 45,
          "failed": 0,
          "errors": 0,
          "duration": 4.34,
          "log_tail": "test_quoting (utils_tests.test_http.ETagProcessingTests) ... ok\ntest (utils_tests.test_http.EscapeLeadingSlashesTests) ... ok\ntest_input_too_large (utils_tests.test_http.Base36IntTests) ... ok\ntest_invalid_literal (utils_tests.test_http.Base36IntTests) ... ok\ntest_negative_input (utils_tests.test_http.Base36IntTests) ... ok\ntest_roundtrip (utils_tests.test_http.Base36IntTests) ... ok\ntest_to_base36_errors (utils_tests.test_http.Base36IntTests) ... ok\ntest_to_int_errors (utils_tests.test_http.Base36IntTests) ... ok\ntest_values (utils_tests.test_http.Base36IntTests) ... ok\ntest_roundtrip (utils_tests.test_http.URLSafeBase64Tests) ... ok\ntest_bad (utils_tests.test_http.IsSameDomainTests) ... ok\ntest_good (utils_tests.test_http.IsSameDomainTests) ... ok\ntest_custom_iterable_not_doseq (utils_tests.test_http.URLEncodeTests) ... ok\ntest_dict (utils_tests.test_http.URLEncodeTests) ... ok\ntest_dict_containing_empty_sequence_doseq (utils_tests.test_http.URLEncodeTests) ... ok\ntest_dict_containing_sequence_doseq (utils_tests.test_http.URLEncodeTests) ... ok\ntest_dict_containing_sequence_not_doseq (utils_tests.test_http.URLEncodeTests) ... ok\ntest_dict_containing_tuple_not_doseq (utils_tests.test_http.URLEncodeTests) ... ok\ntest_dict_with_bytearray (utils_tests.test_http.URLEncodeTests) ... ok\ntest_dict_with_bytes_values (utils_tests.test_http.URLEncodeTests) ... ok\ntest_dict_with_sequence_of_bytes (utils_tests.test_http.URLEncodeTests) ... ok\ntest_generator (utils_tests.test_http.URLEncodeTests) ... ok\ntest_multivaluedict (utils_tests.test_http.URLEncodeTests) ... ok\ntest_none (utils_tests.test_http.URLEncodeTests) ... ok\ntest_none_in_generator (utils_tests.test_http.URLEncodeTests) ... ok\ntest_none_in_sequence (utils_tests.test_http.URLEncodeTests) ... ok\ntest_tuples (utils_tests.test_http.URLEncodeTests) ... ok\ntest_quote (utils_tests.test_http.URLQuoteTests) ... ok\ntest_quote_plus (utils_tests.test_http.URLQuoteTests) ... ok\ntest_unquote (utils_tests.test_http.URLQuoteTests) ... ok\ntest_unquote_plus (utils_tests.test_http.URLQuoteTests) ... ok\ntest_http_date (utils_tests.test_http.HttpDateProcessingTests) ... ok\ntest_parsing_asctime (utils_tests.test_http.HttpDateProcessingTests) ... ok\ntest_parsing_rfc1123 (utils_tests.test_http.HttpDateProcessingTests) ... ok\ntest_parsing_rfc850 (utils_tests.test_http.HttpDateProcessingTests) ... ok\ntest_parsing_year_less_than_70 (utils_tests.test_http.HttpDateProcessingTests) ... ok\ntest_allowed_hosts_str (utils_tests.test_http.IsSafeURLTests) ... ok\ntest_bad_urls (utils_tests.test_http.IsSafeURLTests) ... ok\ntest_basic_auth (utils_tests.test_http.IsSafeURLTests) ... ok\ntest_good_urls (utils_tests.test_http.IsSafeURLTests) ... ok\ntest_is_safe_url_deprecated (utils_tests.test_http.IsSafeURLTests) ... ok\ntest_no_allowed_hosts (utils_tests.test_http.IsSafeURLTests) ... ok\ntest_secure_param_https_urls (utils_tests.test_http.IsSafeURLTests) ... ok\ntest_secure_param_non_https_urls (utils_tests.test_http.IsSafeURLTests) ... ok\n\n----------------------------------------------------------------------\nRan 45 tests in 0.198s\n\nOK\n",
          "test_files_run": [
            "tests/utils_tests/test_http.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-11815",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.70.1.155:8080",
      "duration": 11.19571590423584,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 44,
          "failed": 2,
          "errors": 0,
          "duration": 6.02,
          "log_tail": "    self.assertEqual(string, \"django.core.validators.RegexValidator('^[0-9]+$', flags=re.RegexFlag['DOTALL'])\")\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1203, in assertMultiLineEqual\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: \"djan[13 chars]ators.RegexValidator('^[0-9]+$', flags=re.RegexFlag(16))\" != \"djan[13 chars]ators.RegexValidator('^[0-9]+$', flags=re.RegexFlag['DOTALL'])\"\n- django.core.validators.RegexValidator('^[0-9]+$', flags=re.RegexFlag(16))\n?                                                                     ^^^^\n+ django.core.validators.RegexValidator('^[0-9]+$', flags=re.RegexFlag['DOTALL'])\n?                                                                     ^^^^^^^^^^\n\n\n======================================================================\nFAIL: test_serialize_enums (migrations.test_writer.WriterTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/migrations/test_writer.py\", line 274, in test_serialize_enums\n    (\"migrations.test_writer.TextEnum['A']\", {'import migrations.test_writer'})\n  File \"/testbed/tests/migrations/test_writer.py\", line 187, in assertSerializedResultEqual\n    self.assertEqual(MigrationWriter.serialize(value), target)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1039, in assertTupleEqual\n    self.assertSequenceEqual(tuple1, tuple2, msg, seq_type=tuple)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1010, in assertSequenceEqual\n    self.fail(msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: Tuples differ: (\"mig[13 chars]writer.TextEnum('a-value')\", {'import migrations.test_writer'}) != (\"mig[13 chars]writer.TextEnum['A']\", {'import migrations.test_writer'})\n\nFirst differing element 0:\n\"migrations.test_writer.TextEnum('a-value')\"\n\"migrations.test_writer.TextEnum['A']\"\n\n+ (\"migrations.test_writer.TextEnum['A']\", {'import migrations.test_writer'})\n- (\"migrations.test_writer.TextEnum('a-value')\",\n-  {'import migrations.test_writer'})\n\n----------------------------------------------------------------------\nRan 46 tests in 0.198s\n\nFAILED (failures=2)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 migrations.test_writer` failed. (See above for error)",
          "test_files_run": [
            "tests/migrations/test_writer.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 46,
          "failed": 0,
          "errors": 0,
          "duration": 4.34,
          "log_tail": "test_kwargs_signature (migrations.test_writer.OperationWriterTests) ... ok\ntest_multiline_args_signature (migrations.test_writer.OperationWriterTests) ... ok\ntest_nested_args_signature (migrations.test_writer.OperationWriterTests) ... ok\ntest_nested_operation_expand_args_signature (migrations.test_writer.OperationWriterTests) ... ok\ntest_custom_operation (migrations.test_writer.WriterTests) ... ok\ntest_deconstruct_class_arguments (migrations.test_writer.WriterTests) ... ok\ntest_migration_file_header_comments (migrations.test_writer.WriterTests) ... ok\ntest_migration_path (migrations.test_writer.WriterTests) ... ok\ntest_models_import_omitted (migrations.test_writer.WriterTests) ... ok\ntest_register_non_serializer (migrations.test_writer.WriterTests) ... ok\ntest_register_serializer (migrations.test_writer.WriterTests) ... ok\ntest_serialize_builtin_types (migrations.test_writer.WriterTests) ... ok\ntest_serialize_builtins (migrations.test_writer.WriterTests) ... ok\ntest_serialize_choices (migrations.test_writer.WriterTests) ... ok\ntest_serialize_class_based_validators (migrations.test_writer.WriterTests) ... ok\ntest_serialize_collections (migrations.test_writer.WriterTests) ... ok\ntest_serialize_compiled_regex (migrations.test_writer.WriterTests) ... ok\ntest_serialize_constants (migrations.test_writer.WriterTests) ... ok\ntest_serialize_datetime (migrations.test_writer.WriterTests) ... ok\ntest_serialize_empty_nonempty_tuple (migrations.test_writer.WriterTests) ... ok\ntest_serialize_enums (migrations.test_writer.WriterTests) ... ok\ntest_serialize_fields (migrations.test_writer.WriterTests) ... ok\ntest_serialize_frozensets (migrations.test_writer.WriterTests) ... ok\ntest_serialize_functions (migrations.test_writer.WriterTests) ... ok\ntest_serialize_functools_partial (migrations.test_writer.WriterTests) ... ok\ntest_serialize_functools_partialmethod (migrations.test_writer.WriterTests) ... ok\ntest_serialize_iterators (migrations.test_writer.WriterTests) ... ok\ntest_serialize_lazy_objects (migrations.test_writer.WriterTests) ... ok\ntest_serialize_local_function_reference (migrations.test_writer.WriterTests)\nA reference in a local scope can't be serialized. ... ok\ntest_serialize_managers (migrations.test_writer.WriterTests) ... ok\ntest_serialize_multiline_strings (migrations.test_writer.WriterTests) ... ok\ntest_serialize_numbers (migrations.test_writer.WriterTests) ... ok\ntest_serialize_range (migrations.test_writer.WriterTests) ... ok\ntest_serialize_set (migrations.test_writer.WriterTests) ... ok\ntest_serialize_settings (migrations.test_writer.WriterTests) ... ok\ntest_serialize_strings (migrations.test_writer.WriterTests) ... ok\ntest_serialize_timedelta (migrations.test_writer.WriterTests) ... ok\ntest_serialize_type_none (migrations.test_writer.WriterTests) ... ok\ntest_serialize_unbound_method_reference (migrations.test_writer.WriterTests)\nAn unbound method used within a class body can be serialized. ... ok\ntest_serialize_uuid (migrations.test_writer.WriterTests) ... ok\ntest_simple_migration (migrations.test_writer.WriterTests) ... ok\ntest_sorted_imports (migrations.test_writer.WriterTests) ... ok\n\n----------------------------------------------------------------------\nRan 46 tests in 0.196s\n\nOK\n",
          "test_files_run": [
            "tests/migrations/test_writer.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-11790",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 12.965265989303589,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 77,
          "failed": 2,
          "errors": 0,
          "duration": 7.0,
          "log_tail": "FAIL: test_username_field_max_length_defaults_to_254 (auth_tests.test_forms.AuthenticationFormTest)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/django/test/utils.py\", line 370, in inner\n    return func(*args, **kwargs)\n  File \"/testbed/tests/auth_tests/test_forms.py\", line 439, in test_username_field_max_length_defaults_to_254\n    self.assertEqual(form.fields['username'].widget.attrs.get('maxlength'), 254)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 822, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: None != 254\n\n======================================================================\nFAIL: test_username_field_max_length_matches_user_model (auth_tests.test_forms.AuthenticationFormTest)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/django/test/utils.py\", line 370, in inner\n    return func(*args, **kwargs)\n  File \"/testbed/tests/auth_tests/test_forms.py\", line 426, in test_username_field_max_length_matches_user_model\n    self.assertEqual(form.fields['username'].widget.attrs.get('maxlength'), 255)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 822, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: None != 255\n\n----------------------------------------------------------------------\nRan 79 tests in 0.311s\n\nFAILED (failures=2)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 auth_tests.test_forms` failed. (See above for error)",
          "test_files_run": [
            "tests/auth_tests/test_forms.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 79,
          "failed": 0,
          "errors": 0,
          "duration": 4.92,
          "log_tail": "test_invalid_username (auth_tests.test_forms.AuthenticationFormTest) ... ok\ntest_login_failed (auth_tests.test_forms.AuthenticationFormTest) ... ok\ntest_password_whitespace_not_stripped (auth_tests.test_forms.AuthenticationFormTest) ... ok\ntest_success (auth_tests.test_forms.AuthenticationFormTest) ... ok\ntest_unicode_username (auth_tests.test_forms.AuthenticationFormTest) ... ok\ntest_username_field_autocapitalize_none (auth_tests.test_forms.AuthenticationFormTest) ... ok\ntest_username_field_label (auth_tests.test_forms.AuthenticationFormTest) ... ok\ntest_username_field_label_empty_string (auth_tests.test_forms.AuthenticationFormTest) ... ok\ntest_username_field_label_not_set (auth_tests.test_forms.AuthenticationFormTest) ... ok\ntest_username_field_max_length_defaults_to_254 (auth_tests.test_forms.AuthenticationFormTest) ... ok\ntest_username_field_max_length_matches_user_model (auth_tests.test_forms.AuthenticationFormTest) ... ok\ntest_cleaned_data (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_custom_email_constructor (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_custom_email_field (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_custom_email_subject (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_html_autocomplete_attributes (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_inactive_user (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_invalid_email (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_nonexistent_email (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_preserve_username_case (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_save_html_email_template_name (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_save_plaintext_email (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_unusable_password (auth_tests.test_forms.PasswordResetFormTest) ... ok\ntest_bug_14242 (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_bug_17944_empty_password (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_bug_17944_unknown_password_algorithm (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_bug_17944_unmanageable_password (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_bug_19133 (auth_tests.test_forms.UserChangeFormTest)\nThe change form does not return the password value ... ok\ntest_bug_19349_bound_password_field (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_custom_form (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_password_excluded (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_unusable_password (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_username_field_autocapitalize_none (auth_tests.test_forms.UserChangeFormTest) ... ok\ntest_username_validity (auth_tests.test_forms.UserChangeFormTest) ... ok\n\n----------------------------------------------------------------------\nRan 79 tests in 0.307s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/auth_tests/test_forms.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-11149",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 13.111768245697021,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 52,
          "failed": 2,
          "errors": 0,
          "duration": 6.17,
          "log_tail": "test_tabular_inline_show_change_link_false_registered (admin_inlines.tests.TestInline)\nInlines `show_change_link` disabled by default. ... ok\ntest_tabular_model_form_meta_readonly_field (admin_inlines.tests.TestInline) ... ok\ntest_tabular_non_field_errors (admin_inlines.tests.TestInline) ... ok\n\n======================================================================\nFAIL: test_inline_add_m2m_view_only_perm (admin_inlines.tests.TestInlinePermissions)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/admin_inlines/tests.py\", line 646, in test_inline_add_m2m_view_only_perm\n    self.assertIs(response.context['inline_admin_formset'].has_add_permission, False)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1103, in assertIs\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: True is not False\n\n======================================================================\nFAIL: test_inline_change_m2m_view_only_perm (admin_inlines.tests.TestInlinePermissions)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/admin_inlines/tests.py\", line 693, in test_inline_change_m2m_view_only_perm\n    self.assertIs(response.context['inline_admin_formset'].has_add_permission, False)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1103, in assertIs\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: True is not False\n\n----------------------------------------------------------------------\nRan 54 tests in 1.512s\n\nFAILED (failures=2, skipped=6)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 admin_inlines.models admin_inlines.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/admin_inlines/models.py",
            "tests/admin_inlines/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 54,
          "failed": 0,
          "errors": 0,
          "duration": 6.03,
          "log_tail": "test_callable_lookup (admin_inlines.tests.TestInline)\nAdmin inline should invoke local callable when its name is listed in readonly_fields ... ok\ntest_can_delete (admin_inlines.tests.TestInline) ... ok\ntest_create_inlines_on_inherited_model (admin_inlines.tests.TestInline) ... ok\ntest_custom_form_tabular_inline_label (admin_inlines.tests.TestInline) ... ok\ntest_custom_form_tabular_inline_overridden_label (admin_inlines.tests.TestInline) ... ok\ntest_custom_get_extra_form (admin_inlines.tests.TestInline) ... ok\ntest_custom_min_num (admin_inlines.tests.TestInline) ... ok\ntest_custom_pk_shortcut (admin_inlines.tests.TestInline) ... ok\ntest_help_text (admin_inlines.tests.TestInline) ... ok\ntest_inline_editable_pk (admin_inlines.tests.TestInline) ... ok\ntest_inline_hidden_field_no_column (admin_inlines.tests.TestInline)\n#18263 -- Make sure hidden fields don't get a column in tabular inlines ... ok\ntest_inline_nonauto_noneditable_inherited_pk (admin_inlines.tests.TestInline) ... ok\ntest_inline_nonauto_noneditable_pk (admin_inlines.tests.TestInline) ... ok\ntest_inline_primary (admin_inlines.tests.TestInline) ... ok\ntest_inlines_show_change_link_registered (admin_inlines.tests.TestInline)\nInlines `show_change_link` for registered models when enabled. ... ok\ntest_inlines_show_change_link_unregistered (admin_inlines.tests.TestInline)\nInlines `show_change_link` disabled for unregistered models. ... ok\ntest_localize_pk_shortcut (admin_inlines.tests.TestInline) ... ok\ntest_many_to_many_inlines (admin_inlines.tests.TestInline)\nAutogenerated many-to-many inlines are displayed correctly (#13407) ... ok\ntest_min_num (admin_inlines.tests.TestInline) ... ok\ntest_no_parent_callable_lookup (admin_inlines.tests.TestInline)\nAdmin inline `readonly_field` shouldn't invoke parent ModelAdmin callable ... ok\ntest_non_related_name_inline (admin_inlines.tests.TestInline) ... ok\ntest_noneditable_inline_has_field_inputs (admin_inlines.tests.TestInline)\nInlines without change permission shows field inputs on add form. ... ok\ntest_readonly_stacked_inline_label (admin_inlines.tests.TestInline)\nBug #13174. ... ok\ntest_stacked_inline_edit_form_contains_has_original_class (admin_inlines.tests.TestInline) ... ok\ntest_tabular_inline_column_css_class (admin_inlines.tests.TestInline) ... ok\ntest_tabular_inline_show_change_link_false_registered (admin_inlines.tests.TestInline)\nInlines `show_change_link` disabled by default. ... ok\ntest_tabular_model_form_meta_readonly_field (admin_inlines.tests.TestInline) ... ok\ntest_tabular_non_field_errors (admin_inlines.tests.TestInline) ... ok\n\n----------------------------------------------------------------------\nRan 54 tests in 1.512s\n\nOK (skipped=6)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/admin_inlines/models.py",
            "tests/admin_inlines/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-11299",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 15.745583057403564,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 104,
          "failed": 1,
          "errors": 0,
          "duration": 8.55,
          "log_tail": "test_rename_model_with_self_referential_fk (migrations.test_operations.OperationTests) ... ok\ntest_rename_model_with_self_referential_m2m (migrations.test_operations.OperationTests) ... ok\ntest_rename_model_with_superclass_fk (migrations.test_operations.OperationTests) ... ok\ntest_rename_referenced_field_state_forward (migrations.test_operations.OperationTests) ... ok\ntest_repoint_field_m2m (migrations.test_operations.OperationTests) ... ok\ntest_run_python (migrations.test_operations.OperationTests) ... ok\ntest_run_python_atomic (migrations.test_operations.OperationTests) ... ok\ntest_run_python_noop (migrations.test_operations.OperationTests) ... ok\ntest_run_python_related_assignment (migrations.test_operations.OperationTests) ... ok\ntest_run_sql (migrations.test_operations.OperationTests) ... ok\ntest_run_sql_noop (migrations.test_operations.OperationTests) ... ok\ntest_run_sql_params (migrations.test_operations.OperationTests) ... ok\ntest_run_sql_params_invalid (migrations.test_operations.OperationTests) ... ok\ntest_separate_database_and_state (migrations.test_operations.OperationTests) ... ok\ntest_separate_database_and_state2 (migrations.test_operations.OperationTests) ... ok\n\n======================================================================\nFAIL: test_simplecol_query (queries.test_query.TestQuery)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/queries/test_query.py\", line 32, in test_simplecol_query\n    self.assertIsInstance(num_gt_lookup.lhs, SimpleCol)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1246, in assertIsInstance\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: Col(queries_author, queries.Author.num) is not an instance of <class 'django.db.models.expressions.SimpleCol'>\n\n----------------------------------------------------------------------\nRan 105 tests in 1.215s\n\nFAILED (failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 migrations.test_operations queries.test_query` failed. (See above for error)",
          "test_files_run": [
            "tests/migrations/test_operations.py",
            "tests/queries/test_query.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 105,
          "failed": 0,
          "errors": 0,
          "duration": 6.33,
          "log_tail": "test_remove_field (migrations.test_operations.OperationTests) ... ok\ntest_remove_field_m2m (migrations.test_operations.OperationTests) ... ok\ntest_remove_field_m2m_with_through (migrations.test_operations.OperationTests) ... ok\ntest_remove_fk (migrations.test_operations.OperationTests) ... ok\ntest_remove_index (migrations.test_operations.OperationTests) ... ok\ntest_remove_index_state_forwards (migrations.test_operations.OperationTests) ... ok\ntest_remove_partial_unique_constraint (migrations.test_operations.OperationTests) ... ok\ntest_rename_field (migrations.test_operations.OperationTests) ... ok\ntest_rename_field_reloads_state_on_fk_target_changes (migrations.test_operations.OperationTests) ... ok\ntest_rename_m2m_model_after_rename_field (migrations.test_operations.OperationTests)\nRenameModel renames a many-to-many column after a RenameField. ... ok\ntest_rename_m2m_target_model (migrations.test_operations.OperationTests) ... ok\ntest_rename_m2m_through_model (migrations.test_operations.OperationTests) ... ok\ntest_rename_missing_field (migrations.test_operations.OperationTests) ... ok\ntest_rename_model (migrations.test_operations.OperationTests) ... ok\ntest_rename_model_state_forwards (migrations.test_operations.OperationTests) ... ok\ntest_rename_model_with_m2m (migrations.test_operations.OperationTests) ... ok\ntest_rename_model_with_self_referential_fk (migrations.test_operations.OperationTests) ... ok\ntest_rename_model_with_self_referential_m2m (migrations.test_operations.OperationTests) ... ok\ntest_rename_model_with_superclass_fk (migrations.test_operations.OperationTests) ... ok\ntest_rename_referenced_field_state_forward (migrations.test_operations.OperationTests) ... ok\ntest_repoint_field_m2m (migrations.test_operations.OperationTests) ... ok\ntest_run_python (migrations.test_operations.OperationTests) ... ok\ntest_run_python_atomic (migrations.test_operations.OperationTests) ... ok\ntest_run_python_noop (migrations.test_operations.OperationTests) ... ok\ntest_run_python_related_assignment (migrations.test_operations.OperationTests) ... ok\ntest_run_sql (migrations.test_operations.OperationTests) ... ok\ntest_run_sql_noop (migrations.test_operations.OperationTests) ... ok\ntest_run_sql_params (migrations.test_operations.OperationTests) ... ok\ntest_run_sql_params_invalid (migrations.test_operations.OperationTests) ... ok\ntest_separate_database_and_state (migrations.test_operations.OperationTests) ... ok\ntest_separate_database_and_state2 (migrations.test_operations.OperationTests) ... ok\n\n----------------------------------------------------------------------\nRan 105 tests in 1.216s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/migrations/test_operations.py",
            "tests/queries/test_query.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-12193",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 12.130225896835327,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 121,
          "failed": 1,
          "errors": 0,
          "duration": 6.72,
          "log_tail": "test_with_validators (postgres_tests.test_array.TestValidation) ... skipped 'PostgreSQL specific tests'\ntest_get_context_does_not_mutate_attrs (forms_tests.widget_tests.test_checkboxinput.CheckboxInputTest) ... FAIL\ntest_render_check_exception (forms_tests.widget_tests.test_checkboxinput.CheckboxInputTest) ... ok\ntest_render_check_test (forms_tests.widget_tests.test_checkboxinput.CheckboxInputTest) ... ok\ntest_render_empty (forms_tests.widget_tests.test_checkboxinput.CheckboxInputTest) ... ok\ntest_render_false (forms_tests.widget_tests.test_checkboxinput.CheckboxInputTest) ... ok\ntest_render_int (forms_tests.widget_tests.test_checkboxinput.CheckboxInputTest) ... ok\ntest_render_none (forms_tests.widget_tests.test_checkboxinput.CheckboxInputTest) ... ok\ntest_render_true (forms_tests.widget_tests.test_checkboxinput.CheckboxInputTest) ... ok\ntest_render_value (forms_tests.widget_tests.test_checkboxinput.CheckboxInputTest) ... ok\ntest_value_from_datadict (forms_tests.widget_tests.test_checkboxinput.CheckboxInputTest) ... ok\ntest_value_from_datadict_string_int (forms_tests.widget_tests.test_checkboxinput.CheckboxInputTest) ... ok\ntest_value_omitted_from_data (forms_tests.widget_tests.test_checkboxinput.CheckboxInputTest) ... ok\n\n======================================================================\nFAIL: test_get_context_does_not_mutate_attrs (forms_tests.widget_tests.test_checkboxinput.CheckboxInputTest)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/forms_tests/widget_tests/test_checkboxinput.py\", line 96, in test_get_context_does_not_mutate_attrs\n    self.assertIs(attrs['checked'], False)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1103, in assertIs\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: True is not False\n\n----------------------------------------------------------------------\nRan 122 tests in 0.210s\n\nFAILED (failures=1, skipped=110)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 forms_tests.widget_tests.test_checkboxinput postgres_tests.test_array` failed. (See above for error)",
          "test_files_run": [
            "tests/forms_tests/widget_tests/test_checkboxinput.py",
            "tests/postgres_tests/test_array.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 122,
          "failed": 0,
          "errors": 0,
          "duration": 4.58,
          "log_tail": "test_rendering (postgres_tests.test_array.TestSplitFormField) ... skipped 'PostgreSQL specific tests'\ntest_required (postgres_tests.test_array.TestSplitFormField) ... skipped 'PostgreSQL specific tests'\ntest_required_field (postgres_tests.test_array.TestSplitFormField) ... skipped 'PostgreSQL specific tests'\ntest_splitarrayfield_has_changed (postgres_tests.test_array.TestSplitFormField) ... skipped 'PostgreSQL specific tests'\ntest_splitarrayfield_remove_trailing_nulls_has_changed (postgres_tests.test_array.TestSplitFormField) ... skipped 'PostgreSQL specific tests'\ntest_splitarraywidget_value_omitted_from_data (postgres_tests.test_array.TestSplitFormField) ... skipped 'PostgreSQL specific tests'\ntest_valid (postgres_tests.test_array.TestSplitFormField) ... skipped 'PostgreSQL specific tests'\ntest_checkbox_get_context_attrs (postgres_tests.test_array.TestSplitFormWidget) ... skipped 'PostgreSQL specific tests'\ntest_get_context (postgres_tests.test_array.TestSplitFormWidget) ... skipped 'PostgreSQL specific tests'\ntest_render (postgres_tests.test_array.TestSplitFormWidget) ... skipped 'PostgreSQL specific tests'\ntest_render_attrs (postgres_tests.test_array.TestSplitFormWidget) ... skipped 'PostgreSQL specific tests'\ntest_value_omitted_from_data (postgres_tests.test_array.TestSplitFormWidget) ... skipped 'PostgreSQL specific tests'\ntest_blank_true (postgres_tests.test_array.TestValidation) ... skipped 'PostgreSQL specific tests'\ntest_nested_array_mismatch (postgres_tests.test_array.TestValidation) ... skipped 'PostgreSQL specific tests'\ntest_unbounded (postgres_tests.test_array.TestValidation) ... skipped 'PostgreSQL specific tests'\ntest_with_base_field_error_params (postgres_tests.test_array.TestValidation) ... skipped 'PostgreSQL specific tests'\ntest_with_size (postgres_tests.test_array.TestValidation) ... skipped 'PostgreSQL specific tests'\ntest_with_validators (postgres_tests.test_array.TestValidation) ... skipped 'PostgreSQL specific tests'\ntest_get_context_does_not_mutate_attrs (forms_tests.widget_tests.test_checkboxinput.CheckboxInputTest) ... ok\ntest_render_check_exception (forms_tests.widget_tests.test_checkboxinput.CheckboxInputTest) ... ok\ntest_render_check_test (forms_tests.widget_tests.test_checkboxinput.CheckboxInputTest) ... ok\ntest_render_empty (forms_tests.widget_tests.test_checkboxinput.CheckboxInputTest) ... ok\ntest_render_false (forms_tests.widget_tests.test_checkboxinput.CheckboxInputTest) ... ok\ntest_render_int (forms_tests.widget_tests.test_checkboxinput.CheckboxInputTest) ... ok\ntest_render_none (forms_tests.widget_tests.test_checkboxinput.CheckboxInputTest) ... ok\ntest_render_true (forms_tests.widget_tests.test_checkboxinput.CheckboxInputTest) ... ok\ntest_render_value (forms_tests.widget_tests.test_checkboxinput.CheckboxInputTest) ... ok\ntest_value_from_datadict (forms_tests.widget_tests.test_checkboxinput.CheckboxInputTest) ... ok\ntest_value_from_datadict_string_int (forms_tests.widget_tests.test_checkboxinput.CheckboxInputTest) ... ok\ntest_value_omitted_from_data (forms_tests.widget_tests.test_checkboxinput.CheckboxInputTest) ... ok\n\n----------------------------------------------------------------------\nRan 122 tests in 0.210s\n\nOK (skipped=110)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/forms_tests/widget_tests/test_checkboxinput.py",
            "tests/postgres_tests/test_array.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-12262",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.70.1.155:8080",
      "duration": 12.031272888183594,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 18,
          "failed": 2,
          "errors": 2,
          "duration": 6.56,
          "log_tail": "  File \"/testbed/django/template/library.py\", line 268, in parse_bits\n    (name, param))\ndjango.template.exceptions.TemplateSyntaxError: 'inclusion_keyword_only_default' received unexpected keyword argument 'kwarg'\n\n======================================================================\nFAIL: test_simple_tag_errors (template_tests.test_custom.SimpleTagTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/template_tests/test_custom.py\", line 124, in test_simple_tag_errors\n    self.engine.from_string(entry[1])\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/contextlib.py\", line 99, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/testbed/django/test/testcases.py\", line 683, in _assert_raises_or_warns_cm\n    self.assertIn(expected_message, str(getattr(cm, cm_attr)))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1089, in assertIn\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: \"'simple_keyword_only_param' received multiple values for keyword argument 'kwarg'\" not found in \"'simple_keyword_only_param' received unexpected keyword argument 'kwarg'\"\n\n======================================================================\nFAIL: test_inclusion_tag_errors (template_tests.test_custom.InclusionTagTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/template_tests/test_custom.py\", line 248, in test_inclusion_tag_errors\n    self.engine.from_string(entry[1])\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/contextlib.py\", line 99, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/testbed/django/test/testcases.py\", line 683, in _assert_raises_or_warns_cm\n    self.assertIn(expected_message, str(getattr(cm, cm_attr)))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1089, in assertIn\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: \"'inclusion_keyword_only_default' received multiple values for keyword argument 'kwarg'\" not found in \"'inclusion_keyword_only_default' received unexpected keyword argument 'kwarg'\"\n\n----------------------------------------------------------------------\nRan 22 tests in 0.196s\n\nFAILED (failures=2, errors=2)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 template_tests.templatetags.inclusion template_tests.test_custom` failed. (See above for error)",
          "test_files_run": [
            "tests/template_tests/templatetags/inclusion.py",
            "tests/template_tests/test_custom.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 22,
          "failed": 0,
          "errors": 0,
          "duration": 4.56,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application template_tests\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_decorated_filter (template_tests.test_custom.CustomFilterTests) ... ok\ntest_filter (template_tests.test_custom.CustomFilterTests) ... ok\ntest_load_annotated_function (template_tests.test_custom.TemplateTagLoadingTests) ... ok\ntest_load_error (template_tests.test_custom.TemplateTagLoadingTests) ... ok\ntest_load_error_egg (template_tests.test_custom.TemplateTagLoadingTests) ... ok\ntest_load_working_egg (template_tests.test_custom.TemplateTagLoadingTests) ... ok\ntest_simple_tag_errors (template_tests.test_custom.SimpleTagTests) ... ok\ntest_simple_tag_escaping_autoescape_off (template_tests.test_custom.SimpleTagTests) ... ok\ntest_simple_tag_explicit_escaping (template_tests.test_custom.SimpleTagTests) ... ok\ntest_simple_tag_format_html_escaping (template_tests.test_custom.SimpleTagTests) ... ok\ntest_simple_tag_missing_context (template_tests.test_custom.SimpleTagTests) ... ok\ntest_simple_tag_naive_escaping (template_tests.test_custom.SimpleTagTests) ... ok\ntest_simple_tag_registration (template_tests.test_custom.SimpleTagTests) ... ok\ntest_simple_tags (template_tests.test_custom.SimpleTagTests) ... ok\ntest_15070_use_l10n (template_tests.test_custom.InclusionTagTests) ... ok\ntest_include_tag_missing_context (template_tests.test_custom.InclusionTagTests) ... ok\ntest_inclusion_tag_errors (template_tests.test_custom.InclusionTagTests) ... ok\ntest_inclusion_tag_registration (template_tests.test_custom.InclusionTagTests) ... ok\ntest_inclusion_tags (template_tests.test_custom.InclusionTagTests) ... ok\ntest_inclusion_tags_from_template (template_tests.test_custom.InclusionTagTests) ... ok\ntest_no_render_side_effect (template_tests.test_custom.InclusionTagTests) ... ok\ntest_render_context_is_cleared (template_tests.test_custom.InclusionTagTests) ... ok\n\n----------------------------------------------------------------------\nRan 22 tests in 0.198s\n\nOK\n",
          "test_files_run": [
            "tests/template_tests/templatetags/inclusion.py",
            "tests/template_tests/test_custom.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-12308",
      "repo": "django/django",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 11.505452156066895,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 19,
          "failed": 3,
          "errors": 0,
          "duration": 6.22,
          "log_tail": "FAIL: test_json_display_for_field (admin_utils.tests.UtilsTests) [<object object at 0x70fc4f5a7ae0>] (value=['a', 'b'])\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 523, in subTest\n    yield\n  File \"/testbed/tests/admin_utils/tests.py\", line 193, in test_json_display_for_field\n    display_value,\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1203, in assertMultiLineEqual\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: 'a, b' != '[\"a\", \"b\"]'\n- a, b\n+ [\"a\", \"b\"]\n\n\n======================================================================\nFAIL: test_json_display_for_field (admin_utils.tests.UtilsTests) [<object object at 0x70fc4f5a7ae0>] (value='a')\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 523, in subTest\n    yield\n  File \"/testbed/tests/admin_utils/tests.py\", line 193, in test_json_display_for_field\n    display_value,\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1203, in assertMultiLineEqual\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: 'a' != '\"a\"'\n- a\n+ \"a\"\n\n\n----------------------------------------------------------------------\nRan 22 tests in 0.201s\n\nFAILED (failures=3)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 admin_utils.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/admin_utils/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 22,
          "failed": 0,
          "errors": 0,
          "duration": 4.48,
          "log_tail": "    Creating table admin_utils_event\n    Creating table admin_utils_location\n    Creating table admin_utils_guest\n    Creating table admin_utils_eventguide\n    Creating table admin_utils_vehicle\n    Creating table admin_utils_car\n    Running deferred SQL...\nRunning migrations:\n  Applying admin.0001_initial... OK\n  Applying admin.0002_logentry_remove_auto_add... OK\n  Applying admin.0003_logentry_add_action_flag_choices... OK\n  Applying sites.0001_initial... OK\n  Applying sites.0002_alter_domain_unique... OK\nSystem check identified no issues (0 silenced).\n\n\nCreating test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nCloning test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\ntest_cyclic (admin_utils.tests.NestedObjectsTests) ... ok\ntest_non_added_parent (admin_utils.tests.NestedObjectsTests) ... ok\ntest_on_delete_do_nothing (admin_utils.tests.NestedObjectsTests) ... ok\ntest_queries (admin_utils.tests.NestedObjectsTests) ... ok\ntest_relation_on_abstract (admin_utils.tests.NestedObjectsTests) ... ok\ntest_siblings (admin_utils.tests.NestedObjectsTests) ... ok\ntest_unrelated_roots (admin_utils.tests.NestedObjectsTests) ... ok\ntest_flatten (admin_utils.tests.UtilsTests) ... ok\ntest_flatten_fieldsets (admin_utils.tests.UtilsTests) ... ok\ntest_json_display_for_field (admin_utils.tests.UtilsTests) ... ok\ntest_label_for_field (admin_utils.tests.UtilsTests) ... ok\ntest_label_for_field_form_argument (admin_utils.tests.UtilsTests) ... ok\ntest_label_for_property (admin_utils.tests.UtilsTests) ... ok\ntest_list_display_for_value (admin_utils.tests.UtilsTests) ... ok\ntest_list_display_for_value_boolean (admin_utils.tests.UtilsTests) ... ok\ntest_null_display_for_field (admin_utils.tests.UtilsTests) ... ok\ntest_number_formats_display_for_field (admin_utils.tests.UtilsTests) ... ok\ntest_number_formats_with_thousand_separator_display_for_field (admin_utils.tests.UtilsTests) ... ok\ntest_quote (admin_utils.tests.UtilsTests) ... ok\ntest_related_name (admin_utils.tests.UtilsTests) ... ok\ntest_safestring_in_field_label (admin_utils.tests.UtilsTests) ... ok\ntest_values_from_lookup_field (admin_utils.tests.UtilsTests) ... ok\n\n----------------------------------------------------------------------\nRan 22 tests in 0.207s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/admin_utils/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-12209",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.70.1.155:8080",
      "duration": 13.603355169296265,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 4,
          "duration": 7.42,
          "log_tail": "ERROR: test_yaml_serializer (serializers.test_data.SerializerDataTests)\npartial(func, *args, **keywords) - new function with partial application\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/django/db/backends/utils.py\", line 84, in _execute\n    return self.cursor.execute(sql, params)\n  File \"/testbed/django/db/backends/sqlite3/base.py\", line 401, in execute\n    return Database.Cursor.execute(self, query, params)\nsqlite3.IntegrityError: UNIQUE constraint failed: serializers_uuiddefaultdata.data\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/testbed/tests/serializers/test_data.py\", line 415, in serializerTest\n    obj.save()\n  File \"/testbed/django/core/serializers/base.py\", line 223, in save\n    models.Model.save_base(self.object, using=using, raw=True, **kwargs)\n  File \"/testbed/django/db/models/base.py\", line 785, in save_base\n    force_update, using, update_fields,\n  File \"/testbed/django/db/models/base.py\", line 887, in _save_table\n    results = self._do_insert(cls._base_manager, using, fields, returning_fields, raw)\n  File \"/testbed/django/db/models/base.py\", line 926, in _do_insert\n    using=using, raw=raw,\n  File \"/testbed/django/db/models/manager.py\", line 82, in manager_method\n    return getattr(self.get_queryset(), name)(*args, **kwargs)\n  File \"/testbed/django/db/models/query.py\", line 1226, in _insert\n    return query.get_compiler(using=using).execute_sql(returning_fields)\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1374, in execute_sql\n    cursor.execute(sql, params)\n  File \"/testbed/django/db/backends/utils.py\", line 66, in execute\n    return self._execute_with_wrappers(sql, params, many=False, executor=self._execute)\n  File \"/testbed/django/db/backends/utils.py\", line 75, in _execute_with_wrappers\n    return executor(sql, params, many, context)\n  File \"/testbed/django/db/backends/utils.py\", line 84, in _execute\n    return self.cursor.execute(sql, params)\n  File \"/testbed/django/db/utils.py\", line 90, in __exit__\n    raise dj_exc_value.with_traceback(traceback) from exc_value\n  File \"/testbed/django/db/backends/utils.py\", line 84, in _execute\n    return self.cursor.execute(sql, params)\n  File \"/testbed/django/db/backends/sqlite3/base.py\", line 401, in execute\n    return Database.Cursor.execute(self, query, params)\ndjango.db.utils.IntegrityError: UNIQUE constraint failed: serializers_uuiddefaultdata.data\n\n----------------------------------------------------------------------\nRan 4 tests in 0.633s\n\nFAILED (errors=4)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 serializers.models.data serializers.test_data` failed. (See above for error)",
          "test_files_run": [
            "tests/serializers/models/data.py",
            "tests/serializers/test_data.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 4,
          "failed": 0,
          "errors": 0,
          "duration": 5.37,
          "log_tail": "    Creating table serializers_emailpkdata\n    Creating table serializers_filepathpkdata\n    Creating table serializers_floatpkdata\n    Creating table serializers_integerpkdata\n    Creating table serializers_genericipaddresspkdata\n    Creating table serializers_positiveintegerpkdata\n    Creating table serializers_positivesmallintegerpkdata\n    Creating table serializers_slugpkdata\n    Creating table serializers_smallpkdata\n    Creating table serializers_uuiddata\n    Creating table serializers_uuiddefaultdata\n    Creating table serializers_fktouuid\n    Creating table serializers_autonowdatetimedata\n    Creating table serializers_modifyingsavedata\n    Creating table serializers_inheritabstractmodel\n    Creating table serializers_inheritbasemodel\n    Creating table serializers_explicitinheritbasemodel\n    Creating table serializers_lengthmodel\n    Creating table serializers_parent\n    Creating table serializers_child\n    Creating table serializers_naturalkeyanchor\n    Creating table serializers_fkdatanaturalkey\n    Creating table serializers_naturalkeything\n    Creating table serializers_naturalpkwithdefault\n    Running deferred SQL...\nRunning migrations:\n  Applying admin.0001_initial... OK\n  Applying admin.0002_logentry_remove_auto_add... OK\n  Applying admin.0003_logentry_add_action_flag_choices... OK\n  Applying sites.0001_initial... OK\n  Applying sites.0002_alter_domain_unique... OK\nSystem check identified no issues (0 silenced).\n\n\nCreating test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\ntest_json_serializer (serializers.test_data.SerializerDataTests)\npartial(func, *args, **keywords) - new function with partial application ... ok\ntest_python_serializer (serializers.test_data.SerializerDataTests)\npartial(func, *args, **keywords) - new function with partial application ... ok\ntest_xml_serializer (serializers.test_data.SerializerDataTests)\npartial(func, *args, **keywords) - new function with partial application ... ok\ntest_yaml_serializer (serializers.test_data.SerializerDataTests)\npartial(func, *args, **keywords) - new function with partial application ... ok\n\n----------------------------------------------------------------------\nRan 4 tests in 0.864s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/serializers/models/data.py",
            "tests/serializers/test_data.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-12419",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.123.9.23:8080",
      "duration": 11.084151268005371,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 1,
          "errors": 0,
          "duration": 5.92,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application project_template\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_middleware_headers (project_template.test_settings.TestStartProjectSettings) ... FAIL\n\n======================================================================\nFAIL: test_middleware_headers (project_template.test_settings.TestStartProjectSettings)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/project_template/test_settings.py\", line 43, in test_middleware_headers\n    b'X-Frame-Options: DENY',\nAssertionError: Lists differ: [b'Co[58 chars]', b'X-Content-Type-Options: nosniff', b'X-Fra[13 chars]ENY'] != [b'Co[58 chars]', b'Referrer-Policy: same-origin', b'X-Conten[46 chars]ENY']\n\nFirst differing element 2:\nb'X-Content-Type-Options: nosniff'\nb'Referrer-Policy: same-origin'\n\nSecond list contains 1 additional elements.\nFirst extra element 4:\nb'X-Frame-Options: DENY'\n\n  [b'Content-Length: 0',\n   b'Content-Type: text/html; charset=utf-8',\n+  b'Referrer-Policy: same-origin',\n   b'X-Content-Type-Options: nosniff',\n   b'X-Frame-Options: DENY']\n\n----------------------------------------------------------------------\nRan 1 test in 0.009s\n\nFAILED (failures=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 project_template.test_settings` failed. (See above for error)",
          "test_files_run": [
            "tests/project_template/test_settings.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 1,
          "failed": 0,
          "errors": 0,
          "duration": 4.26,
          "log_tail": "Testing against Django installed in '/testbed/django' with up to 60 processes\nImporting application project_template\nSkipping setup of unused database(s): default, other.\nSystem check identified no issues (0 silenced).\n\n\ntest_middleware_headers (project_template.test_settings.TestStartProjectSettings) ... ok\n\n----------------------------------------------------------------------\nRan 1 test in 0.008s\n\nOK\n",
          "test_files_run": [
            "tests/project_template/test_settings.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-12741",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.59.30.169:8080",
      "duration": 11.635859966278076,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 78,
          "failed": 0,
          "errors": 2,
          "duration": 6.28,
          "log_tail": "test_unicode_fetches (backends.tests.BackendTestCase) ... ok\ntest_unicode_password (backends.tests.BackendTestCase) ... ok\n\n======================================================================\nERROR: test_execute_sql_flush_statements (backends.base.test_operations.SqlFlushTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/backends/base/test_operations.py\", line 175, in test_execute_sql_flush_statements\n    connection.ops.execute_sql_flush(sql_list)\nTypeError: execute_sql_flush() missing 1 required positional argument: 'sql_list'\n\n======================================================================\nERROR: test_sequence_name_length_limits_flush (backends.tests.LongNameTest)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/backends/tests.py\", line 165, in test_sequence_name_length_limits_flush\n    connection.ops.execute_sql_flush(sql_list)\nTypeError: execute_sql_flush() missing 1 required positional argument: 'sql_list'\n\n----------------------------------------------------------------------\nRan 80 tests in 0.204s\n\nFAILED (errors=2, skipped=11)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 backends.base.test_operations backends.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/backends/base/test_operations.py",
            "tests/backends/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 80,
          "failed": 0,
          "errors": 0,
          "duration": 4.49,
          "log_tail": "test_disable_constraint_checks_manually (backends.tests.FkConstraintsTests) ... ok\ntest_integrity_checks_on_creation (backends.tests.FkConstraintsTests) ... ok\ntest_integrity_checks_on_update (backends.tests.FkConstraintsTests) ... ok\ntest_closing_non_shared_connections (backends.tests.ThreadTests) ... ok\ntest_connections_thread_local (backends.tests.ThreadTests) ... ok\ntest_default_connection_thread_local (backends.tests.ThreadTests) ... ok\ntest_pass_connection_between_threads (backends.tests.ThreadTests) ... ok\ntest_thread_sharing_count (backends.tests.ThreadTests) ... ok\ntest_cached_db_features (backends.tests.BackendTestCase) ... ok\ntest_cursor_contextmanager (backends.tests.BackendTestCase) ... ok\ntest_cursor_contextmanager_closing (backends.tests.BackendTestCase) ... skipped 'Psycopg2 specific cursor.closed attribute needed'\ntest_cursor_execute_with_pyformat (backends.tests.BackendTestCase) ... skipped \"Database doesn't support feature(s): supports_paramstyle_pyformat\"\ntest_cursor_executemany (backends.tests.BackendTestCase) ... ok\ntest_cursor_executemany_with_empty_params_list (backends.tests.BackendTestCase) ... ok\ntest_cursor_executemany_with_iterator (backends.tests.BackendTestCase) ... ok\ntest_cursor_executemany_with_pyformat (backends.tests.BackendTestCase) ... skipped \"Database doesn't support feature(s): supports_paramstyle_pyformat\"\ntest_cursor_executemany_with_pyformat_iterator (backends.tests.BackendTestCase) ... skipped \"Database doesn't support feature(s): supports_paramstyle_pyformat\"\ntest_database_operations_helper_class (backends.tests.BackendTestCase) ... ok\ntest_database_operations_init (backends.tests.BackendTestCase) ... ok\ntest_duplicate_table_error (backends.tests.BackendTestCase)\nCreating an existing table returns a DatabaseError ... ok\ntest_is_usable_after_database_disconnects (backends.tests.BackendTestCase) ... skipped \"Database doesn't support feature(s): test_db_allows_multiple_connections\"\ntest_queries (backends.tests.BackendTestCase) ... ok\ntest_queries_limit (backends.tests.BackendTestCase) ... skipped \"Database doesn't support feature(s): test_db_allows_multiple_connections\"\ntest_timezone_none_use_tz_false (backends.tests.BackendTestCase) ... ok\ntest_unicode_fetches (backends.tests.BackendTestCase) ... ok\ntest_unicode_password (backends.tests.BackendTestCase) ... ok\n\n----------------------------------------------------------------------\nRan 80 tests in 0.203s\n\nOK (skipped=11)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/backends/base/test_operations.py",
            "tests/backends/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-12858",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.123.9.23:8080",
      "duration": 11.579314947128296,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 75,
          "failed": 1,
          "errors": 0,
          "duration": 6.24,
          "log_tail": "\n======================================================================\nFAIL: test_ordering_pointing_to_lookup_not_transform (invalid_models_tests.test_models.OtherModelTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/invalid_models_tests/test_models.py\", line 903, in test_ordering_pointing_to_lookup_not_transform\n    self.assertEqual(Model.check(), [])\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1028, in assertListEqual\n    self.assertSequenceEqual(list1, list2, msg, seq_type=list)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1010, in assertSequenceEqual\n    self.fail(msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: Lists differ: [<Error: level=40, msg=\"'ordering' refers [219 chars]15'>] != []\n\nFirst list contains 1 additional elements.\nFirst extra element 0:\n<Error: level=40, msg=\"'ordering' refers to the nonexistent field, related field, or lookup 'test__isnull'.\", hint=None, obj=<class 'invalid_models_tests.test_models.OtherModelTests.test_ordering_pointing_to_lookup_not_transform.<locals>.Model'>, id='models.E015'>\n\n- [<Error: level=40, msg=\"'ordering' refers to the nonexistent field, related field, or lookup 'test__isnull'.\", hint=None, obj=<class 'invalid_models_tests.test_models.OtherModelTests.test_ordering_pointing_to_lookup_not_transform.<locals>.Model'>, id='models.E015'>]\n+ []\n\n----------------------------------------------------------------------\nRan 76 tests in 0.206s\n\nFAILED (failures=1, skipped=2)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 invalid_models_tests.test_models` failed. (See above for error)",
          "test_files_run": [
            "tests/invalid_models_tests/test_models.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 76,
          "failed": 0,
          "errors": 0,
          "duration": 4.52,
          "log_tail": "test_m2m_to_concrete_and_proxy_allowed (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_m2m_unmanaged_shadow_models_not_checked (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_name_beginning_with_underscore (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_name_contains_double_underscores (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_name_ending_with_underscore (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_non_valid (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_onetoone_with_explicit_parent_link_parent_model (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_onetoone_with_parent_model (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_ordering_allows_registered_lookups (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_ordering_non_iterable (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_ordering_pointing_multiple_times_to_model_fields (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_ordering_pointing_to_foreignkey_field (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_ordering_pointing_to_lookup_not_transform (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_ordering_pointing_to_missing_field (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_ordering_pointing_to_missing_foreignkey_field (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_ordering_pointing_to_missing_related_field (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_ordering_pointing_to_missing_related_model_field (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_ordering_pointing_to_non_related_field (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_ordering_pointing_to_related_model_pk (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_ordering_pointing_to_two_related_model_field (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_ordering_with_order_with_respect_to (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_property_and_related_field_accessor_clash (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_single_primary_key (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_swappable_missing_app (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_swappable_missing_app_name (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_two_m2m_through_same_model_with_different_through_fields (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_two_m2m_through_same_relationship (invalid_models_tests.test_models.OtherModelTests) ... ok\ntest_unique_primary_key (invalid_models_tests.test_models.OtherModelTests) ... ok\n\n----------------------------------------------------------------------\nRan 76 tests in 0.208s\n\nOK (skipped=2)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/invalid_models_tests/test_models.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-12754",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.59.30.169:8080",
      "duration": 15.208829164505005,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 115,
          "failed": 1,
          "errors": 0,
          "duration": 7.27,
          "log_tail": "Tests autodetection of renamed models. ... ok\ntest_rename_model_case (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_rename_model_reverse_relation_dependencies (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_rename_model_with_fks_in_different_position (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_rename_model_with_renamed_rel_field (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_rename_referenced_primary_key (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_rename_related_field_preserved_db_column (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_replace_string_with_foreignkey (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_same_app_circular_fk_dependency (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_same_app_circular_fk_dependency_with_unique_together_and_indexes (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_same_app_no_fk_dependency (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_set_alter_order_with_respect_to (migrations.test_autodetector.AutodetectorTests)\nSetting order_with_respect_to adds a field. ... ok\ntest_supports_functools_partial (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_swappable (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_swappable_changed (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_swappable_circular_multi_mti (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_swappable_first_inheritance (migrations.test_autodetector.AutodetectorTests)\nSwappable models get their CreateModel first. ... ok\ntest_swappable_first_setting (migrations.test_autodetector.AutodetectorTests)\nSwappable models get their CreateModel first. ... ok\ntest_trim_apps (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_unmanaged_create (migrations.test_autodetector.AutodetectorTests)\nThe autodetector correctly deals with managed models. ... ok\ntest_unmanaged_custom_pk (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_unmanaged_delete (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_unmanaged_to_managed (migrations.test_autodetector.AutodetectorTests) ... ok\n\n======================================================================\nFAIL: test_add_model_with_field_removed_from_base_model (migrations.test_autodetector.AutodetectorTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/migrations/test_autodetector.py\", line 2479, in test_add_model_with_field_removed_from_base_model\n    self.assertOperationTypes(changes, 'app', 0, ['RemoveField', 'CreateModel'])\n  File \"/testbed/tests/migrations/test_autodetector.py\", line 517, in assertOperationTypes\n    self.repr_changes(changes),\nAssertionError: Operation type mismatch for app.auto_1 (expected ['RemoveField', 'CreateModel']):\n  app:\n    auto_1\n      <CreateModel  name='book', fields=[('title', <django.db.models.fields.CharField>)], options={}, bases=('app.readable',), managers=[]>\n      <RemoveField  model_name='readable', name='title'>\n\n\n----------------------------------------------------------------------\nRan 116 tests in 0.264s\n\nFAILED (failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 migrations.test_autodetector` failed. (See above for error)",
          "test_files_run": [
            "tests/migrations/test_autodetector.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 116,
          "failed": 0,
          "errors": 0,
          "duration": 7.07,
          "log_tail": "Test change detection of removed constraints. ... ok\ntest_remove_field (migrations.test_autodetector.AutodetectorTests)\nTests autodetection of removed fields. ... ok\ntest_remove_field_and_foo_together (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_remove_foo_together (migrations.test_autodetector.AutodetectorTests)\nTests index/unique_together detection. ... ok\ntest_remove_indexes (migrations.test_autodetector.AutodetectorTests)\nTest change detection of removed indexes. ... ok\ntest_rename_field (migrations.test_autodetector.AutodetectorTests)\nTests autodetection of renamed fields. ... ok\ntest_rename_field_and_foo_together (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_rename_field_foreign_key_to_field (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_rename_field_preserved_db_column (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_rename_foreign_object_fields (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_rename_m2m_through_model (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_rename_model (migrations.test_autodetector.AutodetectorTests)\nTests autodetection of renamed models. ... ok\ntest_rename_model_case (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_rename_model_reverse_relation_dependencies (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_rename_model_with_fks_in_different_position (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_rename_model_with_renamed_rel_field (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_rename_referenced_primary_key (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_rename_related_field_preserved_db_column (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_replace_string_with_foreignkey (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_same_app_circular_fk_dependency (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_same_app_circular_fk_dependency_with_unique_together_and_indexes (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_same_app_no_fk_dependency (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_set_alter_order_with_respect_to (migrations.test_autodetector.AutodetectorTests)\nSetting order_with_respect_to adds a field. ... ok\ntest_supports_functools_partial (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_swappable (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_swappable_changed (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_swappable_circular_multi_mti (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_swappable_first_inheritance (migrations.test_autodetector.AutodetectorTests)\nSwappable models get their CreateModel first. ... ok\ntest_swappable_first_setting (migrations.test_autodetector.AutodetectorTests)\nSwappable models get their CreateModel first. ... ok\ntest_trim_apps (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_unmanaged_create (migrations.test_autodetector.AutodetectorTests)\nThe autodetector correctly deals with managed models. ... ok\ntest_unmanaged_custom_pk (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_unmanaged_delete (migrations.test_autodetector.AutodetectorTests) ... ok\ntest_unmanaged_to_managed (migrations.test_autodetector.AutodetectorTests) ... ok\n\n----------------------------------------------------------------------\nRan 116 tests in 0.259s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/migrations/test_autodetector.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-12965",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.41.233.120:8080",
      "duration": 18.112151861190796,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 53,
          "failed": 1,
          "errors": 0,
          "duration": 9.5,
          "log_tail": "test_restrict_path_cascade_indirect_diamond (delete.tests.OnDeleteTests) ... ok\ntest_setdefault (delete.tests.OnDeleteTests) ... ok\ntest_setdefault_none (delete.tests.OnDeleteTests) ... ok\ntest_setnull (delete.tests.OnDeleteTests) ... ok\ntest_setnull_from_child (delete.tests.OnDeleteTests) ... ok\ntest_setnull_from_parent (delete.tests.OnDeleteTests) ... ok\ntest_setvalue (delete.tests.OnDeleteTests) ... ok\ntest_bulk (delete.tests.DeletionTests) ... ok\ntest_can_defer_constraint_checks (delete.tests.DeletionTests) ... ok\ntest_cannot_defer_constraint_checks (delete.tests.DeletionTests) ... skipped 'Database has feature(s) can_defer_constraint_checks'\ntest_delete_with_keeping_parents (delete.tests.DeletionTests) ... ok\ntest_delete_with_keeping_parents_relationships (delete.tests.DeletionTests) ... ok\ntest_deletion_order (delete.tests.DeletionTests) ... ok\ntest_hidden_related (delete.tests.DeletionTests) ... ok\ntest_instance_update (delete.tests.DeletionTests) ... ok\ntest_large_delete (delete.tests.DeletionTests) ... ok\ntest_large_delete_related (delete.tests.DeletionTests) ... ok\ntest_m2m (delete.tests.DeletionTests) ... ok\ntest_model_delete_returns_num_rows (delete.tests.DeletionTests) ... ok\ntest_only_referenced_fields_selected (delete.tests.DeletionTests) ... ok\ntest_proxied_model_duplicate_queries (delete.tests.DeletionTests) ... ok\ntest_queryset_delete_returns_num_rows (delete.tests.DeletionTests) ... ok\ntest_relational_post_delete_signals_happen_before_parent_object (delete.tests.DeletionTests) ... ok\n\n======================================================================\nFAIL: test_fast_delete_all (delete.tests.FastDeleteTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/delete/tests.py\", line 613, in test_fast_delete_all\n    self.assertNotIn('SELECT', sql)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1096, in assertNotIn\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: 'SELECT' unexpectedly found in 'DELETE FROM \"delete_user\" WHERE \"delete_user\".\"id\" IN (SELECT \"delete_user\".\"id\" FROM \"delete_user\")'\n\n----------------------------------------------------------------------\nRan 54 tests in 0.808s\n\nFAILED (failures=1, skipped=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 delete.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/delete/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 54,
          "failed": 0,
          "errors": 0,
          "duration": 7.79,
          "log_tail": "test_cascade_from_child (delete.tests.OnDeleteTests) ... ok\ntest_cascade_from_parent (delete.tests.OnDeleteTests) ... ok\ntest_cascade_nullable (delete.tests.OnDeleteTests) ... ok\ntest_do_nothing (delete.tests.OnDeleteTests) ... ok\ntest_do_nothing_qscount (delete.tests.OnDeleteTests) ... ok\ntest_inheritance_cascade_down (delete.tests.OnDeleteTests) ... ok\ntest_inheritance_cascade_up (delete.tests.OnDeleteTests) ... ok\ntest_non_callable (delete.tests.OnDeleteTests) ... ok\ntest_o2o_setnull (delete.tests.OnDeleteTests) ... ok\ntest_protect (delete.tests.OnDeleteTests) ... ok\ntest_protect_multiple (delete.tests.OnDeleteTests) ... ok\ntest_protect_path (delete.tests.OnDeleteTests) ... ok\ntest_restrict (delete.tests.OnDeleteTests) ... ok\ntest_restrict_gfk_no_fast_delete (delete.tests.OnDeleteTests) ... ok\ntest_restrict_multiple (delete.tests.OnDeleteTests) ... ok\ntest_restrict_path_cascade_direct (delete.tests.OnDeleteTests) ... ok\ntest_restrict_path_cascade_indirect (delete.tests.OnDeleteTests) ... ok\ntest_restrict_path_cascade_indirect_diamond (delete.tests.OnDeleteTests) ... ok\ntest_setdefault (delete.tests.OnDeleteTests) ... ok\ntest_setdefault_none (delete.tests.OnDeleteTests) ... ok\ntest_setnull (delete.tests.OnDeleteTests) ... ok\ntest_setnull_from_child (delete.tests.OnDeleteTests) ... ok\ntest_setnull_from_parent (delete.tests.OnDeleteTests) ... ok\ntest_setvalue (delete.tests.OnDeleteTests) ... ok\ntest_bulk (delete.tests.DeletionTests) ... ok\ntest_can_defer_constraint_checks (delete.tests.DeletionTests) ... ok\ntest_cannot_defer_constraint_checks (delete.tests.DeletionTests) ... skipped 'Database has feature(s) can_defer_constraint_checks'\ntest_delete_with_keeping_parents (delete.tests.DeletionTests) ... ok\ntest_delete_with_keeping_parents_relationships (delete.tests.DeletionTests) ... ok\ntest_deletion_order (delete.tests.DeletionTests) ... ok\ntest_hidden_related (delete.tests.DeletionTests) ... ok\ntest_instance_update (delete.tests.DeletionTests) ... ok\ntest_large_delete (delete.tests.DeletionTests) ... ok\ntest_large_delete_related (delete.tests.DeletionTests) ... ok\ntest_m2m (delete.tests.DeletionTests) ... ok\ntest_model_delete_returns_num_rows (delete.tests.DeletionTests) ... ok\ntest_only_referenced_fields_selected (delete.tests.DeletionTests) ... ok\ntest_proxied_model_duplicate_queries (delete.tests.DeletionTests) ... ok\ntest_queryset_delete_returns_num_rows (delete.tests.DeletionTests) ... ok\ntest_relational_post_delete_signals_happen_before_parent_object (delete.tests.DeletionTests) ... ok\n\n----------------------------------------------------------------------\nRan 54 tests in 0.804s\n\nOK (skipped=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/delete/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-13023",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.70.1.155:8080",
      "duration": 16.837540864944458,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 5,
          "failed": 0,
          "errors": 7,
          "duration": 8.85,
          "log_tail": "    field.clean(value, None)\n  File \"/testbed/django/db/models/fields/__init__.py\", line 650, in clean\n    value = self.to_python(value)\n  File \"/testbed/django/db/models/fields/__init__.py\", line 1503, in to_python\n    return decimal.Decimal(value)\nTypeError: conversion from set to Decimal is not supported\n\n======================================================================\nERROR: test_invalid_value (model_fields.test_decimalfield.DecimalFieldTests) [<object object at 0x7c284b794c10>]\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/model_fields/test_decimalfield.py\", line 41, in test_invalid_value\n    field.clean(value, None)\n  File \"/testbed/django/db/models/fields/__init__.py\", line 650, in clean\n    value = self.to_python(value)\n  File \"/testbed/django/db/models/fields/__init__.py\", line 1503, in to_python\n    return decimal.Decimal(value)\nTypeError: conversion from object to Decimal is not supported\n\n======================================================================\nERROR: test_invalid_value (model_fields.test_decimalfield.DecimalFieldTests) [0j]\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/model_fields/test_decimalfield.py\", line 41, in test_invalid_value\n    field.clean(value, None)\n  File \"/testbed/django/db/models/fields/__init__.py\", line 650, in clean\n    value = self.to_python(value)\n  File \"/testbed/django/db/models/fields/__init__.py\", line 1503, in to_python\n    return decimal.Decimal(value)\nTypeError: conversion from complex to Decimal is not supported\n\n======================================================================\nERROR: test_invalid_value (model_fields.test_decimalfield.DecimalFieldTests) [b'non-numeric byte-string']\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/model_fields/test_decimalfield.py\", line 41, in test_invalid_value\n    field.clean(value, None)\n  File \"/testbed/django/db/models/fields/__init__.py\", line 650, in clean\n    value = self.to_python(value)\n  File \"/testbed/django/db/models/fields/__init__.py\", line 1503, in to_python\n    return decimal.Decimal(value)\nTypeError: conversion from bytes to Decimal is not supported\n\n----------------------------------------------------------------------\nRan 12 tests in 0.009s\n\nFAILED (errors=7, skipped=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 model_fields.test_decimalfield` failed. (See above for error)",
          "test_files_run": [
            "tests/model_fields/test_decimalfield.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 12,
          "failed": 0,
          "errors": 0,
          "duration": 7.13,
          "log_tail": "    Creating table model_fields_decimallessthanone\n    Creating table model_fields_fieldclassattributemodel\n    Creating table model_fields_datamodel\n    Creating table model_fields_document\n    Creating table model_fields_person\n    Creating table model_fields_personwithheight\n    Creating table model_fields_personwithheightandwidth\n    Creating table model_fields_persondimensionsfirst\n    Creating table model_fields_persontwoimages\n    Creating table model_fields_jsonmodel\n    Creating table model_fields_nullablejsonmodel\n    Creating table model_fields_allfieldsmodel\n    Creating table model_fields_manytomany\n    Creating table model_fields_uuidmodel\n    Creating table model_fields_nullableuuidmodel\n    Creating table model_fields_primarykeyuuidmodel\n    Creating table model_fields_relatedtouuidmodel\n    Creating table model_fields_uuidchild\n    Creating table model_fields_uuidgrandchild\n    Running deferred SQL...\nRunning migrations:\n  Applying admin.0001_initial... OK\n  Applying admin.0002_logentry_remove_auto_add... OK\n  Applying admin.0003_logentry_add_action_flag_choices... OK\n  Applying sites.0001_initial... OK\n  Applying sites.0002_alter_domain_unique... OK\nSystem check identified no issues (3 silenced).\n\n\nCreating test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\ntest_default (model_fields.test_decimalfield.DecimalFieldTests) ... ok\ntest_fetch_from_db_without_float_rounding (model_fields.test_decimalfield.DecimalFieldTests) ... skipped 'SQLite stores values rounded to 15 significant digits.'\ntest_filter_with_strings (model_fields.test_decimalfield.DecimalFieldTests) ... ok\ntest_get_prep_value (model_fields.test_decimalfield.DecimalFieldTests) ... ok\ntest_invalid_value (model_fields.test_decimalfield.DecimalFieldTests) ... ok\ntest_lookup_really_big_value (model_fields.test_decimalfield.DecimalFieldTests) ... ok\ntest_max_decimal_places_validation (model_fields.test_decimalfield.DecimalFieldTests) ... ok\ntest_max_digits_validation (model_fields.test_decimalfield.DecimalFieldTests) ... ok\ntest_max_whole_digits_validation (model_fields.test_decimalfield.DecimalFieldTests) ... ok\ntest_roundtrip_with_trailing_zeros (model_fields.test_decimalfield.DecimalFieldTests)\nTrailing zeros in the fractional part aren't truncated. ... ok\ntest_save_without_float_conversion (model_fields.test_decimalfield.DecimalFieldTests) ... ok\ntest_to_python (model_fields.test_decimalfield.DecimalFieldTests) ... ok\n\n----------------------------------------------------------------------\nRan 12 tests in 0.008s\n\nOK (skipped=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/model_fields/test_decimalfield.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-13028",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.70.1.155:8080",
      "duration": 18.157991886138916,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 280,
          "failed": 2,
          "errors": 2,
          "duration": 9.57,
          "log_tail": "Destroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 queries.models queries.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/queries/models.py",
            "tests/queries/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 284,
          "failed": 0,
          "errors": 0,
          "duration": 7.78,
          "log_tail": "Destroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/queries/models.py",
            "tests/queries/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-13121",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.123.9.23:8080",
      "duration": 15.315649032592773,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 172,
          "failed": 0,
          "errors": 1,
          "duration": 7.23,
          "log_tail": "test_update_inherited_field_value (expressions.tests.BasicExpressionsTests) ... ok\ntest_update_with_fk (expressions.tests.BasicExpressionsTests) ... ok\ntest_update_with_none (expressions.tests.BasicExpressionsTests) ... ok\ntest_uuid_pk_subquery (expressions.tests.BasicExpressionsTests) ... ok\n\n======================================================================\nERROR: test_duration_expressions (expressions.tests.FTimeDeltaTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/expressions/tests.py\", line 1474, in test_duration_expressions\n    for obj in qs:\n  File \"/testbed/django/db/models/query.py\", line 287, in __iter__\n    self._fetch_all()\n  File \"/testbed/django/db/models/query.py\", line 1305, in _fetch_all\n    self._result_cache = list(self._iterable_class(self))\n  File \"/testbed/django/db/models/query.py\", line 70, in __iter__\n    for row in compiler.results_iter(results):\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1105, in apply_converters\n    value = converter(value, expression, connection)\n  File \"/testbed/django/db/backends/base/operations.py\", line 583, in convert_durationfield_value\n    return datetime.timedelta(0, 0, value)\nTypeError: unsupported type for timedelta microseconds component: str\n\n----------------------------------------------------------------------\nRan 173 tests in 0.312s\n\nFAILED (errors=1, skipped=4)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 backends.base.test_operations expressions.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/backends/base/test_operations.py",
            "tests/expressions/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 173,
          "failed": 0,
          "errors": 0,
          "duration": 7.24,
          "log_tail": "test_object_update_unsaved_objects (expressions.tests.BasicExpressionsTests) ... ok\ntest_order_by_exists (expressions.tests.BasicExpressionsTests) ... ok\ntest_order_by_multiline_sql (expressions.tests.BasicExpressionsTests) ... ok\ntest_order_of_operations (expressions.tests.BasicExpressionsTests) ... ok\ntest_outerref (expressions.tests.BasicExpressionsTests) ... ok\ntest_outerref_mixed_case_table_name (expressions.tests.BasicExpressionsTests) ... ok\ntest_outerref_with_operator (expressions.tests.BasicExpressionsTests) ... ok\ntest_parenthesis_priority (expressions.tests.BasicExpressionsTests) ... ok\ntest_pickle_expression (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_eq (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_filter_by_aggregate (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_filter_by_lazy (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_group_by_outerref_in_filter (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_in_filter (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_references_joined_table_twice (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_11722_iexact_lookup (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_16731_startswith_lookup (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_18375_chained_filters (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_18375_join_reuse (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_18375_kwarg_ordering (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_18375_kwarg_ordering_2 (expressions.tests.BasicExpressionsTests) ... ok\ntest_update (expressions.tests.BasicExpressionsTests) ... ok\ntest_update_inherited_field_value (expressions.tests.BasicExpressionsTests) ... ok\ntest_update_with_fk (expressions.tests.BasicExpressionsTests) ... ok\ntest_update_with_none (expressions.tests.BasicExpressionsTests) ... ok\ntest_uuid_pk_subquery (expressions.tests.BasicExpressionsTests) ... ok\n\n----------------------------------------------------------------------\nRan 173 tests in 0.316s\n\nOK (skipped=4)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/backends/base/test_operations.py",
            "tests/expressions/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-13128",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.70.1.155:8080",
      "duration": 16.977227687835693,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 136,
          "failed": 0,
          "errors": 7,
          "duration": 9.01,
          "log_tail": "TypeError: expected string or bytes-like object\n\n======================================================================\nERROR: test_time_subtraction (expressions.tests.FTimeDeltaTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/django/test/testcases.py\", line 1274, in skip_wrapper\n    return test_func(*args, **kwargs)\n  File \"/testbed/tests/expressions/tests.py\", line 1549, in test_time_subtraction\n    queryset.get().difference,\n  File \"/testbed/django/db/models/query.py\", line 425, in get\n    num = len(clone)\n  File \"/testbed/django/db/models/query.py\", line 269, in __len__\n    self._fetch_all()\n  File \"/testbed/django/db/models/query.py\", line 1305, in _fetch_all\n    self._result_cache = list(self._iterable_class(self))\n  File \"/testbed/django/db/models/query.py\", line 70, in __iter__\n    for row in compiler.results_iter(results):\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1105, in apply_converters\n    value = converter(value, expression, connection)\n  File \"/testbed/django/db/backends/sqlite3/operations.py\", line 293, in convert_timefield_value\n    value = parse_time(value)\n  File \"/testbed/django/utils/dateparse.py\", line 90, in parse_time\n    match = time_re.match(value)\nTypeError: expected string or bytes-like object\n\n----------------------------------------------------------------------\nRan 143 tests in 0.307s\n\nFAILED (errors=7, skipped=2)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 expressions.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/expressions/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 143,
          "failed": 0,
          "errors": 0,
          "duration": 7.15,
          "log_tail": "test_object_create_with_aggregate (expressions.tests.BasicExpressionsTests) ... ok\ntest_object_update (expressions.tests.BasicExpressionsTests) ... ok\ntest_object_update_fk (expressions.tests.BasicExpressionsTests) ... ok\ntest_object_update_unsaved_objects (expressions.tests.BasicExpressionsTests) ... ok\ntest_order_by_exists (expressions.tests.BasicExpressionsTests) ... ok\ntest_order_by_multiline_sql (expressions.tests.BasicExpressionsTests) ... ok\ntest_order_of_operations (expressions.tests.BasicExpressionsTests) ... ok\ntest_outerref (expressions.tests.BasicExpressionsTests) ... ok\ntest_outerref_mixed_case_table_name (expressions.tests.BasicExpressionsTests) ... ok\ntest_outerref_with_operator (expressions.tests.BasicExpressionsTests) ... ok\ntest_parenthesis_priority (expressions.tests.BasicExpressionsTests) ... ok\ntest_pickle_expression (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_eq (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_filter_by_aggregate (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_filter_by_lazy (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_group_by_outerref_in_filter (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_in_filter (expressions.tests.BasicExpressionsTests) ... ok\ntest_subquery_references_joined_table_twice (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_11722_iexact_lookup (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_16731_startswith_lookup (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_18375_chained_filters (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_18375_join_reuse (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_18375_kwarg_ordering (expressions.tests.BasicExpressionsTests) ... ok\ntest_ticket_18375_kwarg_ordering_2 (expressions.tests.BasicExpressionsTests) ... ok\ntest_update (expressions.tests.BasicExpressionsTests) ... ok\ntest_update_inherited_field_value (expressions.tests.BasicExpressionsTests) ... ok\ntest_update_with_fk (expressions.tests.BasicExpressionsTests) ... ok\ntest_update_with_none (expressions.tests.BasicExpressionsTests) ... ok\ntest_uuid_pk_subquery (expressions.tests.BasicExpressionsTests) ... ok\n\n----------------------------------------------------------------------\nRan 143 tests in 0.306s\n\nOK (skipped=2)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/expressions/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-11740",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10ce3dbe0>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 1
    },
    {
      "instance_id": "django__django-12143",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10ce63fe0>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 1
    },
    {
      "instance_id": "django__django-13089",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.41.233.120:8080",
      "duration": 43.22055196762085,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 481,
          "failed": 0,
          "errors": 2,
          "duration": 22.06,
          "log_tail": "----------------------------------------------------------------------\nRan 483 tests in 13.440s\n\nFAILED (errors=2, skipped=117)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 cache.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/cache/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 483,
          "failed": 0,
          "errors": 0,
          "duration": 20.32,
          "log_tail": "\n----------------------------------------------------------------------\nRan 483 tests in 13.444s\n\nOK (skipped=117)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/cache/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-13195",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 17.562127828598022,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 413,
          "failed": 1,
          "errors": 2,
          "duration": 9.16,
          "log_tail": "    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: 'Set-[61 chars]Jan 1970 00:00:00 GMT; Max-Age=0; Path=/example/; SameSite=Lax' != 'Set-[61 chars]Jan 1970 00:00:00 GMT; Max-Age=0; Path=/example/'\n- Set-Cookie: sessionid=\"\"; Domain=.example.local; expires=Thu, 01 Jan 1970 00:00:00 GMT; Max-Age=0; Path=/example/; SameSite=Lax\n?                                                                                                                  --------------\n+ Set-Cookie: sessionid=\"\"; Domain=.example.local; expires=Thu, 01 Jan 1970 00:00:00 GMT; Max-Age=0; Path=/example/\n\n\n======================================================================\nFAIL: test_cookie_setings (messages_tests.test_cookie.CookieTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/django/test/utils.py\", line 381, in inner\n    return func(*args, **kwargs)\n  File \"/testbed/tests/messages_tests/test_cookie.py\", line 91, in test_cookie_setings\n    settings.SESSION_COOKIE_SAMESITE,\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1203, in assertMultiLineEqual\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: '' != 'Strict'\n+ Strict\n\n----------------------------------------------------------------------\nRan 416 tests in 0.311s\n\nFAILED (failures=3, errors=2, skipped=2, expected failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 messages_tests.test_cookie responses.test_cookie sessions_tests.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/messages_tests/test_cookie.py",
            "tests/responses/test_cookie.py",
            "tests/sessions_tests/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 416,
          "failed": 0,
          "errors": 0,
          "duration": 7.41,
          "log_tail": "test_update (sessions_tests.tests.CustomDatabaseSessionTests) ... ok\ntest_values (sessions_tests.tests.CustomDatabaseSessionTests) ... ok\ntest_add (messages_tests.test_cookie.CookieTests) ... ok\ntest_add_lazy_translation (messages_tests.test_cookie.CookieTests) ... ok\ntest_add_update (messages_tests.test_cookie.CookieTests) ... ok\ntest_context_processor_message_levels (messages_tests.test_cookie.CookieTests) ... ok\ntest_cookie_setings (messages_tests.test_cookie.CookieTests) ... ok\ntest_custom_tags (messages_tests.test_cookie.CookieTests) ... ok\ntest_default_level (messages_tests.test_cookie.CookieTests) ... ok\ntest_existing_add (messages_tests.test_cookie.CookieTests) ... ok\ntest_existing_add_read_update (messages_tests.test_cookie.CookieTests) ... ok\ntest_existing_read (messages_tests.test_cookie.CookieTests) ... ok\ntest_existing_read_add_update (messages_tests.test_cookie.CookieTests) ... ok\ntest_full_request_response_cycle (messages_tests.test_cookie.CookieTests) ... ok\ntest_get (messages_tests.test_cookie.CookieTests) ... ok\ntest_get_bad_cookie (messages_tests.test_cookie.CookieTests) ... ok\ntest_high_level (messages_tests.test_cookie.CookieTests) ... ok\ntest_json_encoder_decoder (messages_tests.test_cookie.CookieTests) ... ok\ntest_legacy_hash_decode (messages_tests.test_cookie.CookieTests) ... ok\ntest_level_tag (messages_tests.test_cookie.CookieTests) ... ok\ntest_low_level (messages_tests.test_cookie.CookieTests) ... ok\ntest_max_cookie_length (messages_tests.test_cookie.CookieTests) ... ok\ntest_middleware_disabled (messages_tests.test_cookie.CookieTests) ... ok\ntest_middleware_disabled_fail_silently (messages_tests.test_cookie.CookieTests) ... ok\ntest_multiple_posts (messages_tests.test_cookie.CookieTests) ... ok\ntest_no_update (messages_tests.test_cookie.CookieTests) ... ok\ntest_safedata (messages_tests.test_cookie.CookieTests) ... ok\ntest_settings_level (messages_tests.test_cookie.CookieTests) ... ok\ntest_tags (messages_tests.test_cookie.CookieTests) ... ok\ntest_with_template_response (messages_tests.test_cookie.CookieTests) ... ok\n\n----------------------------------------------------------------------\nRan 416 tests in 0.313s\n\nOK (skipped=2, expected failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/messages_tests/test_cookie.py",
            "tests/responses/test_cookie.py",
            "tests/sessions_tests/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-13279",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.41.233.120:8080",
      "duration": 14.976078271865845,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 383,
          "failed": 1,
          "errors": 0,
          "duration": 7.1,
          "log_tail": "    self.assertEqual(self.session._legacy_decode(encoded), data)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1121, in assertDictEqual\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: {} != {'a test key': 'a test value'}\n- {}\n+ {'a test key': 'a test value'}\n\n======================================================================\nFAIL: test_default_hashing_algorith_legacy_decode (sessions_tests.tests.CustomDatabaseSessionTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/django/test/utils.py\", line 381, in inner\n    return func(*args, **kwargs)\n  File \"/testbed/tests/sessions_tests/tests.py\", line 333, in test_default_hashing_algorith_legacy_decode\n    self.assertEqual(self.session._legacy_decode(encoded), data)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1121, in assertDictEqual\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: {} != {'a test key': 'a test value'}\n- {}\n+ {'a test key': 'a test value'}\n\n----------------------------------------------------------------------\nRan 384 tests in 0.300s\n\nFAILED (failures=9, skipped=2, expected failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 sessions_tests.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/sessions_tests/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 384,
          "failed": 0,
          "errors": 0,
          "duration": 7.06,
          "log_tail": "test_delete (sessions_tests.tests.CustomDatabaseSessionTests) ... ok\ntest_extra_session_field (sessions_tests.tests.CustomDatabaseSessionTests) ... ok\ntest_flush (sessions_tests.tests.CustomDatabaseSessionTests) ... ok\ntest_get_empty (sessions_tests.tests.CustomDatabaseSessionTests) ... ok\ntest_get_expire_at_browser_close (sessions_tests.tests.CustomDatabaseSessionTests) ... ok\ntest_has_key (sessions_tests.tests.CustomDatabaseSessionTests) ... ok\ntest_invalid_key (sessions_tests.tests.CustomDatabaseSessionTests) ... ok\ntest_items (sessions_tests.tests.CustomDatabaseSessionTests) ... ok\ntest_keys (sessions_tests.tests.CustomDatabaseSessionTests) ... ok\ntest_new_session (sessions_tests.tests.CustomDatabaseSessionTests) ... ok\ntest_pop (sessions_tests.tests.CustomDatabaseSessionTests) ... ok\ntest_pop_default (sessions_tests.tests.CustomDatabaseSessionTests) ... ok\ntest_pop_default_named_argument (sessions_tests.tests.CustomDatabaseSessionTests) ... ok\ntest_pop_no_default_keyerror_raised (sessions_tests.tests.CustomDatabaseSessionTests) ... ok\ntest_save (sessions_tests.tests.CustomDatabaseSessionTests) ... ok\ntest_save_doesnt_clear_data (sessions_tests.tests.CustomDatabaseSessionTests) ... ok\ntest_session_get_decoded (sessions_tests.tests.CustomDatabaseSessionTests) ... ok\ntest_session_key_empty_string_invalid (sessions_tests.tests.CustomDatabaseSessionTests)\nFalsey values (Such as an empty string) are rejected. ... ok\ntest_session_key_is_read_only (sessions_tests.tests.CustomDatabaseSessionTests) ... ok\ntest_session_key_too_short_invalid (sessions_tests.tests.CustomDatabaseSessionTests)\nStrings shorter than 8 characters are rejected. ... ok\ntest_session_key_valid_string_saved (sessions_tests.tests.CustomDatabaseSessionTests)\nStrings of length 8 and up are accepted and stored. ... ok\ntest_session_load_does_not_create_record (sessions_tests.tests.CustomDatabaseSessionTests) ... ok\ntest_session_save_does_not_resurrect_session_logged_out_in_other_context (sessions_tests.tests.CustomDatabaseSessionTests) ... ok\ntest_session_str (sessions_tests.tests.CustomDatabaseSessionTests)\nSession repr should be the session key. ... ok\ntest_sessionmanager_save (sessions_tests.tests.CustomDatabaseSessionTests) ... ok\ntest_setdefault (sessions_tests.tests.CustomDatabaseSessionTests) ... ok\ntest_store (sessions_tests.tests.CustomDatabaseSessionTests) ... ok\ntest_update (sessions_tests.tests.CustomDatabaseSessionTests) ... ok\ntest_values (sessions_tests.tests.CustomDatabaseSessionTests) ... ok\n\n----------------------------------------------------------------------\nRan 384 tests in 0.205s\n\nOK (skipped=2, expected failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/sessions_tests/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-12325",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10ce3ef60>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 1
    },
    {
      "instance_id": "django__django-13315",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 17.63601589202881,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 148,
          "failed": 1,
          "errors": 0,
          "duration": 9.36,
          "log_tail": "test_subset_fields (model_forms.tests.ModelFormBasicTests) ... ok\ntest_validate_foreign_key_to_model_with_overridden_manager (model_forms.tests.ModelFormBasicTests) ... ok\ntest_validate_foreign_key_uses_default_manager (model_forms.tests.ModelFormBasicTests) ... ok\n\n======================================================================\nFAIL: test_limit_choices_to_no_duplicates (model_forms.tests.LimitChoicesToTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/django/test/utils.py\", line 382, in inner\n    return func(*args, **kwargs)\n  File \"/testbed/tests/model_forms/tests.py\", line 2888, in test_limit_choices_to_no_duplicates\n    [self.marley, self.threepwood],\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1183, in assertCountEqual\n    self.fail(msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: Element counts were not equal:\nFirst has 4, Second has 1:  <Character: threepwood>\nFirst has 3, Second has 1:  <Character: marley>\n\n----------------------------------------------------------------------\nRan 149 tests in 0.318s\n\nFAILED (failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 model_forms.models model_forms.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/model_forms/models.py",
            "tests/model_forms/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 149,
          "failed": 0,
          "errors": 0,
          "duration": 7.45,
          "log_tail": "test_http_prefixing (model_forms.tests.ModelOtherFieldTests) ... ok\ntest_modelform_non_editable_field (model_forms.tests.ModelOtherFieldTests) ... ok\ntest_url_on_modelform (model_forms.tests.ModelOtherFieldTests)\nCheck basic URL field validation on model forms ... ok\ntest_error_messages_overrides (model_forms.tests.TestFieldOverridesByFormMeta) ... ok\ntest_field_type_overrides (model_forms.tests.TestFieldOverridesByFormMeta) ... ok\ntest_help_text_overrides (model_forms.tests.TestFieldOverridesByFormMeta) ... ok\ntest_label_overrides (model_forms.tests.TestFieldOverridesByFormMeta) ... ok\ntest_widget_overrides (model_forms.tests.TestFieldOverridesByFormMeta) ... ok\ntest_auto_id (model_forms.tests.ModelFormBasicTests) ... ok\ntest_base_form (model_forms.tests.ModelFormBasicTests) ... ok\ntest_basic_creation (model_forms.tests.ModelFormBasicTests) ... ok\ntest_custom_form_fields (model_forms.tests.ModelFormBasicTests) ... ok\ntest_initial_values (model_forms.tests.ModelFormBasicTests) ... ok\ntest_m2m_editing (model_forms.tests.ModelFormBasicTests) ... ok\ntest_m2m_initial_callable (model_forms.tests.ModelFormBasicTests) ... ok\ntest_multi_fields (model_forms.tests.ModelFormBasicTests) ... ok\ntest_recleaning_model_form_instance (model_forms.tests.ModelFormBasicTests) ... ok\ntest_runtime_choicefield_populated (model_forms.tests.ModelFormBasicTests) ... ok\ntest_save_commit_false (model_forms.tests.ModelFormBasicTests) ... ok\ntest_save_with_data_errors (model_forms.tests.ModelFormBasicTests) ... ok\ntest_subset_fields (model_forms.tests.ModelFormBasicTests) ... ok\ntest_validate_foreign_key_to_model_with_overridden_manager (model_forms.tests.ModelFormBasicTests) ... ok\ntest_validate_foreign_key_uses_default_manager (model_forms.tests.ModelFormBasicTests) ... ok\n\n----------------------------------------------------------------------\nRan 149 tests in 0.313s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/model_forms/models.py",
            "tests/model_forms/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-13343",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 18.92951202392578,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 134,
          "failed": 1,
          "errors": 0,
          "duration": 10.06,
          "log_tail": "test_file_save_with_path (file_storage.tests.CustomStorageTests) ... ok\ntest_file_save_without_name (file_storage.tests.CustomStorageTests) ... ok\ntest_file_storage_preserves_filename_case (file_storage.tests.CustomStorageTests)\nThe storage backend should preserve case of filenames. ... ok\ntest_file_storage_prevents_directory_traversal (file_storage.tests.CustomStorageTests) ... ok\ntest_file_url (file_storage.tests.CustomStorageTests) ... ok\ntest_listdir (file_storage.tests.CustomStorageTests) ... ok\ntest_makedirs_race_handling (file_storage.tests.CustomStorageTests) ... ok\ntest_remove_race_handling (file_storage.tests.CustomStorageTests) ... ok\ntest_save_doesnt_close (file_storage.tests.CustomStorageTests) ... ok\ntest_setting_changed (file_storage.tests.CustomStorageTests) ... ok\ntest_urllib_request_urlopen (file_storage.tests.FileLikeObjectTestCase) ... ok\ntest_race_condition (file_storage.tests.FileSaveRaceConditionTest) ... ok\n\n======================================================================\nFAIL: test_deconstruction (file_storage.tests.FieldCallableFileStorageTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/file_storage/tests.py\", line 924, in test_deconstruction\n    self.assertIs(storage, callable_storage)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1103, in assertIs\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: <django.core.files.storage.FileSystemStorage object at 0x7410731bdc88> is not <function callable_storage at 0x7410734d3bf8>\n\n----------------------------------------------------------------------\nRan 135 tests in 1.212s\n\nFAILED (failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 file_storage.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/file_storage/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 135,
          "failed": 0,
          "errors": 0,
          "duration": 8.0,
          "log_tail": "test_setting_changed (file_storage.tests.FileStorageTests) ... ok\ntest_base_url (file_storage.tests.OverwritingStorageTests) ... ok\ntest_delete_deletes_directories (file_storage.tests.OverwritingStorageTests) ... ok\ntest_delete_no_name (file_storage.tests.OverwritingStorageTests) ... ok\ntest_empty_location (file_storage.tests.OverwritingStorageTests) ... ok\ntest_file_access_options (file_storage.tests.OverwritingStorageTests) ... ok\ntest_file_chunks_error (file_storage.tests.OverwritingStorageTests) ... ok\ntest_file_get_accessed_time (file_storage.tests.OverwritingStorageTests) ... ok\ntest_file_get_accessed_time_timezone (file_storage.tests.OverwritingStorageTests) ... ok\ntest_file_get_created_time (file_storage.tests.OverwritingStorageTests) ... ok\ntest_file_get_created_time_timezone (file_storage.tests.OverwritingStorageTests) ... ok\ntest_file_get_modified_time (file_storage.tests.OverwritingStorageTests) ... ok\ntest_file_get_modified_time_timezone (file_storage.tests.OverwritingStorageTests) ... ok\ntest_file_methods_pathlib_path (file_storage.tests.OverwritingStorageTests) ... ok\ntest_file_path (file_storage.tests.OverwritingStorageTests) ... ok\ntest_file_save_with_path (file_storage.tests.OverwritingStorageTests) ... ok\ntest_file_save_without_name (file_storage.tests.OverwritingStorageTests) ... ok\ntest_file_storage_preserves_filename_case (file_storage.tests.OverwritingStorageTests)\nThe storage backend should preserve case of filenames. ... ok\ntest_file_storage_prevents_directory_traversal (file_storage.tests.OverwritingStorageTests) ... ok\ntest_file_url (file_storage.tests.OverwritingStorageTests) ... ok\ntest_listdir (file_storage.tests.OverwritingStorageTests) ... ok\ntest_makedirs_race_handling (file_storage.tests.OverwritingStorageTests) ... ok\ntest_remove_race_handling (file_storage.tests.OverwritingStorageTests) ... ok\ntest_save_doesnt_close (file_storage.tests.OverwritingStorageTests) ... ok\ntest_save_overwrite_behavior (file_storage.tests.OverwritingStorageTests)\nSaving to same file name twice overwrites the first file. ... ok\ntest_setting_changed (file_storage.tests.OverwritingStorageTests) ... ok\ntest_urllib_request_urlopen (file_storage.tests.FileLikeObjectTestCase) ... ok\ntest_race_condition (file_storage.tests.FileSaveRaceConditionTest) ... ok\n\n----------------------------------------------------------------------\nRan 135 tests in 1.206s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/file_storage/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-13012",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10cf2e1b0>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 1
    },
    {
      "instance_id": "django__django-13346",
      "repo": "django/django",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 17.025705814361572,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 66,
          "failed": 9,
          "errors": 0,
          "duration": 8.98,
          "log_tail": "  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1010, in assertSequenceEqual\n    self.fail(msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: Sequences differ: <QuerySet []> != [<NullableJSONModel: NullableJSONModel object (8)>]\n\nSecond sequence contains 1 additional elements.\nFirst extra element 0:\n<NullableJSONModel: NullableJSONModel object (8)>\n\n- <QuerySet []>\n+ [<NullableJSONModel: NullableJSONModel object (8)>]\n\n======================================================================\nFAIL: test_key_in (model_fields.test_jsonfield.TestQuerying) [<object object at 0x7787b9f78c90>] (lookup='value__bax__in', value=[{'foo': 'bar'}, {'a': 'b'}])\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 523, in subTest\n    yield\n  File \"/testbed/tests/model_fields/test_jsonfield.py\", line 646, in test_key_in\n    expected,\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1010, in assertSequenceEqual\n    self.fail(msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: Sequences differ: <QuerySet []> != [<NullableJSONModel: NullableJSONModel object (8)>]\n\nSecond sequence contains 1 additional elements.\nFirst extra element 0:\n<NullableJSONModel: NullableJSONModel object (8)>\n\n- <QuerySet []>\n+ [<NullableJSONModel: NullableJSONModel object (8)>]\n\n----------------------------------------------------------------------\nRan 75 tests in 0.311s\n\nFAILED (failures=9, skipped=8)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 model_fields.test_jsonfield` failed. (See above for error)",
          "test_files_run": [
            "tests/model_fields/test_jsonfield.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 75,
          "failed": 0,
          "errors": 0,
          "duration": 7.23,
          "log_tail": "test_has_key_deep (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_has_key_list (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_has_key_null_value (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_has_keys (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_isnull (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_isnull_key (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_isnull_key_or_none (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_key_contains (model_fields.test_jsonfield.TestQuerying) ... skipped \"Database doesn't support feature(s): supports_json_field_contains\"\ntest_key_endswith (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_key_escape (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_key_icontains (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_key_iendswith (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_key_iexact (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_key_in (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_key_iregex (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_key_istartswith (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_key_regex (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_key_sql_injection (model_fields.test_jsonfield.TestQuerying) ... skipped \"Database doesn't support feature(s): has_json_operators\"\ntest_key_sql_injection_escape (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_key_startswith (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_key_transform_expression (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_key_transform_raw_expression (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_lookups_with_key_transform (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_nested_key_transform_expression (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_nested_key_transform_raw_expression (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_none_key (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_none_key_and_exact_lookup (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_none_key_exclude (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_obj_subquery_lookup (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_ordering_by_transform (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_ordering_grouping_by_count (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_ordering_grouping_by_key_transform (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_shallow_list_lookup (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_shallow_lookup_obj_target (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_shallow_obj_lookup (model_fields.test_jsonfield.TestQuerying) ... ok\ntest_usage_in_subquery (model_fields.test_jsonfield.TestQuerying) ... ok\n\n----------------------------------------------------------------------\nRan 75 tests in 0.211s\n\nOK (skipped=8)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/model_fields/test_jsonfield.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-13363",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.59.30.169:8080",
      "duration": 15.096932172775269,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 78,
          "failed": 1,
          "errors": 0,
          "duration": 7.14,
          "log_tail": "test_extract_week_func_boundaries (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_weekday_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_year_exact_lookup (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_year_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_year_greaterthan_lookup (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_year_lessthan_lookup (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_ambiguous_and_invalid_times (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_date_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_date_none (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_day_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_func_with_timezone (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_hour_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_minute_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_month_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_none (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_quarter_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_second_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_subquery_with_parameters (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_time_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_time_none (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_timezone_applied_before_truncation (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... FAIL\ntest_trunc_week_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_year_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\n\n======================================================================\nFAIL: test_trunc_timezone_applied_before_truncation (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/db_functions/datetime/test_extract_trunc.py\", line 1142, in test_trunc_timezone_applied_before_truncation\n    self.assertEqual(model.pacific_date, pacific_start_datetime.date())\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 822, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: datetime.date(2016, 1, 1) != datetime.date(2015, 12, 31)\n\n----------------------------------------------------------------------\nRan 79 tests in 0.300s\n\nFAILED (failures=1, skipped=2)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 db_functions.datetime.test_extract_trunc` failed. (See above for error)",
          "test_files_run": [
            "tests/db_functions/datetime/test_extract_trunc.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 79,
          "failed": 0,
          "errors": 0,
          "duration": 7.14,
          "log_tail": "test_extract_duration (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... skipped \"Database doesn't support feature(s): has_native_duration_field\"\ntest_extract_duration_unsupported_lookups (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_duration_without_native_duration_field (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_func_explicit_timezone_priority (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_func_with_timezone (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_hour_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_iso_weekday_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_iso_year_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_iso_year_func_boundaries (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_minute_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_month_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_none (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_quarter_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_quarter_func_boundaries (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_second_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_week_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_week_func_boundaries (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_weekday_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_year_exact_lookup (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_year_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_year_greaterthan_lookup (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_extract_year_lessthan_lookup (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_ambiguous_and_invalid_times (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_date_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_date_none (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_day_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_func_with_timezone (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_hour_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_minute_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_month_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_none (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_quarter_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_second_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_subquery_with_parameters (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_time_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_time_none (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_timezone_applied_before_truncation (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_week_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\ntest_trunc_year_func (db_functions.datetime.test_extract_trunc.DateFunctionWithTimeZoneTests) ... ok\n\n----------------------------------------------------------------------\nRan 79 tests in 0.302s\n\nOK (skipped=2)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/db_functions/datetime/test_extract_trunc.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-13401",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.70.1.155:8080",
      "duration": 16.945735931396484,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 32,
          "failed": 1,
          "errors": 0,
          "duration": 8.89,
          "log_tail": "test_deconstruct_nested_field (model_fields.tests.BasicFieldTests)\ndeconstruct() uses __qualname__ for nested class support. ... ok\ntest_field_instance_is_picklable (model_fields.tests.BasicFieldTests)\nField instances can be pickled. ... ok\ntest_field_name (model_fields.tests.BasicFieldTests) ... ok\ntest_field_ordering (model_fields.tests.BasicFieldTests)\nFields are ordered based on their creation. ... ok\ntest_field_repr (model_fields.tests.BasicFieldTests) ... ok\ntest_field_repr_nested (model_fields.tests.BasicFieldTests)\n__repr__() uses __qualname__ for nested class support. ... ok\ntest_field_str (model_fields.tests.BasicFieldTests) ... ok\ntest_field_verbose_name (model_fields.tests.BasicFieldTests) ... ok\ntest_formfield_disabled (model_fields.tests.BasicFieldTests)\nField.formfield() sets disabled for fields with choices. ... ok\ntest_show_hidden_initial (model_fields.tests.BasicFieldTests) ... ok\ntest_get_choices (model_fields.tests.GetChoicesLimitChoicesToTests) ... ok\ntest_get_choices_reverse_related_field (model_fields.tests.GetChoicesLimitChoicesToTests) ... ok\ntest_get_choices (model_fields.tests.GetChoicesOrderingTests) ... ok\ntest_get_choices_default_ordering (model_fields.tests.GetChoicesOrderingTests) ... ok\ntest_get_choices_reverse_related_field (model_fields.tests.GetChoicesOrderingTests) ... ok\ntest_get_choices_reverse_related_field_default_ordering (model_fields.tests.GetChoicesOrderingTests) ... ok\n\n======================================================================\nFAIL: test_abstract_inherited_fields (model_fields.tests.BasicFieldTests)\nField instances from abstract models are not equal.\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/model_fields/tests.py\", line 123, in test_abstract_inherited_fields\n    self.assertNotEqual(abstract_model_field, inherit1_model_field)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 838, in assertNotEqual\n    raise self.failureException(msg)\nAssertionError: <django.db.models.fields.IntegerField: field> == <django.db.models.fields.IntegerField: field>\n\n----------------------------------------------------------------------\nRan 33 tests in 0.209s\n\nFAILED (failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 model_fields.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/model_fields/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 33,
          "failed": 0,
          "errors": 0,
          "duration": 7.21,
          "log_tail": "test_check (model_fields.tests.ChoicesTests) ... ok\ntest_choices (model_fields.tests.ChoicesTests) ... ok\ntest_flatchoices (model_fields.tests.ChoicesTests) ... ok\ntest_formfield (model_fields.tests.ChoicesTests) ... ok\ntest_invalid_choice (model_fields.tests.ChoicesTests) ... ok\ntest_choices_and_field_display (model_fields.tests.GetFieldDisplayTests) ... ok\ntest_empty_iterator_choices (model_fields.tests.GetFieldDisplayTests) ... ok\ntest_get_FIELD_display_translated (model_fields.tests.GetFieldDisplayTests)\nA translated display value is coerced to str. ... ok\ntest_iterator_choices (model_fields.tests.GetFieldDisplayTests) ... ok\ntest_overriding_FIELD_display (model_fields.tests.GetFieldDisplayTests) ... ok\ntest_overriding_inherited_FIELD_display (model_fields.tests.GetFieldDisplayTests) ... ok\ntest_abstract_inherited_fields (model_fields.tests.BasicFieldTests)\nField instances from abstract models are not equal. ... ok\ntest_choices_form_class (model_fields.tests.BasicFieldTests)\nCan supply a custom choices form class to Field.formfield() ... ok\ntest_deconstruct_nested_field (model_fields.tests.BasicFieldTests)\ndeconstruct() uses __qualname__ for nested class support. ... ok\ntest_field_instance_is_picklable (model_fields.tests.BasicFieldTests)\nField instances can be pickled. ... ok\ntest_field_name (model_fields.tests.BasicFieldTests) ... ok\ntest_field_ordering (model_fields.tests.BasicFieldTests)\nFields are ordered based on their creation. ... ok\ntest_field_repr (model_fields.tests.BasicFieldTests) ... ok\ntest_field_repr_nested (model_fields.tests.BasicFieldTests)\n__repr__() uses __qualname__ for nested class support. ... ok\ntest_field_str (model_fields.tests.BasicFieldTests) ... ok\ntest_field_verbose_name (model_fields.tests.BasicFieldTests) ... ok\ntest_formfield_disabled (model_fields.tests.BasicFieldTests)\nField.formfield() sets disabled for fields with choices. ... ok\ntest_show_hidden_initial (model_fields.tests.BasicFieldTests) ... ok\ntest_get_choices (model_fields.tests.GetChoicesLimitChoicesToTests) ... ok\ntest_get_choices_reverse_related_field (model_fields.tests.GetChoicesLimitChoicesToTests) ... ok\ntest_get_choices (model_fields.tests.GetChoicesOrderingTests) ... ok\ntest_get_choices_default_ordering (model_fields.tests.GetChoicesOrderingTests) ... ok\ntest_get_choices_reverse_related_field (model_fields.tests.GetChoicesOrderingTests) ... ok\ntest_get_choices_reverse_related_field_default_ordering (model_fields.tests.GetChoicesOrderingTests) ... ok\n\n----------------------------------------------------------------------\nRan 33 tests in 0.211s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/model_fields/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-13410",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.123.9.23:8080",
      "duration": 16.705177068710327,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 40,
          "failed": 2,
          "errors": 0,
          "duration": 8.74,
          "log_tail": "test_shared_lock (files.tests.FileTests) ... FAIL\ntest_unicode_file_name (files.tests.FileTests) ... ok\ntest_unicode_uploadedfile_name (files.tests.FileTests) ... ok\ntest_writable (files.tests.FileTests) ... ok\ntest_closing_of_filenames (files.tests.DimensionClosingBug) ... ok\ntest_not_closing_of_files (files.tests.DimensionClosingBug) ... ok\ntest_bug_19457 (files.tests.InconsistentGetImageDimensionsBug) ... ok\ntest_multiple_calls (files.tests.InconsistentGetImageDimensionsBug) ... ok\ntest_invalid_image (files.tests.GetImageDimensionsTests) ... ok\ntest_valid_image (files.tests.GetImageDimensionsTests) ... ok\ntest_webp (files.tests.GetImageDimensionsTests) ... ok\n\n======================================================================\nFAIL: test_exclusive_lock (files.tests.FileTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/files/tests.py\", line 175, in test_exclusive_lock\n    self.assertIs(locks.lock(f1, locks.LOCK_EX), True)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1103, in assertIs\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: False is not True\n\n======================================================================\nFAIL: test_shared_lock (files.tests.FileTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/files/tests.py\", line 183, in test_shared_lock\n    self.assertIs(locks.lock(f1, locks.LOCK_SH), True)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1103, in assertIs\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: False is not True\n\n----------------------------------------------------------------------\nRan 42 tests in 0.201s\n\nFAILED (failures=2)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 files.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/files/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 42,
          "failed": 0,
          "errors": 0,
          "duration": 7.1,
          "log_tail": "test_content_file_custom_name (files.tests.ContentFileTestCase) ... ok\ntest_content_file_default_name (files.tests.ContentFileTestCase) ... ok\ntest_content_file_input_type (files.tests.ContentFileTestCase) ... ok\ntest_open_resets_file_to_start_and_returns_context_manager (files.tests.ContentFileTestCase) ... ok\ntest_size_changing_after_writing (files.tests.ContentFileTestCase)\nContentFile.size changes after a write(). ... ok\ntest_open_resets_file_to_start_and_returns_context_manager (files.tests.InMemoryUploadedFileTests) ... ok\ntest_noname_file_default_name (files.tests.NoNameFileTestCase) ... ok\ntest_noname_file_get_size (files.tests.NoNameFileTestCase) ... ok\ntest_in_memory_spooled_temp (files.tests.SpooledTempTests) ... ok\ntest_written_spooled_temp (files.tests.SpooledTempTests) ... ok\ntest_file_move_copystat_cifs (files.tests.FileMoveSafeTests) ... ok\ntest_file_move_overwrite (files.tests.FileMoveSafeTests) ... ok\ntest_extension_kept (files.tests.TemporaryUploadedFileTests)\nThe temporary file name has the same suffix as the original file. ... ok\ntest_file_upload_temp_dir_pathlib (files.tests.TemporaryUploadedFileTests) ... ok\ntest_context_manager (files.tests.FileTests) ... ok\ntest_exclusive_lock (files.tests.FileTests) ... ok\ntest_file_iteration (files.tests.FileTests) ... ok\ntest_file_iteration_mac_newlines (files.tests.FileTests) ... ok\ntest_file_iteration_mixed_newlines (files.tests.FileTests) ... ok\ntest_file_iteration_windows_newlines (files.tests.FileTests) ... ok\ntest_file_iteration_with_mac_newline_at_chunk_boundary (files.tests.FileTests) ... ok\ntest_file_iteration_with_text (files.tests.FileTests) ... ok\ntest_file_iteration_with_unix_newline_at_chunk_boundary (files.tests.FileTests) ... ok\ntest_file_iteration_with_windows_newline_at_chunk_boundary (files.tests.FileTests) ... ok\ntest_file_mode (files.tests.FileTests) ... ok\ntest_io_wrapper (files.tests.FileTests) ... ok\ntest_namedtemporaryfile_closes (files.tests.FileTests) ... ok\ntest_open_reopens_closed_file_and_returns_context_manager (files.tests.FileTests) ... ok\ntest_open_resets_opened_file_to_start_and_returns_context_manager (files.tests.FileTests) ... ok\ntest_readable (files.tests.FileTests) ... ok\ntest_seekable (files.tests.FileTests) ... ok\ntest_shared_lock (files.tests.FileTests) ... ok\ntest_unicode_file_name (files.tests.FileTests) ... ok\ntest_unicode_uploadedfile_name (files.tests.FileTests) ... ok\ntest_writable (files.tests.FileTests) ... ok\ntest_closing_of_filenames (files.tests.DimensionClosingBug) ... ok\ntest_not_closing_of_files (files.tests.DimensionClosingBug) ... ok\ntest_bug_19457 (files.tests.InconsistentGetImageDimensionsBug) ... ok\ntest_multiple_calls (files.tests.InconsistentGetImageDimensionsBug) ... ok\ntest_invalid_image (files.tests.GetImageDimensionsTests) ... ok\ntest_valid_image (files.tests.GetImageDimensionsTests) ... ok\ntest_webp (files.tests.GetImageDimensionsTests) ... ok\n\n----------------------------------------------------------------------\nRan 42 tests in 0.200s\n\nOK\n",
          "test_files_run": [
            "tests/files/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-13112",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10cf2c080>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 1
    },
    {
      "instance_id": "django__django-13417",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.70.1.155:8080",
      "duration": 16.45784020423889,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 286,
          "failed": 2,
          "errors": 0,
          "duration": 7.83,
          "log_tail": "Destroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 queries.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/queries/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 288,
          "failed": 0,
          "errors": 0,
          "duration": 7.81,
          "log_tail": "Destroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/queries/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-13449",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.123.9.23:8080",
      "duration": 16.955200910568237,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 49,
          "failed": 0,
          "errors": 1,
          "duration": 8.91,
          "log_tail": "Traceback (most recent call last):\n  File \"/testbed/django/db/backends/utils.py\", line 84, in _execute\n    return self.cursor.execute(sql, params)\n  File \"/testbed/django/db/backends/sqlite3/base.py\", line 412, in execute\n    return Database.Cursor.execute(self, query, params)\nsqlite3.OperationalError: near \"OVER\": syntax error\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/expressions_window/tests.py\", line 232, in test_lag_decimalfield\n    ], transform=lambda row: (row.name, row.bonus, row.department, row.lag))\n  File \"/testbed/django/test/testcases.py\", line 1044, in assertQuerysetEqual\n    items = map(transform, qs)\n  File \"/testbed/django/db/models/query.py\", line 280, in __iter__\n    self._fetch_all()\n  File \"/testbed/django/db/models/query.py\", line 1303, in _fetch_all\n    self._result_cache = list(self._iterable_class(self))\n  File \"/testbed/django/db/models/query.py\", line 51, in __iter__\n    results = compiler.execute_sql(chunked_fetch=self.chunked_fetch, chunk_size=self.chunk_size)\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1160, in execute_sql\n    cursor.execute(sql, params)\n  File \"/testbed/django/db/backends/utils.py\", line 66, in execute\n    return self._execute_with_wrappers(sql, params, many=False, executor=self._execute)\n  File \"/testbed/django/db/backends/utils.py\", line 75, in _execute_with_wrappers\n    return executor(sql, params, many, context)\n  File \"/testbed/django/db/backends/utils.py\", line 84, in _execute\n    return self.cursor.execute(sql, params)\n  File \"/testbed/django/db/utils.py\", line 90, in __exit__\n    raise dj_exc_value.with_traceback(traceback) from exc_value\n  File \"/testbed/django/db/backends/utils.py\", line 84, in _execute\n    return self.cursor.execute(sql, params)\n  File \"/testbed/django/db/backends/sqlite3/base.py\", line 412, in execute\n    return Database.Cursor.execute(self, query, params)\ndjango.db.utils.OperationalError: near \"OVER\": syntax error\n\n----------------------------------------------------------------------\nRan 50 tests in 0.206s\n\nFAILED (errors=1, skipped=3)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 expressions_window.models expressions_window.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/expressions_window/models.py",
            "tests/expressions_window/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 50,
          "failed": 0,
          "errors": 0,
          "duration": 7.16,
          "log_tail": "test_distinct_window_function (expressions_window.tests.WindowFunctionTests) ... skipped \"Database doesn't support feature(s): can_distinct_on_fields\"\ntest_fail_insert (expressions_window.tests.WindowFunctionTests)\nWindow expressions can't be used in an INSERT statement. ... ok\ntest_fail_update (expressions_window.tests.WindowFunctionTests)\nWindow expressions can't be used in an UPDATE statement. ... ok\ntest_first_value (expressions_window.tests.WindowFunctionTests) ... ok\ntest_function_list_of_values (expressions_window.tests.WindowFunctionTests) ... ok\ntest_invalid_end_value_range (expressions_window.tests.WindowFunctionTests) ... ok\ntest_invalid_start_value_range (expressions_window.tests.WindowFunctionTests) ... ok\ntest_invalid_type_end_row_range (expressions_window.tests.WindowFunctionTests) ... ok\ntest_invalid_type_end_value_range (expressions_window.tests.WindowFunctionTests) ... ok\ntest_invalid_type_start_row_range (expressions_window.tests.WindowFunctionTests) ... ok\ntest_invalid_type_start_value_range (expressions_window.tests.WindowFunctionTests) ... ok\ntest_lag (expressions_window.tests.WindowFunctionTests) ... ok\ntest_lag_decimalfield (expressions_window.tests.WindowFunctionTests) ... ok\ntest_last_value (expressions_window.tests.WindowFunctionTests) ... ok\ntest_lead (expressions_window.tests.WindowFunctionTests) ... ok\ntest_lead_default (expressions_window.tests.WindowFunctionTests) ... ok\ntest_lead_offset (expressions_window.tests.WindowFunctionTests) ... ok\ntest_max_per_year (expressions_window.tests.WindowFunctionTests) ... ok\ntest_min_department (expressions_window.tests.WindowFunctionTests)\nAn alternative way to specify a query for FirstValue. ... ok\ntest_multiple_ordering (expressions_window.tests.WindowFunctionTests) ... ok\ntest_multiple_partitioning (expressions_window.tests.WindowFunctionTests) ... ok\ntest_nth_returns_null (expressions_window.tests.WindowFunctionTests) ... ok\ntest_nthvalue (expressions_window.tests.WindowFunctionTests) ... ok\ntest_ntile (expressions_window.tests.WindowFunctionTests) ... ok\ntest_percent_rank (expressions_window.tests.WindowFunctionTests) ... ok\ntest_range_n_preceding_and_following (expressions_window.tests.WindowFunctionTests) ... ok\ntest_range_unbound (expressions_window.tests.WindowFunctionTests)\nA query with RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING. ... ok\ntest_rank (expressions_window.tests.WindowFunctionTests) ... ok\ntest_related_ordering_with_count (expressions_window.tests.WindowFunctionTests) ... ok\ntest_row_number (expressions_window.tests.WindowFunctionTests) ... ok\ntest_row_number_no_ordering (expressions_window.tests.WindowFunctionTests) ... ok\ntest_row_range_rank (expressions_window.tests.WindowFunctionTests) ... ok\ntest_subquery_row_range_rank (expressions_window.tests.WindowFunctionTests) ... ok\ntest_unsupported_range_frame_end (expressions_window.tests.WindowFunctionTests) ... skipped \"Database doesn't support feature(s): only_supports_unbounded_with_preceding_and_following\"\ntest_unsupported_range_frame_start (expressions_window.tests.WindowFunctionTests) ... skipped \"Database doesn't support feature(s): only_supports_unbounded_with_preceding_and_following\"\ntest_window_expression_within_subquery (expressions_window.tests.WindowFunctionTests) ... ok\n\n----------------------------------------------------------------------\nRan 50 tests in 0.202s\n\nOK (skipped=3)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/expressions_window/models.py",
            "tests/expressions_window/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-13344",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.123.9.23:8080",
      "duration": 43.71373724937439,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 483,
          "failed": 4,
          "errors": 0,
          "duration": 22.18,
          "log_tail": "\nFAILED (failures=4, skipped=117)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 cache.tests deprecation.test_middleware_mixin runtests` failed. (See above for error)",
          "test_files_run": [
            "tests/cache/tests.py",
            "tests/deprecation/test_middleware_mixin.py",
            "tests/runtests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 487,
          "failed": 0,
          "errors": 0,
          "duration": 20.7,
          "log_tail": "Ran 487 tests in 13.543s\n\nOK (skipped=117)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\nDestroying test database for alias 'other' ('file:memorydb_other?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/cache/tests.py",
            "tests/deprecation/test_middleware_mixin.py",
            "tests/runtests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-13513",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 18.444703102111816,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 88,
          "failed": 1,
          "errors": 0,
          "duration": 8.71,
          "log_tail": "test_cleanse_setting_recurses_in_dictionary (view_tests.tests.test_debug.ExceptionReporterFilterTests) ... ok\ntest_cleanse_setting_recurses_in_dictionary_with_non_string_key (view_tests.tests.test_debug.ExceptionReporterFilterTests) ... ok\ntest_cleanse_setting_recurses_in_list_tuples (view_tests.tests.test_debug.ExceptionReporterFilterTests) ... ok\ntest_custom_exception_reporter_filter (view_tests.tests.test_debug.ExceptionReporterFilterTests) ... ok\ntest_dict_setting_with_non_str_key (view_tests.tests.test_debug.ExceptionReporterFilterTests) ... ok\ntest_exception_report_uses_meta_filtering (view_tests.tests.test_debug.ExceptionReporterFilterTests) ... ok\ntest_multivalue_dict_key_error (view_tests.tests.test_debug.ExceptionReporterFilterTests) ... ok\ntest_non_sensitive_request (view_tests.tests.test_debug.ExceptionReporterFilterTests) ... ok\ntest_paranoid_request (view_tests.tests.test_debug.ExceptionReporterFilterTests) ... ok\ntest_request_meta_filtering (view_tests.tests.test_debug.ExceptionReporterFilterTests) ... ok\ntest_sensitive_function_arguments (view_tests.tests.test_debug.ExceptionReporterFilterTests) ... ok\ntest_sensitive_function_keyword_arguments (view_tests.tests.test_debug.ExceptionReporterFilterTests) ... ok\ntest_sensitive_method (view_tests.tests.test_debug.ExceptionReporterFilterTests) ... ok\ntest_sensitive_request (view_tests.tests.test_debug.ExceptionReporterFilterTests) ... ok\ntest_sensitive_settings (view_tests.tests.test_debug.ExceptionReporterFilterTests) ... ok\ntest_settings_with_sensitive_keys (view_tests.tests.test_debug.ExceptionReporterFilterTests) ... ok\n\n======================================================================\nFAIL: test_innermost_exception_without_traceback (view_tests.tests.test_debug.ExceptionReporterTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/view_tests/tests/test_debug.py\", line 483, in test_innermost_exception_without_traceback\n    self.assertEqual(len(frames), 1)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 829, in assertEqual\n    assertion_func(first, second, msg=msg)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 822, in _baseAssertEqual\n    raise self.failureException(msg)\nAssertionError: 0 != 1\n\n----------------------------------------------------------------------\nRan 89 tests in 1.711s\n\nFAILED (failures=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 view_tests.tests.test_debug` failed. (See above for error)",
          "test_files_run": [
            "tests/view_tests/tests/test_debug.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 89,
          "failed": 0,
          "errors": 0,
          "duration": 8.81,
          "log_tail": "test_request_and_exception (view_tests.tests.test_debug.ExceptionReporterTests)\nA simple exception report can be generated ... ok\ntest_request_and_message (view_tests.tests.test_debug.ExceptionReporterTests)\nA message can be provided in addition to a request ... ok\ntest_request_with_items_key (view_tests.tests.test_debug.ExceptionReporterTests) ... ok\ntest_sharing_traceback (view_tests.tests.test_debug.ExceptionReporterTests) ... ok\ntest_suppressed_context (view_tests.tests.test_debug.ExceptionReporterTests) ... ok\ntest_template_encoding (view_tests.tests.test_debug.ExceptionReporterTests) ... ok\ntest_too_large_values_handling (view_tests.tests.test_debug.ExceptionReporterTests)\nLarge values should not create a large HTML. ... ok\ntest_unfrozen_importlib (view_tests.tests.test_debug.ExceptionReporterTests) ... ok\ntest_unprintable_values_handling (view_tests.tests.test_debug.ExceptionReporterTests)\nUnprintable values should not make the output generation choke. ... ok\ntest_callable_settings (view_tests.tests.test_debug.ExceptionReporterFilterTests) ... ok\ntest_callable_settings_forbidding_to_set_attributes (view_tests.tests.test_debug.ExceptionReporterFilterTests) ... ok\ntest_cleanse_setting_basic (view_tests.tests.test_debug.ExceptionReporterFilterTests) ... ok\ntest_cleanse_setting_ignore_case (view_tests.tests.test_debug.ExceptionReporterFilterTests) ... ok\ntest_cleanse_setting_recurses_in_dictionary (view_tests.tests.test_debug.ExceptionReporterFilterTests) ... ok\ntest_cleanse_setting_recurses_in_dictionary_with_non_string_key (view_tests.tests.test_debug.ExceptionReporterFilterTests) ... ok\ntest_cleanse_setting_recurses_in_list_tuples (view_tests.tests.test_debug.ExceptionReporterFilterTests) ... ok\ntest_custom_exception_reporter_filter (view_tests.tests.test_debug.ExceptionReporterFilterTests) ... ok\ntest_dict_setting_with_non_str_key (view_tests.tests.test_debug.ExceptionReporterFilterTests) ... ok\ntest_exception_report_uses_meta_filtering (view_tests.tests.test_debug.ExceptionReporterFilterTests) ... ok\ntest_multivalue_dict_key_error (view_tests.tests.test_debug.ExceptionReporterFilterTests) ... ok\ntest_non_sensitive_request (view_tests.tests.test_debug.ExceptionReporterFilterTests) ... ok\ntest_paranoid_request (view_tests.tests.test_debug.ExceptionReporterFilterTests) ... ok\ntest_request_meta_filtering (view_tests.tests.test_debug.ExceptionReporterFilterTests) ... ok\ntest_sensitive_function_arguments (view_tests.tests.test_debug.ExceptionReporterFilterTests) ... ok\ntest_sensitive_function_keyword_arguments (view_tests.tests.test_debug.ExceptionReporterFilterTests) ... ok\ntest_sensitive_method (view_tests.tests.test_debug.ExceptionReporterFilterTests) ... ok\ntest_sensitive_request (view_tests.tests.test_debug.ExceptionReporterFilterTests) ... ok\ntest_sensitive_settings (view_tests.tests.test_debug.ExceptionReporterFilterTests) ... ok\ntest_settings_with_sensitive_keys (view_tests.tests.test_debug.ExceptionReporterFilterTests) ... ok\n\n----------------------------------------------------------------------\nRan 89 tests in 1.707s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/view_tests/tests/test_debug.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-15037",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.44.241.183:8080",
      "duration": 10.3229238986969,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 19,
          "failed": 2,
          "errors": 0,
          "duration": 4.71,
          "log_tail": "Unsupported index types (COALESCE here) are skipped. ... skipped 'PostgreSQL specific SQL'\n\n======================================================================\nFAIL: test_custom_fields (inspectdb.tests.InspectDBTestCase)\nIntrospection of columns with a custom field (#21090)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/tests/inspectdb/tests.py\", line 323, in test_custom_fields\n    self.assertIn(\"text_field = myfields.TextField()\", output)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 1104, in assertIn\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 676, in fail\n    raise self.failureException(msg)\nAssertionError: 'text_field = myfields.TextField()' not found in \"# This is an auto-generated Django model module.\\n# You'll have to do the following manually to clean this up:\\n#   * Rearrange models' order\\n#   * Make sure each model has one field with primary_key=True\\n#   * Make sure each ForeignKey and OneToOneField has `on_delete` set to the desired behavior\\n#   * Remove `managed = False` lines if you wish to allow Django to create, modify, and delete the table\\n# Feel free to rename the models, but don't rename db_table values or field names.\\nfrom django.db import models\\n\\n\\nclass InspectdbColumntypes(models.Model):\\n    id = models.TextField(primary_key=True)  # This field type is a guess.\\n    big_int_field = models.BigIntegerField()\\n    bool_field = models.TextField()  # This field type is a guess.\\n    null_bool_field = models.TextField(blank=True, null=True)  # This field type is a guess.\\n    char_field = models.TextField()  # This field type is a guess.\\n    null_char_field = models.TextField(blank=True, null=True)  # This field type is a guess.\\n    date_field = models.TextField()  # This field type is a guess.\\n    date_time_field = models.TextField()  # This field type is a guess.\\n    decimal_field = models.TextField()  # This field type is a guess.\\n    email_field = models.TextField()  # This field type is a guess.\\n    file_field = models.TextField()  # This field type is a guess.\\n    file_path_field = models.TextField()  # This field type is a guess.\\n    float_field = models.TextField()  # This field type is a guess.\\n    int_field = models.TextField()  # This field type is a guess.\\n    gen_ip_address_field = models.TextField()  # This field type is a guess.\\n    pos_big_int_field = models.TextField()  # This field type is a guess.\\n    pos_int_field = models.TextField()  # This field type is a guess.\\n    pos_small_int_field = models.TextField()  # This field type is a guess.\\n    slug_field = models.TextField()  # This field type is a guess.\\n    small_int_field = models.TextField()  # This field type is a guess.\\n    text_field = models.TextField()  # This field type is a guess.\\n    time_field = models.TextField()  # This field type is a guess.\\n    url_field = models.TextField()  # This field type is a guess.\\n    uuid_field = models.TextField()  # This field type is a guess.\\n\\n    class Meta:\\n        managed = False\\n        db_table = 'inspectdb_columntypes'\\n\"\n\n======================================================================\nFAIL: test_foreign_key_to_field (inspectdb.tests.InspectDBTestCase)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/django/test/testcases.py\", line 1305, in skip_wrapper\n    return test_func(*args, **kwargs)\n  File \"/testbed/tests/inspectdb/tests.py\", line 211, in test_foreign_key_to_field\n    self.assertIn(\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 1104, in assertIn\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 676, in fail\n    raise self.failureException(msg)\nAssertionError: \"to_field_fk = models.ForeignKey('InspectdbPeoplemoredata', models.DO_NOTHING, to_field='people_unique_id')\" not found in \"# This is an auto-generated Django model module.\\n# You'll have to do the following manually to clean this up:\\n#   * Rearrange models' order\\n#   * Make sure each model has one field with primary_key=True\\n#   * Make sure each ForeignKey and OneToOneField has `on_delete` set to the desired behavior\\n#   * Remove `managed = False` lines if you wish to allow Django to create, modify, and delete the table\\n# Feel free to rename the models, but don't rename db_table values or field names.\\nfrom django.db import models\\n\\n\\nclass InspectdbForeignkeytofield(models.Model):\\n    to_field_fk = models.ForeignKey('InspectdbPeoplemoredata', models.DO_NOTHING)\\n\\n    class Meta:\\n        managed = False\\n        db_table = 'inspectdb_foreignkeytofield'\\n\"\n\n----------------------------------------------------------------------\nRan 21 tests in 0.321s\n\nFAILED (failures=2, skipped=4)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 inspectdb.models inspectdb.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/inspectdb/models.py",
            "tests/inspectdb/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 20,
          "failed": 1,
          "errors": 0,
          "duration": 4.74,
          "log_tail": "test_field_types (inspectdb.tests.InspectDBTestCase)\nTest introspection of various Django field types ... ok\ntest_foreign_key_to_field (inspectdb.tests.InspectDBTestCase) ... ok\ntest_introspection_errors (inspectdb.tests.InspectDBTestCase)\nIntrospection errors should not crash the command, and the error should ... ok\ntest_json_field (inspectdb.tests.InspectDBTestCase) ... ok\ntest_managed_models (inspectdb.tests.InspectDBTestCase)\nBy default the command generates models with `Meta.managed = False` (#14305) ... ok\ntest_number_field_types (inspectdb.tests.InspectDBTestCase)\nTest introspection of various Django field types ... ok\ntest_special_column_name_introspection (inspectdb.tests.InspectDBTestCase)\nIntrospection of column names containing special characters, ... ok\ntest_stealth_table_name_filter_option (inspectdb.tests.InspectDBTestCase) ... ok\ntest_table_name_introspection (inspectdb.tests.InspectDBTestCase)\nIntrospection of table names containing special characters, ... ok\ntest_table_option (inspectdb.tests.InspectDBTestCase)\ninspectdb can inspect a subset of tables by passing the table names as ... ok\ntest_text_field_db_collation (inspectdb.tests.InspectDBTestCase) ... ok\ntest_unique_together_meta (inspectdb.tests.InspectDBTestCase) ... ok\ntest_unsupported_unique_together (inspectdb.tests.InspectDBTestCase)\nUnsupported index types (COALESCE here) are skipped. ... skipped 'PostgreSQL specific SQL'\n\n======================================================================\nFAIL: test_custom_fields (inspectdb.tests.InspectDBTestCase)\nIntrospection of columns with a custom field (#21090)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 592, in run\n    self._callTestMethod(testMethod)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n    method()\n  File \"/testbed/tests/inspectdb/tests.py\", line 323, in test_custom_fields\n    self.assertIn(\"text_field = myfields.TextField()\", output)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 1104, in assertIn\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/unittest/case.py\", line 676, in fail\n    raise self.failureException(msg)\nAssertionError: 'text_field = myfields.TextField()' not found in \"# This is an auto-generated Django model module.\\n# You'll have to do the following manually to clean this up:\\n#   * Rearrange models' order\\n#   * Make sure each model has one field with primary_key=True\\n#   * Make sure each ForeignKey and OneToOneField has `on_delete` set to the desired behavior\\n#   * Remove `managed = False` lines if you wish to allow Django to create, modify, and delete the table\\n# Feel free to rename the models, but don't rename db_table values or field names.\\nfrom django.db import models\\n\\n\\nclass InspectdbColumntypes(models.Model):\\n    id = models.TextField(primary_key=True)  # This field type is a guess.\\n    big_int_field = models.BigIntegerField()\\n    bool_field = models.TextField()  # This field type is a guess.\\n    null_bool_field = models.TextField(blank=True, null=True)  # This field type is a guess.\\n    char_field = models.TextField()  # This field type is a guess.\\n    null_char_field = models.TextField(blank=True, null=True)  # This field type is a guess.\\n    date_field = models.TextField()  # This field type is a guess.\\n    date_time_field = models.TextField()  # This field type is a guess.\\n    decimal_field = models.TextField()  # This field type is a guess.\\n    email_field = models.TextField()  # This field type is a guess.\\n    file_field = models.TextField()  # This field type is a guess.\\n    file_path_field = models.TextField()  # This field type is a guess.\\n    float_field = models.TextField()  # This field type is a guess.\\n    int_field = models.TextField()  # This field type is a guess.\\n    gen_ip_address_field = models.TextField()  # This field type is a guess.\\n    pos_big_int_field = models.TextField()  # This field type is a guess.\\n    pos_int_field = models.TextField()  # This field type is a guess.\\n    pos_small_int_field = models.TextField()  # This field type is a guess.\\n    slug_field = models.TextField()  # This field type is a guess.\\n    small_int_field = models.TextField()  # This field type is a guess.\\n    text_field = models.TextField()  # This field type is a guess.\\n    time_field = models.TextField()  # This field type is a guess.\\n    url_field = models.TextField()  # This field type is a guess.\\n    uuid_field = models.TextField()  # This field type is a guess.\\n\\n    class Meta:\\n        managed = False\\n        db_table = 'inspectdb_columntypes'\\n\"\n\n----------------------------------------------------------------------\nRan 21 tests in 0.321s\n\nFAILED (failures=1, skipped=4)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 inspectdb.models inspectdb.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/inspectdb/models.py",
            "tests/inspectdb/tests.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "django__django-13516",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 17.92396092414856,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 43,
          "failed": 1,
          "errors": 0,
          "duration": 9.4,
          "log_tail": "test_command_add_arguments_after_common_arguments (user_commands.tests.CommandTests) ... ok\ntest_command_style (user_commands.tests.CommandTests) ... ok\ntest_create_parser_kwargs (user_commands.tests.CommandTests)\nBaseCommand.create_parser() passes kwargs to CommandParser. ... ok\ntest_discover_commands_in_eggs (user_commands.tests.CommandTests) ... ok\ntest_explode (user_commands.tests.CommandTests)\nAn unknown command raises CommandError ... ok\ntest_find_command_without_PATH (user_commands.tests.CommandTests) ... ok\ntest_language_preserved (user_commands.tests.CommandTests) ... ok\ntest_mutually_exclusive_group_required_const_options (user_commands.tests.CommandTests) ... ok\ntest_mutually_exclusive_group_required_options (user_commands.tests.CommandTests) ... ok\ntest_no_translations_deactivate_translations (user_commands.tests.CommandTests) ... ok\ntest_output_transaction (user_commands.tests.CommandTests) ... ok\ntest_outputwrapper_flush (user_commands.tests.CommandTests) ... FAIL\ntest_required_const_options (user_commands.tests.CommandTests) ... ok\ntest_requires_system_checks_empty (user_commands.tests.CommandTests) ... ok\ntest_requires_system_checks_invalid (user_commands.tests.CommandTests) ... ok\ntest_requires_system_checks_specific (user_commands.tests.CommandTests) ... ok\ntest_subparser (user_commands.tests.CommandTests) ... ok\ntest_subparser_dest_args (user_commands.tests.CommandTests) ... ok\ntest_subparser_dest_required_args (user_commands.tests.CommandTests) ... ok\ntest_subparser_invalid_option (user_commands.tests.CommandTests) ... ok\ntest_system_exit (user_commands.tests.CommandTests)\nException raised in a command should raise CommandError with ... ok\ntest_disallowed_abbreviated_options (user_commands.tests.CommandRunTests) ... ok\ntest_script_prefix_set_in_commands (user_commands.tests.CommandRunTests) ... ok\ntest_skip_checks (user_commands.tests.CommandRunTests) ... ok\n\n======================================================================\nFAIL: test_outputwrapper_flush (user_commands.tests.CommandTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 59, in testPartExecutor\n    yield\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 605, in run\n    testMethod()\n  File \"/testbed/tests/user_commands/tests.py\", line 349, in test_outputwrapper_flush\n    self.assertIs(mocked_flush.called, True)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 1103, in assertIs\n    self.fail(self._formatMessage(msg, standardMsg))\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py\", line 670, in fail\n    raise self.failureException(msg)\nAssertionError: False is not True\n\n----------------------------------------------------------------------\nRan 44 tests in 0.807s\n\nFAILED (failures=1)\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 user_commands.management.commands.outputwrapper user_commands.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/user_commands/management/commands/outputwrapper.py",
            "tests/user_commands/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 44,
          "failed": 0,
          "errors": 0,
          "duration": 7.63,
          "log_tail": "test_get_random_secret_key (user_commands.tests.UtilsTests) ... ok\ntest_is_ignored_path_false (user_commands.tests.UtilsTests) ... ok\ntest_is_ignored_path_true (user_commands.tests.UtilsTests) ... ok\ntest_no_existent_external_program (user_commands.tests.UtilsTests) ... ok\ntest_normalize_path_patterns_truncates_wildcard_base (user_commands.tests.UtilsTests) ... ok\ntest_call_command_no_checks (user_commands.tests.CommandTests) ... ok\ntest_call_command_option_parsing (user_commands.tests.CommandTests) ... ok\ntest_call_command_option_parsing_non_string_arg (user_commands.tests.CommandTests) ... ok\ntest_call_command_unrecognized_option (user_commands.tests.CommandTests) ... ok\ntest_call_command_with_required_parameters_in_mixed_options (user_commands.tests.CommandTests) ... ok\ntest_call_command_with_required_parameters_in_options (user_commands.tests.CommandTests) ... ok\ntest_calling_a_command_with_no_app_labels_and_parameters_should_raise_a_command_error (user_commands.tests.CommandTests) ... ok\ntest_calling_a_command_with_only_empty_parameter_should_ends_gracefully (user_commands.tests.CommandTests) ... ok\ntest_calling_command_with_app_labels_and_parameters_should_be_ok (user_commands.tests.CommandTests) ... ok\ntest_calling_command_with_parameters_and_app_labels_at_the_end_should_be_ok (user_commands.tests.CommandTests) ... ok\ntest_check_migrations (user_commands.tests.CommandTests) ... ok\ntest_command (user_commands.tests.CommandTests) ... ok\ntest_command_add_arguments_after_common_arguments (user_commands.tests.CommandTests) ... ok\ntest_command_style (user_commands.tests.CommandTests) ... ok\ntest_create_parser_kwargs (user_commands.tests.CommandTests)\nBaseCommand.create_parser() passes kwargs to CommandParser. ... ok\ntest_discover_commands_in_eggs (user_commands.tests.CommandTests) ... ok\ntest_explode (user_commands.tests.CommandTests)\nAn unknown command raises CommandError ... ok\ntest_find_command_without_PATH (user_commands.tests.CommandTests) ... ok\ntest_language_preserved (user_commands.tests.CommandTests) ... ok\ntest_mutually_exclusive_group_required_const_options (user_commands.tests.CommandTests) ... ok\ntest_mutually_exclusive_group_required_options (user_commands.tests.CommandTests) ... ok\ntest_no_translations_deactivate_translations (user_commands.tests.CommandTests) ... ok\ntest_output_transaction (user_commands.tests.CommandTests) ... ok\ntest_outputwrapper_flush (user_commands.tests.CommandTests) ... ok\ntest_required_const_options (user_commands.tests.CommandTests) ... ok\ntest_requires_system_checks_empty (user_commands.tests.CommandTests) ... ok\ntest_requires_system_checks_invalid (user_commands.tests.CommandTests) ... ok\ntest_requires_system_checks_specific (user_commands.tests.CommandTests) ... ok\ntest_subparser (user_commands.tests.CommandTests) ... ok\ntest_subparser_dest_args (user_commands.tests.CommandTests) ... ok\ntest_subparser_dest_required_args (user_commands.tests.CommandTests) ... ok\ntest_subparser_invalid_option (user_commands.tests.CommandTests) ... ok\ntest_system_exit (user_commands.tests.CommandTests)\nException raised in a command should raise CommandError with ... ok\ntest_disallowed_abbreviated_options (user_commands.tests.CommandRunTests) ... ok\ntest_script_prefix_set_in_commands (user_commands.tests.CommandRunTests) ... ok\ntest_skip_checks (user_commands.tests.CommandRunTests) ... ok\n\n----------------------------------------------------------------------\nRan 44 tests in 0.796s\n\nOK\n",
          "test_files_run": [
            "tests/user_commands/management/commands/outputwrapper.py",
            "tests/user_commands/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-12096",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://34.44.241.183:8080",
      "duration": 14.529079914093018,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 44,
          "failed": 27,
          "errors": 0,
          "collected": 71,
          "duration": 7.35,
          "log_tail": "sympy/solvers/solveset.py:738\n  /testbed/sympy/solvers/solveset.py:738: DeprecationWarning: invalid escape sequence \\_\n    \"\"\"Solves a given inequality or equation with set as output\n\nsympy/calculus/util.py:458\n  /testbed/sympy/calculus/util.py:458: DeprecationWarning: invalid escape sequence \\l\n    \"\"\"\n\nsympy/solvers/recurr.py:1\n  /testbed/sympy/solvers/recurr.py:1: DeprecationWarning: invalid escape sequence \\l\n    \"\"\"\n\nsympy/solvers/recurr.py:72\n  /testbed/sympy/solvers/recurr.py:72: DeprecationWarning: invalid escape sequence \\o\n    \"\"\"\n\nsympy/solvers/recurr.py:350\n  /testbed/sympy/solvers/recurr.py:350: DeprecationWarning: invalid escape sequence \\o\n    \"\"\"\n\nsympy/solvers/recurr.py:461\n  /testbed/sympy/solvers/recurr.py:461: DeprecationWarning: invalid escape sequence \\o\n    \"\"\"\n\nsympy/solvers/recurr.py:663\n  /testbed/sympy/solvers/recurr.py:663: DeprecationWarning: invalid escape sequence \\o\n    \"\"\"\n\nsympy/calculus/finite_diff.py:420\n  /testbed/sympy/calculus/finite_diff.py:420: DeprecationWarning: invalid escape sequence \\*\n    \"\"\" Differentiate expr and replace Derivatives with finite differences.\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\nsympy/interactive/printing.py:245\n  /testbed/sympy/interactive/printing.py:245: DeprecationWarning: invalid escape sequence \\/\n    \"\"\"\n\nsympy/interactive/session.py:316\n  /testbed/sympy/interactive/session.py:316: DeprecationWarning: invalid escape sequence \\/\n    \"\"\"\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n================== 27 failed, 44 passed, 97 warnings in 0.90s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/utilities/tests/test_lambdify.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/utilities/tests/test_lambdify.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 45,
          "failed": 26,
          "errors": 0,
          "collected": 71,
          "duration": 6.33,
          "log_tail": "sympy/solvers/solveset.py:738\n  /testbed/sympy/solvers/solveset.py:738: DeprecationWarning: invalid escape sequence \\_\n    \"\"\"Solves a given inequality or equation with set as output\n\nsympy/calculus/util.py:458\n  /testbed/sympy/calculus/util.py:458: DeprecationWarning: invalid escape sequence \\l\n    \"\"\"\n\nsympy/solvers/recurr.py:1\n  /testbed/sympy/solvers/recurr.py:1: DeprecationWarning: invalid escape sequence \\l\n    \"\"\"\n\nsympy/solvers/recurr.py:72\n  /testbed/sympy/solvers/recurr.py:72: DeprecationWarning: invalid escape sequence \\o\n    \"\"\"\n\nsympy/solvers/recurr.py:350\n  /testbed/sympy/solvers/recurr.py:350: DeprecationWarning: invalid escape sequence \\o\n    \"\"\"\n\nsympy/solvers/recurr.py:461\n  /testbed/sympy/solvers/recurr.py:461: DeprecationWarning: invalid escape sequence \\o\n    \"\"\"\n\nsympy/solvers/recurr.py:663\n  /testbed/sympy/solvers/recurr.py:663: DeprecationWarning: invalid escape sequence \\o\n    \"\"\"\n\nsympy/calculus/finite_diff.py:420\n  /testbed/sympy/calculus/finite_diff.py:420: DeprecationWarning: invalid escape sequence \\*\n    \"\"\" Differentiate expr and replace Derivatives with finite differences.\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\nsympy/interactive/printing.py:245\n  /testbed/sympy/interactive/printing.py:245: DeprecationWarning: invalid escape sequence \\/\n    \"\"\"\n\nsympy/interactive/session.py:316\n  /testbed/sympy/interactive/session.py:316: DeprecationWarning: invalid escape sequence \\/\n    \"\"\"\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n================== 26 failed, 45 passed, 97 warnings in 0.86s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/utilities/tests/test_lambdify.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/utilities/tests/test_lambdify.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sympy__sympy-13091",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://34.70.1.155:8080",
      "duration": 15.43687105178833,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 94,
          "failed": 4,
          "errors": 0,
          "collected": 98,
          "duration": 7.3,
          "log_tail": "sympy/core/tests/test_numbers.py::test_issue_9491 PASSED                 [ 92%]\nsympy/core/tests/test_numbers.py::test_issue_10063 PASSED                [ 93%]\nsympy/core/tests/test_numbers.py::test_issue_10020 PASSED                [ 94%]\nsympy/core/tests/test_numbers.py::test_invert_numbers PASSED             [ 95%]\nsympy/core/tests/test_numbers.py::test_mod_inverse PASSED                [ 96%]\nsympy/core/tests/test_numbers.py::test_golden_ratio_rewrite_as_sqrt PASSED [ 97%]\nsympy/core/tests/test_numbers.py::test_comparisons_with_unknown_type FAILED [ 98%]\nsympy/core/tests/test_numbers.py::test_NumberSymbol_comparison FAILED    [100%]\n\n=================================== FAILURES ===================================\n________________________________ test_equality _________________________________\nsympy/core/tests/test_basic.py:73: in test_equality\n    assert b == bar\nE   assert Basic() == <sympy.core.tests.test_basic.test_equality.<locals>.Bar object at 0x71eb3870a100>\n______________________________ test_mpmath_issues ______________________________\nsympy/core/tests/test_numbers.py:1500: in test_mpmath_issues\n    assert _normalize(mpf, 53) != (0, long(0), 0, 0)\nE   TypeError: _normalize() missing 4 required positional arguments: 'exp', 'bc', 'prec', and 'rnd'\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:121: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_mpmath_issues\n______________________ test_comparisons_with_unknown_type ______________________\nsympy/core/tests/test_numbers.py:1702: in test_comparisons_with_unknown_type\n    assert n == bar\nE   assert 3 == <sympy.core.tests.test_numbers.test_comparisons_with_unknown_type.<locals>.Bar object at 0x71eb38d1c490>\n_________________________ test_NumberSymbol_comparison _________________________\nsympy/core/tests/test_numbers.py:1731: in test_NumberSymbol_comparison\n    assert (rpi > pi) == (pi < rpi)\nE   assert (905502432259640373/288230376151711744 > pi) == (pi < 905502432259640373/288230376151711744)\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 4 failed, 94 passed, 3 warnings in 1.70s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/core/tests/test_basic.py sympy/core/tests/test_numbers.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/core/tests/test_basic.py",
            "sympy/core/tests/test_numbers.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 97,
          "failed": 1,
          "errors": 0,
          "collected": 98,
          "duration": 7.15,
          "log_tail": "sympy/core/tests/test_numbers.py::test_mpmath_issues FAILED              [ 80%]\nsympy/core/tests/test_numbers.py::test_Catalan_EulerGamma_prec PASSED    [ 81%]\nsympy/core/tests/test_numbers.py::test_Float_eq PASSED                   [ 82%]\nsympy/core/tests/test_numbers.py::test_int_NumberSymbols PASSED          [ 83%]\nsympy/core/tests/test_numbers.py::test_issue_6640 PASSED                 [ 84%]\nsympy/core/tests/test_numbers.py::test_issue_6349 PASSED                 [ 85%]\nsympy/core/tests/test_numbers.py::test_mpf_norm PASSED                   [ 86%]\nsympy/core/tests/test_numbers.py::test_latex PASSED                      [ 87%]\nsympy/core/tests/test_numbers.py::test_issue_7742 PASSED                 [ 88%]\nsympy/core/tests/test_numbers.py::test_simplify_AlgebraicNumber PASSED   [ 89%]\nsympy/core/tests/test_numbers.py::test_Float_idempotence PASSED          [ 90%]\nsympy/core/tests/test_numbers.py::test_comp PASSED                       [ 91%]\nsympy/core/tests/test_numbers.py::test_issue_9491 PASSED                 [ 92%]\nsympy/core/tests/test_numbers.py::test_issue_10063 PASSED                [ 93%]\nsympy/core/tests/test_numbers.py::test_issue_10020 PASSED                [ 94%]\nsympy/core/tests/test_numbers.py::test_invert_numbers PASSED             [ 95%]\nsympy/core/tests/test_numbers.py::test_mod_inverse PASSED                [ 96%]\nsympy/core/tests/test_numbers.py::test_golden_ratio_rewrite_as_sqrt PASSED [ 97%]\nsympy/core/tests/test_numbers.py::test_comparisons_with_unknown_type PASSED [ 98%]\nsympy/core/tests/test_numbers.py::test_NumberSymbol_comparison PASSED    [100%]\n\n=================================== FAILURES ===================================\n______________________________ test_mpmath_issues ______________________________\nsympy/core/tests/test_numbers.py:1500: in test_mpmath_issues\n    assert _normalize(mpf, 53) != (0, long(0), 0, 0)\nE   TypeError: _normalize() missing 4 required positional arguments: 'exp', 'bc', 'prec', and 'rnd'\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:121: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_mpmath_issues\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 1 failed, 97 passed, 3 warnings in 1.61s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/core/tests/test_basic.py sympy/core/tests/test_numbers.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/core/tests/test_basic.py",
            "sympy/core/tests/test_numbers.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "django__django-13658",
      "repo": "django/django",
      "valid": true,
      "worker": "http://34.41.233.120:8080",
      "duration": 28.136205673217773,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 195,
          "failed": 0,
          "errors": 1,
          "duration": 13.77,
          "log_tail": "    execute_from_command_line(['django-admin'] + args)\n  File \"/testbed/django/core/management/__init__.py\", line 414, in execute_from_command_line\n    utility.execute()\n  File \"/testbed/django/core/management/__init__.py\", line 347, in execute\n    parser = CommandParser(usage='%(prog)s subcommand [options] [args]', add_help=False, allow_abbrev=False)\n  File \"/testbed/django/core/management/base.py\", line 54, in __init__\n    super().__init__(**kwargs)\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/argparse.py\", line 1626, in __init__\n    prog = _os.path.basename(_sys.argv[0])\n  File \"/opt/miniconda3/envs/testbed/lib/python3.6/posixpath.py\", line 146, in basename\n    p = os.fspath(p)\nTypeError: expected str, bytes or os.PathLike object, not NoneType\n\n----------------------------------------------------------------------\nRan 196 tests in 6.833s\n\nFAILED (errors=1)\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n\nERROR conda.cli.main_run:execute(124): `conda run python runtests.py --verbosity=2 admin_scripts.tests` failed. (See above for error)",
          "test_files_run": [
            "tests/admin_scripts/tests.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 196,
          "failed": 0,
          "errors": 0,
          "duration": 13.56,
          "log_tail": "test_no_color_force_color_mutually_exclusive_execute (admin_scripts.tests.CommandTypes) ... ok\ntest_noargs (admin_scripts.tests.CommandTypes)\nNoArg Commands can be executed ... ok\ntest_noargs_with_args (admin_scripts.tests.CommandTypes)\nNoArg Commands raise an error if an argument is provided ... ok\ntest_run_from_argv_closes_connections (admin_scripts.tests.CommandTypes) ... ok\ntest_run_from_argv_non_ascii_error (admin_scripts.tests.CommandTypes) ... ok\ntest_specific_help (admin_scripts.tests.CommandTypes)\n--help can be used on a specific command ... ok\ntest_version (admin_scripts.tests.CommandTypes)\nversion is handled as a special case ... ok\ntest_version_alternative (admin_scripts.tests.CommandTypes)\n--version is equivalent to version ... ok\n\n----------------------------------------------------------------------\nRan 196 tests in 6.735s\n\nOK\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\nDestroying test database for alias 'default' ('file:memorydb_default?mode=memory&cache=shared')...\n",
          "test_files_run": [
            "tests/admin_scripts/tests.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "django__django-13297",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10cf2c530>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 1
    },
    {
      "instance_id": "sympy__sympy-13372",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "duration": 21.046591997146606,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 45,
          "failed": 3,
          "errors": 0,
          "collected": 48,
          "duration": 10.54,
          "log_tail": "E   AssertionError: assert '-389.636364136010' == '-389.63636413601 + 0.e-14*I'\nE     \nE     - -389.63636413601 + 0.e-14*I\nE     ?                 --- -------\nE     + -389.636364136010\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:121: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_evalf_complex_powers_bug\n_______________________________ test_evalf_bugs ________________________________\nsympy/core/evalf.py:1287: in evalf\n    rf = evalf_table[x.func]\nE   KeyError: Max\n\nDuring handling of the above exception, another exception occurred:\nsympy/core/tests/test_evalf.py:234: in test_evalf_bugs\n    assert NS(Mul(Max(0, y), x, evaluate=False).evalf()) == 'x*Max(0, y)'\nsympy/core/evalf.py:1396: in evalf\n    result = evalf(self, prec + 4, options)\nsympy/core/evalf.py:1288: in evalf\n    r = rf(x, prec, options)\nsympy/core/evalf.py:540: in evalf_mul\n    arg = evalf(arg, prec, options)\nsympy/core/evalf.py:1310: in evalf\n    r = re, im, reprec, imprec\nE   UnboundLocalError: local variable 'reprec' referenced before assignment\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/core/containers.py:271\n  /testbed/sympy/core/containers.py:271: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    class OrderedSet(collections.MutableSet):\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 3 failed, 45 passed, 4 warnings in 4.04s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/core/tests/test_evalf.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/core/tests/test_evalf.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 46,
          "failed": 2,
          "errors": 0,
          "collected": 48,
          "duration": 9.65,
          "log_tail": "sympy/core/tests/test_evalf.py::test_AssocOp_Function PASSED             [ 97%]\nsympy/core/tests/test_evalf.py::test_issue_10395 PASSED                  [100%]\n\n=================================== FAILURES ===================================\n____________________________ test_evalf_complex_bug ____________________________\nsympy/core/tests/test_evalf.py:66: in test_evalf_complex_bug\n    assert NS('(pi+E*I)*(E+pi*I)', 15) in ('0.e-15 + 17.25866050002*I',\nE   AssertionError: assert '17.2586605000200*I' in ('0.e-15 + 17.25866050002*I', '0.e-17 + 17.25866050002*I', '-0.e-17 + 17.25866050002*I')\nE    +  where '17.2586605000200*I' = NS('(pi+E*I)*(E+pi*I)', 15)\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:121: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_evalf_complex_bug\n________________________ test_evalf_complex_powers_bug _________________________\nsympy/core/tests/test_evalf.py:89: in test_evalf_complex_powers_bug\n    assert NS('(pi + pi*I)**4') == '-389.63636413601 + 0.e-14*I'\nE   AssertionError: assert '-389.636364136010' == '-389.63636413601 + 0.e-14*I'\nE     \nE     - -389.63636413601 + 0.e-14*I\nE     ?                 --- -------\nE     + -389.636364136010\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:121: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_evalf_complex_powers_bug\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/core/containers.py:271\n  /testbed/sympy/core/containers.py:271: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    class OrderedSet(collections.MutableSet):\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 2 failed, 46 passed, 4 warnings in 3.98s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/core/tests/test_evalf.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/core/tests/test_evalf.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sympy__sympy-13615",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://34.70.1.155:8080",
      "duration": 21.895716190338135,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 71,
          "failed": 3,
          "errors": 0,
          "collected": 74,
          "duration": 11.55,
          "log_tail": "___________________________ test_image_Intersection ____________________________\nsympy/sets/tests/test_sets.py:797: in test_image_Intersection\n    assert imageset(x, x**2, Interval(-2, 0).intersect(Interval(x, y))) == \\\nE   assert Intersection(...terval(x, y))) == Intersection(...(x**2, y**2)))\nE     \nE     Full diff:\nE     - Intersection(Interval(0, 4), Interval(Min(x**2, y**2), Max(x**2, y**2)))\nE     + Intersection(Interval(0, 4), ImageSet(Lambda(x, x**2), Interval(x, y)))\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:121: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_image_Intersection\n_____________________ test_union_boundary_of_joining_sets ______________________\nsympy/sets/tests/test_sets.py:848: in test_union_boundary_of_joining_sets\n    assert Union(Interval(0, 10), Interval(10, 15), evaluate=False).boundary \\\nE   assert {0, 10, 15} == {0, 15}\nE     \nE     Full diff:\nE     - {0, 15}\nE     + {0, 10, 15}\nE     ?     ++++\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:121: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_union_boundary_of_joining_sets\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/core/containers.py:271\n  /testbed/sympy/core/containers.py:271: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    class OrderedSet(collections.MutableSet):\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 3 failed, 71 passed, 4 warnings in 5.88s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/sets/tests/test_sets.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/sets/tests/test_sets.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 72,
          "failed": 2,
          "errors": 0,
          "collected": 74,
          "duration": 9.43,
          "log_tail": "___________________________ test_image_Intersection ____________________________\nsympy/sets/tests/test_sets.py:797: in test_image_Intersection\n    assert imageset(x, x**2, Interval(-2, 0).intersect(Interval(x, y))) == \\\nE   assert Intersection(...terval(x, y))) == Intersection(...(x**2, y**2)))\nE     \nE     Full diff:\nE     - Intersection(Interval(0, 4), Interval(Min(x**2, y**2), Max(x**2, y**2)))\nE     + Intersection(Interval(0, 4), ImageSet(Lambda(x, x**2), Interval(x, y)))\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:121: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_image_Intersection\n_____________________ test_union_boundary_of_joining_sets ______________________\nsympy/sets/tests/test_sets.py:848: in test_union_boundary_of_joining_sets\n    assert Union(Interval(0, 10), Interval(10, 15), evaluate=False).boundary \\\nE   assert {0, 10, 15} == {0, 15}\nE     \nE     Full diff:\nE     - {0, 15}\nE     + {0, 10, 15}\nE     ?     ++++\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:121: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_union_boundary_of_joining_sets\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/core/containers.py:271\n  /testbed/sympy/core/containers.py:271: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    class OrderedSet(collections.MutableSet):\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 2 failed, 72 passed, 4 warnings in 3.67s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/sets/tests/test_sets.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/sets/tests/test_sets.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sympy__sympy-13647",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://34.123.9.23:8080",
      "duration": 16.033038854599,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 79,
          "failed": 2,
          "errors": 0,
          "collected": 81,
          "duration": 7.59,
          "log_tail": "E     \nE     ...Full output truncated (3 lines hidden), use '-vv' to show\n__________________________________ test_diff ___________________________________\nsympy/matrices/tests/test_commonmatrix.py:1316: in test_diff\n    assert m.diff(x) == Matrix(2, 1, [1, 0])\nsympy/matrices/matrices.py:1564: in diff\n    return Derivative(self, *args, evaluate=True)\nsympy/core/function.py:1105: in __new__\n    expr = sympify(expr)\nsympy/core/sympify.py:322: in sympify\n    return type(a)([sympify(x, locals=locals, convert_xor=convert_xor,\nsympy/matrices/common.py:2183: in __init__\n    raise NotImplementedError(\"Cannot initialize matrix with given parameters\")\nE   NotImplementedError: Cannot initialize matrix with given parameters\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:121: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_diff\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/core/containers.py:271\n  /testbed/sympy/core/containers.py:271: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    class OrderedSet(collections.MutableSet):\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\nsympy/matrices/tests/test_commonmatrix.py::test_refine\n  /testbed/sympy/assumptions/sathandlers.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import MutableMapping, defaultdict\n\nsympy/matrices/tests/test_commonmatrix.py::test_jacobian2\n  /testbed/sympy/core/function.py:1227: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    if isinstance(v, (collections.Iterable, Tuple, MatrixCommon, NDimArray)):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 2 failed, 79 passed, 6 warnings in 1.97s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/matrices/tests/test_commonmatrix.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/matrices/tests/test_commonmatrix.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 80,
          "failed": 1,
          "errors": 0,
          "collected": 81,
          "duration": 7.6,
          "log_tail": "\n=================================== FAILURES ===================================\n__________________________________ test_diff ___________________________________\nsympy/matrices/tests/test_commonmatrix.py:1316: in test_diff\n    assert m.diff(x) == Matrix(2, 1, [1, 0])\nsympy/matrices/matrices.py:1564: in diff\n    return Derivative(self, *args, evaluate=True)\nsympy/core/function.py:1105: in __new__\n    expr = sympify(expr)\nsympy/core/sympify.py:322: in sympify\n    return type(a)([sympify(x, locals=locals, convert_xor=convert_xor,\nsympy/matrices/common.py:2183: in __init__\n    raise NotImplementedError(\"Cannot initialize matrix with given parameters\")\nE   NotImplementedError: Cannot initialize matrix with given parameters\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:121: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_diff\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/core/containers.py:271\n  /testbed/sympy/core/containers.py:271: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    class OrderedSet(collections.MutableSet):\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\nsympy/matrices/tests/test_commonmatrix.py::test_refine\n  /testbed/sympy/assumptions/sathandlers.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import MutableMapping, defaultdict\n\nsympy/matrices/tests/test_commonmatrix.py::test_jacobian2\n  /testbed/sympy/core/function.py:1227: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    if isinstance(v, (collections.Iterable, Tuple, MatrixCommon, NDimArray)):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 1 failed, 80 passed, 6 warnings in 1.99s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/matrices/tests/test_commonmatrix.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/matrices/tests/test_commonmatrix.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sympy__sympy-13798",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://34.44.241.183:8080",
      "duration": 17.011027097702026,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 111,
          "failed": 5,
          "errors": 0,
          "collected": 116,
          "duration": 8.52,
          "log_tail": "sympy/printing/tests/test_latex.py:1613: in test_issue_8470\n    e = parse_expr(\"-B*A\", evaluate=False)\nsympy/parsing/sympy_parser.py:892: in parse_expr\n    code = compile(evaluateFalse(code), '<string>', 'eval')\nE   ValueError: Name node can't be used with 'False' constant\n_______________________________ test_issue_13559 _______________________________\nsympy/printing/tests/test_latex.py:1646: in test_issue_13559\n    expr = parse_expr('5/1', evaluate=False)\nsympy/parsing/sympy_parser.py:892: in parse_expr\n    code = compile(evaluateFalse(code), '<string>', 'eval')\nE   ValueError: Name node can't be used with 'False' constant\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/core/containers.py:271\n  /testbed/sympy/core/containers.py:271: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    class OrderedSet(collections.MutableSet):\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\nsympy/vector/coordsysrect.py:171\n  /testbed/sympy/vector/coordsysrect.py:171: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if transformation.name is 'spherical':\n\nsympy/vector/coordsysrect.py:173\n  /testbed/sympy/vector/coordsysrect.py:173: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    elif transformation.name is 'cylindrical':\n\nsympy/printing/tests/test_latex.py::test_latex_indexed\n  /testbed/sympy/tensor/indexed.py:155: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    if isinstance(base, (NDimArray, collections.Iterable, Tuple, MatrixBase)) and all([i.is_number for i in args]):\n\nsympy/printing/tests/test_latex.py::test_PolynomialRingBase\n  /testbed/sympy/polys/agca/modules.py:351: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    elif elem is 0:\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n================== 5 failed, 111 passed, 8 warnings in 1.98s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/printing/tests/test_latex.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/printing/tests/test_latex.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 112,
          "failed": 4,
          "errors": 0,
          "collected": 116,
          "duration": 7.58,
          "log_tail": "sympy/printing/tests/test_latex.py:1613: in test_issue_8470\n    e = parse_expr(\"-B*A\", evaluate=False)\nsympy/parsing/sympy_parser.py:892: in parse_expr\n    code = compile(evaluateFalse(code), '<string>', 'eval')\nE   ValueError: Name node can't be used with 'False' constant\n_______________________________ test_issue_13559 _______________________________\nsympy/printing/tests/test_latex.py:1646: in test_issue_13559\n    expr = parse_expr('5/1', evaluate=False)\nsympy/parsing/sympy_parser.py:892: in parse_expr\n    code = compile(evaluateFalse(code), '<string>', 'eval')\nE   ValueError: Name node can't be used with 'False' constant\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/core/containers.py:271\n  /testbed/sympy/core/containers.py:271: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    class OrderedSet(collections.MutableSet):\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\nsympy/vector/coordsysrect.py:171\n  /testbed/sympy/vector/coordsysrect.py:171: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if transformation.name is 'spherical':\n\nsympy/vector/coordsysrect.py:173\n  /testbed/sympy/vector/coordsysrect.py:173: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    elif transformation.name is 'cylindrical':\n\nsympy/printing/tests/test_latex.py::test_latex_indexed\n  /testbed/sympy/tensor/indexed.py:155: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    if isinstance(base, (NDimArray, collections.Iterable, Tuple, MatrixBase)) and all([i.is_number for i in args]):\n\nsympy/printing/tests/test_latex.py::test_PolynomialRingBase\n  /testbed/sympy/polys/agca/modules.py:351: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    elif elem is 0:\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n================== 4 failed, 112 passed, 8 warnings in 1.86s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/printing/tests/test_latex.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/printing/tests/test_latex.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sympy__sympy-13757",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://34.44.241.183:8080",
      "duration": 21.888263940811157,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 173,
          "failed": 6,
          "errors": 0,
          "collected": 179,
          "duration": 10.58,
          "log_tail": "E    +  where Poly(x, x, domain='ZZ') = Poly(x, x)\nE    +  and   Poly(I*x, x, domain='EX') = Poly((I * x), x)\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:121: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_poly_matching_consistency\n_______________________________ test_issue_5786 ________________________________\nsympy/polys/tests/test_polytools.py:3214: in test_issue_5786\n    assert expand(factor(expand(\nE   assert x - I*y == (((((-I * t) * x) - (t * y)) + (x * z)) - ((I * y) * z))\nE    +  where x - I*y = expand(x - I*y)\nE    +    where x - I*y = factor(-I*t*x - t*y + x*z - I*y*z, extension=[I])\nE    +      where -I*t*x - t*y + x*z - I*y*z = expand(((x - (I * y)) * (z - (I * t))))\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:121: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_issue_5786\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/core/containers.py:271\n  /testbed/sympy/core/containers.py:271: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    class OrderedSet(collections.MutableSet):\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\nsympy/core/tests/test_match.py::test_match_deriv_bug1\n  /testbed/sympy/core/function.py:1227: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    if isinstance(v, (collections.Iterable, Tuple, MatrixCommon, NDimArray)):\n\nsympy/polys/tests/test_polytools.py::test_Poly__unify\n  /testbed/sympy/polys/agca/modules.py:351: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    elif elem is 0:\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n================== 6 failed, 173 passed, 6 warnings in 4.91s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/core/tests/test_match.py sympy/polys/tests/test_polytools.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/core/tests/test_match.py",
            "sympy/polys/tests/test_polytools.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 174,
          "failed": 5,
          "errors": 0,
          "collected": 179,
          "duration": 10.4,
          "log_tail": "sympy/utilities/pytest.py:121: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_factor_noeval\n________________________ test_poly_matching_consistency ________________________\nsympy/utilities/pytest.py:124: in wrapper\n    raise XPass(get_function_name(func))\nE   sympy.utilities.pytest.XPass: test_poly_matching_consistency\n_______________________________ test_issue_5786 ________________________________\nsympy/polys/tests/test_polytools.py:3214: in test_issue_5786\n    assert expand(factor(expand(\nE   assert x - I*y == (((((-I * t) * x) - (t * y)) + (x * z)) - ((I * y) * z))\nE    +  where x - I*y = expand(x - I*y)\nE    +    where x - I*y = factor(-I*t*x - t*y + x*z - I*y*z, extension=[I])\nE    +      where -I*t*x - t*y + x*z - I*y*z = expand(((x - (I * y)) * (z - (I * t))))\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:121: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_issue_5786\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/core/containers.py:271\n  /testbed/sympy/core/containers.py:271: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    class OrderedSet(collections.MutableSet):\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\nsympy/core/tests/test_match.py::test_match_deriv_bug1\n  /testbed/sympy/core/function.py:1227: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    if isinstance(v, (collections.Iterable, Tuple, MatrixCommon, NDimArray)):\n\nsympy/polys/tests/test_polytools.py::test_Poly__unify\n  /testbed/sympy/polys/agca/modules.py:351: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    elif elem is 0:\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n================== 5 failed, 174 passed, 6 warnings in 4.62s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/core/tests/test_match.py sympy/polys/tests/test_polytools.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/core/tests/test_match.py",
            "sympy/polys/tests/test_polytools.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sympy__sympy-14531",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://34.70.1.155:8080",
      "duration": 14.99238395690918,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 86,
          "failed": 3,
          "errors": 0,
          "collected": 89,
          "duration": 7.49,
          "log_tail": "_______________________ test_python_functions_conjugates _______________________\nsympy/printing/tests/test_python.py:131: in test_python_functions_conjugates\n    assert python( conjugate(a + b*I) ) == '_     _\\na - I*b'\nE   assert \"a = Symbol('...*conjugate(b)\" == '_     _\\na - I*b'\nE     \nE     - _     _\nE     - a - I*b\nE     + a = Symbol('a')\nE     + b = Symbol('b')\nE     + e = conjugate(a) - I*conjugate(b)\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:121: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_python_functions_conjugates\n________________________________ test_Rational _________________________________\nsympy/printing/tests/test_str.py:495: in test_Rational\n    assert sstr(Eq(x, Rational(2, 3)), sympy_integers=True) == \"Eq(x, S(2)/3)\"\nE   AssertionError: assert 'Eq(x, 2/3)' == 'Eq(x, S(2)/3)'\nE     \nE     - Eq(x, S(2)/3)\nE     ?       -- -\nE     + Eq(x, 2/3)\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/core/expr.py:12\n  /testbed/sympy/core/expr.py:12: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import defaultdict, Iterable\n\nsympy/core/containers.py:271\n  /testbed/sympy/core/containers.py:271: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    class OrderedSet(collections.MutableSet):\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 3 failed, 86 passed, 5 warnings in 1.08s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/printing/tests/test_python.py sympy/printing/tests/test_str.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/printing/tests/test_python.py",
            "sympy/printing/tests/test_str.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 88,
          "failed": 1,
          "errors": 0,
          "collected": 89,
          "duration": 6.66,
          "log_tail": "sympy/printing/tests/test_str.py::test_Xor PASSED                        [ 94%]\nsympy/printing/tests/test_str.py::test_Complement PASSED                 [ 95%]\nsympy/printing/tests/test_str.py::test_SymmetricDifference PASSED        [ 96%]\nsympy/printing/tests/test_str.py::test_UnevaluatedExpr PASSED            [ 97%]\nsympy/printing/tests/test_str.py::test_MatrixElement_printing PASSED     [ 98%]\nsympy/printing/tests/test_str.py::test_MatrixSymbol_printing PASSED      [100%]\n\n=================================== FAILURES ===================================\n_______________________ test_python_functions_conjugates _______________________\nsympy/printing/tests/test_python.py:131: in test_python_functions_conjugates\n    assert python( conjugate(a + b*I) ) == '_     _\\na - I*b'\nE   assert \"a = Symbol('...*conjugate(b)\" == '_     _\\na - I*b'\nE     \nE     - _     _\nE     - a - I*b\nE     + a = Symbol('a')\nE     + b = Symbol('b')\nE     + e = conjugate(a) - I*conjugate(b)\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:121: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_python_functions_conjugates\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/core/expr.py:12\n  /testbed/sympy/core/expr.py:12: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import defaultdict, Iterable\n\nsympy/core/containers.py:271\n  /testbed/sympy/core/containers.py:271: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    class OrderedSet(collections.MutableSet):\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 1 failed, 88 passed, 5 warnings in 1.06s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/printing/tests/test_python.py sympy/printing/tests/test_str.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/printing/tests/test_python.py",
            "sympy/printing/tests/test_str.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "django__django-13512",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10cf2d010>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 1
    },
    {
      "instance_id": "sympy__sympy-14248",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://34.123.9.23:8080",
      "duration": 25.54150390625,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 499,
          "failed": 21,
          "errors": 0,
          "collected": 520,
          "duration": 12.72,
          "log_tail": "__________________________ test_MatrixSymbol_printing __________________________\nsympy/printing/tests/test_str.py:794: in test_MatrixSymbol_printing\n    assert str(A - A*B - B) == \"-B - A*B + A\"\nE   AssertionError: assert '(-1)*B + (-1)*A*B + A' == '-B - A*B + A'\nE     \nE     - -B - A*B + A\nE     + (-1)*B + (-1)*A*B + A\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/core/expr.py:12\n  /testbed/sympy/core/expr.py:12: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import defaultdict, Iterable\n\nsympy/core/containers.py:271\n  /testbed/sympy/core/containers.py:271: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    class OrderedSet(collections.MutableSet):\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\nsympy/vector/coordsysrect.py:171\n  /testbed/sympy/vector/coordsysrect.py:171: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if transformation.name is 'spherical':\n\nsympy/vector/coordsysrect.py:173\n  /testbed/sympy/vector/coordsysrect.py:173: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    elif transformation.name is 'cylindrical':\n\nsympy/printing/pretty/tests/test_pretty.py::test_pretty_geometry\n  /testbed/sympy/assumptions/sathandlers.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import MutableMapping, defaultdict\n\nsympy/printing/pretty/tests/test_pretty.py::test_PrettyModules\n  /testbed/sympy/polys/agca/modules.py:351: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    elif elem is 0:\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n================== 21 failed, 499 passed, 9 warnings in 6.14s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/printing/pretty/tests/test_pretty.py sympy/printing/tests/test_ccode.py sympy/printing/tests/test_fcode.py sympy/printing/tests/test_jscode.py sympy/printing/tests/test_julia.py sympy/printing/tests/test_latex.py sympy/printing/tests/test_octave.py sympy/printing/tests/test_rcode.py sympy/printing/tests/test_str.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/printing/pretty/tests/test_pretty.py",
            "sympy/printing/tests/test_ccode.py",
            "sympy/printing/tests/test_fcode.py",
            "sympy/printing/tests/test_jscode.py",
            "sympy/printing/tests/test_julia.py",
            "sympy/printing/tests/test_latex.py",
            "sympy/printing/tests/test_octave.py",
            "sympy/printing/tests/test_rcode.py",
            "sympy/printing/tests/test_str.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 510,
          "failed": 10,
          "errors": 0,
          "collected": 520,
          "duration": 11.89,
          "log_tail": "E     ?         +        +       ^^^^^^^^^^\nE     - 1        2        x*y]\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:121: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_Matrices_entries_not_hadamard\n=============================== warnings summary ===============================\nsympy/core/basic.py:3\n  /testbed/sympy/core/basic.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping, defaultdict\n\nsympy/core/expr.py:12\n  /testbed/sympy/core/expr.py:12: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import defaultdict, Iterable\n\nsympy/core/containers.py:271\n  /testbed/sympy/core/containers.py:271: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    class OrderedSet(collections.MutableSet):\n\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:28\n  /testbed/sympy/plotting/plot.py:28: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Callable\n\nsympy/vector/coordsysrect.py:171\n  /testbed/sympy/vector/coordsysrect.py:171: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if transformation.name is 'spherical':\n\nsympy/vector/coordsysrect.py:173\n  /testbed/sympy/vector/coordsysrect.py:173: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    elif transformation.name is 'cylindrical':\n\nsympy/printing/pretty/tests/test_pretty.py::test_pretty_geometry\n  /testbed/sympy/assumptions/sathandlers.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import MutableMapping, defaultdict\n\nsympy/printing/pretty/tests/test_pretty.py::test_PrettyModules\n  /testbed/sympy/polys/agca/modules.py:351: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    elif elem is 0:\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n================== 10 failed, 510 passed, 9 warnings in 6.13s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/printing/pretty/tests/test_pretty.py sympy/printing/tests/test_ccode.py sympy/printing/tests/test_fcode.py sympy/printing/tests/test_jscode.py sympy/printing/tests/test_julia.py sympy/printing/tests/test_latex.py sympy/printing/tests/test_octave.py sympy/printing/tests/test_rcode.py sympy/printing/tests/test_str.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/printing/pretty/tests/test_pretty.py",
            "sympy/printing/tests/test_ccode.py",
            "sympy/printing/tests/test_fcode.py",
            "sympy/printing/tests/test_jscode.py",
            "sympy/printing/tests/test_julia.py",
            "sympy/printing/tests/test_latex.py",
            "sympy/printing/tests/test_octave.py",
            "sympy/printing/tests/test_rcode.py",
            "sympy/printing/tests/test_str.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sympy__sympy-15599",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://34.123.9.23:8080",
      "duration": 21.56447172164917,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 81,
          "failed": 4,
          "errors": 0,
          "collected": 85,
          "duration": 10.76,
          "log_tail": "E    +  where None = ((y * x) * (x + k)).is_odd\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:124: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_oddness_in_ternary_integer_product_with_odd\n_______________________________ test_issue_3531 ________________________________\nsympy/core/tests/test_arit.py:1351: in test_issue_3531\n    assert sympify(1)/MightyNumeric((1, 2)) == \"something\"\nsympy/core/decorators.py:91: in __sympifyit_wrapper\n    return func(a, b)\nsympy/core/numbers.py:1643: in __div__\n    return Number.__div__(self, other)\nsympy/core/decorators.py:91: in __sympifyit_wrapper\n    return func(a, b)\nsympy/core/numbers.py:691: in __div__\n    return AtomicExpr.__div__(self, other)\nsympy/core/decorators.py:91: in __sympifyit_wrapper\n    return func(a, b)\nsympy/core/decorators.py:132: in binary_op_wrapper\n    return func(self, other)\nsympy/core/expr.py:188: in __div__\n    return Mul(self, Pow(other, S.NegativeOne))\nsympy/core/cache.py:94: in wrapper\n    retval = cfunc(*args, **kwargs)\nsympy/core/power.py:286: in __new__\n    obj = b._eval_power(e)\nE   AttributeError: 'Tuple' object has no attribute '_eval_power'\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:124: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_issue_3531\n___________________________________ test_Mod ___________________________________\nsympy/core/tests/test_arit.py:1667: in test_Mod\n    assert Mod(3*i, 2) == Mod(i, 2)\nE   assert Mod(3*i, 2) == Mod(i, 2)\nE    +  where Mod(3*i, 2) = Mod((3 * i), 2)\nE    +  and   Mod(i, 2) = Mod(i, 2)\n=============================== warnings summary ===============================\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 4 failed, 81 passed, 1 warning in 3.98s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/core/tests/test_arit.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/core/tests/test_arit.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 82,
          "failed": 3,
          "errors": 0,
          "collected": 85,
          "duration": 9.92,
          "log_tail": "    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_evenness_in_ternary_integer_product_with_odd\n_______________ test_oddness_in_ternary_integer_product_with_odd _______________\nsympy/core/tests/test_arit.py:480: in test_oddness_in_ternary_integer_product_with_odd\n    assert (y*x*(x + k)).is_odd is False\nE   assert None is False\nE    +  where None = ((y * x) * (x + k)).is_odd\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:124: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_oddness_in_ternary_integer_product_with_odd\n_______________________________ test_issue_3531 ________________________________\nsympy/core/tests/test_arit.py:1351: in test_issue_3531\n    assert sympify(1)/MightyNumeric((1, 2)) == \"something\"\nsympy/core/decorators.py:91: in __sympifyit_wrapper\n    return func(a, b)\nsympy/core/numbers.py:1643: in __div__\n    return Number.__div__(self, other)\nsympy/core/decorators.py:91: in __sympifyit_wrapper\n    return func(a, b)\nsympy/core/numbers.py:691: in __div__\n    return AtomicExpr.__div__(self, other)\nsympy/core/decorators.py:91: in __sympifyit_wrapper\n    return func(a, b)\nsympy/core/decorators.py:132: in binary_op_wrapper\n    return func(self, other)\nsympy/core/expr.py:188: in __div__\n    return Mul(self, Pow(other, S.NegativeOne))\nsympy/core/cache.py:94: in wrapper\n    retval = cfunc(*args, **kwargs)\nsympy/core/power.py:286: in __new__\n    obj = b._eval_power(e)\nE   AttributeError: 'Tuple' object has no attribute '_eval_power'\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:124: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_issue_3531\n=============================== warnings summary ===============================\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 3 failed, 82 passed, 1 warning in 4.04s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/core/tests/test_arit.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/core/tests/test_arit.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sympy__sympy-15809",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "duration": 16.93536686897278,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 11,
          "failed": 3,
          "errors": 0,
          "collected": 14,
          "duration": 8.49,
          "log_tail": "___________________________________ test_Min ___________________________________\nsympy/functions/elementary/tests/test_miscellaneous.py:88: in test_Min\n    assert Min() == S.Infinity\nsympy/functions/elementary/miscellaneous.py:343: in __new__\n    raise ValueError(\"The Max/Min functions must have arguments.\")\nE   ValueError: The Max/Min functions must have arguments.\n___________________________________ test_Max ___________________________________\nsympy/functions/elementary/tests/test_miscellaneous.py:160: in test_Max\n    assert Max() == S.NegativeInfinity\nsympy/functions/elementary/miscellaneous.py:343: in __new__\n    raise ValueError(\"The Max/Min functions must have arguments.\")\nE   ValueError: The Max/Min functions must have arguments.\n_______________________________ test_issue_11463 _______________________________\nsympy/functions/elementary/tests/test_miscellaneous.py:346: in test_issue_11463\n    skip(\"numpy not installed.\")\nsympy/utilities/pytest.py:138: in skip\n    raise Skipped(str)\nE   sympy.utilities.pytest.Skipped: numpy not installed.\n=============================== warnings summary ===============================\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:520\n  /testbed/sympy/plotting/plot.py:520: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:540\n  /testbed/sympy/plotting/plot.py:540: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:553\n  /testbed/sympy/plotting/plot.py:553: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:560\n  /testbed/sympy/plotting/plot.py:560: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 3 failed, 11 passed, 6 warnings in 1.69s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/functions/elementary/tests/test_miscellaneous.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/functions/elementary/tests/test_miscellaneous.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 13,
          "failed": 1,
          "errors": 0,
          "collected": 14,
          "duration": 7.61,
          "log_tail": "sympy/functions/elementary/tests/test_miscellaneous.py::test_root PASSED [ 35%]\nsympy/functions/elementary/tests/test_miscellaneous.py::test_real_root PASSED [ 42%]\nsympy/functions/elementary/tests/test_miscellaneous.py::test_issue_11463 FAILED [ 50%]\nsympy/functions/elementary/tests/test_miscellaneous.py::test_rewrite_MaxMin_as_Heaviside PASSED [ 57%]\nsympy/functions/elementary/tests/test_miscellaneous.py::test_rewrite_MaxMin_as_Piecewise PASSED [ 64%]\nsympy/functions/elementary/tests/test_miscellaneous.py::test_issue_11099 PASSED [ 71%]\nsympy/functions/elementary/tests/test_miscellaneous.py::test_issue_12638 PASSED [ 78%]\nsympy/functions/elementary/tests/test_miscellaneous.py::test_instantiation_evaluation PASSED [ 85%]\nsympy/functions/elementary/tests/test_miscellaneous.py::test_rewrite_as_Abs PASSED [ 92%]\nsympy/functions/elementary/tests/test_miscellaneous.py::test_issue_14000 PASSED [100%]\n\n=================================== FAILURES ===================================\n_______________________________ test_issue_11463 _______________________________\nsympy/functions/elementary/tests/test_miscellaneous.py:346: in test_issue_11463\n    skip(\"numpy not installed.\")\nsympy/utilities/pytest.py:138: in skip\n    raise Skipped(str)\nE   sympy.utilities.pytest.Skipped: numpy not installed.\n=============================== warnings summary ===============================\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:520\n  /testbed/sympy/plotting/plot.py:520: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:540\n  /testbed/sympy/plotting/plot.py:540: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:553\n  /testbed/sympy/plotting/plot.py:553: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:560\n  /testbed/sympy/plotting/plot.py:560: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 1 failed, 13 passed, 6 warnings in 1.81s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/functions/elementary/tests/test_miscellaneous.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/functions/elementary/tests/test_miscellaneous.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "django__django-13551",
      "repo": "django/django",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10ce833b0>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 1
    },
    {
      "instance_id": "sympy__sympy-15875",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://34.44.241.183:8080",
      "duration": 20.224727153778076,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 81,
          "failed": 4,
          "errors": 0,
          "collected": 85,
          "duration": 9.67,
          "log_tail": "    return func(self, other)\nsympy/core/expr.py:188: in __div__\n    return Mul(self, Pow(other, S.NegativeOne))\nsympy/core/cache.py:94: in wrapper\n    retval = cfunc(*args, **kwargs)\nsympy/core/power.py:286: in __new__\n    obj = b._eval_power(e)\nE   AttributeError: 'Tuple' object has no attribute '_eval_power'\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_issue_3531\n_______________________________ test_Add_is_zero _______________________________\nsympy/core/tests/test_arit.py:1991: in test_Add_is_zero\n    assert e.is_zero is None\nE   assert False is None\nE    +  where False = -2*I + (1 + I)**2.is_zero\n=============================== warnings summary ===============================\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:520\n  /testbed/sympy/plotting/plot.py:520: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:540\n  /testbed/sympy/plotting/plot.py:540: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:553\n  /testbed/sympy/plotting/plot.py:553: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:560\n  /testbed/sympy/plotting/plot.py:560: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 4 failed, 81 passed, 6 warnings in 3.83s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/core/tests/test_arit.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/core/tests/test_arit.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 82,
          "failed": 3,
          "errors": 0,
          "collected": 85,
          "duration": 9.64,
          "log_tail": "sympy/core/numbers.py:673: in __div__\n    return AtomicExpr.__div__(self, other)\nsympy/core/decorators.py:91: in __sympifyit_wrapper\n    return func(a, b)\nsympy/core/decorators.py:132: in binary_op_wrapper\n    return func(self, other)\nsympy/core/expr.py:188: in __div__\n    return Mul(self, Pow(other, S.NegativeOne))\nsympy/core/cache.py:94: in wrapper\n    retval = cfunc(*args, **kwargs)\nsympy/core/power.py:286: in __new__\n    obj = b._eval_power(e)\nE   AttributeError: 'Tuple' object has no attribute '_eval_power'\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_issue_3531\n=============================== warnings summary ===============================\nsympy/solvers/diophantine.py:3188\n  /testbed/sympy/solvers/diophantine.py:3188: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:520\n  /testbed/sympy/plotting/plot.py:520: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:540\n  /testbed/sympy/plotting/plot.py:540: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:553\n  /testbed/sympy/plotting/plot.py:553: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:560\n  /testbed/sympy/plotting/plot.py:560: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 3 failed, 82 passed, 6 warnings in 3.77s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/core/tests/test_arit.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/core/tests/test_arit.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sympy__sympy-16597",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://34.123.9.23:8080",
      "duration": 18.74691605567932,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 76,
          "failed": 7,
          "errors": 0,
          "collected": 83,
          "duration": 9.36,
          "log_tail": "    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_issue_6275\n_______________________________ test_issue_7993 ________________________________\nsympy/core/tests/test_assumptions.py:1007: in test_issue_7993\n    assert (x - y).is_zero is False\nE   assert None is False\nE    +  where None = (_Dummy_204 - _Dummy_205).is_zero\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_issue_7993\n_______________________________ test_issue_11463 _______________________________\nsympy/functions/elementary/tests/test_miscellaneous.py:346: in test_issue_11463\n    skip(\"numpy not installed.\")\nsympy/utilities/pytest.py:138: in skip\n    raise Skipped(str)\nE   sympy.utilities.pytest.Skipped: numpy not installed.\n=============================== warnings summary ===============================\nsympy/solvers/diophantine.py:3185\n  /testbed/sympy/solvers/diophantine.py:3185: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:644\n  /testbed/sympy/plotting/plot.py:644: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:664\n  /testbed/sympy/plotting/plot.py:664: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:677\n  /testbed/sympy/plotting/plot.py:677: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:684\n  /testbed/sympy/plotting/plot.py:684: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 7 failed, 76 passed, 6 warnings in 2.58s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/core/tests/test_assumptions.py sympy/functions/elementary/tests/test_miscellaneous.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/core/tests/test_assumptions.py",
            "sympy/functions/elementary/tests/test_miscellaneous.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 79,
          "failed": 4,
          "errors": 0,
          "collected": 83,
          "duration": 8.4,
          "log_tail": "    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_issue_6275\n_______________________________ test_issue_7993 ________________________________\nsympy/core/tests/test_assumptions.py:1007: in test_issue_7993\n    assert (x - y).is_zero is False\nE   assert None is False\nE    +  where None = (_Dummy_203 - _Dummy_204).is_zero\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_issue_7993\n_______________________________ test_issue_11463 _______________________________\nsympy/functions/elementary/tests/test_miscellaneous.py:346: in test_issue_11463\n    skip(\"numpy not installed.\")\nsympy/utilities/pytest.py:138: in skip\n    raise Skipped(str)\nE   sympy.utilities.pytest.Skipped: numpy not installed.\n=============================== warnings summary ===============================\nsympy/solvers/diophantine.py:3185\n  /testbed/sympy/solvers/diophantine.py:3185: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:644\n  /testbed/sympy/plotting/plot.py:644: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:664\n  /testbed/sympy/plotting/plot.py:664: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:677\n  /testbed/sympy/plotting/plot.py:677: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:684\n  /testbed/sympy/plotting/plot.py:684: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 4 failed, 79 passed, 6 warnings in 2.55s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/core/tests/test_assumptions.py sympy/functions/elementary/tests/test_miscellaneous.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/core/tests/test_assumptions.py",
            "sympy/functions/elementary/tests/test_miscellaneous.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sympy__sympy-16450",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://34.41.233.120:8080",
      "duration": 28.855204105377197,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 40,
          "failed": 3,
          "errors": 0,
          "collected": 43,
          "duration": 14.52,
          "log_tail": "E     Full diff:\nE       {...\nE     \nE     ...Full output truncated (14 lines hidden), use '-vv' to show\n________________________ test_simplify_float_vs_integer ________________________\nsympy/simplify/tests/test_simplify.py:533: in test_simplify_float_vs_integer\n    assert simplify(x**2.0 - x**2) == 0\nE   assert -x**2 + x**2.0 == 0\nE    +  where -x**2 + x**2.0 = simplify(((x ** 2.0) - (x ** 2)))\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_simplify_float_vs_integer\n=============================== warnings summary ===============================\nsympy/solvers/diophantine.py:3186\n  /testbed/sympy/solvers/diophantine.py:3186: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:509\n  /testbed/sympy/plotting/plot.py:509: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:529\n  /testbed/sympy/plotting/plot.py:529: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:542\n  /testbed/sympy/plotting/plot.py:542: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:549\n  /testbed/sympy/plotting/plot.py:549: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\nsympy/simplify/tests/test_simplify.py::test_simplify_expr\n  /testbed/sympy/polys/agca/modules.py:360: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    elif elem is 0:\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 3 failed, 40 passed, 7 warnings in 7.67s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/simplify/tests/test_simplify.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/simplify/tests/test_simplify.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 41,
          "failed": 2,
          "errors": 0,
          "collected": 43,
          "duration": 13.5,
          "log_tail": "During handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_factorial_simplify\n________________________ test_simplify_float_vs_integer ________________________\nsympy/simplify/tests/test_simplify.py:533: in test_simplify_float_vs_integer\n    assert simplify(x**2.0 - x**2) == 0\nE   assert -x**2 + x**2.0 == 0\nE    +  where -x**2 + x**2.0 = simplify(((x ** 2.0) - (x ** 2)))\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_simplify_float_vs_integer\n=============================== warnings summary ===============================\nsympy/solvers/diophantine.py:3186\n  /testbed/sympy/solvers/diophantine.py:3186: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if feasible is 1:  # it's prime and k == 2\n\nsympy/plotting/plot.py:509\n  /testbed/sympy/plotting/plot.py:509: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:529\n  /testbed/sympy/plotting/plot.py:529: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:542\n  /testbed/sympy/plotting/plot.py:542: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\nsympy/plotting/plot.py:549\n  /testbed/sympy/plotting/plot.py:549: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.xscale is 'log':\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\nsympy/simplify/tests/test_simplify.py::test_simplify_expr\n  /testbed/sympy/polys/agca/modules.py:360: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    elif elem is 0:\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 2 failed, 41 passed, 7 warnings in 7.63s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/simplify/tests/test_simplify.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/simplify/tests/test_simplify.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sympy__sympy-17630",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://34.123.9.23:8080",
      "duration": 14.347662687301636,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 20,
          "failed": 3,
          "errors": 0,
          "collected": 23,
          "duration": 7.21,
          "log_tail": "    result = rule(expr)\nsympy/strategies/core.py:11: in exhaustive_rl\n    new, old = rule(expr), expr\nsympy/strategies/core.py:44: in chain_rl\n    expr = rule(expr)\nsympy/strategies/core.py:11: in exhaustive_rl\n    new, old = rule(expr), expr\nsympy/strategies/core.py:33: in conditioned_rl\n    return rule(expr)\nsympy/strategies/core.py:95: in switch_rl\n    return rl(expr)\nsympy/matrices/expressions/blockmatrix.py:467: in bc_matmul\n    matrices[i] = A._blockmul(B)\nsympy/matrices/expressions/blockmatrix.py:167: in _blockmul\n    return BlockMatrix(self.blocks*other.blocks)\nsympy/matrices/expressions/blockmatrix.py:86: in __new__\n    raise ValueError(filldedent('''\nE   ValueError: \nE   expecting a sequence of 1 or more rows containing Matrices.\n_____________________________ test_zero_matrix_add _____________________________\nsympy/matrices/expressions/tests/test_matadd.py:37: in test_zero_matrix_add\n    assert Add(ZeroMatrix(2, 2), ZeroMatrix(2, 2)) == ZeroMatrix(2, 2)\nE   assert 0 == 0\nE    +  where 0 = Add(0, 0)\nE    +    where 0 = ZeroMatrix(2, 2)\nE    +    and   0 = ZeroMatrix(2, 2)\nE    +  and   0 = ZeroMatrix(2, 2)\n_________________________ test_matrix_add_with_scalar __________________________\nsympy/matrices/expressions/tests/test_matadd.py:41: in test_matrix_add_with_scalar\n    raises(TypeError, lambda: Add(0, ZeroMatrix(2, 2)))\nsympy/utilities/pytest.py:86: in raises\n    raise Failed(\"DID NOT RAISE\")\nE   sympy.utilities.pytest.Failed: DID NOT RAISE\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_matrix_add_with_scalar\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 3 failed, 20 passed, 1 warning in 0.48s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/matrices/expressions/tests/test_blockmatrix.py sympy/matrices/expressions/tests/test_matadd.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/matrices/expressions/tests/test_blockmatrix.py",
            "sympy/matrices/expressions/tests/test_matadd.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 22,
          "failed": 1,
          "errors": 0,
          "collected": 23,
          "duration": 6.28,
          "log_tail": "collecting ... collected 23 items\n\nsympy/matrices/expressions/tests/test_blockmatrix.py::test_bc_matmul PASSED [  4%]\nsympy/matrices/expressions/tests/test_blockmatrix.py::test_bc_matadd PASSED [  8%]\nsympy/matrices/expressions/tests/test_blockmatrix.py::test_bc_transpose PASSED [ 13%]\nsympy/matrices/expressions/tests/test_blockmatrix.py::test_bc_dist_diag PASSED [ 17%]\nsympy/matrices/expressions/tests/test_blockmatrix.py::test_block_plus_ident PASSED [ 21%]\nsympy/matrices/expressions/tests/test_blockmatrix.py::test_BlockMatrix PASSED [ 26%]\nsympy/matrices/expressions/tests/test_blockmatrix.py::test_block_collapse_explicit_matrices PASSED [ 30%]\nsympy/matrices/expressions/tests/test_blockmatrix.py::test_issue_17624 PASSED [ 34%]\nsympy/matrices/expressions/tests/test_blockmatrix.py::test_BlockMatrix_trace PASSED [ 39%]\nsympy/matrices/expressions/tests/test_blockmatrix.py::test_BlockMatrix_Determinant PASSED [ 43%]\nsympy/matrices/expressions/tests/test_blockmatrix.py::test_squareBlockMatrix PASSED [ 47%]\nsympy/matrices/expressions/tests/test_blockmatrix.py::test_BlockDiagMatrix PASSED [ 52%]\nsympy/matrices/expressions/tests/test_blockmatrix.py::test_blockcut PASSED [ 56%]\nsympy/matrices/expressions/tests/test_blockmatrix.py::test_reblock_2x2 PASSED [ 60%]\nsympy/matrices/expressions/tests/test_blockmatrix.py::test_deblock PASSED [ 65%]\nsympy/matrices/expressions/tests/test_blockmatrix.py::test_block_collapse_type PASSED [ 69%]\nsympy/matrices/expressions/tests/test_matadd.py::test_sort_key PASSED    [ 73%]\nsympy/matrices/expressions/tests/test_matadd.py::test_matadd_sympify PASSED [ 78%]\nsympy/matrices/expressions/tests/test_matadd.py::test_matadd_of_matrices PASSED [ 82%]\nsympy/matrices/expressions/tests/test_matadd.py::test_doit_args PASSED   [ 86%]\nsympy/matrices/expressions/tests/test_matadd.py::test_generic_identity PASSED [ 91%]\nsympy/matrices/expressions/tests/test_matadd.py::test_zero_matrix_add PASSED [ 95%]\nsympy/matrices/expressions/tests/test_matadd.py::test_matrix_add_with_scalar FAILED [100%]\n\n=================================== FAILURES ===================================\n_________________________ test_matrix_add_with_scalar __________________________\nsympy/matrices/expressions/tests/test_matadd.py:41: in test_matrix_add_with_scalar\n    raises(TypeError, lambda: Add(0, ZeroMatrix(2, 2)))\nsympy/utilities/pytest.py:86: in raises\n    raise Failed(\"DID NOT RAISE\")\nE   sympy.utilities.pytest.Failed: DID NOT RAISE\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_matrix_add_with_scalar\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 1 failed, 22 passed, 1 warning in 0.45s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/matrices/expressions/tests/test_blockmatrix.py sympy/matrices/expressions/tests/test_matadd.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/matrices/expressions/tests/test_blockmatrix.py",
            "sympy/matrices/expressions/tests/test_matadd.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sympy__sympy-17139",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://34.44.241.183:8080",
      "duration": 33.26469898223877,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 69,
          "failed": 4,
          "errors": 0,
          "collected": 73,
          "duration": 16.79,
          "log_tail": "During handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_simplify_float_vs_integer\n_______________________________ test_issue_17137 _______________________________\nsympy/simplify/tests/test_simplify.py:815: in test_issue_17137\n    assert simplify(cos(x)**I) == cos(x)**I\nsympy/simplify/simplify.py:587: in simplify\n    expr = trigsimp(expr, deep=True)\nsympy/simplify/trigsimp.py:508: in trigsimp\n    return trigsimpfunc(expr)\nsympy/simplify/trigsimp.py:501: in <lambda>\n    'matching': (lambda x: futrig(x)),\nsympy/simplify/trigsimp.py:1101: in futrig\n    e = bottom_up(e, lambda x: _futrig(x, **kwargs))\nsympy/simplify/simplify.py:1081: in bottom_up\n    rv = F(rv)\nsympy/simplify/trigsimp.py:1101: in <lambda>\n    e = bottom_up(e, lambda x: _futrig(x, **kwargs))\nsympy/simplify/trigsimp.py:1169: in _futrig\n    e = greedy(tree, objective=Lops)(e)\nsympy/strategies/core.py:115: in minrule\n    return min([rule(expr) for rule in rules], key=objective)\nsympy/strategies/core.py:115: in <listcomp>\n    return min([rule(expr) for rule in rules], key=objective)\nsympy/strategies/core.py:44: in chain_rl\n    expr = rule(expr)\nsympy/simplify/fu.py:566: in TR6\n    return _TR56(rv, cos, sin, lambda x: 1 - x, max=max, pow=pow)\nsympy/simplify/fu.py:524: in _TR56\n    return bottom_up(rv, _f)\nsympy/simplify/simplify.py:1081: in bottom_up\n    rv = F(rv)\nsympy/simplify/fu.py:504: in _f\n    if (rv.exp < 0) == True:\nsympy/core/expr.py:406: in __lt__\n    raise TypeError(\"Invalid comparison of complex %s\" % me)\nE   TypeError: Invalid comparison of complex I\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 4 failed, 69 passed, 1 warning in 9.91s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/simplify/tests/test_fu.py sympy/simplify/tests/test_simplify.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/simplify/tests/test_fu.py",
            "sympy/simplify/tests/test_simplify.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 71,
          "failed": 2,
          "errors": 0,
          "collected": 73,
          "duration": 15.57,
          "log_tail": "sympy/simplify/tests/test_simplify.py::test_besselsimp PASSED            [ 78%]\nsympy/simplify/tests/test_simplify.py::test_Piecewise PASSED             [ 79%]\nsympy/simplify/tests/test_simplify.py::test_polymorphism PASSED          [ 80%]\nsympy/simplify/tests/test_simplify.py::test_issue_from_PR1599 PASSED     [ 82%]\nsympy/simplify/tests/test_simplify.py::test_issue_6811 PASSED            [ 83%]\nsympy/simplify/tests/test_simplify.py::test_issue_6920 PASSED            [ 84%]\nsympy/simplify/tests/test_simplify.py::test_issue_7001 PASSED            [ 86%]\nsympy/simplify/tests/test_simplify.py::test_inequality_no_auto_simplify PASSED [ 87%]\nsympy/simplify/tests/test_simplify.py::test_issue_9398 PASSED            [ 89%]\nsympy/simplify/tests/test_simplify.py::test_issue_9324_simplify PASSED   [ 90%]\nsympy/simplify/tests/test_simplify.py::test_issue_13474 PASSED           [ 91%]\nsympy/simplify/tests/test_simplify.py::test_simplify_function_inverse PASSED [ 93%]\nsympy/simplify/tests/test_simplify.py::test_clear_coefficients PASSED    [ 94%]\nsympy/simplify/tests/test_simplify.py::test_nc_simplify PASSED           [ 95%]\nsympy/simplify/tests/test_simplify.py::test_issue_15965 PASSED           [ 97%]\nsympy/simplify/tests/test_simplify.py::test_issue_17137 PASSED           [ 98%]\nsympy/simplify/tests/test_simplify.py::test_issue_7971 PASSED            [100%]\n\n=================================== FAILURES ===================================\n___________________________ test_factorial_simplify ____________________________\nsympy/simplify/tests/test_simplify.py:29: in test_factorial_simplify\n    from sympy.specfun.factorials import factorial\nE   ModuleNotFoundError: No module named 'sympy.specfun'\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_factorial_simplify\n________________________ test_simplify_float_vs_integer ________________________\nsympy/simplify/tests/test_simplify.py:538: in test_simplify_float_vs_integer\n    assert simplify(x**2.0 - x**2) == 0\nE   assert -x**2 + x**2.0 == 0\nE    +  where -x**2 + x**2.0 = simplify(((x ** 2.0) - (x ** 2)))\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_simplify_float_vs_integer\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 2 failed, 71 passed, 1 warning in 9.64s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/simplify/tests/test_fu.py sympy/simplify/tests/test_simplify.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/simplify/tests/test_fu.py",
            "sympy/simplify/tests/test_simplify.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sympy__sympy-13877",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10ce82de0>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 1
    },
    {
      "instance_id": "sympy__sympy-18211",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://34.70.1.155:8080",
      "duration": 19.237576007843018,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 55,
          "failed": 3,
          "errors": 0,
          "collected": 58,
          "duration": 9.61,
          "log_tail": "sympy/logic/boolalg.py:161: in as_set\n    raise NotImplementedError(\"Sorry, as_set has not yet been\"\nE   NotImplementedError: Sorry, as_set has not yet been implemented for multivariate expressions\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_multivariate_relational_as_set\n_______________________ test_issue_8444_nonworkingtests ________________________\nsympy/core/tests/test_relational.py:828: in test_issue_8444_nonworkingtests\n    assert x >= floor(x)\nsympy/core/relational.py:385: in __nonzero__\n    raise TypeError(\"cannot determine truth value of Relational\")\nE   TypeError: cannot determine truth value of Relational\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_issue_8444_nonworkingtests\n_______________________________ test_issue_18188 _______________________________\nsympy/solvers/inequalities.py:524: in solve_univariate_inequality\n    solns = solvify(e, gen, domain)\nsympy/solvers/solveset.py:2138: in solvify\n    raise NotImplementedError('solveset is unable to solve this equation.')\nE   NotImplementedError: solveset is unable to solve this equation.\n\nDuring handling of the above exception, another exception occurred:\nsympy/core/tests/test_relational.py:964: in test_issue_18188\n    assert result1.as_set() == ConditionSet(x, Eq(x*cos(x) - 3*sin(x), 0), Reals)\nsympy/logic/boolalg.py:159: in as_set\n    return self.subs(reps)._eval_as_set()\nsympy/core/relational.py:395: in _eval_as_set\n    return solve_univariate_inequality(self, x, relational=False)\nsympy/solvers/inequalities.py:531: in solve_univariate_inequality\n    raise NotImplementedError(filldedent('''\nE   NotImplementedError: \nE   The inequality, Eq(x*cos(x) - 3*sin(x), 0), cannot be solved using\nE   solve_univariate_inequality.\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 3 failed, 55 passed, 1 warning in 2.88s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/core/tests/test_relational.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/core/tests/test_relational.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 56,
          "failed": 2,
          "errors": 0,
          "collected": 58,
          "duration": 8.66,
          "log_tail": "sympy/core/tests/test_relational.py::test_issue_18188 PASSED             [ 77%]\nsympy/core/tests/test_relational.py::test_binary_symbols PASSED          [ 79%]\nsympy/core/tests/test_relational.py::test_rel_args PASSED                [ 81%]\nsympy/core/tests/test_relational.py::test_Equality_rewrite_as_Add PASSED [ 82%]\nsympy/core/tests/test_relational.py::test_issue_15847 PASSED             [ 84%]\nsympy/core/tests/test_relational.py::test_negated_property PASSED        [ 86%]\nsympy/core/tests/test_relational.py::test_reversedsign_property PASSED   [ 87%]\nsympy/core/tests/test_relational.py::test_reversed_reversedsign_property PASSED [ 89%]\nsympy/core/tests/test_relational.py::test_improved_canonical PASSED      [ 91%]\nsympy/core/tests/test_relational.py::test_set_equality_canonical PASSED  [ 93%]\nsympy/core/tests/test_relational.py::test_trigsimp PASSED                [ 94%]\nsympy/core/tests/test_relational.py::test_polynomial_relation_simplification PASSED [ 96%]\nsympy/core/tests/test_relational.py::test_multivariate_linear_function_simplification PASSED [ 98%]\nsympy/core/tests/test_relational.py::test_nonpolymonial_relations PASSED [100%]\n\n=================================== FAILURES ===================================\n_____________________ test_multivariate_relational_as_set ______________________\nsympy/core/tests/test_relational.py:432: in test_multivariate_relational_as_set\n    assert (x*y >= 0).as_set() == Interval(0, oo)*Interval(0, oo) + \\\nsympy/logic/boolalg.py:161: in as_set\n    raise NotImplementedError(\"Sorry, as_set has not yet been\"\nE   NotImplementedError: Sorry, as_set has not yet been implemented for multivariate expressions\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_multivariate_relational_as_set\n_______________________ test_issue_8444_nonworkingtests ________________________\nsympy/core/tests/test_relational.py:828: in test_issue_8444_nonworkingtests\n    assert x >= floor(x)\nsympy/core/relational.py:385: in __nonzero__\n    raise TypeError(\"cannot determine truth value of Relational\")\nE   TypeError: cannot determine truth value of Relational\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_issue_8444_nonworkingtests\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 2 failed, 56 passed, 1 warning in 2.84s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/core/tests/test_relational.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/core/tests/test_relational.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sympy__sympy-14976",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10ce3e240>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 1
    },
    {
      "instance_id": "sympy__sympy-19346",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://34.41.233.120:8080",
      "duration": 14.455413579940796,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 40,
          "failed": 4,
          "errors": 0,
          "collected": 44,
          "duration": 7.29,
          "log_tail": "sympy/printing/tests/test_repr.py::test_Naturals0 PASSED                 [ 84%]\nsympy/printing/tests/test_repr.py::test_Reals PASSED                     [ 86%]\nsympy/printing/tests/test_repr.py::test_matrix_expressions PASSED        [ 88%]\nsympy/printing/tests/test_repr.py::test_Cycle PASSED                     [ 90%]\nsympy/printing/tests/test_repr.py::test_Permutation PASSED               [ 93%]\nsympy/printing/tests/test_repr.py::test_diffgeom PASSED                  [ 95%]\nsympy/printing/tests/test_repr.py::test_dict FAILED                      [ 97%]\nsympy/printing/tests/test_repr.py::test_set FAILED                       [100%]\n\n=================================== FAILURES ===================================\n___________________________________ test_Add ___________________________________\nsympy/printing/tests/test_repr.py:51: in test_Add\n    assert srepr(sympify('x + 3 - 2', evaluate=False), order='none') == \"Add(Symbol('x'), Integer(3), Mul(Integer(-1), Integer(2)))\"\nsympy/core/sympify.py:406: in sympify\n    expr = parse_expr(a, local_dict=locals, transformations=transformations, evaluate=evaluate)\nsympy/parsing/sympy_parser.py:1006: in parse_expr\n    code = compile(evaluateFalse(code), '<string>', 'eval')\nE   ValueError: Name node can't be used with 'False' constant\n___________________________________ test_Mul ___________________________________\nsympy/printing/tests/test_repr.py:207: in test_Mul\n    assert srepr(sympify('(x+4)*2*x*7', evaluate=False), order='none') == \"Mul(Add(Symbol('x'), Integer(4)), Integer(2), Symbol('x'), Integer(7))\"\nsympy/core/sympify.py:406: in sympify\n    expr = parse_expr(a, local_dict=locals, transformations=transformations, evaluate=evaluate)\nsympy/parsing/sympy_parser.py:1006: in parse_expr\n    code = compile(evaluateFalse(code), '<string>', 'eval')\nE   ValueError: Name node can't be used with 'False' constant\n__________________________________ test_dict ___________________________________\nsympy/printing/tests/test_repr.py:328: in test_dict\n    assert srepr(d) == \"{Symbol('x'): Symbol('y')}\"\nE   assert '{x: y}' == \"{Symbol('x'): Symbol('y')}\"\nE     \nE     - {Symbol('x'): Symbol('y')}\nE     + {x: y}\n___________________________________ test_set ___________________________________\nsympy/printing/tests/test_repr.py:343: in test_set\n    assert srepr(s) in (\"{Symbol('x'), Symbol('y')}\", \"{Symbol('y'), Symbol('x')}\")\nE   assert '{y, x}' in (\"{Symbol('x'), Symbol('y')}\", \"{Symbol('y'), Symbol('x')}\")\nE    +  where '{y, x}' = <function srepr at 0x7bde48db0ee0>({y, x})\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 4 failed, 40 passed, 1 warning in 0.45s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/printing/tests/test_repr.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/printing/tests/test_repr.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 42,
          "failed": 2,
          "errors": 0,
          "collected": 44,
          "duration": 6.24,
          "log_tail": "sympy/printing/tests/test_repr.py::test_PolyRing PASSED                  [ 56%]\nsympy/printing/tests/test_repr.py::test_FracField PASSED                 [ 59%]\nsympy/printing/tests/test_repr.py::test_PolyElement PASSED               [ 61%]\nsympy/printing/tests/test_repr.py::test_FracElement PASSED               [ 63%]\nsympy/printing/tests/test_repr.py::test_FractionField PASSED             [ 65%]\nsympy/printing/tests/test_repr.py::test_PolynomialRingBase PASSED        [ 68%]\nsympy/printing/tests/test_repr.py::test_DMP PASSED                       [ 70%]\nsympy/printing/tests/test_repr.py::test_FiniteExtension PASSED           [ 72%]\nsympy/printing/tests/test_repr.py::test_ExtensionElement PASSED          [ 75%]\nsympy/printing/tests/test_repr.py::test_BooleanAtom PASSED               [ 77%]\nsympy/printing/tests/test_repr.py::test_Integers PASSED                  [ 79%]\nsympy/printing/tests/test_repr.py::test_Naturals PASSED                  [ 81%]\nsympy/printing/tests/test_repr.py::test_Naturals0 PASSED                 [ 84%]\nsympy/printing/tests/test_repr.py::test_Reals PASSED                     [ 86%]\nsympy/printing/tests/test_repr.py::test_matrix_expressions PASSED        [ 88%]\nsympy/printing/tests/test_repr.py::test_Cycle PASSED                     [ 90%]\nsympy/printing/tests/test_repr.py::test_Permutation PASSED               [ 93%]\nsympy/printing/tests/test_repr.py::test_diffgeom PASSED                  [ 95%]\nsympy/printing/tests/test_repr.py::test_dict PASSED                      [ 97%]\nsympy/printing/tests/test_repr.py::test_set PASSED                       [100%]\n\n=================================== FAILURES ===================================\n___________________________________ test_Add ___________________________________\nsympy/printing/tests/test_repr.py:51: in test_Add\n    assert srepr(sympify('x + 3 - 2', evaluate=False), order='none') == \"Add(Symbol('x'), Integer(3), Mul(Integer(-1), Integer(2)))\"\nsympy/core/sympify.py:406: in sympify\n    expr = parse_expr(a, local_dict=locals, transformations=transformations, evaluate=evaluate)\nsympy/parsing/sympy_parser.py:1006: in parse_expr\n    code = compile(evaluateFalse(code), '<string>', 'eval')\nE   ValueError: Name node can't be used with 'False' constant\n___________________________________ test_Mul ___________________________________\nsympy/printing/tests/test_repr.py:207: in test_Mul\n    assert srepr(sympify('(x+4)*2*x*7', evaluate=False), order='none') == \"Mul(Add(Symbol('x'), Integer(4)), Integer(2), Symbol('x'), Integer(7))\"\nsympy/core/sympify.py:406: in sympify\n    expr = parse_expr(a, local_dict=locals, transformations=transformations, evaluate=evaluate)\nsympy/parsing/sympy_parser.py:1006: in parse_expr\n    code = compile(evaluateFalse(code), '<string>', 'eval')\nE   ValueError: Name node can't be used with 'False' constant\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 2 failed, 42 passed, 1 warning in 0.45s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/printing/tests/test_repr.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/printing/tests/test_repr.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sympy__sympy-18763",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://34.41.233.120:8080",
      "duration": 18.860016107559204,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 142,
          "failed": 5,
          "errors": 0,
          "collected": 147,
          "duration": 9.56,
          "log_tail": "E     + \\text{False}\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_latex_symbols_failing\n_______________________________ test_latex_subs ________________________________\nsympy/printing/tests/test_latex.py:676: in test_latex_subs\n    assert latex(Subs(x*y, (\nE   AssertionError: assert '\\\\left. x y ...=1\\\\\\\\ y=2 }}' == '\\\\left. \\\\le...=1\\\\\\\\ y=2 }}'\nE     \nE     - \\left. \\left(x y\\right) \\right|_{\\substack{ x=1\\\\ y=2 }}\nE     ?        ------   -------\nE     + \\left. x y \\right|_{\\substack{ x=1\\\\ y=2 }}\n__________________ test_builtin_without_args_mismatched_names __________________\nsympy/printing/tests/test_latex.py:2030: in test_builtin_without_args_mismatched_names\n    assert latex(CosineTransform) == r'\\mathcal{COS}'\nE   AssertionError: assert '\\\\operatorna...ineTransform}' == '\\\\mathcal{COS}'\nE     \nE     - \\mathcal{COS}\nE     + \\operatorname{CosineTransform}\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_builtin_without_args_mismatched_names\n_______________________________ test_issue_8470 ________________________________\nsympy/printing/tests/test_latex.py:2083: in test_issue_8470\n    e = parse_expr(\"-B*A\", evaluate=False)\nsympy/parsing/sympy_parser.py:1006: in parse_expr\n    code = compile(evaluateFalse(code), '<string>', 'eval')\nE   ValueError: Name node can't be used with 'False' constant\n_______________________________ test_issue_13559 _______________________________\nsympy/printing/tests/test_latex.py:2125: in test_issue_13559\n    expr = parse_expr('5/1', evaluate=False)\nsympy/parsing/sympy_parser.py:1006: in parse_expr\n    code = compile(evaluateFalse(code), '<string>', 'eval')\nE   ValueError: Name node can't be used with 'False' constant\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 5 failed, 142 passed, 1 warning in 2.81s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/printing/tests/test_latex.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/printing/tests/test_latex.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 143,
          "failed": 4,
          "errors": 0,
          "collected": 147,
          "duration": 8.46,
          "log_tail": "\n=================================== FAILURES ===================================\n__________________________ test_latex_symbols_failing __________________________\nsympy/printing/tests/test_latex.py:287: in test_latex_symbols_failing\n    assert latex(\nE   AssertionError: assert '\\\\text{False}' == '\\\\rho \\\\math...\\mathrm{mass}'\nE     \nE     - \\rho \\mathrm{volume} = \\mathrm{mass}\nE     + \\text{False}\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_latex_symbols_failing\n__________________ test_builtin_without_args_mismatched_names __________________\nsympy/printing/tests/test_latex.py:2030: in test_builtin_without_args_mismatched_names\n    assert latex(CosineTransform) == r'\\mathcal{COS}'\nE   AssertionError: assert '\\\\operatorna...ineTransform}' == '\\\\mathcal{COS}'\nE     \nE     - \\mathcal{COS}\nE     + \\operatorname{CosineTransform}\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_builtin_without_args_mismatched_names\n_______________________________ test_issue_8470 ________________________________\nsympy/printing/tests/test_latex.py:2083: in test_issue_8470\n    e = parse_expr(\"-B*A\", evaluate=False)\nsympy/parsing/sympy_parser.py:1006: in parse_expr\n    code = compile(evaluateFalse(code), '<string>', 'eval')\nE   ValueError: Name node can't be used with 'False' constant\n_______________________________ test_issue_13559 _______________________________\nsympy/printing/tests/test_latex.py:2125: in test_issue_13559\n    expr = parse_expr('5/1', evaluate=False)\nsympy/parsing/sympy_parser.py:1006: in parse_expr\n    code = compile(evaluateFalse(code), '<string>', 'eval')\nE   ValueError: Name node can't be used with 'False' constant\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 4 failed, 143 passed, 1 warning in 2.60s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/printing/tests/test_latex.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/printing/tests/test_latex.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sympy__sympy-19637",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://34.70.1.155:8080",
      "duration": 14.079182863235474,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 40,
          "failed": 3,
          "errors": 0,
          "collected": 50,
          "duration": 6.58,
          "log_tail": "sympy/core/tests/test_sympify.py::test_issue_6540_6552 PASSED            [ 74%]\nsympy/core/tests/test_sympify.py::test_issue_6046 PASSED                 [ 76%]\nsympy/core/tests/test_sympify.py::test_issue_8821_highprec_from_str PASSED [ 78%]\nsympy/core/tests/test_sympify.py::test_issue_10295 SKIPPED (numpy no...) [ 80%]\nsympy/core/tests/test_sympify.py::test_Range PASSED                      [ 82%]\nsympy/core/tests/test_sympify.py::test_sympify_set PASSED                [ 84%]\nsympy/core/tests/test_sympify.py::test_sympify_numpy SKIPPED (numpy ...) [ 86%]\nsympy/core/tests/test_sympify.py::test_sympify_rational_numbers_set XFAIL [ 88%]\nsympy/core/tests/test_sympify.py::test_issue_13924 SKIPPED (numpy no...) [ 90%]\nsympy/core/tests/test_sympify.py::test_numpy_sympify_args SKIPPED (n...) [ 92%]\nsympy/core/tests/test_sympify.py::test_issue_5939 PASSED                 [ 94%]\nsympy/core/tests/test_sympify.py::test_issue_16759 PASSED                [ 96%]\nsympy/core/tests/test_sympify.py::test_issue_17811 FAILED                [ 98%]\nsympy/core/tests/test_sympify.py::test_issue_14706 SKIPPED (numpy no...) [100%]\n\n=================================== FAILURES ===================================\n_____________________________ test_evaluate_false ______________________________\nsympy/core/tests/test_sympify.py:435: in test_evaluate_false\n    assert sympify(case, evaluate=False) == result\nsympy/core/sympify.py:406: in sympify\n    expr = parse_expr(a, local_dict=locals, transformations=transformations, evaluate=evaluate)\nsympy/parsing/sympy_parser.py:1006: in parse_expr\n    code = compile(evaluateFalse(code), '<string>', 'eval')\nE   ValueError: Name node can't be used with 'False' constant\n__________________________________ test_kernS __________________________________\nsympy/core/tests/test_sympify.py:515: in test_kernS\n    assert kernS(\"(2*x)/(x-1)\") == 2*x/(x-1)\nsympy/core/sympify.py:516: in kernS\n    hit = kern in s\nE   UnboundLocalError: local variable 'kern' referenced before assignment\n_______________________________ test_issue_17811 _______________________________\nsympy/core/tests/test_sympify.py:707: in test_issue_17811\n    assert sympify('a(x)*5', evaluate=False) == Mul(a(x), 5, evaluate=False)\nsympy/core/sympify.py:406: in sympify\n    expr = parse_expr(a, local_dict=locals, transformations=transformations, evaluate=evaluate)\nsympy/parsing/sympy_parser.py:1006: in parse_expr\n    code = compile(evaluateFalse(code), '<string>', 'eval')\nE   ValueError: Name node can't be used with 'False' constant\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n======== 3 failed, 40 passed, 5 skipped, 2 xfailed, 1 warning in 0.74s =========\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/core/tests/test_sympify.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/core/tests/test_sympify.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 41,
          "failed": 2,
          "errors": 0,
          "collected": 50,
          "duration": 6.62,
          "log_tail": "sympy/core/tests/test_sympify.py::test_issue_4788 PASSED                 [ 62%]\nsympy/core/tests/test_sympify.py::test_issue_4798_None PASSED            [ 64%]\nsympy/core/tests/test_sympify.py::test_issue_3218 PASSED                 [ 66%]\nsympy/core/tests/test_sympify.py::test_issue_4988_builtins PASSED        [ 68%]\nsympy/core/tests/test_sympify.py::test_geometry PASSED                   [ 70%]\nsympy/core/tests/test_sympify.py::test_kernS PASSED                      [ 72%]\nsympy/core/tests/test_sympify.py::test_issue_6540_6552 PASSED            [ 74%]\nsympy/core/tests/test_sympify.py::test_issue_6046 PASSED                 [ 76%]\nsympy/core/tests/test_sympify.py::test_issue_8821_highprec_from_str PASSED [ 78%]\nsympy/core/tests/test_sympify.py::test_issue_10295 SKIPPED (numpy no...) [ 80%]\nsympy/core/tests/test_sympify.py::test_Range PASSED                      [ 82%]\nsympy/core/tests/test_sympify.py::test_sympify_set PASSED                [ 84%]\nsympy/core/tests/test_sympify.py::test_sympify_numpy SKIPPED (numpy ...) [ 86%]\nsympy/core/tests/test_sympify.py::test_sympify_rational_numbers_set XFAIL [ 88%]\nsympy/core/tests/test_sympify.py::test_issue_13924 SKIPPED (numpy no...) [ 90%]\nsympy/core/tests/test_sympify.py::test_numpy_sympify_args SKIPPED (n...) [ 92%]\nsympy/core/tests/test_sympify.py::test_issue_5939 PASSED                 [ 94%]\nsympy/core/tests/test_sympify.py::test_issue_16759 PASSED                [ 96%]\nsympy/core/tests/test_sympify.py::test_issue_17811 FAILED                [ 98%]\nsympy/core/tests/test_sympify.py::test_issue_14706 SKIPPED (numpy no...) [100%]\n\n=================================== FAILURES ===================================\n_____________________________ test_evaluate_false ______________________________\nsympy/core/tests/test_sympify.py:435: in test_evaluate_false\n    assert sympify(case, evaluate=False) == result\nsympy/core/sympify.py:406: in sympify\n    expr = parse_expr(a, local_dict=locals, transformations=transformations, evaluate=evaluate)\nsympy/parsing/sympy_parser.py:1006: in parse_expr\n    code = compile(evaluateFalse(code), '<string>', 'eval')\nE   ValueError: Name node can't be used with 'False' constant\n_______________________________ test_issue_17811 _______________________________\nsympy/core/tests/test_sympify.py:707: in test_issue_17811\n    assert sympify('a(x)*5', evaluate=False) == Mul(a(x), 5, evaluate=False)\nsympy/core/sympify.py:406: in sympify\n    expr = parse_expr(a, local_dict=locals, transformations=transformations, evaluate=evaluate)\nsympy/parsing/sympy_parser.py:1006: in parse_expr\n    code = compile(evaluateFalse(code), '<string>', 'eval')\nE   ValueError: Name node can't be used with 'False' constant\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n======== 2 failed, 41 passed, 5 skipped, 2 xfailed, 1 warning in 0.71s =========\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/core/tests/test_sympify.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/core/tests/test_sympify.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sympy__sympy-18189",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://34.70.1.155:8080",
      "duration": 63.27647590637207,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 43,
          "failed": 3,
          "errors": 0,
          "collected": 46,
          "duration": 31.27,
          "log_tail": "E     (2, -3)\nE     (-2, -3)\nE     (2, 3)...\nE     \nE     ...Full output truncated (38 lines hidden), use '-vv' to show\n_______________________________ test_fail_holzer _______________________________\nsympy/solvers/tests/test_diophantine.py:813: in test_fail_holzer\n    assert h == ans  # it would be nice to get the smaller soln\nE   AssertionError: assert (26, 1, 11) == (2, 7, 13)\nE     \nE     At index 0 diff: 26 != 2\nE     \nE     Full diff:\nE       (\nE     -     2,\nE     +     26,...\nE     \nE     ...Full output truncated (7 lines hidden), use '-vv' to show\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_fail_holzer\n_____________________________ test_not_implemented _____________________________\nsympy/solvers/tests/test_diophantine.py:924: in test_not_implemented\n    assert diophantine(eq, syms=[x, y]) == set([(9, 1), (1, 3)])\nsympy/solvers/diophantine.py:304: in diophantine\n    var_t, _, eq_type = classify_diop(base, _dict=False)\nsympy/solvers/diophantine.py:550: in classify_diop\n    raise NotImplementedError(filldedent('''\nE   NotImplementedError: \nE   This equation is not yet recognized or else has not been simplified\nE   sufficiently to put it in a form recognized by diop_classify().\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_not_implemented\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 3 failed, 43 passed, 1 warning in 25.43s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/solvers/tests/test_diophantine.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/solvers/tests/test_diophantine.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 44,
          "failed": 2,
          "errors": 0,
          "collected": 46,
          "duration": 31.1,
          "log_tail": "sympy/solvers/tests/test_diophantine.py::test_not_implemented FAILED     [ 95%]\nsympy/solvers/tests/test_diophantine.py::test_issue_9538 PASSED          [ 97%]\nsympy/solvers/tests/test_diophantine.py::test_ternary_quadratic PASSED   [100%]\n\n=================================== FAILURES ===================================\n_______________________________ test_fail_holzer _______________________________\nsympy/solvers/tests/test_diophantine.py:813: in test_fail_holzer\n    assert h == ans  # it would be nice to get the smaller soln\nE   AssertionError: assert (26, 1, 11) == (2, 7, 13)\nE     \nE     At index 0 diff: 26 != 2\nE     \nE     Full diff:\nE       (\nE     -     2,\nE     +     26,...\nE     \nE     ...Full output truncated (7 lines hidden), use '-vv' to show\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_fail_holzer\n_____________________________ test_not_implemented _____________________________\nsympy/solvers/tests/test_diophantine.py:924: in test_not_implemented\n    assert diophantine(eq, syms=[x, y]) == set([(9, 1), (1, 3)])\nsympy/solvers/diophantine.py:304: in diophantine\n    var_t, _, eq_type = classify_diop(base, _dict=False)\nsympy/solvers/diophantine.py:550: in classify_diop\n    raise NotImplementedError(filldedent('''\nE   NotImplementedError: \nE   This equation is not yet recognized or else has not been simplified\nE   sufficiently to put it in a form recognized by diop_classify().\n\nDuring handling of the above exception, another exception occurred:\nsympy/utilities/pytest.py:129: in wrapper\n    raise XFail(get_function_name(func))\nE   sympy.utilities.pytest.XFail: test_not_implemented\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n=================== 2 failed, 44 passed, 1 warning in 25.10s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/solvers/tests/test_diophantine.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/solvers/tests/test_diophantine.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "matplotlib__matplotlib-20488",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://34.59.30.169:8080",
      "duration": 34.13101005554199,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 111,
          "failed": 10,
          "errors": 0,
          "collected": 140,
          "duration": 16.84,
          "log_tail": "    return self._comparison(other, operator.gt)\n/opt/miniconda3/envs/testbed/lib/python3.8/site-packages/numpy/ma/core.py:4123: in _comparison\n    check = compare(sdata, odata)\nlib/matplotlib/tests/test_image.py:1200: in __array_ufunc__\n    raise NotImplementedError\nE   NotImplementedError\n_________________________ test_huge_range_log[png--1] __________________________\nlib/matplotlib/testing/decorators.py:443: in wrapper\n    fig_test.savefig(test_image_path)\nlib/matplotlib/figure.py:2969: in savefig\n    self.canvas.print_figure(fname, **kwargs)\nlib/matplotlib/backend_bases.py:2297: in print_figure\n    result = print_method(\nlib/matplotlib/backend_bases.py:1650: in wrapper\n    return func(*args, **kwargs)\nlib/matplotlib/_api/deprecation.py:449: in wrapper\n    return func(*inner_args, **inner_kwargs)\nlib/matplotlib/backends/backend_agg.py:491: in print_png\n    FigureCanvasAgg.draw(self)\nlib/matplotlib/backends/backend_agg.py:387: in draw\n    self.figure.draw(self.renderer)\nlib/matplotlib/artist.py:71: in draw_wrapper\n    result = draw(artist, renderer, *args, **kwargs)\nlib/matplotlib/artist.py:48: in draw_wrapper\n    return draw(artist, renderer)\nlib/matplotlib/figure.py:2754: in draw\n    mimage._draw_list_compositing_images(\nlib/matplotlib/image.py:132: in _draw_list_compositing_images\n    a.draw(renderer)\nlib/matplotlib/artist.py:48: in draw_wrapper\n    return draw(artist, renderer)\nlib/matplotlib/axes/_base.py:3074: in draw\n    mimage._draw_list_compositing_images(\nlib/matplotlib/image.py:132: in _draw_list_compositing_images\n    a.draw(renderer)\nlib/matplotlib/artist.py:48: in draw_wrapper\n    return draw(artist, renderer)\nlib/matplotlib/image.py:638: in draw\n    im, l, b, trans = self.make_image(\nlib/matplotlib/image.py:924: in make_image\n    return self._make_image(self._A, bbox, transformed_bbox, clip,\nlib/matplotlib/image.py:542: in _make_image\n    output = self.norm(resampled_masked)\nlib/matplotlib/colors.py:1477: in __call__\n    raise ValueError(\"Invalid vmin or vmax\")\nE   ValueError: Invalid vmin or vmax\n================= 10 failed, 111 passed, 19 skipped in 14.30s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_image.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_image.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 112,
          "failed": 9,
          "errors": 0,
          "collected": 140,
          "duration": 16.4,
          "log_tail": "    \tresult_images/test_image/bbox_image_inverted_pdf-failed-diff.png\nAll traceback entries are hidden. Pass `--full-trace` to see hidden and internal frames.\n_____________________________ test_mask_image[pdf] _____________________________\nE   matplotlib.testing.exceptions.ImageComparisonFailure: images not close (RMS 7.745):\n    \tresult_images/test_image/mask_image_pdf.png\n    \tresult_images/test_image/mask_image-expected_pdf.png\n    \tresult_images/test_image/mask_image_pdf-failed-diff.png\nAll traceback entries are hidden. Pass `--full-trace` to see hidden and internal frames.\n______________________________ test_full_invalid _______________________________\nlib/matplotlib/tests/test_image.py:1021: in test_full_invalid\n    fig.canvas.draw()\nE   DeprecationWarning: Passing `np.nan` to mean no clipping in np.clip has always been unreliable, and is now deprecated. In future, this will always return nan, like it already does when min or max are arrays that contain nan. To skip a bound, pass either None or an np.inf of an appropriate sign.\n____________________________ test_imshow_quantitynd ____________________________\nlib/matplotlib/tests/test_image.py:1233: in test_imshow_quantitynd\n    fig.canvas.draw()\nlib/matplotlib/backends/backend_agg.py:387: in draw\n    self.figure.draw(self.renderer)\nlib/matplotlib/artist.py:71: in draw_wrapper\n    result = draw(artist, renderer, *args, **kwargs)\nlib/matplotlib/artist.py:48: in draw_wrapper\n    return draw(artist, renderer)\nlib/matplotlib/figure.py:2754: in draw\n    mimage._draw_list_compositing_images(\nlib/matplotlib/image.py:132: in _draw_list_compositing_images\n    a.draw(renderer)\nlib/matplotlib/artist.py:48: in draw_wrapper\n    return draw(artist, renderer)\nlib/matplotlib/axes/_base.py:3074: in draw\n    mimage._draw_list_compositing_images(\nlib/matplotlib/image.py:132: in _draw_list_compositing_images\n    a.draw(renderer)\nlib/matplotlib/artist.py:48: in draw_wrapper\n    return draw(artist, renderer)\nlib/matplotlib/image.py:638: in draw\n    im, l, b, trans = self.make_image(\nlib/matplotlib/image.py:924: in make_image\n    return self._make_image(self._A, bbox, transformed_bbox, clip,\nlib/matplotlib/image.py:445: in _make_image\n    if newmin < a_min:\n/opt/miniconda3/envs/testbed/lib/python3.8/site-packages/numpy/ma/core.py:4191: in __gt__\n    return self._comparison(other, operator.gt)\n/opt/miniconda3/envs/testbed/lib/python3.8/site-packages/numpy/ma/core.py:4123: in _comparison\n    check = compare(sdata, odata)\nlib/matplotlib/tests/test_image.py:1200: in __array_ufunc__\n    raise NotImplementedError\nE   NotImplementedError\n================== 9 failed, 112 passed, 19 skipped in 13.87s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_image.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_image.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sympy__sympy-21930",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 46.2057318687439,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 47,
          "failed": 6,
          "errors": 0,
          "collected": 53,
          "duration": 22.91,
          "log_tail": "E     \nE     - {b^\\dagger_{i}}\nE     ? -             -\nE     + b^\\dagger_{i}\n_______________________________ test_commutation _______________________________\nsympy/physics/tests/test_secondquant.py:261: in test_commutation\n    assert latex(c) == r'\\left[{a^\\dagger_{a}} a_{i},{a^\\dagger_{b}} a_{j}\\right]'\nE   AssertionError: assert '\\\\left[a^\\\\d...a_{j}\\\\right]' == '\\\\left[{a^\\\\...a_{j}\\\\right]'\nE     \nE     - \\left[{a^\\dagger_{a}} a_{i},{a^\\dagger_{b}} a_{j}\\right]\nE     ?       -             -       -             -\nE     + \\left[a^\\dagger_{a} a_{i},a^\\dagger_{b} a_{j}\\right]\n________________________________ test_create_f _________________________________\nsympy/physics/tests/test_secondquant.py:291: in test_create_f\n    assert latex(Fd(p)) == r'{a^\\dagger_{p}}'\nE   AssertionError: assert 'a^\\\\dagger_{p}' == '{a^\\\\dagger_{p}}'\nE     \nE     - {a^\\dagger_{p}}\nE     ? -             -\nE     + a^\\dagger_{p}\n___________________________________ test_NO ____________________________________\nsympy/physics/tests/test_secondquant.py:429: in test_NO\n    assert latex(no) == r'\\left\\{{a^\\dagger_{a}} {a^\\dagger_{i}}\\right\\}'\nE   AssertionError: assert '\\\\left\\\\{a^\\...{i}\\\\right\\\\}' == '\\\\left\\\\{{a^...i}}\\\\right\\\\}'\nE     \nE     - \\left\\{{a^\\dagger_{a}} {a^\\dagger_{i}}\\right\\}\nE     ?       -              ^^^             -\nE     + \\left\\{a^\\dagger_{a} a^\\dagger_{i}\\right\\}\nE     ?                     ^\n_________________________________ test_Tensors _________________________________\nsympy/physics/tests/test_secondquant.py:534: in test_Tensors\n    assert latex(tabij) == '{t^{ab}_{ij}}'\nE   AssertionError: assert 't^{ab}_{ij}' == '{t^{ab}_{ij}}'\nE     \nE     - {t^{ab}_{ij}}\nE     ? -           -\nE     + t^{ab}_{ij}\n_______________________________ test_issue_19661 _______________________________\nsympy/physics/tests/test_secondquant.py:1260: in test_issue_19661\n    assert latex(Commutator(Bd(a)**2, B(a))\nE   AssertionError: assert '- \\\\left[b_{...}^{2}\\\\right]' == '- \\\\left[b_{...}^{2}\\\\right]'\nE     \nE     - - \\left[b_{0},{b^\\dagger_{0}}^{2}\\right]\nE     ?               -             -\nE     + - \\left[b_{0},b^\\dagger_{0}^{2}\\right]\n                                DO *NOT* COMMIT!                                \n======================== 6 failed, 47 passed in 16.95s =========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/physics/tests/test_secondquant.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/physics/tests/test_secondquant.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 53,
          "failed": 0,
          "errors": 0,
          "collected": 53,
          "duration": 22.37,
          "log_tail": "sympy/physics/tests/test_secondquant.py::test_basic_apply PASSED         [ 15%]\nsympy/physics/tests/test_secondquant.py::test_complex_apply PASSED       [ 16%]\nsympy/physics/tests/test_secondquant.py::test_number_operator PASSED     [ 18%]\nsympy/physics/tests/test_secondquant.py::test_inner_product PASSED       [ 20%]\nsympy/physics/tests/test_secondquant.py::test_symbolic_matrix_elements PASSED [ 22%]\nsympy/physics/tests/test_secondquant.py::test_matrix_elements PASSED     [ 24%]\nsympy/physics/tests/test_secondquant.py::test_fixed_bosonic_basis PASSED [ 26%]\nsympy/physics/tests/test_secondquant.py::test_sho PASSED                 [ 28%]\nsympy/physics/tests/test_secondquant.py::test_commutation PASSED         [ 30%]\nsympy/physics/tests/test_secondquant.py::test_create_f PASSED            [ 32%]\nsympy/physics/tests/test_secondquant.py::test_annihilate_f PASSED        [ 33%]\nsympy/physics/tests/test_secondquant.py::test_create_b PASSED            [ 35%]\nsympy/physics/tests/test_secondquant.py::test_annihilate_b PASSED        [ 37%]\nsympy/physics/tests/test_secondquant.py::test_wicks PASSED               [ 39%]\nsympy/physics/tests/test_secondquant.py::test_NO PASSED                  [ 41%]\nsympy/physics/tests/test_secondquant.py::test_sorting PASSED             [ 43%]\nsympy/physics/tests/test_secondquant.py::test_contraction PASSED         [ 45%]\nsympy/physics/tests/test_secondquant.py::test_evaluate_deltas PASSED     [ 47%]\nsympy/physics/tests/test_secondquant.py::test_Tensors PASSED             [ 49%]\nsympy/physics/tests/test_secondquant.py::test_fully_contracted PASSED    [ 50%]\nsympy/physics/tests/test_secondquant.py::test_substitute_dummies_without_dummies PASSED [ 52%]\nsympy/physics/tests/test_secondquant.py::test_substitute_dummies_NO_operator PASSED [ 54%]\nsympy/physics/tests/test_secondquant.py::test_substitute_dummies_SQ_operator PASSED [ 56%]\nsympy/physics/tests/test_secondquant.py::test_substitute_dummies_new_indices PASSED [ 58%]\nsympy/physics/tests/test_secondquant.py::test_substitute_dummies_substitution_order PASSED [ 60%]\nsympy/physics/tests/test_secondquant.py::test_dummy_order_inner_outer_lines_VT1T1T1 PASSED [ 62%]\nsympy/physics/tests/test_secondquant.py::test_dummy_order_inner_outer_lines_VT1T1T1T1 PASSED [ 64%]\nsympy/physics/tests/test_secondquant.py::test_get_subNO PASSED           [ 66%]\nsympy/physics/tests/test_secondquant.py::test_equivalent_internal_lines_VT1T1 PASSED [ 67%]\nsympy/physics/tests/test_secondquant.py::test_equivalent_internal_lines_VT2conjT2 PASSED [ 69%]\nsympy/physics/tests/test_secondquant.py::test_equivalent_internal_lines_VT2conjT2_ambiguous_order PASSED [ 71%]\nsympy/physics/tests/test_secondquant.py::test_equivalent_internal_lines_VT2 PASSED [ 73%]\nsympy/physics/tests/test_secondquant.py::test_internal_external_VT2T2 PASSED [ 75%]\nsympy/physics/tests/test_secondquant.py::test_internal_external_pqrs PASSED [ 77%]\nsympy/physics/tests/test_secondquant.py::test_dummy_order_well_defined PASSED [ 79%]\nsympy/physics/tests/test_secondquant.py::test_dummy_order_ambiguous PASSED [ 81%]\nsympy/physics/tests/test_secondquant.py::test_dummy_order_inner_outer_lines_VT1T1T1_AT PASSED [ 83%]\nsympy/physics/tests/test_secondquant.py::test_dummy_order_inner_outer_lines_VT1T1T1T1_AT PASSED [ 84%]\nsympy/physics/tests/test_secondquant.py::test_equivalent_internal_lines_VT1T1_AT PASSED [ 86%]\nsympy/physics/tests/test_secondquant.py::test_equivalent_internal_lines_VT2conjT2_AT PASSED [ 88%]\nsympy/physics/tests/test_secondquant.py::test_equivalent_internal_lines_VT2conjT2_ambiguous_order_AT PASSED [ 90%]\nsympy/physics/tests/test_secondquant.py::test_equivalent_internal_lines_VT2_AT PASSED [ 92%]\nsympy/physics/tests/test_secondquant.py::test_internal_external_VT2T2_AT PASSED [ 94%]\nsympy/physics/tests/test_secondquant.py::test_internal_external_pqrs_AT PASSED [ 96%]\nsympy/physics/tests/test_secondquant.py::test_issue_19661 PASSED         [ 98%]\nsympy/physics/tests/test_secondquant.py::test_canonical_ordering_AntiSymmetricTensor PASSED [100%]\n\n============================= 53 passed in 16.50s ==============================\n\n",
          "test_files_run": [
            "sympy/physics/tests/test_secondquant.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "matplotlib__matplotlib-20676",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://34.44.241.183:8080",
      "duration": 22.33727788925171,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 32,
          "failed": 3,
          "errors": 0,
          "collected": 36,
          "duration": 10.6,
          "log_tail": "lib/matplotlib/tests/test_widgets.py::test_range_slider[vertical] PASSED [ 66%]\nlib/matplotlib/tests/test_widgets.py::test_polygon_selector PASSED       [ 69%]\nlib/matplotlib/tests/test_widgets.py::test_MultiCursor[True-True] PASSED [ 72%]\nlib/matplotlib/tests/test_widgets.py::test_MultiCursor[True-False] PASSED [ 75%]\nlib/matplotlib/tests/test_widgets.py::test_MultiCursor[False-True] PASSED [ 77%]\nlib/matplotlib/tests/test_widgets.py::test_rect_visibility[png] PASSED   [ 80%]\nlib/matplotlib/tests/test_widgets.py::test_rect_visibility[pdf] PASSED   [ 83%]\nlib/matplotlib/tests/test_widgets.py::test_rect_visibility[svg] SKIPPED  [ 86%]\nlib/matplotlib/tests/test_widgets.py::test_polygon_selector_remove[1] PASSED [ 88%]\nlib/matplotlib/tests/test_widgets.py::test_polygon_selector_remove[2] PASSED [ 91%]\nlib/matplotlib/tests/test_widgets.py::test_polygon_selector_remove[3] PASSED [ 94%]\nlib/matplotlib/tests/test_widgets.py::test_polygon_selector_remove_first_point PASSED [ 97%]\nlib/matplotlib/tests/test_widgets.py::test_polygon_selector_redraw PASSED [100%]\n\n=================================== FAILURES ===================================\n___________________________ test_rectangle_selector ____________________________\nlib/matplotlib/tests/test_widgets.py:45: in test_rectangle_selector\n    check_rectangle(drawtype='line', useblit=False)\nE   matplotlib._api.deprecation.MatplotlibDeprecationWarning: \nE   The 'drawtype' parameter of __init__() was deprecated in Matplotlib 3.5 and will be removed two minor releases later. If any parameter follows 'drawtype', they should be passed as keyword, not positionally.\n_____________________ test_span_selector_bound[horizontal] _____________________\nlib/matplotlib/tests/test_widgets.py:314: in test_span_selector_bound\n    assert ax.get_xbound() == x_bound\nE   AssertionError: assert (0.0, 20.0) == (10.0, 20.0)\nE     \nE     At index 0 diff: 0.0 != 10.0\nE     \nE     Full diff:\nE       (\nE     -     10.0,\nE     ?     -...\nE     \nE     ...Full output truncated (3 lines hidden), use '-vv' to show\n______________________ test_span_selector_bound[vertical] ______________________\nlib/matplotlib/tests/test_widgets.py:315: in test_span_selector_bound\n    assert ax.get_ybound() == y_bound\nE   AssertionError: assert (0.0, 30.0) == (10.0, 30.0)\nE     \nE     At index 0 diff: 0.0 != 10.0\nE     \nE     Full diff:\nE       (\nE     -     10.0,\nE     ?     -...\nE     \nE     ...Full output truncated (3 lines hidden), use '-vv' to show\n=================== 3 failed, 32 passed, 1 skipped in 8.04s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_widgets.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_widgets.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 34,
          "failed": 1,
          "errors": 0,
          "collected": 36,
          "duration": 10.87,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 36 items\n\nlib/matplotlib/tests/test_widgets.py::test_rectangle_selector FAILED     [  2%]\nlib/matplotlib/tests/test_widgets.py::test_rectangle_drag[True-new_center0] PASSED [  5%]\nlib/matplotlib/tests/test_widgets.py::test_rectangle_drag[False-new_center1] PASSED [  8%]\nlib/matplotlib/tests/test_widgets.py::test_ellipse PASSED                [ 11%]\nlib/matplotlib/tests/test_widgets.py::test_rectangle_handles PASSED      [ 13%]\nlib/matplotlib/tests/test_widgets.py::test_span_selector PASSED          [ 16%]\nlib/matplotlib/tests/test_widgets.py::test_span_selector_drag[True] PASSED [ 19%]\nlib/matplotlib/tests/test_widgets.py::test_span_selector_drag[False] PASSED [ 22%]\nlib/matplotlib/tests/test_widgets.py::test_span_selector_direction PASSED [ 25%]\nlib/matplotlib/tests/test_widgets.py::test_tool_line_handle PASSED       [ 27%]\nlib/matplotlib/tests/test_widgets.py::test_span_selector_bound[horizontal] PASSED [ 30%]\nlib/matplotlib/tests/test_widgets.py::test_span_selector_bound[vertical] PASSED [ 33%]\nlib/matplotlib/tests/test_widgets.py::test_lasso_selector PASSED         [ 36%]\nlib/matplotlib/tests/test_widgets.py::test_CheckButtons PASSED           [ 38%]\nlib/matplotlib/tests/test_widgets.py::test_TextBox PASSED                [ 41%]\nlib/matplotlib/tests/test_widgets.py::test_check_radio_buttons_image[png] PASSED [ 44%]\nlib/matplotlib/tests/test_widgets.py::test_check_bunch_of_radio_buttons[png] PASSED [ 47%]\nlib/matplotlib/tests/test_widgets.py::test_slider_slidermin_slidermax_invalid PASSED [ 50%]\nlib/matplotlib/tests/test_widgets.py::test_slider_slidermin_slidermax PASSED [ 52%]\nlib/matplotlib/tests/test_widgets.py::test_slider_valmin_valmax PASSED   [ 55%]\nlib/matplotlib/tests/test_widgets.py::test_slider_valstep_snapping PASSED [ 58%]\nlib/matplotlib/tests/test_widgets.py::test_slider_horizontal_vertical PASSED [ 61%]\nlib/matplotlib/tests/test_widgets.py::test_range_slider[horizontal] PASSED [ 63%]\nlib/matplotlib/tests/test_widgets.py::test_range_slider[vertical] PASSED [ 66%]\nlib/matplotlib/tests/test_widgets.py::test_polygon_selector PASSED       [ 69%]\nlib/matplotlib/tests/test_widgets.py::test_MultiCursor[True-True] PASSED [ 72%]\nlib/matplotlib/tests/test_widgets.py::test_MultiCursor[True-False] PASSED [ 75%]\nlib/matplotlib/tests/test_widgets.py::test_MultiCursor[False-True] PASSED [ 77%]\nlib/matplotlib/tests/test_widgets.py::test_rect_visibility[png] PASSED   [ 80%]\nlib/matplotlib/tests/test_widgets.py::test_rect_visibility[pdf] PASSED   [ 83%]\nlib/matplotlib/tests/test_widgets.py::test_rect_visibility[svg] SKIPPED  [ 86%]\nlib/matplotlib/tests/test_widgets.py::test_polygon_selector_remove[1] PASSED [ 88%]\nlib/matplotlib/tests/test_widgets.py::test_polygon_selector_remove[2] PASSED [ 91%]\nlib/matplotlib/tests/test_widgets.py::test_polygon_selector_remove[3] PASSED [ 94%]\nlib/matplotlib/tests/test_widgets.py::test_polygon_selector_remove_first_point PASSED [ 97%]\nlib/matplotlib/tests/test_widgets.py::test_polygon_selector_redraw PASSED [100%]\n\n=================================== FAILURES ===================================\n___________________________ test_rectangle_selector ____________________________\nlib/matplotlib/tests/test_widgets.py:45: in test_rectangle_selector\n    check_rectangle(drawtype='line', useblit=False)\nE   matplotlib._api.deprecation.MatplotlibDeprecationWarning: \nE   The 'drawtype' parameter of __init__() was deprecated in Matplotlib 3.5 and will be removed two minor releases later. If any parameter follows 'drawtype', they should be passed as keyword, not positionally.\n=================== 1 failed, 34 passed, 1 skipped in 8.28s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_widgets.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_widgets.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sympy__sympy-13878",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://34.44.241.183:8080",
      "error": "HTTPConnectionPool(host='34.44.241.183', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 1
    },
    {
      "instance_id": "matplotlib__matplotlib-13989",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10cf2f8f0>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 1
    },
    {
      "instance_id": "sympy__sympy-18199",
      "repo": "sympy/sympy",
      "valid": true,
      "worker": "http://34.70.1.155:8080",
      "duration": 105.1990602016449,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 116,
          "failed": 2,
          "errors": 0,
          "collected": 132,
          "duration": 52.05,
          "log_tail": "sympy/solvers/tests/test_solveset.py::test_issue_14454 PASSED            [ 85%]\nsympy/solvers/tests/test_solveset.py::test_term_factors PASSED           [ 86%]\nsympy/solvers/tests/test_solveset.py::test_transolve PASSED              [ 87%]\nsympy/solvers/tests/test_solveset.py::test_exponential_real PASSED       [ 87%]\nsympy/solvers/tests/test_solveset.py::test_exponential_complex XFAIL     [ 88%]\nsympy/solvers/tests/test_solveset.py::test_expo_conditionset PASSED      [ 89%]\nsympy/solvers/tests/test_solveset.py::test_exponential_symbols PASSED    [ 90%]\nsympy/solvers/tests/test_solveset.py::test_issue_10864 XFAIL             [ 90%]\nsympy/solvers/tests/test_solveset.py::test_solve_only_exp_2 XFAIL        [ 91%]\nsympy/solvers/tests/test_solveset.py::test_is_exponential PASSED         [ 92%]\nsympy/solvers/tests/test_solveset.py::test_solve_exponential PASSED      [ 93%]\nsympy/solvers/tests/test_solveset.py::test_logarithmic PASSED            [ 93%]\nsympy/solvers/tests/test_solveset.py::test_uselogcombine_2 XFAIL         [ 94%]\nsympy/solvers/tests/test_solveset.py::test_is_logarithmic PASSED         [ 95%]\nsympy/solvers/tests/test_solveset.py::test_solve_logarithm PASSED        [ 96%]\nsympy/solvers/tests/test_solveset.py::test_linear_coeffs PASSED          [ 96%]\nsympy/solvers/tests/test_solveset.py::test_is_modular PASSED             [ 97%]\nsympy/solvers/tests/test_solveset.py::test_invert_modular PASSED         [ 98%]\nsympy/solvers/tests/test_solveset.py::test_solve_modular FAILED          [ 99%]\nsympy/solvers/tests/test_solveset.py::test_solve_modular_fail XFAIL      [100%]\n\n=================================== FAILURES ===================================\n_________________________________ test_residue _________________________________\nsympy/ntheory/tests/test_residue.py:166: in test_residue\n    assert nthroot_mod(29, 31, 74) == [45]\nsympy/ntheory/residue_ntheory.py:777: in nthroot_mod\n    raise NotImplementedError(\"Not implemented for composite p\")\nE   NotImplementedError: Not implemented for composite p\n______________________________ test_solve_modular ______________________________\nsympy/solvers/tests/test_solveset.py:2246: in test_solve_modular\n    assert solveset(Mod(x**3, 8) - 1, x, S.Integers) == \\\nE   assert ConditionSet(x, Eq(Mod(x**3, 8) - 1, 0), Integers) == ImageSet(Lambda(_n, 8*_n + 1), Integers)\nE    +  where ConditionSet(x, Eq(Mod(x**3, 8) - 1, 0), Integers) = solveset((Mod(x**3, 8) - 1), x, Integers)\nE    +    where Mod(x**3, 8) = Mod((x ** 3), 8)\nE    +    and   Integers = S.Integers\nE    +  and   ImageSet(Lambda(_n, 8*_n + 1), Integers) = ImageSet(Lambda(_n, 8*_n + 1), Integers)\nE    +    where Lambda(_n, 8*_n + 1) = Lambda(_n, ((8 * _n) + 1))\nE    +    and   Integers = S.Integers\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n                                DO *NOT* COMMIT!                                \n======= 2 failed, 116 passed, 2 skipped, 12 xfailed, 1 warning in 45.10s =======\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sympy/ntheory/tests/test_residue.py sympy/solvers/tests/test_solveset.py` failed. (See above for error)",
          "test_files_run": [
            "sympy/ntheory/tests/test_residue.py",
            "sympy/solvers/tests/test_solveset.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 118,
          "failed": 0,
          "errors": 0,
          "collected": 132,
          "duration": 52.26,
          "log_tail": "sympy/solvers/tests/test_solveset.py::test_issue_10397 PASSED            [ 71%]\nsympy/solvers/tests/test_solveset.py::test_issue_14987 PASSED            [ 71%]\nsympy/solvers/tests/test_solveset.py::test_simplification PASSED         [ 72%]\nsympy/solvers/tests/test_solveset.py::test_issue_10555 PASSED            [ 73%]\nsympy/solvers/tests/test_solveset.py::test_issue_8715 PASSED             [ 74%]\nsympy/solvers/tests/test_solveset.py::test_issue_11174 PASSED            [ 75%]\nsympy/solvers/tests/test_solveset.py::test_issue_11534 PASSED            [ 75%]\nsympy/solvers/tests/test_solveset.py::test_issue_10477 PASSED            [ 76%]\nsympy/solvers/tests/test_solveset.py::test_issue_10671 PASSED            [ 77%]\nsympy/solvers/tests/test_solveset.py::test_issue_11064 PASSED            [ 78%]\nsympy/solvers/tests/test_solveset.py::test_issue_12478 PASSED            [ 78%]\nsympy/solvers/tests/test_solveset.py::test_issue_12429 PASSED            [ 79%]\nsympy/solvers/tests/test_solveset.py::test_solveset_arg PASSED           [ 80%]\nsympy/solvers/tests/test_solveset.py::test__is_finite_with_finite_vars PASSED [ 81%]\nsympy/solvers/tests/test_solveset.py::test_issue_13550 PASSED            [ 81%]\nsympy/solvers/tests/test_solveset.py::test_issue_13849 PASSED            [ 82%]\nsympy/solvers/tests/test_solveset.py::test_issue_14223 PASSED            [ 83%]\nsympy/solvers/tests/test_solveset.py::test_issue_10158 PASSED            [ 84%]\nsympy/solvers/tests/test_solveset.py::test_issue_14300 PASSED            [ 84%]\nsympy/solvers/tests/test_solveset.py::test_issue_14454 PASSED            [ 85%]\nsympy/solvers/tests/test_solveset.py::test_term_factors PASSED           [ 86%]\nsympy/solvers/tests/test_solveset.py::test_transolve PASSED              [ 87%]\nsympy/solvers/tests/test_solveset.py::test_exponential_real PASSED       [ 87%]\nsympy/solvers/tests/test_solveset.py::test_exponential_complex XFAIL     [ 88%]\nsympy/solvers/tests/test_solveset.py::test_expo_conditionset PASSED      [ 89%]\nsympy/solvers/tests/test_solveset.py::test_exponential_symbols PASSED    [ 90%]\nsympy/solvers/tests/test_solveset.py::test_issue_10864 XFAIL             [ 90%]\nsympy/solvers/tests/test_solveset.py::test_solve_only_exp_2 XFAIL        [ 91%]\nsympy/solvers/tests/test_solveset.py::test_is_exponential PASSED         [ 92%]\nsympy/solvers/tests/test_solveset.py::test_solve_exponential PASSED      [ 93%]\nsympy/solvers/tests/test_solveset.py::test_logarithmic PASSED            [ 93%]\nsympy/solvers/tests/test_solveset.py::test_uselogcombine_2 XFAIL         [ 94%]\nsympy/solvers/tests/test_solveset.py::test_is_logarithmic PASSED         [ 95%]\nsympy/solvers/tests/test_solveset.py::test_solve_logarithm PASSED        [ 96%]\nsympy/solvers/tests/test_solveset.py::test_linear_coeffs PASSED          [ 96%]\nsympy/solvers/tests/test_solveset.py::test_is_modular PASSED             [ 97%]\nsympy/solvers/tests/test_solveset.py::test_invert_modular PASSED         [ 98%]\nsympy/solvers/tests/test_solveset.py::test_solve_modular PASSED          [ 99%]\nsympy/solvers/tests/test_solveset.py::test_solve_modular_fail XPASS      [100%]\n\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:1474: PytestConfigWarning: Unknown config option: doctestplus\n  \n    self._warn_or_fail_if_strict(f\"Unknown config option: {key}\\n\")\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n====== 118 passed, 2 skipped, 11 xfailed, 1 xpassed, 1 warning in 46.14s =======\n\n",
          "test_files_run": [
            "sympy/ntheory/tests/test_residue.py",
            "sympy/solvers/tests/test_solveset.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "matplotlib__matplotlib-23299",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "duration": 18.524970054626465,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 204,
          "failed": 3,
          "errors": 0,
          "collected": 208,
          "duration": 9.95,
          "log_tail": "lib/matplotlib/tests/test_rcparams.py::test_validate_fontstretch[stretch7-ValueError] PASSED [ 97%]\nlib/matplotlib/tests/test_rcparams.py::test_keymaps PASSED               [ 97%]\nlib/matplotlib/tests/test_rcparams.py::test_no_backend_reset_rccontext FAILED [ 98%]\nlib/matplotlib/tests/test_rcparams.py::test_rcparams_reset_after_fail PASSED [ 98%]\nlib/matplotlib/tests/test_rcparams.py::test_backend_fallback_headless PASSED [ 99%]\nlib/matplotlib/tests/test_rcparams.py::test_backend_fallback_headful SKIPPED [ 99%]\nlib/matplotlib/tests/test_rcparams.py::test_deprecation PASSED           [100%]\n\n=================================== FAILURES ===================================\n_____________________________ test_rcparams_update _____________________________\nlib/matplotlib/tests/test_rcparams.py:111: in test_rcparams_update\n    rc.update(bad_dict)\n<frozen _collections_abc>:949: in update\n    ???\nlib/matplotlib/__init__.py:651: in __setitem__\n    raise ValueError(f\"Key {key}: {ve}\") from None\nE   ValueError: Key figure.figsize: Expected 2 values, but there are 3 values in (3.5, 42, 1)\n\nDuring handling of the above exception, another exception occurred:\nlib/matplotlib/tests/test_rcparams.py:109: in test_rcparams_update\n    with pytest.raises(ValueError), \\\nE   Failed: DID NOT WARN. No warnings of type (<class 'UserWarning'>,) were emitted.\nE    Emitted warnings: [].\n______________________________ test_rcparams_init ______________________________\nlib/matplotlib/tests/test_rcparams.py:117: in test_rcparams_init\n    mpl.RcParams({'figure.figsize': (3.5, 42, 1)})\nlib/matplotlib/__init__.py:626: in __init__\n    self.update(*args, **kwargs)\n<frozen _collections_abc>:949: in update\n    ???\nlib/matplotlib/__init__.py:651: in __setitem__\n    raise ValueError(f\"Key {key}: {ve}\") from None\nE   ValueError: Key figure.figsize: Expected 2 values, but there are 3 values in (3.5, 42, 1)\n\nDuring handling of the above exception, another exception occurred:\nlib/matplotlib/tests/test_rcparams.py:115: in test_rcparams_init\n    with pytest.raises(ValueError), \\\nE   Failed: DID NOT WARN. No warnings of type (<class 'UserWarning'>,) were emitted.\nE    Emitted warnings: [].\n_______________________ test_no_backend_reset_rccontext ________________________\nlib/matplotlib/tests/test_rcparams.py:503: in test_no_backend_reset_rccontext\n    assert mpl.rcParams['backend'] == 'module://aardvark'\nE   AssertionError: assert 'agg' == 'module://aardvark'\nE     \nE     - module://aardvark\nE     + agg\n=================== 3 failed, 204 passed, 1 skipped in 5.29s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_rcparams.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_rcparams.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 205,
          "failed": 2,
          "errors": 0,
          "collected": 208,
          "duration": 7.76,
          "log_tail": "lib/matplotlib/tests/test_rcparams.py::test_validate_fontstretch[expanded-expanded] PASSED [ 93%]\nlib/matplotlib/tests/test_rcparams.py::test_validate_fontstretch[EXPANDED-ValueError] PASSED [ 94%]\nlib/matplotlib/tests/test_rcparams.py::test_validate_fontstretch[100-100_0] PASSED [ 94%]\nlib/matplotlib/tests/test_rcparams.py::test_validate_fontstretch[100-100_1] PASSED [ 95%]\nlib/matplotlib/tests/test_rcparams.py::test_validate_fontstretch[stretch4-100] PASSED [ 95%]\nlib/matplotlib/tests/test_rcparams.py::test_validate_fontstretch[20.6-20] PASSED [ 96%]\nlib/matplotlib/tests/test_rcparams.py::test_validate_fontstretch[20.6-ValueError] PASSED [ 96%]\nlib/matplotlib/tests/test_rcparams.py::test_validate_fontstretch[stretch7-ValueError] PASSED [ 97%]\nlib/matplotlib/tests/test_rcparams.py::test_keymaps PASSED               [ 97%]\nlib/matplotlib/tests/test_rcparams.py::test_no_backend_reset_rccontext PASSED [ 98%]\nlib/matplotlib/tests/test_rcparams.py::test_rcparams_reset_after_fail PASSED [ 98%]\nlib/matplotlib/tests/test_rcparams.py::test_backend_fallback_headless PASSED [ 99%]\nlib/matplotlib/tests/test_rcparams.py::test_backend_fallback_headful SKIPPED [ 99%]\nlib/matplotlib/tests/test_rcparams.py::test_deprecation PASSED           [100%]\n\n=================================== FAILURES ===================================\n_____________________________ test_rcparams_update _____________________________\nlib/matplotlib/tests/test_rcparams.py:111: in test_rcparams_update\n    rc.update(bad_dict)\n<frozen _collections_abc>:949: in update\n    ???\nlib/matplotlib/__init__.py:651: in __setitem__\n    raise ValueError(f\"Key {key}: {ve}\") from None\nE   ValueError: Key figure.figsize: Expected 2 values, but there are 3 values in (3.5, 42, 1)\n\nDuring handling of the above exception, another exception occurred:\nlib/matplotlib/tests/test_rcparams.py:109: in test_rcparams_update\n    with pytest.raises(ValueError), \\\nE   Failed: DID NOT WARN. No warnings of type (<class 'UserWarning'>,) were emitted.\nE    Emitted warnings: [].\n______________________________ test_rcparams_init ______________________________\nlib/matplotlib/tests/test_rcparams.py:117: in test_rcparams_init\n    mpl.RcParams({'figure.figsize': (3.5, 42, 1)})\nlib/matplotlib/__init__.py:626: in __init__\n    self.update(*args, **kwargs)\n<frozen _collections_abc>:949: in update\n    ???\nlib/matplotlib/__init__.py:651: in __setitem__\n    raise ValueError(f\"Key {key}: {ve}\") from None\nE   ValueError: Key figure.figsize: Expected 2 values, but there are 3 values in (3.5, 42, 1)\n\nDuring handling of the above exception, another exception occurred:\nlib/matplotlib/tests/test_rcparams.py:115: in test_rcparams_init\n    with pytest.raises(ValueError), \\\nE   Failed: DID NOT WARN. No warnings of type (<class 'UserWarning'>,) were emitted.\nE    Emitted warnings: [].\n=================== 2 failed, 205 passed, 1 skipped in 5.18s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_rcparams.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_rcparams.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "matplotlib__matplotlib-20859",
      "repo": "matplotlib/matplotlib",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 39.02047610282898,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 88,
          "failed": 1,
          "errors": 0,
          "collected": 99,
          "duration": 18.96,
          "log_tail": "lib/matplotlib/tests/test_legend.py::test_window_extent_cached_renderer PASSED [ 64%]\nlib/matplotlib/tests/test_legend.py::test_legend_title_fontprop_fontsize PASSED [ 65%]\nlib/matplotlib/tests/test_legend.py::test_legend_labelcolor_single[red] PASSED [ 66%]\nlib/matplotlib/tests/test_legend.py::test_legend_labelcolor_single[none] PASSED [ 67%]\nlib/matplotlib/tests/test_legend.py::test_legend_labelcolor_single[color2] PASSED [ 68%]\nlib/matplotlib/tests/test_legend.py::test_legend_labelcolor_list PASSED  [ 69%]\nlib/matplotlib/tests/test_legend.py::test_legend_labelcolor_linecolor PASSED [ 70%]\nlib/matplotlib/tests/test_legend.py::test_legend_labelcolor_markeredgecolor PASSED [ 71%]\nlib/matplotlib/tests/test_legend.py::test_legend_labelcolor_markerfacecolor PASSED [ 72%]\nlib/matplotlib/tests/test_legend.py::test_legend_labelcolor_rcparam_single[red] PASSED [ 73%]\nlib/matplotlib/tests/test_legend.py::test_legend_labelcolor_rcparam_single[none] PASSED [ 74%]\nlib/matplotlib/tests/test_legend.py::test_legend_labelcolor_rcparam_single[color2] PASSED [ 75%]\nlib/matplotlib/tests/test_legend.py::test_legend_labelcolor_rcparam_linecolor PASSED [ 76%]\nlib/matplotlib/tests/test_legend.py::test_legend_labelcolor_rcparam_markeredgecolor PASSED [ 77%]\nlib/matplotlib/tests/test_legend.py::test_legend_labelcolor_rcparam_markeredgecolor_short PASSED [ 78%]\nlib/matplotlib/tests/test_legend.py::test_legend_labelcolor_rcparam_markerfacecolor PASSED [ 79%]\nlib/matplotlib/tests/test_legend.py::test_legend_labelcolor_rcparam_markerfacecolor_short PASSED [ 80%]\nlib/matplotlib/tests/test_legend.py::test_get_set_draggable PASSED       [ 81%]\nlib/matplotlib/tests/test_legend.py::test_alpha_handles PASSED           [ 82%]\nlib/matplotlib/tests/test_legend.py::test_usetex_no_warn SKIPPED (Th...) [ 83%]\nlib/matplotlib/tests/test_legend.py::test_warn_big_data_best_loc PASSED  [ 84%]\nlib/matplotlib/tests/test_legend.py::test_no_warn_big_data_when_loc_specified PASSED [ 85%]\nlib/matplotlib/tests/test_legend.py::test_plot_multiple_input_multiple_label[label_array0] PASSED [ 86%]\nlib/matplotlib/tests/test_legend.py::test_plot_multiple_input_multiple_label[label_array1] PASSED [ 87%]\nlib/matplotlib/tests/test_legend.py::test_plot_multiple_input_multiple_label[label_array2] PASSED [ 88%]\nlib/matplotlib/tests/test_legend.py::test_plot_multiple_input_single_label[one] PASSED [ 89%]\nlib/matplotlib/tests/test_legend.py::test_plot_multiple_input_single_label[1] PASSED [ 90%]\nlib/matplotlib/tests/test_legend.py::test_plot_multiple_input_single_label[int] PASSED [ 91%]\nlib/matplotlib/tests/test_legend.py::test_plot_single_input_multiple_label[label_array0] PASSED [ 92%]\nlib/matplotlib/tests/test_legend.py::test_plot_single_input_multiple_label[label_array1] PASSED [ 93%]\nlib/matplotlib/tests/test_legend.py::test_plot_single_input_multiple_label[label_array2] PASSED [ 94%]\nlib/matplotlib/tests/test_legend.py::test_plot_multiple_label_incorrect_length_exception PASSED [ 95%]\nlib/matplotlib/tests/test_legend.py::test_legend_face_edgecolor PASSED   [ 96%]\nlib/matplotlib/tests/test_legend.py::test_legend_text_axes PASSED        [ 97%]\nlib/matplotlib/tests/test_legend.py::test_handlerline2d PASSED           [ 98%]\nlib/matplotlib/tests/test_legend.py::test_subfigure_legend FAILED        [100%]\n\n=================================== FAILURES ===================================\n____________________________ test_subfigure_legend _____________________________\nlib/matplotlib/tests/test_legend.py:881: in test_subfigure_legend\n    leg = subfig.legend()\nlib/matplotlib/figure.py:1068: in legend\n    l = mlegend.Legend(self, handles, labels, *extra_args,\nlib/matplotlib/legend.py:441: in __init__\n    raise TypeError(\"Legend needs either Axes or Figure as parent\")\nE   TypeError: Legend needs either Axes or Figure as parent\n================== 1 failed, 88 passed, 10 skipped in 16.32s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_legend.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_legend.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 89,
          "failed": 0,
          "errors": 0,
          "collected": 99,
          "duration": 18.89,
          "log_tail": "lib/matplotlib/tests/test_legend.py::test_nanscatter PASSED              [ 54%]\nlib/matplotlib/tests/test_legend.py::test_legend_repeatcheckok PASSED    [ 55%]\nlib/matplotlib/tests/test_legend.py::test_not_covering_scatter[png] PASSED [ 56%]\nlib/matplotlib/tests/test_legend.py::test_not_covering_scatter_transform[png] PASSED [ 57%]\nlib/matplotlib/tests/test_legend.py::test_linecollection_scaled_dashes PASSED [ 58%]\nlib/matplotlib/tests/test_legend.py::test_handler_numpoints PASSED       [ 59%]\nlib/matplotlib/tests/test_legend.py::test_empty_bar_chart_with_legend PASSED [ 60%]\nlib/matplotlib/tests/test_legend.py::test_shadow_framealpha PASSED       [ 61%]\nlib/matplotlib/tests/test_legend.py::test_legend_title_empty PASSED      [ 62%]\nlib/matplotlib/tests/test_legend.py::test_legend_proper_window_extent PASSED [ 63%]\nlib/matplotlib/tests/test_legend.py::test_window_extent_cached_renderer PASSED [ 64%]\nlib/matplotlib/tests/test_legend.py::test_legend_title_fontprop_fontsize PASSED [ 65%]\nlib/matplotlib/tests/test_legend.py::test_legend_labelcolor_single[red] PASSED [ 66%]\nlib/matplotlib/tests/test_legend.py::test_legend_labelcolor_single[none] PASSED [ 67%]\nlib/matplotlib/tests/test_legend.py::test_legend_labelcolor_single[color2] PASSED [ 68%]\nlib/matplotlib/tests/test_legend.py::test_legend_labelcolor_list PASSED  [ 69%]\nlib/matplotlib/tests/test_legend.py::test_legend_labelcolor_linecolor PASSED [ 70%]\nlib/matplotlib/tests/test_legend.py::test_legend_labelcolor_markeredgecolor PASSED [ 71%]\nlib/matplotlib/tests/test_legend.py::test_legend_labelcolor_markerfacecolor PASSED [ 72%]\nlib/matplotlib/tests/test_legend.py::test_legend_labelcolor_rcparam_single[red] PASSED [ 73%]\nlib/matplotlib/tests/test_legend.py::test_legend_labelcolor_rcparam_single[none] PASSED [ 74%]\nlib/matplotlib/tests/test_legend.py::test_legend_labelcolor_rcparam_single[color2] PASSED [ 75%]\nlib/matplotlib/tests/test_legend.py::test_legend_labelcolor_rcparam_linecolor PASSED [ 76%]\nlib/matplotlib/tests/test_legend.py::test_legend_labelcolor_rcparam_markeredgecolor PASSED [ 77%]\nlib/matplotlib/tests/test_legend.py::test_legend_labelcolor_rcparam_markeredgecolor_short PASSED [ 78%]\nlib/matplotlib/tests/test_legend.py::test_legend_labelcolor_rcparam_markerfacecolor PASSED [ 79%]\nlib/matplotlib/tests/test_legend.py::test_legend_labelcolor_rcparam_markerfacecolor_short PASSED [ 80%]\nlib/matplotlib/tests/test_legend.py::test_get_set_draggable PASSED       [ 81%]\nlib/matplotlib/tests/test_legend.py::test_alpha_handles PASSED           [ 82%]\nlib/matplotlib/tests/test_legend.py::test_usetex_no_warn SKIPPED (Th...) [ 83%]\nlib/matplotlib/tests/test_legend.py::test_warn_big_data_best_loc PASSED  [ 84%]\nlib/matplotlib/tests/test_legend.py::test_no_warn_big_data_when_loc_specified PASSED [ 85%]\nlib/matplotlib/tests/test_legend.py::test_plot_multiple_input_multiple_label[label_array0] PASSED [ 86%]\nlib/matplotlib/tests/test_legend.py::test_plot_multiple_input_multiple_label[label_array1] PASSED [ 87%]\nlib/matplotlib/tests/test_legend.py::test_plot_multiple_input_multiple_label[label_array2] PASSED [ 88%]\nlib/matplotlib/tests/test_legend.py::test_plot_multiple_input_single_label[one] PASSED [ 89%]\nlib/matplotlib/tests/test_legend.py::test_plot_multiple_input_single_label[1] PASSED [ 90%]\nlib/matplotlib/tests/test_legend.py::test_plot_multiple_input_single_label[int] PASSED [ 91%]\nlib/matplotlib/tests/test_legend.py::test_plot_single_input_multiple_label[label_array0] PASSED [ 92%]\nlib/matplotlib/tests/test_legend.py::test_plot_single_input_multiple_label[label_array1] PASSED [ 93%]\nlib/matplotlib/tests/test_legend.py::test_plot_single_input_multiple_label[label_array2] PASSED [ 94%]\nlib/matplotlib/tests/test_legend.py::test_plot_multiple_label_incorrect_length_exception PASSED [ 95%]\nlib/matplotlib/tests/test_legend.py::test_legend_face_edgecolor PASSED   [ 96%]\nlib/matplotlib/tests/test_legend.py::test_legend_text_axes PASSED        [ 97%]\nlib/matplotlib/tests/test_legend.py::test_handlerline2d PASSED           [ 98%]\nlib/matplotlib/tests/test_legend.py::test_subfigure_legend PASSED        [100%]\n\n======================= 89 passed, 10 skipped in 16.21s ========================\n\n",
          "test_files_run": [
            "lib/matplotlib/tests/test_legend.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sympy__sympy-17318",
      "repo": "sympy/sympy",
      "valid": false,
      "worker": "http://34.59.30.169:8080",
      "error": "HTTPConnectionPool(host='34.59.30.169', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 1
    },
    {
      "instance_id": "matplotlib__matplotlib-23476",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://35.239.238.137:8080",
      "duration": 40.54958701133728,
      "test_only": {
        "passed": true,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "collected": 112,
          "duration": 20.94,
          "log_tail": "lib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_empty[x5-0-png] PASSED [ 66%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_fail_list_of_str PASSED [ 66%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_subplot_kw[subplot_kw0-png] PASSED [ 67%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_subplot_kw[subplot_kw1-png] PASSED [ 68%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_subplot_kw[None-png] PASSED [ 69%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_string_parser PASSED [ 70%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_single_str_input[AAA\\nBBB-png] PASSED [ 71%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_single_str_input[\\nAAA\\nBBB\\n-png] PASSED [ 72%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_single_str_input[ABC\\nDEF-png] PASSED [ 73%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_fail[x0-(?m)we found that the label .A. specifies a non-rectangular or non-contiguous area.] PASSED [ 74%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_fail[x1-There are duplicate keys .* between the outer layout] PASSED [ 75%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_fail[AAA\\nc\\nBBB-All of the rows must be the same length] PASSED [ 75%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_fail[x3-All of the rows must be the same length] PASSED [ 76%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_hashable_keys[png] PASSED [ 77%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_user_order[abc] PASSED [ 78%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_user_order[cab] PASSED [ 79%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_user_order[bca] PASSED [ 80%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_user_order[cba] PASSED [ 81%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_user_order[acb] PASSED [ 82%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_user_order[bac] PASSED [ 83%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_nested_user_order PASSED [ 83%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_share_all PASSED [ 84%]\nlib/matplotlib/tests/test_figure.py::test_reused_gridspec PASSED         [ 85%]\nlib/matplotlib/tests/test_figure.py::test_subfigure[png] PASSED          [ 86%]\nlib/matplotlib/tests/test_figure.py::test_subfigure_tightbbox PASSED     [ 87%]\nlib/matplotlib/tests/test_figure.py::test_subfigure_dpi PASSED           [ 88%]\nlib/matplotlib/tests/test_figure.py::test_subfigure_ss[png] PASSED       [ 89%]\nlib/matplotlib/tests/test_figure.py::test_subfigure_double[png] PASSED   [ 90%]\nlib/matplotlib/tests/test_figure.py::test_subfigure_spanning PASSED      [ 91%]\nlib/matplotlib/tests/test_figure.py::test_subfigure_ticks PASSED         [ 91%]\nlib/matplotlib/tests/test_figure.py::test_subfigure_scatter_size[png] PASSED [ 92%]\nlib/matplotlib/tests/test_figure.py::test_subfigure_pdf PASSED           [ 93%]\nlib/matplotlib/tests/test_figure.py::test_add_subplot_kwargs PASSED      [ 94%]\nlib/matplotlib/tests/test_figure.py::test_add_axes_kwargs PASSED         [ 95%]\nlib/matplotlib/tests/test_figure.py::test_ginput PASSED                  [ 96%]\nlib/matplotlib/tests/test_figure.py::test_waitforbuttonpress PASSED      [ 97%]\nlib/matplotlib/tests/test_figure.py::test_kwargs_pass PASSED             [ 98%]\nlib/matplotlib/tests/test_figure.py::test_deepcopy PASSED                [ 99%]\nlib/matplotlib/tests/test_figure.py::test_unpickle_with_device_pixel_ratio FAILED [100%]\n\n=================================== FAILURES ===================================\n____________________ test_unpickle_with_device_pixel_ratio _____________________\nlib/matplotlib/tests/test_figure.py:1391: in test_unpickle_with_device_pixel_ratio\n    assert fig2.dpi == 42\nE   assert 294 == 42\nE    +  where 294 = <Figure size 2352x1764 with 0 Axes>.dpi\n================== 1 failed, 104 passed, 7 skipped in 16.25s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_figure.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_figure.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 105,
          "failed": 0,
          "errors": 0,
          "collected": 112,
          "duration": 18.74,
          "log_tail": "lib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_nested[png] PASSED [ 59%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_nested_tuple[png] PASSED [ 60%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_empty[x0-None-png] PASSED [ 61%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_empty[x1-SKIP-png] PASSED [ 62%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_empty[x2-0-png] PASSED [ 63%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_empty[x3-None-png] PASSED [ 64%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_empty[x4-SKIP-png] PASSED [ 65%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_empty[x5-0-png] PASSED [ 66%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_fail_list_of_str PASSED [ 66%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_subplot_kw[subplot_kw0-png] PASSED [ 67%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_subplot_kw[subplot_kw1-png] PASSED [ 68%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_subplot_kw[None-png] PASSED [ 69%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_string_parser PASSED [ 70%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_single_str_input[AAA\\nBBB-png] PASSED [ 71%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_single_str_input[\\nAAA\\nBBB\\n-png] PASSED [ 72%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_single_str_input[ABC\\nDEF-png] PASSED [ 73%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_fail[x0-(?m)we found that the label .A. specifies a non-rectangular or non-contiguous area.] PASSED [ 74%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_fail[x1-There are duplicate keys .* between the outer layout] PASSED [ 75%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_fail[AAA\\nc\\nBBB-All of the rows must be the same length] PASSED [ 75%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_fail[x3-All of the rows must be the same length] PASSED [ 76%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_hashable_keys[png] PASSED [ 77%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_user_order[abc] PASSED [ 78%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_user_order[cab] PASSED [ 79%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_user_order[bca] PASSED [ 80%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_user_order[cba] PASSED [ 81%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_user_order[acb] PASSED [ 82%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_user_order[bac] PASSED [ 83%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_nested_user_order PASSED [ 83%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_share_all PASSED [ 84%]\nlib/matplotlib/tests/test_figure.py::test_reused_gridspec PASSED         [ 85%]\nlib/matplotlib/tests/test_figure.py::test_subfigure[png] PASSED          [ 86%]\nlib/matplotlib/tests/test_figure.py::test_subfigure_tightbbox PASSED     [ 87%]\nlib/matplotlib/tests/test_figure.py::test_subfigure_dpi PASSED           [ 88%]\nlib/matplotlib/tests/test_figure.py::test_subfigure_ss[png] PASSED       [ 89%]\nlib/matplotlib/tests/test_figure.py::test_subfigure_double[png] PASSED   [ 90%]\nlib/matplotlib/tests/test_figure.py::test_subfigure_spanning PASSED      [ 91%]\nlib/matplotlib/tests/test_figure.py::test_subfigure_ticks PASSED         [ 91%]\nlib/matplotlib/tests/test_figure.py::test_subfigure_scatter_size[png] PASSED [ 92%]\nlib/matplotlib/tests/test_figure.py::test_subfigure_pdf PASSED           [ 93%]\nlib/matplotlib/tests/test_figure.py::test_add_subplot_kwargs PASSED      [ 94%]\nlib/matplotlib/tests/test_figure.py::test_add_axes_kwargs PASSED         [ 95%]\nlib/matplotlib/tests/test_figure.py::test_ginput PASSED                  [ 96%]\nlib/matplotlib/tests/test_figure.py::test_waitforbuttonpress PASSED      [ 97%]\nlib/matplotlib/tests/test_figure.py::test_kwargs_pass PASSED             [ 98%]\nlib/matplotlib/tests/test_figure.py::test_deepcopy PASSED                [ 99%]\nlib/matplotlib/tests/test_figure.py::test_unpickle_with_device_pixel_ratio PASSED [100%]\n\n======================= 105 passed, 7 skipped in 16.17s ========================\n\n",
          "test_files_run": [
            "lib/matplotlib/tests/test_figure.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got True\u2192True"
    },
    {
      "instance_id": "matplotlib__matplotlib-22865",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10ce3ef30>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 1
    },
    {
      "instance_id": "matplotlib__matplotlib-14623",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://34.70.1.155:8080",
      "duration": 130.6392810344696,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 400,
          "failed": 181,
          "errors": 0,
          "collected": 654,
          "duration": 65.03,
          "log_tail": "    return func(ax, *map(sanitize_sequence, args), **kwargs)\nlib/matplotlib/axes/_axes.py:6686: in hist\n    input_empty = np.size(x) == 0\n<__array_function__ internals>:200: in size\n    ???\n/opt/miniconda3/envs/testbed/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3233: in size\n    return asarray(a).size\nE   ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.\n=============================== warnings summary ===============================\nlib/matplotlib/__init__.py:200\nlib/matplotlib/__init__.py:200\nlib/matplotlib/__init__.py:200\nlib/matplotlib/__init__.py:200\nlib/matplotlib/__init__.py:200\n  /testbed/lib/matplotlib/__init__.py:200: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(module.__version__) < minver:\n\n../opt/miniconda3/envs/testbed/lib/python3.8/site-packages/setuptools/_distutils/version.py:337\n../opt/miniconda3/envs/testbed/lib/python3.8/site-packages/setuptools/_distutils/version.py:337\n../opt/miniconda3/envs/testbed/lib/python3.8/site-packages/setuptools/_distutils/version.py:337\n../opt/miniconda3/envs/testbed/lib/python3.8/site-packages/setuptools/_distutils/version.py:337\n../opt/miniconda3/envs/testbed/lib/python3.8/site-packages/setuptools/_distutils/version.py:337\n../opt/miniconda3/envs/testbed/lib/python3.8/site-packages/setuptools/_distutils/version.py:337\n  /opt/miniconda3/envs/testbed/lib/python3.8/site-packages/setuptools/_distutils/version.py:337: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    other = LooseVersion(other)\n\nlib/matplotlib/__init__.py:332\n  /testbed/lib/matplotlib/__init__.py:332: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    version = LooseVersion(match.group(1))\n\nlib/matplotlib/tests/test_axes.py::test_pcolormesh[pdf]\n  /testbed/lib/matplotlib/backends/backend_pdf.py:1301: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n    self.write(streamarr.tostring())\n\nlib/matplotlib/tests/test_axes.py::test_stem_args\nlib/matplotlib/tests/test_axes.py::test_stem_dates\n  /opt/miniconda3/envs/testbed/lib/python3.8/site-packages/_pytest/python.py:159: UserWarning: In Matplotlib 3.3 individual lines on a stem plot will be added as a LineCollection instead of individual lines. This significantly improves the performance of a stem plot. To remove this warning and switch to the new behaviour, set the \"use_line_collection\" keyword argument to True.\n    result = testfunction(**testargs)\n\nlib/matplotlib/tests/test_axes.py::test_secondary_xy[png]\n  /testbed/lib/matplotlib/tests/test_axes.py:6100: RuntimeWarning: invalid value encountered in sqrt\n    axsec = secax(0.6, functions=(lambda x: x**2, lambda x: x**(1/2)))\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n===== 181 failed, 400 passed, 73 skipped, 16 warnings in 61.91s (0:01:01) ======\n\n\nMatplotlib is not built with the correct FreeType version to run tests.  Set local_freetype=True in setup.cfg and rebuild. Expect many image comparison failures below. Expected freetype version 2.6.1. Found freetype version 2.11.1. Freetype build type is not local\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_axes.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_axes.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 401,
          "failed": 180,
          "errors": 0,
          "collected": 654,
          "duration": 64.69,
          "log_tail": "    return func(ax, *map(sanitize_sequence, args), **kwargs)\nlib/matplotlib/axes/_axes.py:6686: in hist\n    input_empty = np.size(x) == 0\n<__array_function__ internals>:200: in size\n    ???\n/opt/miniconda3/envs/testbed/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3233: in size\n    return asarray(a).size\nE   ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.\n=============================== warnings summary ===============================\nlib/matplotlib/__init__.py:200\nlib/matplotlib/__init__.py:200\nlib/matplotlib/__init__.py:200\nlib/matplotlib/__init__.py:200\nlib/matplotlib/__init__.py:200\n  /testbed/lib/matplotlib/__init__.py:200: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(module.__version__) < minver:\n\n../opt/miniconda3/envs/testbed/lib/python3.8/site-packages/setuptools/_distutils/version.py:337\n../opt/miniconda3/envs/testbed/lib/python3.8/site-packages/setuptools/_distutils/version.py:337\n../opt/miniconda3/envs/testbed/lib/python3.8/site-packages/setuptools/_distutils/version.py:337\n../opt/miniconda3/envs/testbed/lib/python3.8/site-packages/setuptools/_distutils/version.py:337\n../opt/miniconda3/envs/testbed/lib/python3.8/site-packages/setuptools/_distutils/version.py:337\n../opt/miniconda3/envs/testbed/lib/python3.8/site-packages/setuptools/_distutils/version.py:337\n  /opt/miniconda3/envs/testbed/lib/python3.8/site-packages/setuptools/_distutils/version.py:337: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    other = LooseVersion(other)\n\nlib/matplotlib/__init__.py:332\n  /testbed/lib/matplotlib/__init__.py:332: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    version = LooseVersion(match.group(1))\n\nlib/matplotlib/tests/test_axes.py::test_pcolormesh[pdf]\n  /testbed/lib/matplotlib/backends/backend_pdf.py:1301: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n    self.write(streamarr.tostring())\n\nlib/matplotlib/tests/test_axes.py::test_stem_args\nlib/matplotlib/tests/test_axes.py::test_stem_dates\n  /opt/miniconda3/envs/testbed/lib/python3.8/site-packages/_pytest/python.py:159: UserWarning: In Matplotlib 3.3 individual lines on a stem plot will be added as a LineCollection instead of individual lines. This significantly improves the performance of a stem plot. To remove this warning and switch to the new behaviour, set the \"use_line_collection\" keyword argument to True.\n    result = testfunction(**testargs)\n\nlib/matplotlib/tests/test_axes.py::test_secondary_xy[png]\n  /testbed/lib/matplotlib/tests/test_axes.py:6100: RuntimeWarning: invalid value encountered in sqrt\n    axsec = secax(0.6, functions=(lambda x: x**2, lambda x: x**(1/2)))\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n===== 180 failed, 401 passed, 73 skipped, 16 warnings in 61.59s (0:01:01) ======\n\n\nMatplotlib is not built with the correct FreeType version to run tests.  Set local_freetype=True in setup.cfg and rebuild. Expect many image comparison failures below. Expected freetype version 2.6.1. Found freetype version 2.11.1. Freetype build type is not local\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_axes.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_axes.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "matplotlib__matplotlib-24970",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "duration": 20.79137396812439,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 253,
          "failed": 2,
          "errors": 0,
          "collected": 256,
          "duration": 11.15,
          "log_tail": "lib/matplotlib/tests/test_colors.py::test_has_alpha_channel PASSED       [ 88%]\nlib/matplotlib/tests/test_colors.py::test_cn PASSED                      [ 88%]\nlib/matplotlib/tests/test_colors.py::test_conversions PASSED             [ 89%]\nlib/matplotlib/tests/test_colors.py::test_conversions_masked PASSED      [ 89%]\nlib/matplotlib/tests/test_colors.py::test_to_rgba_array_single_str PASSED [ 89%]\nlib/matplotlib/tests/test_colors.py::test_to_rgba_array_alpha_array PASSED [ 90%]\nlib/matplotlib/tests/test_colors.py::test_failed_conversions PASSED      [ 90%]\nlib/matplotlib/tests/test_colors.py::test_grey_gray PASSED               [ 91%]\nlib/matplotlib/tests/test_colors.py::test_tableau_order PASSED           [ 91%]\nlib/matplotlib/tests/test_colors.py::test_ndarray_subclass_norm PASSED   [ 91%]\nlib/matplotlib/tests/test_colors.py::test_same_color PASSED              [ 92%]\nlib/matplotlib/tests/test_colors.py::test_hex_shorthand_notation PASSED  [ 92%]\nlib/matplotlib/tests/test_colors.py::test_repr_png PASSED                [ 92%]\nlib/matplotlib/tests/test_colors.py::test_repr_html PASSED               [ 93%]\nlib/matplotlib/tests/test_colors.py::test_get_under_over_bad PASSED      [ 93%]\nlib/matplotlib/tests/test_colors.py::test_non_mutable_get_values[over] PASSED [ 94%]\nlib/matplotlib/tests/test_colors.py::test_non_mutable_get_values[under] PASSED [ 94%]\nlib/matplotlib/tests/test_colors.py::test_non_mutable_get_values[bad] PASSED [ 94%]\nlib/matplotlib/tests/test_colors.py::test_colormap_alpha_array PASSED    [ 95%]\nlib/matplotlib/tests/test_colors.py::test_colormap_bad_data_with_alpha PASSED [ 95%]\nlib/matplotlib/tests/test_colors.py::test_2d_to_rgba PASSED              [ 96%]\nlib/matplotlib/tests/test_colors.py::test_set_dict_to_rgba PASSED        [ 96%]\nlib/matplotlib/tests/test_colors.py::test_norm_deepcopy PASSED           [ 96%]\nlib/matplotlib/tests/test_colors.py::test_norm_callback PASSED           [ 97%]\nlib/matplotlib/tests/test_colors.py::test_scalarmappable_norm_update PASSED [ 97%]\nlib/matplotlib/tests/test_colors.py::test_norm_update_figs[png] PASSED   [ 98%]\nlib/matplotlib/tests/test_colors.py::test_norm_update_figs[pdf] PASSED   [ 98%]\nlib/matplotlib/tests/test_colors.py::test_norm_update_figs[svg] SKIPPED  [ 98%]\nlib/matplotlib/tests/test_colors.py::test_make_norm_from_scale_name PASSED [ 99%]\nlib/matplotlib/tests/test_colors.py::test_color_sequences PASSED         [ 99%]\nlib/matplotlib/tests/test_colors.py::test_cm_set_cmap_error PASSED       [100%]\n\n=================================== FAILURES ===================================\n___________________________ test_index_dtype[uint8] ____________________________\nlib/matplotlib/tests/test_colors.py:37: in test_index_dtype\n    assert_array_equal(cm(dtype(0)), cm(0))\nlib/matplotlib/colors.py:730: in __call__\n    xa[xa > self.N - 1] = self._i_over\nE   DeprecationWarning: NumPy will stop allowing conversion of out-of-bound Python integers to integer arrays.  The conversion of 257 to uint8 will fail in the future.\nE   For the old behavior, usually:\nE       np.array(value).astype(dtype)\nE   will give the desired result (the cast overflows).\n______________________ test_double_register_builtin_cmap _______________________\nlib/matplotlib/tests/test_colors.py:149: in test_double_register_builtin_cmap\n    with pytest.warns(UserWarning):\nE   matplotlib._api.deprecation.MatplotlibDeprecationWarning: The register_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps.register(name)`` instead.\n=================== 2 failed, 253 passed, 1 skipped in 6.19s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_colors.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_colors.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 254,
          "failed": 1,
          "errors": 0,
          "collected": 256,
          "duration": 8.79,
          "log_tail": "lib/matplotlib/tests/test_colors.py::test_colormap_reversing[turbo_r] PASSED [ 84%]\nlib/matplotlib/tests/test_colors.py::test_colormap_reversing[twilight] PASSED [ 85%]\nlib/matplotlib/tests/test_colors.py::test_colormap_reversing[twilight_r] PASSED [ 85%]\nlib/matplotlib/tests/test_colors.py::test_colormap_reversing[twilight_shifted] PASSED [ 85%]\nlib/matplotlib/tests/test_colors.py::test_colormap_reversing[twilight_shifted_r] PASSED [ 86%]\nlib/matplotlib/tests/test_colors.py::test_colormap_reversing[viridis] PASSED [ 86%]\nlib/matplotlib/tests/test_colors.py::test_colormap_reversing[viridis_r] PASSED [ 87%]\nlib/matplotlib/tests/test_colors.py::test_colormap_reversing[winter] PASSED [ 87%]\nlib/matplotlib/tests/test_colors.py::test_colormap_reversing[winter_r] PASSED [ 87%]\nlib/matplotlib/tests/test_colors.py::test_has_alpha_channel PASSED       [ 88%]\nlib/matplotlib/tests/test_colors.py::test_cn PASSED                      [ 88%]\nlib/matplotlib/tests/test_colors.py::test_conversions PASSED             [ 89%]\nlib/matplotlib/tests/test_colors.py::test_conversions_masked PASSED      [ 89%]\nlib/matplotlib/tests/test_colors.py::test_to_rgba_array_single_str PASSED [ 89%]\nlib/matplotlib/tests/test_colors.py::test_to_rgba_array_alpha_array PASSED [ 90%]\nlib/matplotlib/tests/test_colors.py::test_failed_conversions PASSED      [ 90%]\nlib/matplotlib/tests/test_colors.py::test_grey_gray PASSED               [ 91%]\nlib/matplotlib/tests/test_colors.py::test_tableau_order PASSED           [ 91%]\nlib/matplotlib/tests/test_colors.py::test_ndarray_subclass_norm PASSED   [ 91%]\nlib/matplotlib/tests/test_colors.py::test_same_color PASSED              [ 92%]\nlib/matplotlib/tests/test_colors.py::test_hex_shorthand_notation PASSED  [ 92%]\nlib/matplotlib/tests/test_colors.py::test_repr_png PASSED                [ 92%]\nlib/matplotlib/tests/test_colors.py::test_repr_html PASSED               [ 93%]\nlib/matplotlib/tests/test_colors.py::test_get_under_over_bad PASSED      [ 93%]\nlib/matplotlib/tests/test_colors.py::test_non_mutable_get_values[over] PASSED [ 94%]\nlib/matplotlib/tests/test_colors.py::test_non_mutable_get_values[under] PASSED [ 94%]\nlib/matplotlib/tests/test_colors.py::test_non_mutable_get_values[bad] PASSED [ 94%]\nlib/matplotlib/tests/test_colors.py::test_colormap_alpha_array PASSED    [ 95%]\nlib/matplotlib/tests/test_colors.py::test_colormap_bad_data_with_alpha PASSED [ 95%]\nlib/matplotlib/tests/test_colors.py::test_2d_to_rgba PASSED              [ 96%]\nlib/matplotlib/tests/test_colors.py::test_set_dict_to_rgba PASSED        [ 96%]\nlib/matplotlib/tests/test_colors.py::test_norm_deepcopy PASSED           [ 96%]\nlib/matplotlib/tests/test_colors.py::test_norm_callback PASSED           [ 97%]\nlib/matplotlib/tests/test_colors.py::test_scalarmappable_norm_update PASSED [ 97%]\nlib/matplotlib/tests/test_colors.py::test_norm_update_figs[png] PASSED   [ 98%]\nlib/matplotlib/tests/test_colors.py::test_norm_update_figs[pdf] PASSED   [ 98%]\nlib/matplotlib/tests/test_colors.py::test_norm_update_figs[svg] SKIPPED  [ 98%]\nlib/matplotlib/tests/test_colors.py::test_make_norm_from_scale_name PASSED [ 99%]\nlib/matplotlib/tests/test_colors.py::test_color_sequences PASSED         [ 99%]\nlib/matplotlib/tests/test_colors.py::test_cm_set_cmap_error PASSED       [100%]\n\n=================================== FAILURES ===================================\n______________________ test_double_register_builtin_cmap _______________________\nlib/matplotlib/tests/test_colors.py:149: in test_double_register_builtin_cmap\n    with pytest.warns(UserWarning):\nE   matplotlib._api.deprecation.MatplotlibDeprecationWarning: The register_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps.register(name)`` instead.\n=================== 1 failed, 254 passed, 1 skipped in 6.18s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_colors.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_colors.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "matplotlib__matplotlib-25122",
      "repo": "matplotlib/matplotlib",
      "valid": true,
      "worker": "http://34.123.9.23:8080",
      "duration": 29.725470066070557,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 2478,
          "failed": 12,
          "errors": 0,
          "collected": 2490,
          "duration": 15.6,
          "log_tail": "E   AssertionError: \nE   Not equal to tolerance rtol=1e-07, atol=1e-08\nE   \nE   Mismatched elements: 51 / 51 (100%)\nE   Max absolute difference: 602971.30790557\nE   Max relative difference: 0.26476368\nE    x: array([1.259197e-04, 2.959055e-04, 4.056243e-04, 4.816066e-04,\nE          3.455267e-04, 2.221068e-03, 5.713080e+02, 6.971239e+04,\nE          7.130906e+05, 1.567900e+06, 1.674423e+06, 1.567905e+06,...\nE    y: array([1.712642e-04, 4.024631e-04, 5.516924e-04, 6.550364e-04,\nE          4.699532e-04, 3.020890e-03, 7.770400e+02, 9.481631e+04,\nE          9.698794e+05, 2.132512e+06, 2.277394e+06, 2.132518e+06,...\n__________ TestSpectral.test_psd_window_flattop[FsAll-onesided-real] ___________\nlib/matplotlib/tests/test_mlab.py:696: in test_psd_window_flattop\n    assert_allclose(spec*win.sum()**2,\n/opt/miniconda3/envs/testbed/lib/python3.11/contextlib.py:81: in inner\n    return func(*args, **kwds)\nE   AssertionError: \nE   Not equal to tolerance rtol=1e-07, atol=1e-08\nE   \nE   Mismatched elements: 51 / 51 (100%)\nE   Max absolute difference: 602971.30790557\nE   Max relative difference: 0.26476368\nE    x: array([1.259197e-04, 2.959055e-04, 4.056243e-04, 4.816066e-04,\nE          3.455267e-04, 2.221068e-03, 5.713080e+02, 6.971239e+04,\nE          7.130906e+05, 1.567900e+06, 1.674423e+06, 1.567905e+06,...\nE    y: array([1.712642e-04, 4.024631e-04, 5.516924e-04, 6.550364e-04,\nE          4.699532e-04, 3.020890e-03, 7.770400e+02, 9.481631e+04,\nE          9.698794e+05, 2.132512e+06, 2.277394e+06, 2.132518e+06,...\n___________ TestSpectral.test_psd_window_flattop[Fs4-onesided-real] ____________\nlib/matplotlib/tests/test_mlab.py:696: in test_psd_window_flattop\n    assert_allclose(spec*win.sum()**2,\n/opt/miniconda3/envs/testbed/lib/python3.11/contextlib.py:81: in inner\n    return func(*args, **kwds)\nE   AssertionError: \nE   Not equal to tolerance rtol=1e-07, atol=1e-08\nE   \nE   Mismatched elements: 25 / 51 (49%)\nE   Max absolute difference: 60.29681452\nE   Max relative difference: 0.26476368\nE    x: array([1.841296e-09, 3.750803e-09, 3.959713e-09, 4.322579e-09,\nE          4.862987e-09, 5.617299e-09, 6.638569e-09, 8.002465e-09,\nE          9.816067e-09, 1.223074e-08, 1.546062e-08, 1.980828e-08,...\nE    y: array([2.504359e-09, 5.101493e-09, 5.385633e-09, 5.879170e-09,\nE          6.614182e-09, 7.640127e-09, 9.029164e-09, 1.088421e-08,\nE          1.335090e-08, 1.663511e-08, 2.102809e-08, 2.694138e-08,...\n======================= 12 failed, 2478 passed in 10.80s =======================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_mlab.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_mlab.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 2490,
          "failed": 0,
          "errors": 0,
          "collected": 2490,
          "duration": 13.24,
          "log_tail": "lib/matplotlib/tests/test_mlab.py::TestSpectral::test_psd_window_hanning[nosig-twosided-real] PASSED [ 98%]\nlib/matplotlib/tests/test_mlab.py::TestSpectral::test_psd_window_hanning_detrend_linear[nosig-twosided-real] PASSED [ 98%]\nlib/matplotlib/tests/test_mlab.py::TestSpectral::test_psd_window_flattop[nosig-twosided-real] PASSED [ 98%]\nlib/matplotlib/tests/test_mlab.py::TestSpectral::test_psd_windowarray[nosig-twosided-real] PASSED [ 98%]\nlib/matplotlib/tests/test_mlab.py::TestSpectral::test_psd_windowarray_scale_by_freq[nosig-twosided-real] PASSED [ 98%]\nlib/matplotlib/tests/test_mlab.py::TestSpectral::test_spectrum[complex-nosig-twosided-real] PASSED [ 98%]\nlib/matplotlib/tests/test_mlab.py::TestSpectral::test_spectrum[magnitude-nosig-twosided-real] PASSED [ 98%]\nlib/matplotlib/tests/test_mlab.py::TestSpectral::test_spectrum[angle-nosig-twosided-real] PASSED [ 98%]\nlib/matplotlib/tests/test_mlab.py::TestSpectral::test_spectrum[phase-nosig-twosided-real] PASSED [ 98%]\nlib/matplotlib/tests/test_mlab.py::TestSpectral::test_specgram[kwargs0-nosig-twosided-real] PASSED [ 98%]\nlib/matplotlib/tests/test_mlab.py::TestSpectral::test_specgram[kwargs1-nosig-twosided-real] PASSED [ 98%]\nlib/matplotlib/tests/test_mlab.py::TestSpectral::test_specgram[kwargs2-nosig-twosided-real] PASSED [ 98%]\nlib/matplotlib/tests/test_mlab.py::TestSpectral::test_specgram[kwargs3-nosig-twosided-real] PASSED [ 98%]\nlib/matplotlib/tests/test_mlab.py::TestSpectral::test_specgram[kwargs4-nosig-twosided-real] PASSED [ 98%]\nlib/matplotlib/tests/test_mlab.py::TestSpectral::test_specgram[kwargs5-nosig-twosided-real] PASSED [ 98%]\nlib/matplotlib/tests/test_mlab.py::TestSpectral::test_specgram[kwargs6-nosig-twosided-real] PASSED [ 98%]\nlib/matplotlib/tests/test_mlab.py::TestSpectral::test_specgram_warn_only1seg[nosig-twosided-real] PASSED [ 98%]\nlib/matplotlib/tests/test_mlab.py::TestSpectral::test_psd_csd_equal[nosig-twosided-real] PASSED [ 98%]\nlib/matplotlib/tests/test_mlab.py::TestSpectral::test_specgram_auto_default_psd_equal[default-nosig-twosided-real] PASSED [ 98%]\nlib/matplotlib/tests/test_mlab.py::TestSpectral::test_specgram_auto_default_psd_equal[psd-nosig-twosided-real] PASSED [ 98%]\nlib/matplotlib/tests/test_mlab.py::TestSpectral::test_specgram_complex_equivalent[magnitude-absolute-nosig-twosided-real] PASSED [ 98%]\nlib/matplotlib/tests/test_mlab.py::TestSpectral::test_specgram_complex_equivalent[angle-angle-nosig-twosided-real] PASSED [ 99%]\nlib/matplotlib/tests/test_mlab.py::TestSpectral::test_specgram_complex_equivalent[phase-<lambda>-nosig-twosided-real] PASSED [ 99%]\nlib/matplotlib/tests/test_mlab.py::TestSpectral::test_psd_windowarray_equal[nosig-twosided-real] PASSED [ 99%]\nlib/matplotlib/tests/test_mlab.py::test_cohere PASSED                    [ 99%]\nlib/matplotlib/tests/test_mlab.py::TestGaussianKDE::test_kde_integer_input PASSED [ 99%]\nlib/matplotlib/tests/test_mlab.py::TestGaussianKDE::test_gaussian_kde_covariance_caching PASSED [ 99%]\nlib/matplotlib/tests/test_mlab.py::TestGaussianKDE::test_kde_bandwidth_method PASSED [ 99%]\nlib/matplotlib/tests/test_mlab.py::TestGaussianKDECustom::test_no_data PASSED [ 99%]\nlib/matplotlib/tests/test_mlab.py::TestGaussianKDECustom::test_single_dataset_element PASSED [ 99%]\nlib/matplotlib/tests/test_mlab.py::TestGaussianKDECustom::test_silverman_multidim_dataset PASSED [ 99%]\nlib/matplotlib/tests/test_mlab.py::TestGaussianKDECustom::test_silverman_singledim_dataset PASSED [ 99%]\nlib/matplotlib/tests/test_mlab.py::TestGaussianKDECustom::test_scott_multidim_dataset PASSED [ 99%]\nlib/matplotlib/tests/test_mlab.py::TestGaussianKDECustom::test_scott_singledim_dataset PASSED [ 99%]\nlib/matplotlib/tests/test_mlab.py::TestGaussianKDECustom::test_scalar_empty_dataset PASSED [ 99%]\nlib/matplotlib/tests/test_mlab.py::TestGaussianKDECustom::test_scalar_covariance_dataset PASSED [ 99%]\nlib/matplotlib/tests/test_mlab.py::TestGaussianKDECustom::test_callable_covariance_dataset PASSED [ 99%]\nlib/matplotlib/tests/test_mlab.py::TestGaussianKDECustom::test_callable_singledim_dataset PASSED [ 99%]\nlib/matplotlib/tests/test_mlab.py::TestGaussianKDECustom::test_wrong_bw_method PASSED [ 99%]\nlib/matplotlib/tests/test_mlab.py::TestGaussianKDEEvaluate::test_evaluate_diff_dim PASSED [ 99%]\nlib/matplotlib/tests/test_mlab.py::TestGaussianKDEEvaluate::test_evaluate_inv_dim PASSED [ 99%]\nlib/matplotlib/tests/test_mlab.py::TestGaussianKDEEvaluate::test_evaluate_dim_and_num PASSED [ 99%]\nlib/matplotlib/tests/test_mlab.py::TestGaussianKDEEvaluate::test_evaluate_point_dim_not_one PASSED [ 99%]\nlib/matplotlib/tests/test_mlab.py::TestGaussianKDEEvaluate::test_evaluate_equal_dim_and_num_lt PASSED [ 99%]\nlib/matplotlib/tests/test_mlab.py::test_psd_onesided_norm PASSED         [ 99%]\nlib/matplotlib/tests/test_mlab.py::test_psd_oversampling PASSED          [100%]\n\n============================ 2490 passed in 10.52s =============================\n\n",
          "test_files_run": [
            "lib/matplotlib/tests/test_mlab.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "matplotlib__matplotlib-25311",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://35.239.238.137:8080",
      "duration": 19.51887798309326,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 181,
          "failed": 2,
          "errors": 0,
          "collected": 183,
          "duration": 10.07,
          "log_tail": "lib/matplotlib/tests/test_pickle.py::test_cmap[cmap147] PASSED           [ 87%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap148] PASSED           [ 87%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap149] PASSED           [ 88%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap150] PASSED           [ 89%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap151] PASSED           [ 89%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap152] PASSED           [ 90%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap153] PASSED           [ 90%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap154] PASSED           [ 91%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap155] PASSED           [ 91%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap156] PASSED           [ 92%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap157] PASSED           [ 92%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap158] PASSED           [ 93%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap159] PASSED           [ 93%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap160] PASSED           [ 94%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap161] PASSED           [ 95%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap162] PASSED           [ 95%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap163] PASSED           [ 96%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap164] PASSED           [ 96%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap165] PASSED           [ 97%]\nlib/matplotlib/tests/test_pickle.py::test_unpickle_canvas PASSED         [ 97%]\nlib/matplotlib/tests/test_pickle.py::test_mpl_toolkits PASSED            [ 98%]\nlib/matplotlib/tests/test_pickle.py::test_standard_norm PASSED           [ 98%]\nlib/matplotlib/tests/test_pickle.py::test_dynamic_norm PASSED            [ 99%]\nlib/matplotlib/tests/test_pickle.py::test_vertexselector PASSED          [100%]\n\n=================================== FAILURES ===================================\n______________________________ test_complete[png] ______________________________\nlib/matplotlib/testing/decorators.py:472: in wrapper\n    func(*args, fig_test=fig_test, fig_ref=fig_ref, **kwargs)\nlib/matplotlib/tests/test_pickle.py:105: in test_complete\n    assert \"FigureCanvasAgg\" not in [arg for op, arg, pos in pickletools.genops(pkl)]\nE   AssertionError: assert 'FigureCanvasAgg' not in [5, 65538, 'matplotlib.figure', None, 'Figure', None, ...]\n------------------------------ Captured log call -------------------------------\nWARNING  matplotlib.legend:legend.py:1330 No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n____________________ test_pickle_load_from_subprocess[png] _____________________\nlib/matplotlib/testing/decorators.py:472: in wrapper\n    func(*args, fig_test=fig_test, fig_ref=fig_ref, **kwargs)\nlib/matplotlib/tests/test_pickle.py:145: in test_pickle_load_from_subprocess\n    loaded_fig = pickle.loads(ast.literal_eval(proc.stdout))\nlib/matplotlib/figure.py:3184: in __setstate__\n    _api.warn_external(\nlib/matplotlib/_api/__init__.py:388: in warn_external\n    warnings.warn(message, category, stacklevel)\nE   UserWarning: This figure was saved with matplotlib version 3.8.0.dev441+g430fb1db88.d19700101 and is unlikely to function correctly.\n------------------------------ Captured log call -------------------------------\nWARNING  matplotlib.legend:legend.py:1330 No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n======================== 2 failed, 181 passed in 5.36s =========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_pickle.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_pickle.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 182,
          "failed": 1,
          "errors": 0,
          "collected": 183,
          "duration": 8.58,
          "log_tail": "lib/matplotlib/tests/test_pickle.py::test_cmap[cmap139] PASSED           [ 83%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap140] PASSED           [ 83%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap141] PASSED           [ 84%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap142] PASSED           [ 84%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap143] PASSED           [ 85%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap144] PASSED           [ 85%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap145] PASSED           [ 86%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap146] PASSED           [ 86%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap147] PASSED           [ 87%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap148] PASSED           [ 87%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap149] PASSED           [ 88%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap150] PASSED           [ 89%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap151] PASSED           [ 89%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap152] PASSED           [ 90%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap153] PASSED           [ 90%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap154] PASSED           [ 91%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap155] PASSED           [ 91%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap156] PASSED           [ 92%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap157] PASSED           [ 92%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap158] PASSED           [ 93%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap159] PASSED           [ 93%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap160] PASSED           [ 94%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap161] PASSED           [ 95%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap162] PASSED           [ 95%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap163] PASSED           [ 96%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap164] PASSED           [ 96%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap165] PASSED           [ 97%]\nlib/matplotlib/tests/test_pickle.py::test_unpickle_canvas PASSED         [ 97%]\nlib/matplotlib/tests/test_pickle.py::test_mpl_toolkits PASSED            [ 98%]\nlib/matplotlib/tests/test_pickle.py::test_standard_norm PASSED           [ 98%]\nlib/matplotlib/tests/test_pickle.py::test_dynamic_norm PASSED            [ 99%]\nlib/matplotlib/tests/test_pickle.py::test_vertexselector PASSED          [100%]\n\n=================================== FAILURES ===================================\n____________________ test_pickle_load_from_subprocess[png] _____________________\nlib/matplotlib/testing/decorators.py:472: in wrapper\n    func(*args, fig_test=fig_test, fig_ref=fig_ref, **kwargs)\nlib/matplotlib/tests/test_pickle.py:145: in test_pickle_load_from_subprocess\n    loaded_fig = pickle.loads(ast.literal_eval(proc.stdout))\nlib/matplotlib/figure.py:3184: in __setstate__\n    _api.warn_external(\nlib/matplotlib/_api/__init__.py:388: in warn_external\n    warnings.warn(message, category, stacklevel)\nE   UserWarning: This figure was saved with matplotlib version 3.8.0.dev441+g430fb1db88.d19700101 and is unlikely to function correctly.\n------------------------------ Captured log call -------------------------------\nWARNING  matplotlib.legend:legend.py:1330 No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n======================== 1 failed, 182 passed in 6.03s =========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_pickle.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_pickle.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "matplotlib__matplotlib-20826",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://34.44.241.183:8080",
      "duration": 149.0946922302246,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 673,
          "failed": 9,
          "errors": 0,
          "collected": 745,
          "duration": 74.23,
          "log_tail": "E   \tresult_images/test_axes/errorbar_mixed_pdf-failed-diff.png\n__________________________ test_pandas_indexing_dates __________________________\nlib/matplotlib/tests/test_axes.py:5741: in test_pandas_indexing_dates\n    ax.plot('dates', 'values', data=without_zero_index)\nlib/matplotlib/axes/_axes.py:1626: in plot\n    lines = [*self._get_lines(*args, data=data, **kwargs)]\nlib/matplotlib/axes/_base.py:312: in __call__\n    yield from self._plot_args(this, kwargs)\nlib/matplotlib/axes/_base.py:487: in _plot_args\n    x = _check_1d(xy[0])\nlib/matplotlib/cbook/__init__.py:1289: in _check_1d\n    ndim = x[:, None].ndim\n/opt/miniconda3/envs/testbed/lib/python3.8/site-packages/pandas/core/series.py:1033: in __getitem__\n    return self._get_with(key)\n/opt/miniconda3/envs/testbed/lib/python3.8/site-packages/pandas/core/series.py:1048: in _get_with\n    return self._get_values_tuple(key)\n/opt/miniconda3/envs/testbed/lib/python3.8/site-packages/pandas/core/series.py:1082: in _get_values_tuple\n    disallow_ndim_indexing(result)\n/opt/miniconda3/envs/testbed/lib/python3.8/site-packages/pandas/core/indexers/utils.py:343: in disallow_ndim_indexing\n    raise ValueError(\nE   ValueError: Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer supported. Convert to a numpy array before indexing instead.\n___________________________ test_pandas_index_shape ____________________________\nlib/matplotlib/tests/test_axes.py:5755: in test_pandas_index_shape\n    ax.plot(df.index, df['YY'])\nlib/matplotlib/axes/_axes.py:1626: in plot\n    lines = [*self._get_lines(*args, data=data, **kwargs)]\nlib/matplotlib/axes/_base.py:312: in __call__\n    yield from self._plot_args(this, kwargs)\nlib/matplotlib/axes/_base.py:487: in _plot_args\n    x = _check_1d(xy[0])\nlib/matplotlib/cbook/__init__.py:1289: in _check_1d\n    ndim = x[:, None].ndim\n/opt/miniconda3/envs/testbed/lib/python3.8/site-packages/pandas/core/indexes/range.py:924: in __getitem__\n    return super().__getitem__(key)\n/opt/miniconda3/envs/testbed/lib/python3.8/site-packages/pandas/core/indexes/base.py:5199: in __getitem__\n    disallow_ndim_indexing(result)\n/opt/miniconda3/envs/testbed/lib/python3.8/site-packages/pandas/core/indexers/utils.py:343: in disallow_ndim_indexing\n    raise ValueError(\nE   ValueError: Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer supported. Convert to a numpy array before indexing instead.\n_________________________ test_shared_axes_clear[png] __________________________\nlib/matplotlib/testing/decorators.py:444: in wrapper\n    _raise_on_image_difference(\nE   matplotlib.testing.exceptions.ImageComparisonFailure: images not close (RMS 12.919):\nE   \tresult_images/test_axes/test_shared_axes_clear[png].png\nE   \tresult_images/test_axes/test_shared_axes_clear[png]-expected.png\nE   \tresult_images/test_axes/test_shared_axes_clear[png]-failed-diff.png\n============= 9 failed, 673 passed, 63 skipped in 71.43s (0:01:11) =============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_axes.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_axes.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 674,
          "failed": 8,
          "errors": 0,
          "collected": 745,
          "duration": 73.85,
          "log_tail": "E   \tresult_images/test_axes/errorbar_mixed-failed-diff.png\n______________________________ test_errorbar[pdf] ______________________________\n/opt/miniconda3/envs/testbed/lib/python3.8/contextlib.py:75: in inner\n    return func(*args, **kwds)\nE   matplotlib.testing.exceptions.ImageComparisonFailure: images not close (RMS 25.943):\nE   \tresult_images/test_axes/errorbar_mixed_pdf.png\nE   \tresult_images/test_axes/errorbar_mixed-expected_pdf.png\nE   \tresult_images/test_axes/errorbar_mixed_pdf-failed-diff.png\n__________________________ test_pandas_indexing_dates __________________________\nlib/matplotlib/tests/test_axes.py:5741: in test_pandas_indexing_dates\n    ax.plot('dates', 'values', data=without_zero_index)\nlib/matplotlib/axes/_axes.py:1626: in plot\n    lines = [*self._get_lines(*args, data=data, **kwargs)]\nlib/matplotlib/axes/_base.py:312: in __call__\n    yield from self._plot_args(this, kwargs)\nlib/matplotlib/axes/_base.py:487: in _plot_args\n    x = _check_1d(xy[0])\nlib/matplotlib/cbook/__init__.py:1289: in _check_1d\n    ndim = x[:, None].ndim\n/opt/miniconda3/envs/testbed/lib/python3.8/site-packages/pandas/core/series.py:1033: in __getitem__\n    return self._get_with(key)\n/opt/miniconda3/envs/testbed/lib/python3.8/site-packages/pandas/core/series.py:1048: in _get_with\n    return self._get_values_tuple(key)\n/opt/miniconda3/envs/testbed/lib/python3.8/site-packages/pandas/core/series.py:1082: in _get_values_tuple\n    disallow_ndim_indexing(result)\n/opt/miniconda3/envs/testbed/lib/python3.8/site-packages/pandas/core/indexers/utils.py:343: in disallow_ndim_indexing\n    raise ValueError(\nE   ValueError: Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer supported. Convert to a numpy array before indexing instead.\n___________________________ test_pandas_index_shape ____________________________\nlib/matplotlib/tests/test_axes.py:5755: in test_pandas_index_shape\n    ax.plot(df.index, df['YY'])\nlib/matplotlib/axes/_axes.py:1626: in plot\n    lines = [*self._get_lines(*args, data=data, **kwargs)]\nlib/matplotlib/axes/_base.py:312: in __call__\n    yield from self._plot_args(this, kwargs)\nlib/matplotlib/axes/_base.py:487: in _plot_args\n    x = _check_1d(xy[0])\nlib/matplotlib/cbook/__init__.py:1289: in _check_1d\n    ndim = x[:, None].ndim\n/opt/miniconda3/envs/testbed/lib/python3.8/site-packages/pandas/core/indexes/range.py:924: in __getitem__\n    return super().__getitem__(key)\n/opt/miniconda3/envs/testbed/lib/python3.8/site-packages/pandas/core/indexes/base.py:5199: in __getitem__\n    disallow_ndim_indexing(result)\n/opt/miniconda3/envs/testbed/lib/python3.8/site-packages/pandas/core/indexers/utils.py:343: in disallow_ndim_indexing\n    raise ValueError(\nE   ValueError: Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer supported. Convert to a numpy array before indexing instead.\n============= 8 failed, 674 passed, 63 skipped in 71.16s (0:01:11) =============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_axes.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_axes.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "matplotlib__matplotlib-25332",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://34.44.241.183:8080",
      "duration": 19.180797338485718,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 181,
          "failed": 2,
          "errors": 0,
          "collected": 183,
          "duration": 9.4,
          "log_tail": "lib/matplotlib/tests/test_pickle.py::test_cmap[cmap139] PASSED           [ 83%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap140] PASSED           [ 83%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap141] PASSED           [ 84%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap142] PASSED           [ 84%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap143] PASSED           [ 85%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap144] PASSED           [ 85%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap145] PASSED           [ 86%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap146] PASSED           [ 86%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap147] PASSED           [ 87%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap148] PASSED           [ 87%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap149] PASSED           [ 88%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap150] PASSED           [ 89%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap151] PASSED           [ 89%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap152] PASSED           [ 90%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap153] PASSED           [ 90%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap154] PASSED           [ 91%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap155] PASSED           [ 91%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap156] PASSED           [ 92%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap157] PASSED           [ 92%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap158] PASSED           [ 93%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap159] PASSED           [ 93%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap160] PASSED           [ 94%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap161] PASSED           [ 95%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap162] PASSED           [ 95%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap163] PASSED           [ 96%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap164] PASSED           [ 96%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap165] PASSED           [ 97%]\nlib/matplotlib/tests/test_pickle.py::test_unpickle_canvas PASSED         [ 97%]\nlib/matplotlib/tests/test_pickle.py::test_mpl_toolkits PASSED            [ 98%]\nlib/matplotlib/tests/test_pickle.py::test_standard_norm PASSED           [ 98%]\nlib/matplotlib/tests/test_pickle.py::test_dynamic_norm PASSED            [ 99%]\nlib/matplotlib/tests/test_pickle.py::test_vertexselector PASSED          [100%]\n\n=================================== FAILURES ===================================\n______________________________ test_complete[png] ______________________________\nlib/matplotlib/testing/decorators.py:472: in wrapper\n    func(*args, fig_test=fig_test, fig_ref=fig_ref, **kwargs)\nlib/matplotlib/tests/test_pickle.py:103: in test_complete\n    pickle.dump(fig_ref, pkl, pickle.HIGHEST_PROTOCOL)\nE   TypeError: cannot pickle 'weakref.ReferenceType' object\n____________________ test_pickle_load_from_subprocess[png] _____________________\nlib/matplotlib/testing/decorators.py:472: in wrapper\n    func(*args, fig_test=fig_test, fig_ref=fig_ref, **kwargs)\nlib/matplotlib/tests/test_pickle.py:134: in test_pickle_load_from_subprocess\n    pickle.dump(fig_ref, file, pickle.HIGHEST_PROTOCOL)\nE   TypeError: cannot pickle 'weakref.ReferenceType' object\n======================== 2 failed, 181 passed in 4.46s =========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_pickle.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_pickle.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 182,
          "failed": 1,
          "errors": 0,
          "collected": 183,
          "duration": 8.45,
          "log_tail": "lib/matplotlib/tests/test_pickle.py::test_cmap[cmap137] PASSED           [ 81%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap138] PASSED           [ 82%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap139] PASSED           [ 83%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap140] PASSED           [ 83%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap141] PASSED           [ 84%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap142] PASSED           [ 84%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap143] PASSED           [ 85%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap144] PASSED           [ 85%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap145] PASSED           [ 86%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap146] PASSED           [ 86%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap147] PASSED           [ 87%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap148] PASSED           [ 87%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap149] PASSED           [ 88%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap150] PASSED           [ 89%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap151] PASSED           [ 89%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap152] PASSED           [ 90%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap153] PASSED           [ 90%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap154] PASSED           [ 91%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap155] PASSED           [ 91%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap156] PASSED           [ 92%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap157] PASSED           [ 92%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap158] PASSED           [ 93%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap159] PASSED           [ 93%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap160] PASSED           [ 94%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap161] PASSED           [ 95%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap162] PASSED           [ 95%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap163] PASSED           [ 96%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap164] PASSED           [ 96%]\nlib/matplotlib/tests/test_pickle.py::test_cmap[cmap165] PASSED           [ 97%]\nlib/matplotlib/tests/test_pickle.py::test_unpickle_canvas PASSED         [ 97%]\nlib/matplotlib/tests/test_pickle.py::test_mpl_toolkits PASSED            [ 98%]\nlib/matplotlib/tests/test_pickle.py::test_standard_norm PASSED           [ 98%]\nlib/matplotlib/tests/test_pickle.py::test_dynamic_norm PASSED            [ 99%]\nlib/matplotlib/tests/test_pickle.py::test_vertexselector PASSED          [100%]\n\n=================================== FAILURES ===================================\n____________________ test_pickle_load_from_subprocess[png] _____________________\nlib/matplotlib/testing/decorators.py:472: in wrapper\n    func(*args, fig_test=fig_test, fig_ref=fig_ref, **kwargs)\nlib/matplotlib/tests/test_pickle.py:143: in test_pickle_load_from_subprocess\n    loaded_fig = pickle.loads(ast.literal_eval(proc.stdout))\nlib/matplotlib/figure.py:3184: in __setstate__\n    _api.warn_external(\nlib/matplotlib/_api/__init__.py:388: in warn_external\n    warnings.warn(message, category, stacklevel)\nE   UserWarning: This figure was saved with matplotlib version 3.8.0.dev452+g66ba515e67.d19700101 and is unlikely to function correctly.\n======================== 1 failed, 182 passed in 5.90s =========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_pickle.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_pickle.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "matplotlib__matplotlib-25479",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://34.59.30.169:8080",
      "duration": 20.55673599243164,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 263,
          "failed": 3,
          "errors": 0,
          "collected": 267,
          "duration": 10.91,
          "log_tail": "lib/matplotlib/tests/test_colors.py::test_to_rgba_accepts_color_alpha_tuple[rgba_alpha3] PASSED [ 89%]\nlib/matplotlib/tests/test_colors.py::test_to_rgba_explicit_alpha_overrides_tuple_alpha PASSED [ 89%]\nlib/matplotlib/tests/test_colors.py::test_to_rgba_error_with_color_invalid_alpha_tuple PASSED [ 90%]\nlib/matplotlib/tests/test_colors.py::test_failed_conversions PASSED      [ 90%]\nlib/matplotlib/tests/test_colors.py::test_grey_gray PASSED               [ 91%]\nlib/matplotlib/tests/test_colors.py::test_tableau_order PASSED           [ 91%]\nlib/matplotlib/tests/test_colors.py::test_ndarray_subclass_norm PASSED   [ 91%]\nlib/matplotlib/tests/test_colors.py::test_same_color PASSED              [ 92%]\nlib/matplotlib/tests/test_colors.py::test_hex_shorthand_notation PASSED  [ 92%]\nlib/matplotlib/tests/test_colors.py::test_repr_png PASSED                [ 92%]\nlib/matplotlib/tests/test_colors.py::test_repr_html PASSED               [ 93%]\nlib/matplotlib/tests/test_colors.py::test_get_under_over_bad PASSED      [ 93%]\nlib/matplotlib/tests/test_colors.py::test_non_mutable_get_values[over] PASSED [ 94%]\nlib/matplotlib/tests/test_colors.py::test_non_mutable_get_values[under] PASSED [ 94%]\nlib/matplotlib/tests/test_colors.py::test_non_mutable_get_values[bad] PASSED [ 94%]\nlib/matplotlib/tests/test_colors.py::test_colormap_alpha_array PASSED    [ 95%]\nlib/matplotlib/tests/test_colors.py::test_colormap_bad_data_with_alpha PASSED [ 95%]\nlib/matplotlib/tests/test_colors.py::test_2d_to_rgba PASSED              [ 95%]\nlib/matplotlib/tests/test_colors.py::test_set_dict_to_rgba PASSED        [ 96%]\nlib/matplotlib/tests/test_colors.py::test_norm_deepcopy PASSED           [ 96%]\nlib/matplotlib/tests/test_colors.py::test_norm_callback PASSED           [ 97%]\nlib/matplotlib/tests/test_colors.py::test_scalarmappable_norm_update PASSED [ 97%]\nlib/matplotlib/tests/test_colors.py::test_norm_update_figs[png] PASSED   [ 97%]\nlib/matplotlib/tests/test_colors.py::test_norm_update_figs[pdf] PASSED   [ 98%]\nlib/matplotlib/tests/test_colors.py::test_norm_update_figs[svg] SKIPPED  [ 98%]\nlib/matplotlib/tests/test_colors.py::test_make_norm_from_scale_name PASSED [ 98%]\nlib/matplotlib/tests/test_colors.py::test_color_sequences PASSED         [ 99%]\nlib/matplotlib/tests/test_colors.py::test_cm_set_cmap_error PASSED       [ 99%]\nlib/matplotlib/tests/test_colors.py::test_set_cmap_mismatched_name FAILED [100%]\n\n=================================== FAILURES ===================================\n______________________ test_double_register_builtin_cmap _______________________\nlib/matplotlib/tests/test_colors.py:150: in test_double_register_builtin_cmap\n    with pytest.warns(UserWarning):\nE   matplotlib._api.deprecation.MatplotlibDeprecationWarning: The register_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps.register(name)`` instead.\n_____________________________ test_colormap_equals _____________________________\nlib/matplotlib/tests/test_colors.py:201: in test_colormap_equals\n    assert cm_copy == cmap\nE   assert <matplotlib.colors.ListedColormap object at 0x7320f73f3b50> == <matplotlib.colors.ListedColormap object at 0x7320e2352710>\n________________________ test_set_cmap_mismatched_name _________________________\nlib/matplotlib/tests/test_colors.py:1663: in test_set_cmap_mismatched_name\n    assert cmap_returned.name == \"wrong-cmap\"\nE   AssertionError: assert 'test-cmap' == 'wrong-cmap'\nE     \nE     - wrong-cmap\nE     + test-cmap\n=================== 3 failed, 263 passed, 1 skipped in 6.29s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_colors.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_colors.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 265,
          "failed": 1,
          "errors": 0,
          "collected": 267,
          "duration": 8.81,
          "log_tail": "lib/matplotlib/tests/test_colors.py::test_conversions PASSED             [ 85%]\nlib/matplotlib/tests/test_colors.py::test_conversions_masked PASSED      [ 85%]\nlib/matplotlib/tests/test_colors.py::test_to_rgba_array_single_str PASSED [ 86%]\nlib/matplotlib/tests/test_colors.py::test_to_rgba_array_alpha_array PASSED [ 86%]\nlib/matplotlib/tests/test_colors.py::test_to_rgba_array_accepts_color_alpha_tuple PASSED [ 86%]\nlib/matplotlib/tests/test_colors.py::test_to_rgba_array_explicit_alpha_overrides_tuple_alpha PASSED [ 87%]\nlib/matplotlib/tests/test_colors.py::test_to_rgba_array_accepts_color_alpha_tuple_with_multiple_colors PASSED [ 87%]\nlib/matplotlib/tests/test_colors.py::test_to_rgba_array_error_with_color_invalid_alpha_tuple PASSED [ 88%]\nlib/matplotlib/tests/test_colors.py::test_to_rgba_accepts_color_alpha_tuple[rgba_alpha0] PASSED [ 88%]\nlib/matplotlib/tests/test_colors.py::test_to_rgba_accepts_color_alpha_tuple[rgba_alpha1] PASSED [ 88%]\nlib/matplotlib/tests/test_colors.py::test_to_rgba_accepts_color_alpha_tuple[rgba_alpha2] PASSED [ 89%]\nlib/matplotlib/tests/test_colors.py::test_to_rgba_accepts_color_alpha_tuple[rgba_alpha3] PASSED [ 89%]\nlib/matplotlib/tests/test_colors.py::test_to_rgba_explicit_alpha_overrides_tuple_alpha PASSED [ 89%]\nlib/matplotlib/tests/test_colors.py::test_to_rgba_error_with_color_invalid_alpha_tuple PASSED [ 90%]\nlib/matplotlib/tests/test_colors.py::test_failed_conversions PASSED      [ 90%]\nlib/matplotlib/tests/test_colors.py::test_grey_gray PASSED               [ 91%]\nlib/matplotlib/tests/test_colors.py::test_tableau_order PASSED           [ 91%]\nlib/matplotlib/tests/test_colors.py::test_ndarray_subclass_norm PASSED   [ 91%]\nlib/matplotlib/tests/test_colors.py::test_same_color PASSED              [ 92%]\nlib/matplotlib/tests/test_colors.py::test_hex_shorthand_notation PASSED  [ 92%]\nlib/matplotlib/tests/test_colors.py::test_repr_png PASSED                [ 92%]\nlib/matplotlib/tests/test_colors.py::test_repr_html PASSED               [ 93%]\nlib/matplotlib/tests/test_colors.py::test_get_under_over_bad PASSED      [ 93%]\nlib/matplotlib/tests/test_colors.py::test_non_mutable_get_values[over] PASSED [ 94%]\nlib/matplotlib/tests/test_colors.py::test_non_mutable_get_values[under] PASSED [ 94%]\nlib/matplotlib/tests/test_colors.py::test_non_mutable_get_values[bad] PASSED [ 94%]\nlib/matplotlib/tests/test_colors.py::test_colormap_alpha_array PASSED    [ 95%]\nlib/matplotlib/tests/test_colors.py::test_colormap_bad_data_with_alpha PASSED [ 95%]\nlib/matplotlib/tests/test_colors.py::test_2d_to_rgba PASSED              [ 95%]\nlib/matplotlib/tests/test_colors.py::test_set_dict_to_rgba PASSED        [ 96%]\nlib/matplotlib/tests/test_colors.py::test_norm_deepcopy PASSED           [ 96%]\nlib/matplotlib/tests/test_colors.py::test_norm_callback PASSED           [ 97%]\nlib/matplotlib/tests/test_colors.py::test_scalarmappable_norm_update PASSED [ 97%]\nlib/matplotlib/tests/test_colors.py::test_norm_update_figs[png] PASSED   [ 97%]\nlib/matplotlib/tests/test_colors.py::test_norm_update_figs[pdf] PASSED   [ 98%]\nlib/matplotlib/tests/test_colors.py::test_norm_update_figs[svg] SKIPPED  [ 98%]\nlib/matplotlib/tests/test_colors.py::test_make_norm_from_scale_name PASSED [ 98%]\nlib/matplotlib/tests/test_colors.py::test_color_sequences PASSED         [ 99%]\nlib/matplotlib/tests/test_colors.py::test_cm_set_cmap_error PASSED       [ 99%]\nlib/matplotlib/tests/test_colors.py::test_set_cmap_mismatched_name PASSED [100%]\n\n=================================== FAILURES ===================================\n______________________ test_double_register_builtin_cmap _______________________\nlib/matplotlib/tests/test_colors.py:150: in test_double_register_builtin_cmap\n    with pytest.warns(UserWarning):\nE   matplotlib._api.deprecation.MatplotlibDeprecationWarning: The register_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps.register(name)`` instead.\n=================== 1 failed, 265 passed, 1 skipped in 6.21s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_colors.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_colors.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "matplotlib__matplotlib-23314",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://34.123.9.23:8080",
      "error": "HTTPConnectionPool(host='34.123.9.23', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 1
    },
    {
      "instance_id": "matplotlib__matplotlib-24026",
      "repo": "matplotlib/matplotlib",
      "valid": true,
      "worker": "http://34.70.1.155:8080",
      "duration": 148.9722101688385,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 765,
          "failed": 2,
          "errors": 0,
          "collected": 831,
          "duration": 74.52,
          "log_tail": "lib/matplotlib/tests/test_axes.py::test_plot_format_errors[data1-:o-r-':o-r' is not a valid format string \\\\(two linestyle symbols\\\\)] PASSED [ 99%]\nlib/matplotlib/tests/test_axes.py::test_plot_format PASSED               [ 99%]\nlib/matplotlib/tests/test_axes.py::test_automatic_legend PASSED          [ 99%]\nlib/matplotlib/tests/test_axes.py::test_plot_errors PASSED               [ 99%]\nlib/matplotlib/tests/test_axes.py::test_clim PASSED                      [ 99%]\nlib/matplotlib/tests/test_axes.py::test_bezier_autoscale PASSED          [ 99%]\nlib/matplotlib/tests/test_axes.py::test_get_xticklabel PASSED            [ 99%]\nlib/matplotlib/tests/test_axes.py::test_bar_leading_nan PASSED           [100%]\n\n=================================== FAILURES ===================================\n_____________________________ test_stackplot[png] ______________________________\nlib/matplotlib/tests/test_axes.py:2866: in test_stackplot\n    ax.stackplot(\"x\", \"y1\", \"y2\", \"y3\", data=data, colors=[\"C0\", \"C1\", \"C2\"])\nlib/matplotlib/__init__.py:1449: in inner\n    return func(*new_args, **new_kwargs)\nlib/matplotlib/stackplot.py:73: in stackplot\n    axes.set_prop_cycle(color=colors)\nlib/matplotlib/axes/_base.py:1620: in set_prop_cycle\n    prop_cycle = cycler(*args, **kwargs)\nlib/matplotlib/rcsetup.py:709: in cycler\n    vals = validator(vals)\nlib/matplotlib/rcsetup.py:107: in f\n    val = [scalar_validator(v) for v in s\nlib/matplotlib/rcsetup.py:107: in <listcomp>\n    val = [scalar_validator(v) for v in s\nlib/matplotlib/rcsetup.py:285: in validate_color_for_prop_cycle\n    raise ValueError(f\"Cannot put cycle reference ({s!r}) in prop_cycler\")\nE   ValueError: Cannot put cycle reference ('C0') in prop_cycler\n_____________________________ test_stackplot[pdf] ______________________________\nlib/matplotlib/tests/test_axes.py:2866: in test_stackplot\n    ax.stackplot(\"x\", \"y1\", \"y2\", \"y3\", data=data, colors=[\"C0\", \"C1\", \"C2\"])\nlib/matplotlib/__init__.py:1449: in inner\n    return func(*new_args, **new_kwargs)\nlib/matplotlib/stackplot.py:73: in stackplot\n    axes.set_prop_cycle(color=colors)\nlib/matplotlib/axes/_base.py:1620: in set_prop_cycle\n    prop_cycle = cycler(*args, **kwargs)\nlib/matplotlib/rcsetup.py:709: in cycler\n    vals = validator(vals)\nlib/matplotlib/rcsetup.py:107: in f\n    val = [scalar_validator(v) for v in s\nlib/matplotlib/rcsetup.py:107: in <listcomp>\n    val = [scalar_validator(v) for v in s\nlib/matplotlib/rcsetup.py:285: in validate_color_for_prop_cycle\n    raise ValueError(f\"Cannot put cycle reference ({s!r}) in prop_cycler\")\nE   ValueError: Cannot put cycle reference ('C0') in prop_cycler\n============= 2 failed, 765 passed, 64 skipped in 69.93s (0:01:09) =============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_axes.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_axes.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 767,
          "failed": 0,
          "errors": 0,
          "collected": 831,
          "duration": 73.49,
          "log_tail": "lib/matplotlib/tests/test_axes.py::test_multiplot_autoscale PASSED       [ 94%]\nlib/matplotlib/tests/test_axes.py::test_sharing_does_not_link_positions PASSED [ 94%]\nlib/matplotlib/tests/test_axes.py::test_2dcolor_plot[pdf] PASSED         [ 94%]\nlib/matplotlib/tests/test_axes.py::test_shared_axes_clear[png] PASSED    [ 94%]\nlib/matplotlib/tests/test_axes.py::test_shared_axes_retick PASSED        [ 95%]\nlib/matplotlib/tests/test_axes.py::test_ylabel_ha_with_position[left] PASSED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_ylabel_ha_with_position[center] PASSED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_ylabel_ha_with_position[right] PASSED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_vertical PASSED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_vertical_yinverted PASSED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_horizontal PASSED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_horizontal_yinverted PASSED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_horizontal_xinverted PASSED [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_horizontal_xyinverted PASSED [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_center PASSED [ 96%]\nlib/matplotlib/tests/test_axes.py::test_centered_bar_label_nonlinear[svg] SKIPPED [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_errorbars PASSED [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_fmt[%.2f] PASSED       [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_fmt[{:.2f}] PASSED     [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_fmt[format] PASSED     [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_fmt_error PASSED       [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_labels PASSED          [ 97%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_nan_ydata PASSED       [ 97%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_nan_ydata_inverted PASSED [ 97%]\nlib/matplotlib/tests/test_axes.py::test_nan_barlabels PASSED             [ 97%]\nlib/matplotlib/tests/test_axes.py::test_patch_bounds PASSED              [ 97%]\nlib/matplotlib/tests/test_axes.py::test_warn_ignored_scatter_kwargs PASSED [ 97%]\nlib/matplotlib/tests/test_axes.py::test_artist_sublists PASSED           [ 97%]\nlib/matplotlib/tests/test_axes.py::test_empty_line_plots PASSED          [ 97%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[None-f-'f' is not a valid format string \\\\(unrecognized character 'f'\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[None-o+-'o\\\\+' is not a valid format string \\\\(two marker symbols\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[None-:--':-' is not a valid format string \\\\(two linestyle symbols\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[None-rk-'rk' is not a valid format string \\\\(two color symbols\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[None-:o-r-':o-r' is not a valid format string \\\\(two linestyle symbols\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[data1-f-'f' is not a valid format string \\\\(unrecognized character 'f'\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[data1-o+-'o\\\\+' is not a valid format string \\\\(two marker symbols\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[data1-:--':-' is not a valid format string \\\\(two linestyle symbols\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[data1-rk-'rk' is not a valid format string \\\\(two color symbols\\\\)] PASSED [ 99%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[data1-:o-r-':o-r' is not a valid format string \\\\(two linestyle symbols\\\\)] PASSED [ 99%]\nlib/matplotlib/tests/test_axes.py::test_plot_format PASSED               [ 99%]\nlib/matplotlib/tests/test_axes.py::test_automatic_legend PASSED          [ 99%]\nlib/matplotlib/tests/test_axes.py::test_plot_errors PASSED               [ 99%]\nlib/matplotlib/tests/test_axes.py::test_clim PASSED                      [ 99%]\nlib/matplotlib/tests/test_axes.py::test_bezier_autoscale PASSED          [ 99%]\nlib/matplotlib/tests/test_axes.py::test_get_xticklabel PASSED            [ 99%]\nlib/matplotlib/tests/test_axes.py::test_bar_leading_nan PASSED           [100%]\n\n================== 767 passed, 64 skipped in 70.74s (0:01:10) ==================\n\n",
          "test_files_run": [
            "lib/matplotlib/tests/test_axes.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "matplotlib__matplotlib-24149",
      "repo": "matplotlib/matplotlib",
      "valid": true,
      "worker": "http://34.123.9.23:8080",
      "duration": 149.0445351600647,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 767,
          "failed": 1,
          "errors": 0,
          "collected": 832,
          "duration": 75.15,
          "log_tail": "lib/matplotlib/tests/test_axes.py::test_clim PASSED                      [ 99%]\nlib/matplotlib/tests/test_axes.py::test_bezier_autoscale PASSED          [ 99%]\nlib/matplotlib/tests/test_axes.py::test_get_xticklabel PASSED            [ 99%]\nlib/matplotlib/tests/test_axes.py::test_bar_leading_nan PASSED           [ 99%]\nlib/matplotlib/tests/test_axes.py::test_bar_all_nan[png] FAILED          [100%]\n\n=================================== FAILURES ===================================\n____________________________ test_bar_all_nan[png] _____________________________\nlib/matplotlib/testing/decorators.py:472: in wrapper\n    func(*args, fig_test=fig_test, fig_ref=fig_ref, **kwargs)\nlib/matplotlib/tests/test_axes.py:8206: in test_bar_all_nan\n    ax_test.bar([np.nan], [np.nan])\nlib/matplotlib/__init__.py:1423: in inner\n    return func(ax, *map(sanitize_sequence, args), **kwargs)\nlib/matplotlib/axes/_axes.py:2373: in bar\n    width = self._convert_dx(width, x0, x, self.convert_xunits)\nlib/matplotlib/axes/_axes.py:2182: in _convert_dx\n    x0 = cbook._safe_first_finite(x0)\nlib/matplotlib/cbook/__init__.py:1749: in _safe_first_finite\n    return next(val for val in obj if safe_isfinite(val))\nE   StopIteration\n\nThe above exception was the direct cause of the following exception:\n/opt/miniconda3/envs/testbed/lib/python3.11/site-packages/_pytest/runner.py:341: in from_call\n    result: TResult | None = func()\n/opt/miniconda3/envs/testbed/lib/python3.11/site-packages/_pytest/runner.py:242: in <lambda>\n    lambda: runtest_hook(item=item, **kwds), when=when, reraise=reraise\n/opt/miniconda3/envs/testbed/lib/python3.11/site-packages/pluggy/_hooks.py:513: in __call__\n    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n/opt/miniconda3/envs/testbed/lib/python3.11/site-packages/pluggy/_manager.py:120: in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n/opt/miniconda3/envs/testbed/lib/python3.11/site-packages/_pytest/threadexception.py:92: in pytest_runtest_call\n    yield from thread_exception_runtest_hook()\n/opt/miniconda3/envs/testbed/lib/python3.11/site-packages/_pytest/threadexception.py:68: in thread_exception_runtest_hook\n    yield\n/opt/miniconda3/envs/testbed/lib/python3.11/site-packages/_pytest/unraisableexception.py:95: in pytest_runtest_call\n    yield from unraisable_exception_runtest_hook()\n/opt/miniconda3/envs/testbed/lib/python3.11/site-packages/_pytest/unraisableexception.py:70: in unraisable_exception_runtest_hook\n    yield\n/opt/miniconda3/envs/testbed/lib/python3.11/site-packages/_pytest/logging.py:846: in pytest_runtest_call\n    yield from self._runtest_for(item, \"call\")\n/opt/miniconda3/envs/testbed/lib/python3.11/site-packages/_pytest/logging.py:829: in _runtest_for\n    yield\n/opt/miniconda3/envs/testbed/lib/python3.11/site-packages/_pytest/capture.py:880: in pytest_runtest_call\n    return (yield)\nE   RuntimeError: generator raised StopIteration\n============= 1 failed, 767 passed, 64 skipped in 70.30s (0:01:10) =============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_axes.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_axes.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 768,
          "failed": 0,
          "errors": 0,
          "collected": 832,
          "duration": 72.86,
          "log_tail": "lib/matplotlib/tests/test_axes.py::test_sharing_does_not_link_positions PASSED [ 94%]\nlib/matplotlib/tests/test_axes.py::test_2dcolor_plot[pdf] PASSED         [ 94%]\nlib/matplotlib/tests/test_axes.py::test_shared_axes_clear[png] PASSED    [ 94%]\nlib/matplotlib/tests/test_axes.py::test_shared_axes_retick PASSED        [ 94%]\nlib/matplotlib/tests/test_axes.py::test_ylabel_ha_with_position[left] PASSED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_ylabel_ha_with_position[center] PASSED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_ylabel_ha_with_position[right] PASSED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_vertical PASSED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_vertical_yinverted PASSED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_horizontal PASSED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_horizontal_yinverted PASSED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_horizontal_xinverted PASSED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_horizontal_xyinverted PASSED [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_center PASSED [ 96%]\nlib/matplotlib/tests/test_axes.py::test_centered_bar_label_nonlinear[svg] SKIPPED [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_errorbars PASSED [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_fmt[%.2f] PASSED       [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_fmt[{:.2f}] PASSED     [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_fmt[format] PASSED     [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_fmt_error PASSED       [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_labels PASSED          [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_nan_ydata PASSED       [ 97%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_nan_ydata_inverted PASSED [ 97%]\nlib/matplotlib/tests/test_axes.py::test_nan_barlabels PASSED             [ 97%]\nlib/matplotlib/tests/test_axes.py::test_patch_bounds PASSED              [ 97%]\nlib/matplotlib/tests/test_axes.py::test_warn_ignored_scatter_kwargs PASSED [ 97%]\nlib/matplotlib/tests/test_axes.py::test_artist_sublists PASSED           [ 97%]\nlib/matplotlib/tests/test_axes.py::test_empty_line_plots PASSED          [ 97%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[None-f-'f' is not a valid format string \\\\(unrecognized character 'f'\\\\)] PASSED [ 97%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[None-o+-'o\\\\+' is not a valid format string \\\\(two marker symbols\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[None-:--':-' is not a valid format string \\\\(two linestyle symbols\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[None-rk-'rk' is not a valid format string \\\\(two color symbols\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[None-:o-r-':o-r' is not a valid format string \\\\(two linestyle symbols\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[data1-f-'f' is not a valid format string \\\\(unrecognized character 'f'\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[data1-o+-'o\\\\+' is not a valid format string \\\\(two marker symbols\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[data1-:--':-' is not a valid format string \\\\(two linestyle symbols\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[data1-rk-'rk' is not a valid format string \\\\(two color symbols\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[data1-:o-r-':o-r' is not a valid format string \\\\(two linestyle symbols\\\\)] PASSED [ 99%]\nlib/matplotlib/tests/test_axes.py::test_plot_format PASSED               [ 99%]\nlib/matplotlib/tests/test_axes.py::test_automatic_legend PASSED          [ 99%]\nlib/matplotlib/tests/test_axes.py::test_plot_errors PASSED               [ 99%]\nlib/matplotlib/tests/test_axes.py::test_clim PASSED                      [ 99%]\nlib/matplotlib/tests/test_axes.py::test_bezier_autoscale PASSED          [ 99%]\nlib/matplotlib/tests/test_axes.py::test_get_xticklabel PASSED            [ 99%]\nlib/matplotlib/tests/test_axes.py::test_bar_leading_nan PASSED           [ 99%]\nlib/matplotlib/tests/test_axes.py::test_bar_all_nan[png] PASSED          [100%]\n\n================== 768 passed, 64 skipped in 70.08s (0:01:10) ==================\n\n",
          "test_files_run": [
            "lib/matplotlib/tests/test_axes.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sphinx-doc__sphinx-7440",
      "repo": "sphinx-doc/sphinx",
      "valid": false,
      "worker": "http://34.41.233.120:8080",
      "duration": 9.476776123046875,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 12,
          "failed": 2,
          "errors": 0,
          "collected": 14,
          "duration": 5.26,
          "log_tail": "tests/test_domain_std.py::test_productionlist\ntests/test_domain_std.py::test_productionlist\n  /testbed/sphinx/environment/adapters/toctree.py:313: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in toc.traverse(nodes.reference):\n\ntests/test_domain_std.py: 10 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:114: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n    _gaq.push(['_setAllowLinker', true]);\n\ntests/test_domain_std.py: 10 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:70: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_std.py: 10 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:99: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_std.py: 10 warnings\n  /testbed/sphinx/environment/adapters/toctree.py:327: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for toctreenode in doctree.traverse(addnodes.toctree):\n\ntests/test_domain_std.py: 77 warnings\n  /testbed/sphinx/environment/adapters/toctree.py:204: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for subtocnode in toc.traverse(addnodes.toctree):\n\ntests/test_domain_std.py: 11 warnings\n  /testbed/sphinx/environment/adapters/toctree.py:262: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for refnode in newnode.traverse(nodes.reference):\n\ntests/test_domain_std.py: 10 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:215: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_std.py: 10 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:238: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_std.py::test_productionlist\n  <template>:33: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_std.py::test_productionlist\n  <template>:224: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_std.py::test_productionlist\n  <template>:386: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_std.py::test_productionlist\n  <template>:401: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================= 2 failed, 12 passed, 1008 warnings in 0.92s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_domain_std.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_domain_std.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 13,
          "failed": 1,
          "errors": 0,
          "collected": 14,
          "duration": 3.4,
          "log_tail": "tests/test_domain_std.py::test_productionlist\ntests/test_domain_std.py::test_productionlist\n  /testbed/sphinx/environment/adapters/toctree.py:313: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in toc.traverse(nodes.reference):\n\ntests/test_domain_std.py: 10 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:114: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n    _gaq.push(['_setAllowLinker', true]);\n\ntests/test_domain_std.py: 10 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:70: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_std.py: 10 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:99: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_std.py: 10 warnings\n  /testbed/sphinx/environment/adapters/toctree.py:327: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for toctreenode in doctree.traverse(addnodes.toctree):\n\ntests/test_domain_std.py: 77 warnings\n  /testbed/sphinx/environment/adapters/toctree.py:204: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for subtocnode in toc.traverse(addnodes.toctree):\n\ntests/test_domain_std.py: 11 warnings\n  /testbed/sphinx/environment/adapters/toctree.py:262: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for refnode in newnode.traverse(nodes.reference):\n\ntests/test_domain_std.py: 10 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:215: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_std.py: 10 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:238: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_std.py::test_productionlist\n  <template>:33: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_std.py::test_productionlist\n  <template>:224: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_std.py::test_productionlist\n  <template>:386: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_domain_std.py::test_productionlist\n  <template>:401: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================= 1 failed, 13 passed, 1008 warnings in 0.92s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_domain_std.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_domain_std.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "matplotlib__matplotlib-25960",
      "repo": "matplotlib/matplotlib",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 45.693809032440186,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 137,
          "failed": 1,
          "errors": 0,
          "collected": 145,
          "duration": 23.49,
          "log_tail": "lib/matplotlib/tests/test_figure.py::test_subfigure_dpi PASSED           [ 79%]\nlib/matplotlib/tests/test_figure.py::test_subfigure_ss[png] PASSED       [ 80%]\nlib/matplotlib/tests/test_figure.py::test_subfigure_double[png] PASSED   [ 80%]\nlib/matplotlib/tests/test_figure.py::test_subfigure_spanning PASSED      [ 81%]\nlib/matplotlib/tests/test_figure.py::test_subfigure_ticks PASSED         [ 82%]\nlib/matplotlib/tests/test_figure.py::test_subfigure_scatter_size[png] PASSED [ 82%]\nlib/matplotlib/tests/test_figure.py::test_subfigure_pdf PASSED           [ 83%]\nlib/matplotlib/tests/test_figure.py::test_subfigures_wspace_hspace FAILED [ 84%]\nlib/matplotlib/tests/test_figure.py::test_add_subplot_kwargs PASSED      [ 84%]\nlib/matplotlib/tests/test_figure.py::test_add_axes_kwargs PASSED         [ 85%]\nlib/matplotlib/tests/test_figure.py::test_ginput PASSED                  [ 86%]\nlib/matplotlib/tests/test_figure.py::test_waitforbuttonpress PASSED      [ 86%]\nlib/matplotlib/tests/test_figure.py::test_kwargs_pass PASSED             [ 87%]\nlib/matplotlib/tests/test_figure.py::test_rcparams[png] PASSED           [ 88%]\nlib/matplotlib/tests/test_figure.py::test_deepcopy PASSED                [ 88%]\nlib/matplotlib/tests/test_figure.py::test_unpickle_with_device_pixel_ratio PASSED [ 89%]\nlib/matplotlib/tests/test_figure.py::test_gridspec_no_mutate_input PASSED [ 90%]\nlib/matplotlib/tests/test_figure.py::test_savefig_metadata[eps] PASSED   [ 91%]\nlib/matplotlib/tests/test_figure.py::test_savefig_metadata[pdf] PASSED   [ 91%]\nlib/matplotlib/tests/test_figure.py::test_savefig_metadata[png] PASSED   [ 92%]\nlib/matplotlib/tests/test_figure.py::test_savefig_metadata[ps] PASSED    [ 93%]\nlib/matplotlib/tests/test_figure.py::test_savefig_metadata[svg] PASSED   [ 93%]\nlib/matplotlib/tests/test_figure.py::test_savefig_metadata[svgz] PASSED  [ 94%]\nlib/matplotlib/tests/test_figure.py::test_savefig_metadata_error[jpeg] PASSED [ 95%]\nlib/matplotlib/tests/test_figure.py::test_savefig_metadata_error[jpg] PASSED [ 95%]\nlib/matplotlib/tests/test_figure.py::test_savefig_metadata_error[tif] PASSED [ 96%]\nlib/matplotlib/tests/test_figure.py::test_savefig_metadata_error[tiff] PASSED [ 97%]\nlib/matplotlib/tests/test_figure.py::test_savefig_metadata_error[webp] PASSED [ 97%]\nlib/matplotlib/tests/test_figure.py::test_savefig_metadata_error[raw] PASSED [ 98%]\nlib/matplotlib/tests/test_figure.py::test_savefig_metadata_error[rgba] PASSED [ 99%]\nlib/matplotlib/tests/test_figure.py::test_get_constrained_layout_pads PASSED [100%]\n\n=================================== FAILURES ===================================\n________________________ test_subfigures_wspace_hspace _________________________\nlib/matplotlib/tests/test_figure.py:1458: in test_subfigures_wspace_hspace\n    np.testing.assert_allclose(sub_figs[0, 0].bbox.min, [0., h * 0.6])\n/opt/miniconda3/envs/testbed/lib/python3.11/contextlib.py:81: in inner\n    return func(*args, **kwds)\nE   AssertionError: \nE   Not equal to tolerance rtol=1e-07, atol=0\nE   \nE   Mismatched elements: 1 / 2 (50%)\nE   Max absolute difference: 48.\nE   Max relative difference: 0.16666667\nE    x: array([  0., 240.])\nE    y: array([  0., 288.])\n================== 1 failed, 137 passed, 7 skipped in 18.61s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_figure.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_figure.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 138,
          "failed": 0,
          "errors": 0,
          "collected": 145,
          "duration": 21.34,
          "log_tail": "lib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_fail[x1-There are duplicate keys .* between the outer layout] PASSED [ 68%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_fail[AAA\\nc\\nBBB-All of the rows must be the same length] PASSED [ 69%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_fail[x3-All of the rows must be the same length] PASSED [ 70%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_hashable_keys[png] PASSED [ 71%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_user_order[abc] PASSED [ 71%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_user_order[cab] PASSED [ 72%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_user_order[bca] PASSED [ 73%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_user_order[cba] PASSED [ 73%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_user_order[acb] PASSED [ 74%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_user_order[bac] PASSED [ 75%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_nested_user_order PASSED [ 75%]\nlib/matplotlib/tests/test_figure.py::TestSubplotMosaic::test_share_all PASSED [ 76%]\nlib/matplotlib/tests/test_figure.py::test_reused_gridspec PASSED         [ 77%]\nlib/matplotlib/tests/test_figure.py::test_subfigure[png] PASSED          [ 77%]\nlib/matplotlib/tests/test_figure.py::test_subfigure_tightbbox PASSED     [ 78%]\nlib/matplotlib/tests/test_figure.py::test_subfigure_dpi PASSED           [ 79%]\nlib/matplotlib/tests/test_figure.py::test_subfigure_ss[png] PASSED       [ 80%]\nlib/matplotlib/tests/test_figure.py::test_subfigure_double[png] PASSED   [ 80%]\nlib/matplotlib/tests/test_figure.py::test_subfigure_spanning PASSED      [ 81%]\nlib/matplotlib/tests/test_figure.py::test_subfigure_ticks PASSED         [ 82%]\nlib/matplotlib/tests/test_figure.py::test_subfigure_scatter_size[png] PASSED [ 82%]\nlib/matplotlib/tests/test_figure.py::test_subfigure_pdf PASSED           [ 83%]\nlib/matplotlib/tests/test_figure.py::test_subfigures_wspace_hspace PASSED [ 84%]\nlib/matplotlib/tests/test_figure.py::test_add_subplot_kwargs PASSED      [ 84%]\nlib/matplotlib/tests/test_figure.py::test_add_axes_kwargs PASSED         [ 85%]\nlib/matplotlib/tests/test_figure.py::test_ginput PASSED                  [ 86%]\nlib/matplotlib/tests/test_figure.py::test_waitforbuttonpress PASSED      [ 86%]\nlib/matplotlib/tests/test_figure.py::test_kwargs_pass PASSED             [ 87%]\nlib/matplotlib/tests/test_figure.py::test_rcparams[png] PASSED           [ 88%]\nlib/matplotlib/tests/test_figure.py::test_deepcopy PASSED                [ 88%]\nlib/matplotlib/tests/test_figure.py::test_unpickle_with_device_pixel_ratio PASSED [ 89%]\nlib/matplotlib/tests/test_figure.py::test_gridspec_no_mutate_input PASSED [ 90%]\nlib/matplotlib/tests/test_figure.py::test_savefig_metadata[eps] PASSED   [ 91%]\nlib/matplotlib/tests/test_figure.py::test_savefig_metadata[pdf] PASSED   [ 91%]\nlib/matplotlib/tests/test_figure.py::test_savefig_metadata[png] PASSED   [ 92%]\nlib/matplotlib/tests/test_figure.py::test_savefig_metadata[ps] PASSED    [ 93%]\nlib/matplotlib/tests/test_figure.py::test_savefig_metadata[svg] PASSED   [ 93%]\nlib/matplotlib/tests/test_figure.py::test_savefig_metadata[svgz] PASSED  [ 94%]\nlib/matplotlib/tests/test_figure.py::test_savefig_metadata_error[jpeg] PASSED [ 95%]\nlib/matplotlib/tests/test_figure.py::test_savefig_metadata_error[jpg] PASSED [ 95%]\nlib/matplotlib/tests/test_figure.py::test_savefig_metadata_error[tif] PASSED [ 96%]\nlib/matplotlib/tests/test_figure.py::test_savefig_metadata_error[tiff] PASSED [ 97%]\nlib/matplotlib/tests/test_figure.py::test_savefig_metadata_error[webp] PASSED [ 97%]\nlib/matplotlib/tests/test_figure.py::test_savefig_metadata_error[raw] PASSED [ 98%]\nlib/matplotlib/tests/test_figure.py::test_savefig_metadata_error[rgba] PASSED [ 99%]\nlib/matplotlib/tests/test_figure.py::test_get_constrained_layout_pads PASSED [100%]\n\n======================= 138 passed, 7 skipped in 18.69s ========================\n\n",
          "test_files_run": [
            "lib/matplotlib/tests/test_figure.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "sphinx-doc__sphinx-8056",
      "repo": "sphinx-doc/sphinx",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "duration": 8.776602983474731,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 40,
          "failed": 2,
          "errors": 0,
          "collected": 42,
          "duration": 4.93,
          "log_tail": "E   ?         ++++\nE   - :param x2: Input arrays, description of ``x1``, ``x2``.\nE   - :type x2: :class:`array_like`\n__________________ TestNumpyDocstring.test_token_type_invalid __________________\ntests/test_ext_napoleon_docstring.py:2264: in test_token_type_invalid\n    _token_type(token)\n/opt/miniconda3/envs/testbed/lib/python3.9/contextlib.py:126: in __exit__\n    next(self.gen)\ntests/test_ext_napoleon_docstring.py:2240: in warns\n    assert len(warnings) == 1 and all(match_re.match(w) for w in warnings)\nE   assert (2 == 1)\nE    +  where 2 = len([\"\\x1b[91mWARNING: while setting up extension sphinx.addnodes: node class 'meta' is already registered, its visitors will be overridden\\x1b[39;49;00m\", '\\x1b[91mWARNING: invalid value set (missing closing brace): {1, 2\\x1b[39;49;00m'])\n--------------------------- Captured stdout teardown ---------------------------\n# testroot: root\n# builder: html\n# srcdir: /tmp/pytest-of-root/pytest-0/root\n# outdir: /tmp/pytest-of-root/pytest-0/root/_build/html\n# status: \n\u001b[01mRunning Sphinx v3.2.0\u001b[39;49;00m\n\n# warning: \n\u001b[91mWARNING: while setting up extension sphinx.addnodes: node class 'meta' is already registered, its visitors will be overridden\u001b[39;49;00m\n\u001b[91mWARNING: invalid value set (missing closing brace): {1, 2\u001b[39;49;00m\n\n=============================== warnings summary ===============================\nsphinx/util/docutils.py:45\n  /testbed/sphinx/util/docutils.py:45: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    __version_info__ = tuple(LooseVersion(docutils.__version__).version)\n\nsphinx/registry.py:22\n  /testbed/sphinx/registry.py:22: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    from pkg_resources import iter_entry_points\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n    declare_namespace(pkg)\n\nsphinx/directives/patches.py:15\n  /testbed/sphinx/directives/patches.py:15: DeprecationWarning: The `docutils.parsers.rst.directive.html` module will be removed in Docutils 2.0. Since Docutils 0.18, the \"Meta\" node is defined in `docutils.parsers.rst.directives.misc`.\n    from docutils.parsers.rst.directives import images, html, tables\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=================== 2 failed, 40 passed, 7 warnings in 0.51s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_ext_napoleon_docstring.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_ext_napoleon_docstring.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 41,
          "failed": 1,
          "errors": 0,
          "collected": 42,
          "duration": 3.03,
          "log_tail": "tests/test_ext_napoleon_docstring.py::TestNumpyDocstring::test_escape_args_and_kwargs[*x, **y-\\\\*x, \\\\*\\\\*y] PASSED [100%]\n\n=================================== FAILURES ===================================\n__________________ TestNumpyDocstring.test_token_type_invalid __________________\ntests/test_ext_napoleon_docstring.py:2264: in test_token_type_invalid\n    _token_type(token)\n/opt/miniconda3/envs/testbed/lib/python3.9/contextlib.py:126: in __exit__\n    next(self.gen)\ntests/test_ext_napoleon_docstring.py:2240: in warns\n    assert len(warnings) == 1 and all(match_re.match(w) for w in warnings)\nE   assert (2 == 1)\nE    +  where 2 = len([\"\\x1b[91mWARNING: while setting up extension sphinx.addnodes: node class 'meta' is already registered, its visitors will be overridden\\x1b[39;49;00m\", '\\x1b[91mWARNING: invalid value set (missing closing brace): {1, 2\\x1b[39;49;00m'])\n--------------------------- Captured stdout teardown ---------------------------\n# testroot: root\n# builder: html\n# srcdir: /tmp/pytest-of-root/pytest-0/root\n# outdir: /tmp/pytest-of-root/pytest-0/root/_build/html\n# status: \n\u001b[01mRunning Sphinx v3.2.0\u001b[39;49;00m\n\n# warning: \n\u001b[91mWARNING: while setting up extension sphinx.addnodes: node class 'meta' is already registered, its visitors will be overridden\u001b[39;49;00m\n\u001b[91mWARNING: invalid value set (missing closing brace): {1, 2\u001b[39;49;00m\n\n=============================== warnings summary ===============================\nsphinx/util/docutils.py:45\n  /testbed/sphinx/util/docutils.py:45: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    __version_info__ = tuple(LooseVersion(docutils.__version__).version)\n\nsphinx/registry.py:22\n  /testbed/sphinx/registry.py:22: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    from pkg_resources import iter_entry_points\n\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n    declare_namespace(pkg)\n\nsphinx/directives/patches.py:15\n  /testbed/sphinx/directives/patches.py:15: DeprecationWarning: The `docutils.parsers.rst.directive.html` module will be removed in Docutils 2.0. Since Docutils 0.18, the \"Meta\" node is defined in `docutils.parsers.rst.directives.misc`.\n    from docutils.parsers.rst.directives import images, html, tables\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=================== 1 failed, 41 passed, 7 warnings in 0.51s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_ext_napoleon_docstring.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_ext_napoleon_docstring.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "matplotlib__matplotlib-24177",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://35.239.238.137:8080",
      "duration": 148.8748860359192,
      "test_only": {
        "passed": true,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "collected": 833,
          "duration": 74.83,
          "log_tail": "lib/matplotlib/tests/test_axes.py::test_bar_label_location_vertical PASSED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_vertical_yinverted PASSED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_horizontal PASSED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_horizontal_yinverted PASSED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_horizontal_xinverted PASSED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_horizontal_xyinverted PASSED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_center PASSED [ 96%]\nlib/matplotlib/tests/test_axes.py::test_centered_bar_label_nonlinear[svg] SKIPPED [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_errorbars PASSED [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_fmt[%.2f] PASSED       [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_fmt[{:.2f}] PASSED     [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_fmt[format] PASSED     [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_fmt_error PASSED       [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_labels PASSED          [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_nan_ydata PASSED       [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_nan_ydata_inverted PASSED [ 97%]\nlib/matplotlib/tests/test_axes.py::test_nan_barlabels PASSED             [ 97%]\nlib/matplotlib/tests/test_axes.py::test_patch_bounds PASSED              [ 97%]\nlib/matplotlib/tests/test_axes.py::test_warn_ignored_scatter_kwargs PASSED [ 97%]\nlib/matplotlib/tests/test_axes.py::test_artist_sublists PASSED           [ 97%]\nlib/matplotlib/tests/test_axes.py::test_empty_line_plots PASSED          [ 97%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[None-f-'f' is not a valid format string \\\\(unrecognized character 'f'\\\\)] PASSED [ 97%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[None-o+-'o\\\\+' is not a valid format string \\\\(two marker symbols\\\\)] PASSED [ 97%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[None-:--':-' is not a valid format string \\\\(two linestyle symbols\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[None-rk-'rk' is not a valid format string \\\\(two color symbols\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[None-:o-r-':o-r' is not a valid format string \\\\(two linestyle symbols\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[data1-f-'f' is not a valid format string \\\\(unrecognized character 'f'\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[data1-o+-'o\\\\+' is not a valid format string \\\\(two marker symbols\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[data1-:--':-' is not a valid format string \\\\(two linestyle symbols\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[data1-rk-'rk' is not a valid format string \\\\(two color symbols\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[data1-:o-r-':o-r' is not a valid format string \\\\(two linestyle symbols\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format PASSED               [ 99%]\nlib/matplotlib/tests/test_axes.py::test_automatic_legend PASSED          [ 99%]\nlib/matplotlib/tests/test_axes.py::test_plot_errors PASSED               [ 99%]\nlib/matplotlib/tests/test_axes.py::test_clim PASSED                      [ 99%]\nlib/matplotlib/tests/test_axes.py::test_bezier_autoscale PASSED          [ 99%]\nlib/matplotlib/tests/test_axes.py::test_small_autoscale FAILED           [ 99%]\nlib/matplotlib/tests/test_axes.py::test_get_xticklabel PASSED            [ 99%]\nlib/matplotlib/tests/test_axes.py::test_bar_leading_nan PASSED           [ 99%]\nlib/matplotlib/tests/test_axes.py::test_bar_all_nan[png] PASSED          [100%]\n\n=================================== FAILURES ===================================\n_____________________________ test_small_autoscale _____________________________\nlib/matplotlib/tests/test_axes.py:8217: in test_small_autoscale\n    assert ax.get_ylim()[1] >= maxy\nE   assert 0.25 >= 0.33\n============= 1 failed, 768 passed, 64 skipped in 70.09s (0:01:10) =============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_axes.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_axes.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 769,
          "failed": 0,
          "errors": 0,
          "collected": 833,
          "duration": 73.11,
          "log_tail": "lib/matplotlib/tests/test_axes.py::test_2dcolor_plot[pdf] PASSED         [ 94%]\nlib/matplotlib/tests/test_axes.py::test_shared_axes_clear[png] PASSED    [ 94%]\nlib/matplotlib/tests/test_axes.py::test_shared_axes_retick PASSED        [ 94%]\nlib/matplotlib/tests/test_axes.py::test_ylabel_ha_with_position[left] PASSED [ 94%]\nlib/matplotlib/tests/test_axes.py::test_ylabel_ha_with_position[center] PASSED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_ylabel_ha_with_position[right] PASSED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_vertical PASSED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_vertical_yinverted PASSED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_horizontal PASSED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_horizontal_yinverted PASSED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_horizontal_xinverted PASSED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_horizontal_xyinverted PASSED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_center PASSED [ 96%]\nlib/matplotlib/tests/test_axes.py::test_centered_bar_label_nonlinear[svg] SKIPPED [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_errorbars PASSED [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_fmt[%.2f] PASSED       [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_fmt[{:.2f}] PASSED     [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_fmt[format] PASSED     [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_fmt_error PASSED       [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_labels PASSED          [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_nan_ydata PASSED       [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_nan_ydata_inverted PASSED [ 97%]\nlib/matplotlib/tests/test_axes.py::test_nan_barlabels PASSED             [ 97%]\nlib/matplotlib/tests/test_axes.py::test_patch_bounds PASSED              [ 97%]\nlib/matplotlib/tests/test_axes.py::test_warn_ignored_scatter_kwargs PASSED [ 97%]\nlib/matplotlib/tests/test_axes.py::test_artist_sublists PASSED           [ 97%]\nlib/matplotlib/tests/test_axes.py::test_empty_line_plots PASSED          [ 97%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[None-f-'f' is not a valid format string \\\\(unrecognized character 'f'\\\\)] PASSED [ 97%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[None-o+-'o\\\\+' is not a valid format string \\\\(two marker symbols\\\\)] PASSED [ 97%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[None-:--':-' is not a valid format string \\\\(two linestyle symbols\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[None-rk-'rk' is not a valid format string \\\\(two color symbols\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[None-:o-r-':o-r' is not a valid format string \\\\(two linestyle symbols\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[data1-f-'f' is not a valid format string \\\\(unrecognized character 'f'\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[data1-o+-'o\\\\+' is not a valid format string \\\\(two marker symbols\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[data1-:--':-' is not a valid format string \\\\(two linestyle symbols\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[data1-rk-'rk' is not a valid format string \\\\(two color symbols\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[data1-:o-r-':o-r' is not a valid format string \\\\(two linestyle symbols\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format PASSED               [ 99%]\nlib/matplotlib/tests/test_axes.py::test_automatic_legend PASSED          [ 99%]\nlib/matplotlib/tests/test_axes.py::test_plot_errors PASSED               [ 99%]\nlib/matplotlib/tests/test_axes.py::test_clim PASSED                      [ 99%]\nlib/matplotlib/tests/test_axes.py::test_bezier_autoscale PASSED          [ 99%]\nlib/matplotlib/tests/test_axes.py::test_small_autoscale PASSED           [ 99%]\nlib/matplotlib/tests/test_axes.py::test_get_xticklabel PASSED            [ 99%]\nlib/matplotlib/tests/test_axes.py::test_bar_leading_nan PASSED           [ 99%]\nlib/matplotlib/tests/test_axes.py::test_bar_all_nan[png] PASSED          [100%]\n\n================== 769 passed, 64 skipped in 70.35s (0:01:10) ==================\n\n",
          "test_files_run": [
            "lib/matplotlib/tests/test_axes.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got True\u2192True"
    },
    {
      "instance_id": "matplotlib__matplotlib-26342",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://34.44.241.183:8080",
      "duration": 24.92396903038025,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 81,
          "failed": 2,
          "errors": 0,
          "collected": 87,
          "duration": 13.18,
          "log_tail": "lib/matplotlib/tests/test_contour.py::test_contour_line_start_on_corner_edge[png-True] PASSED [ 64%]\nlib/matplotlib/tests/test_contour.py::test_find_nearest_contour PASSED   [ 65%]\nlib/matplotlib/tests/test_contour.py::test_find_nearest_contour_no_filled PASSED [ 66%]\nlib/matplotlib/tests/test_contour.py::test_contour_autolabel_beyond_powerlimits PASSED [ 67%]\nlib/matplotlib/tests/test_contour.py::test_contourf_legend_elements PASSED [ 68%]\nlib/matplotlib/tests/test_contour.py::test_contour_legend_elements PASSED [ 70%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_name[mpl2005-Mpl2005ContourGenerator] PASSED [ 71%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_name[mpl2014-Mpl2014ContourGenerator] PASSED [ 72%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_name[serial-SerialContourGenerator] PASSED [ 73%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_name[threaded-ThreadedContourGenerator] PASSED [ 74%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_name[invalid-None] PASSED [ 75%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_supports_corner_mask[mpl2005] PASSED [ 77%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_supports_corner_mask[mpl2014] PASSED [ 78%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_supports_corner_mask[serial] PASSED [ 79%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_supports_corner_mask[threaded] PASSED [ 80%]\nlib/matplotlib/tests/test_contour.py::test_all_algorithms[png-False] PASSED [ 81%]\nlib/matplotlib/tests/test_contour.py::test_all_algorithms[png-True] PASSED [ 82%]\nlib/matplotlib/tests/test_contour.py::test_subfigure_clabel PASSED       [ 83%]\nlib/matplotlib/tests/test_contour.py::test_linestyles[solid] PASSED      [ 85%]\nlib/matplotlib/tests/test_contour.py::test_linestyles[dashed] PASSED     [ 86%]\nlib/matplotlib/tests/test_contour.py::test_linestyles[dashdot] PASSED    [ 87%]\nlib/matplotlib/tests/test_contour.py::test_linestyles[dotted] PASSED     [ 88%]\nlib/matplotlib/tests/test_contour.py::test_negative_linestyles[solid] PASSED [ 89%]\nlib/matplotlib/tests/test_contour.py::test_negative_linestyles[dashed] PASSED [ 90%]\nlib/matplotlib/tests/test_contour.py::test_negative_linestyles[dashdot] PASSED [ 91%]\nlib/matplotlib/tests/test_contour.py::test_negative_linestyles[dotted] PASSED [ 93%]\nlib/matplotlib/tests/test_contour.py::test_contour_remove PASSED         [ 94%]\nlib/matplotlib/tests/test_contour.py::test_contour_no_args PASSED        [ 95%]\nlib/matplotlib/tests/test_contour.py::test_contour_clip_path PASSED      [ 96%]\nlib/matplotlib/tests/test_contour.py::test_bool_autolevel PASSED         [ 97%]\nlib/matplotlib/tests/test_contour.py::test_all_nan PASSED                [ 98%]\nlib/matplotlib/tests/test_contour.py::test_deprecated_apis FAILED        [100%]\n\n=================================== FAILURES ===================================\n_________________________ test_contour_set_paths[png] __________________________\nlib/matplotlib/testing/decorators.py:411: in wrapper\n    func(*args, fig_test=fig_test, fig_ref=fig_ref, **kwargs)\nlib/matplotlib/tests/test_contour.py:108: in test_contour_set_paths\n    cs_test.set_paths(cs_ref.get_paths())\nlib/matplotlib/collections.py:210: in set_paths\n    raise NotImplementedError\nE   NotImplementedError\n_____________________________ test_deprecated_apis _____________________________\nlib/matplotlib/tests/test_contour.py:826: in test_deprecated_apis\n    with pytest.warns(PendingDeprecationWarning, match=\"allsegs\"):\nE   matplotlib._api.deprecation.MatplotlibDeprecationWarning: The collections attribute was deprecated in Matplotlib 3.8 and will be removed two minor releases later.\n=================== 2 failed, 81 passed, 4 skipped in 8.36s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_contour.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_contour.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 82,
          "failed": 1,
          "errors": 0,
          "collected": 87,
          "duration": 10.92,
          "log_tail": "lib/matplotlib/tests/test_contour.py::test_contour_linewidth[1.23-4.24-5.02-5.02] PASSED [ 55%]\nlib/matplotlib/tests/test_contour.py::test_label_nonagg PASSED           [ 56%]\nlib/matplotlib/tests/test_contour.py::test_contour_closed_line_loop[png-False] PASSED [ 57%]\nlib/matplotlib/tests/test_contour.py::test_contour_closed_line_loop[png-True] PASSED [ 58%]\nlib/matplotlib/tests/test_contour.py::test_quadcontourset_reuse PASSED   [ 59%]\nlib/matplotlib/tests/test_contour.py::test_contour_manual[png-False] PASSED [ 60%]\nlib/matplotlib/tests/test_contour.py::test_contour_manual[png-True] PASSED [ 62%]\nlib/matplotlib/tests/test_contour.py::test_contour_line_start_on_corner_edge[png-False] PASSED [ 63%]\nlib/matplotlib/tests/test_contour.py::test_contour_line_start_on_corner_edge[png-True] PASSED [ 64%]\nlib/matplotlib/tests/test_contour.py::test_find_nearest_contour PASSED   [ 65%]\nlib/matplotlib/tests/test_contour.py::test_find_nearest_contour_no_filled PASSED [ 66%]\nlib/matplotlib/tests/test_contour.py::test_contour_autolabel_beyond_powerlimits PASSED [ 67%]\nlib/matplotlib/tests/test_contour.py::test_contourf_legend_elements PASSED [ 68%]\nlib/matplotlib/tests/test_contour.py::test_contour_legend_elements PASSED [ 70%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_name[mpl2005-Mpl2005ContourGenerator] PASSED [ 71%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_name[mpl2014-Mpl2014ContourGenerator] PASSED [ 72%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_name[serial-SerialContourGenerator] PASSED [ 73%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_name[threaded-ThreadedContourGenerator] PASSED [ 74%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_name[invalid-None] PASSED [ 75%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_supports_corner_mask[mpl2005] PASSED [ 77%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_supports_corner_mask[mpl2014] PASSED [ 78%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_supports_corner_mask[serial] PASSED [ 79%]\nlib/matplotlib/tests/test_contour.py::test_algorithm_supports_corner_mask[threaded] PASSED [ 80%]\nlib/matplotlib/tests/test_contour.py::test_all_algorithms[png-False] PASSED [ 81%]\nlib/matplotlib/tests/test_contour.py::test_all_algorithms[png-True] PASSED [ 82%]\nlib/matplotlib/tests/test_contour.py::test_subfigure_clabel PASSED       [ 83%]\nlib/matplotlib/tests/test_contour.py::test_linestyles[solid] PASSED      [ 85%]\nlib/matplotlib/tests/test_contour.py::test_linestyles[dashed] PASSED     [ 86%]\nlib/matplotlib/tests/test_contour.py::test_linestyles[dashdot] PASSED    [ 87%]\nlib/matplotlib/tests/test_contour.py::test_linestyles[dotted] PASSED     [ 88%]\nlib/matplotlib/tests/test_contour.py::test_negative_linestyles[solid] PASSED [ 89%]\nlib/matplotlib/tests/test_contour.py::test_negative_linestyles[dashed] PASSED [ 90%]\nlib/matplotlib/tests/test_contour.py::test_negative_linestyles[dashdot] PASSED [ 91%]\nlib/matplotlib/tests/test_contour.py::test_negative_linestyles[dotted] PASSED [ 93%]\nlib/matplotlib/tests/test_contour.py::test_contour_remove PASSED         [ 94%]\nlib/matplotlib/tests/test_contour.py::test_contour_no_args PASSED        [ 95%]\nlib/matplotlib/tests/test_contour.py::test_contour_clip_path PASSED      [ 96%]\nlib/matplotlib/tests/test_contour.py::test_bool_autolevel PASSED         [ 97%]\nlib/matplotlib/tests/test_contour.py::test_all_nan PASSED                [ 98%]\nlib/matplotlib/tests/test_contour.py::test_deprecated_apis FAILED        [100%]\n\n=================================== FAILURES ===================================\n_____________________________ test_deprecated_apis _____________________________\nlib/matplotlib/tests/test_contour.py:826: in test_deprecated_apis\n    with pytest.warns(PendingDeprecationWarning, match=\"allsegs\"):\nE   matplotlib._api.deprecation.MatplotlibDeprecationWarning: The collections attribute was deprecated in Matplotlib 3.8 and will be removed two minor releases later.\n=================== 1 failed, 82 passed, 4 skipped in 8.30s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_contour.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_contour.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sphinx-doc__sphinx-8621",
      "repo": "sphinx-doc/sphinx",
      "valid": false,
      "worker": "http://34.41.233.120:8080",
      "duration": 8.131347894668579,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 31,
          "failed": 4,
          "errors": 0,
          "collected": 35,
          "duration": 3.66,
          "log_tail": "tests/test_markup.py::test_rst_prolog\ntests/test_markup.py::test_rst_prolog\ntests/test_markup.py::test_keep_warnings_is_True\ntests/test_markup.py::test_keep_warnings_is_False\ntests/test_markup.py::test_compact_refonly_bullet_list\ntests/test_markup.py::test_default_role1\ntests/test_markup.py::test_default_role1\ntests/test_markup.py::test_default_role2\ntests/test_markup.py::test_default_role2\n  /testbed/sphinx/builders/latex/transforms.py:608: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for i, index in enumerate(node.traverse(addnodes.index)):\n\ntests/test_markup.py: 10 warnings\n  /testbed/sphinx/transforms/post_transforms/code.py:43: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(addnodes.highlightlang):\n\ntests/test_markup.py: 10 warnings\n  /testbed/sphinx/transforms/post_transforms/code.py:95: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for lbnode in self.document.traverse(nodes.literal_block):  # type: nodes.literal_block\n\ntests/test_markup.py: 10 warnings\n  /testbed/sphinx/transforms/post_transforms/code.py:99: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for dbnode in self.document.traverse(nodes.doctest_block):  # type: nodes.doctest_block\n\ntests/test_markup.py: 10 warnings\n  /testbed/sphinx/environment/__init__.py:540: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for toctreenode in doctree.traverse(addnodes.toctree):\n\ntests/test_markup.py::test_rst_prolog\ntests/test_markup.py::test_rst_prolog\n  /testbed/sphinx/environment/adapters/toctree.py:203: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for subtocnode in toc.traverse(addnodes.toctree):\n\ntests/test_markup.py::test_rst_prolog\n  /testbed/sphinx/environment/adapters/toctree.py:261: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for refnode in newnode.traverse(nodes.reference):\n\ntests/test_markup.py::test_compact_refonly_bullet_list\n  /testbed/sphinx/transforms/compact_bullet_list.py:77: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(nodes.bullet_list):\n\ntests/test_markup.py::test_compact_refonly_bullet_list\n  /testbed/sphinx/transforms/compact_bullet_list.py:79: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for item in node.traverse(nodes.list_item):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================= 4 failed, 31 passed, 3175 warnings in 1.20s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_markup.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_markup.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 33,
          "failed": 2,
          "errors": 0,
          "collected": 35,
          "duration": 3.66,
          "log_tail": "tests/test_markup.py::test_rst_prolog\ntests/test_markup.py::test_rst_prolog\ntests/test_markup.py::test_keep_warnings_is_True\ntests/test_markup.py::test_keep_warnings_is_False\ntests/test_markup.py::test_compact_refonly_bullet_list\ntests/test_markup.py::test_default_role1\ntests/test_markup.py::test_default_role1\ntests/test_markup.py::test_default_role2\ntests/test_markup.py::test_default_role2\n  /testbed/sphinx/builders/latex/transforms.py:608: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for i, index in enumerate(node.traverse(addnodes.index)):\n\ntests/test_markup.py: 10 warnings\n  /testbed/sphinx/transforms/post_transforms/code.py:43: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(addnodes.highlightlang):\n\ntests/test_markup.py: 10 warnings\n  /testbed/sphinx/transforms/post_transforms/code.py:95: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for lbnode in self.document.traverse(nodes.literal_block):  # type: nodes.literal_block\n\ntests/test_markup.py: 10 warnings\n  /testbed/sphinx/transforms/post_transforms/code.py:99: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for dbnode in self.document.traverse(nodes.doctest_block):  # type: nodes.doctest_block\n\ntests/test_markup.py: 10 warnings\n  /testbed/sphinx/environment/__init__.py:540: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for toctreenode in doctree.traverse(addnodes.toctree):\n\ntests/test_markup.py::test_rst_prolog\ntests/test_markup.py::test_rst_prolog\n  /testbed/sphinx/environment/adapters/toctree.py:203: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for subtocnode in toc.traverse(addnodes.toctree):\n\ntests/test_markup.py::test_rst_prolog\n  /testbed/sphinx/environment/adapters/toctree.py:261: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for refnode in newnode.traverse(nodes.reference):\n\ntests/test_markup.py::test_compact_refonly_bullet_list\n  /testbed/sphinx/transforms/compact_bullet_list.py:77: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in self.document.traverse(nodes.bullet_list):\n\ntests/test_markup.py::test_compact_refonly_bullet_list\n  /testbed/sphinx/transforms/compact_bullet_list.py:79: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for item in node.traverse(nodes.list_item):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================= 2 failed, 33 passed, 3177 warnings in 1.18s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_markup.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_markup.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sphinx-doc__sphinx-8120",
      "repo": "sphinx-doc/sphinx",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "duration": 15.04989218711853,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 44,
          "failed": 5,
          "errors": 0,
          "collected": 49,
          "duration": 6.97,
          "log_tail": "\ntests/test_intl.py: 56 warnings\n  /testbed/sphinx/environment/adapters/toctree.py:313: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in toc.traverse(nodes.reference):\n\ntests/test_intl.py: 62 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:114: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n    _gaq.push(['_setAllowLinker', true]);\n\ntests/test_intl.py: 62 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:70: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_intl.py: 62 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:99: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_intl.py: 62 warnings\n  /testbed/sphinx/environment/adapters/toctree.py:327: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for toctreenode in doctree.traverse(addnodes.toctree):\n\ntests/test_intl.py: 62 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:215: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_intl.py: 62 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:238: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_intl.py::test_html_meta\ntests/test_intl.py::test_additional_targets_should_be_translated\n  <template>:33: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_intl.py::test_html_meta\ntests/test_intl.py::test_additional_targets_should_be_translated\n  <template>:224: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_intl.py::test_html_meta\ntests/test_intl.py::test_additional_targets_should_be_translated\n  <template>:386: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_intl.py::test_html_meta\ntests/test_intl.py::test_additional_targets_should_be_translated\n  <template>:401: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_intl.py: 28 warnings\n  /testbed/sphinx/builders/xml.py:79: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in doctree.traverse(nodes.Element):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================= 5 failed, 44 passed, 12363 warnings in 4.38s =================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_intl.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_intl.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 45,
          "failed": 4,
          "errors": 0,
          "collected": 49,
          "duration": 7.2,
          "log_tail": "\ntests/test_intl.py: 65 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:114: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n    _gaq.push(['_setAllowLinker', true]);\n\ntests/test_intl.py: 65 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:70: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_intl.py: 65 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/about.html:99: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_intl.py: 65 warnings\n  /testbed/sphinx/environment/adapters/toctree.py:327: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for toctreenode in doctree.traverse(addnodes.toctree):\n\ntests/test_intl.py: 65 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:215: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_intl.py: 65 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/alabaster/layout.html:238: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_intl.py::test_html_meta\ntests/test_intl.py::test_additional_targets_should_be_translated\ntests/test_intl.py::test_customize_system_message\n  <template>:33: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_intl.py::test_html_meta\ntests/test_intl.py::test_additional_targets_should_be_translated\ntests/test_intl.py::test_customize_system_message\n  <template>:224: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_intl.py::test_html_meta\ntests/test_intl.py::test_additional_targets_should_be_translated\ntests/test_intl.py::test_customize_system_message\n  <template>:386: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_intl.py::test_html_meta\ntests/test_intl.py::test_additional_targets_should_be_translated\ntests/test_intl.py::test_customize_system_message\n  <template>:401: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n\ntests/test_intl.py: 28 warnings\n  /testbed/sphinx/builders/xml.py:79: PendingDeprecationWarning: nodes.Node.traverse() is obsoleted by Node.findall().\n    for node in doctree.traverse(nodes.Element):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================= 4 failed, 45 passed, 12504 warnings in 4.60s =================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_intl.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_intl.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "scikit-learn__scikit-learn-10297",
      "repo": "scikit-learn/scikit-learn",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 8.931912183761597,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 28,
          "failed": 1,
          "errors": 0,
          "collected": 30,
          "duration": 4.82,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 30 items\n\nsklearn/linear_model/tests/test_ridge.py::test_ridge PASSED              [  3%]\nsklearn/linear_model/tests/test_ridge.py::test_primal_dual_relationship PASSED [  6%]\nsklearn/linear_model/tests/test_ridge.py::test_ridge_singular PASSED     [ 10%]\nsklearn/linear_model/tests/test_ridge.py::test_ridge_regression_sample_weights PASSED [ 13%]\nsklearn/linear_model/tests/test_ridge.py::test_ridge_sample_weights PASSED [ 16%]\nsklearn/linear_model/tests/test_ridge.py::test_ridge_shapes PASSED       [ 20%]\nsklearn/linear_model/tests/test_ridge.py::test_ridge_intercept PASSED    [ 23%]\nsklearn/linear_model/tests/test_ridge.py::test_toy_ridge_object PASSED   [ 26%]\nsklearn/linear_model/tests/test_ridge.py::test_ridge_vs_lstsq PASSED     [ 30%]\nsklearn/linear_model/tests/test_ridge.py::test_ridge_individual_penalties PASSED [ 33%]\nsklearn/linear_model/tests/test_ridge.py::test_dense_sparse XFAIL ([...) [ 36%]\nsklearn/linear_model/tests/test_ridge.py::test_ridge_cv_sparse_svd PASSED [ 40%]\nsklearn/linear_model/tests/test_ridge.py::test_ridge_sparse_svd PASSED   [ 43%]\nsklearn/linear_model/tests/test_ridge.py::test_class_weights PASSED      [ 46%]\nsklearn/linear_model/tests/test_ridge.py::test_class_weight_vs_sample_weight PASSED [ 50%]\nsklearn/linear_model/tests/test_ridge.py::test_class_weights_cv PASSED   [ 53%]\nsklearn/linear_model/tests/test_ridge.py::test_ridgecv_store_cv_values PASSED [ 56%]\nsklearn/linear_model/tests/test_ridge.py::test_ridge_classifier_cv_store_cv_values FAILED [ 60%]\nsklearn/linear_model/tests/test_ridge.py::test_ridgecv_sample_weight PASSED [ 63%]\nsklearn/linear_model/tests/test_ridge.py::test_raises_value_error_if_sample_weights_greater_than_1d PASSED [ 66%]\nsklearn/linear_model/tests/test_ridge.py::test_sparse_design_with_sample_weights PASSED [ 70%]\nsklearn/linear_model/tests/test_ridge.py::test_raises_value_error_if_solver_not_supported PASSED [ 73%]\nsklearn/linear_model/tests/test_ridge.py::test_sparse_cg_max_iter PASSED [ 76%]\nsklearn/linear_model/tests/test_ridge.py::test_n_iter PASSED             [ 80%]\nsklearn/linear_model/tests/test_ridge.py::test_ridge_fit_intercept_sparse PASSED [ 83%]\nsklearn/linear_model/tests/test_ridge.py::test_errors_and_values_helper PASSED [ 86%]\nsklearn/linear_model/tests/test_ridge.py::test_errors_and_values_svd_helper PASSED [ 90%]\nsklearn/linear_model/tests/test_ridge.py::test_ridge_classifier_no_support_multilabel PASSED [ 93%]\nsklearn/linear_model/tests/test_ridge.py::test_dtype_match PASSED        [ 96%]\nsklearn/linear_model/tests/test_ridge.py::test_dtype_match_cholesky PASSED [100%]\n\n=================================== FAILURES ===================================\n___________________ test_ridge_classifier_cv_store_cv_values ___________________\nsklearn/linear_model/tests/test_ridge.py:609: in test_ridge_classifier_cv_store_cv_values\n    r = RidgeClassifierCV(alphas=alphas, store_cv_values=True)\nE   TypeError: __init__() got an unexpected keyword argument 'store_cv_values'\n============= 1 failed, 28 passed, 1 xfailed, 22 warnings in 1.00s =============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sklearn/linear_model/tests/test_ridge.py` failed. (See above for error)",
          "test_files_run": [
            "sklearn/linear_model/tests/test_ridge.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 29,
          "failed": 0,
          "errors": 0,
          "collected": 30,
          "duration": 3.29,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 30 items\n\nsklearn/linear_model/tests/test_ridge.py::test_ridge PASSED              [  3%]\nsklearn/linear_model/tests/test_ridge.py::test_primal_dual_relationship PASSED [  6%]\nsklearn/linear_model/tests/test_ridge.py::test_ridge_singular PASSED     [ 10%]\nsklearn/linear_model/tests/test_ridge.py::test_ridge_regression_sample_weights PASSED [ 13%]\nsklearn/linear_model/tests/test_ridge.py::test_ridge_sample_weights PASSED [ 16%]\nsklearn/linear_model/tests/test_ridge.py::test_ridge_shapes PASSED       [ 20%]\nsklearn/linear_model/tests/test_ridge.py::test_ridge_intercept PASSED    [ 23%]\nsklearn/linear_model/tests/test_ridge.py::test_toy_ridge_object PASSED   [ 26%]\nsklearn/linear_model/tests/test_ridge.py::test_ridge_vs_lstsq PASSED     [ 30%]\nsklearn/linear_model/tests/test_ridge.py::test_ridge_individual_penalties PASSED [ 33%]\nsklearn/linear_model/tests/test_ridge.py::test_dense_sparse XFAIL ([...) [ 36%]\nsklearn/linear_model/tests/test_ridge.py::test_ridge_cv_sparse_svd PASSED [ 40%]\nsklearn/linear_model/tests/test_ridge.py::test_ridge_sparse_svd PASSED   [ 43%]\nsklearn/linear_model/tests/test_ridge.py::test_class_weights PASSED      [ 46%]\nsklearn/linear_model/tests/test_ridge.py::test_class_weight_vs_sample_weight PASSED [ 50%]\nsklearn/linear_model/tests/test_ridge.py::test_class_weights_cv PASSED   [ 53%]\nsklearn/linear_model/tests/test_ridge.py::test_ridgecv_store_cv_values PASSED [ 56%]\nsklearn/linear_model/tests/test_ridge.py::test_ridge_classifier_cv_store_cv_values PASSED [ 60%]\nsklearn/linear_model/tests/test_ridge.py::test_ridgecv_sample_weight PASSED [ 63%]\nsklearn/linear_model/tests/test_ridge.py::test_raises_value_error_if_sample_weights_greater_than_1d PASSED [ 66%]\nsklearn/linear_model/tests/test_ridge.py::test_sparse_design_with_sample_weights PASSED [ 70%]\nsklearn/linear_model/tests/test_ridge.py::test_raises_value_error_if_solver_not_supported PASSED [ 73%]\nsklearn/linear_model/tests/test_ridge.py::test_sparse_cg_max_iter PASSED [ 76%]\nsklearn/linear_model/tests/test_ridge.py::test_n_iter PASSED             [ 80%]\nsklearn/linear_model/tests/test_ridge.py::test_ridge_fit_intercept_sparse PASSED [ 83%]\nsklearn/linear_model/tests/test_ridge.py::test_errors_and_values_helper PASSED [ 86%]\nsklearn/linear_model/tests/test_ridge.py::test_errors_and_values_svd_helper PASSED [ 90%]\nsklearn/linear_model/tests/test_ridge.py::test_ridge_classifier_no_support_multilabel PASSED [ 93%]\nsklearn/linear_model/tests/test_ridge.py::test_dtype_match PASSED        [ 96%]\nsklearn/linear_model/tests/test_ridge.py::test_dtype_match_cholesky PASSED [100%]\n\n================== 29 passed, 1 xfailed, 22 warnings in 1.01s ==================\n\n",
          "test_files_run": [
            "sklearn/linear_model/tests/test_ridge.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "matplotlib__matplotlib-24627",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://34.70.1.155:8080",
      "duration": 148.43793892860413,
      "test_only": {
        "passed": true,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "collected": 841,
          "duration": 73.76,
          "log_tail": "lib/matplotlib/tests/test_axes.py::test_bar_label_location_horizontal_xinverted PASSED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_horizontal_xyinverted PASSED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_center PASSED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_centered_bar_label_nonlinear[svg] SKIPPED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_errorbars PASSED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_fmt[%.2f] PASSED       [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_fmt[{:.2f}] PASSED     [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_fmt[format] PASSED     [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_fmt_error PASSED       [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_labels PASSED          [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_nan_ydata PASSED       [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_nan_ydata_inverted PASSED [ 96%]\nlib/matplotlib/tests/test_axes.py::test_nan_barlabels PASSED             [ 96%]\nlib/matplotlib/tests/test_axes.py::test_patch_bounds PASSED              [ 97%]\nlib/matplotlib/tests/test_axes.py::test_warn_ignored_scatter_kwargs PASSED [ 97%]\nlib/matplotlib/tests/test_axes.py::test_artist_sublists PASSED           [ 97%]\nlib/matplotlib/tests/test_axes.py::test_empty_line_plots PASSED          [ 97%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[None-f-'f' is not a valid format string \\\\(unrecognized character 'f'\\\\)] PASSED [ 97%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[None-o+-'o\\\\+' is not a valid format string \\\\(two marker symbols\\\\)] PASSED [ 97%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[None-:--':-' is not a valid format string \\\\(two linestyle symbols\\\\)] PASSED [ 97%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[None-rk-'rk' is not a valid format string \\\\(two color symbols\\\\)] PASSED [ 97%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[None-:o-r-':o-r' is not a valid format string \\\\(two linestyle symbols\\\\)] PASSED [ 97%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[data1-f-'f' is not a valid format string \\\\(unrecognized character 'f'\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[data1-o+-'o\\\\+' is not a valid format string \\\\(two marker symbols\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[data1-:--':-' is not a valid format string \\\\(two linestyle symbols\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[data1-rk-'rk' is not a valid format string \\\\(two color symbols\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[data1-:o-r-':o-r' is not a valid format string \\\\(two linestyle symbols\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format PASSED               [ 98%]\nlib/matplotlib/tests/test_axes.py::test_automatic_legend PASSED          [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_errors PASSED               [ 98%]\nlib/matplotlib/tests/test_axes.py::test_clim PASSED                      [ 99%]\nlib/matplotlib/tests/test_axes.py::test_bezier_autoscale PASSED          [ 99%]\nlib/matplotlib/tests/test_axes.py::test_small_autoscale PASSED           [ 99%]\nlib/matplotlib/tests/test_axes.py::test_get_xticklabel PASSED            [ 99%]\nlib/matplotlib/tests/test_axes.py::test_bar_leading_nan PASSED           [ 99%]\nlib/matplotlib/tests/test_axes.py::test_bar_all_nan[png] PASSED          [ 99%]\nlib/matplotlib/tests/test_axes.py::test_extent_units[png] PASSED         [ 99%]\nlib/matplotlib/tests/test_axes.py::test_cla_clears_children_axes_and_fig FAILED [ 99%]\nlib/matplotlib/tests/test_axes.py::test_scatter_color_repr_error PASSED  [100%]\n\n=================================== FAILURES ===================================\n____________________ test_cla_clears_children_axes_and_fig _____________________\nlib/matplotlib/tests/test_axes.py:8382: in test_cla_clears_children_axes_and_fig\n    assert art.axes is None\nE   assert <Axes: > is None\nE    +  where <Axes: > = <matplotlib.lines.Line2D object at 0x7deca9185350>.axes\n============= 1 failed, 776 passed, 64 skipped in 70.98s (0:01:10) =============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN lib/matplotlib/tests/test_axes.py` failed. (See above for error)",
          "test_files_run": [
            "lib/matplotlib/tests/test_axes.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 777,
          "failed": 0,
          "errors": 0,
          "collected": 841,
          "duration": 73.76,
          "log_tail": "lib/matplotlib/tests/test_axes.py::test_ylabel_ha_with_position[left] PASSED [ 94%]\nlib/matplotlib/tests/test_axes.py::test_ylabel_ha_with_position[center] PASSED [ 94%]\nlib/matplotlib/tests/test_axes.py::test_ylabel_ha_with_position[right] PASSED [ 94%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_vertical PASSED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_vertical_yinverted PASSED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_horizontal PASSED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_horizontal_yinverted PASSED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_horizontal_xinverted PASSED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_horizontal_xyinverted PASSED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_center PASSED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_centered_bar_label_nonlinear[svg] SKIPPED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_location_errorbars PASSED [ 95%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_fmt[%.2f] PASSED       [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_fmt[{:.2f}] PASSED     [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_fmt[format] PASSED     [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_fmt_error PASSED       [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_labels PASSED          [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_nan_ydata PASSED       [ 96%]\nlib/matplotlib/tests/test_axes.py::test_bar_label_nan_ydata_inverted PASSED [ 96%]\nlib/matplotlib/tests/test_axes.py::test_nan_barlabels PASSED             [ 96%]\nlib/matplotlib/tests/test_axes.py::test_patch_bounds PASSED              [ 97%]\nlib/matplotlib/tests/test_axes.py::test_warn_ignored_scatter_kwargs PASSED [ 97%]\nlib/matplotlib/tests/test_axes.py::test_artist_sublists PASSED           [ 97%]\nlib/matplotlib/tests/test_axes.py::test_empty_line_plots PASSED          [ 97%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[None-f-'f' is not a valid format string \\\\(unrecognized character 'f'\\\\)] PASSED [ 97%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[None-o+-'o\\\\+' is not a valid format string \\\\(two marker symbols\\\\)] PASSED [ 97%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[None-:--':-' is not a valid format string \\\\(two linestyle symbols\\\\)] PASSED [ 97%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[None-rk-'rk' is not a valid format string \\\\(two color symbols\\\\)] PASSED [ 97%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[None-:o-r-':o-r' is not a valid format string \\\\(two linestyle symbols\\\\)] PASSED [ 97%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[data1-f-'f' is not a valid format string \\\\(unrecognized character 'f'\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[data1-o+-'o\\\\+' is not a valid format string \\\\(two marker symbols\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[data1-:--':-' is not a valid format string \\\\(two linestyle symbols\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[data1-rk-'rk' is not a valid format string \\\\(two color symbols\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format_errors[data1-:o-r-':o-r' is not a valid format string \\\\(two linestyle symbols\\\\)] PASSED [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_format PASSED               [ 98%]\nlib/matplotlib/tests/test_axes.py::test_automatic_legend PASSED          [ 98%]\nlib/matplotlib/tests/test_axes.py::test_plot_errors PASSED               [ 98%]\nlib/matplotlib/tests/test_axes.py::test_clim PASSED                      [ 99%]\nlib/matplotlib/tests/test_axes.py::test_bezier_autoscale PASSED          [ 99%]\nlib/matplotlib/tests/test_axes.py::test_small_autoscale PASSED           [ 99%]\nlib/matplotlib/tests/test_axes.py::test_get_xticklabel PASSED            [ 99%]\nlib/matplotlib/tests/test_axes.py::test_bar_leading_nan PASSED           [ 99%]\nlib/matplotlib/tests/test_axes.py::test_bar_all_nan[png] PASSED          [ 99%]\nlib/matplotlib/tests/test_axes.py::test_extent_units[png] PASSED         [ 99%]\nlib/matplotlib/tests/test_axes.py::test_cla_clears_children_axes_and_fig PASSED [ 99%]\nlib/matplotlib/tests/test_axes.py::test_scatter_color_repr_error PASSED  [100%]\n\n================== 777 passed, 64 skipped in 71.01s (0:01:11) ==================\n\n",
          "test_files_run": [
            "lib/matplotlib/tests/test_axes.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got True\u2192True"
    },
    {
      "instance_id": "scikit-learn__scikit-learn-10844",
      "repo": "scikit-learn/scikit-learn",
      "valid": true,
      "worker": "http://34.41.233.120:8080",
      "duration": 9.12989091873169,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 16,
          "failed": 1,
          "errors": 0,
          "collected": 17,
          "duration": 4.4,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 17 items\n\nsklearn/metrics/cluster/tests/test_supervised.py::test_error_messages_on_wrong_input PASSED [  5%]\nsklearn/metrics/cluster/tests/test_supervised.py::test_perfect_matches PASSED [ 11%]\nsklearn/metrics/cluster/tests/test_supervised.py::test_homogeneous_but_not_complete_labeling PASSED [ 17%]\nsklearn/metrics/cluster/tests/test_supervised.py::test_complete_but_not_homogeneous_labeling PASSED [ 23%]\nsklearn/metrics/cluster/tests/test_supervised.py::test_not_complete_and_not_homogeneous_labeling PASSED [ 29%]\nsklearn/metrics/cluster/tests/test_supervised.py::test_non_consicutive_labels PASSED [ 35%]\nsklearn/metrics/cluster/tests/test_supervised.py::test_adjustment_for_chance PASSED [ 41%]\nsklearn/metrics/cluster/tests/test_supervised.py::test_adjusted_mutual_info_score PASSED [ 47%]\nsklearn/metrics/cluster/tests/test_supervised.py::test_expected_mutual_info_overflow PASSED [ 52%]\nsklearn/metrics/cluster/tests/test_supervised.py::test_int_overflow_mutual_info_fowlkes_mallows_score FAILED [ 58%]\nsklearn/metrics/cluster/tests/test_supervised.py::test_entropy PASSED    [ 64%]\nsklearn/metrics/cluster/tests/test_supervised.py::test_contingency_matrix PASSED [ 70%]\nsklearn/metrics/cluster/tests/test_supervised.py::test_contingency_matrix_sparse PASSED [ 76%]\nsklearn/metrics/cluster/tests/test_supervised.py::test_exactly_zero_info_score PASSED [ 82%]\nsklearn/metrics/cluster/tests/test_supervised.py::test_v_measure_and_mutual_information PASSED [ 88%]\nsklearn/metrics/cluster/tests/test_supervised.py::test_fowlkes_mallows_score PASSED [ 94%]\nsklearn/metrics/cluster/tests/test_supervised.py::test_fowlkes_mallows_score_properties PASSED [100%]\n\n=================================== FAILURES ===================================\n_____________ test_int_overflow_mutual_info_fowlkes_mallows_score ______________\nsklearn/metrics/cluster/tests/test_supervised.py:185: in test_int_overflow_mutual_info_fowlkes_mallows_score\n    assert_all_finite(fowlkes_mallows_score(x, y))\nsklearn/utils/validation.py:62: in assert_all_finite\n    _assert_all_finite(X.data if sp.issparse(X) else X, allow_nan)\nsklearn/utils/validation.py:50: in _assert_all_finite\n    raise ValueError(msg_err.format(type_err, X.dtype))\nE   ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n=================== 1 failed, 16 passed, 6 warnings in 0.55s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sklearn/metrics/cluster/tests/test_supervised.py` failed. (See above for error)",
          "test_files_run": [
            "sklearn/metrics/cluster/tests/test_supervised.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 17,
          "failed": 0,
          "errors": 0,
          "collected": 17,
          "duration": 3.79,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 17 items\n\nsklearn/metrics/cluster/tests/test_supervised.py::test_error_messages_on_wrong_input PASSED [  5%]\nsklearn/metrics/cluster/tests/test_supervised.py::test_perfect_matches PASSED [ 11%]\nsklearn/metrics/cluster/tests/test_supervised.py::test_homogeneous_but_not_complete_labeling PASSED [ 17%]\nsklearn/metrics/cluster/tests/test_supervised.py::test_complete_but_not_homogeneous_labeling PASSED [ 23%]\nsklearn/metrics/cluster/tests/test_supervised.py::test_not_complete_and_not_homogeneous_labeling PASSED [ 29%]\nsklearn/metrics/cluster/tests/test_supervised.py::test_non_consicutive_labels PASSED [ 35%]\nsklearn/metrics/cluster/tests/test_supervised.py::test_adjustment_for_chance PASSED [ 41%]\nsklearn/metrics/cluster/tests/test_supervised.py::test_adjusted_mutual_info_score PASSED [ 47%]\nsklearn/metrics/cluster/tests/test_supervised.py::test_expected_mutual_info_overflow PASSED [ 52%]\nsklearn/metrics/cluster/tests/test_supervised.py::test_int_overflow_mutual_info_fowlkes_mallows_score PASSED [ 58%]\nsklearn/metrics/cluster/tests/test_supervised.py::test_entropy PASSED    [ 64%]\nsklearn/metrics/cluster/tests/test_supervised.py::test_contingency_matrix PASSED [ 70%]\nsklearn/metrics/cluster/tests/test_supervised.py::test_contingency_matrix_sparse PASSED [ 76%]\nsklearn/metrics/cluster/tests/test_supervised.py::test_exactly_zero_info_score PASSED [ 82%]\nsklearn/metrics/cluster/tests/test_supervised.py::test_v_measure_and_mutual_information PASSED [ 88%]\nsklearn/metrics/cluster/tests/test_supervised.py::test_fowlkes_mallows_score PASSED [ 94%]\nsklearn/metrics/cluster/tests/test_supervised.py::test_fowlkes_mallows_score_properties PASSED [100%]\n\n======================== 17 passed, 4 warnings in 0.55s ========================\n\n",
          "test_files_run": [
            "sklearn/metrics/cluster/tests/test_supervised.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "scikit-learn__scikit-learn-10908",
      "repo": "scikit-learn/scikit-learn",
      "valid": true,
      "worker": "http://34.59.30.169:8080",
      "duration": 11.107558012008667,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 47,
          "failed": 1,
          "errors": 0,
          "collected": 48,
          "duration": 3.64,
          "log_tail": "sklearn/feature_extraction/tests/test_text.py::test_countvectorizer_custom_vocabulary PASSED [ 18%]\nsklearn/feature_extraction/tests/test_text.py::test_countvectorizer_custom_vocabulary_pipeline PASSED [ 20%]\nsklearn/feature_extraction/tests/test_text.py::test_countvectorizer_custom_vocabulary_repeated_indices PASSED [ 22%]\nsklearn/feature_extraction/tests/test_text.py::test_countvectorizer_custom_vocabulary_gap_index PASSED [ 25%]\nsklearn/feature_extraction/tests/test_text.py::test_countvectorizer_stop_words PASSED [ 27%]\nsklearn/feature_extraction/tests/test_text.py::test_countvectorizer_empty_vocabulary PASSED [ 29%]\nsklearn/feature_extraction/tests/test_text.py::test_fit_countvectorizer_twice PASSED [ 31%]\nsklearn/feature_extraction/tests/test_text.py::test_tf_idf_smoothing PASSED [ 33%]\nsklearn/feature_extraction/tests/test_text.py::test_tfidf_no_smoothing PASSED [ 35%]\nsklearn/feature_extraction/tests/test_text.py::test_sublinear_tf PASSED  [ 37%]\nsklearn/feature_extraction/tests/test_text.py::test_vectorizer PASSED    [ 39%]\nsklearn/feature_extraction/tests/test_text.py::test_tfidf_vectorizer_setters PASSED [ 41%]\nsklearn/feature_extraction/tests/test_text.py::test_hashing_vectorizer PASSED [ 43%]\nsklearn/feature_extraction/tests/test_text.py::test_feature_names FAILED [ 45%]\nsklearn/feature_extraction/tests/test_text.py::test_vectorizer_max_features PASSED [ 47%]\nsklearn/feature_extraction/tests/test_text.py::test_count_vectorizer_max_features PASSED [ 50%]\nsklearn/feature_extraction/tests/test_text.py::test_vectorizer_max_df PASSED [ 52%]\nsklearn/feature_extraction/tests/test_text.py::test_vectorizer_min_df PASSED [ 54%]\nsklearn/feature_extraction/tests/test_text.py::test_count_binary_occurrences PASSED [ 56%]\nsklearn/feature_extraction/tests/test_text.py::test_hashed_binary_occurrences PASSED [ 58%]\nsklearn/feature_extraction/tests/test_text.py::test_vectorizer_inverse_transform PASSED [ 60%]\nsklearn/feature_extraction/tests/test_text.py::test_count_vectorizer_pipeline_grid_selection PASSED [ 62%]\nsklearn/feature_extraction/tests/test_text.py::test_vectorizer_pipeline_grid_selection PASSED [ 64%]\nsklearn/feature_extraction/tests/test_text.py::test_vectorizer_pipeline_cross_validation PASSED [ 66%]\nsklearn/feature_extraction/tests/test_text.py::test_vectorizer_unicode PASSED [ 68%]\nsklearn/feature_extraction/tests/test_text.py::test_tfidf_vectorizer_with_fixed_vocabulary PASSED [ 70%]\nsklearn/feature_extraction/tests/test_text.py::test_pickling_vectorizer PASSED [ 72%]\nsklearn/feature_extraction/tests/test_text.py::test_countvectorizer_vocab_sets_when_pickling PASSED [ 75%]\nsklearn/feature_extraction/tests/test_text.py::test_countvectorizer_vocab_dicts_when_pickling PASSED [ 77%]\nsklearn/feature_extraction/tests/test_text.py::test_stop_words_removal PASSED [ 79%]\nsklearn/feature_extraction/tests/test_text.py::test_pickling_transformer PASSED [ 81%]\nsklearn/feature_extraction/tests/test_text.py::test_non_unique_vocab PASSED [ 83%]\nsklearn/feature_extraction/tests/test_text.py::test_hashingvectorizer_nan_in_docs PASSED [ 85%]\nsklearn/feature_extraction/tests/test_text.py::test_tfidfvectorizer_binary PASSED [ 87%]\nsklearn/feature_extraction/tests/test_text.py::test_tfidfvectorizer_export_idf PASSED [ 89%]\nsklearn/feature_extraction/tests/test_text.py::test_vectorizer_vocab_clone PASSED [ 91%]\nsklearn/feature_extraction/tests/test_text.py::test_vectorizer_string_object_as_input PASSED [ 93%]\nsklearn/feature_extraction/tests/test_text.py::test_vectorizers_invalid_ngram_range[vec0] PASSED [ 95%]\nsklearn/feature_extraction/tests/test_text.py::test_vectorizers_invalid_ngram_range[vec1] PASSED [ 97%]\nsklearn/feature_extraction/tests/test_text.py::test_vectorizers_invalid_ngram_range[vec2] PASSED [100%]\n\n=================================== FAILURES ===================================\n______________________________ test_feature_names ______________________________\nsklearn/feature_extraction/tests/test_text.py:547: in test_feature_names\n    assert_false(cv.fixed_vocabulary_)\nE   AttributeError: 'CountVectorizer' object has no attribute 'fixed_vocabulary_'\n=================== 1 failed, 47 passed, 4 warnings in 1.41s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sklearn/feature_extraction/tests/test_text.py` failed. (See above for error)",
          "test_files_run": [
            "sklearn/feature_extraction/tests/test_text.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 48,
          "failed": 0,
          "errors": 0,
          "collected": 48,
          "duration": 4.41,
          "log_tail": "sklearn/feature_extraction/tests/test_text.py::test_word_analyzer_unigrams PASSED [  6%]\nsklearn/feature_extraction/tests/test_text.py::test_word_analyzer_unigrams_and_bigrams PASSED [  8%]\nsklearn/feature_extraction/tests/test_text.py::test_unicode_decode_error PASSED [ 10%]\nsklearn/feature_extraction/tests/test_text.py::test_char_ngram_analyzer PASSED [ 12%]\nsklearn/feature_extraction/tests/test_text.py::test_char_wb_ngram_analyzer PASSED [ 14%]\nsklearn/feature_extraction/tests/test_text.py::test_word_ngram_analyzer PASSED [ 16%]\nsklearn/feature_extraction/tests/test_text.py::test_countvectorizer_custom_vocabulary PASSED [ 18%]\nsklearn/feature_extraction/tests/test_text.py::test_countvectorizer_custom_vocabulary_pipeline PASSED [ 20%]\nsklearn/feature_extraction/tests/test_text.py::test_countvectorizer_custom_vocabulary_repeated_indices PASSED [ 22%]\nsklearn/feature_extraction/tests/test_text.py::test_countvectorizer_custom_vocabulary_gap_index PASSED [ 25%]\nsklearn/feature_extraction/tests/test_text.py::test_countvectorizer_stop_words PASSED [ 27%]\nsklearn/feature_extraction/tests/test_text.py::test_countvectorizer_empty_vocabulary PASSED [ 29%]\nsklearn/feature_extraction/tests/test_text.py::test_fit_countvectorizer_twice PASSED [ 31%]\nsklearn/feature_extraction/tests/test_text.py::test_tf_idf_smoothing PASSED [ 33%]\nsklearn/feature_extraction/tests/test_text.py::test_tfidf_no_smoothing PASSED [ 35%]\nsklearn/feature_extraction/tests/test_text.py::test_sublinear_tf PASSED  [ 37%]\nsklearn/feature_extraction/tests/test_text.py::test_vectorizer PASSED    [ 39%]\nsklearn/feature_extraction/tests/test_text.py::test_tfidf_vectorizer_setters PASSED [ 41%]\nsklearn/feature_extraction/tests/test_text.py::test_hashing_vectorizer PASSED [ 43%]\nsklearn/feature_extraction/tests/test_text.py::test_feature_names PASSED [ 45%]\nsklearn/feature_extraction/tests/test_text.py::test_vectorizer_max_features PASSED [ 47%]\nsklearn/feature_extraction/tests/test_text.py::test_count_vectorizer_max_features PASSED [ 50%]\nsklearn/feature_extraction/tests/test_text.py::test_vectorizer_max_df PASSED [ 52%]\nsklearn/feature_extraction/tests/test_text.py::test_vectorizer_min_df PASSED [ 54%]\nsklearn/feature_extraction/tests/test_text.py::test_count_binary_occurrences PASSED [ 56%]\nsklearn/feature_extraction/tests/test_text.py::test_hashed_binary_occurrences PASSED [ 58%]\nsklearn/feature_extraction/tests/test_text.py::test_vectorizer_inverse_transform PASSED [ 60%]\nsklearn/feature_extraction/tests/test_text.py::test_count_vectorizer_pipeline_grid_selection PASSED [ 62%]\nsklearn/feature_extraction/tests/test_text.py::test_vectorizer_pipeline_grid_selection PASSED [ 64%]\nsklearn/feature_extraction/tests/test_text.py::test_vectorizer_pipeline_cross_validation PASSED [ 66%]\nsklearn/feature_extraction/tests/test_text.py::test_vectorizer_unicode PASSED [ 68%]\nsklearn/feature_extraction/tests/test_text.py::test_tfidf_vectorizer_with_fixed_vocabulary PASSED [ 70%]\nsklearn/feature_extraction/tests/test_text.py::test_pickling_vectorizer PASSED [ 72%]\nsklearn/feature_extraction/tests/test_text.py::test_countvectorizer_vocab_sets_when_pickling PASSED [ 75%]\nsklearn/feature_extraction/tests/test_text.py::test_countvectorizer_vocab_dicts_when_pickling PASSED [ 77%]\nsklearn/feature_extraction/tests/test_text.py::test_stop_words_removal PASSED [ 79%]\nsklearn/feature_extraction/tests/test_text.py::test_pickling_transformer PASSED [ 81%]\nsklearn/feature_extraction/tests/test_text.py::test_non_unique_vocab PASSED [ 83%]\nsklearn/feature_extraction/tests/test_text.py::test_hashingvectorizer_nan_in_docs PASSED [ 85%]\nsklearn/feature_extraction/tests/test_text.py::test_tfidfvectorizer_binary PASSED [ 87%]\nsklearn/feature_extraction/tests/test_text.py::test_tfidfvectorizer_export_idf PASSED [ 89%]\nsklearn/feature_extraction/tests/test_text.py::test_vectorizer_vocab_clone PASSED [ 91%]\nsklearn/feature_extraction/tests/test_text.py::test_vectorizer_string_object_as_input PASSED [ 93%]\nsklearn/feature_extraction/tests/test_text.py::test_vectorizers_invalid_ngram_range[vec0] PASSED [ 95%]\nsklearn/feature_extraction/tests/test_text.py::test_vectorizers_invalid_ngram_range[vec1] PASSED [ 97%]\nsklearn/feature_extraction/tests/test_text.py::test_vectorizers_invalid_ngram_range[vec2] PASSED [100%]\n\n======================== 48 passed, 4 warnings in 1.89s ========================\n\n",
          "test_files_run": [
            "sklearn/feature_extraction/tests/test_text.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "scikit-learn__scikit-learn-12585",
      "repo": "scikit-learn/scikit-learn",
      "valid": true,
      "worker": "http://34.70.1.155:8080",
      "duration": 7.3023810386657715,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 22,
          "failed": 1,
          "errors": 0,
          "collected": 23,
          "duration": 3.11,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 23 items\n\nsklearn/tests/test_base.py::test_clone PASSED                            [  4%]\nsklearn/tests/test_base.py::test_clone_2 PASSED                          [  8%]\nsklearn/tests/test_base.py::test_clone_buggy PASSED                      [ 13%]\nsklearn/tests/test_base.py::test_clone_empty_array PASSED                [ 17%]\nsklearn/tests/test_base.py::test_clone_nan PASSED                        [ 21%]\nsklearn/tests/test_base.py::test_clone_sparse_matrices PASSED            [ 26%]\nsklearn/tests/test_base.py::test_clone_estimator_types FAILED            [ 30%]\nsklearn/tests/test_base.py::test_repr PASSED                             [ 34%]\nsklearn/tests/test_base.py::test_str PASSED                              [ 39%]\nsklearn/tests/test_base.py::test_get_params PASSED                       [ 43%]\nsklearn/tests/test_base.py::test_is_classifier PASSED                    [ 47%]\nsklearn/tests/test_base.py::test_set_params PASSED                       [ 52%]\nsklearn/tests/test_base.py::test_set_params_passes_all_parameters PASSED [ 56%]\nsklearn/tests/test_base.py::test_set_params_updates_valid_params PASSED  [ 60%]\nsklearn/tests/test_base.py::test_score_sample_weight PASSED              [ 65%]\nsklearn/tests/test_base.py::test_clone_pandas_dataframe PASSED           [ 69%]\nsklearn/tests/test_base.py::test_pickle_version_warning_is_not_raised_with_matching_version PASSED [ 73%]\nsklearn/tests/test_base.py::test_pickle_version_warning_is_issued_upon_different_version PASSED [ 78%]\nsklearn/tests/test_base.py::test_pickle_version_warning_is_issued_when_no_version_info_in_pickle PASSED [ 82%]\nsklearn/tests/test_base.py::test_pickle_version_no_warning_is_issued_with_non_sklearn_estimator PASSED [ 86%]\nsklearn/tests/test_base.py::test_pickling_when_getstate_is_overwritten_by_mixin PASSED [ 91%]\nsklearn/tests/test_base.py::test_pickling_when_getstate_is_overwritten_by_mixin_outside_of_sklearn PASSED [ 95%]\nsklearn/tests/test_base.py::test_pickling_works_when_getstate_is_overwritten_in_the_child_class PASSED [100%]\n\n=================================== FAILURES ===================================\n__________________________ test_clone_estimator_types __________________________\nsklearn/tests/test_base.py:174: in test_clone_estimator_types\n    clf2 = clone(clf)\nsklearn/base.py:62: in clone\n    new_object_params[name] = clone(param, safe=False)\nsklearn/base.py:60: in clone\n    new_object_params = estimator.get_params(deep=False)\nE   TypeError: get_params() missing 1 required positional argument: 'self'\n=================== 1 failed, 22 passed, 1 warning in 0.50s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sklearn/tests/test_base.py` failed. (See above for error)",
          "test_files_run": [
            "sklearn/tests/test_base.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 23,
          "failed": 0,
          "errors": 0,
          "collected": 23,
          "duration": 3.29,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 23 items\n\nsklearn/tests/test_base.py::test_clone PASSED                            [  4%]\nsklearn/tests/test_base.py::test_clone_2 PASSED                          [  8%]\nsklearn/tests/test_base.py::test_clone_buggy PASSED                      [ 13%]\nsklearn/tests/test_base.py::test_clone_empty_array PASSED                [ 17%]\nsklearn/tests/test_base.py::test_clone_nan PASSED                        [ 21%]\nsklearn/tests/test_base.py::test_clone_sparse_matrices PASSED            [ 26%]\nsklearn/tests/test_base.py::test_clone_estimator_types PASSED            [ 30%]\nsklearn/tests/test_base.py::test_repr PASSED                             [ 34%]\nsklearn/tests/test_base.py::test_str PASSED                              [ 39%]\nsklearn/tests/test_base.py::test_get_params PASSED                       [ 43%]\nsklearn/tests/test_base.py::test_is_classifier PASSED                    [ 47%]\nsklearn/tests/test_base.py::test_set_params PASSED                       [ 52%]\nsklearn/tests/test_base.py::test_set_params_passes_all_parameters PASSED [ 56%]\nsklearn/tests/test_base.py::test_set_params_updates_valid_params PASSED  [ 60%]\nsklearn/tests/test_base.py::test_score_sample_weight PASSED              [ 65%]\nsklearn/tests/test_base.py::test_clone_pandas_dataframe PASSED           [ 69%]\nsklearn/tests/test_base.py::test_pickle_version_warning_is_not_raised_with_matching_version PASSED [ 73%]\nsklearn/tests/test_base.py::test_pickle_version_warning_is_issued_upon_different_version PASSED [ 78%]\nsklearn/tests/test_base.py::test_pickle_version_warning_is_issued_when_no_version_info_in_pickle PASSED [ 82%]\nsklearn/tests/test_base.py::test_pickle_version_no_warning_is_issued_with_non_sklearn_estimator PASSED [ 86%]\nsklearn/tests/test_base.py::test_pickling_when_getstate_is_overwritten_by_mixin PASSED [ 91%]\nsklearn/tests/test_base.py::test_pickling_when_getstate_is_overwritten_by_mixin_outside_of_sklearn PASSED [ 95%]\nsklearn/tests/test_base.py::test_pickling_works_when_getstate_is_overwritten_in_the_child_class PASSED [100%]\n\n======================== 23 passed, 1 warning in 0.51s =========================\n\n",
          "test_files_run": [
            "sklearn/tests/test_base.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "scikit-learn__scikit-learn-11310",
      "repo": "scikit-learn/scikit-learn",
      "valid": false,
      "worker": "http://34.44.241.183:8080",
      "duration": 15.21057391166687,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 50,
          "failed": 4,
          "errors": 0,
          "collected": 54,
          "duration": 7.03,
          "log_tail": "sklearn/model_selection/tests/test_search.py::test_param_sampler PASSED  [ 59%]\nsklearn/model_selection/tests/test_search.py::test_grid_search_cv_results PASSED [ 61%]\nsklearn/model_selection/tests/test_search.py::test_random_search_cv_results PASSED [ 62%]\nsklearn/model_selection/tests/test_search.py::test_search_iid_param PASSED [ 64%]\nsklearn/model_selection/tests/test_search.py::test_grid_search_cv_results_multimetric PASSED [ 66%]\nsklearn/model_selection/tests/test_search.py::test_random_search_cv_results_multimetric PASSED [ 68%]\nsklearn/model_selection/tests/test_search.py::test_search_cv_results_rank_tie_breaking PASSED [ 70%]\nsklearn/model_selection/tests/test_search.py::test_search_cv_results_none_param PASSED [ 72%]\nsklearn/model_selection/tests/test_search.py::test_search_cv_timing FAILED [ 74%]\nsklearn/model_selection/tests/test_search.py::test_grid_search_correct_score_results PASSED [ 75%]\nsklearn/model_selection/tests/test_search.py::test_fit_grid_point PASSED [ 77%]\nsklearn/model_selection/tests/test_search.py::test_pickle PASSED         [ 79%]\nsklearn/model_selection/tests/test_search.py::test_grid_search_with_multioutput_data PASSED [ 81%]\nsklearn/model_selection/tests/test_search.py::test_predict_proba_disabled PASSED [ 83%]\nsklearn/model_selection/tests/test_search.py::test_grid_search_allows_nans PASSED [ 85%]\nsklearn/model_selection/tests/test_search.py::test_grid_search_failing_classifier PASSED [ 87%]\nsklearn/model_selection/tests/test_search.py::test_grid_search_failing_classifier_raise PASSED [ 88%]\nsklearn/model_selection/tests/test_search.py::test_parameters_sampler_replacement PASSED [ 90%]\nsklearn/model_selection/tests/test_search.py::test_stochastic_gradient_loss_param PASSED [ 92%]\nsklearn/model_selection/tests/test_search.py::test_search_train_scores_set_to_false PASSED [ 94%]\nsklearn/model_selection/tests/test_search.py::test_grid_search_cv_splits_consistency PASSED [ 96%]\nsklearn/model_selection/tests/test_search.py::test_transform_inverse_transform_round_trip PASSED [ 98%]\nsklearn/model_selection/tests/test_search.py::test_deprecated_grid_search_iid PASSED [100%]\n\n=================================== FAILURES ===================================\n_ test_validate_parameter_grid_input[0-TypeError-Parameter grid is not a dict or a list (0)] _\nsklearn/model_selection/tests/test_search.py:139: in test_validate_parameter_grid_input\n    with pytest.raises(error_type, message=error_message):\nE   TypeError: Unexpected keyword arguments passed to pytest.raises: message\nE   Use context-manager form instead?\n_ test_validate_parameter_grid_input[input1-TypeError-Parameter grid is not a dict (0)] _\nsklearn/model_selection/tests/test_search.py:139: in test_validate_parameter_grid_input\n    with pytest.raises(error_type, message=error_message):\nE   TypeError: Unexpected keyword arguments passed to pytest.raises: message\nE   Use context-manager form instead?\n_ test_validate_parameter_grid_input[input2-TypeError-Parameter grid value is not iterable (key='foo', value=0)] _\nsklearn/model_selection/tests/test_search.py:139: in test_validate_parameter_grid_input\n    with pytest.raises(error_type, message=error_message):\nE   TypeError: Unexpected keyword arguments passed to pytest.raises: message\nE   Use context-manager form instead?\n____________________________ test_search_cv_timing _____________________________\nsklearn/model_selection/tests/test_search.py:1176: in test_search_cv_timing\n    assert_true(hasattr(search, \"refit_time_\"))\n/opt/miniconda3/envs/testbed/lib/python3.6/unittest/case.py:682: in assertTrue\n    raise self.failureException(msg)\nE   AssertionError: False is not true\n================== 4 failed, 50 passed, 158 warnings in 4.83s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sklearn/model_selection/tests/test_search.py` failed. (See above for error)",
          "test_files_run": [
            "sklearn/model_selection/tests/test_search.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 51,
          "failed": 3,
          "errors": 0,
          "collected": 54,
          "duration": 7.34,
          "log_tail": "sklearn/model_selection/tests/test_search.py::test_gridsearch_nd PASSED  [ 48%]\nsklearn/model_selection/tests/test_search.py::test_X_as_list PASSED      [ 50%]\nsklearn/model_selection/tests/test_search.py::test_y_as_list PASSED      [ 51%]\nsklearn/model_selection/tests/test_search.py::test_pandas_input PASSED   [ 53%]\nsklearn/model_selection/tests/test_search.py::test_unsupervised_grid_search PASSED [ 55%]\nsklearn/model_selection/tests/test_search.py::test_gridsearch_no_predict PASSED [ 57%]\nsklearn/model_selection/tests/test_search.py::test_param_sampler PASSED  [ 59%]\nsklearn/model_selection/tests/test_search.py::test_grid_search_cv_results PASSED [ 61%]\nsklearn/model_selection/tests/test_search.py::test_random_search_cv_results PASSED [ 62%]\nsklearn/model_selection/tests/test_search.py::test_search_iid_param PASSED [ 64%]\nsklearn/model_selection/tests/test_search.py::test_grid_search_cv_results_multimetric PASSED [ 66%]\nsklearn/model_selection/tests/test_search.py::test_random_search_cv_results_multimetric PASSED [ 68%]\nsklearn/model_selection/tests/test_search.py::test_search_cv_results_rank_tie_breaking PASSED [ 70%]\nsklearn/model_selection/tests/test_search.py::test_search_cv_results_none_param PASSED [ 72%]\nsklearn/model_selection/tests/test_search.py::test_search_cv_timing PASSED [ 74%]\nsklearn/model_selection/tests/test_search.py::test_grid_search_correct_score_results PASSED [ 75%]\nsklearn/model_selection/tests/test_search.py::test_fit_grid_point PASSED [ 77%]\nsklearn/model_selection/tests/test_search.py::test_pickle PASSED         [ 79%]\nsklearn/model_selection/tests/test_search.py::test_grid_search_with_multioutput_data PASSED [ 81%]\nsklearn/model_selection/tests/test_search.py::test_predict_proba_disabled PASSED [ 83%]\nsklearn/model_selection/tests/test_search.py::test_grid_search_allows_nans PASSED [ 85%]\nsklearn/model_selection/tests/test_search.py::test_grid_search_failing_classifier PASSED [ 87%]\nsklearn/model_selection/tests/test_search.py::test_grid_search_failing_classifier_raise PASSED [ 88%]\nsklearn/model_selection/tests/test_search.py::test_parameters_sampler_replacement PASSED [ 90%]\nsklearn/model_selection/tests/test_search.py::test_stochastic_gradient_loss_param PASSED [ 92%]\nsklearn/model_selection/tests/test_search.py::test_search_train_scores_set_to_false PASSED [ 94%]\nsklearn/model_selection/tests/test_search.py::test_grid_search_cv_splits_consistency PASSED [ 96%]\nsklearn/model_selection/tests/test_search.py::test_transform_inverse_transform_round_trip PASSED [ 98%]\nsklearn/model_selection/tests/test_search.py::test_deprecated_grid_search_iid PASSED [100%]\n\n=================================== FAILURES ===================================\n_ test_validate_parameter_grid_input[0-TypeError-Parameter grid is not a dict or a list (0)] _\nsklearn/model_selection/tests/test_search.py:139: in test_validate_parameter_grid_input\n    with pytest.raises(error_type, message=error_message):\nE   TypeError: Unexpected keyword arguments passed to pytest.raises: message\nE   Use context-manager form instead?\n_ test_validate_parameter_grid_input[input1-TypeError-Parameter grid is not a dict (0)] _\nsklearn/model_selection/tests/test_search.py:139: in test_validate_parameter_grid_input\n    with pytest.raises(error_type, message=error_message):\nE   TypeError: Unexpected keyword arguments passed to pytest.raises: message\nE   Use context-manager form instead?\n_ test_validate_parameter_grid_input[input2-TypeError-Parameter grid value is not iterable (key='foo', value=0)] _\nsklearn/model_selection/tests/test_search.py:139: in test_validate_parameter_grid_input\n    with pytest.raises(error_type, message=error_message):\nE   TypeError: Unexpected keyword arguments passed to pytest.raises: message\nE   Use context-manager form instead?\n================== 3 failed, 51 passed, 158 warnings in 4.97s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sklearn/model_selection/tests/test_search.py` failed. (See above for error)",
          "test_files_run": [
            "sklearn/model_selection/tests/test_search.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "matplotlib__matplotlib-26113",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10cf2eba0>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 1
    },
    {
      "instance_id": "scikit-learn__scikit-learn-11578",
      "repo": "scikit-learn/scikit-learn",
      "valid": true,
      "worker": "http://34.41.233.120:8080",
      "duration": 20.67258596420288,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 93,
          "failed": 1,
          "errors": 0,
          "collected": 94,
          "duration": 9.7,
          "log_tail": "sklearn/linear_model/tests/test_logistic.py::test_warm_start[ovr-True-True-saga] PASSED [ 65%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[ovr-True-True-lbfgs] PASSED [ 67%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[ovr-True-False-newton-cg] PASSED [ 68%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[ovr-True-False-sag] PASSED [ 69%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[ovr-True-False-saga] PASSED [ 70%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[ovr-True-False-lbfgs] PASSED [ 71%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[ovr-False-True-newton-cg] PASSED [ 72%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[ovr-False-True-sag] PASSED [ 73%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[ovr-False-True-saga] PASSED [ 74%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[ovr-False-True-lbfgs] PASSED [ 75%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[ovr-False-False-newton-cg] PASSED [ 76%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[ovr-False-False-sag] PASSED [ 77%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[ovr-False-False-saga] PASSED [ 78%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[ovr-False-False-lbfgs] PASSED [ 79%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[multinomial-True-True-newton-cg] PASSED [ 80%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[multinomial-True-True-sag] PASSED [ 81%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[multinomial-True-True-saga] PASSED [ 82%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[multinomial-True-True-lbfgs] PASSED [ 84%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[multinomial-True-False-newton-cg] PASSED [ 85%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[multinomial-True-False-sag] PASSED [ 86%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[multinomial-True-False-saga] PASSED [ 87%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[multinomial-True-False-lbfgs] PASSED [ 88%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[multinomial-False-True-newton-cg] PASSED [ 89%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[multinomial-False-True-sag] PASSED [ 90%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[multinomial-False-True-saga] PASSED [ 91%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[multinomial-False-True-lbfgs] PASSED [ 92%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[multinomial-False-False-newton-cg] PASSED [ 93%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[multinomial-False-False-sag] PASSED [ 94%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[multinomial-False-False-saga] PASSED [ 95%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[multinomial-False-False-lbfgs] PASSED [ 96%]\nsklearn/linear_model/tests/test_logistic.py::test_saga_vs_liblinear PASSED [ 97%]\nsklearn/linear_model/tests/test_logistic.py::test_dtype_match PASSED     [ 98%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start_converge_LR PASSED [100%]\n\n=================================== FAILURES ===================================\n____ test_logistic_cv_multinomial_score[neg_log_loss-multiclass_agg_list3] _____\nsklearn/linear_model/tests/test_logistic.py:526: in test_logistic_cv_multinomial_score\n    scorer(lr, X[test], y[test]))\nE   AssertionError: \nE   Arrays are not almost equal to 6 decimals\nE   \nE   Mismatched elements: 1 / 1 (100%)\nE   Max absolute difference: 0.04312538\nE   Max relative difference: 0.05731496\nE    x: array(-0.795553)\nE    y: array(-0.752428)\n================== 1 failed, 93 passed, 25 warnings in 6.83s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sklearn/linear_model/tests/test_logistic.py` failed. (See above for error)",
          "test_files_run": [
            "sklearn/linear_model/tests/test_logistic.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 94,
          "failed": 0,
          "errors": 0,
          "collected": 94,
          "duration": 10.05,
          "log_tail": "sklearn/linear_model/tests/test_logistic.py::test_logreg_intercept_scaling_zero PASSED [ 52%]\nsklearn/linear_model/tests/test_logistic.py::test_logreg_l1 PASSED       [ 53%]\nsklearn/linear_model/tests/test_logistic.py::test_logreg_l1_sparse_data PASSED [ 54%]\nsklearn/linear_model/tests/test_logistic.py::test_logreg_cv_penalty PASSED [ 55%]\nsklearn/linear_model/tests/test_logistic.py::test_logreg_predict_proba_multinomial PASSED [ 56%]\nsklearn/linear_model/tests/test_logistic.py::test_max_iter PASSED        [ 57%]\nsklearn/linear_model/tests/test_logistic.py::test_n_iter[newton-cg] PASSED [ 58%]\nsklearn/linear_model/tests/test_logistic.py::test_n_iter[liblinear] PASSED [ 59%]\nsklearn/linear_model/tests/test_logistic.py::test_n_iter[sag] PASSED     [ 60%]\nsklearn/linear_model/tests/test_logistic.py::test_n_iter[saga] PASSED    [ 61%]\nsklearn/linear_model/tests/test_logistic.py::test_n_iter[lbfgs] PASSED   [ 62%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[ovr-True-True-newton-cg] PASSED [ 63%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[ovr-True-True-sag] PASSED [ 64%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[ovr-True-True-saga] PASSED [ 65%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[ovr-True-True-lbfgs] PASSED [ 67%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[ovr-True-False-newton-cg] PASSED [ 68%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[ovr-True-False-sag] PASSED [ 69%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[ovr-True-False-saga] PASSED [ 70%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[ovr-True-False-lbfgs] PASSED [ 71%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[ovr-False-True-newton-cg] PASSED [ 72%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[ovr-False-True-sag] PASSED [ 73%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[ovr-False-True-saga] PASSED [ 74%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[ovr-False-True-lbfgs] PASSED [ 75%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[ovr-False-False-newton-cg] PASSED [ 76%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[ovr-False-False-sag] PASSED [ 77%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[ovr-False-False-saga] PASSED [ 78%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[ovr-False-False-lbfgs] PASSED [ 79%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[multinomial-True-True-newton-cg] PASSED [ 80%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[multinomial-True-True-sag] PASSED [ 81%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[multinomial-True-True-saga] PASSED [ 82%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[multinomial-True-True-lbfgs] PASSED [ 84%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[multinomial-True-False-newton-cg] PASSED [ 85%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[multinomial-True-False-sag] PASSED [ 86%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[multinomial-True-False-saga] PASSED [ 87%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[multinomial-True-False-lbfgs] PASSED [ 88%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[multinomial-False-True-newton-cg] PASSED [ 89%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[multinomial-False-True-sag] PASSED [ 90%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[multinomial-False-True-saga] PASSED [ 91%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[multinomial-False-True-lbfgs] PASSED [ 92%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[multinomial-False-False-newton-cg] PASSED [ 93%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[multinomial-False-False-sag] PASSED [ 94%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[multinomial-False-False-saga] PASSED [ 95%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start[multinomial-False-False-lbfgs] PASSED [ 96%]\nsklearn/linear_model/tests/test_logistic.py::test_saga_vs_liblinear PASSED [ 97%]\nsklearn/linear_model/tests/test_logistic.py::test_dtype_match PASSED     [ 98%]\nsklearn/linear_model/tests/test_logistic.py::test_warm_start_converge_LR PASSED [100%]\n\n======================= 94 passed, 25 warnings in 7.24s ========================\n\n",
          "test_files_run": [
            "sklearn/linear_model/tests/test_logistic.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "scikit-learn__scikit-learn-12973",
      "repo": "scikit-learn/scikit-learn",
      "valid": true,
      "worker": "http://34.59.30.169:8080",
      "duration": 15.02390718460083,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 33,
          "failed": 1,
          "errors": 0,
          "collected": 34,
          "duration": 6.52,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 34 items\n\nsklearn/linear_model/tests/test_least_angle.py::test_simple PASSED       [  2%]\nsklearn/linear_model/tests/test_least_angle.py::test_simple_precomputed PASSED [  5%]\nsklearn/linear_model/tests/test_least_angle.py::test_all_precomputed PASSED [  8%]\nsklearn/linear_model/tests/test_least_angle.py::test_lars_lstsq PASSED   [ 11%]\nsklearn/linear_model/tests/test_least_angle.py::test_lasso_gives_lstsq_solution PASSED [ 14%]\nsklearn/linear_model/tests/test_least_angle.py::test_collinearity PASSED [ 17%]\nsklearn/linear_model/tests/test_least_angle.py::test_no_path PASSED      [ 20%]\nsklearn/linear_model/tests/test_least_angle.py::test_no_path_precomputed PASSED [ 23%]\nsklearn/linear_model/tests/test_least_angle.py::test_no_path_all_precomputed PASSED [ 26%]\nsklearn/linear_model/tests/test_least_angle.py::test_lars_precompute[Lars] PASSED [ 29%]\nsklearn/linear_model/tests/test_least_angle.py::test_lars_precompute[LarsCV] PASSED [ 32%]\nsklearn/linear_model/tests/test_least_angle.py::test_lars_precompute[LassoLarsIC] PASSED [ 35%]\nsklearn/linear_model/tests/test_least_angle.py::test_singular_matrix PASSED [ 38%]\nsklearn/linear_model/tests/test_least_angle.py::test_rank_deficient_design PASSED [ 41%]\nsklearn/linear_model/tests/test_least_angle.py::test_lasso_lars_vs_lasso_cd PASSED [ 44%]\nsklearn/linear_model/tests/test_least_angle.py::test_lasso_lars_vs_lasso_cd_early_stopping PASSED [ 47%]\nsklearn/linear_model/tests/test_least_angle.py::test_lasso_lars_path_length PASSED [ 50%]\nsklearn/linear_model/tests/test_least_angle.py::test_lasso_lars_vs_lasso_cd_ill_conditioned PASSED [ 52%]\nsklearn/linear_model/tests/test_least_angle.py::test_lasso_lars_vs_lasso_cd_ill_conditioned2 PASSED [ 55%]\nsklearn/linear_model/tests/test_least_angle.py::test_lars_add_features PASSED [ 58%]\nsklearn/linear_model/tests/test_least_angle.py::test_lars_n_nonzero_coefs PASSED [ 61%]\nsklearn/linear_model/tests/test_least_angle.py::test_multitarget PASSED  [ 64%]\nsklearn/linear_model/tests/test_least_angle.py::test_lars_cv PASSED      [ 67%]\nsklearn/linear_model/tests/test_least_angle.py::test_lars_cv_max_iter PASSED [ 70%]\nsklearn/linear_model/tests/test_least_angle.py::test_lasso_lars_ic PASSED [ 73%]\nsklearn/linear_model/tests/test_least_angle.py::test_lars_path_readonly_data PASSED [ 76%]\nsklearn/linear_model/tests/test_least_angle.py::test_lars_path_positive_constraint PASSED [ 79%]\nsklearn/linear_model/tests/test_least_angle.py::test_estimatorclasses_positive_constraint PASSED [ 82%]\nsklearn/linear_model/tests/test_least_angle.py::test_lasso_lars_vs_lasso_cd_positive PASSED [ 85%]\nsklearn/linear_model/tests/test_least_angle.py::test_lasso_lars_vs_R_implementation PASSED [ 88%]\nsklearn/linear_model/tests/test_least_angle.py::test_lasso_lars_copyX_behaviour[True] PASSED [ 91%]\nsklearn/linear_model/tests/test_least_angle.py::test_lasso_lars_copyX_behaviour[False] PASSED [ 94%]\nsklearn/linear_model/tests/test_least_angle.py::test_lasso_lars_fit_copyX_behaviour[True] PASSED [ 97%]\nsklearn/linear_model/tests/test_least_angle.py::test_lasso_lars_fit_copyX_behaviour[False] FAILED [100%]\n\n=================================== FAILURES ===================================\n__________________ test_lasso_lars_fit_copyX_behaviour[False] __________________\nsklearn/linear_model/tests/test_least_angle.py:719: in test_lasso_lars_fit_copyX_behaviour\n    assert copy_X == np.array_equal(X, X_copy)\nE   assert False == True\nE     +False\nE     -True\n=================== 1 failed, 33 passed, 4 warnings in 2.24s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sklearn/linear_model/tests/test_least_angle.py` failed. (See above for error)",
          "test_files_run": [
            "sklearn/linear_model/tests/test_least_angle.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 34,
          "failed": 0,
          "errors": 0,
          "collected": 34,
          "duration": 6.72,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 34 items\n\nsklearn/linear_model/tests/test_least_angle.py::test_simple PASSED       [  2%]\nsklearn/linear_model/tests/test_least_angle.py::test_simple_precomputed PASSED [  5%]\nsklearn/linear_model/tests/test_least_angle.py::test_all_precomputed PASSED [  8%]\nsklearn/linear_model/tests/test_least_angle.py::test_lars_lstsq PASSED   [ 11%]\nsklearn/linear_model/tests/test_least_angle.py::test_lasso_gives_lstsq_solution PASSED [ 14%]\nsklearn/linear_model/tests/test_least_angle.py::test_collinearity PASSED [ 17%]\nsklearn/linear_model/tests/test_least_angle.py::test_no_path PASSED      [ 20%]\nsklearn/linear_model/tests/test_least_angle.py::test_no_path_precomputed PASSED [ 23%]\nsklearn/linear_model/tests/test_least_angle.py::test_no_path_all_precomputed PASSED [ 26%]\nsklearn/linear_model/tests/test_least_angle.py::test_lars_precompute[Lars] PASSED [ 29%]\nsklearn/linear_model/tests/test_least_angle.py::test_lars_precompute[LarsCV] PASSED [ 32%]\nsklearn/linear_model/tests/test_least_angle.py::test_lars_precompute[LassoLarsIC] PASSED [ 35%]\nsklearn/linear_model/tests/test_least_angle.py::test_singular_matrix PASSED [ 38%]\nsklearn/linear_model/tests/test_least_angle.py::test_rank_deficient_design PASSED [ 41%]\nsklearn/linear_model/tests/test_least_angle.py::test_lasso_lars_vs_lasso_cd PASSED [ 44%]\nsklearn/linear_model/tests/test_least_angle.py::test_lasso_lars_vs_lasso_cd_early_stopping PASSED [ 47%]\nsklearn/linear_model/tests/test_least_angle.py::test_lasso_lars_path_length PASSED [ 50%]\nsklearn/linear_model/tests/test_least_angle.py::test_lasso_lars_vs_lasso_cd_ill_conditioned PASSED [ 52%]\nsklearn/linear_model/tests/test_least_angle.py::test_lasso_lars_vs_lasso_cd_ill_conditioned2 PASSED [ 55%]\nsklearn/linear_model/tests/test_least_angle.py::test_lars_add_features PASSED [ 58%]\nsklearn/linear_model/tests/test_least_angle.py::test_lars_n_nonzero_coefs PASSED [ 61%]\nsklearn/linear_model/tests/test_least_angle.py::test_multitarget PASSED  [ 64%]\nsklearn/linear_model/tests/test_least_angle.py::test_lars_cv PASSED      [ 67%]\nsklearn/linear_model/tests/test_least_angle.py::test_lars_cv_max_iter PASSED [ 70%]\nsklearn/linear_model/tests/test_least_angle.py::test_lasso_lars_ic PASSED [ 73%]\nsklearn/linear_model/tests/test_least_angle.py::test_lars_path_readonly_data PASSED [ 76%]\nsklearn/linear_model/tests/test_least_angle.py::test_lars_path_positive_constraint PASSED [ 79%]\nsklearn/linear_model/tests/test_least_angle.py::test_estimatorclasses_positive_constraint PASSED [ 82%]\nsklearn/linear_model/tests/test_least_angle.py::test_lasso_lars_vs_lasso_cd_positive PASSED [ 85%]\nsklearn/linear_model/tests/test_least_angle.py::test_lasso_lars_vs_R_implementation PASSED [ 88%]\nsklearn/linear_model/tests/test_least_angle.py::test_lasso_lars_copyX_behaviour[True] PASSED [ 91%]\nsklearn/linear_model/tests/test_least_angle.py::test_lasso_lars_copyX_behaviour[False] PASSED [ 94%]\nsklearn/linear_model/tests/test_least_angle.py::test_lasso_lars_fit_copyX_behaviour[True] PASSED [ 97%]\nsklearn/linear_model/tests/test_least_angle.py::test_lasso_lars_fit_copyX_behaviour[False] PASSED [100%]\n\n======================== 34 passed, 4 warnings in 2.20s ========================\n\n",
          "test_files_run": [
            "sklearn/linear_model/tests/test_least_angle.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "scikit-learn__scikit-learn-13124",
      "repo": "scikit-learn/scikit-learn",
      "valid": false,
      "worker": "http://34.70.1.155:8080",
      "duration": 15.049715280532837,
      "test_only": {
        "passed": true,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "collected": 61,
          "duration": 8.54,
          "log_tail": "sklearn/model_selection/tests/test_split.py::test_predefinedsplit_with_kfold_split PASSED [ 36%]\nsklearn/model_selection/tests/test_split.py::test_group_shuffle_split PASSED [ 37%]\nsklearn/model_selection/tests/test_split.py::test_leave_one_p_group_out PASSED [ 39%]\nsklearn/model_selection/tests/test_split.py::test_leave_group_out_changing_groups PASSED [ 40%]\nsklearn/model_selection/tests/test_split.py::test_leave_one_p_group_out_error_on_fewer_number_of_groups PASSED [ 42%]\nsklearn/model_selection/tests/test_split.py::test_repeated_cv_value_errors PASSED [ 44%]\nsklearn/model_selection/tests/test_split.py::test_repeated_kfold_determinstic_split PASSED [ 45%]\nsklearn/model_selection/tests/test_split.py::test_get_n_splits_for_repeated_kfold PASSED [ 47%]\nsklearn/model_selection/tests/test_split.py::test_get_n_splits_for_repeated_stratified_kfold PASSED [ 49%]\nsklearn/model_selection/tests/test_split.py::test_repeated_stratified_kfold_determinstic_split PASSED [ 50%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_errors PASSED [ 52%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes1[1.2-0.8] PASSED [ 54%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes1[1.0-0.8] PASSED [ 55%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes1[0.0-0.8] PASSED [ 57%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes1[-0.2-0.8] PASSED [ 59%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes1[0.8-1.2] PASSED [ 60%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes1[0.8-1.0] PASSED [ 62%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes1[0.8-0.0] PASSED [ 63%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes1[0.8--0.2] PASSED [ 65%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes2[-10-0.8] PASSED [ 67%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes2[0-0.8] PASSED [ 68%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes2[11-0.8] PASSED [ 70%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes2[0.8--10] PASSED [ 72%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes2[0.8-0] PASSED [ 73%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes2[0.8-11] PASSED [ 75%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split PASSED [ 77%]\nsklearn/model_selection/tests/test_split.py::test_shufflesplit_errors PASSED [ 78%]\nsklearn/model_selection/tests/test_split.py::test_shufflesplit_reproducible PASSED [ 80%]\nsklearn/model_selection/tests/test_split.py::test_stratifiedshufflesplit_list_input PASSED [ 81%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_allow_nans PASSED [ 83%]\nsklearn/model_selection/tests/test_split.py::test_check_cv PASSED        [ 85%]\nsklearn/model_selection/tests/test_split.py::test_cv_iterable_wrapper PASSED [ 86%]\nsklearn/model_selection/tests/test_split.py::test_group_kfold PASSED     [ 88%]\nsklearn/model_selection/tests/test_split.py::test_time_series_cv PASSED  [ 90%]\nsklearn/model_selection/tests/test_split.py::test_time_series_max_train_size PASSED [ 91%]\nsklearn/model_selection/tests/test_split.py::test_nested_cv PASSED       [ 93%]\nsklearn/model_selection/tests/test_split.py::test_train_test_default_warning PASSED [ 95%]\nsklearn/model_selection/tests/test_split.py::test_nsplit_default_warn PASSED [ 96%]\nsklearn/model_selection/tests/test_split.py::test_check_cv_default_warn PASSED [ 98%]\nsklearn/model_selection/tests/test_split.py::test_build_repr PASSED      [100%]\n\n=================================== FAILURES ===================================\n_________________________ test_shuffle_stratifiedkfold _________________________\nsklearn/model_selection/tests/test_split.py:505: in test_shuffle_stratifiedkfold\n    assert test_set1 != test_set2\nE   assert [(0, 5), (1, 6), (2, 7), (3, 8), (4, 9)] != [(0, 5), (1, 6), (2, 7), (3, 8), (4, 9)]\n================== 1 failed, 60 passed, 674 warnings in 3.24s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sklearn/model_selection/tests/test_split.py` failed. (See above for error)",
          "test_files_run": [
            "sklearn/model_selection/tests/test_split.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 61,
          "failed": 0,
          "errors": 0,
          "collected": 61,
          "duration": 5.5,
          "log_tail": "sklearn/model_selection/tests/test_split.py::test_stratified_shuffle_split_respects_test_size PASSED [ 26%]\nsklearn/model_selection/tests/test_split.py::test_stratified_shuffle_split_iter PASSED [ 27%]\nsklearn/model_selection/tests/test_split.py::test_stratified_shuffle_split_even PASSED [ 29%]\nsklearn/model_selection/tests/test_split.py::test_stratified_shuffle_split_overlap_train_test_bug PASSED [ 31%]\nsklearn/model_selection/tests/test_split.py::test_stratified_shuffle_split_multilabel PASSED [ 32%]\nsklearn/model_selection/tests/test_split.py::test_stratified_shuffle_split_multilabel_many_labels PASSED [ 34%]\nsklearn/model_selection/tests/test_split.py::test_predefinedsplit_with_kfold_split PASSED [ 36%]\nsklearn/model_selection/tests/test_split.py::test_group_shuffle_split PASSED [ 37%]\nsklearn/model_selection/tests/test_split.py::test_leave_one_p_group_out PASSED [ 39%]\nsklearn/model_selection/tests/test_split.py::test_leave_group_out_changing_groups PASSED [ 40%]\nsklearn/model_selection/tests/test_split.py::test_leave_one_p_group_out_error_on_fewer_number_of_groups PASSED [ 42%]\nsklearn/model_selection/tests/test_split.py::test_repeated_cv_value_errors PASSED [ 44%]\nsklearn/model_selection/tests/test_split.py::test_repeated_kfold_determinstic_split PASSED [ 45%]\nsklearn/model_selection/tests/test_split.py::test_get_n_splits_for_repeated_kfold PASSED [ 47%]\nsklearn/model_selection/tests/test_split.py::test_get_n_splits_for_repeated_stratified_kfold PASSED [ 49%]\nsklearn/model_selection/tests/test_split.py::test_repeated_stratified_kfold_determinstic_split PASSED [ 50%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_errors PASSED [ 52%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes1[1.2-0.8] PASSED [ 54%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes1[1.0-0.8] PASSED [ 55%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes1[0.0-0.8] PASSED [ 57%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes1[-0.2-0.8] PASSED [ 59%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes1[0.8-1.2] PASSED [ 60%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes1[0.8-1.0] PASSED [ 62%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes1[0.8-0.0] PASSED [ 63%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes1[0.8--0.2] PASSED [ 65%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes2[-10-0.8] PASSED [ 67%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes2[0-0.8] PASSED [ 68%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes2[11-0.8] PASSED [ 70%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes2[0.8--10] PASSED [ 72%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes2[0.8-0] PASSED [ 73%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes2[0.8-11] PASSED [ 75%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split PASSED [ 77%]\nsklearn/model_selection/tests/test_split.py::test_shufflesplit_errors PASSED [ 78%]\nsklearn/model_selection/tests/test_split.py::test_shufflesplit_reproducible PASSED [ 80%]\nsklearn/model_selection/tests/test_split.py::test_stratifiedshufflesplit_list_input PASSED [ 81%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_allow_nans PASSED [ 83%]\nsklearn/model_selection/tests/test_split.py::test_check_cv PASSED        [ 85%]\nsklearn/model_selection/tests/test_split.py::test_cv_iterable_wrapper PASSED [ 86%]\nsklearn/model_selection/tests/test_split.py::test_group_kfold PASSED     [ 88%]\nsklearn/model_selection/tests/test_split.py::test_time_series_cv PASSED  [ 90%]\nsklearn/model_selection/tests/test_split.py::test_time_series_max_train_size PASSED [ 91%]\nsklearn/model_selection/tests/test_split.py::test_nested_cv PASSED       [ 93%]\nsklearn/model_selection/tests/test_split.py::test_train_test_default_warning PASSED [ 95%]\nsklearn/model_selection/tests/test_split.py::test_nsplit_default_warn PASSED [ 96%]\nsklearn/model_selection/tests/test_split.py::test_check_cv_default_warn PASSED [ 98%]\nsklearn/model_selection/tests/test_split.py::test_build_repr PASSED      [100%]\n\n======================= 61 passed, 674 warnings in 2.93s =======================\n\n",
          "test_files_run": [
            "sklearn/model_selection/tests/test_split.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got True\u2192True"
    },
    {
      "instance_id": "scikit-learn__scikit-learn-13135",
      "repo": "scikit-learn/scikit-learn",
      "valid": true,
      "worker": "http://34.123.9.23:8080",
      "duration": 10.14529800415039,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 33,
          "failed": 1,
          "errors": 0,
          "collected": 34,
          "duration": 5.77,
          "log_tail": "sklearn/preprocessing/tests/test_discretization.py::test_fit_transform[quantile-expected2] PASSED [  8%]\nsklearn/preprocessing/tests/test_discretization.py::test_valid_n_bins PASSED [ 11%]\nsklearn/preprocessing/tests/test_discretization.py::test_invalid_n_bins PASSED [ 14%]\nsklearn/preprocessing/tests/test_discretization.py::test_invalid_n_bins_array PASSED [ 17%]\nsklearn/preprocessing/tests/test_discretization.py::test_fit_transform_n_bins_array[uniform-expected0] PASSED [ 20%]\nsklearn/preprocessing/tests/test_discretization.py::test_fit_transform_n_bins_array[kmeans-expected1] PASSED [ 23%]\nsklearn/preprocessing/tests/test_discretization.py::test_fit_transform_n_bins_array[quantile-expected2] PASSED [ 26%]\nsklearn/preprocessing/tests/test_discretization.py::test_invalid_n_features PASSED [ 29%]\nsklearn/preprocessing/tests/test_discretization.py::test_same_min_max[uniform] PASSED [ 32%]\nsklearn/preprocessing/tests/test_discretization.py::test_same_min_max[kmeans] PASSED [ 35%]\nsklearn/preprocessing/tests/test_discretization.py::test_same_min_max[quantile] PASSED [ 38%]\nsklearn/preprocessing/tests/test_discretization.py::test_transform_1d_behavior PASSED [ 41%]\nsklearn/preprocessing/tests/test_discretization.py::test_numeric_stability PASSED [ 44%]\nsklearn/preprocessing/tests/test_discretization.py::test_invalid_encode_option PASSED [ 47%]\nsklearn/preprocessing/tests/test_discretization.py::test_encode_options PASSED [ 50%]\nsklearn/preprocessing/tests/test_discretization.py::test_invalid_strategy_option PASSED [ 52%]\nsklearn/preprocessing/tests/test_discretization.py::test_nonuniform_strategies[uniform-expected_2bins0-expected_3bins0-expected_5bins0] PASSED [ 55%]\nsklearn/preprocessing/tests/test_discretization.py::test_nonuniform_strategies[kmeans-expected_2bins1-expected_3bins1-expected_5bins1] FAILED [ 58%]\nsklearn/preprocessing/tests/test_discretization.py::test_nonuniform_strategies[quantile-expected_2bins2-expected_3bins2-expected_5bins2] PASSED [ 61%]\nsklearn/preprocessing/tests/test_discretization.py::test_inverse_transform[ordinal-uniform] PASSED [ 64%]\nsklearn/preprocessing/tests/test_discretization.py::test_inverse_transform[ordinal-kmeans] PASSED [ 67%]\nsklearn/preprocessing/tests/test_discretization.py::test_inverse_transform[ordinal-quantile] PASSED [ 70%]\nsklearn/preprocessing/tests/test_discretization.py::test_inverse_transform[onehot-uniform] PASSED [ 73%]\nsklearn/preprocessing/tests/test_discretization.py::test_inverse_transform[onehot-kmeans] PASSED [ 76%]\nsklearn/preprocessing/tests/test_discretization.py::test_inverse_transform[onehot-quantile] PASSED [ 79%]\nsklearn/preprocessing/tests/test_discretization.py::test_inverse_transform[onehot-dense-uniform] PASSED [ 82%]\nsklearn/preprocessing/tests/test_discretization.py::test_inverse_transform[onehot-dense-kmeans] PASSED [ 85%]\nsklearn/preprocessing/tests/test_discretization.py::test_inverse_transform[onehot-dense-quantile] PASSED [ 88%]\nsklearn/preprocessing/tests/test_discretization.py::test_transform_outside_fit_range[uniform] PASSED [ 91%]\nsklearn/preprocessing/tests/test_discretization.py::test_transform_outside_fit_range[kmeans] PASSED [ 94%]\nsklearn/preprocessing/tests/test_discretization.py::test_transform_outside_fit_range[quantile] PASSED [ 97%]\nsklearn/preprocessing/tests/test_discretization.py::test_overwrite PASSED [100%]\n\n=================================== FAILURES ===================================\n_ test_nonuniform_strategies[kmeans-expected_2bins1-expected_3bins1-expected_5bins1] _\nsklearn/preprocessing/tests/test_discretization.py:208: in test_nonuniform_strategies\n    Xt = est.fit_transform(X)\nsklearn/base.py:476: in fit_transform\n    return self.fit(X, **fit_params).transform(X)\nsklearn/preprocessing/_discretization.py:255: in transform\n    Xt[:, jj] = np.digitize(Xt[:, jj] + eps, bin_edges[jj][1:])\n<__array_function__ internals>:6: in digitize\n    ???\n/opt/miniconda3/envs/testbed/lib/python3.6/site-packages/numpy/lib/function_base.py:4778: in digitize\n    raise ValueError(\"bins must be monotonically increasing or decreasing\")\nE   ValueError: bins must be monotonically increasing or decreasing\n========================= 1 failed, 33 passed in 1.27s =========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sklearn/preprocessing/tests/test_discretization.py` failed. (See above for error)",
          "test_files_run": [
            "sklearn/preprocessing/tests/test_discretization.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 34,
          "failed": 0,
          "errors": 0,
          "collected": 34,
          "duration": 3.32,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 34 items\n\nsklearn/preprocessing/tests/test_discretization.py::test_fit_transform[uniform-expected0] PASSED [  2%]\nsklearn/preprocessing/tests/test_discretization.py::test_fit_transform[kmeans-expected1] PASSED [  5%]\nsklearn/preprocessing/tests/test_discretization.py::test_fit_transform[quantile-expected2] PASSED [  8%]\nsklearn/preprocessing/tests/test_discretization.py::test_valid_n_bins PASSED [ 11%]\nsklearn/preprocessing/tests/test_discretization.py::test_invalid_n_bins PASSED [ 14%]\nsklearn/preprocessing/tests/test_discretization.py::test_invalid_n_bins_array PASSED [ 17%]\nsklearn/preprocessing/tests/test_discretization.py::test_fit_transform_n_bins_array[uniform-expected0] PASSED [ 20%]\nsklearn/preprocessing/tests/test_discretization.py::test_fit_transform_n_bins_array[kmeans-expected1] PASSED [ 23%]\nsklearn/preprocessing/tests/test_discretization.py::test_fit_transform_n_bins_array[quantile-expected2] PASSED [ 26%]\nsklearn/preprocessing/tests/test_discretization.py::test_invalid_n_features PASSED [ 29%]\nsklearn/preprocessing/tests/test_discretization.py::test_same_min_max[uniform] PASSED [ 32%]\nsklearn/preprocessing/tests/test_discretization.py::test_same_min_max[kmeans] PASSED [ 35%]\nsklearn/preprocessing/tests/test_discretization.py::test_same_min_max[quantile] PASSED [ 38%]\nsklearn/preprocessing/tests/test_discretization.py::test_transform_1d_behavior PASSED [ 41%]\nsklearn/preprocessing/tests/test_discretization.py::test_numeric_stability PASSED [ 44%]\nsklearn/preprocessing/tests/test_discretization.py::test_invalid_encode_option PASSED [ 47%]\nsklearn/preprocessing/tests/test_discretization.py::test_encode_options PASSED [ 50%]\nsklearn/preprocessing/tests/test_discretization.py::test_invalid_strategy_option PASSED [ 52%]\nsklearn/preprocessing/tests/test_discretization.py::test_nonuniform_strategies[uniform-expected_2bins0-expected_3bins0-expected_5bins0] PASSED [ 55%]\nsklearn/preprocessing/tests/test_discretization.py::test_nonuniform_strategies[kmeans-expected_2bins1-expected_3bins1-expected_5bins1] PASSED [ 58%]\nsklearn/preprocessing/tests/test_discretization.py::test_nonuniform_strategies[quantile-expected_2bins2-expected_3bins2-expected_5bins2] PASSED [ 61%]\nsklearn/preprocessing/tests/test_discretization.py::test_inverse_transform[ordinal-uniform] PASSED [ 64%]\nsklearn/preprocessing/tests/test_discretization.py::test_inverse_transform[ordinal-kmeans] PASSED [ 67%]\nsklearn/preprocessing/tests/test_discretization.py::test_inverse_transform[ordinal-quantile] PASSED [ 70%]\nsklearn/preprocessing/tests/test_discretization.py::test_inverse_transform[onehot-uniform] PASSED [ 73%]\nsklearn/preprocessing/tests/test_discretization.py::test_inverse_transform[onehot-kmeans] PASSED [ 76%]\nsklearn/preprocessing/tests/test_discretization.py::test_inverse_transform[onehot-quantile] PASSED [ 79%]\nsklearn/preprocessing/tests/test_discretization.py::test_inverse_transform[onehot-dense-uniform] PASSED [ 82%]\nsklearn/preprocessing/tests/test_discretization.py::test_inverse_transform[onehot-dense-kmeans] PASSED [ 85%]\nsklearn/preprocessing/tests/test_discretization.py::test_inverse_transform[onehot-dense-quantile] PASSED [ 88%]\nsklearn/preprocessing/tests/test_discretization.py::test_transform_outside_fit_range[uniform] PASSED [ 91%]\nsklearn/preprocessing/tests/test_discretization.py::test_transform_outside_fit_range[kmeans] PASSED [ 94%]\nsklearn/preprocessing/tests/test_discretization.py::test_transform_outside_fit_range[quantile] PASSED [ 97%]\nsklearn/preprocessing/tests/test_discretization.py::test_overwrite PASSED [100%]\n\n============================== 34 passed in 0.90s ==============================\n\n",
          "test_files_run": [
            "sklearn/preprocessing/tests/test_discretization.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "scikit-learn__scikit-learn-13328",
      "repo": "scikit-learn/scikit-learn",
      "valid": true,
      "worker": "http://34.123.9.23:8080",
      "duration": 9.583672046661377,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 9,
          "failed": 1,
          "errors": 0,
          "collected": 10,
          "duration": 5.34,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 10 items\n\nsklearn/linear_model/tests/test_huber.py::test_huber_equals_lr_for_high_epsilon PASSED [ 10%]\nsklearn/linear_model/tests/test_huber.py::test_huber_max_iter PASSED     [ 20%]\nsklearn/linear_model/tests/test_huber.py::test_huber_gradient PASSED     [ 30%]\nsklearn/linear_model/tests/test_huber.py::test_huber_sample_weights PASSED [ 40%]\nsklearn/linear_model/tests/test_huber.py::test_huber_sparse PASSED       [ 50%]\nsklearn/linear_model/tests/test_huber.py::test_huber_scaling_invariant PASSED [ 60%]\nsklearn/linear_model/tests/test_huber.py::test_huber_and_sgd_same_results PASSED [ 70%]\nsklearn/linear_model/tests/test_huber.py::test_huber_warm_start PASSED   [ 80%]\nsklearn/linear_model/tests/test_huber.py::test_huber_better_r2_score PASSED [ 90%]\nsklearn/linear_model/tests/test_huber.py::test_huber_bool FAILED         [100%]\n\n=================================== FAILURES ===================================\n_______________________________ test_huber_bool ________________________________\nsklearn/linear_model/tests/test_huber.py:215: in test_huber_bool\n    HuberRegressor().fit(X_bool, y)\nsklearn/linear_model/huber.py:288: in fit\n    iprint=0)\n/opt/miniconda3/envs/testbed/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py:198: in fmin_l_bfgs_b\n    **opts)\n/opt/miniconda3/envs/testbed/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py:308: in _minimize_lbfgsb\n    finite_diff_rel_step=finite_diff_rel_step)\n/opt/miniconda3/envs/testbed/lib/python3.6/site-packages/scipy/optimize/optimize.py:262: in _prepare_scalar_function\n    finite_diff_rel_step, bounds, epsilon=epsilon)\n/opt/miniconda3/envs/testbed/lib/python3.6/site-packages/scipy/optimize/_differentiable_functions.py:76: in __init__\n    self._update_fun()\n/opt/miniconda3/envs/testbed/lib/python3.6/site-packages/scipy/optimize/_differentiable_functions.py:166: in _update_fun\n    self._update_fun_impl()\n/opt/miniconda3/envs/testbed/lib/python3.6/site-packages/scipy/optimize/_differentiable_functions.py:73: in update_fun\n    self.f = fun_wrapped(self.x)\n/opt/miniconda3/envs/testbed/lib/python3.6/site-packages/scipy/optimize/_differentiable_functions.py:70: in fun_wrapped\n    return fun(x, *args)\n/opt/miniconda3/envs/testbed/lib/python3.6/site-packages/scipy/optimize/optimize.py:74: in __call__\n    self._compute_if_needed(x, *args)\n/opt/miniconda3/envs/testbed/lib/python3.6/site-packages/scipy/optimize/optimize.py:68: in _compute_if_needed\n    fg = self.fun(x, *args)\nsklearn/linear_model/huber.py:93: in _huber_loss_and_gradient\n    X_non_outliers = -axis0_safe_slice(X, ~outliers_mask, n_non_outliers)\nE   TypeError: The numpy boolean negative, the `-` operator, is not supported, use the `~` operator or the logical_not function instead.\n========================= 1 failed, 9 passed in 1.21s ==========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sklearn/linear_model/tests/test_huber.py` failed. (See above for error)",
          "test_files_run": [
            "sklearn/linear_model/tests/test_huber.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 10,
          "failed": 0,
          "errors": 0,
          "collected": 10,
          "duration": 3.31,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 10 items\n\nsklearn/linear_model/tests/test_huber.py::test_huber_equals_lr_for_high_epsilon PASSED [ 10%]\nsklearn/linear_model/tests/test_huber.py::test_huber_max_iter PASSED     [ 20%]\nsklearn/linear_model/tests/test_huber.py::test_huber_gradient PASSED     [ 30%]\nsklearn/linear_model/tests/test_huber.py::test_huber_sample_weights PASSED [ 40%]\nsklearn/linear_model/tests/test_huber.py::test_huber_sparse PASSED       [ 50%]\nsklearn/linear_model/tests/test_huber.py::test_huber_scaling_invariant PASSED [ 60%]\nsklearn/linear_model/tests/test_huber.py::test_huber_and_sgd_same_results PASSED [ 70%]\nsklearn/linear_model/tests/test_huber.py::test_huber_warm_start PASSED   [ 80%]\nsklearn/linear_model/tests/test_huber.py::test_huber_better_r2_score PASSED [ 90%]\nsklearn/linear_model/tests/test_huber.py::test_huber_bool PASSED         [100%]\n\n============================== 10 passed in 1.02s ==============================\n\n",
          "test_files_run": [
            "sklearn/linear_model/tests/test_huber.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "scikit-learn__scikit-learn-13439",
      "repo": "scikit-learn/scikit-learn",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 14.593923091888428,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 40,
          "failed": 1,
          "errors": 0,
          "collected": 41,
          "duration": 7.15,
          "log_tail": "sklearn/tests/test_pipeline.py::test_pipeline_init_tuple PASSED          [  4%]\nsklearn/tests/test_pipeline.py::test_pipeline_methods_anova PASSED       [  7%]\nsklearn/tests/test_pipeline.py::test_pipeline_fit_params PASSED          [  9%]\nsklearn/tests/test_pipeline.py::test_pipeline_sample_weight_supported PASSED [ 12%]\nsklearn/tests/test_pipeline.py::test_pipeline_sample_weight_unsupported PASSED [ 14%]\nsklearn/tests/test_pipeline.py::test_pipeline_raise_set_params_error PASSED [ 17%]\nsklearn/tests/test_pipeline.py::test_pipeline_methods_pca_svm PASSED     [ 19%]\nsklearn/tests/test_pipeline.py::test_pipeline_methods_preprocessing_svm PASSED [ 21%]\nsklearn/tests/test_pipeline.py::test_fit_predict_on_pipeline PASSED      [ 24%]\nsklearn/tests/test_pipeline.py::test_fit_predict_on_pipeline_without_fit_predict PASSED [ 26%]\nsklearn/tests/test_pipeline.py::test_fit_predict_with_intermediate_fit_params PASSED [ 29%]\nsklearn/tests/test_pipeline.py::test_predict_with_predict_params PASSED  [ 31%]\nsklearn/tests/test_pipeline.py::test_feature_union PASSED                [ 34%]\nsklearn/tests/test_pipeline.py::test_make_union PASSED                   [ 36%]\nsklearn/tests/test_pipeline.py::test_make_union_kwargs PASSED            [ 39%]\nsklearn/tests/test_pipeline.py::test_pipeline_transform PASSED           [ 41%]\nsklearn/tests/test_pipeline.py::test_pipeline_fit_transform PASSED       [ 43%]\nsklearn/tests/test_pipeline.py::test_pipeline_slice PASSED               [ 46%]\nsklearn/tests/test_pipeline.py::test_pipeline_index PASSED               [ 48%]\nsklearn/tests/test_pipeline.py::test_set_pipeline_steps PASSED           [ 51%]\nsklearn/tests/test_pipeline.py::test_pipeline_named_steps PASSED         [ 53%]\nsklearn/tests/test_pipeline.py::test_pipeline_correctly_adjusts_steps[None] PASSED [ 56%]\nsklearn/tests/test_pipeline.py::test_pipeline_correctly_adjusts_steps[passthrough] PASSED [ 58%]\nsklearn/tests/test_pipeline.py::test_set_pipeline_step_passthrough[None] PASSED [ 60%]\nsklearn/tests/test_pipeline.py::test_set_pipeline_step_passthrough[passthrough] PASSED [ 63%]\nsklearn/tests/test_pipeline.py::test_pipeline_ducktyping PASSED          [ 65%]\nsklearn/tests/test_pipeline.py::test_make_pipeline PASSED                [ 68%]\nsklearn/tests/test_pipeline.py::test_feature_union_weights PASSED        [ 70%]\nsklearn/tests/test_pipeline.py::test_feature_union_parallel PASSED       [ 73%]\nsklearn/tests/test_pipeline.py::test_feature_union_feature_names PASSED  [ 75%]\nsklearn/tests/test_pipeline.py::test_classes_property PASSED             [ 78%]\nsklearn/tests/test_pipeline.py::test_set_feature_union_steps PASSED      [ 80%]\nsklearn/tests/test_pipeline.py::test_set_feature_union_step_drop[drop] PASSED [ 82%]\nsklearn/tests/test_pipeline.py::test_set_feature_union_step_drop[None] PASSED [ 85%]\nsklearn/tests/test_pipeline.py::test_step_name_validation PASSED         [ 87%]\nsklearn/tests/test_pipeline.py::test_set_params_nested_pipeline PASSED   [ 90%]\nsklearn/tests/test_pipeline.py::test_pipeline_wrong_memory PASSED        [ 92%]\nsklearn/tests/test_pipeline.py::test_pipeline_with_cache_attribute PASSED [ 95%]\nsklearn/tests/test_pipeline.py::test_pipeline_memory PASSED              [ 97%]\nsklearn/tests/test_pipeline.py::test_make_pipeline_memory FAILED         [100%]\n\n=================================== FAILURES ===================================\n__________________________ test_make_pipeline_memory ___________________________\nsklearn/tests/test_pipeline.py:1072: in test_make_pipeline_memory\n    assert len(pipeline) == 2\nE   TypeError: object of type 'Pipeline' has no len()\n=================== 1 failed, 40 passed, 2 warnings in 2.26s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sklearn/tests/test_pipeline.py` failed. (See above for error)",
          "test_files_run": [
            "sklearn/tests/test_pipeline.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 41,
          "failed": 0,
          "errors": 0,
          "collected": 41,
          "duration": 6.47,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 41 items\n\nsklearn/tests/test_pipeline.py::test_pipeline_init PASSED                [  2%]\nsklearn/tests/test_pipeline.py::test_pipeline_init_tuple PASSED          [  4%]\nsklearn/tests/test_pipeline.py::test_pipeline_methods_anova PASSED       [  7%]\nsklearn/tests/test_pipeline.py::test_pipeline_fit_params PASSED          [  9%]\nsklearn/tests/test_pipeline.py::test_pipeline_sample_weight_supported PASSED [ 12%]\nsklearn/tests/test_pipeline.py::test_pipeline_sample_weight_unsupported PASSED [ 14%]\nsklearn/tests/test_pipeline.py::test_pipeline_raise_set_params_error PASSED [ 17%]\nsklearn/tests/test_pipeline.py::test_pipeline_methods_pca_svm PASSED     [ 19%]\nsklearn/tests/test_pipeline.py::test_pipeline_methods_preprocessing_svm PASSED [ 21%]\nsklearn/tests/test_pipeline.py::test_fit_predict_on_pipeline PASSED      [ 24%]\nsklearn/tests/test_pipeline.py::test_fit_predict_on_pipeline_without_fit_predict PASSED [ 26%]\nsklearn/tests/test_pipeline.py::test_fit_predict_with_intermediate_fit_params PASSED [ 29%]\nsklearn/tests/test_pipeline.py::test_predict_with_predict_params PASSED  [ 31%]\nsklearn/tests/test_pipeline.py::test_feature_union PASSED                [ 34%]\nsklearn/tests/test_pipeline.py::test_make_union PASSED                   [ 36%]\nsklearn/tests/test_pipeline.py::test_make_union_kwargs PASSED            [ 39%]\nsklearn/tests/test_pipeline.py::test_pipeline_transform PASSED           [ 41%]\nsklearn/tests/test_pipeline.py::test_pipeline_fit_transform PASSED       [ 43%]\nsklearn/tests/test_pipeline.py::test_pipeline_slice PASSED               [ 46%]\nsklearn/tests/test_pipeline.py::test_pipeline_index PASSED               [ 48%]\nsklearn/tests/test_pipeline.py::test_set_pipeline_steps PASSED           [ 51%]\nsklearn/tests/test_pipeline.py::test_pipeline_named_steps PASSED         [ 53%]\nsklearn/tests/test_pipeline.py::test_pipeline_correctly_adjusts_steps[None] PASSED [ 56%]\nsklearn/tests/test_pipeline.py::test_pipeline_correctly_adjusts_steps[passthrough] PASSED [ 58%]\nsklearn/tests/test_pipeline.py::test_set_pipeline_step_passthrough[None] PASSED [ 60%]\nsklearn/tests/test_pipeline.py::test_set_pipeline_step_passthrough[passthrough] PASSED [ 63%]\nsklearn/tests/test_pipeline.py::test_pipeline_ducktyping PASSED          [ 65%]\nsklearn/tests/test_pipeline.py::test_make_pipeline PASSED                [ 68%]\nsklearn/tests/test_pipeline.py::test_feature_union_weights PASSED        [ 70%]\nsklearn/tests/test_pipeline.py::test_feature_union_parallel PASSED       [ 73%]\nsklearn/tests/test_pipeline.py::test_feature_union_feature_names PASSED  [ 75%]\nsklearn/tests/test_pipeline.py::test_classes_property PASSED             [ 78%]\nsklearn/tests/test_pipeline.py::test_set_feature_union_steps PASSED      [ 80%]\nsklearn/tests/test_pipeline.py::test_set_feature_union_step_drop[drop] PASSED [ 82%]\nsklearn/tests/test_pipeline.py::test_set_feature_union_step_drop[None] PASSED [ 85%]\nsklearn/tests/test_pipeline.py::test_step_name_validation PASSED         [ 87%]\nsklearn/tests/test_pipeline.py::test_set_params_nested_pipeline PASSED   [ 90%]\nsklearn/tests/test_pipeline.py::test_pipeline_wrong_memory PASSED        [ 92%]\nsklearn/tests/test_pipeline.py::test_pipeline_with_cache_attribute PASSED [ 95%]\nsklearn/tests/test_pipeline.py::test_pipeline_memory PASSED              [ 97%]\nsklearn/tests/test_pipeline.py::test_make_pipeline_memory PASSED         [100%]\n\n======================== 41 passed, 2 warnings in 3.09s ========================\n\n",
          "test_files_run": [
            "sklearn/tests/test_pipeline.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "scikit-learn__scikit-learn-13779",
      "repo": "scikit-learn/scikit-learn",
      "valid": true,
      "worker": "http://34.41.233.120:8080",
      "duration": 11.338301181793213,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 18,
          "failed": 2,
          "errors": 0,
          "collected": 20,
          "duration": 5.38,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 20 items\n\nsklearn/ensemble/tests/test_voting.py::test_estimator_init PASSED        [  5%]\nsklearn/ensemble/tests/test_voting.py::test_predictproba_hardvoting PASSED [ 10%]\nsklearn/ensemble/tests/test_voting.py::test_notfitted PASSED             [ 15%]\nsklearn/ensemble/tests/test_voting.py::test_majority_label_iris PASSED   [ 20%]\nsklearn/ensemble/tests/test_voting.py::test_tie_situation PASSED         [ 25%]\nsklearn/ensemble/tests/test_voting.py::test_weights_iris PASSED          [ 30%]\nsklearn/ensemble/tests/test_voting.py::test_weights_regressor PASSED     [ 35%]\nsklearn/ensemble/tests/test_voting.py::test_predict_on_toy_problem PASSED [ 40%]\nsklearn/ensemble/tests/test_voting.py::test_predict_proba_on_toy_problem PASSED [ 45%]\nsklearn/ensemble/tests/test_voting.py::test_multilabel PASSED            [ 50%]\nsklearn/ensemble/tests/test_voting.py::test_gridsearch PASSED            [ 55%]\nsklearn/ensemble/tests/test_voting.py::test_parallel_fit PASSED          [ 60%]\nsklearn/ensemble/tests/test_voting.py::test_sample_weight PASSED         [ 65%]\nsklearn/ensemble/tests/test_voting.py::test_sample_weight_kwargs PASSED  [ 70%]\nsklearn/ensemble/tests/test_voting.py::test_set_params PASSED            [ 75%]\nsklearn/ensemble/tests/test_voting.py::test_set_estimator_none PASSED    [ 80%]\nsklearn/ensemble/tests/test_voting.py::test_estimator_weights_format PASSED [ 85%]\nsklearn/ensemble/tests/test_voting.py::test_transform PASSED             [ 90%]\nsklearn/ensemble/tests/test_voting.py::test_none_estimator_with_weights[X0-y0-voter0] FAILED [ 95%]\nsklearn/ensemble/tests/test_voting.py::test_none_estimator_with_weights[X1-y1-voter1] FAILED [100%]\n\n=================================== FAILURES ===================================\n________________ test_none_estimator_with_weights[X0-y0-voter0] ________________\nsklearn/ensemble/tests/test_voting.py:531: in test_none_estimator_with_weights\n    voter.fit(X, y, sample_weight=np.ones(y.shape))\nsklearn/ensemble/voting.py:273: in fit\n    return super().fit(X, transformed_y, sample_weight)\nsklearn/ensemble/voting.py:81: in fit\n    if not has_fit_parameter(step, 'sample_weight'):\nsklearn/utils/validation.py:808: in has_fit_parameter\n    return parameter in signature(estimator.fit).parameters\nE   AttributeError: 'NoneType' object has no attribute 'fit'\n________________ test_none_estimator_with_weights[X1-y1-voter1] ________________\nsklearn/ensemble/tests/test_voting.py:531: in test_none_estimator_with_weights\n    voter.fit(X, y, sample_weight=np.ones(y.shape))\nsklearn/ensemble/voting.py:451: in fit\n    return super().fit(X, y, sample_weight)\nsklearn/ensemble/voting.py:81: in fit\n    if not has_fit_parameter(step, 'sample_weight'):\nsklearn/utils/validation.py:808: in has_fit_parameter\n    return parameter in signature(estimator.fit).parameters\nE   AttributeError: 'NoneType' object has no attribute 'fit'\n=================== 2 failed, 18 passed, 1 warning in 2.48s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sklearn/ensemble/tests/test_voting.py` failed. (See above for error)",
          "test_files_run": [
            "sklearn/ensemble/tests/test_voting.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 20,
          "failed": 0,
          "errors": 0,
          "collected": 20,
          "duration": 5.06,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 20 items\n\nsklearn/ensemble/tests/test_voting.py::test_estimator_init PASSED        [  5%]\nsklearn/ensemble/tests/test_voting.py::test_predictproba_hardvoting PASSED [ 10%]\nsklearn/ensemble/tests/test_voting.py::test_notfitted PASSED             [ 15%]\nsklearn/ensemble/tests/test_voting.py::test_majority_label_iris PASSED   [ 20%]\nsklearn/ensemble/tests/test_voting.py::test_tie_situation PASSED         [ 25%]\nsklearn/ensemble/tests/test_voting.py::test_weights_iris PASSED          [ 30%]\nsklearn/ensemble/tests/test_voting.py::test_weights_regressor PASSED     [ 35%]\nsklearn/ensemble/tests/test_voting.py::test_predict_on_toy_problem PASSED [ 40%]\nsklearn/ensemble/tests/test_voting.py::test_predict_proba_on_toy_problem PASSED [ 45%]\nsklearn/ensemble/tests/test_voting.py::test_multilabel PASSED            [ 50%]\nsklearn/ensemble/tests/test_voting.py::test_gridsearch PASSED            [ 55%]\nsklearn/ensemble/tests/test_voting.py::test_parallel_fit PASSED          [ 60%]\nsklearn/ensemble/tests/test_voting.py::test_sample_weight PASSED         [ 65%]\nsklearn/ensemble/tests/test_voting.py::test_sample_weight_kwargs PASSED  [ 70%]\nsklearn/ensemble/tests/test_voting.py::test_set_params PASSED            [ 75%]\nsklearn/ensemble/tests/test_voting.py::test_set_estimator_none PASSED    [ 80%]\nsklearn/ensemble/tests/test_voting.py::test_estimator_weights_format PASSED [ 85%]\nsklearn/ensemble/tests/test_voting.py::test_transform PASSED             [ 90%]\nsklearn/ensemble/tests/test_voting.py::test_none_estimator_with_weights[X0-y0-voter0] PASSED [ 95%]\nsklearn/ensemble/tests/test_voting.py::test_none_estimator_with_weights[X1-y1-voter1] PASSED [100%]\n\n======================== 20 passed, 1 warning in 2.25s =========================\n\n",
          "test_files_run": [
            "sklearn/ensemble/tests/test_voting.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "scikit-learn__scikit-learn-13142",
      "repo": "scikit-learn/scikit-learn",
      "valid": true,
      "worker": "http://34.41.233.120:8080",
      "duration": 26.490147829055786,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 54,
          "failed": 2,
          "errors": 0,
          "collected": 56,
          "duration": 13.73,
          "log_tail": "sklearn/mixture/tests/test_gaussian_mixture.py::test_bic_1d_1component PASSED [ 76%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_gaussian_mixture_aic_bic PASSED [ 78%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_gaussian_mixture_verbose PASSED [ 80%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_warm_start[0] PASSED [ 82%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_warm_start[1] PASSED [ 83%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_warm_start[2] PASSED [ 85%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_convergence_detected_with_warm_start PASSED [ 87%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_score PASSED        [ 89%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_score_samples PASSED [ 91%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_monotonic_likelihood PASSED [ 92%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_regularisation PASSED [ 94%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_property PASSED     [ 96%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_sample PASSED       [ 98%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_init PASSED         [100%]\n\n=================================== FAILURES ===================================\n___________________ test_bayesian_mixture_fit_predict_n_init ___________________\nsklearn/mixture/tests/test_bayesian_mixture.py:460: in test_bayesian_mixture_fit_predict_n_init\n    assert_array_equal(y_pred1, y_pred2)\nE   AssertionError: \nE   Arrays are not equal\nE   \nE   Mismatched elements: 878 / 1000 (87.8%)\nE   Max absolute difference: 4\nE   Max relative difference: 2.\nE    x: array([2, 2, 2, 2, 2, 1, 0, 2, 4, 2, 2, 0, 2, 2, 3, 2, 2, 0, 2, 2, 0, 2,\nE          0, 2, 2, 2, 2, 3, 1, 3, 2, 4, 2, 2, 3, 2, 2, 2, 2, 1, 2, 2, 3, 2,\nE          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 3, 2,...\nE    y: array([1, 0, 0, 0, 0, 0, 0, 0, 3, 2, 0, 2, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1,\nE          1, 1, 1, 1, 0, 3, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 3, 1,\nE          3, 0, 0, 0, 0, 0, 1, 2, 0, 0, 1, 0, 0, 1, 1, 1, 0, 3, 0, 0, 0, 1,...\n___________________ test_gaussian_mixture_fit_predict_n_init ___________________\nsklearn/mixture/tests/test_gaussian_mixture.py:607: in test_gaussian_mixture_fit_predict_n_init\n    assert_array_equal(y_pred1, y_pred2)\nE   AssertionError: \nE   Arrays are not equal\nE   \nE   Mismatched elements: 815 / 1000 (81.5%)\nE   Max absolute difference: 4\nE   Max relative difference: 3.\nE    x: array([1, 0, 0, 3, 0, 1, 2, 2, 4, 2, 4, 2, 4, 2, 2, 4, 0, 2, 1, 1, 3, 3,\nE          3, 0, 1, 1, 4, 3, 0, 2, 0, 4, 3, 3, 2, 2, 2, 1, 0, 1, 1, 4, 2, 1,\nE          4, 2, 4, 0, 2, 4, 2, 2, 3, 2, 1, 0, 0, 1, 1, 2, 0, 4, 0, 2, 2, 1,...\nE    y: array([2, 4, 2, 1, 3, 4, 0, 1, 4, 3, 4, 0, 3, 3, 0, 3, 3, 0, 4, 2, 2, 2,\nE          2, 2, 2, 2, 4, 1, 3, 0, 4, 4, 1, 2, 1, 0, 3, 3, 3, 2, 2, 4, 1, 2,\nE          1, 0, 4, 0, 3, 3, 3, 0, 1, 0, 3, 3, 4, 2, 3, 0, 3, 4, 4, 0, 1, 3,...\n=================== 2 failed, 54 passed, 9 warnings in 9.09s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sklearn/mixture/tests/test_bayesian_mixture.py sklearn/mixture/tests/test_gaussian_mixture.py` failed. (See above for error)",
          "test_files_run": [
            "sklearn/mixture/tests/test_bayesian_mixture.py",
            "sklearn/mixture/tests/test_gaussian_mixture.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 56,
          "failed": 0,
          "errors": 0,
          "collected": 56,
          "duration": 11.88,
          "log_tail": "sklearn/mixture/tests/test_bayesian_mixture.py::test_compare_covar_type PASSED [ 19%]\nsklearn/mixture/tests/test_bayesian_mixture.py::test_check_covariance_precision PASSED [ 21%]\nsklearn/mixture/tests/test_bayesian_mixture.py::test_invariant_translation PASSED [ 23%]\nsklearn/mixture/tests/test_bayesian_mixture.py::test_bayesian_mixture_fit_predict[0-2-1e-07] PASSED [ 25%]\nsklearn/mixture/tests/test_bayesian_mixture.py::test_bayesian_mixture_fit_predict[1-2-0.1] PASSED [ 26%]\nsklearn/mixture/tests/test_bayesian_mixture.py::test_bayesian_mixture_fit_predict[3-300-1e-07] PASSED [ 28%]\nsklearn/mixture/tests/test_bayesian_mixture.py::test_bayesian_mixture_fit_predict[4-300-0.1] PASSED [ 30%]\nsklearn/mixture/tests/test_bayesian_mixture.py::test_bayesian_mixture_fit_predict_n_init PASSED [ 32%]\nsklearn/mixture/tests/test_bayesian_mixture.py::test_bayesian_mixture_predict_predict_proba PASSED [ 33%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_gaussian_mixture_attributes PASSED [ 35%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_check_X PASSED      [ 37%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_check_weights PASSED [ 39%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_check_means PASSED  [ 41%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_check_precisions PASSED [ 42%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_suffstat_sk_full PASSED [ 44%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_suffstat_sk_tied PASSED [ 46%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_suffstat_sk_diag PASSED [ 48%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_gaussian_suffstat_sk_spherical PASSED [ 50%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_compute_log_det_cholesky PASSED [ 51%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_gaussian_mixture_log_probabilities PASSED [ 53%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_gaussian_mixture_estimate_log_prob_resp PASSED [ 55%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_gaussian_mixture_predict_predict_proba PASSED [ 57%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_gaussian_mixture_fit_predict[0-2-1e-07] PASSED [ 58%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_gaussian_mixture_fit_predict[1-2-0.1] PASSED [ 60%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_gaussian_mixture_fit_predict[3-300-1e-07] PASSED [ 62%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_gaussian_mixture_fit_predict[4-300-0.1] PASSED [ 64%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_gaussian_mixture_fit_predict_n_init PASSED [ 66%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_gaussian_mixture_fit PASSED [ 67%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_gaussian_mixture_fit_best_params PASSED [ 69%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_gaussian_mixture_fit_convergence_warning PASSED [ 71%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_multiple_init PASSED [ 73%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_gaussian_mixture_n_parameters PASSED [ 75%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_bic_1d_1component PASSED [ 76%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_gaussian_mixture_aic_bic PASSED [ 78%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_gaussian_mixture_verbose PASSED [ 80%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_warm_start[0] PASSED [ 82%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_warm_start[1] PASSED [ 83%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_warm_start[2] PASSED [ 85%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_convergence_detected_with_warm_start PASSED [ 87%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_score PASSED        [ 89%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_score_samples PASSED [ 91%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_monotonic_likelihood PASSED [ 92%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_regularisation PASSED [ 94%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_property PASSED     [ 96%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_sample PASSED       [ 98%]\nsklearn/mixture/tests/test_gaussian_mixture.py::test_init PASSED         [100%]\n\n======================== 56 passed, 9 warnings in 9.44s ========================\n\n",
          "test_files_run": [
            "sklearn/mixture/tests/test_bayesian_mixture.py",
            "sklearn/mixture/tests/test_gaussian_mixture.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "scikit-learn__scikit-learn-13496",
      "repo": "scikit-learn/scikit-learn",
      "valid": true,
      "worker": "http://34.41.233.120:8080",
      "duration": 18.389787912368774,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 19,
          "failed": 1,
          "errors": 0,
          "collected": 20,
          "duration": 9.75,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 20 items\n\nsklearn/ensemble/tests/test_iforest.py::test_iforest PASSED              [  5%]\nsklearn/ensemble/tests/test_iforest.py::test_iforest_sparse PASSED       [ 10%]\nsklearn/ensemble/tests/test_iforest.py::test_iforest_error PASSED        [ 15%]\nsklearn/ensemble/tests/test_iforest.py::test_recalculate_max_depth PASSED [ 20%]\nsklearn/ensemble/tests/test_iforest.py::test_max_samples_attribute PASSED [ 25%]\nsklearn/ensemble/tests/test_iforest.py::test_iforest_parallel_regression PASSED [ 30%]\nsklearn/ensemble/tests/test_iforest.py::test_iforest_performance PASSED  [ 35%]\nsklearn/ensemble/tests/test_iforest.py::test_iforest_works[0.25] PASSED  [ 40%]\nsklearn/ensemble/tests/test_iforest.py::test_iforest_works[auto] PASSED  [ 45%]\nsklearn/ensemble/tests/test_iforest.py::test_max_samples_consistency PASSED [ 50%]\nsklearn/ensemble/tests/test_iforest.py::test_iforest_subsampled_features PASSED [ 55%]\nsklearn/ensemble/tests/test_iforest.py::test_iforest_average_path_length PASSED [ 60%]\nsklearn/ensemble/tests/test_iforest.py::test_score_samples PASSED        [ 65%]\nsklearn/ensemble/tests/test_iforest.py::test_iforest_warm_start FAILED   [ 70%]\nsklearn/ensemble/tests/test_iforest.py::test_deprecation PASSED          [ 75%]\nsklearn/ensemble/tests/test_iforest.py::test_behaviour_param PASSED      [ 80%]\nsklearn/ensemble/tests/test_iforest.py::test_iforest_chunks_works1[0.25-3] PASSED [ 85%]\nsklearn/ensemble/tests/test_iforest.py::test_iforest_chunks_works1[auto-2] PASSED [ 90%]\nsklearn/ensemble/tests/test_iforest.py::test_iforest_chunks_works2[0.25-3] PASSED [ 95%]\nsklearn/ensemble/tests/test_iforest.py::test_iforest_chunks_works2[auto-2] PASSED [100%]\n\n=================================== FAILURES ===================================\n___________________________ test_iforest_warm_start ____________________________\nsklearn/ensemble/tests/test_iforest.py:308: in test_iforest_warm_start\n    random_state=rng, warm_start=True)\nE   TypeError: __init__() got an unexpected keyword argument 'warm_start'\n========================= 1 failed, 19 passed in 5.33s =========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sklearn/ensemble/tests/test_iforest.py` failed. (See above for error)",
          "test_files_run": [
            "sklearn/ensemble/tests/test_iforest.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 20,
          "failed": 0,
          "errors": 0,
          "collected": 20,
          "duration": 7.72,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 20 items\n\nsklearn/ensemble/tests/test_iforest.py::test_iforest PASSED              [  5%]\nsklearn/ensemble/tests/test_iforest.py::test_iforest_sparse PASSED       [ 10%]\nsklearn/ensemble/tests/test_iforest.py::test_iforest_error PASSED        [ 15%]\nsklearn/ensemble/tests/test_iforest.py::test_recalculate_max_depth PASSED [ 20%]\nsklearn/ensemble/tests/test_iforest.py::test_max_samples_attribute PASSED [ 25%]\nsklearn/ensemble/tests/test_iforest.py::test_iforest_parallel_regression PASSED [ 30%]\nsklearn/ensemble/tests/test_iforest.py::test_iforest_performance PASSED  [ 35%]\nsklearn/ensemble/tests/test_iforest.py::test_iforest_works[0.25] PASSED  [ 40%]\nsklearn/ensemble/tests/test_iforest.py::test_iforest_works[auto] PASSED  [ 45%]\nsklearn/ensemble/tests/test_iforest.py::test_max_samples_consistency PASSED [ 50%]\nsklearn/ensemble/tests/test_iforest.py::test_iforest_subsampled_features PASSED [ 55%]\nsklearn/ensemble/tests/test_iforest.py::test_iforest_average_path_length PASSED [ 60%]\nsklearn/ensemble/tests/test_iforest.py::test_score_samples PASSED        [ 65%]\nsklearn/ensemble/tests/test_iforest.py::test_iforest_warm_start PASSED   [ 70%]\nsklearn/ensemble/tests/test_iforest.py::test_deprecation PASSED          [ 75%]\nsklearn/ensemble/tests/test_iforest.py::test_behaviour_param PASSED      [ 80%]\nsklearn/ensemble/tests/test_iforest.py::test_iforest_chunks_works1[0.25-3] PASSED [ 85%]\nsklearn/ensemble/tests/test_iforest.py::test_iforest_chunks_works1[auto-2] PASSED [ 90%]\nsklearn/ensemble/tests/test_iforest.py::test_iforest_chunks_works2[0.25-3] PASSED [ 95%]\nsklearn/ensemble/tests/test_iforest.py::test_iforest_chunks_works2[auto-2] PASSED [100%]\n\n============================== 20 passed in 5.22s ==============================\n\n",
          "test_files_run": [
            "sklearn/ensemble/tests/test_iforest.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "scikit-learn__scikit-learn-14053",
      "repo": "scikit-learn/scikit-learn",
      "valid": false,
      "worker": "http://34.70.1.155:8080",
      "duration": 9.633905172348022,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 5,
          "failed": 1,
          "errors": 2,
          "collected": 8,
          "duration": 5.47,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 8 items\n\nsklearn/tree/tests/test_export.py::test_graphviz_toy PASSED              [ 12%]\nsklearn/tree/tests/test_export.py::test_graphviz_errors PASSED           [ 25%]\nsklearn/tree/tests/test_export.py::test_friedman_mse_in_graphviz PASSED  [ 37%]\nsklearn/tree/tests/test_export.py::test_precision PASSED                 [ 50%]\nsklearn/tree/tests/test_export.py::test_export_text_errors PASSED        [ 62%]\nsklearn/tree/tests/test_export.py::test_export_text FAILED               [ 75%]\nsklearn/tree/tests/test_export.py::test_plot_tree_entropy ERROR          [ 87%]\nsklearn/tree/tests/test_export.py::test_plot_tree_gini ERROR             [100%]\n\n==================================== ERRORS ====================================\n___________________ ERROR at setup of test_plot_tree_entropy ___________________\nsklearn/conftest.py:18: in pyplot\n    matplotlib.use('agg', warn=False, force=True)\nE   TypeError: use() got an unexpected keyword argument 'warn'\n____________________ ERROR at setup of test_plot_tree_gini _____________________\nsklearn/conftest.py:18: in pyplot\n    matplotlib.use('agg', warn=False, force=True)\nE   TypeError: use() got an unexpected keyword argument 'warn'\n=================================== FAILURES ===================================\n_______________________________ test_export_text _______________________________\nsklearn/tree/tests/test_export.py:409: in test_export_text\n    assert export_text(reg, decimals=1,\nsklearn/tree/export.py:893: in export_text\n    feature_names_ = [feature_names[i] for i in tree_.feature]\nsklearn/tree/export.py:893: in <listcomp>\n    feature_names_ = [feature_names[i] for i in tree_.feature]\nE   IndexError: list index out of range\n=============== 1 failed, 5 passed, 1 warning, 2 errors in 0.62s ===============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sklearn/tree/tests/test_export.py` failed. (See above for error)",
          "test_files_run": [
            "sklearn/tree/tests/test_export.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 6,
          "failed": 0,
          "errors": 2,
          "collected": 8,
          "duration": 3.21,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 8 items\n\nsklearn/tree/tests/test_export.py::test_graphviz_toy PASSED              [ 12%]\nsklearn/tree/tests/test_export.py::test_graphviz_errors PASSED           [ 25%]\nsklearn/tree/tests/test_export.py::test_friedman_mse_in_graphviz PASSED  [ 37%]\nsklearn/tree/tests/test_export.py::test_precision PASSED                 [ 50%]\nsklearn/tree/tests/test_export.py::test_export_text_errors PASSED        [ 62%]\nsklearn/tree/tests/test_export.py::test_export_text PASSED               [ 75%]\nsklearn/tree/tests/test_export.py::test_plot_tree_entropy ERROR          [ 87%]\nsklearn/tree/tests/test_export.py::test_plot_tree_gini ERROR             [100%]\n\n==================================== ERRORS ====================================\n___________________ ERROR at setup of test_plot_tree_entropy ___________________\nsklearn/conftest.py:18: in pyplot\n    matplotlib.use('agg', warn=False, force=True)\nE   TypeError: use() got an unexpected keyword argument 'warn'\n____________________ ERROR at setup of test_plot_tree_gini _____________________\nsklearn/conftest.py:18: in pyplot\n    matplotlib.use('agg', warn=False, force=True)\nE   TypeError: use() got an unexpected keyword argument 'warn'\n==================== 6 passed, 1 warning, 2 errors in 0.57s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sklearn/tree/tests/test_export.py` failed. (See above for error)",
          "test_files_run": [
            "sklearn/tree/tests/test_export.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "sphinx-doc__sphinx-8721",
      "repo": "sphinx-doc/sphinx",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10cf2d1f0>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 1
    },
    {
      "instance_id": "scikit-learn__scikit-learn-14496",
      "repo": "scikit-learn/scikit-learn",
      "valid": true,
      "worker": "http://34.70.1.155:8080",
      "duration": 16.831439971923828,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 39,
          "failed": 1,
          "errors": 0,
          "collected": 40,
          "duration": 7.98,
          "log_tail": "sklearn/cluster/tests/test_optics.py::test_the_extract_xi_labels[ordering0-clusters0-expected0] PASSED [ 22%]\nsklearn/cluster/tests/test_optics.py::test_the_extract_xi_labels[ordering1-clusters1-expected1] PASSED [ 25%]\nsklearn/cluster/tests/test_optics.py::test_the_extract_xi_labels[ordering2-clusters2-expected2] PASSED [ 27%]\nsklearn/cluster/tests/test_optics.py::test_the_extract_xi_labels[ordering3-clusters3-expected3] PASSED [ 30%]\nsklearn/cluster/tests/test_optics.py::test_extract_xi FAILED             [ 32%]\nsklearn/cluster/tests/test_optics.py::test_cluster_hierarchy_ PASSED     [ 35%]\nsklearn/cluster/tests/test_optics.py::test_correct_number_of_clusters PASSED [ 37%]\nsklearn/cluster/tests/test_optics.py::test_minimum_number_of_sample_check PASSED [ 40%]\nsklearn/cluster/tests/test_optics.py::test_bad_extract PASSED            [ 42%]\nsklearn/cluster/tests/test_optics.py::test_bad_reachability PASSED       [ 45%]\nsklearn/cluster/tests/test_optics.py::test_close_extract PASSED          [ 47%]\nsklearn/cluster/tests/test_optics.py::test_dbscan_optics_parity[3-0.1] PASSED [ 50%]\nsklearn/cluster/tests/test_optics.py::test_dbscan_optics_parity[3-0.3] PASSED [ 52%]\nsklearn/cluster/tests/test_optics.py::test_dbscan_optics_parity[3-0.5] PASSED [ 55%]\nsklearn/cluster/tests/test_optics.py::test_dbscan_optics_parity[10-0.1] PASSED [ 57%]\nsklearn/cluster/tests/test_optics.py::test_dbscan_optics_parity[10-0.3] PASSED [ 60%]\nsklearn/cluster/tests/test_optics.py::test_dbscan_optics_parity[10-0.5] PASSED [ 62%]\nsklearn/cluster/tests/test_optics.py::test_dbscan_optics_parity[20-0.1] PASSED [ 65%]\nsklearn/cluster/tests/test_optics.py::test_dbscan_optics_parity[20-0.3] PASSED [ 67%]\nsklearn/cluster/tests/test_optics.py::test_dbscan_optics_parity[20-0.5] PASSED [ 70%]\nsklearn/cluster/tests/test_optics.py::test_min_samples_edge_case PASSED  [ 72%]\nsklearn/cluster/tests/test_optics.py::test_min_cluster_size[2] PASSED    [ 75%]\nsklearn/cluster/tests/test_optics.py::test_min_cluster_size_invalid[0] PASSED [ 77%]\nsklearn/cluster/tests/test_optics.py::test_min_cluster_size_invalid[-1] PASSED [ 80%]\nsklearn/cluster/tests/test_optics.py::test_min_cluster_size_invalid[1.1] PASSED [ 82%]\nsklearn/cluster/tests/test_optics.py::test_min_cluster_size_invalid[2.2] PASSED [ 85%]\nsklearn/cluster/tests/test_optics.py::test_min_cluster_size_invalid2 PASSED [ 87%]\nsklearn/cluster/tests/test_optics.py::test_processing_order PASSED       [ 90%]\nsklearn/cluster/tests/test_optics.py::test_compare_to_ELKI PASSED        [ 92%]\nsklearn/cluster/tests/test_optics.py::test_wrong_cluster_method PASSED   [ 95%]\nsklearn/cluster/tests/test_optics.py::test_extract_dbscan PASSED         [ 97%]\nsklearn/cluster/tests/test_optics.py::test_precomputed_dists PASSED      [100%]\n\n=================================== FAILURES ===================================\n_______________________________ test_extract_xi ________________________________\nsklearn/cluster/tests/test_optics.py:107: in test_extract_xi\n    xi=0.4).fit(X)\nsklearn/cluster/optics_.py:248: in fit\n    max_eps=self.max_eps)\nsklearn/cluster/optics_.py:456: in compute_optics_graph\n    nbrs.fit(X)\nsklearn/neighbors/base.py:932: in fit\n    return self._fit(X)\nsklearn/neighbors/base.py:276: in _fit\n    type(self.n_neighbors))\nE   TypeError: n_neighbors does not take <class 'float'> value, enter integer value\n=================== 1 failed, 39 passed, 1 warning in 5.37s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sklearn/cluster/tests/test_optics.py` failed. (See above for error)",
          "test_files_run": [
            "sklearn/cluster/tests/test_optics.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 40,
          "failed": 0,
          "errors": 0,
          "collected": 40,
          "duration": 7.96,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 40 items\n\nsklearn/cluster/tests/test_optics.py::test_extend_downward[r_plot0-3] PASSED [  2%]\nsklearn/cluster/tests/test_optics.py::test_extend_downward[r_plot1-0] PASSED [  5%]\nsklearn/cluster/tests/test_optics.py::test_extend_downward[r_plot2-4] PASSED [  7%]\nsklearn/cluster/tests/test_optics.py::test_extend_downward[r_plot3-4] PASSED [ 10%]\nsklearn/cluster/tests/test_optics.py::test_extend_upward[r_plot0-6] PASSED [ 12%]\nsklearn/cluster/tests/test_optics.py::test_extend_upward[r_plot1-0] PASSED [ 15%]\nsklearn/cluster/tests/test_optics.py::test_extend_upward[r_plot2-0] PASSED [ 17%]\nsklearn/cluster/tests/test_optics.py::test_extend_upward[r_plot3-2] PASSED [ 20%]\nsklearn/cluster/tests/test_optics.py::test_the_extract_xi_labels[ordering0-clusters0-expected0] PASSED [ 22%]\nsklearn/cluster/tests/test_optics.py::test_the_extract_xi_labels[ordering1-clusters1-expected1] PASSED [ 25%]\nsklearn/cluster/tests/test_optics.py::test_the_extract_xi_labels[ordering2-clusters2-expected2] PASSED [ 27%]\nsklearn/cluster/tests/test_optics.py::test_the_extract_xi_labels[ordering3-clusters3-expected3] PASSED [ 30%]\nsklearn/cluster/tests/test_optics.py::test_extract_xi PASSED             [ 32%]\nsklearn/cluster/tests/test_optics.py::test_cluster_hierarchy_ PASSED     [ 35%]\nsklearn/cluster/tests/test_optics.py::test_correct_number_of_clusters PASSED [ 37%]\nsklearn/cluster/tests/test_optics.py::test_minimum_number_of_sample_check PASSED [ 40%]\nsklearn/cluster/tests/test_optics.py::test_bad_extract PASSED            [ 42%]\nsklearn/cluster/tests/test_optics.py::test_bad_reachability PASSED       [ 45%]\nsklearn/cluster/tests/test_optics.py::test_close_extract PASSED          [ 47%]\nsklearn/cluster/tests/test_optics.py::test_dbscan_optics_parity[3-0.1] PASSED [ 50%]\nsklearn/cluster/tests/test_optics.py::test_dbscan_optics_parity[3-0.3] PASSED [ 52%]\nsklearn/cluster/tests/test_optics.py::test_dbscan_optics_parity[3-0.5] PASSED [ 55%]\nsklearn/cluster/tests/test_optics.py::test_dbscan_optics_parity[10-0.1] PASSED [ 57%]\nsklearn/cluster/tests/test_optics.py::test_dbscan_optics_parity[10-0.3] PASSED [ 60%]\nsklearn/cluster/tests/test_optics.py::test_dbscan_optics_parity[10-0.5] PASSED [ 62%]\nsklearn/cluster/tests/test_optics.py::test_dbscan_optics_parity[20-0.1] PASSED [ 65%]\nsklearn/cluster/tests/test_optics.py::test_dbscan_optics_parity[20-0.3] PASSED [ 67%]\nsklearn/cluster/tests/test_optics.py::test_dbscan_optics_parity[20-0.5] PASSED [ 70%]\nsklearn/cluster/tests/test_optics.py::test_min_samples_edge_case PASSED  [ 72%]\nsklearn/cluster/tests/test_optics.py::test_min_cluster_size[2] PASSED    [ 75%]\nsklearn/cluster/tests/test_optics.py::test_min_cluster_size_invalid[0] PASSED [ 77%]\nsklearn/cluster/tests/test_optics.py::test_min_cluster_size_invalid[-1] PASSED [ 80%]\nsklearn/cluster/tests/test_optics.py::test_min_cluster_size_invalid[1.1] PASSED [ 82%]\nsklearn/cluster/tests/test_optics.py::test_min_cluster_size_invalid[2.2] PASSED [ 85%]\nsklearn/cluster/tests/test_optics.py::test_min_cluster_size_invalid2 PASSED [ 87%]\nsklearn/cluster/tests/test_optics.py::test_processing_order PASSED       [ 90%]\nsklearn/cluster/tests/test_optics.py::test_compare_to_ELKI PASSED        [ 92%]\nsklearn/cluster/tests/test_optics.py::test_wrong_cluster_method PASSED   [ 95%]\nsklearn/cluster/tests/test_optics.py::test_extract_dbscan PASSED         [ 97%]\nsklearn/cluster/tests/test_optics.py::test_precomputed_dists PASSED      [100%]\n\n======================== 40 passed, 1 warning in 5.38s =========================\n\n",
          "test_files_run": [
            "sklearn/cluster/tests/test_optics.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "scikit-learn__scikit-learn-12682",
      "repo": "scikit-learn/scikit-learn",
      "valid": true,
      "worker": "http://34.59.30.169:8080",
      "duration": 61.75840616226196,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 66,
          "failed": 1,
          "errors": 0,
          "collected": 67,
          "duration": 35.84,
          "log_tail": "sklearn/decomposition/tests/test_dict_learning.py::test_dict_learning_online_lars_positive_parameter PASSED [ 41%]\nsklearn/decomposition/tests/test_dict_learning.py::test_minibatch_dictionary_learning_positivity[False-False-lasso_lars] PASSED [ 43%]\nsklearn/decomposition/tests/test_dict_learning.py::test_minibatch_dictionary_learning_positivity[False-False-lasso_cd] PASSED [ 44%]\nsklearn/decomposition/tests/test_dict_learning.py::test_minibatch_dictionary_learning_positivity[False-False-threshold] PASSED [ 46%]\nsklearn/decomposition/tests/test_dict_learning.py::test_minibatch_dictionary_learning_positivity[False-True-lasso_lars] PASSED [ 47%]\nsklearn/decomposition/tests/test_dict_learning.py::test_minibatch_dictionary_learning_positivity[False-True-lasso_cd] PASSED [ 49%]\nsklearn/decomposition/tests/test_dict_learning.py::test_minibatch_dictionary_learning_positivity[False-True-threshold] PASSED [ 50%]\nsklearn/decomposition/tests/test_dict_learning.py::test_minibatch_dictionary_learning_positivity[True-False-lasso_lars] PASSED [ 52%]\nsklearn/decomposition/tests/test_dict_learning.py::test_minibatch_dictionary_learning_positivity[True-False-lasso_cd] PASSED [ 53%]\nsklearn/decomposition/tests/test_dict_learning.py::test_minibatch_dictionary_learning_positivity[True-False-threshold] PASSED [ 55%]\nsklearn/decomposition/tests/test_dict_learning.py::test_minibatch_dictionary_learning_positivity[True-True-lasso_lars] PASSED [ 56%]\nsklearn/decomposition/tests/test_dict_learning.py::test_minibatch_dictionary_learning_positivity[True-True-lasso_cd] PASSED [ 58%]\nsklearn/decomposition/tests/test_dict_learning.py::test_minibatch_dictionary_learning_positivity[True-True-threshold] PASSED [ 59%]\nsklearn/decomposition/tests/test_dict_learning.py::test_minibatch_dictionary_learning_lars[False] PASSED [ 61%]\nsklearn/decomposition/tests/test_dict_learning.py::test_minibatch_dictionary_learning_lars[True] PASSED [ 62%]\nsklearn/decomposition/tests/test_dict_learning.py::test_dict_learning_online_positivity[False-False] PASSED [ 64%]\nsklearn/decomposition/tests/test_dict_learning.py::test_dict_learning_online_positivity[False-True] PASSED [ 65%]\nsklearn/decomposition/tests/test_dict_learning.py::test_dict_learning_online_positivity[True-False] PASSED [ 67%]\nsklearn/decomposition/tests/test_dict_learning.py::test_dict_learning_online_positivity[True-True] PASSED [ 68%]\nsklearn/decomposition/tests/test_dict_learning.py::test_dict_learning_online_verbosity PASSED [ 70%]\nsklearn/decomposition/tests/test_dict_learning.py::test_dict_learning_online_estimator_shapes PASSED [ 71%]\nsklearn/decomposition/tests/test_dict_learning.py::test_dict_learning_online_overcomplete PASSED [ 73%]\nsklearn/decomposition/tests/test_dict_learning.py::test_dict_learning_online_initialization PASSED [ 74%]\nsklearn/decomposition/tests/test_dict_learning.py::test_dict_learning_online_readonly_initialization PASSED [ 76%]\nsklearn/decomposition/tests/test_dict_learning.py::test_dict_learning_online_partial_fit PASSED [ 77%]\nsklearn/decomposition/tests/test_dict_learning.py::test_sparse_encode_shapes PASSED [ 79%]\nsklearn/decomposition/tests/test_dict_learning.py::test_sparse_encode_positivity[False-lasso_lars] PASSED [ 80%]\nsklearn/decomposition/tests/test_dict_learning.py::test_sparse_encode_positivity[False-lasso_cd] PASSED [ 82%]\nsklearn/decomposition/tests/test_dict_learning.py::test_sparse_encode_positivity[False-threshold] PASSED [ 83%]\nsklearn/decomposition/tests/test_dict_learning.py::test_sparse_encode_positivity[True-lasso_lars] PASSED [ 85%]\nsklearn/decomposition/tests/test_dict_learning.py::test_sparse_encode_positivity[True-lasso_cd] PASSED [ 86%]\nsklearn/decomposition/tests/test_dict_learning.py::test_sparse_encode_positivity[True-threshold] PASSED [ 88%]\nsklearn/decomposition/tests/test_dict_learning.py::test_sparse_encode_unavailable_positivity[lars] PASSED [ 89%]\nsklearn/decomposition/tests/test_dict_learning.py::test_sparse_encode_unavailable_positivity[omp] PASSED [ 91%]\nsklearn/decomposition/tests/test_dict_learning.py::test_sparse_encode_input PASSED [ 92%]\nsklearn/decomposition/tests/test_dict_learning.py::test_sparse_encode_error PASSED [ 94%]\nsklearn/decomposition/tests/test_dict_learning.py::test_sparse_encode_error_default_sparsity PASSED [ 95%]\nsklearn/decomposition/tests/test_dict_learning.py::test_unknown_method PASSED [ 97%]\nsklearn/decomposition/tests/test_dict_learning.py::test_sparse_coder_estimator PASSED [ 98%]\nsklearn/decomposition/tests/test_dict_learning.py::test_sparse_coder_parallel_mmap PASSED [100%]\n\n=================================== FAILURES ===================================\n________________________________ test_max_iter _________________________________\nsklearn/decomposition/tests/test_dict_learning.py:97: in test_max_iter\n    transform_max_iter=1)\nE   TypeError: __init__() got an unexpected keyword argument 'transform_max_iter'\n=================== 1 failed, 66 passed, 1 warning in 21.01s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sklearn/decomposition/tests/test_dict_learning.py` failed. (See above for error)",
          "test_files_run": [
            "sklearn/decomposition/tests/test_dict_learning.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 67,
          "failed": 0,
          "errors": 0,
          "collected": 67,
          "duration": 24.81,
          "log_tail": "sklearn/decomposition/tests/test_dict_learning.py::test_dict_learning_reconstruction_parallel PASSED [ 32%]\nsklearn/decomposition/tests/test_dict_learning.py::test_dict_learning_lassocd_readonly_data PASSED [ 34%]\nsklearn/decomposition/tests/test_dict_learning.py::test_dict_learning_nonzero_coefs PASSED [ 35%]\nsklearn/decomposition/tests/test_dict_learning.py::test_dict_learning_unknown_fit_algorithm PASSED [ 37%]\nsklearn/decomposition/tests/test_dict_learning.py::test_dict_learning_split PASSED [ 38%]\nsklearn/decomposition/tests/test_dict_learning.py::test_dict_learning_online_shapes PASSED [ 40%]\nsklearn/decomposition/tests/test_dict_learning.py::test_dict_learning_online_lars_positive_parameter PASSED [ 41%]\nsklearn/decomposition/tests/test_dict_learning.py::test_minibatch_dictionary_learning_positivity[False-False-lasso_lars] PASSED [ 43%]\nsklearn/decomposition/tests/test_dict_learning.py::test_minibatch_dictionary_learning_positivity[False-False-lasso_cd] PASSED [ 44%]\nsklearn/decomposition/tests/test_dict_learning.py::test_minibatch_dictionary_learning_positivity[False-False-threshold] PASSED [ 46%]\nsklearn/decomposition/tests/test_dict_learning.py::test_minibatch_dictionary_learning_positivity[False-True-lasso_lars] PASSED [ 47%]\nsklearn/decomposition/tests/test_dict_learning.py::test_minibatch_dictionary_learning_positivity[False-True-lasso_cd] PASSED [ 49%]\nsklearn/decomposition/tests/test_dict_learning.py::test_minibatch_dictionary_learning_positivity[False-True-threshold] PASSED [ 50%]\nsklearn/decomposition/tests/test_dict_learning.py::test_minibatch_dictionary_learning_positivity[True-False-lasso_lars] PASSED [ 52%]\nsklearn/decomposition/tests/test_dict_learning.py::test_minibatch_dictionary_learning_positivity[True-False-lasso_cd] PASSED [ 53%]\nsklearn/decomposition/tests/test_dict_learning.py::test_minibatch_dictionary_learning_positivity[True-False-threshold] PASSED [ 55%]\nsklearn/decomposition/tests/test_dict_learning.py::test_minibatch_dictionary_learning_positivity[True-True-lasso_lars] PASSED [ 56%]\nsklearn/decomposition/tests/test_dict_learning.py::test_minibatch_dictionary_learning_positivity[True-True-lasso_cd] PASSED [ 58%]\nsklearn/decomposition/tests/test_dict_learning.py::test_minibatch_dictionary_learning_positivity[True-True-threshold] PASSED [ 59%]\nsklearn/decomposition/tests/test_dict_learning.py::test_minibatch_dictionary_learning_lars[False] PASSED [ 61%]\nsklearn/decomposition/tests/test_dict_learning.py::test_minibatch_dictionary_learning_lars[True] PASSED [ 62%]\nsklearn/decomposition/tests/test_dict_learning.py::test_dict_learning_online_positivity[False-False] PASSED [ 64%]\nsklearn/decomposition/tests/test_dict_learning.py::test_dict_learning_online_positivity[False-True] PASSED [ 65%]\nsklearn/decomposition/tests/test_dict_learning.py::test_dict_learning_online_positivity[True-False] PASSED [ 67%]\nsklearn/decomposition/tests/test_dict_learning.py::test_dict_learning_online_positivity[True-True] PASSED [ 68%]\nsklearn/decomposition/tests/test_dict_learning.py::test_dict_learning_online_verbosity PASSED [ 70%]\nsklearn/decomposition/tests/test_dict_learning.py::test_dict_learning_online_estimator_shapes PASSED [ 71%]\nsklearn/decomposition/tests/test_dict_learning.py::test_dict_learning_online_overcomplete PASSED [ 73%]\nsklearn/decomposition/tests/test_dict_learning.py::test_dict_learning_online_initialization PASSED [ 74%]\nsklearn/decomposition/tests/test_dict_learning.py::test_dict_learning_online_readonly_initialization PASSED [ 76%]\nsklearn/decomposition/tests/test_dict_learning.py::test_dict_learning_online_partial_fit PASSED [ 77%]\nsklearn/decomposition/tests/test_dict_learning.py::test_sparse_encode_shapes PASSED [ 79%]\nsklearn/decomposition/tests/test_dict_learning.py::test_sparse_encode_positivity[False-lasso_lars] PASSED [ 80%]\nsklearn/decomposition/tests/test_dict_learning.py::test_sparse_encode_positivity[False-lasso_cd] PASSED [ 82%]\nsklearn/decomposition/tests/test_dict_learning.py::test_sparse_encode_positivity[False-threshold] PASSED [ 83%]\nsklearn/decomposition/tests/test_dict_learning.py::test_sparse_encode_positivity[True-lasso_lars] PASSED [ 85%]\nsklearn/decomposition/tests/test_dict_learning.py::test_sparse_encode_positivity[True-lasso_cd] PASSED [ 86%]\nsklearn/decomposition/tests/test_dict_learning.py::test_sparse_encode_positivity[True-threshold] PASSED [ 88%]\nsklearn/decomposition/tests/test_dict_learning.py::test_sparse_encode_unavailable_positivity[lars] PASSED [ 89%]\nsklearn/decomposition/tests/test_dict_learning.py::test_sparse_encode_unavailable_positivity[omp] PASSED [ 91%]\nsklearn/decomposition/tests/test_dict_learning.py::test_sparse_encode_input PASSED [ 92%]\nsklearn/decomposition/tests/test_dict_learning.py::test_sparse_encode_error PASSED [ 94%]\nsklearn/decomposition/tests/test_dict_learning.py::test_sparse_encode_error_default_sparsity PASSED [ 95%]\nsklearn/decomposition/tests/test_dict_learning.py::test_unknown_method PASSED [ 97%]\nsklearn/decomposition/tests/test_dict_learning.py::test_sparse_coder_estimator PASSED [ 98%]\nsklearn/decomposition/tests/test_dict_learning.py::test_sparse_coder_parallel_mmap PASSED [100%]\n\n======================== 67 passed, 1 warning in 20.82s ========================\n\n",
          "test_files_run": [
            "sklearn/decomposition/tests/test_dict_learning.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "scikit-learn__scikit-learn-14983",
      "repo": "scikit-learn/scikit-learn",
      "valid": true,
      "worker": "http://34.70.1.155:8080",
      "duration": 9.636332035064697,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 105,
          "failed": 2,
          "errors": 0,
          "collected": 107,
          "duration": 4.47,
          "log_tail": "sklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes2[0.8-11] PASSED [ 71%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_default_test_size[None-7-3] PASSED [ 71%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_default_test_size[8-8-2] PASSED [ 72%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_default_test_size[0.8-8-2] PASSED [ 73%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split PASSED [ 74%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_pandas PASSED [ 75%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_sparse PASSED [ 76%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_mock_pandas PASSED [ 77%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_list_input PASSED [ 78%]\nsklearn/model_selection/tests/test_split.py::test_shufflesplit_errors[2.0-None] PASSED [ 79%]\nsklearn/model_selection/tests/test_split.py::test_shufflesplit_errors[1.0-None] PASSED [ 80%]\nsklearn/model_selection/tests/test_split.py::test_shufflesplit_errors[0.1-0.95] PASSED [ 81%]\nsklearn/model_selection/tests/test_split.py::test_shufflesplit_errors[None-train_size3] PASSED [ 82%]\nsklearn/model_selection/tests/test_split.py::test_shufflesplit_errors[11-None] PASSED [ 83%]\nsklearn/model_selection/tests/test_split.py::test_shufflesplit_errors[10-None] PASSED [ 84%]\nsklearn/model_selection/tests/test_split.py::test_shufflesplit_errors[8-3] PASSED [ 85%]\nsklearn/model_selection/tests/test_split.py::test_shufflesplit_reproducible PASSED [ 85%]\nsklearn/model_selection/tests/test_split.py::test_stratifiedshufflesplit_list_input PASSED [ 86%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_allow_nans PASSED [ 87%]\nsklearn/model_selection/tests/test_split.py::test_check_cv PASSED        [ 88%]\nsklearn/model_selection/tests/test_split.py::test_cv_iterable_wrapper PASSED [ 89%]\nsklearn/model_selection/tests/test_split.py::test_group_kfold PASSED     [ 90%]\nsklearn/model_selection/tests/test_split.py::test_time_series_cv PASSED  [ 91%]\nsklearn/model_selection/tests/test_split.py::test_time_series_max_train_size PASSED [ 92%]\nsklearn/model_selection/tests/test_split.py::test_nested_cv PASSED       [ 93%]\nsklearn/model_selection/tests/test_split.py::test_build_repr PASSED      [ 94%]\nsklearn/model_selection/tests/test_split.py::test_shuffle_split_empty_trainset[ShuffleSplit] PASSED [ 95%]\nsklearn/model_selection/tests/test_split.py::test_shuffle_split_empty_trainset[GroupShuffleSplit] PASSED [ 96%]\nsklearn/model_selection/tests/test_split.py::test_shuffle_split_empty_trainset[StratifiedShuffleSplit] PASSED [ 97%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_empty_trainset PASSED [ 98%]\nsklearn/model_selection/tests/test_split.py::test_leave_one_out_empty_trainset PASSED [ 99%]\nsklearn/model_selection/tests/test_split.py::test_leave_p_out_empty_trainset PASSED [100%]\n\n=================================== FAILURES ===================================\n_____________________ test_repeated_cv_repr[RepeatedKFold] _____________________\nsklearn/model_selection/tests/test_split.py:991: in test_repeated_cv_repr\n    assert repeated_cv_repr == repr(repeated_cv)\nE   AssertionError: assert 'RepeatedKFol...m_state=None)' == '<sklearn.mod...727c96b82710>'\nE     - <sklearn.model_selection._split.RepeatedKFold object at 0x727c96b82710>\nE     + RepeatedKFold(n_repeats=6, n_splits=2, random_state=None)\n________________ test_repeated_cv_repr[RepeatedStratifiedKFold] ________________\nsklearn/model_selection/tests/test_split.py:991: in test_repeated_cv_repr\n    assert repeated_cv_repr == repr(repeated_cv)\nE   AssertionError: assert 'RepeatedStra...m_state=None)' == '<sklearn.mod...727c9f464358>'\nE     - <sklearn.model_selection._split.RepeatedStratifiedKFold object at 0x727c9f464358>\nE     + RepeatedStratifiedKFold(n_repeats=6, n_splits=2, random_state=None)\n================= 2 failed, 105 passed, 122 warnings in 1.89s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sklearn/model_selection/tests/test_split.py` failed. (See above for error)",
          "test_files_run": [
            "sklearn/model_selection/tests/test_split.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 107,
          "failed": 0,
          "errors": 0,
          "collected": 107,
          "duration": 4.31,
          "log_tail": "sklearn/model_selection/tests/test_split.py::test_train_test_split_errors PASSED [ 57%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes1[1.2-0.8] PASSED [ 58%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes1[1.0-0.8] PASSED [ 59%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes1[0.0-0.8] PASSED [ 60%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes1[-0.2-0.8] PASSED [ 61%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes1[0.8-1.2] PASSED [ 62%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes1[0.8-1.0] PASSED [ 63%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes1[0.8-0.0] PASSED [ 64%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes1[0.8--0.2] PASSED [ 65%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes2[-10-0.8] PASSED [ 66%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes2[0-0.8] PASSED [ 67%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes2[11-0.8] PASSED [ 68%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes2[0.8--10] PASSED [ 69%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes2[0.8-0] PASSED [ 70%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_invalid_sizes2[0.8-11] PASSED [ 71%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_default_test_size[None-7-3] PASSED [ 71%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_default_test_size[8-8-2] PASSED [ 72%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_default_test_size[0.8-8-2] PASSED [ 73%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split PASSED [ 74%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_pandas PASSED [ 75%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_sparse PASSED [ 76%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_mock_pandas PASSED [ 77%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_list_input PASSED [ 78%]\nsklearn/model_selection/tests/test_split.py::test_shufflesplit_errors[2.0-None] PASSED [ 79%]\nsklearn/model_selection/tests/test_split.py::test_shufflesplit_errors[1.0-None] PASSED [ 80%]\nsklearn/model_selection/tests/test_split.py::test_shufflesplit_errors[0.1-0.95] PASSED [ 81%]\nsklearn/model_selection/tests/test_split.py::test_shufflesplit_errors[None-train_size3] PASSED [ 82%]\nsklearn/model_selection/tests/test_split.py::test_shufflesplit_errors[11-None] PASSED [ 83%]\nsklearn/model_selection/tests/test_split.py::test_shufflesplit_errors[10-None] PASSED [ 84%]\nsklearn/model_selection/tests/test_split.py::test_shufflesplit_errors[8-3] PASSED [ 85%]\nsklearn/model_selection/tests/test_split.py::test_shufflesplit_reproducible PASSED [ 85%]\nsklearn/model_selection/tests/test_split.py::test_stratifiedshufflesplit_list_input PASSED [ 86%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_allow_nans PASSED [ 87%]\nsklearn/model_selection/tests/test_split.py::test_check_cv PASSED        [ 88%]\nsklearn/model_selection/tests/test_split.py::test_cv_iterable_wrapper PASSED [ 89%]\nsklearn/model_selection/tests/test_split.py::test_group_kfold PASSED     [ 90%]\nsklearn/model_selection/tests/test_split.py::test_time_series_cv PASSED  [ 91%]\nsklearn/model_selection/tests/test_split.py::test_time_series_max_train_size PASSED [ 92%]\nsklearn/model_selection/tests/test_split.py::test_nested_cv PASSED       [ 93%]\nsklearn/model_selection/tests/test_split.py::test_build_repr PASSED      [ 94%]\nsklearn/model_selection/tests/test_split.py::test_shuffle_split_empty_trainset[ShuffleSplit] PASSED [ 95%]\nsklearn/model_selection/tests/test_split.py::test_shuffle_split_empty_trainset[GroupShuffleSplit] PASSED [ 96%]\nsklearn/model_selection/tests/test_split.py::test_shuffle_split_empty_trainset[StratifiedShuffleSplit] PASSED [ 97%]\nsklearn/model_selection/tests/test_split.py::test_train_test_split_empty_trainset PASSED [ 98%]\nsklearn/model_selection/tests/test_split.py::test_leave_one_out_empty_trainset PASSED [ 99%]\nsklearn/model_selection/tests/test_split.py::test_leave_p_out_empty_trainset PASSED [100%]\n\n====================== 107 passed, 122 warnings in 1.81s =======================\n\n",
          "test_files_run": [
            "sklearn/model_selection/tests/test_split.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "scikit-learn__scikit-learn-14141",
      "repo": "scikit-learn/scikit-learn",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 31.68627405166626,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 2,
          "failed": 1,
          "errors": 0,
          "collected": 3,
          "duration": 6.07,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 3 items\n\nsklearn/utils/tests/test_show_versions.py::test_get_sys_info PASSED      [ 33%]\nsklearn/utils/tests/test_show_versions.py::test_get_deps_info FAILED     [ 66%]\nsklearn/utils/tests/test_show_versions.py::test_show_versions_with_blas PASSED [100%]\n\n=================================== FAILURES ===================================\n______________________________ test_get_deps_info ______________________________\nsklearn/utils/tests/test_show_versions.py:26: in test_get_deps_info\n    assert 'joblib' in deps_info\nE   AssertionError: assert 'joblib' in {'Cython': '0.29.24', 'matplotlib': '3.3.4', 'numpy': '1.19.2', 'pandas': '1.1.5', ...}\n========================= 1 failed, 2 passed in 1.27s ==========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sklearn/utils/tests/test_show_versions.py` failed. (See above for error)",
          "test_files_run": [
            "sklearn/utils/tests/test_show_versions.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 3,
          "failed": 0,
          "errors": 0,
          "collected": 3,
          "duration": 5.62,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 3 items\n\nsklearn/utils/tests/test_show_versions.py::test_get_sys_info PASSED      [ 33%]\nsklearn/utils/tests/test_show_versions.py::test_get_deps_info PASSED     [ 66%]\nsklearn/utils/tests/test_show_versions.py::test_show_versions_with_blas PASSED [100%]\n\n============================== 3 passed in 0.96s ===============================\n\n",
          "test_files_run": [
            "sklearn/utils/tests/test_show_versions.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "scikit-learn__scikit-learn-14710",
      "repo": "scikit-learn/scikit-learn",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 21.825905084609985,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 79,
          "failed": 1,
          "errors": 0,
          "collected": 80,
          "duration": 10.76,
          "log_tail": "sklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_should_stop[scores8-5-0.001-True] PASSED [ 78%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_should_stop[scores9-5-5-True] PASSED [ 80%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_binning_train_validation_are_separated PASSED [ 81%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_missing_values_trivial PASSED [ 82%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_missing_values_resilience[0.1-0.97-0.89-classification] PASSED [ 83%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_missing_values_resilience[0.1-0.97-0.89-regression] PASSED [ 85%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_missing_values_resilience[0.2-0.93-0.81-classification] PASSED [ 86%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_missing_values_resilience[0.2-0.93-0.81-regression] PASSED [ 87%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_missing_values_resilience[0.5-0.79-0.52-classification] PASSED [ 88%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_missing_values_resilience[0.5-0.79-0.52-regression] PASSED [ 90%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_zero_division_hessians[binary_crossentropy] PASSED [ 91%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_zero_division_hessians[categorical_crossentropy] PASSED [ 92%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_small_trainset PASSED [ 93%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_missing_values_minmax_imputation PASSED [ 95%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_infinite_values PASSED [ 96%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_infinite_values_missing_values PASSED [ 97%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_string_target_early_stopping[None] FAILED [ 98%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_string_target_early_stopping[loss] PASSED [100%]\n\n=================================== FAILURES ===================================\n___________________ test_string_target_early_stopping[None] ____________________\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py:428: in test_string_target_early_stopping\n    gbrt.fit(X, y)\nsklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:254: in fit\n    X_binned_val, y_val,\nsklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:430: in _check_early_stopping_scorer\n    self.scorer_(self, X_binned_small_train, y_small_train)\nsklearn/metrics/scorer.py:241: in _passthrough_scorer\n    return estimator.score(*args, **kwargs)\nsklearn/base.py:368: in score\n    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\nsklearn/metrics/classification.py:176: in accuracy_score\n    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\nsklearn/metrics/classification.py:94: in _check_targets\n    unique_values = np.union1d(y_true, y_pred)\n<__array_function__ internals>:6: in union1d\n    ???\n/opt/miniconda3/envs/testbed/lib/python3.6/site-packages/numpy/lib/arraysetops.py:749: in union1d\n    return unique(np.concatenate((ar1, ar2), axis=None))\n<__array_function__ internals>:6: in unique\n    ???\n/opt/miniconda3/envs/testbed/lib/python3.6/site-packages/numpy/lib/arraysetops.py:261: in unique\n    ret = _unique1d(ar, return_index, return_inverse, return_counts)\n/opt/miniconda3/envs/testbed/lib/python3.6/site-packages/numpy/lib/arraysetops.py:322: in _unique1d\n    ar.sort()\nE   TypeError: '<' not supported between instances of 'str' and 'float'\n=================== 1 failed, 79 passed, 1 warning in 8.33s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py` failed. (See above for error)",
          "test_files_run": [
            "sklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 80,
          "failed": 0,
          "errors": 0,
          "collected": 80,
          "duration": 10.21,
          "log_tail": "sklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_early_stopping_regression[neg_mean_squared_error-None-5-0.1] PASSED [ 43%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_early_stopping_regression[None-0.1-5-1e-07] PASSED [ 45%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_early_stopping_regression[None-None-5-0.1] PASSED [ 46%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_early_stopping_regression[loss-0.1-5-1e-07] PASSED [ 47%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_early_stopping_regression[loss-None-5-0.1] PASSED [ 48%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_early_stopping_regression[None-None-None-None] PASSED [ 50%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_early_stopping_classification[accuracy-0.1-5-1e-07-data0] PASSED [ 51%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_early_stopping_classification[accuracy-0.1-5-1e-07-data1] PASSED [ 52%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_early_stopping_classification[accuracy-None-5-0.1-data0] PASSED [ 53%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_early_stopping_classification[accuracy-None-5-0.1-data1] PASSED [ 55%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_early_stopping_classification[None-0.1-5-1e-07-data0] PASSED [ 56%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_early_stopping_classification[None-0.1-5-1e-07-data1] PASSED [ 57%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_early_stopping_classification[None-None-5-0.1-data0] PASSED [ 58%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_early_stopping_classification[None-None-5-0.1-data1] PASSED [ 60%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_early_stopping_classification[loss-0.1-5-1e-07-data0] PASSED [ 61%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_early_stopping_classification[loss-0.1-5-1e-07-data1] PASSED [ 62%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_early_stopping_classification[loss-None-5-0.1-data0] PASSED [ 63%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_early_stopping_classification[loss-None-5-0.1-data1] PASSED [ 65%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_early_stopping_classification[None-None-None-None-data0] PASSED [ 66%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_early_stopping_classification[None-None-None-None-data1] PASSED [ 67%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_should_stop[scores0-1-0.001-False] PASSED [ 68%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_should_stop[scores1-5-0.001-False] PASSED [ 70%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_should_stop[scores2-5-0.001-False] PASSED [ 71%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_should_stop[scores3-5-0.001-False] PASSED [ 72%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_should_stop[scores4-5-0.0-False] PASSED [ 73%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_should_stop[scores5-5-0.999-False] PASSED [ 75%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_should_stop[scores6-5-4.99999-False] PASSED [ 76%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_should_stop[scores7-5-0.0-True] PASSED [ 77%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_should_stop[scores8-5-0.001-True] PASSED [ 78%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_should_stop[scores9-5-5-True] PASSED [ 80%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_binning_train_validation_are_separated PASSED [ 81%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_missing_values_trivial PASSED [ 82%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_missing_values_resilience[0.1-0.97-0.89-classification] PASSED [ 83%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_missing_values_resilience[0.1-0.97-0.89-regression] PASSED [ 85%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_missing_values_resilience[0.2-0.93-0.81-classification] PASSED [ 86%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_missing_values_resilience[0.2-0.93-0.81-regression] PASSED [ 87%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_missing_values_resilience[0.5-0.79-0.52-classification] PASSED [ 88%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_missing_values_resilience[0.5-0.79-0.52-regression] PASSED [ 90%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_zero_division_hessians[binary_crossentropy] PASSED [ 91%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_zero_division_hessians[categorical_crossentropy] PASSED [ 92%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_small_trainset PASSED [ 93%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_missing_values_minmax_imputation PASSED [ 95%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_infinite_values PASSED [ 96%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_infinite_values_missing_values PASSED [ 97%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_string_target_early_stopping[None] PASSED [ 98%]\nsklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py::test_string_target_early_stopping[loss] PASSED [100%]\n\n======================== 80 passed, 1 warning in 7.77s =========================\n\n",
          "test_files_run": [
            "sklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "scikit-learn__scikit-learn-14894",
      "repo": "scikit-learn/scikit-learn",
      "valid": true,
      "worker": "http://34.59.30.169:8080",
      "duration": 20.314286947250366,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 85,
          "failed": 1,
          "errors": 0,
          "collected": 86,
          "duration": 10.04,
          "log_tail": "sklearn/svm/tests/test_svm.py::test_svm_gamma_error[NuSVR-data3] PASSED  [ 59%]\nsklearn/svm/tests/test_svm.py::test_svm_gamma_error[OneClassSVM-data4] PASSED [ 60%]\nsklearn/svm/tests/test_svm.py::test_unicode_kernel PASSED                [ 61%]\nsklearn/svm/tests/test_svm.py::test_sparse_precomputed PASSED            [ 62%]\nsklearn/svm/tests/test_svm.py::test_sparse_fit_support_vectors_empty FAILED [ 63%]\nsklearn/svm/tests/test_svm.py::test_linearsvc_parameters PASSED          [ 65%]\nsklearn/svm/tests/test_svm.py::test_linearsvx_loss_penalty_deprecations PASSED [ 66%]\nsklearn/svm/tests/test_svm.py::test_linear_svx_uppercase_loss_penality_raises_error PASSED [ 67%]\nsklearn/svm/tests/test_svm.py::test_linearsvc PASSED                     [ 68%]\nsklearn/svm/tests/test_svm.py::test_linearsvc_crammer_singer PASSED      [ 69%]\nsklearn/svm/tests/test_svm.py::test_linearsvc_fit_sampleweight PASSED    [ 70%]\nsklearn/svm/tests/test_svm.py::test_crammer_singer_binary PASSED         [ 72%]\nsklearn/svm/tests/test_svm.py::test_linearsvc_iris PASSED                [ 73%]\nsklearn/svm/tests/test_svm.py::test_dense_liblinear_intercept_handling PASSED [ 74%]\nsklearn/svm/tests/test_svm.py::test_liblinear_set_coef PASSED            [ 75%]\nsklearn/svm/tests/test_svm.py::test_immutable_coef_property PASSED       [ 76%]\nsklearn/svm/tests/test_svm.py::test_linearsvc_verbose PASSED             [ 77%]\nsklearn/svm/tests/test_svm.py::test_svc_clone_with_callable_kernel PASSED [ 79%]\nsklearn/svm/tests/test_svm.py::test_svc_bad_kernel PASSED                [ 80%]\nsklearn/svm/tests/test_svm.py::test_timeout PASSED                       [ 81%]\nsklearn/svm/tests/test_svm.py::test_unfitted PASSED                      [ 82%]\nsklearn/svm/tests/test_svm.py::test_consistent_proba PASSED              [ 83%]\nsklearn/svm/tests/test_svm.py::test_linear_svm_convergence_warnings PASSED [ 84%]\nsklearn/svm/tests/test_svm.py::test_svr_coef_sign PASSED                 [ 86%]\nsklearn/svm/tests/test_svm.py::test_linear_svc_intercept_scaling PASSED  [ 87%]\nsklearn/svm/tests/test_svm.py::test_lsvc_intercept_scaling_zero PASSED   [ 88%]\nsklearn/svm/tests/test_svm.py::test_hasattr_predict_proba PASSED         [ 89%]\nsklearn/svm/tests/test_svm.py::test_decision_function_shape_two_class PASSED [ 90%]\nsklearn/svm/tests/test_svm.py::test_ovr_decision_function PASSED         [ 91%]\nsklearn/svm/tests/test_svm.py::test_svc_invalid_break_ties_param[SVC] PASSED [ 93%]\nsklearn/svm/tests/test_svm.py::test_svc_invalid_break_ties_param[NuSVC] PASSED [ 94%]\nsklearn/svm/tests/test_svm.py::test_svc_ovr_tie_breaking[SVC] PASSED     [ 95%]\nsklearn/svm/tests/test_svm.py::test_svc_ovr_tie_breaking[NuSVC] PASSED   [ 96%]\nsklearn/svm/tests/test_svm.py::test_gamma_auto PASSED                    [ 97%]\nsklearn/svm/tests/test_svm.py::test_gamma_scale PASSED                   [ 98%]\nsklearn/svm/tests/test_svm.py::test_n_support_oneclass_svr PASSED        [100%]\n\n=================================== FAILURES ===================================\n____________________ test_sparse_fit_support_vectors_empty _____________________\nsklearn/svm/tests/test_svm.py:701: in test_sparse_fit_support_vectors_empty\n    model.fit(X_train, y_train)\nsklearn/svm/base.py:198: in fit\n    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\nsklearn/svm/base.py:291: in _sparse_fit\n    dual_coef_indices.size / n_class)\nE   ZeroDivisionError: float division by zero\n================== 1 failed, 85 passed, 13 warnings in 6.30s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sklearn/svm/tests/test_svm.py` failed. (See above for error)",
          "test_files_run": [
            "sklearn/svm/tests/test_svm.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 86,
          "failed": 0,
          "errors": 0,
          "collected": 86,
          "duration": 9.27,
          "log_tail": "sklearn/svm/tests/test_svm.py::test_negative_weight_equal_coeffs[partial-mask-label-1-NuSVC] PASSED [ 47%]\nsklearn/svm/tests/test_svm.py::test_negative_weight_equal_coeffs[partial-mask-label-1-NuSVR] PASSED [ 48%]\nsklearn/svm/tests/test_svm.py::test_negative_weight_equal_coeffs[partial-mask-label-2-SVC] PASSED [ 50%]\nsklearn/svm/tests/test_svm.py::test_negative_weight_equal_coeffs[partial-mask-label-2-NuSVC] PASSED [ 51%]\nsklearn/svm/tests/test_svm.py::test_negative_weight_equal_coeffs[partial-mask-label-2-NuSVR] PASSED [ 52%]\nsklearn/svm/tests/test_svm.py::test_auto_weight PASSED                   [ 53%]\nsklearn/svm/tests/test_svm.py::test_bad_input PASSED                     [ 54%]\nsklearn/svm/tests/test_svm.py::test_svm_gamma_error[SVC-data0] PASSED    [ 55%]\nsklearn/svm/tests/test_svm.py::test_svm_gamma_error[NuSVC-data1] PASSED  [ 56%]\nsklearn/svm/tests/test_svm.py::test_svm_gamma_error[SVR-data2] PASSED    [ 58%]\nsklearn/svm/tests/test_svm.py::test_svm_gamma_error[NuSVR-data3] PASSED  [ 59%]\nsklearn/svm/tests/test_svm.py::test_svm_gamma_error[OneClassSVM-data4] PASSED [ 60%]\nsklearn/svm/tests/test_svm.py::test_unicode_kernel PASSED                [ 61%]\nsklearn/svm/tests/test_svm.py::test_sparse_precomputed PASSED            [ 62%]\nsklearn/svm/tests/test_svm.py::test_sparse_fit_support_vectors_empty PASSED [ 63%]\nsklearn/svm/tests/test_svm.py::test_linearsvc_parameters PASSED          [ 65%]\nsklearn/svm/tests/test_svm.py::test_linearsvx_loss_penalty_deprecations PASSED [ 66%]\nsklearn/svm/tests/test_svm.py::test_linear_svx_uppercase_loss_penality_raises_error PASSED [ 67%]\nsklearn/svm/tests/test_svm.py::test_linearsvc PASSED                     [ 68%]\nsklearn/svm/tests/test_svm.py::test_linearsvc_crammer_singer PASSED      [ 69%]\nsklearn/svm/tests/test_svm.py::test_linearsvc_fit_sampleweight PASSED    [ 70%]\nsklearn/svm/tests/test_svm.py::test_crammer_singer_binary PASSED         [ 72%]\nsklearn/svm/tests/test_svm.py::test_linearsvc_iris PASSED                [ 73%]\nsklearn/svm/tests/test_svm.py::test_dense_liblinear_intercept_handling PASSED [ 74%]\nsklearn/svm/tests/test_svm.py::test_liblinear_set_coef PASSED            [ 75%]\nsklearn/svm/tests/test_svm.py::test_immutable_coef_property PASSED       [ 76%]\nsklearn/svm/tests/test_svm.py::test_linearsvc_verbose PASSED             [ 77%]\nsklearn/svm/tests/test_svm.py::test_svc_clone_with_callable_kernel PASSED [ 79%]\nsklearn/svm/tests/test_svm.py::test_svc_bad_kernel PASSED                [ 80%]\nsklearn/svm/tests/test_svm.py::test_timeout PASSED                       [ 81%]\nsklearn/svm/tests/test_svm.py::test_unfitted PASSED                      [ 82%]\nsklearn/svm/tests/test_svm.py::test_consistent_proba PASSED              [ 83%]\nsklearn/svm/tests/test_svm.py::test_linear_svm_convergence_warnings PASSED [ 84%]\nsklearn/svm/tests/test_svm.py::test_svr_coef_sign PASSED                 [ 86%]\nsklearn/svm/tests/test_svm.py::test_linear_svc_intercept_scaling PASSED  [ 87%]\nsklearn/svm/tests/test_svm.py::test_lsvc_intercept_scaling_zero PASSED   [ 88%]\nsklearn/svm/tests/test_svm.py::test_hasattr_predict_proba PASSED         [ 89%]\nsklearn/svm/tests/test_svm.py::test_decision_function_shape_two_class PASSED [ 90%]\nsklearn/svm/tests/test_svm.py::test_ovr_decision_function PASSED         [ 91%]\nsklearn/svm/tests/test_svm.py::test_svc_invalid_break_ties_param[SVC] PASSED [ 93%]\nsklearn/svm/tests/test_svm.py::test_svc_invalid_break_ties_param[NuSVC] PASSED [ 94%]\nsklearn/svm/tests/test_svm.py::test_svc_ovr_tie_breaking[SVC] PASSED     [ 95%]\nsklearn/svm/tests/test_svm.py::test_svc_ovr_tie_breaking[NuSVC] PASSED   [ 96%]\nsklearn/svm/tests/test_svm.py::test_gamma_auto PASSED                    [ 97%]\nsklearn/svm/tests/test_svm.py::test_gamma_scale PASSED                   [ 98%]\nsklearn/svm/tests/test_svm.py::test_n_support_oneclass_svr PASSED        [100%]\n\n======================= 86 passed, 13 warnings in 6.09s ========================\n\n",
          "test_files_run": [
            "sklearn/svm/tests/test_svm.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "scikit-learn__scikit-learn-15100",
      "repo": "scikit-learn/scikit-learn",
      "valid": true,
      "worker": "http://35.239.238.137:8080",
      "duration": 10.445943117141724,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 106,
          "failed": 1,
          "errors": 0,
          "collected": 111,
          "duration": 5.88,
          "log_tail": "sklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_error[filename-FileNotFoundError--TfidfVectorizer] PASSED [ 66%]\nsklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_error[filename-FileNotFoundError--HashingVectorizer] XFAIL [ 67%]\nsklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_error[file-AttributeError-'str' object has no attribute 'read'-CountVectorizer] PASSED [ 68%]\nsklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_error[file-AttributeError-'str' object has no attribute 'read'-TfidfVectorizer] PASSED [ 69%]\nsklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_error[file-AttributeError-'str' object has no attribute 'read'-HashingVectorizer] XFAIL [ 70%]\nsklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_change_behavior[file-<lambda>0-CountVectorizer] PASSED [ 71%]\nsklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_change_behavior[file-<lambda>0-TfidfVectorizer] PASSED [ 72%]\nsklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_change_behavior[file-<lambda>0-HashingVectorizer] PASSED [ 72%]\nsklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_change_behavior[file-<lambda>1-CountVectorizer] PASSED [ 73%]\nsklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_change_behavior[file-<lambda>1-TfidfVectorizer] PASSED [ 74%]\nsklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_change_behavior[file-<lambda>1-HashingVectorizer] PASSED [ 75%]\nsklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_change_behavior[filename-<lambda>0-CountVectorizer] PASSED [ 76%]\nsklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_change_behavior[filename-<lambda>0-TfidfVectorizer] PASSED [ 77%]\nsklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_change_behavior[filename-<lambda>0-HashingVectorizer] PASSED [ 78%]\nsklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_change_behavior[filename-<lambda>1-CountVectorizer] PASSED [ 79%]\nsklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_change_behavior[filename-<lambda>1-TfidfVectorizer] PASSED [ 80%]\nsklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_change_behavior[filename-<lambda>1-HashingVectorizer] PASSED [ 81%]\nsklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_reraise_error[CountVectorizer] PASSED [ 81%]\nsklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_reraise_error[TfidfVectorizer] PASSED [ 82%]\nsklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_reraise_error[HashingVectorizer] XFAIL [ 83%]\nsklearn/feature_extraction/tests/test_text.py::test_unused_parameters_warn[stop_words0-None-None-ngram_range0-None-char-'stop_words'-'analyzer'-!= 'word'-CountVectorizer] PASSED [ 84%]\nsklearn/feature_extraction/tests/test_text.py::test_unused_parameters_warn[stop_words0-None-None-ngram_range0-None-char-'stop_words'-'analyzer'-!= 'word'-HashingVectorizer] PASSED [ 85%]\nsklearn/feature_extraction/tests/test_text.py::test_unused_parameters_warn[stop_words0-None-None-ngram_range0-None-char-'stop_words'-'analyzer'-!= 'word'-TfidfVectorizer] PASSED [ 86%]\nsklearn/feature_extraction/tests/test_text.py::test_unused_parameters_warn[None-<lambda>-None-ngram_range1-None-char-'tokenizer'-'analyzer'-!= 'word'-CountVectorizer] PASSED [ 87%]\nsklearn/feature_extraction/tests/test_text.py::test_unused_parameters_warn[None-<lambda>-None-ngram_range1-None-char-'tokenizer'-'analyzer'-!= 'word'-HashingVectorizer] PASSED [ 88%]\nsklearn/feature_extraction/tests/test_text.py::test_unused_parameters_warn[None-<lambda>-None-ngram_range1-None-char-'tokenizer'-'analyzer'-!= 'word'-TfidfVectorizer] PASSED [ 89%]\nsklearn/feature_extraction/tests/test_text.py::test_unused_parameters_warn[None-<lambda>-None-ngram_range2-\\\\w+-word-'token_pattern'-'tokenizer'-is not None-CountVectorizer] PASSED [ 90%]\nsklearn/feature_extraction/tests/test_text.py::test_unused_parameters_warn[None-<lambda>-None-ngram_range2-\\\\w+-word-'token_pattern'-'tokenizer'-is not None-HashingVectorizer] PASSED [ 90%]\nsklearn/feature_extraction/tests/test_text.py::test_unused_parameters_warn[None-<lambda>-None-ngram_range2-\\\\w+-word-'token_pattern'-'tokenizer'-is not None-TfidfVectorizer] PASSED [ 91%]\nsklearn/feature_extraction/tests/test_text.py::test_unused_parameters_warn[None-None-<lambda>-ngram_range3-\\\\w+-<lambda>-'preprocessor'-'analyzer'-is callable-CountVectorizer] PASSED [ 92%]\nsklearn/feature_extraction/tests/test_text.py::test_unused_parameters_warn[None-None-<lambda>-ngram_range3-\\\\w+-<lambda>-'preprocessor'-'analyzer'-is callable-HashingVectorizer] PASSED [ 93%]\nsklearn/feature_extraction/tests/test_text.py::test_unused_parameters_warn[None-None-<lambda>-ngram_range3-\\\\w+-<lambda>-'preprocessor'-'analyzer'-is callable-TfidfVectorizer] PASSED [ 94%]\nsklearn/feature_extraction/tests/test_text.py::test_unused_parameters_warn[None-None-None-ngram_range4-None-<lambda>-'ngram_range'-'analyzer'-is callable-CountVectorizer] PASSED [ 95%]\nsklearn/feature_extraction/tests/test_text.py::test_unused_parameters_warn[None-None-None-ngram_range4-None-<lambda>-'ngram_range'-'analyzer'-is callable-HashingVectorizer] PASSED [ 96%]\nsklearn/feature_extraction/tests/test_text.py::test_unused_parameters_warn[None-None-None-ngram_range4-None-<lambda>-'ngram_range'-'analyzer'-is callable-TfidfVectorizer] PASSED [ 97%]\nsklearn/feature_extraction/tests/test_text.py::test_unused_parameters_warn[None-None-None-ngram_range5-\\\\w+-char-'token_pattern'-'analyzer'-!= 'word'-CountVectorizer] PASSED [ 98%]\nsklearn/feature_extraction/tests/test_text.py::test_unused_parameters_warn[None-None-None-ngram_range5-\\\\w+-char-'token_pattern'-'analyzer'-!= 'word'-HashingVectorizer] PASSED [ 99%]\nsklearn/feature_extraction/tests/test_text.py::test_unused_parameters_warn[None-None-None-ngram_range5-\\\\w+-char-'token_pattern'-'analyzer'-!= 'word'-TfidfVectorizer] PASSED [100%]\n\n=================================== FAILURES ===================================\n______________________________ test_strip_accents ______________________________\nsklearn/feature_extraction/tests/test_text.py:103: in test_strip_accents\n    assert strip_accents_unicode(a) == expected\nE   AssertionError: assert 'o\u0308' == 'o'\nE     - o\nE     + o\u0308\n============= 1 failed, 106 passed, 4 xfailed, 5 warnings in 1.36s =============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sklearn/feature_extraction/tests/test_text.py` failed. (See above for error)",
          "test_files_run": [
            "sklearn/feature_extraction/tests/test_text.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "collected": 111,
          "duration": 3.72,
          "log_tail": "sklearn/feature_extraction/tests/test_text.py::test_vectorizers_invalid_ngram_range[vec1] PASSED [ 59%]\nsklearn/feature_extraction/tests/test_text.py::test_vectorizers_invalid_ngram_range[vec2] PASSED [ 60%]\nsklearn/feature_extraction/tests/test_text.py::test_vectorizer_stop_words_inconsistent PASSED [ 61%]\nsklearn/feature_extraction/tests/test_text.py::test_countvectorizer_sort_features_64bit_sparse_indices PASSED [ 62%]\nsklearn/feature_extraction/tests/test_text.py::test_stop_word_validation_custom_preprocessor[CountVectorizer] PASSED [ 63%]\nsklearn/feature_extraction/tests/test_text.py::test_stop_word_validation_custom_preprocessor[TfidfVectorizer] PASSED [ 63%]\nsklearn/feature_extraction/tests/test_text.py::test_stop_word_validation_custom_preprocessor[HashingVectorizer] PASSED [ 64%]\nsklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_error[filename-FileNotFoundError--CountVectorizer] PASSED [ 65%]\nsklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_error[filename-FileNotFoundError--TfidfVectorizer] PASSED [ 66%]\nsklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_error[filename-FileNotFoundError--HashingVectorizer] XFAIL [ 67%]\nsklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_error[file-AttributeError-'str' object has no attribute 'read'-CountVectorizer] PASSED [ 68%]\nsklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_error[file-AttributeError-'str' object has no attribute 'read'-TfidfVectorizer] PASSED [ 69%]\nsklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_error[file-AttributeError-'str' object has no attribute 'read'-HashingVectorizer] XFAIL [ 70%]\nsklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_change_behavior[file-<lambda>0-CountVectorizer] PASSED [ 71%]\nsklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_change_behavior[file-<lambda>0-TfidfVectorizer] PASSED [ 72%]\nsklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_change_behavior[file-<lambda>0-HashingVectorizer] PASSED [ 72%]\nsklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_change_behavior[file-<lambda>1-CountVectorizer] PASSED [ 73%]\nsklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_change_behavior[file-<lambda>1-TfidfVectorizer] PASSED [ 74%]\nsklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_change_behavior[file-<lambda>1-HashingVectorizer] PASSED [ 75%]\nsklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_change_behavior[filename-<lambda>0-CountVectorizer] PASSED [ 76%]\nsklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_change_behavior[filename-<lambda>0-TfidfVectorizer] PASSED [ 77%]\nsklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_change_behavior[filename-<lambda>0-HashingVectorizer] PASSED [ 78%]\nsklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_change_behavior[filename-<lambda>1-CountVectorizer] PASSED [ 79%]\nsklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_change_behavior[filename-<lambda>1-TfidfVectorizer] PASSED [ 80%]\nsklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_change_behavior[filename-<lambda>1-HashingVectorizer] PASSED [ 81%]\nsklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_reraise_error[CountVectorizer] PASSED [ 81%]\nsklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_reraise_error[TfidfVectorizer] PASSED [ 82%]\nsklearn/feature_extraction/tests/test_text.py::test_callable_analyzer_reraise_error[HashingVectorizer] XFAIL [ 83%]\nsklearn/feature_extraction/tests/test_text.py::test_unused_parameters_warn[stop_words0-None-None-ngram_range0-None-char-'stop_words'-'analyzer'-!= 'word'-CountVectorizer] PASSED [ 84%]\nsklearn/feature_extraction/tests/test_text.py::test_unused_parameters_warn[stop_words0-None-None-ngram_range0-None-char-'stop_words'-'analyzer'-!= 'word'-HashingVectorizer] PASSED [ 85%]\nsklearn/feature_extraction/tests/test_text.py::test_unused_parameters_warn[stop_words0-None-None-ngram_range0-None-char-'stop_words'-'analyzer'-!= 'word'-TfidfVectorizer] PASSED [ 86%]\nsklearn/feature_extraction/tests/test_text.py::test_unused_parameters_warn[None-<lambda>-None-ngram_range1-None-char-'tokenizer'-'analyzer'-!= 'word'-CountVectorizer] PASSED [ 87%]\nsklearn/feature_extraction/tests/test_text.py::test_unused_parameters_warn[None-<lambda>-None-ngram_range1-None-char-'tokenizer'-'analyzer'-!= 'word'-HashingVectorizer] PASSED [ 88%]\nsklearn/feature_extraction/tests/test_text.py::test_unused_parameters_warn[None-<lambda>-None-ngram_range1-None-char-'tokenizer'-'analyzer'-!= 'word'-TfidfVectorizer] PASSED [ 89%]\nsklearn/feature_extraction/tests/test_text.py::test_unused_parameters_warn[None-<lambda>-None-ngram_range2-\\\\w+-word-'token_pattern'-'tokenizer'-is not None-CountVectorizer] PASSED [ 90%]\nsklearn/feature_extraction/tests/test_text.py::test_unused_parameters_warn[None-<lambda>-None-ngram_range2-\\\\w+-word-'token_pattern'-'tokenizer'-is not None-HashingVectorizer] PASSED [ 90%]\nsklearn/feature_extraction/tests/test_text.py::test_unused_parameters_warn[None-<lambda>-None-ngram_range2-\\\\w+-word-'token_pattern'-'tokenizer'-is not None-TfidfVectorizer] PASSED [ 91%]\nsklearn/feature_extraction/tests/test_text.py::test_unused_parameters_warn[None-None-<lambda>-ngram_range3-\\\\w+-<lambda>-'preprocessor'-'analyzer'-is callable-CountVectorizer] PASSED [ 92%]\nsklearn/feature_extraction/tests/test_text.py::test_unused_parameters_warn[None-None-<lambda>-ngram_range3-\\\\w+-<lambda>-'preprocessor'-'analyzer'-is callable-HashingVectorizer] PASSED [ 93%]\nsklearn/feature_extraction/tests/test_text.py::test_unused_parameters_warn[None-None-<lambda>-ngram_range3-\\\\w+-<lambda>-'preprocessor'-'analyzer'-is callable-TfidfVectorizer] PASSED [ 94%]\nsklearn/feature_extraction/tests/test_text.py::test_unused_parameters_warn[None-None-None-ngram_range4-None-<lambda>-'ngram_range'-'analyzer'-is callable-CountVectorizer] PASSED [ 95%]\nsklearn/feature_extraction/tests/test_text.py::test_unused_parameters_warn[None-None-None-ngram_range4-None-<lambda>-'ngram_range'-'analyzer'-is callable-HashingVectorizer] PASSED [ 96%]\nsklearn/feature_extraction/tests/test_text.py::test_unused_parameters_warn[None-None-None-ngram_range4-None-<lambda>-'ngram_range'-'analyzer'-is callable-TfidfVectorizer] PASSED [ 97%]\nsklearn/feature_extraction/tests/test_text.py::test_unused_parameters_warn[None-None-None-ngram_range5-\\\\w+-char-'token_pattern'-'analyzer'-!= 'word'-CountVectorizer] PASSED [ 98%]\nsklearn/feature_extraction/tests/test_text.py::test_unused_parameters_warn[None-None-None-ngram_range5-\\\\w+-char-'token_pattern'-'analyzer'-!= 'word'-HashingVectorizer] PASSED [ 99%]\nsklearn/feature_extraction/tests/test_text.py::test_unused_parameters_warn[None-None-None-ngram_range5-\\\\w+-char-'token_pattern'-'analyzer'-!= 'word'-TfidfVectorizer] PASSED [100%]\n\n================== 107 passed, 4 xfailed, 5 warnings in 1.33s ==================\n\n",
          "test_files_run": [
            "sklearn/feature_extraction/tests/test_text.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "scikit-learn__scikit-learn-14629",
      "repo": "scikit-learn/scikit-learn",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 40.42376184463501,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 26,
          "failed": 1,
          "errors": 0,
          "collected": 27,
          "duration": 21.08,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 27 items\n\nsklearn/tests/test_multioutput.py::test_multi_target_regression PASSED   [  3%]\nsklearn/tests/test_multioutput.py::test_multi_target_regression_partial_fit PASSED [  7%]\nsklearn/tests/test_multioutput.py::test_multi_target_regression_one_target PASSED [ 11%]\nsklearn/tests/test_multioutput.py::test_multi_target_sparse_regression PASSED [ 14%]\nsklearn/tests/test_multioutput.py::test_multi_target_sample_weights_api PASSED [ 18%]\nsklearn/tests/test_multioutput.py::test_multi_target_sample_weight_partial_fit PASSED [ 22%]\nsklearn/tests/test_multioutput.py::test_multi_target_sample_weights PASSED [ 25%]\nsklearn/tests/test_multioutput.py::test_multi_output_classification_partial_fit_parallelism PASSED [ 29%]\nsklearn/tests/test_multioutput.py::test_multi_output_predict_proba PASSED [ 33%]\nsklearn/tests/test_multioutput.py::test_multi_output_classification_partial_fit PASSED [ 37%]\nsklearn/tests/test_multioutput.py::test_multi_output_classification_partial_fit_no_first_classes_exception PASSED [ 40%]\nsklearn/tests/test_multioutput.py::test_multi_output_classification PASSED [ 44%]\nsklearn/tests/test_multioutput.py::test_multiclass_multioutput_estimator PASSED [ 48%]\nsklearn/tests/test_multioutput.py::test_multiclass_multioutput_estimator_predict_proba PASSED [ 51%]\nsklearn/tests/test_multioutput.py::test_multi_output_classification_sample_weights PASSED [ 55%]\nsklearn/tests/test_multioutput.py::test_multi_output_classification_partial_fit_sample_weights PASSED [ 59%]\nsklearn/tests/test_multioutput.py::test_multi_output_exceptions PASSED   [ 62%]\nsklearn/tests/test_multioutput.py::test_classifier_chain_fit_and_predict_with_linear_svc PASSED [ 66%]\nsklearn/tests/test_multioutput.py::test_classifier_chain_fit_and_predict_with_sparse_data PASSED [ 70%]\nsklearn/tests/test_multioutput.py::test_classifier_chain_vs_independent_models PASSED [ 74%]\nsklearn/tests/test_multioutput.py::test_base_chain_fit_and_predict PASSED [ 77%]\nsklearn/tests/test_multioutput.py::test_base_chain_fit_and_predict_with_sparse_data_and_cv PASSED [ 81%]\nsklearn/tests/test_multioutput.py::test_base_chain_random_order PASSED   [ 85%]\nsklearn/tests/test_multioutput.py::test_base_chain_crossval_fit_and_predict PASSED [ 88%]\nsklearn/tests/test_multioutput.py::test_multi_output_classes_[estimator0] PASSED [ 92%]\nsklearn/tests/test_multioutput.py::test_multi_output_classes_[estimator1] FAILED [ 96%]\nsklearn/tests/test_multioutput.py::test_multi_output_classes_[estimator2] PASSED [100%]\n\n=================================== FAILURES ===================================\n____________________ test_multi_output_classes_[estimator1] ____________________\nsklearn/tests/test_multioutput.py:542: in test_multi_output_classes_\n    assert isinstance(estimator.classes_, list)\nE   AttributeError: 'MultiOutputClassifier' object has no attribute 'classes_'\n================== 1 failed, 26 passed, 61 warnings in 10.98s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sklearn/tests/test_multioutput.py` failed. (See above for error)",
          "test_files_run": [
            "sklearn/tests/test_multioutput.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 27,
          "failed": 0,
          "errors": 0,
          "collected": 27,
          "duration": 7.91,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 27 items\n\nsklearn/tests/test_multioutput.py::test_multi_target_regression PASSED   [  3%]\nsklearn/tests/test_multioutput.py::test_multi_target_regression_partial_fit PASSED [  7%]\nsklearn/tests/test_multioutput.py::test_multi_target_regression_one_target PASSED [ 11%]\nsklearn/tests/test_multioutput.py::test_multi_target_sparse_regression PASSED [ 14%]\nsklearn/tests/test_multioutput.py::test_multi_target_sample_weights_api PASSED [ 18%]\nsklearn/tests/test_multioutput.py::test_multi_target_sample_weight_partial_fit PASSED [ 22%]\nsklearn/tests/test_multioutput.py::test_multi_target_sample_weights PASSED [ 25%]\nsklearn/tests/test_multioutput.py::test_multi_output_classification_partial_fit_parallelism PASSED [ 29%]\nsklearn/tests/test_multioutput.py::test_multi_output_predict_proba PASSED [ 33%]\nsklearn/tests/test_multioutput.py::test_multi_output_classification_partial_fit PASSED [ 37%]\nsklearn/tests/test_multioutput.py::test_multi_output_classification_partial_fit_no_first_classes_exception PASSED [ 40%]\nsklearn/tests/test_multioutput.py::test_multi_output_classification PASSED [ 44%]\nsklearn/tests/test_multioutput.py::test_multiclass_multioutput_estimator PASSED [ 48%]\nsklearn/tests/test_multioutput.py::test_multiclass_multioutput_estimator_predict_proba PASSED [ 51%]\nsklearn/tests/test_multioutput.py::test_multi_output_classification_sample_weights PASSED [ 55%]\nsklearn/tests/test_multioutput.py::test_multi_output_classification_partial_fit_sample_weights PASSED [ 59%]\nsklearn/tests/test_multioutput.py::test_multi_output_exceptions PASSED   [ 62%]\nsklearn/tests/test_multioutput.py::test_classifier_chain_fit_and_predict_with_linear_svc PASSED [ 66%]\nsklearn/tests/test_multioutput.py::test_classifier_chain_fit_and_predict_with_sparse_data PASSED [ 70%]\nsklearn/tests/test_multioutput.py::test_classifier_chain_vs_independent_models PASSED [ 74%]\nsklearn/tests/test_multioutput.py::test_base_chain_fit_and_predict PASSED [ 77%]\nsklearn/tests/test_multioutput.py::test_base_chain_fit_and_predict_with_sparse_data_and_cv PASSED [ 81%]\nsklearn/tests/test_multioutput.py::test_base_chain_random_order PASSED   [ 85%]\nsklearn/tests/test_multioutput.py::test_base_chain_crossval_fit_and_predict PASSED [ 88%]\nsklearn/tests/test_multioutput.py::test_multi_output_classes_[estimator0] PASSED [ 92%]\nsklearn/tests/test_multioutput.py::test_multi_output_classes_[estimator1] PASSED [ 96%]\nsklearn/tests/test_multioutput.py::test_multi_output_classes_[estimator2] PASSED [100%]\n\n======================= 27 passed, 61 warnings in 5.29s ========================\n\n",
          "test_files_run": [
            "sklearn/tests/test_multioutput.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "scikit-learn__scikit-learn-25102",
      "repo": "scikit-learn/scikit-learn",
      "valid": true,
      "worker": "http://34.70.1.155:8080",
      "duration": 13.930413722991943,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 59,
          "failed": 2,
          "errors": 0,
          "collected": 61,
          "duration": 7.81,
          "log_tail": "sklearn/feature_selection/tests/test_feature_select.py::test_f_regression_corner_case[X7-y7-expected_f_statistic7-expected_p_values7-False] \u001b[32mPASSED\u001b[0m\u001b[31m [ 42%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_f_classif_multi_class \u001b[32mPASSED\u001b[0m\u001b[31m [ 44%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_percentile_classif \u001b[32mPASSED\u001b[0m\u001b[31m [ 45%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_percentile_classif_sparse \u001b[32mPASSED\u001b[0m\u001b[31m [ 47%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_kbest_classif \u001b[32mPASSED\u001b[0m\u001b[31m [ 49%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_kbest_all \u001b[32mPASSED\u001b[0m\u001b[31m [ 50%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_kbest_zero[float32] \u001b[32mPASSED\u001b[0m\u001b[31m [ 52%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_kbest_zero[float64] \u001b[32mPASSED\u001b[0m\u001b[31m [ 54%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_heuristics_classif \u001b[32mPASSED\u001b[0m\u001b[31m [ 55%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_percentile_regression \u001b[32mPASSED\u001b[0m\u001b[31m [ 57%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_percentile_regression_full \u001b[32mPASSED\u001b[0m\u001b[31m [ 59%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_kbest_regression \u001b[32mPASSED\u001b[0m\u001b[31m [ 60%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_heuristics_regression \u001b[32mPASSED\u001b[0m\u001b[31m [ 62%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_boundary_case_ch2 \u001b[32mPASSED\u001b[0m\u001b[31m [ 63%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_fdr_regression[1-0.001] \u001b[32mPASSED\u001b[0m\u001b[31m [ 65%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_fdr_regression[1-0.01] \u001b[32mPASSED\u001b[0m\u001b[31m [ 67%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_fdr_regression[1-0.1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 68%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_fdr_regression[5-0.001] \u001b[32mPASSED\u001b[0m\u001b[31m [ 70%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_fdr_regression[5-0.01] \u001b[32mPASSED\u001b[0m\u001b[31m [ 72%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_fdr_regression[5-0.1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 73%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_fdr_regression[10-0.001] \u001b[32mPASSED\u001b[0m\u001b[31m [ 75%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_fdr_regression[10-0.01] \u001b[32mPASSED\u001b[0m\u001b[31m [ 77%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_fdr_regression[10-0.1] \u001b[32mPASSED\u001b[0m\u001b[31m [ 78%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_fwe_regression \u001b[32mPASSED\u001b[0m\u001b[31m [ 80%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_selectkbest_tiebreaking \u001b[32mPASSED\u001b[0m\u001b[31m [ 81%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_selectpercentile_tiebreaking \u001b[32mPASSED\u001b[0m\u001b[31m [ 83%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_tied_pvalues \u001b[32mPASSED\u001b[0m\u001b[31m [ 85%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_scorefunc_multilabel \u001b[32mPASSED\u001b[0m\u001b[31m [ 86%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_tied_scores \u001b[32mPASSED\u001b[0m\u001b[31m [ 88%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_nans \u001b[32mPASSED\u001b[0m\u001b[31m [ 90%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_invalid_k \u001b[32mPASSED\u001b[0m\u001b[31m [ 91%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_f_classif_constant_feature \u001b[32mPASSED\u001b[0m\u001b[31m [ 93%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_no_feature_selected \u001b[32mPASSED\u001b[0m\u001b[31m [ 95%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_mutual_info_classif \u001b[32mPASSED\u001b[0m\u001b[31m [ 96%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_mutual_info_regression \u001b[32mPASSED\u001b[0m\u001b[31m [ 98%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_dataframe_output_dtypes \u001b[31mFAILED\u001b[0m\u001b[31m [100%]\u001b[0m\n\n=================================== FAILURES ===================================\n\u001b[31m\u001b[1m____________________________ test_output_dataframe _____________________________\u001b[0m\n\u001b[1m\u001b[31msklearn/feature_selection/tests/test_base.py\u001b[0m:140: in test_output_dataframe\n    assert dtype == X.dtypes[name]\n\u001b[1m\u001b[31mE   AssertionError: assert dtype('O') == dtype('float32')\u001b[0m\n\u001b[31m\u001b[1m_________________________ test_dataframe_output_dtypes _________________________\u001b[0m\n\u001b[1m\u001b[31msklearn/feature_selection/tests/test_feature_select.py\u001b[0m:984: in test_dataframe_output_dtypes\n    assert dtype == X.dtypes[name]\n\u001b[1m\u001b[31mE   AssertionError: assert dtype('O') == dtype('float32')\u001b[0m\n\u001b[31m========================= \u001b[31m\u001b[1m2 failed\u001b[0m, \u001b[32m59 passed\u001b[0m\u001b[31m in 2.62s\u001b[0m\u001b[31m =========================\u001b[0m\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sklearn/feature_selection/tests/test_base.py sklearn/feature_selection/tests/test_feature_select.py` failed. (See above for error)",
          "test_files_run": [
            "sklearn/feature_selection/tests/test_base.py",
            "sklearn/feature_selection/tests/test_feature_select.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 61,
          "failed": 0,
          "errors": 0,
          "collected": 61,
          "duration": 5.26,
          "log_tail": "sklearn/feature_selection/tests/test_feature_select.py::test_r_regression_force_finite[X1-y1-expected_corr_coef1-True] \u001b[32mPASSED\u001b[0m\u001b[32m [ 26%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_r_regression_force_finite[X2-y2-expected_corr_coef2-False] \u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_r_regression_force_finite[X3-y3-expected_corr_coef3-False] \u001b[32mPASSED\u001b[0m\u001b[32m [ 29%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_f_regression_corner_case[X0-y0-expected_f_statistic0-expected_p_values0-True] \u001b[32mPASSED\u001b[0m\u001b[32m [ 31%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_f_regression_corner_case[X1-y1-expected_f_statistic1-expected_p_values1-True] \u001b[32mPASSED\u001b[0m\u001b[32m [ 32%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_f_regression_corner_case[X2-y2-expected_f_statistic2-expected_p_values2-True] \u001b[32mPASSED\u001b[0m\u001b[32m [ 34%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_f_regression_corner_case[X3-y3-expected_f_statistic3-expected_p_values3-True] \u001b[32mPASSED\u001b[0m\u001b[32m [ 36%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_f_regression_corner_case[X4-y4-expected_f_statistic4-expected_p_values4-False] \u001b[32mPASSED\u001b[0m\u001b[32m [ 37%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_f_regression_corner_case[X5-y5-expected_f_statistic5-expected_p_values5-False] \u001b[32mPASSED\u001b[0m\u001b[32m [ 39%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_f_regression_corner_case[X6-y6-expected_f_statistic6-expected_p_values6-False] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_f_regression_corner_case[X7-y7-expected_f_statistic7-expected_p_values7-False] \u001b[32mPASSED\u001b[0m\u001b[32m [ 42%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_f_classif_multi_class \u001b[32mPASSED\u001b[0m\u001b[32m [ 44%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_percentile_classif \u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_percentile_classif_sparse \u001b[32mPASSED\u001b[0m\u001b[32m [ 47%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_kbest_classif \u001b[32mPASSED\u001b[0m\u001b[32m [ 49%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_kbest_all \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_kbest_zero[float32] \u001b[32mPASSED\u001b[0m\u001b[32m [ 52%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_kbest_zero[float64] \u001b[32mPASSED\u001b[0m\u001b[32m [ 54%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_heuristics_classif \u001b[32mPASSED\u001b[0m\u001b[32m [ 55%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_percentile_regression \u001b[32mPASSED\u001b[0m\u001b[32m [ 57%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_percentile_regression_full \u001b[32mPASSED\u001b[0m\u001b[32m [ 59%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_kbest_regression \u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_heuristics_regression \u001b[32mPASSED\u001b[0m\u001b[32m [ 62%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_boundary_case_ch2 \u001b[32mPASSED\u001b[0m\u001b[32m [ 63%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_fdr_regression[1-0.001] \u001b[32mPASSED\u001b[0m\u001b[32m [ 65%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_fdr_regression[1-0.01] \u001b[32mPASSED\u001b[0m\u001b[32m [ 67%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_fdr_regression[1-0.1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 68%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_fdr_regression[5-0.001] \u001b[32mPASSED\u001b[0m\u001b[32m [ 70%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_fdr_regression[5-0.01] \u001b[32mPASSED\u001b[0m\u001b[32m [ 72%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_fdr_regression[5-0.1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_fdr_regression[10-0.001] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_fdr_regression[10-0.01] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_fdr_regression[10-0.1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_select_fwe_regression \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_selectkbest_tiebreaking \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_selectpercentile_tiebreaking \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_tied_pvalues \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_scorefunc_multilabel \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_tied_scores \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_nans \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_invalid_k \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_f_classif_constant_feature \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_no_feature_selected \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_mutual_info_classif \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_mutual_info_regression \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\nsklearn/feature_selection/tests/test_feature_select.py::test_dataframe_output_dtypes \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n\n\u001b[32m============================== \u001b[32m\u001b[1m61 passed\u001b[0m\u001b[32m in 2.54s\u001b[0m\u001b[32m ==============================\u001b[0m\n\n",
          "test_files_run": [
            "sklearn/feature_selection/tests/test_base.py",
            "sklearn/feature_selection/tests/test_feature_select.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "scikit-learn__scikit-learn-25747",
      "repo": "scikit-learn/scikit-learn",
      "valid": true,
      "worker": "http://34.59.30.169:8080",
      "duration": 8.018846988677979,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 14,
          "failed": 1,
          "errors": 0,
          "collected": 15,
          "duration": 3.7,
          "log_tail": "\u001b[1m============================= test session starts ==============================\u001b[0m\n\u001b[1mcollecting ... \u001b[0mcollected 15 items\n\nsklearn/utils/tests/test_set_output.py::test__wrap_in_pandas_container_dense \u001b[32mPASSED\u001b[0m\u001b[32m [  6%]\u001b[0m\nsklearn/utils/tests/test_set_output.py::test__wrap_in_pandas_container_dense_update_columns_and_index \u001b[32mPASSED\u001b[0m\u001b[32m [ 13%]\u001b[0m\nsklearn/utils/tests/test_set_output.py::test__wrap_in_pandas_container_error_validation \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\nsklearn/utils/tests/test_set_output.py::test__safe_set_output \u001b[32mPASSED\u001b[0m\u001b[32m     [ 26%]\u001b[0m\nsklearn/utils/tests/test_set_output.py::test_set_output_mixin \u001b[32mPASSED\u001b[0m\u001b[32m     [ 33%]\u001b[0m\nsklearn/utils/tests/test_set_output.py::test__safe_set_output_error \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\nsklearn/utils/tests/test_set_output.py::test_set_output_method \u001b[32mPASSED\u001b[0m\u001b[32m    [ 46%]\u001b[0m\nsklearn/utils/tests/test_set_output.py::test_set_output_method_error \u001b[32mPASSED\u001b[0m\u001b[32m [ 53%]\u001b[0m\nsklearn/utils/tests/test_set_output.py::test__get_output_config \u001b[32mPASSED\u001b[0m\u001b[32m   [ 60%]\u001b[0m\nsklearn/utils/tests/test_set_output.py::test_get_output_auto_wrap_false \u001b[32mPASSED\u001b[0m\u001b[32m [ 66%]\u001b[0m\nsklearn/utils/tests/test_set_output.py::test_auto_wrap_output_keys_errors_with_incorrect_input \u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\nsklearn/utils/tests/test_set_output.py::test_set_output_mixin_custom_mixin \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\nsklearn/utils/tests/test_set_output.py::test__wrap_in_pandas_container_column_errors \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\nsklearn/utils/tests/test_set_output.py::test_set_output_mro \u001b[32mPASSED\u001b[0m\u001b[32m       [ 93%]\u001b[0m\nsklearn/utils/tests/test_set_output.py::test_set_output_pandas_keep_index \u001b[31mFAILED\u001b[0m\u001b[31m [100%]\u001b[0m\n\n=================================== FAILURES ===================================\n\u001b[31m\u001b[1m______________________ test_set_output_pandas_keep_index _______________________\u001b[0m\n\u001b[1m\u001b[31msklearn/utils/tests/test_set_output.py\u001b[0m:294: in test_set_output_pandas_keep_index\n    assert_array_equal(X_trans.index, [\"s0\", \"s1\"])\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Arrays are not equal\u001b[0m\n\u001b[1m\u001b[31mE   \u001b[0m\n\u001b[1m\u001b[31mE   Mismatched elements: 1 / 1 (100%)\u001b[0m\n\u001b[1m\u001b[31mE    x: array([0, 1])\u001b[0m\n\u001b[1m\u001b[31mE    y: array(['s0', 's1'], dtype='<U2')\u001b[0m\n\u001b[31m=================== \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m14 passed\u001b[0m, \u001b[33m1 warning\u001b[0m\u001b[31m in 0.34s\u001b[0m\u001b[31m ====================\u001b[0m\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sklearn/utils/tests/test_set_output.py` failed. (See above for error)",
          "test_files_run": [
            "sklearn/utils/tests/test_set_output.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 15,
          "failed": 0,
          "errors": 0,
          "collected": 15,
          "duration": 3.4,
          "log_tail": "\u001b[1m============================= test session starts ==============================\u001b[0m\n\u001b[1mcollecting ... \u001b[0mcollected 15 items\n\nsklearn/utils/tests/test_set_output.py::test__wrap_in_pandas_container_dense \u001b[32mPASSED\u001b[0m\u001b[32m [  6%]\u001b[0m\nsklearn/utils/tests/test_set_output.py::test__wrap_in_pandas_container_dense_update_columns_and_index \u001b[32mPASSED\u001b[0m\u001b[32m [ 13%]\u001b[0m\nsklearn/utils/tests/test_set_output.py::test__wrap_in_pandas_container_error_validation \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%]\u001b[0m\nsklearn/utils/tests/test_set_output.py::test__safe_set_output \u001b[32mPASSED\u001b[0m\u001b[32m     [ 26%]\u001b[0m\nsklearn/utils/tests/test_set_output.py::test_set_output_mixin \u001b[32mPASSED\u001b[0m\u001b[32m     [ 33%]\u001b[0m\nsklearn/utils/tests/test_set_output.py::test__safe_set_output_error \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\nsklearn/utils/tests/test_set_output.py::test_set_output_method \u001b[32mPASSED\u001b[0m\u001b[32m    [ 46%]\u001b[0m\nsklearn/utils/tests/test_set_output.py::test_set_output_method_error \u001b[32mPASSED\u001b[0m\u001b[32m [ 53%]\u001b[0m\nsklearn/utils/tests/test_set_output.py::test__get_output_config \u001b[32mPASSED\u001b[0m\u001b[32m   [ 60%]\u001b[0m\nsklearn/utils/tests/test_set_output.py::test_get_output_auto_wrap_false \u001b[32mPASSED\u001b[0m\u001b[32m [ 66%]\u001b[0m\nsklearn/utils/tests/test_set_output.py::test_auto_wrap_output_keys_errors_with_incorrect_input \u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\nsklearn/utils/tests/test_set_output.py::test_set_output_mixin_custom_mixin \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\nsklearn/utils/tests/test_set_output.py::test__wrap_in_pandas_container_column_errors \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\nsklearn/utils/tests/test_set_output.py::test_set_output_mro \u001b[32mPASSED\u001b[0m\u001b[32m       [ 93%]\u001b[0m\nsklearn/utils/tests/test_set_output.py::test_set_output_pandas_keep_index \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n\n\u001b[32m============================== \u001b[32m\u001b[1m15 passed\u001b[0m\u001b[32m in 0.25s\u001b[0m\u001b[32m ==============================\u001b[0m\n\n",
          "test_files_run": [
            "sklearn/utils/tests/test_set_output.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "scikit-learn__scikit-learn-26323",
      "repo": "scikit-learn/scikit-learn",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 10.081176280975342,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 188,
          "failed": 1,
          "errors": 0,
          "collected": 189,
          "duration": 4.84,
          "log_tail": "sklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false[transformers8-passthrough-expected_names8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false[transformers9-drop-expected_names9] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false[transformers10-passthrough-expected_names10] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false[transformers11-passthrough-expected_names11] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false[transformers12-drop-expected_names12] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false[transformers13-drop-expected_names13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false_errors[transformers0-drop-['b']] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false_errors[transformers1-drop-['c']] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false_errors[transformers2-passthrough-['a']] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false_errors[transformers3-passthrough-['a']] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false_errors[transformers4-drop-['b', 'c']] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false_errors[transformers5-passthrough-['a']] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false_errors[transformers6-passthrough-['a', 'b']] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false_errors[transformers7-passthrough-['pca0', 'pca1', 'pca2', 'pca3', 'pca4', ...]] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false_errors[transformers8-passthrough-['a', 'b']] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false_errors[transformers9-passthrough-['a', 'b']] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false_errors[transformers10-passthrough-['a', 'b']] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false_errors[transformers11-passthrough-['a', 'b']] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_column_transformer_set_output[drop-True] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_column_transformer_set_output[drop-False] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_column_transformer_set_output[passthrough-True] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_column_transformer_set_output[passthrough-False] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_column_transform_set_output_mixed[True-drop] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_column_transform_set_output_mixed[True-passthrough] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_column_transform_set_output_mixed[False-drop] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_column_transform_set_output_mixed[False-passthrough] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_column_transform_set_output_after_fitting[drop] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_column_transform_set_output_after_fitting[passthrough] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_transformers_with_pandas_out_but_not_feature_names_out[trans_10-expected_verbose_names0-expected_non_verbose_names0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_transformers_with_pandas_out_but_not_feature_names_out[drop-expected_verbose_names1-expected_non_verbose_names1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_transformers_with_pandas_out_but_not_feature_names_out[passthrough-expected_verbose_names2-expected_non_verbose_names2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_empty_selection_pandas_output[list] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_empty_selection_pandas_output[bool] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_empty_selection_pandas_output[bool_int] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_raise_error_if_index_not_aligned \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_remainder_set_output \u001b[31mFAILED\u001b[0m\u001b[31m [100%]\u001b[0m\n\n=================================== FAILURES ===================================\n\u001b[31m\u001b[1m__________________________ test_remainder_set_output ___________________________\u001b[0m\n\u001b[1m\u001b[31msklearn/compose/tests/test_column_transformer.py\u001b[0m:2208: in test_remainder_set_output\n    pd.testing.assert_frame_equal(out, df)\n\u001b[1m\u001b[31mE   AssertionError: Attributes of DataFrame.iloc[:, 0] (column name=\"a\") are different\u001b[0m\n\u001b[1m\u001b[31mE   \u001b[0m\n\u001b[1m\u001b[31mE   Attribute \"dtype\" are different\u001b[0m\n\u001b[1m\u001b[31mE   [left]:  int64\u001b[0m\n\u001b[1m\u001b[31mE   [right]: bool\u001b[0m\n\u001b[31m======================== \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m188 passed\u001b[0m\u001b[31m in 1.68s\u001b[0m\u001b[31m =========================\u001b[0m\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sklearn/compose/tests/test_column_transformer.py` failed. (See above for error)",
          "test_files_run": [
            "sklearn/compose/tests/test_column_transformer.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 189,
          "failed": 0,
          "errors": 0,
          "collected": 189,
          "duration": 4.36,
          "log_tail": "sklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_true[transformers11-passthrough-expected_names11] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_true[transformers12-passthrough-expected_names12] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false[transformers0-passthrough-expected_names0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false[transformers1-drop-expected_names1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false[transformers2-passthrough-expected_names2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false[transformers3-passthrough-expected_names3] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false[transformers4-drop-expected_names4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false[transformers5-passthrough-expected_names5] \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false[transformers6-drop-expected_names6] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false[transformers7-passthrough-expected_names7] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false[transformers8-passthrough-expected_names8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false[transformers9-drop-expected_names9] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false[transformers10-passthrough-expected_names10] \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false[transformers11-passthrough-expected_names11] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false[transformers12-drop-expected_names12] \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false[transformers13-drop-expected_names13] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false_errors[transformers0-drop-['b']] \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false_errors[transformers1-drop-['c']] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false_errors[transformers2-passthrough-['a']] \u001b[32mPASSED\u001b[0m\u001b[32m [ 85%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false_errors[transformers3-passthrough-['a']] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false_errors[transformers4-drop-['b', 'c']] \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false_errors[transformers5-passthrough-['a']] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false_errors[transformers6-passthrough-['a', 'b']] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false_errors[transformers7-passthrough-['pca0', 'pca1', 'pca2', 'pca3', 'pca4', ...]] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false_errors[transformers8-passthrough-['a', 'b']] \u001b[32mPASSED\u001b[0m\u001b[32m [ 88%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false_errors[transformers9-passthrough-['a', 'b']] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false_errors[transformers10-passthrough-['a', 'b']] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_verbose_feature_names_out_false_errors[transformers11-passthrough-['a', 'b']] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_column_transformer_set_output[drop-True] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_column_transformer_set_output[drop-False] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_column_transformer_set_output[passthrough-True] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_column_transformer_set_output[passthrough-False] \u001b[32mPASSED\u001b[0m\u001b[32m [ 92%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_column_transform_set_output_mixed[True-drop] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_column_transform_set_output_mixed[True-passthrough] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_column_transform_set_output_mixed[False-drop] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_column_transform_set_output_mixed[False-passthrough] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_column_transform_set_output_after_fitting[drop] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_column_transform_set_output_after_fitting[passthrough] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_transformers_with_pandas_out_but_not_feature_names_out[trans_10-expected_verbose_names0-expected_non_verbose_names0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_transformers_with_pandas_out_but_not_feature_names_out[drop-expected_verbose_names1-expected_non_verbose_names1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 96%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_transformers_with_pandas_out_but_not_feature_names_out[passthrough-expected_verbose_names2-expected_non_verbose_names2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_empty_selection_pandas_output[list] \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_empty_selection_pandas_output[bool] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_empty_selection_pandas_output[bool_int] \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_raise_error_if_index_not_aligned \u001b[32mPASSED\u001b[0m\u001b[32m [ 99%]\u001b[0m\nsklearn/compose/tests/test_column_transformer.py::test_remainder_set_output \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n\n\u001b[32m============================= \u001b[32m\u001b[1m189 passed\u001b[0m\u001b[32m in 1.46s\u001b[0m\u001b[32m ==============================\u001b[0m\n\n",
          "test_files_run": [
            "sklearn/compose/tests/test_column_transformer.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "scikit-learn__scikit-learn-26194",
      "repo": "scikit-learn/scikit-learn",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 12.180893898010254,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 203,
          "failed": 2,
          "errors": 0,
          "collected": 205,
          "duration": 6.63,
          "log_tail": "sklearn/metrics/tests/test_ranking.py::test_top_k_accuracy_score_warning[y_true0-4] \u001b[32mPASSED\u001b[0m\u001b[31m [ 87%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_top_k_accuracy_score_warning[y_true1-5] \u001b[32mPASSED\u001b[0m\u001b[31m [ 87%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_top_k_accuracy_score_error[y_true0-y_score0-None-y type must be 'binary' or 'multiclass', got 'continuous'] \u001b[32mPASSED\u001b[0m\u001b[31m [ 88%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_top_k_accuracy_score_error[y_true1-y_score1-None-Number of classes in 'y_true' \\\\(4\\\\) not equal to the number of classes in 'y_score' \\\\(3\\\\).] \u001b[32mPASSED\u001b[0m\u001b[31m [ 88%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_top_k_accuracy_score_error[y_true2-y_score2-labels2-Parameter 'labels' must be unique.] \u001b[32mPASSED\u001b[0m\u001b[31m [ 89%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_top_k_accuracy_score_error[y_true3-y_score3-labels3-Parameter 'labels' must be ordered.] \u001b[32mPASSED\u001b[0m\u001b[31m [ 89%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_top_k_accuracy_score_error[y_true4-y_score4-labels4-Number of given labels \\\\(4\\\\) not equal to the number of classes in 'y_score' \\\\(3\\\\).] \u001b[32mPASSED\u001b[0m\u001b[31m [ 90%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_top_k_accuracy_score_error[y_true5-y_score5-labels5-'y_true' contains labels not in parameter 'labels'.] \u001b[32mPASSED\u001b[0m\u001b[31m [ 90%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_top_k_accuracy_score_error[y_true6-y_score6-None-`y_true` is binary while y_score is 2d with 3 classes. If `y_true` does not contain all the labels, `labels` must be provided] \u001b[32mPASSED\u001b[0m\u001b[31m [ 91%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_label_ranking_avg_precision_score_should_allow_csr_matrix_for_y_true_input \u001b[32mPASSED\u001b[0m\u001b[31m [ 91%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_ranking_metric_pos_label_types[classes0-average_precision_score] \u001b[32mPASSED\u001b[0m\u001b[31m [ 92%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_ranking_metric_pos_label_types[classes0-det_curve] \u001b[32mPASSED\u001b[0m\u001b[31m [ 92%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_ranking_metric_pos_label_types[classes0-precision_recall_curve] \u001b[32mPASSED\u001b[0m\u001b[31m [ 93%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_ranking_metric_pos_label_types[classes0-roc_curve] \u001b[32mPASSED\u001b[0m\u001b[31m [ 93%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_ranking_metric_pos_label_types[classes1-average_precision_score] \u001b[32mPASSED\u001b[0m\u001b[31m [ 94%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_ranking_metric_pos_label_types[classes1-det_curve] \u001b[32mPASSED\u001b[0m\u001b[31m [ 94%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_ranking_metric_pos_label_types[classes1-precision_recall_curve] \u001b[32mPASSED\u001b[0m\u001b[31m [ 95%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_ranking_metric_pos_label_types[classes1-roc_curve] \u001b[32mPASSED\u001b[0m\u001b[31m [ 95%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_ranking_metric_pos_label_types[classes2-average_precision_score] \u001b[32mPASSED\u001b[0m\u001b[31m [ 96%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_ranking_metric_pos_label_types[classes2-det_curve] \u001b[32mPASSED\u001b[0m\u001b[31m [ 96%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_ranking_metric_pos_label_types[classes2-precision_recall_curve] \u001b[32mPASSED\u001b[0m\u001b[31m [ 97%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_ranking_metric_pos_label_types[classes2-roc_curve] \u001b[32mPASSED\u001b[0m\u001b[31m [ 97%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_ranking_metric_pos_label_types[classes3-average_precision_score] \u001b[32mPASSED\u001b[0m\u001b[31m [ 98%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_ranking_metric_pos_label_types[classes3-det_curve] \u001b[32mPASSED\u001b[0m\u001b[31m [ 98%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_ranking_metric_pos_label_types[classes3-precision_recall_curve] \u001b[32mPASSED\u001b[0m\u001b[31m [ 99%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_ranking_metric_pos_label_types[classes3-roc_curve] \u001b[32mPASSED\u001b[0m\u001b[31m [ 99%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_roc_curve_with_probablity_estimates[42] \u001b[31mFAILED\u001b[0m\u001b[31m [100%]\u001b[0m\n\n=================================== FAILURES ===================================\n\u001b[31m\u001b[1m_______________________ test_roc_curve_drop_intermediate _______________________\u001b[0m\n\u001b[1m\u001b[31msklearn/metrics/tests/test_ranking.py\u001b[0m:421: in test_roc_curve_drop_intermediate\n    assert_array_almost_equal(thresholds, [np.inf, 1.0, 0.7, 0.0])\n\u001b[1m\u001b[31m/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/testing/_private/utils.py\u001b[0m:740: in func_assert_same_pos\n    raise AssertionError(msg)\n\u001b[1m\u001b[31mE   AssertionError: \u001b[0m\n\u001b[1m\u001b[31mE   Arrays are not almost equal to 6 decimals\u001b[0m\n\u001b[1m\u001b[31mE   \u001b[0m\n\u001b[1m\u001b[31mE   x and y +inf location mismatch:\u001b[0m\n\u001b[1m\u001b[31mE    x: array([2. , 1. , 0.7, 0. ])\u001b[0m\n\u001b[1m\u001b[31mE    y: array([inf, 1. , 0.7, 0. ])\u001b[0m\n\u001b[31m\u001b[1m_________________ test_roc_curve_with_probablity_estimates[42] _________________\u001b[0m\n\u001b[1m\u001b[31msklearn/metrics/tests/test_ranking.py\u001b[0m:2215: in test_roc_curve_with_probablity_estimates\n    assert np.isinf(thresholds[0])\n\u001b[1m\u001b[31mE   AssertionError: assert False\u001b[0m\n\u001b[1m\u001b[31mE    +  where False = <ufunc 'isinf'>(1.9699098521619942)\u001b[0m\n\u001b[1m\u001b[31mE    +    where <ufunc 'isinf'> = np.isinf\u001b[0m\n\u001b[31m================== \u001b[31m\u001b[1m2 failed\u001b[0m, \u001b[32m203 passed\u001b[0m, \u001b[33m3 warnings\u001b[0m\u001b[31m in 1.78s\u001b[0m\u001b[31m ===================\u001b[0m\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sklearn/metrics/tests/test_ranking.py` failed. (See above for error)",
          "test_files_run": [
            "sklearn/metrics/tests/test_ranking.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 205,
          "failed": 0,
          "errors": 0,
          "collected": 205,
          "duration": 4.52,
          "log_tail": "sklearn/metrics/tests/test_ranking.py::test_top_k_accuracy_score[y_true2-3-0.75] \u001b[32mPASSED\u001b[0m\u001b[33m [ 78%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_top_k_accuracy_score_binary[y_score0-1-1] \u001b[32mPASSED\u001b[0m\u001b[33m [ 78%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_top_k_accuracy_score_binary[y_score1-1-0.5] \u001b[32mPASSED\u001b[0m\u001b[33m [ 79%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_top_k_accuracy_score_binary[y_score2-2-1] \u001b[32mPASSED\u001b[0m\u001b[33m [ 79%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_top_k_accuracy_score_binary[y_score3-1-1] \u001b[32mPASSED\u001b[0m\u001b[33m [ 80%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_top_k_accuracy_score_binary[y_score4-1-0.5] \u001b[32mPASSED\u001b[0m\u001b[33m [ 80%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_top_k_accuracy_score_binary[y_score5-2-1] \u001b[32mPASSED\u001b[0m\u001b[33m [ 80%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_top_k_accuracy_score_multiclass_with_labels[True-y_true0-0.75-labels0] \u001b[32mPASSED\u001b[0m\u001b[33m [ 81%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_top_k_accuracy_score_multiclass_with_labels[True-y_true1-0.5-labels1] \u001b[32mPASSED\u001b[0m\u001b[33m [ 81%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_top_k_accuracy_score_multiclass_with_labels[True-y_true2-0.5-labels2] \u001b[32mPASSED\u001b[0m\u001b[33m [ 82%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_top_k_accuracy_score_multiclass_with_labels[True-y_true3-0.75-labels3] \u001b[32mPASSED\u001b[0m\u001b[33m [ 82%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_top_k_accuracy_score_multiclass_with_labels[False-y_true0-0.75-labels0] \u001b[32mPASSED\u001b[0m\u001b[33m [ 83%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_top_k_accuracy_score_multiclass_with_labels[False-y_true1-0.5-labels1] \u001b[32mPASSED\u001b[0m\u001b[33m [ 83%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_top_k_accuracy_score_multiclass_with_labels[False-y_true2-0.5-labels2] \u001b[32mPASSED\u001b[0m\u001b[33m [ 84%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_top_k_accuracy_score_multiclass_with_labels[False-y_true3-0.75-labels3] \u001b[32mPASSED\u001b[0m\u001b[33m [ 84%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_top_k_accuracy_score_increasing \u001b[32mPASSED\u001b[0m\u001b[33m [ 85%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_top_k_accuracy_score_ties[y_true0-1-0.25] \u001b[32mPASSED\u001b[0m\u001b[33m [ 85%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_top_k_accuracy_score_ties[y_true1-2-0.5] \u001b[32mPASSED\u001b[0m\u001b[33m [ 86%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_top_k_accuracy_score_ties[y_true2-3-1] \u001b[32mPASSED\u001b[0m\u001b[33m [ 86%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_top_k_accuracy_score_warning[y_true0-4] \u001b[32mPASSED\u001b[0m\u001b[33m [ 87%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_top_k_accuracy_score_warning[y_true1-5] \u001b[32mPASSED\u001b[0m\u001b[33m [ 87%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_top_k_accuracy_score_error[y_true0-y_score0-None-y type must be 'binary' or 'multiclass', got 'continuous'] \u001b[32mPASSED\u001b[0m\u001b[33m [ 88%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_top_k_accuracy_score_error[y_true1-y_score1-None-Number of classes in 'y_true' \\\\(4\\\\) not equal to the number of classes in 'y_score' \\\\(3\\\\).] \u001b[32mPASSED\u001b[0m\u001b[33m [ 88%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_top_k_accuracy_score_error[y_true2-y_score2-labels2-Parameter 'labels' must be unique.] \u001b[32mPASSED\u001b[0m\u001b[33m [ 89%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_top_k_accuracy_score_error[y_true3-y_score3-labels3-Parameter 'labels' must be ordered.] \u001b[32mPASSED\u001b[0m\u001b[33m [ 89%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_top_k_accuracy_score_error[y_true4-y_score4-labels4-Number of given labels \\\\(4\\\\) not equal to the number of classes in 'y_score' \\\\(3\\\\).] \u001b[32mPASSED\u001b[0m\u001b[33m [ 90%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_top_k_accuracy_score_error[y_true5-y_score5-labels5-'y_true' contains labels not in parameter 'labels'.] \u001b[32mPASSED\u001b[0m\u001b[33m [ 90%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_top_k_accuracy_score_error[y_true6-y_score6-None-`y_true` is binary while y_score is 2d with 3 classes. If `y_true` does not contain all the labels, `labels` must be provided] \u001b[32mPASSED\u001b[0m\u001b[33m [ 91%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_label_ranking_avg_precision_score_should_allow_csr_matrix_for_y_true_input \u001b[32mPASSED\u001b[0m\u001b[33m [ 91%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_ranking_metric_pos_label_types[classes0-average_precision_score] \u001b[32mPASSED\u001b[0m\u001b[33m [ 92%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_ranking_metric_pos_label_types[classes0-det_curve] \u001b[32mPASSED\u001b[0m\u001b[33m [ 92%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_ranking_metric_pos_label_types[classes0-precision_recall_curve] \u001b[32mPASSED\u001b[0m\u001b[33m [ 93%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_ranking_metric_pos_label_types[classes0-roc_curve] \u001b[32mPASSED\u001b[0m\u001b[33m [ 93%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_ranking_metric_pos_label_types[classes1-average_precision_score] \u001b[32mPASSED\u001b[0m\u001b[33m [ 94%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_ranking_metric_pos_label_types[classes1-det_curve] \u001b[32mPASSED\u001b[0m\u001b[33m [ 94%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_ranking_metric_pos_label_types[classes1-precision_recall_curve] \u001b[32mPASSED\u001b[0m\u001b[33m [ 95%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_ranking_metric_pos_label_types[classes1-roc_curve] \u001b[32mPASSED\u001b[0m\u001b[33m [ 95%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_ranking_metric_pos_label_types[classes2-average_precision_score] \u001b[32mPASSED\u001b[0m\u001b[33m [ 96%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_ranking_metric_pos_label_types[classes2-det_curve] \u001b[32mPASSED\u001b[0m\u001b[33m [ 96%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_ranking_metric_pos_label_types[classes2-precision_recall_curve] \u001b[32mPASSED\u001b[0m\u001b[33m [ 97%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_ranking_metric_pos_label_types[classes2-roc_curve] \u001b[32mPASSED\u001b[0m\u001b[33m [ 97%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_ranking_metric_pos_label_types[classes3-average_precision_score] \u001b[32mPASSED\u001b[0m\u001b[33m [ 98%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_ranking_metric_pos_label_types[classes3-det_curve] \u001b[32mPASSED\u001b[0m\u001b[33m [ 98%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_ranking_metric_pos_label_types[classes3-precision_recall_curve] \u001b[32mPASSED\u001b[0m\u001b[33m [ 99%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_ranking_metric_pos_label_types[classes3-roc_curve] \u001b[32mPASSED\u001b[0m\u001b[33m [ 99%]\u001b[0m\nsklearn/metrics/tests/test_ranking.py::test_roc_curve_with_probablity_estimates[42] \u001b[32mPASSED\u001b[0m\u001b[33m [100%]\u001b[0m\n\n\u001b[33m======================= \u001b[32m205 passed\u001b[0m, \u001b[33m\u001b[1m3 warnings\u001b[0m\u001b[33m in 1.62s\u001b[0m\u001b[33m ========================\u001b[0m\n\n",
          "test_files_run": [
            "sklearn/metrics/tests/test_ranking.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "scikit-learn__scikit-learn-25931",
      "repo": "scikit-learn/scikit-learn",
      "valid": true,
      "worker": "http://34.41.233.120:8080",
      "duration": 17.259926080703735,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 21,
          "failed": 1,
          "errors": 0,
          "collected": 22,
          "duration": 9.34,
          "log_tail": "\u001b[1m============================= test session starts ==============================\u001b[0m\n\u001b[1mcollecting ... \u001b[0mcollected 22 items\n\nsklearn/ensemble/tests/test_iforest.py::test_iforest[42] \u001b[32mPASSED\u001b[0m\u001b[32m          [  4%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_iforest_sparse[42] \u001b[32mPASSED\u001b[0m\u001b[32m   [  9%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_iforest_error \u001b[32mPASSED\u001b[0m\u001b[32m        [ 13%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_recalculate_max_depth \u001b[32mPASSED\u001b[0m\u001b[32m [ 18%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_max_samples_attribute \u001b[32mPASSED\u001b[0m\u001b[32m [ 22%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_iforest_parallel_regression[42] \u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_iforest_performance[42] \u001b[32mPASSED\u001b[0m\u001b[32m [ 31%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_iforest_works[42-0.25] \u001b[32mPASSED\u001b[0m\u001b[32m [ 36%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_iforest_works[42-auto] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_max_samples_consistency \u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_iforest_subsampled_features \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_iforest_average_path_length \u001b[32mPASSED\u001b[0m\u001b[32m [ 54%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_score_samples \u001b[32mPASSED\u001b[0m\u001b[32m        [ 59%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_iforest_warm_start \u001b[32mPASSED\u001b[0m\u001b[32m   [ 63%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_iforest_chunks_works1[42-0.25-3] \u001b[32mPASSED\u001b[0m\u001b[32m [ 68%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_iforest_chunks_works1[42-auto-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 72%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_iforest_chunks_works2[42-0.25-3] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_iforest_chunks_works2[42-auto-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_iforest_with_uniform_data \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_iforest_with_n_jobs_does_not_segfault \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_base_estimator_property_deprecated \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_iforest_preserve_feature_names \u001b[31mFAILED\u001b[0m\u001b[31m [100%]\u001b[0m\n\n=================================== FAILURES ===================================\n\u001b[31m\u001b[1m_____________________ test_iforest_preserve_feature_names ______________________\u001b[0m\n\u001b[1m\u001b[31msklearn/ensemble/tests/test_iforest.py\u001b[0m:359: in test_iforest_preserve_feature_names\n    model.fit(X)\n\u001b[1m\u001b[31msklearn/ensemble/_iforest.py\u001b[0m:348: in fit\n    self.offset_ = np.percentile(self.score_samples(X), 100.0 * self.contamination)\n\u001b[1m\u001b[31msklearn/ensemble/_iforest.py\u001b[0m:436: in score_samples\n    X = self._validate_data(X, accept_sparse=\"csr\", dtype=np.float32, reset=False)\n\u001b[1m\u001b[31msklearn/base.py\u001b[0m:566: in _validate_data\n    self._check_feature_names(X, reset=reset)\n\u001b[1m\u001b[31msklearn/base.py\u001b[0m:451: in _check_feature_names\n    warnings.warn(\n\u001b[1m\u001b[31mE   UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\u001b[0m\n\u001b[31m========================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m21 passed\u001b[0m\u001b[31m in 4.52s\u001b[0m\u001b[31m =========================\u001b[0m\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sklearn/ensemble/tests/test_iforest.py` failed. (See above for error)",
          "test_files_run": [
            "sklearn/ensemble/tests/test_iforest.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 22,
          "failed": 0,
          "errors": 0,
          "collected": 22,
          "duration": 7.07,
          "log_tail": "\u001b[1m============================= test session starts ==============================\u001b[0m\n\u001b[1mcollecting ... \u001b[0mcollected 22 items\n\nsklearn/ensemble/tests/test_iforest.py::test_iforest[42] \u001b[32mPASSED\u001b[0m\u001b[32m          [  4%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_iforest_sparse[42] \u001b[32mPASSED\u001b[0m\u001b[32m   [  9%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_iforest_error \u001b[32mPASSED\u001b[0m\u001b[32m        [ 13%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_recalculate_max_depth \u001b[32mPASSED\u001b[0m\u001b[32m [ 18%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_max_samples_attribute \u001b[32mPASSED\u001b[0m\u001b[32m [ 22%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_iforest_parallel_regression[42] \u001b[32mPASSED\u001b[0m\u001b[32m [ 27%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_iforest_performance[42] \u001b[32mPASSED\u001b[0m\u001b[32m [ 31%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_iforest_works[42-0.25] \u001b[32mPASSED\u001b[0m\u001b[32m [ 36%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_iforest_works[42-auto] \u001b[32mPASSED\u001b[0m\u001b[32m [ 40%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_max_samples_consistency \u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_iforest_subsampled_features \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_iforest_average_path_length \u001b[32mPASSED\u001b[0m\u001b[32m [ 54%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_score_samples \u001b[32mPASSED\u001b[0m\u001b[32m        [ 59%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_iforest_warm_start \u001b[32mPASSED\u001b[0m\u001b[32m   [ 63%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_iforest_chunks_works1[42-0.25-3] \u001b[32mPASSED\u001b[0m\u001b[32m [ 68%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_iforest_chunks_works1[42-auto-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 72%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_iforest_chunks_works2[42-0.25-3] \u001b[32mPASSED\u001b[0m\u001b[32m [ 77%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_iforest_chunks_works2[42-auto-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 81%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_iforest_with_uniform_data \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_iforest_with_n_jobs_does_not_segfault \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_base_estimator_property_deprecated \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\nsklearn/ensemble/tests/test_iforest.py::test_iforest_preserve_feature_names \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n\n\u001b[32m============================== \u001b[32m\u001b[1m22 passed\u001b[0m\u001b[32m in 4.35s\u001b[0m\u001b[32m ==============================\u001b[0m\n\n",
          "test_files_run": [
            "sklearn/ensemble/tests/test_iforest.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "matplotlib__matplotlib-25287",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 1
    },
    {
      "instance_id": "matplotlib__matplotlib-26208",
      "repo": "matplotlib/matplotlib",
      "valid": false,
      "worker": "http://35.239.238.137:8080",
      "error": "HTTPConnectionPool(host='35.239.238.137', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 1
    },
    {
      "instance_id": "scikit-learn__scikit-learn-14087",
      "repo": "scikit-learn/scikit-learn",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 65.04604125022888,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 172,
          "failed": 3,
          "errors": 0,
          "collected": 175,
          "duration": 35.77,
          "log_tail": "    lrcv.fit(X, y)\nsklearn/linear_model/logistic.py:2184: in fit\n    self.l1_ratio_.append(np.mean(l1_ratios_[best_indices_l1]))\nE   TypeError: only integer scalar arrays can be converted to a scalar index\n______________ test_LogisticRegressionCV_no_refit[multinomial-l2] ______________\nsklearn/linear_model/tests/test_logistic.py:1555: in test_LogisticRegressionCV_no_refit\n    lrcv.fit(X, y)\nsklearn/linear_model/logistic.py:2184: in fit\n    self.l1_ratio_.append(np.mean(l1_ratios_[best_indices_l1]))\nE   TypeError: only integer scalar arrays can be converted to a scalar index\n_________________ test_LogisticRegressionCV_no_refit[auto-l2] __________________\nsklearn/linear_model/tests/test_logistic.py:1555: in test_LogisticRegressionCV_no_refit\n    lrcv.fit(X, y)\nsklearn/linear_model/logistic.py:2184: in fit\n    self.l1_ratio_.append(np.mean(l1_ratios_[best_indices_l1]))\nE   TypeError: only integer scalar arrays can be converted to a scalar index\n================= 3 failed, 172 passed, 446 warnings in 24.41s =================\nRUNNING THE L-BFGS-B CODE\n\n           * * *\n\nMachine precision = 2.220D-16\n N =            3     M =           10\n\nAt X0         0 variables are exactly at the bounds\n\nAt iterate    0    f=  1.38629D+02    |proj g|=  6.27865D+01\n\n           * * *\n\nTit   = total number of iterations\nTnf   = total number of function evaluations\nTnint = total number of segments explored during Cauchy searches\nSkip  = number of BFGS updates skipped\nNact  = number of active bounds at final generalized Cauchy point\nProjg = norm of the final projected gradient\nF     = final function value\n\n           * * *\n\n   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n    3      1      2      1     0     0   2.422D+01   9.713D+01\n  F =   97.133816163368223     \n\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n\n\n This problem is unconstrained.\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sklearn/linear_model/tests/test_logistic.py` failed. (See above for error)",
          "test_files_run": [
            "sklearn/linear_model/tests/test_logistic.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 175,
          "failed": 0,
          "errors": 0,
          "collected": 175,
          "duration": 18.35,
          "log_tail": "sklearn/linear_model/tests/test_logistic.py::test_logistic_regression_path_coefs_multinomial PASSED [ 91%]\nsklearn/linear_model/tests/test_logistic.py::test_logistic_regression_multi_class_auto[liblinear-est0] PASSED [ 92%]\nsklearn/linear_model/tests/test_logistic.py::test_logistic_regression_multi_class_auto[liblinear-est1] PASSED [ 92%]\nsklearn/linear_model/tests/test_logistic.py::test_logistic_regression_multi_class_auto[lbfgs-est0] PASSED [ 93%]\nsklearn/linear_model/tests/test_logistic.py::test_logistic_regression_multi_class_auto[lbfgs-est1] PASSED [ 93%]\nsklearn/linear_model/tests/test_logistic.py::test_logistic_regression_multi_class_auto[newton-cg-est0] PASSED [ 94%]\nsklearn/linear_model/tests/test_logistic.py::test_logistic_regression_multi_class_auto[newton-cg-est1] PASSED [ 94%]\nsklearn/linear_model/tests/test_logistic.py::test_logistic_regression_multi_class_auto[sag-est0] PASSED [ 95%]\nsklearn/linear_model/tests/test_logistic.py::test_logistic_regression_multi_class_auto[sag-est1] PASSED [ 96%]\nsklearn/linear_model/tests/test_logistic.py::test_logistic_regression_multi_class_auto[saga-est0] PASSED [ 96%]\nsklearn/linear_model/tests/test_logistic.py::test_logistic_regression_multi_class_auto[saga-est1] PASSED [ 97%]\nsklearn/linear_model/tests/test_logistic.py::test_logistic_regression_path_deprecation PASSED [ 97%]\nsklearn/linear_model/tests/test_logistic.py::test_penalty_none[lbfgs] PASSED [ 98%]\nsklearn/linear_model/tests/test_logistic.py::test_penalty_none[newton-cg] PASSED [ 98%]\nsklearn/linear_model/tests/test_logistic.py::test_penalty_none[sag] PASSED [ 99%]\nsklearn/linear_model/tests/test_logistic.py::test_penalty_none[saga] PASSED [100%]\n\n====================== 175 passed, 445 warnings in 15.83s ======================\nRUNNING THE L-BFGS-B CODE\n\n           * * *\n\nMachine precision = 2.220D-16\n N =            3     M =           10\n\nAt X0         0 variables are exactly at the bounds\n\nAt iterate    0    f=  1.38629D+02    |proj g|=  6.27865D+01\n\n           * * *\n\nTit   = total number of iterations\nTnf   = total number of function evaluations\nTnint = total number of segments explored during Cauchy searches\nSkip  = number of BFGS updates skipped\nNact  = number of active bounds at final generalized Cauchy point\nProjg = norm of the final projected gradient\nF     = final function value\n\n           * * *\n\n   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n    3      1      2      1     0     0   2.422D+01   9.713D+01\n  F =   97.133816163368223     \n\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n\n\n This problem is unconstrained.\n",
          "test_files_run": [
            "sklearn/linear_model/tests/test_logistic.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "scikit-learn__scikit-learn-25232",
      "repo": "scikit-learn/scikit-learn",
      "valid": true,
      "worker": "http://34.123.9.23:8080",
      "duration": 29.98396611213684,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 216,
          "failed": 1,
          "errors": 0,
          "collected": 217,
          "duration": 15.31,
          "log_tail": "sklearn/impute/tests/test_impute.py::test_simple_imputation_inverse_transform[-1] \u001b[32mPASSED\u001b[0m\u001b[33m [ 82%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputation_inverse_transform[nan] \u001b[32mPASSED\u001b[0m\u001b[33m [ 82%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputation_inverse_transform_exceptions[-1] \u001b[32mPASSED\u001b[0m\u001b[33m [ 82%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputation_inverse_transform_exceptions[nan] \u001b[32mPASSED\u001b[0m\u001b[33m [ 83%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_most_frequent[extra_value-array0-object-extra_value-2] \u001b[32mPASSED\u001b[0m\u001b[33m [ 83%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_most_frequent[most_frequent_value-array1-object-extra_value-1] \u001b[32mPASSED\u001b[0m\u001b[33m [ 84%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_most_frequent[a-array2-object-a-2] \u001b[32mPASSED\u001b[0m\u001b[33m [ 84%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_most_frequent[min_value-array3-object-z-2] \u001b[32mPASSED\u001b[0m\u001b[33m [ 85%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_most_frequent[10-array4-int-10-2] \u001b[32mPASSED\u001b[0m\u001b[33m [ 85%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_most_frequent[1-array5-int-10-1] \u001b[32mPASSED\u001b[0m\u001b[33m [ 86%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_most_frequent[10-array6-int-10-2] \u001b[32mPASSED\u001b[0m\u001b[33m [ 86%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_most_frequent[1-array7-int-10-2] \u001b[32mPASSED\u001b[0m\u001b[33m [ 87%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_iterative_imputer_keep_empty_features[mean] \u001b[32mPASSED\u001b[0m\u001b[33m [ 87%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_iterative_imputer_keep_empty_features[median] \u001b[32mPASSED\u001b[0m\u001b[33m [ 88%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_iterative_imputer_keep_empty_features[most_frequent] \u001b[32mPASSED\u001b[0m\u001b[33m [ 88%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_iterative_imputer_keep_empty_features[constant] \u001b[32mPASSED\u001b[0m\u001b[33m [ 88%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_iterative_imputer_constant_fill_value \u001b[31mFAILED\u001b[0m\u001b[31m [ 89%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_knn_imputer_keep_empty_features[True] \u001b[32mPASSED\u001b[0m\u001b[31m [ 89%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_knn_imputer_keep_empty_features[False] \u001b[32mPASSED\u001b[0m\u001b[31m [ 90%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_impute_pd_na \u001b[32mPASSED\u001b[0m\u001b[31m     [ 90%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_missing_indicator_feature_names_out \u001b[32mPASSED\u001b[0m\u001b[31m [ 91%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_imputer_lists_fit_transform \u001b[32mPASSED\u001b[0m\u001b[31m [ 91%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_imputer_transform_preserves_numeric_dtype[float32] \u001b[32mPASSED\u001b[0m\u001b[31m [ 92%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_imputer_transform_preserves_numeric_dtype[float64] \u001b[32mPASSED\u001b[0m\u001b[31m [ 92%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputer_constant_keep_empty_features[True-array] \u001b[32mPASSED\u001b[0m\u001b[31m [ 93%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputer_constant_keep_empty_features[True-sparse] \u001b[32mPASSED\u001b[0m\u001b[31m [ 93%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputer_constant_keep_empty_features[False-array] \u001b[32mPASSED\u001b[0m\u001b[31m [ 94%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputer_constant_keep_empty_features[False-sparse] \u001b[32mPASSED\u001b[0m\u001b[31m [ 94%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputer_keep_empty_features[True-mean-array] \u001b[32mPASSED\u001b[0m\u001b[31m [ 94%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputer_keep_empty_features[True-mean-sparse] \u001b[32mPASSED\u001b[0m\u001b[31m [ 95%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputer_keep_empty_features[True-median-array] \u001b[32mPASSED\u001b[0m\u001b[31m [ 95%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputer_keep_empty_features[True-median-sparse] \u001b[32mPASSED\u001b[0m\u001b[31m [ 96%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputer_keep_empty_features[True-most_frequent-array] \u001b[32mPASSED\u001b[0m\u001b[31m [ 96%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputer_keep_empty_features[True-most_frequent-sparse] \u001b[32mPASSED\u001b[0m\u001b[31m [ 97%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputer_keep_empty_features[False-mean-array] \u001b[32mPASSED\u001b[0m\u001b[31m [ 97%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputer_keep_empty_features[False-mean-sparse] \u001b[32mPASSED\u001b[0m\u001b[31m [ 98%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputer_keep_empty_features[False-median-array] \u001b[32mPASSED\u001b[0m\u001b[31m [ 98%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputer_keep_empty_features[False-median-sparse] \u001b[32mPASSED\u001b[0m\u001b[31m [ 99%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputer_keep_empty_features[False-most_frequent-array] \u001b[32mPASSED\u001b[0m\u001b[31m [ 99%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputer_keep_empty_features[False-most_frequent-sparse] \u001b[32mPASSED\u001b[0m\u001b[31m [100%]\u001b[0m\n\n=================================== FAILURES ===================================\n\u001b[31m\u001b[1m__________________ test_iterative_imputer_constant_fill_value __________________\u001b[0m\n\u001b[1m\u001b[31msklearn/impute/tests/test_impute.py\u001b[0m:1532: in test_iterative_imputer_constant_fill_value\n    imputer = IterativeImputer(\n\u001b[1m\u001b[31mE   TypeError: __init__() got an unexpected keyword argument 'fill_value'\u001b[0m\n\u001b[31m================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m216 passed\u001b[0m, \u001b[33m32 warnings\u001b[0m\u001b[31m in 10.60s\u001b[0m\u001b[31m ==================\u001b[0m\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sklearn/impute/tests/test_impute.py` failed. (See above for error)",
          "test_files_run": [
            "sklearn/impute/tests/test_impute.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 217,
          "failed": 0,
          "errors": 0,
          "collected": 217,
          "duration": 13.81,
          "log_tail": "sklearn/impute/tests/test_impute.py::test_simple_imputation_add_indicator_sparse_matrix[lil_matrix] \u001b[32mPASSED\u001b[0m\u001b[33m [ 79%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputation_add_indicator_sparse_matrix[bsr_matrix] \u001b[32mPASSED\u001b[0m\u001b[33m [ 79%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputation_string_list[most_frequent-b] \u001b[32mPASSED\u001b[0m\u001b[33m [ 80%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputation_string_list[constant-missing_value] \u001b[32mPASSED\u001b[0m\u001b[33m [ 80%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_imputation_order[ascending-idx_order0] \u001b[32mPASSED\u001b[0m\u001b[33m [ 81%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_imputation_order[descending-idx_order1] \u001b[32mPASSED\u001b[0m\u001b[33m [ 81%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputation_inverse_transform[-1] \u001b[32mPASSED\u001b[0m\u001b[33m [ 82%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputation_inverse_transform[nan] \u001b[32mPASSED\u001b[0m\u001b[33m [ 82%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputation_inverse_transform_exceptions[-1] \u001b[32mPASSED\u001b[0m\u001b[33m [ 82%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputation_inverse_transform_exceptions[nan] \u001b[32mPASSED\u001b[0m\u001b[33m [ 83%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_most_frequent[extra_value-array0-object-extra_value-2] \u001b[32mPASSED\u001b[0m\u001b[33m [ 83%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_most_frequent[most_frequent_value-array1-object-extra_value-1] \u001b[32mPASSED\u001b[0m\u001b[33m [ 84%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_most_frequent[a-array2-object-a-2] \u001b[32mPASSED\u001b[0m\u001b[33m [ 84%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_most_frequent[min_value-array3-object-z-2] \u001b[32mPASSED\u001b[0m\u001b[33m [ 85%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_most_frequent[10-array4-int-10-2] \u001b[32mPASSED\u001b[0m\u001b[33m [ 85%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_most_frequent[1-array5-int-10-1] \u001b[32mPASSED\u001b[0m\u001b[33m [ 86%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_most_frequent[10-array6-int-10-2] \u001b[32mPASSED\u001b[0m\u001b[33m [ 86%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_most_frequent[1-array7-int-10-2] \u001b[32mPASSED\u001b[0m\u001b[33m [ 87%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_iterative_imputer_keep_empty_features[mean] \u001b[32mPASSED\u001b[0m\u001b[33m [ 87%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_iterative_imputer_keep_empty_features[median] \u001b[32mPASSED\u001b[0m\u001b[33m [ 88%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_iterative_imputer_keep_empty_features[most_frequent] \u001b[32mPASSED\u001b[0m\u001b[33m [ 88%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_iterative_imputer_keep_empty_features[constant] \u001b[32mPASSED\u001b[0m\u001b[33m [ 88%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_iterative_imputer_constant_fill_value \u001b[32mPASSED\u001b[0m\u001b[33m [ 89%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_knn_imputer_keep_empty_features[True] \u001b[32mPASSED\u001b[0m\u001b[33m [ 89%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_knn_imputer_keep_empty_features[False] \u001b[32mPASSED\u001b[0m\u001b[33m [ 90%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_impute_pd_na \u001b[32mPASSED\u001b[0m\u001b[33m     [ 90%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_missing_indicator_feature_names_out \u001b[32mPASSED\u001b[0m\u001b[33m [ 91%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_imputer_lists_fit_transform \u001b[32mPASSED\u001b[0m\u001b[33m [ 91%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_imputer_transform_preserves_numeric_dtype[float32] \u001b[32mPASSED\u001b[0m\u001b[33m [ 92%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_imputer_transform_preserves_numeric_dtype[float64] \u001b[32mPASSED\u001b[0m\u001b[33m [ 92%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputer_constant_keep_empty_features[True-array] \u001b[32mPASSED\u001b[0m\u001b[33m [ 93%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputer_constant_keep_empty_features[True-sparse] \u001b[32mPASSED\u001b[0m\u001b[33m [ 93%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputer_constant_keep_empty_features[False-array] \u001b[32mPASSED\u001b[0m\u001b[33m [ 94%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputer_constant_keep_empty_features[False-sparse] \u001b[32mPASSED\u001b[0m\u001b[33m [ 94%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputer_keep_empty_features[True-mean-array] \u001b[32mPASSED\u001b[0m\u001b[33m [ 94%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputer_keep_empty_features[True-mean-sparse] \u001b[32mPASSED\u001b[0m\u001b[33m [ 95%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputer_keep_empty_features[True-median-array] \u001b[32mPASSED\u001b[0m\u001b[33m [ 95%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputer_keep_empty_features[True-median-sparse] \u001b[32mPASSED\u001b[0m\u001b[33m [ 96%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputer_keep_empty_features[True-most_frequent-array] \u001b[32mPASSED\u001b[0m\u001b[33m [ 96%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputer_keep_empty_features[True-most_frequent-sparse] \u001b[32mPASSED\u001b[0m\u001b[33m [ 97%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputer_keep_empty_features[False-mean-array] \u001b[32mPASSED\u001b[0m\u001b[33m [ 97%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputer_keep_empty_features[False-mean-sparse] \u001b[32mPASSED\u001b[0m\u001b[33m [ 98%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputer_keep_empty_features[False-median-array] \u001b[32mPASSED\u001b[0m\u001b[33m [ 98%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputer_keep_empty_features[False-median-sparse] \u001b[32mPASSED\u001b[0m\u001b[33m [ 99%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputer_keep_empty_features[False-most_frequent-array] \u001b[32mPASSED\u001b[0m\u001b[33m [ 99%]\u001b[0m\nsklearn/impute/tests/test_impute.py::test_simple_imputer_keep_empty_features[False-most_frequent-sparse] \u001b[32mPASSED\u001b[0m\u001b[33m [100%]\u001b[0m\n\n\u001b[33m====================== \u001b[32m217 passed\u001b[0m, \u001b[33m\u001b[1m32 warnings\u001b[0m\u001b[33m in 10.99s\u001b[0m\u001b[33m =======================\u001b[0m\n\n",
          "test_files_run": [
            "sklearn/impute/tests/test_impute.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "astropy__astropy-13033",
      "repo": "astropy/astropy",
      "valid": false,
      "worker": "http://34.123.9.23:8080",
      "duration": 9.707921981811523,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 20,
          "failed": 2,
          "errors": 0,
          "collected": 25,
          "duration": 4.99,
          "log_tail": "astropy/timeseries/tests/test_sampled.py::test_initialization_n_samples PASSED [ 48%]\nastropy/timeseries/tests/test_sampled.py::test_initialization_length_mismatch PASSED [ 52%]\nastropy/timeseries/tests/test_sampled.py::test_initialization_invalid_both_time_and_time_delta PASSED [ 56%]\nastropy/timeseries/tests/test_sampled.py::test_fold PASSED               [ 60%]\nastropy/timeseries/tests/test_sampled.py::test_fold_invalid_options PASSED [ 64%]\nastropy/timeseries/tests/test_sampled.py::test_pandas SKIPPED (could...) [ 68%]\nastropy/timeseries/tests/test_sampled.py::test_read_time_missing PASSED  [ 72%]\nastropy/timeseries/tests/test_sampled.py::test_read_time_wrong PASSED    [ 76%]\nastropy/timeseries/tests/test_sampled.py::test_read PASSED               [ 80%]\nastropy/timeseries/tests/test_sampled.py::test_kepler_astropy SKIPPED    [ 84%]\nastropy/timeseries/tests/test_sampled.py::test_tess_astropy SKIPPED      [ 88%]\nastropy/timeseries/tests/test_sampled.py::test_required_columns FAILED   [ 92%]\nastropy/timeseries/tests/test_sampled.py::test_periodogram[BoxLeastSquares] PASSED [ 96%]\nastropy/timeseries/tests/test_sampled.py::test_periodogram[LombScargle] PASSED [100%]\n\n=================================== FAILURES ===================================\n_____________________ test_initialization_with_time_delta ______________________\nastropy/time/core.py:2824: in update_leap_seconds\n    table = iers.LeapSeconds.auto_open(files)\nastropy/utils/iers/iers.py:1032: in auto_open\n    warn('leap-second file is expired.', IERSStaleWarning)\nE   astropy.utils.iers.iers.IERSStaleWarning: leap-second file is expired.\n\nDuring handling of the above exception, another exception occurred:\nastropy/timeseries/tests/test_sampled.py:67: in test_initialization_with_time_delta\n    ts = TimeSeries(time_start=datetime(2018, 7, 1, 10, 10, 10),\nastropy/timeseries/sampled.py:122: in __init__\n    time = time_start + time_delta\nastropy/time/core.py:2208: in __add__\n    out._set_scale('tai')\nastropy/time/core.py:554: in _set_scale\n    _check_leapsec()\nastropy/time/core.py:2795: in _check_leapsec\n    update_leap_seconds()\nastropy/time/core.py:2828: in update_leap_seconds\n    warn(\"leap-second auto-update failed due to the following \"\nE   astropy.utils.exceptions.AstropyWarning: leap-second auto-update failed due to the following exception: IERSStaleWarning('leap-second file is expired.')\n____________________________ test_required_columns _____________________________\nastropy/timeseries/tests/test_sampled.py:403: in test_required_columns\n    assert exc.value.args[0] == (\"TimeSeries object is invalid - expected \"\nE   assert \"TimeSeries o... found 'time'\" == \"TimeSeries o...['time', 'b']\"\nE     - TimeSeries object is invalid - expected ['time', 'a'] as the first columns but found ['time', 'b']\nE     ?                                         -      ------                                -      ------\nE     + TimeSeries object is invalid - expected 'time' as the first columns but found 'time'\n=================== 2 failed, 20 passed, 3 skipped in 0.29s ====================\n\n\n<frozen importlib._bootstrap>:228: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 80 from C header, got 96 from PyObject\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/timeseries/tests/test_sampled.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/timeseries/tests/test_sampled.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 21,
          "failed": 1,
          "errors": 0,
          "collected": 25,
          "duration": 3.86,
          "log_tail": "astropy/timeseries/tests/test_sampled.py::test_initialize_only_data PASSED [ 20%]\nastropy/timeseries/tests/test_sampled.py::test_initialization_with_table PASSED [ 24%]\nastropy/timeseries/tests/test_sampled.py::test_initialization_with_time_delta FAILED [ 28%]\nastropy/timeseries/tests/test_sampled.py::test_initialization_missing_time_delta PASSED [ 32%]\nastropy/timeseries/tests/test_sampled.py::test_initialization_invalid_time_and_time_start PASSED [ 36%]\nastropy/timeseries/tests/test_sampled.py::test_initialization_invalid_time_delta PASSED [ 40%]\nastropy/timeseries/tests/test_sampled.py::test_initialization_with_time_in_data PASSED [ 44%]\nastropy/timeseries/tests/test_sampled.py::test_initialization_n_samples PASSED [ 48%]\nastropy/timeseries/tests/test_sampled.py::test_initialization_length_mismatch PASSED [ 52%]\nastropy/timeseries/tests/test_sampled.py::test_initialization_invalid_both_time_and_time_delta PASSED [ 56%]\nastropy/timeseries/tests/test_sampled.py::test_fold PASSED               [ 60%]\nastropy/timeseries/tests/test_sampled.py::test_fold_invalid_options PASSED [ 64%]\nastropy/timeseries/tests/test_sampled.py::test_pandas SKIPPED (could...) [ 68%]\nastropy/timeseries/tests/test_sampled.py::test_read_time_missing PASSED  [ 72%]\nastropy/timeseries/tests/test_sampled.py::test_read_time_wrong PASSED    [ 76%]\nastropy/timeseries/tests/test_sampled.py::test_read PASSED               [ 80%]\nastropy/timeseries/tests/test_sampled.py::test_kepler_astropy SKIPPED    [ 84%]\nastropy/timeseries/tests/test_sampled.py::test_tess_astropy SKIPPED      [ 88%]\nastropy/timeseries/tests/test_sampled.py::test_required_columns PASSED   [ 92%]\nastropy/timeseries/tests/test_sampled.py::test_periodogram[BoxLeastSquares] PASSED [ 96%]\nastropy/timeseries/tests/test_sampled.py::test_periodogram[LombScargle] PASSED [100%]\n\n=================================== FAILURES ===================================\n_____________________ test_initialization_with_time_delta ______________________\nastropy/time/core.py:2824: in update_leap_seconds\n    table = iers.LeapSeconds.auto_open(files)\nastropy/utils/iers/iers.py:1032: in auto_open\n    warn('leap-second file is expired.', IERSStaleWarning)\nE   astropy.utils.iers.iers.IERSStaleWarning: leap-second file is expired.\n\nDuring handling of the above exception, another exception occurred:\nastropy/timeseries/tests/test_sampled.py:67: in test_initialization_with_time_delta\n    ts = TimeSeries(time_start=datetime(2018, 7, 1, 10, 10, 10),\nastropy/timeseries/sampled.py:122: in __init__\n    time = time_start + time_delta\nastropy/time/core.py:2208: in __add__\n    out._set_scale('tai')\nastropy/time/core.py:554: in _set_scale\n    _check_leapsec()\nastropy/time/core.py:2795: in _check_leapsec\n    update_leap_seconds()\nastropy/time/core.py:2828: in update_leap_seconds\n    warn(\"leap-second auto-update failed due to the following \"\nE   astropy.utils.exceptions.AstropyWarning: leap-second auto-update failed due to the following exception: IERSStaleWarning('leap-second file is expired.')\n=================== 1 failed, 21 passed, 3 skipped in 0.28s ====================\n\n\n<frozen importlib._bootstrap>:228: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 80 from C header, got 96 from PyObject\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/timeseries/tests/test_sampled.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/timeseries/tests/test_sampled.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "scikit-learn__scikit-learn-25973",
      "repo": "scikit-learn/scikit-learn",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 24.22862720489502,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 72,
          "failed": 1,
          "errors": 0,
          "collected": 73,
          "duration": 11.24,
          "log_tail": "sklearn/feature_selection/tests/test_sequential.py::test_sanity[1-expected_selected_features1-forward-4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[1-expected_selected_features1-forward-5] \u001b[32mPASSED\u001b[0m\u001b[32m [ 61%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[1-expected_selected_features1-forward-6] \u001b[32mPASSED\u001b[0m\u001b[32m [ 63%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[1-expected_selected_features1-forward-7] \u001b[32mPASSED\u001b[0m\u001b[32m [ 64%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[1-expected_selected_features1-forward-8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 65%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[1-expected_selected_features1-forward-9] \u001b[32mPASSED\u001b[0m\u001b[32m [ 67%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[1-expected_selected_features1-backward-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 68%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[1-expected_selected_features1-backward-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 69%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[1-expected_selected_features1-backward-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 71%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[1-expected_selected_features1-backward-3] \u001b[32mPASSED\u001b[0m\u001b[32m [ 72%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[1-expected_selected_features1-backward-4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[1-expected_selected_features1-backward-5] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[1-expected_selected_features1-backward-6] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[1-expected_selected_features1-backward-7] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[1-expected_selected_features1-backward-8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[1-expected_selected_features1-backward-9] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sparse_support \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_nan_support \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_pipeline_support \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_raise_deprecation_warning \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_unsupervised_model_fit[2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_unsupervised_model_fit[3] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_no_y_validation_model_fit[no_validation] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_no_y_validation_model_fit[1j] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_no_y_validation_model_fit[99.9] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_no_y_validation_model_fit[nan] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_no_y_validation_model_fit[3] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_forward_neg_tol_error \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_backward_neg_tol \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_cv_generator_support \u001b[31mFAILED\u001b[0m\u001b[31m [100%]\u001b[0m\n\n=================================== FAILURES ===================================\n\u001b[31m\u001b[1m__________________________ test_cv_generator_support ___________________________\u001b[0m\n\u001b[1m\u001b[31msklearn/feature_selection/tests/test_sequential.py\u001b[0m:336: in test_cv_generator_support\n    sfs.fit(X, y)\n\u001b[1m\u001b[31msklearn/feature_selection/_sequential.py\u001b[0m:277: in fit\n    new_feature_idx, new_score = self._get_best_new_feature_score(\n\u001b[1m\u001b[31msklearn/feature_selection/_sequential.py\u001b[0m:308: in _get_best_new_feature_score\n    scores[feature_idx] = cross_val_score(\n\u001b[1m\u001b[31msklearn/model_selection/_validation.py\u001b[0m:535: in cross_val_score\n    cv_results = cross_validate(\n\u001b[1m\u001b[31msklearn/model_selection/_validation.py\u001b[0m:309: in cross_validate\n    results = _aggregate_score_dicts(results)\n\u001b[1m\u001b[31msklearn/model_selection/_validation.py\u001b[0m:1950: in _aggregate_score_dicts\n    for key in scores[0]\n\u001b[1m\u001b[31mE   IndexError: list index out of range\u001b[0m\n\u001b[31m========================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m72 passed\u001b[0m\u001b[31m in 5.86s\u001b[0m\u001b[31m =========================\u001b[0m\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sklearn/feature_selection/tests/test_sequential.py` failed. (See above for error)",
          "test_files_run": [
            "sklearn/feature_selection/tests/test_sequential.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 73,
          "failed": 0,
          "errors": 0,
          "collected": 73,
          "duration": 12.05,
          "log_tail": "sklearn/feature_selection/tests/test_sequential.py::test_sanity[2-expected_selected_features0-forward-8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 38%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[2-expected_selected_features0-forward-9] \u001b[32mPASSED\u001b[0m\u001b[32m [ 39%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[2-expected_selected_features0-backward-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 41%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[2-expected_selected_features0-backward-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 42%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[2-expected_selected_features0-backward-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 43%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[2-expected_selected_features0-backward-3] \u001b[32mPASSED\u001b[0m\u001b[32m [ 45%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[2-expected_selected_features0-backward-4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 46%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[2-expected_selected_features0-backward-5] \u001b[32mPASSED\u001b[0m\u001b[32m [ 47%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[2-expected_selected_features0-backward-6] \u001b[32mPASSED\u001b[0m\u001b[32m [ 49%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[2-expected_selected_features0-backward-7] \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[2-expected_selected_features0-backward-8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 52%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[2-expected_selected_features0-backward-9] \u001b[32mPASSED\u001b[0m\u001b[32m [ 53%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[1-expected_selected_features1-forward-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 54%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[1-expected_selected_features1-forward-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 56%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[1-expected_selected_features1-forward-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 57%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[1-expected_selected_features1-forward-3] \u001b[32mPASSED\u001b[0m\u001b[32m [ 58%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[1-expected_selected_features1-forward-4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 60%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[1-expected_selected_features1-forward-5] \u001b[32mPASSED\u001b[0m\u001b[32m [ 61%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[1-expected_selected_features1-forward-6] \u001b[32mPASSED\u001b[0m\u001b[32m [ 63%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[1-expected_selected_features1-forward-7] \u001b[32mPASSED\u001b[0m\u001b[32m [ 64%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[1-expected_selected_features1-forward-8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 65%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[1-expected_selected_features1-forward-9] \u001b[32mPASSED\u001b[0m\u001b[32m [ 67%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[1-expected_selected_features1-backward-0] \u001b[32mPASSED\u001b[0m\u001b[32m [ 68%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[1-expected_selected_features1-backward-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 69%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[1-expected_selected_features1-backward-2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 71%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[1-expected_selected_features1-backward-3] \u001b[32mPASSED\u001b[0m\u001b[32m [ 72%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[1-expected_selected_features1-backward-4] \u001b[32mPASSED\u001b[0m\u001b[32m [ 73%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[1-expected_selected_features1-backward-5] \u001b[32mPASSED\u001b[0m\u001b[32m [ 75%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[1-expected_selected_features1-backward-6] \u001b[32mPASSED\u001b[0m\u001b[32m [ 76%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[1-expected_selected_features1-backward-7] \u001b[32mPASSED\u001b[0m\u001b[32m [ 78%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[1-expected_selected_features1-backward-8] \u001b[32mPASSED\u001b[0m\u001b[32m [ 79%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sanity[1-expected_selected_features1-backward-9] \u001b[32mPASSED\u001b[0m\u001b[32m [ 80%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_sparse_support \u001b[32mPASSED\u001b[0m\u001b[32m [ 82%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_nan_support \u001b[32mPASSED\u001b[0m\u001b[32m [ 83%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_pipeline_support \u001b[32mPASSED\u001b[0m\u001b[32m [ 84%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_raise_deprecation_warning \u001b[32mPASSED\u001b[0m\u001b[32m [ 86%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_unsupervised_model_fit[2] \u001b[32mPASSED\u001b[0m\u001b[32m [ 87%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_unsupervised_model_fit[3] \u001b[32mPASSED\u001b[0m\u001b[32m [ 89%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_no_y_validation_model_fit[no_validation] \u001b[32mPASSED\u001b[0m\u001b[32m [ 90%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_no_y_validation_model_fit[1j] \u001b[32mPASSED\u001b[0m\u001b[32m [ 91%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_no_y_validation_model_fit[99.9] \u001b[32mPASSED\u001b[0m\u001b[32m [ 93%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_no_y_validation_model_fit[nan] \u001b[32mPASSED\u001b[0m\u001b[32m [ 94%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_no_y_validation_model_fit[3] \u001b[32mPASSED\u001b[0m\u001b[32m [ 95%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_forward_neg_tol_error \u001b[32mPASSED\u001b[0m\u001b[32m [ 97%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_backward_neg_tol \u001b[32mPASSED\u001b[0m\u001b[32m [ 98%]\u001b[0m\nsklearn/feature_selection/tests/test_sequential.py::test_cv_generator_support \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n\n\u001b[32m============================== \u001b[32m\u001b[1m73 passed\u001b[0m\u001b[32m in 8.49s\u001b[0m\u001b[32m ==============================\u001b[0m\n\n",
          "test_files_run": [
            "sklearn/feature_selection/tests/test_sequential.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "astropy__astropy-13579",
      "repo": "astropy/astropy",
      "valid": false,
      "worker": "http://34.123.9.23:8080",
      "duration": 10.479604959487915,
      "test_only": {
        "passed": true,
        "stats": {
          "passed": 40,
          "failed": 0,
          "errors": 0,
          "collected": 41,
          "duration": 4.91,
          "log_tail": "astropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_sanitize_slice[item2-10-expected2] PASSED [  9%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_ellipsis PASSED [ 12%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_pixel_to_world_broadcasting PASSED [ 14%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_world_to_pixel_broadcasting PASSED [ 17%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_spectral_slice PASSED [ 19%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_spectral_range PASSED [ 21%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_celestial_slice PASSED [ 24%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_celestial_range PASSED [ 26%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_celestial_range_rot PASSED [ 29%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_no_array_shape PASSED [ 31%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_ellipsis_none_types PASSED [ 34%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice10-slice20-expected0] PASSED [ 36%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice11-slice21-expected1] PASSED [ 39%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice12-slice22-expected2] PASSED [ 41%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice13-slice23-expected3] PASSED [ 43%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice14-slice24-expected4] PASSED [ 46%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice15-slice25-expected5] PASSED [ 48%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice16-slice26-expected6] PASSED [ 51%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice17-slice27-expected7] PASSED [ 53%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice18-slice28-expected8] PASSED [ 56%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice19-slice29-expected9] PASSED [ 58%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice110-slice210-expected10] PASSED [ 60%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice111-slice211-expected11] PASSED [ 63%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice112-slice212-expected12] PASSED [ 65%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice113-slice213-expected13] PASSED [ 68%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice114-slice214-expected14] PASSED [ 70%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice115-slice215-expected15] PASSED [ 73%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice116-3-3] PASSED [ 75%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice117-3-5] PASSED [ 78%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice118-3-3] PASSED [ 80%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice119-3-5] PASSED [ 82%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_nested_slicing PASSED [ 85%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_too_much_slicing PASSED [ 87%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_1d_sliced_low_level PASSED [ 90%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_dropped_dimensions PASSED [ 92%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_dropped_dimensions_4d PASSED [ 95%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_pixel_to_world_values_different_int_types PASSED [ 97%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_coupled_world_slicing FAILED [100%]\n\n=================================== FAILURES ===================================\n__________________________ test_coupled_world_slicing __________________________\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py:937: in test_coupled_world_slicing\n    assert np.allclose(out_pix[0], 0)\nE   assert False\nE    +  where False = <function allclose at 0x7ba316b67eb0>(array(1.81818182e+11), 0)\nE    +    where <function allclose at 0x7ba316b67eb0> = np.allclose\n========================= 1 failed, 40 passed in 1.19s =========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 41,
          "failed": 0,
          "errors": 0,
          "collected": 41,
          "duration": 4.71,
          "log_tail": "Internet access disabled\n============================= test session starts ==============================\ncollecting ... collected 41 items\n\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_invalid_slices PASSED [  2%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_sanitize_slice[item0-4-expected0] PASSED [  4%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_sanitize_slice[item1-5-expected1] PASSED [  7%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_sanitize_slice[item2-10-expected2] PASSED [  9%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_ellipsis PASSED [ 12%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_pixel_to_world_broadcasting PASSED [ 14%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_world_to_pixel_broadcasting PASSED [ 17%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_spectral_slice PASSED [ 19%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_spectral_range PASSED [ 21%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_celestial_slice PASSED [ 24%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_celestial_range PASSED [ 26%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_celestial_range_rot PASSED [ 29%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_no_array_shape PASSED [ 31%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_ellipsis_none_types PASSED [ 34%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice10-slice20-expected0] PASSED [ 36%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice11-slice21-expected1] PASSED [ 39%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice12-slice22-expected2] PASSED [ 41%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice13-slice23-expected3] PASSED [ 43%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice14-slice24-expected4] PASSED [ 46%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice15-slice25-expected5] PASSED [ 48%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice16-slice26-expected6] PASSED [ 51%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice17-slice27-expected7] PASSED [ 53%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice18-slice28-expected8] PASSED [ 56%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice19-slice29-expected9] PASSED [ 58%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice110-slice210-expected10] PASSED [ 60%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice111-slice211-expected11] PASSED [ 63%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice112-slice212-expected12] PASSED [ 65%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice113-slice213-expected13] PASSED [ 68%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice114-slice214-expected14] PASSED [ 70%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice115-slice215-expected15] PASSED [ 73%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice116-3-3] PASSED [ 75%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice117-3-5] PASSED [ 78%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice118-3-3] PASSED [ 80%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_combine_slices[slice119-3-5] PASSED [ 82%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_nested_slicing PASSED [ 85%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_too_much_slicing PASSED [ 87%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_1d_sliced_low_level PASSED [ 90%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_dropped_dimensions PASSED [ 92%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_dropped_dimensions_4d PASSED [ 95%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_pixel_to_world_values_different_int_types PASSED [ 97%]\nastropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py::test_coupled_world_slicing PASSED [100%]\n\n============================== 41 passed in 1.10s ==============================\n\n",
          "test_files_run": [
            "astropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got True\u2192True"
    },
    {
      "instance_id": "astropy__astropy-13398",
      "repo": "astropy/astropy",
      "valid": false,
      "worker": "http://34.70.1.155:8080",
      "duration": 11.854052305221558,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 68,
          "failed": 5,
          "errors": 0,
          "collected": 76,
          "duration": 5.47,
          "log_tail": "    cirsnod = inod.transform_to(cframe1)  # uses the default time\nastropy/coordinates/baseframe.py:1202: in transform_to\n    return trans(self, new_frame)\nastropy/coordinates/transformations.py:1478: in __call__\n    curr_coord = t(curr_coord, curr_toframe)\nastropy/coordinates/transformations.py:1079: in __call__\n    return supcall(fromcoord, toframe)\nastropy/coordinates/builtin_frames/icrs_cirs_transforms.py:35: in icrs_to_cirs\n    astrom = erfa_astrom.get().apco(cirs_frame)\nastropy/coordinates/erfa_astrom.py:50: in apco\n    xp, yp = get_polar_motion(obstime)\nastropy/coordinates/builtin_frames/utils.py:47: in get_polar_motion\n    xp, yp, status = iers_table.pm_xy(time, return_status=True)\nastropy/utils/iers/iers.py:365: in pm_xy\n    return self._interpolate(jd1, jd2, ['PM_x', 'PM_y'],\nastropy/utils/iers/iers.py:392: in _interpolate\n    mjd, utc = self.mjd_utc(jd1, jd2)\nastropy/utils/iers/iers.py:271: in mjd_utc\n    mjd = np.floor(jd1 - MJD_ZERO + jd2)\nE   TypeError: unsupported operand type(s) for -: 'Time' and 'float'\n___________________ test_itrs_topo_to_altaz_with_refraction ____________________\nastropy/coordinates/tests/test_intermediate_transformations.py:207: in test_itrs_topo_to_altaz_with_refraction\n    itrs_frame = ITRS(location=loc)\nastropy/coordinates/baseframe.py:319: in __init__\n    raise TypeError(\nE   TypeError: Coordinate frame ITRS got unexpected keywords: ['location']\n___________________ test_itrs_topo_to_hadec_with_refraction ____________________\nastropy/coordinates/tests/test_intermediate_transformations.py:262: in test_itrs_topo_to_hadec_with_refraction\n    itrs_frame = ITRS(location=loc)\nastropy/coordinates/baseframe.py:319: in __init__\n    raise TypeError(\nE   TypeError: Coordinate frame ITRS got unexpected keywords: ['location']\n_____________________________ test_cirs_itrs_topo ______________________________\nastropy/coordinates/tests/test_intermediate_transformations.py:359: in test_cirs_itrs_topo\n    cirs2 = cirs.transform_to(ITRS(location=loc)).transform_to(cirs)\nastropy/coordinates/baseframe.py:319: in __init__\n    raise TypeError(\nE   TypeError: Coordinate frame ITRS got unexpected keywords: ['location']\n_________________________ test_itrs_straight_overhead __________________________\nastropy/coordinates/tests/test_intermediate_transformations.py:957: in test_itrs_straight_overhead\n    itrs_topo = ITRS(itrs_repr, obstime=t, location=home)\nastropy/coordinates/baseframe.py:319: in __init__\n    raise TypeError(\nE   TypeError: Coordinate frame ITRS got unexpected keywords: ['location']\n=================== 5 failed, 68 passed, 3 skipped in 1.99s ====================\n\n\n<frozen importlib._bootstrap>:228: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 80 from C header, got 96 from PyObject\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/coordinates/tests/test_intermediate_transformations.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/coordinates/tests/test_intermediate_transformations.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 72,
          "failed": 1,
          "errors": 0,
          "collected": 76,
          "duration": 5.4,
          "log_tail": "astropy/coordinates/tests/test_intermediate_transformations.py::test_icrs_gcrscirs_sunish[testframe4] PASSED [ 75%]\nastropy/coordinates/tests/test_intermediate_transformations.py::test_icrs_altaz_moonish[testframe0] PASSED [ 76%]\nastropy/coordinates/tests/test_intermediate_transformations.py::test_icrs_altaz_moonish[testframe1] PASSED [ 77%]\nastropy/coordinates/tests/test_intermediate_transformations.py::test_icrs_altaz_moonish[testframe2] PASSED [ 78%]\nastropy/coordinates/tests/test_intermediate_transformations.py::test_icrs_altaz_moonish[testframe3] PASSED [ 80%]\nastropy/coordinates/tests/test_intermediate_transformations.py::test_icrs_altaz_moonish[testframe4] PASSED [ 81%]\nastropy/coordinates/tests/test_intermediate_transformations.py::test_gcrs_self_transform_closeby PASSED [ 82%]\nastropy/coordinates/tests/test_intermediate_transformations.py::test_teme_itrf PASSED [ 84%]\nastropy/coordinates/tests/test_intermediate_transformations.py::test_precessedgeocentric_loopback PASSED [ 85%]\nastropy/coordinates/tests/test_intermediate_transformations.py::test_teme_loopback PASSED [ 86%]\nastropy/coordinates/tests/test_intermediate_transformations.py::test_earth_orientation_table SKIPPED [ 88%]\nastropy/coordinates/tests/test_intermediate_transformations.py::test_ephemerides SKIPPED [ 89%]\nastropy/coordinates/tests/test_intermediate_transformations.py::test_tete_transforms PASSED [ 90%]\nastropy/coordinates/tests/test_intermediate_transformations.py::test_straight_overhead PASSED [ 92%]\nastropy/coordinates/tests/test_intermediate_transformations.py::test_itrs_straight_overhead PASSED [ 93%]\nastropy/coordinates/tests/test_intermediate_transformations.py::test_aa_hd_high_precision SKIPPED [ 94%]\nastropy/coordinates/tests/test_intermediate_transformations.py::test_aa_high_precision_nodata PASSED [ 96%]\nastropy/coordinates/tests/test_intermediate_transformations.py::TestGetLocationGCRS::test_get_gcrs_posvel PASSED [ 97%]\nastropy/coordinates/tests/test_intermediate_transformations.py::TestGetLocationGCRS::test_tete_quick PASSED [ 98%]\nastropy/coordinates/tests/test_intermediate_transformations.py::TestGetLocationGCRS::test_cirs_quick PASSED [100%]\n\n=================================== FAILURES ===================================\n________________________________ test_icrs_cirs ________________________________\nastropy/coordinates/tests/test_intermediate_transformations.py:49: in test_icrs_cirs\n    cirsnod = inod.transform_to(cframe1)  # uses the default time\nastropy/coordinates/baseframe.py:1202: in transform_to\n    return trans(self, new_frame)\nastropy/coordinates/transformations.py:1478: in __call__\n    curr_coord = t(curr_coord, curr_toframe)\nastropy/coordinates/transformations.py:1079: in __call__\n    return supcall(fromcoord, toframe)\nastropy/coordinates/builtin_frames/icrs_cirs_transforms.py:35: in icrs_to_cirs\n    astrom = erfa_astrom.get().apco(cirs_frame)\nastropy/coordinates/erfa_astrom.py:50: in apco\n    xp, yp = get_polar_motion(obstime)\nastropy/coordinates/builtin_frames/utils.py:47: in get_polar_motion\n    xp, yp, status = iers_table.pm_xy(time, return_status=True)\nastropy/utils/iers/iers.py:365: in pm_xy\n    return self._interpolate(jd1, jd2, ['PM_x', 'PM_y'],\nastropy/utils/iers/iers.py:392: in _interpolate\n    mjd, utc = self.mjd_utc(jd1, jd2)\nastropy/utils/iers/iers.py:271: in mjd_utc\n    mjd = np.floor(jd1 - MJD_ZERO + jd2)\nE   TypeError: unsupported operand type(s) for -: 'Time' and 'float'\n=================== 1 failed, 72 passed, 3 skipped in 1.84s ====================\n\n\n<frozen importlib._bootstrap>:228: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 80 from C header, got 96 from PyObject\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/coordinates/tests/test_intermediate_transformations.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/coordinates/tests/test_intermediate_transformations.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "astropy__astropy-7166",
      "repo": "astropy/astropy",
      "valid": false,
      "worker": "http://34.44.241.183:8080",
      "duration": 8.444703102111816,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 4.84,
          "log_tail": "\nusage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/setup.cfg\n  rootdir: /testbed\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/utils/tests/test_misc.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/utils/tests/test_misc.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 2.75,
          "log_tail": "\nusage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/setup.cfg\n  rootdir: /testbed\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/utils/tests/test_misc.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/utils/tests/test_misc.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "astropy__astropy-13236",
      "repo": "astropy/astropy",
      "valid": false,
      "worker": "http://35.239.238.137:8080",
      "duration": 16.292125940322876,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 644,
          "failed": 4,
          "errors": 0,
          "collected": 674,
          "duration": 8.31,
          "log_tail": "astropy/table/tests/test_table.py::test_remove_columns_invalid_names_messages PASSED [ 99%]\nastropy/table/tests/test_table.py::test_read_write_tilde_path[str] PASSED [ 99%]\nastropy/table/tests/test_table.py::test_read_write_tilde_path[Path] PASSED [100%]\n\n=================================== FAILURES ===================================\n_________________________ test_skycoord_representation _________________________\nastropy/table/tests/test_mixin.py:688: in test_skycoord_representation\n    assert t.pformat() == ['  col0  ',\nastropy/table/table.py:1806: in pformat\n    lines, outs = self.formatter._pformat_table(\nastropy/table/pprint.py:563: in _pformat_table\n    show_unit = any(col.info.unit for col in table.columns.values())\nastropy/table/pprint.py:563: in <genexpr>\n    show_unit = any(col.info.unit for col in table.columns.values())\nastropy/coordinates/sky_coordinate.py:52: in unit\n    repr_data = self._repr_data\nastropy/coordinates/sky_coordinate.py:67: in _repr_data\n    repr_data = sc.represent_as(sc.representation_type,\nastropy/coordinates/baseframe.py:1078: in represent_as\n    data = self.data.represent_as(representation_cls)\nastropy/coordinates/representation.py:873: in represent_as\n    new_rep = other_class.from_cartesian(self.to_cartesian())\nastropy/coordinates/representation.py:1606: in from_cartesian\n    p = cart.get_xyz(xyz_axis=-1)\nastropy/coordinates/representation.py:1351: in get_xyz\n    return np.stack([self._x, self._y, self._z], axis=xyz_axis)\nastropy/units/quantity.py:1683: in __array_function__\n    return super().__array_function__(function, types, args, kwargs)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/shape_base.py:456: in stack\n    return _nx.concatenate(expanded_arrays, axis=axis, out=out,\nastropy/units/quantity.py:1688: in __array_function__\n    args, kwargs, unit, out = function_helper(*args, **kwargs)\nE   TypeError: concatenate() got an unexpected keyword argument 'dtype'\n__________________________ test_ndarray_mixin[False] ___________________________\nastropy/table/tests/test_mixin.py:731: in test_ndarray_mixin\n    assert isinstance(t['a'], class_exp)\nE   AssertionError: assert False\nE    +  where False = isinstance(NdarrayMixin([(1, 'a'), (2, 'b'), (3, 'c'), (4, 'd')],\\n             dtype=[('f0', '<i4'), ('f1', '<U1')]), <class 'astropy.table.column.Column'>)\n___________________________ test_values_equal_part1 ____________________________\nastropy/table/tests/test_table.py:1497: in test_values_equal_part1\n    t1.values_equal(2)\nE   Failed: DID NOT RAISE <class 'ValueError'>\n________________________ test_structured_masked_column _________________________\nastropy/table/tests/test_table.py:2928: in test_structured_masked_column\n    assert np.all(t['a']['z'].mask == [False, False])\nE   AttributeError: 'NdarrayMixin' object has no attribute 'mask'\n============= 4 failed, 644 passed, 25 skipped, 1 xfailed in 3.47s =============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/table/tests/test_mixin.py astropy/table/tests/test_table.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/table/tests/test_mixin.py",
            "astropy/table/tests/test_table.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 646,
          "failed": 2,
          "errors": 0,
          "collected": 674,
          "duration": 7.1,
          "log_tail": "astropy/table/tests/test_table.py::test_structured_masked_column PASSED  [ 98%]\nastropy/table/tests/test_table.py::test_rows_with_mixins PASSED          [ 98%]\nastropy/table/tests/test_table.py::test_iterrows PASSED                  [ 98%]\nastropy/table/tests/test_table.py::test_values_and_types PASSED          [ 98%]\nastropy/table/tests/test_table.py::test_items PASSED                     [ 98%]\nastropy/table/tests/test_table.py::test_read_write_not_replaceable PASSED [ 99%]\nastropy/table/tests/test_table.py::test_keep_columns_with_generator PASSED [ 99%]\nastropy/table/tests/test_table.py::test_remove_columns_with_generator PASSED [ 99%]\nastropy/table/tests/test_table.py::test_keep_columns_invalid_names_messages PASSED [ 99%]\nastropy/table/tests/test_table.py::test_remove_columns_invalid_names_messages PASSED [ 99%]\nastropy/table/tests/test_table.py::test_read_write_tilde_path[str] PASSED [ 99%]\nastropy/table/tests/test_table.py::test_read_write_tilde_path[Path] PASSED [100%]\n\n=================================== FAILURES ===================================\n_________________________ test_skycoord_representation _________________________\nastropy/table/tests/test_mixin.py:688: in test_skycoord_representation\n    assert t.pformat() == ['  col0  ',\nastropy/table/table.py:1799: in pformat\n    lines, outs = self.formatter._pformat_table(\nastropy/table/pprint.py:563: in _pformat_table\n    show_unit = any(col.info.unit for col in table.columns.values())\nastropy/table/pprint.py:563: in <genexpr>\n    show_unit = any(col.info.unit for col in table.columns.values())\nastropy/coordinates/sky_coordinate.py:52: in unit\n    repr_data = self._repr_data\nastropy/coordinates/sky_coordinate.py:67: in _repr_data\n    repr_data = sc.represent_as(sc.representation_type,\nastropy/coordinates/baseframe.py:1078: in represent_as\n    data = self.data.represent_as(representation_cls)\nastropy/coordinates/representation.py:873: in represent_as\n    new_rep = other_class.from_cartesian(self.to_cartesian())\nastropy/coordinates/representation.py:1606: in from_cartesian\n    p = cart.get_xyz(xyz_axis=-1)\nastropy/coordinates/representation.py:1351: in get_xyz\n    return np.stack([self._x, self._y, self._z], axis=xyz_axis)\nastropy/units/quantity.py:1683: in __array_function__\n    return super().__array_function__(function, types, args, kwargs)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/numpy/core/shape_base.py:456: in stack\n    return _nx.concatenate(expanded_arrays, axis=axis, out=out,\nastropy/units/quantity.py:1688: in __array_function__\n    args, kwargs, unit, out = function_helper(*args, **kwargs)\nE   TypeError: concatenate() got an unexpected keyword argument 'dtype'\n___________________________ test_values_equal_part1 ____________________________\nastropy/table/tests/test_table.py:1497: in test_values_equal_part1\n    t1.values_equal(2)\nE   Failed: DID NOT RAISE <class 'ValueError'>\n============= 2 failed, 646 passed, 25 skipped, 1 xfailed in 3.41s =============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/table/tests/test_mixin.py astropy/table/tests/test_table.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/table/tests/test_mixin.py",
            "astropy/table/tests/test_table.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "astropy__astropy-7606",
      "repo": "astropy/astropy",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "duration": 6.770729064941406,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 2.9,
          "log_tail": "\nusage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/setup.cfg\n  rootdir: /testbed\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/units/tests/test_units.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/units/tests/test_units.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 3.04,
          "log_tail": "\nusage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/setup.cfg\n  rootdir: /testbed\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/units/tests/test_units.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/units/tests/test_units.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "astropy__astropy-14096",
      "repo": "astropy/astropy",
      "valid": false,
      "worker": "http://35.239.238.137:8080",
      "duration": 16.082753896713257,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 426,
          "failed": 2,
          "errors": 0,
          "collected": 432,
          "duration": 7.65,
          "log_tail": "\u001b[31m\u001b[1m_______________________________ test_repr_altaz ________________________________\u001b[0m\n\u001b[1m\u001b[31mastropy/time/core.py\u001b[0m:3311: in update_leap_seconds\n    table = iers.LeapSeconds.auto_open(files)\n\u001b[1m\u001b[31mastropy/utils/iers/iers.py\u001b[0m:1142: in auto_open\n    warn(\"leap-second file is expired.\", IERSStaleWarning)\n\u001b[1m\u001b[31mE   astropy.utils.iers.iers.IERSStaleWarning: leap-second file is expired.\u001b[0m\n\n\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\n\u001b[1m\u001b[31mastropy/coordinates/tests/test_sky_coord.py\u001b[0m:783: in test_repr_altaz\n    sc4 = sc2.transform_to(AltAz(location=loc, obstime=time))\n\u001b[1m\u001b[31mastropy/coordinates/sky_coordinate.py\u001b[0m:704: in transform_to\n    new_coord = trans(self.frame, generic_frame)\n\u001b[1m\u001b[31mastropy/coordinates/transformations.py\u001b[0m:1575: in __call__\n    curr_coord = t(curr_coord, curr_toframe)\n\u001b[1m\u001b[31mastropy/coordinates/transformations.py\u001b[0m:1144: in __call__\n    return supcall(fromcoord, toframe)\n\u001b[1m\u001b[31mastropy/coordinates/builtin_frames/icrs_observed_transforms.py\u001b[0m:33: in icrs_to_observed\n    astrom = erfa_astrom.get().apco(observed_frame)\n\u001b[1m\u001b[31mastropy/coordinates/erfa_astrom.py\u001b[0m:52: in apco\n    jd1_tt, jd2_tt = get_jd12(obstime, \"tt\")\n\u001b[1m\u001b[31mastropy/coordinates/builtin_frames/utils.py\u001b[0m:115: in get_jd12\n    newtime = getattr(time, scale)\n\u001b[1m\u001b[31mastropy/time/core.py\u001b[0m:1635: in __getattr__\n    tm._set_scale(attr)\n\u001b[1m\u001b[31mastropy/time/core.py\u001b[0m:742: in _set_scale\n    _check_leapsec()\n\u001b[1m\u001b[31mastropy/time/core.py\u001b[0m:3282: in _check_leapsec\n    update_leap_seconds()\n\u001b[1m\u001b[31mastropy/time/core.py\u001b[0m:3315: in update_leap_seconds\n    warn(\n\u001b[1m\u001b[31mE   astropy.utils.exceptions.AstropyWarning: leap-second auto-update failed due to the following exception: IERSStaleWarning('leap-second file is expired.')\u001b[0m\n\u001b[31m\u001b[1m____________________ test_subclass_property_exception_error ____________________\u001b[0m\n\u001b[1m\u001b[31mastropy/coordinates/tests/test_sky_coord.py\u001b[0m:2185: in test_subclass_property_exception_error\n    c.prop\n\u001b[1m\u001b[31mastropy/coordinates/sky_coordinate.py\u001b[0m:898: in __getattr__\n    raise AttributeError(\n\u001b[1m\u001b[31mE   AttributeError: 'custom_coord' object has no attribute 'prop'\u001b[0m\n\n\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\n\u001b[1m\u001b[31mastropy/coordinates/tests/test_sky_coord.py\u001b[0m:2185: in test_subclass_property_exception_error\n    c.prop\n\u001b[1m\u001b[31mE   AssertionError: Regex pattern did not match.\u001b[0m\n\u001b[1m\u001b[31mE    Regex: 'random_attr'\u001b[0m\n\u001b[1m\u001b[31mE    Input: \"'custom_coord' object has no attribute 'prop'\"\u001b[0m\n\u001b[31m============= \u001b[31m\u001b[1m2 failed\u001b[0m, \u001b[32m426 passed\u001b[0m, \u001b[33m3 skipped\u001b[0m, \u001b[33m1 xfailed\u001b[0m\u001b[31m in 4.01s\u001b[0m\u001b[31m ==============\u001b[0m\n\n\n<frozen importlib._bootstrap>:228: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 80 from C header, got 96 from PyObject\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/coordinates/tests/test_sky_coord.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/coordinates/tests/test_sky_coord.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 427,
          "failed": 1,
          "errors": 0,
          "collected": 432,
          "duration": 7.57,
          "log_tail": "astropy/coordinates/tests/test_sky_coord.py::test_extra_attributes \u001b[32mPASSED\u001b[0m\u001b[31m [ 97%]\u001b[0m\nastropy/coordinates/tests/test_sky_coord.py::test_apply_space_motion \u001b[32mPASSED\u001b[0m\u001b[31m [ 97%]\u001b[0m\nastropy/coordinates/tests/test_sky_coord.py::test_custom_frame_skycoord \u001b[32mPASSED\u001b[0m\u001b[31m [ 98%]\u001b[0m\nastropy/coordinates/tests/test_sky_coord.py::test_user_friendly_pm_error \u001b[32mPASSED\u001b[0m\u001b[31m [ 98%]\u001b[0m\nastropy/coordinates/tests/test_sky_coord.py::test_contained_by \u001b[32mPASSED\u001b[0m\u001b[31m    [ 98%]\u001b[0m\nastropy/coordinates/tests/test_sky_coord.py::test_none_differential_type \u001b[32mPASSED\u001b[0m\u001b[31m [ 98%]\u001b[0m\nastropy/coordinates/tests/test_sky_coord.py::test_multiple_aliases \u001b[32mPASSED\u001b[0m\u001b[31m [ 99%]\u001b[0m\nastropy/coordinates/tests/test_sky_coord.py::test_passing_inconsistent_coordinates_and_units_raises_helpful_error[kwargs0-Unit 'deg' \\\\(angle\\\\) could not be applied to 'distance'. ] \u001b[32mPASSED\u001b[0m\u001b[31m [ 99%]\u001b[0m\nastropy/coordinates/tests/test_sky_coord.py::test_passing_inconsistent_coordinates_and_units_raises_helpful_error[kwargs1-Unit 'deg' \\\\(angle\\\\) could not be applied to 'rho'. ] \u001b[32mPASSED\u001b[0m\u001b[31m [ 99%]\u001b[0m\nastropy/coordinates/tests/test_sky_coord.py::test_match_to_catalog_3d_and_sky \u001b[33mSKIPPED\u001b[0m\u001b[31m [ 99%]\u001b[0m\nastropy/coordinates/tests/test_sky_coord.py::test_subclass_property_exception_error \u001b[32mPASSED\u001b[0m\u001b[31m [100%]\u001b[0m\n\n=================================== FAILURES ===================================\n\u001b[31m\u001b[1m_______________________________ test_repr_altaz ________________________________\u001b[0m\n\u001b[1m\u001b[31mastropy/time/core.py\u001b[0m:3311: in update_leap_seconds\n    table = iers.LeapSeconds.auto_open(files)\n\u001b[1m\u001b[31mastropy/utils/iers/iers.py\u001b[0m:1142: in auto_open\n    warn(\"leap-second file is expired.\", IERSStaleWarning)\n\u001b[1m\u001b[31mE   astropy.utils.iers.iers.IERSStaleWarning: leap-second file is expired.\u001b[0m\n\n\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\n\u001b[1m\u001b[31mastropy/coordinates/tests/test_sky_coord.py\u001b[0m:783: in test_repr_altaz\n    sc4 = sc2.transform_to(AltAz(location=loc, obstime=time))\n\u001b[1m\u001b[31mastropy/coordinates/sky_coordinate.py\u001b[0m:704: in transform_to\n    new_coord = trans(self.frame, generic_frame)\n\u001b[1m\u001b[31mastropy/coordinates/transformations.py\u001b[0m:1575: in __call__\n    curr_coord = t(curr_coord, curr_toframe)\n\u001b[1m\u001b[31mastropy/coordinates/transformations.py\u001b[0m:1144: in __call__\n    return supcall(fromcoord, toframe)\n\u001b[1m\u001b[31mastropy/coordinates/builtin_frames/icrs_observed_transforms.py\u001b[0m:33: in icrs_to_observed\n    astrom = erfa_astrom.get().apco(observed_frame)\n\u001b[1m\u001b[31mastropy/coordinates/erfa_astrom.py\u001b[0m:52: in apco\n    jd1_tt, jd2_tt = get_jd12(obstime, \"tt\")\n\u001b[1m\u001b[31mastropy/coordinates/builtin_frames/utils.py\u001b[0m:115: in get_jd12\n    newtime = getattr(time, scale)\n\u001b[1m\u001b[31mastropy/time/core.py\u001b[0m:1635: in __getattr__\n    tm._set_scale(attr)\n\u001b[1m\u001b[31mastropy/time/core.py\u001b[0m:742: in _set_scale\n    _check_leapsec()\n\u001b[1m\u001b[31mastropy/time/core.py\u001b[0m:3282: in _check_leapsec\n    update_leap_seconds()\n\u001b[1m\u001b[31mastropy/time/core.py\u001b[0m:3315: in update_leap_seconds\n    warn(\n\u001b[1m\u001b[31mE   astropy.utils.exceptions.AstropyWarning: leap-second auto-update failed due to the following exception: IERSStaleWarning('leap-second file is expired.')\u001b[0m\n\u001b[31m============= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m427 passed\u001b[0m, \u001b[33m3 skipped\u001b[0m, \u001b[33m1 xfailed\u001b[0m\u001b[31m in 3.92s\u001b[0m\u001b[31m ==============\u001b[0m\n\n\n<frozen importlib._bootstrap>:228: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 80 from C header, got 96 from PyObject\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/coordinates/tests/test_sky_coord.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/coordinates/tests/test_sky_coord.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "astropy__astropy-7671",
      "repo": "astropy/astropy",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "duration": 7.924433946609497,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 4.31,
          "log_tail": "\nusage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/setup.cfg\n  rootdir: /testbed\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/utils/tests/test_introspection.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/utils/tests/test_introspection.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 2.83,
          "log_tail": "\nusage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/setup.cfg\n  rootdir: /testbed\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/utils/tests/test_introspection.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/utils/tests/test_introspection.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "scikit-learn__scikit-learn-9288",
      "repo": "scikit-learn/scikit-learn",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 32.95338702201843,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 123,
          "failed": 1,
          "errors": 0,
          "collected": 124,
          "duration": 17.25,
          "log_tail": "sklearn/cluster/tests/test_k_means.py::test_predict_minibatch_dense_sparse[init2] PASSED [ 77%]\nsklearn/cluster/tests/test_k_means.py::test_int_input PASSED             [ 78%]\nsklearn/cluster/tests/test_k_means.py::test_transform PASSED             [ 79%]\nsklearn/cluster/tests/test_k_means.py::test_fit_transform PASSED         [ 79%]\nsklearn/cluster/tests/test_k_means.py::test_predict_equal_labels[full] PASSED [ 80%]\nsklearn/cluster/tests/test_k_means.py::test_predict_equal_labels[elkan] PASSED [ 81%]\nsklearn/cluster/tests/test_k_means.py::test_full_vs_elkan PASSED         [ 82%]\nsklearn/cluster/tests/test_k_means.py::test_n_init PASSED                [ 83%]\nsklearn/cluster/tests/test_k_means.py::test_k_means_function PASSED      [ 83%]\nsklearn/cluster/tests/test_k_means.py::test_x_squared_norms_init_centroids PASSED [ 84%]\nsklearn/cluster/tests/test_k_means.py::test_max_iter_error PASSED        [ 85%]\nsklearn/cluster/tests/test_k_means.py::test_float_precision[False-KMeans] PASSED [ 86%]\nsklearn/cluster/tests/test_k_means.py::test_float_precision[False-MiniBatchKMeans] PASSED [ 87%]\nsklearn/cluster/tests/test_k_means.py::test_float_precision[True-KMeans] PASSED [ 87%]\nsklearn/cluster/tests/test_k_means.py::test_float_precision[True-MiniBatchKMeans] PASSED [ 88%]\nsklearn/cluster/tests/test_k_means.py::test_k_means_init_centers PASSED  [ 89%]\nsklearn/cluster/tests/test_k_means.py::test_k_means_init_fitted_centers[dense] PASSED [ 90%]\nsklearn/cluster/tests/test_k_means.py::test_k_means_init_fitted_centers[sparse] PASSED [ 91%]\nsklearn/cluster/tests/test_k_means.py::test_sparse_validate_centers PASSED [ 91%]\nsklearn/cluster/tests/test_k_means.py::test_less_centers_than_unique_points PASSED [ 92%]\nsklearn/cluster/tests/test_k_means.py::test_weighted_vs_repeated PASSED  [ 93%]\nsklearn/cluster/tests/test_k_means.py::test_unit_weights_vs_no_weights PASSED [ 94%]\nsklearn/cluster/tests/test_k_means.py::test_scaled_weights PASSED        [ 95%]\nsklearn/cluster/tests/test_k_means.py::test_sample_weight_length PASSED  [ 95%]\nsklearn/cluster/tests/test_k_means.py::test_check_normalize_sample_weight PASSED [ 96%]\nsklearn/cluster/tests/test_k_means.py::test_iter_attribute PASSED        [ 97%]\nsklearn/cluster/tests/test_k_means.py::test_k_means_empty_cluster_relocated PASSED [ 98%]\nsklearn/cluster/tests/test_k_means.py::test_minibatch_kmeans_partial_fit_int_data PASSED [ 99%]\nsklearn/cluster/tests/test_k_means.py::test_result_of_kmeans_equal_in_diff_n_jobs FAILED [100%]\n\n=================================== FAILURES ===================================\n__________________ test_result_of_kmeans_equal_in_diff_n_jobs __________________\nsklearn/cluster/tests/test_k_means.py:963: in test_result_of_kmeans_equal_in_diff_n_jobs\n    assert_array_equal(result_1, result_2)\nE   AssertionError: \nE   Arrays are not equal\nE   \nE   Mismatched elements: 39 / 50 (78%)\nE   Max absolute difference: 2\nE   Max relative difference: 1.\nE    x: array([0, 2, 2, 1, 1, 1, 1, 1, 2, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 2, 2, 0,\nE          1, 2, 1, 1, 1, 1, 0, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1,\nE          2, 2, 1, 2, 2, 2], dtype=int32)\nE    y: array([0, 0, 1, 2, 0, 2, 2, 2, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 2, 2, 0, 2,\nE          0, 0, 2, 0, 0, 0, 0, 0, 1, 2, 2, 0, 2, 0, 0, 0, 2, 2, 0, 1, 0, 0,\nE          0, 0, 0, 1, 2, 1], dtype=int32)\n================= 1 failed, 123 passed, 15 warnings in 12.71s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN sklearn/cluster/tests/test_k_means.py` failed. (See above for error)",
          "test_files_run": [
            "sklearn/cluster/tests/test_k_means.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 124,
          "failed": 0,
          "errors": 0,
          "collected": 124,
          "duration": 14.84,
          "log_tail": "sklearn/cluster/tests/test_k_means.py::test_k_means_non_collapsed PASSED [ 63%]\nsklearn/cluster/tests/test_k_means.py::test_score[full] PASSED           [ 64%]\nsklearn/cluster/tests/test_k_means.py::test_score[elkan] PASSED          [ 65%]\nsklearn/cluster/tests/test_k_means.py::test_predict[random-dense-KMeans] PASSED [ 66%]\nsklearn/cluster/tests/test_k_means.py::test_predict[random-dense-MiniBatchKMeans] PASSED [ 66%]\nsklearn/cluster/tests/test_k_means.py::test_predict[random-sparse-KMeans] PASSED [ 67%]\nsklearn/cluster/tests/test_k_means.py::test_predict[random-sparse-MiniBatchKMeans] PASSED [ 68%]\nsklearn/cluster/tests/test_k_means.py::test_predict[k-means++-dense-KMeans] PASSED [ 69%]\nsklearn/cluster/tests/test_k_means.py::test_predict[k-means++-dense-MiniBatchKMeans] PASSED [ 70%]\nsklearn/cluster/tests/test_k_means.py::test_predict[k-means++-sparse-KMeans] PASSED [ 70%]\nsklearn/cluster/tests/test_k_means.py::test_predict[k-means++-sparse-MiniBatchKMeans] PASSED [ 71%]\nsklearn/cluster/tests/test_k_means.py::test_predict[init2-dense-KMeans] PASSED [ 72%]\nsklearn/cluster/tests/test_k_means.py::test_predict[init2-dense-MiniBatchKMeans] PASSED [ 73%]\nsklearn/cluster/tests/test_k_means.py::test_predict[init2-sparse-KMeans] PASSED [ 74%]\nsklearn/cluster/tests/test_k_means.py::test_predict[init2-sparse-MiniBatchKMeans] PASSED [ 75%]\nsklearn/cluster/tests/test_k_means.py::test_predict_minibatch_dense_sparse[random] PASSED [ 75%]\nsklearn/cluster/tests/test_k_means.py::test_predict_minibatch_dense_sparse[k-means++] PASSED [ 76%]\nsklearn/cluster/tests/test_k_means.py::test_predict_minibatch_dense_sparse[init2] PASSED [ 77%]\nsklearn/cluster/tests/test_k_means.py::test_int_input PASSED             [ 78%]\nsklearn/cluster/tests/test_k_means.py::test_transform PASSED             [ 79%]\nsklearn/cluster/tests/test_k_means.py::test_fit_transform PASSED         [ 79%]\nsklearn/cluster/tests/test_k_means.py::test_predict_equal_labels[full] PASSED [ 80%]\nsklearn/cluster/tests/test_k_means.py::test_predict_equal_labels[elkan] PASSED [ 81%]\nsklearn/cluster/tests/test_k_means.py::test_full_vs_elkan PASSED         [ 82%]\nsklearn/cluster/tests/test_k_means.py::test_n_init PASSED                [ 83%]\nsklearn/cluster/tests/test_k_means.py::test_k_means_function PASSED      [ 83%]\nsklearn/cluster/tests/test_k_means.py::test_x_squared_norms_init_centroids PASSED [ 84%]\nsklearn/cluster/tests/test_k_means.py::test_max_iter_error PASSED        [ 85%]\nsklearn/cluster/tests/test_k_means.py::test_float_precision[False-KMeans] PASSED [ 86%]\nsklearn/cluster/tests/test_k_means.py::test_float_precision[False-MiniBatchKMeans] PASSED [ 87%]\nsklearn/cluster/tests/test_k_means.py::test_float_precision[True-KMeans] PASSED [ 87%]\nsklearn/cluster/tests/test_k_means.py::test_float_precision[True-MiniBatchKMeans] PASSED [ 88%]\nsklearn/cluster/tests/test_k_means.py::test_k_means_init_centers PASSED  [ 89%]\nsklearn/cluster/tests/test_k_means.py::test_k_means_init_fitted_centers[dense] PASSED [ 90%]\nsklearn/cluster/tests/test_k_means.py::test_k_means_init_fitted_centers[sparse] PASSED [ 91%]\nsklearn/cluster/tests/test_k_means.py::test_sparse_validate_centers PASSED [ 91%]\nsklearn/cluster/tests/test_k_means.py::test_less_centers_than_unique_points PASSED [ 92%]\nsklearn/cluster/tests/test_k_means.py::test_weighted_vs_repeated PASSED  [ 93%]\nsklearn/cluster/tests/test_k_means.py::test_unit_weights_vs_no_weights PASSED [ 94%]\nsklearn/cluster/tests/test_k_means.py::test_scaled_weights PASSED        [ 95%]\nsklearn/cluster/tests/test_k_means.py::test_sample_weight_length PASSED  [ 95%]\nsklearn/cluster/tests/test_k_means.py::test_check_normalize_sample_weight PASSED [ 96%]\nsklearn/cluster/tests/test_k_means.py::test_iter_attribute PASSED        [ 97%]\nsklearn/cluster/tests/test_k_means.py::test_k_means_empty_cluster_relocated PASSED [ 98%]\nsklearn/cluster/tests/test_k_means.py::test_minibatch_kmeans_partial_fit_int_data PASSED [ 99%]\nsklearn/cluster/tests/test_k_means.py::test_result_of_kmeans_equal_in_diff_n_jobs PASSED [100%]\n\n====================== 124 passed, 15 warnings in 12.18s =======================\n\n",
          "test_files_run": [
            "sklearn/cluster/tests/test_k_means.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "pydata__xarray-4094",
      "repo": "pydata/xarray",
      "valid": false,
      "worker": "http://34.44.241.183:8080",
      "duration": 40.699352741241455,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 866,
          "failed": 5,
          "errors": 0,
          "collected": 889,
          "duration": 20.21,
          "log_tail": "xarray/tests/test_dataset.py::TestDataset::test_resample_loffset\n  /testbed/xarray/tests/test_dataset.py:3786: FutureWarning: 'loffset' in .resample() and in Grouper() is deprecated.\n  \n  >>> df.resample(freq=\"3s\", loffset=\"8H\")\n  \n  becomes:\n  \n  >>> from pandas.tseries.frequencies import to_offset\n  >>> df = df.resample(freq=\"3s\").mean()\n  >>> df.index = df.index.to_timestamp() + to_offset(\"8H\")\n  \n    ds.bar.to_series().resample(\"24H\", loffset=\"-12H\").mean()\n\nxarray/tests/test_dataset.py::TestDataset::test_resample_drop_nondim_coords\n  /testbed/xarray/core/missing.py:563: FutureWarning: Passing method to DatetimeIndex.get_loc is deprecated and will raise in a future version. Use index.get_indexer([item], method=...) instead.\n    imin = index.get_loc(np.min(new_x.values), method=\"nearest\")\n\nxarray/tests/test_dataset.py::TestDataset::test_resample_drop_nondim_coords\n  /testbed/xarray/core/missing.py:564: FutureWarning: Passing method to DatetimeIndex.get_loc is deprecated and will raise in a future version. Use index.get_indexer([item], method=...) instead.\n    imax = index.get_loc(np.max(new_x.values), method=\"nearest\")\n\nxarray/tests/test_dataset.py::TestDataset::test_from_dataframe_sparse\n  /testbed/xarray/core/dataset.py:4553: FutureWarning: MultiIndex.is_lexsorted is deprecated as a public function, users should use MultiIndex.is_monotonic_increasing instead.\n    is_sorted = idx.is_lexsorted()\n\nxarray/tests/test_dataset.py: 64 warnings\n  /testbed/xarray/core/variable.py:1793: DeprecationWarning: the `interpolation=` argument to nanquantile was renamed to `method=`, which has additional options.\n  Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n    return np.moveaxis(_quantile_func(npa, **kwargs), 0, -1)\n\nxarray/tests/test_dataset.py: 64 warnings\n  /testbed/xarray/core/variable.py:1793: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n  Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n    return np.moveaxis(_quantile_func(npa, **kwargs), 0, -1)\n\nxarray/tests/test_dataset.py::test_coarsen_coords[1-True]\nxarray/tests/test_dataset.py::test_coarsen_coords[1-False]\n  /testbed/xarray/tests/test_dataset.py:5763: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n    coords={\"time\": pd.date_range(\"15/12/1999\", periods=364)},\n\nxarray/tests/test_dataset.py::test_trapz_datetime[np-True]\nxarray/tests/test_dataset.py::test_trapz_datetime[cftime-True]\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/dask/array/core.py:1706: FutureWarning: The `numpy.trapz` function is not implemented by Dask array. You may want to use the da.map_blocks function or something similar to silence this warning. Your code may stop working in a future release.\n    warnings.warn(\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n= 5 failed, 866 passed, 16 skipped, 1 xfailed, 1 xpassed, 2926 warnings in 16.29s =\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN xarray/tests/test_dataset.py` failed. (See above for error)",
          "test_files_run": [
            "xarray/tests/test_dataset.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 867,
          "failed": 4,
          "errors": 0,
          "collected": 889,
          "duration": 19.57,
          "log_tail": "xarray/tests/test_dataset.py::TestDataset::test_resample_loffset\n  /testbed/xarray/tests/test_dataset.py:3786: FutureWarning: 'loffset' in .resample() and in Grouper() is deprecated.\n  \n  >>> df.resample(freq=\"3s\", loffset=\"8H\")\n  \n  becomes:\n  \n  >>> from pandas.tseries.frequencies import to_offset\n  >>> df = df.resample(freq=\"3s\").mean()\n  >>> df.index = df.index.to_timestamp() + to_offset(\"8H\")\n  \n    ds.bar.to_series().resample(\"24H\", loffset=\"-12H\").mean()\n\nxarray/tests/test_dataset.py::TestDataset::test_resample_drop_nondim_coords\n  /testbed/xarray/core/missing.py:563: FutureWarning: Passing method to DatetimeIndex.get_loc is deprecated and will raise in a future version. Use index.get_indexer([item], method=...) instead.\n    imin = index.get_loc(np.min(new_x.values), method=\"nearest\")\n\nxarray/tests/test_dataset.py::TestDataset::test_resample_drop_nondim_coords\n  /testbed/xarray/core/missing.py:564: FutureWarning: Passing method to DatetimeIndex.get_loc is deprecated and will raise in a future version. Use index.get_indexer([item], method=...) instead.\n    imax = index.get_loc(np.max(new_x.values), method=\"nearest\")\n\nxarray/tests/test_dataset.py::TestDataset::test_from_dataframe_sparse\n  /testbed/xarray/core/dataset.py:4553: FutureWarning: MultiIndex.is_lexsorted is deprecated as a public function, users should use MultiIndex.is_monotonic_increasing instead.\n    is_sorted = idx.is_lexsorted()\n\nxarray/tests/test_dataset.py: 64 warnings\n  /testbed/xarray/core/variable.py:1793: DeprecationWarning: the `interpolation=` argument to nanquantile was renamed to `method=`, which has additional options.\n  Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n    return np.moveaxis(_quantile_func(npa, **kwargs), 0, -1)\n\nxarray/tests/test_dataset.py: 64 warnings\n  /testbed/xarray/core/variable.py:1793: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n  Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n    return np.moveaxis(_quantile_func(npa, **kwargs), 0, -1)\n\nxarray/tests/test_dataset.py::test_coarsen_coords[1-True]\nxarray/tests/test_dataset.py::test_coarsen_coords[1-False]\n  /testbed/xarray/tests/test_dataset.py:5763: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n    coords={\"time\": pd.date_range(\"15/12/1999\", periods=364)},\n\nxarray/tests/test_dataset.py::test_trapz_datetime[np-True]\nxarray/tests/test_dataset.py::test_trapz_datetime[cftime-True]\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/dask/array/core.py:1706: FutureWarning: The `numpy.trapz` function is not implemented by Dask array. You may want to use the da.map_blocks function or something similar to silence this warning. Your code may stop working in a future release.\n    warnings.warn(\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n= 4 failed, 867 passed, 16 skipped, 1 xfailed, 1 xpassed, 2926 warnings in 16.42s =\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN xarray/tests/test_dataset.py` failed. (See above for error)",
          "test_files_run": [
            "xarray/tests/test_dataset.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "pydata__xarray-2905",
      "repo": "pydata/xarray",
      "valid": true,
      "worker": "http://34.70.1.155:8080",
      "duration": 53.24074077606201,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 364,
          "failed": 1,
          "errors": 0,
          "collected": 458,
          "duration": 25.72,
          "log_tail": "\n../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345: 1 warning\nxarray/tests/test_variable.py: 13 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    other = LooseVersion(other)\n\nxarray/tests/__init__.py:59\nxarray/tests/__init__.py:59\nxarray/tests/__init__.py:59\nxarray/tests/__init__.py:59\nxarray/tests/__init__.py:59\nxarray/tests/__init__.py:59\n  /testbed/xarray/tests/__init__.py:59: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    return version.LooseVersion(vstring)\n\nxarray/tests/test_variable.py: 46 warnings\n  /testbed/xarray/core/variable.py:1939: DeprecationWarning: the `interpolation=` argument to nanquantile was renamed to `method=`, which has additional options.\n  Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n    return np.moveaxis(_quantile_func(npa, **kwargs), 0, -1)\n\nxarray/tests/test_variable.py: 12 warnings\n  /testbed/xarray/core/variable.py:1939: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n  Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n    return np.moveaxis(_quantile_func(npa, **kwargs), 0, -1)\n\nxarray/tests/test_variable.py: 12 warnings\n  /testbed/xarray/core/computation.py:705: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(dask_version) < LooseVersion(\"2.17.0\"):\n\nxarray/tests/test_variable.py: 13 warnings\n  /testbed/xarray/core/variable.py:1076: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(dask.__version__) < \"2.0.0\":\n\nxarray/tests/test_variable.py::TestVariableWithDask::test_eq_all_dtypes\nxarray/tests/test_variable.py::TestVariableWithDask::test_eq_all_dtypes\nxarray/tests/test_variable.py::TestVariableWithDask::test_eq_all_dtypes\nxarray/tests/test_variable.py::TestVariableWithDask::test_eq_all_dtypes\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/dask/core.py:119: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n    return func(*(_execute_task(a, cache) for a in args))\n\nxarray/tests/test_variable.py::test_raise_no_warning_for_nan_in_binary_ops\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/_pytest/python.py:194: PytestRemovedIn8Warning: Passing None has been deprecated.\n  See https://docs.pytest.org/en/latest/how-to/capture-warnings.html#additional-use-cases-of-warnings-in-tests for alternatives in common use cases.\n    result = testfunction(**testargs)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n===== 1 failed, 364 passed, 71 xfailed, 22 xpassed, 112 warnings in 22.56s =====\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN xarray/tests/test_variable.py` failed. (See above for error)",
          "test_files_run": [
            "xarray/tests/test_variable.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 365,
          "failed": 0,
          "errors": 0,
          "collected": 458,
          "duration": 26.45,
          "log_tail": "    if LooseVersion(pd.__version__) < \"0.25.0\":\n\n../opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345: 1 warning\nxarray/tests/test_variable.py: 13 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/setuptools/_distutils/version.py:345: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    other = LooseVersion(other)\n\nxarray/tests/__init__.py:59\nxarray/tests/__init__.py:59\nxarray/tests/__init__.py:59\nxarray/tests/__init__.py:59\nxarray/tests/__init__.py:59\nxarray/tests/__init__.py:59\n  /testbed/xarray/tests/__init__.py:59: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    return version.LooseVersion(vstring)\n\nxarray/tests/test_variable.py: 46 warnings\n  /testbed/xarray/core/variable.py:1940: DeprecationWarning: the `interpolation=` argument to nanquantile was renamed to `method=`, which has additional options.\n  Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n    return np.moveaxis(_quantile_func(npa, **kwargs), 0, -1)\n\nxarray/tests/test_variable.py: 12 warnings\n  /testbed/xarray/core/variable.py:1940: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n  Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n    return np.moveaxis(_quantile_func(npa, **kwargs), 0, -1)\n\nxarray/tests/test_variable.py: 12 warnings\n  /testbed/xarray/core/computation.py:705: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(dask_version) < LooseVersion(\"2.17.0\"):\n\nxarray/tests/test_variable.py: 13 warnings\n  /testbed/xarray/core/variable.py:1077: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(dask.__version__) < \"2.0.0\":\n\nxarray/tests/test_variable.py::TestVariableWithDask::test_eq_all_dtypes\nxarray/tests/test_variable.py::TestVariableWithDask::test_eq_all_dtypes\nxarray/tests/test_variable.py::TestVariableWithDask::test_eq_all_dtypes\nxarray/tests/test_variable.py::TestVariableWithDask::test_eq_all_dtypes\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/dask/core.py:119: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n    return func(*(_execute_task(a, cache) for a in args))\n\nxarray/tests/test_variable.py::test_raise_no_warning_for_nan_in_binary_ops\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/_pytest/python.py:194: PytestRemovedIn8Warning: Passing None has been deprecated.\n  See https://docs.pytest.org/en/latest/how-to/capture-warnings.html#additional-use-cases-of-warnings-in-tests for alternatives in common use cases.\n    result = testfunction(**testargs)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n========== 365 passed, 71 xfailed, 22 xpassed, 112 warnings in 22.91s ==========\n\n",
          "test_files_run": [
            "xarray/tests/test_variable.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "astropy__astropy-8707",
      "repo": "astropy/astropy",
      "valid": false,
      "worker": "http://34.41.233.120:8080",
      "duration": 56.86002779006958,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 12,
          "failed": 1,
          "errors": 140,
          "collected": 152,
          "duration": 30.58,
          "log_tail": "    lambda: ihook(item=item, **kwds), when=when, reraise=reraise\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pluggy/_hooks.py:493: in __call__\n    return self._hookexec(self.name, self._hookimpls, kwargs, firstresult)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pluggy/_manager.py:115: in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/runner.py:157: in pytest_runtest_setup\n    item.session._setupstate.setup(item)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/runner.py:497: in setup\n    raise exc\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/runner.py:494: in setup\n    col.setup()\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/python.py:1791: in setup\n    self._request._fillfixtures()\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/fixtures.py:566: in _fillfixtures\n    item.funcargs[argname] = self.getfixturevalue(argname)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/fixtures.py:585: in getfixturevalue\n    fixturedef = self._get_active_fixturedef(argname)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/fixtures.py:607: in _get_active_fixturedef\n    self._compute_fixture_value(fixturedef)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/fixtures.py:693: in _compute_fixture_value\n    fixturedef.execute(request=subrequest)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/fixtures.py:1069: in execute\n    result = ihook.pytest_fixture_setup(fixturedef=self, request=request)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pluggy/_hooks.py:493: in __call__\n    return self._hookexec(self.name, self._hookimpls, kwargs, firstresult)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pluggy/_manager.py:115: in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/fixtures.py:1123: in pytest_fixture_setup\n    result = call_fixture_func(fixturefunc, request, kwargs)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/fixtures.py:895: in call_fixture_func\n    fixture_result = next(generator)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/python.py:898: in xunit_setup_method_fixture\n    warnings.warn(\nE   pytest.PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\nE   astropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_hdu_writeto_mode[ab+] is using nose-specific method: `setup(self)`\nE   To remove this warning, rename it to `setup_method(self)`\nE   See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\n=================================== FAILURES ===================================\n___________________ TestHeaderFunctions.test_card_from_bytes ___________________\nastropy/io/fits/tests/test_header.py:93: in test_card_from_bytes\n    c = fits.Card.fromstring(b\"ABC     = 'abc'\")\nastropy/io/fits/card.py:557: in fromstring\n    card._image = _pad(image)\nastropy/io/fits/card.py:1285: in _pad\n    return input + ' ' * (Card.length - strlen)\nE   TypeError: can't concat str to bytes\n================== 1 failed, 12 passed, 140 errors in 24.15s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/io/fits/tests/test_header.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/io/fits/tests/test_header.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 13,
          "failed": 0,
          "errors": 140,
          "collected": 152,
          "duration": 25.3,
          "log_tail": "    warnings.warn(\nE   pytest.PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\nE   astropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_hdu_writeto_mode[ab] is using nose-specific method: `setup(self)`\nE   To remove this warning, rename it to `setup_method(self)`\nE   See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\n__ ERROR at setup of TestRecordValuedKeywordCards.test_hdu_writeto_mode[ab+] ___\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/runner.py:341: in from_call\n    result: Optional[TResult] = func()\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/runner.py:262: in <lambda>\n    lambda: ihook(item=item, **kwds), when=when, reraise=reraise\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pluggy/_hooks.py:493: in __call__\n    return self._hookexec(self.name, self._hookimpls, kwargs, firstresult)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pluggy/_manager.py:115: in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/runner.py:157: in pytest_runtest_setup\n    item.session._setupstate.setup(item)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/runner.py:497: in setup\n    raise exc\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/runner.py:494: in setup\n    col.setup()\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/python.py:1791: in setup\n    self._request._fillfixtures()\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/fixtures.py:566: in _fillfixtures\n    item.funcargs[argname] = self.getfixturevalue(argname)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/fixtures.py:585: in getfixturevalue\n    fixturedef = self._get_active_fixturedef(argname)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/fixtures.py:607: in _get_active_fixturedef\n    self._compute_fixture_value(fixturedef)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/fixtures.py:693: in _compute_fixture_value\n    fixturedef.execute(request=subrequest)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/fixtures.py:1069: in execute\n    result = ihook.pytest_fixture_setup(fixturedef=self, request=request)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pluggy/_hooks.py:493: in __call__\n    return self._hookexec(self.name, self._hookimpls, kwargs, firstresult)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/pluggy/_manager.py:115: in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/fixtures.py:1123: in pytest_fixture_setup\n    result = call_fixture_func(fixturefunc, request, kwargs)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/fixtures.py:895: in call_fixture_func\n    fixture_result = next(generator)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/python.py:898: in xunit_setup_method_fixture\n    warnings.warn(\nE   pytest.PytestRemovedIn8Warning: Support for nose tests is deprecated and will be removed in a future release.\nE   astropy/io/fits/tests/test_header.py::TestRecordValuedKeywordCards::test_hdu_writeto_mode[ab+] is using nose-specific method: `setup(self)`\nE   To remove this warning, rename it to `setup_method(self)`\nE   See docs: https://docs.pytest.org/en/stable/deprecations.html#support-for-tests-written-for-nose\n======================= 13 passed, 140 errors in 21.65s ========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN astropy/io/fits/tests/test_header.py` failed. (See above for error)",
          "test_files_run": [
            "astropy/io/fits/tests/test_header.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "astropy__astropy-7336",
      "repo": "astropy/astropy",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10cdff470>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 1
    },
    {
      "instance_id": "pydata__xarray-4695",
      "repo": "pydata/xarray",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "duration": 55.289833784103394,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 876,
          "failed": 2,
          "errors": 0,
          "collected": 885,
          "duration": 22.57,
          "log_tail": "  /testbed/xarray/core/dataset.py:4861: FutureWarning: MultiIndex.is_lexsorted is deprecated as a public function, users should use MultiIndex.is_monotonic_increasing instead.\n    is_sorted = idx.is_lexsorted()\n\nxarray/tests/test_dataarray.py::TestDataArray::test_to_and_from_cdms2_classic\nxarray/tests/test_dataarray.py::TestIrisConversion::test_to_and_from_iris\nxarray/tests/test_dataarray.py::TestIrisConversion::test_to_and_from_iris\nxarray/tests/test_dataarray.py::TestIrisConversion::test_to_and_from_iris_dask\nxarray/tests/test_dataarray.py::TestIrisConversion::test_to_and_from_iris_dask\n  /testbed/xarray/coding/times.py:236: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(pd.__version__) < \"0.25.0\":\n\nxarray/tests/test_dataarray.py::TestDataArray::test_to_and_from_cdms2_sgrid\nxarray/tests/test_dataarray.py::TestDataArray::test_to_and_from_cdms2_sgrid\nxarray/tests/test_dataarray.py::TestDataArray::test_to_and_from_cdms2_sgrid\nxarray/tests/test_dataarray.py::TestDataArray::test_to_and_from_cdms2_sgrid\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/numpy/ma/core.py:7939: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n    if not np.all(xinf == filled(np.isinf(y), False)):\n\nxarray/tests/test_dataarray.py::TestDataArray::test_polyfit[True-True]\nxarray/tests/test_dataarray.py::TestDataArray::test_polyfit[True-False]\nxarray/tests/test_dataarray.py::TestDataArray::test_polyfit[False-True]\nxarray/tests/test_dataarray.py::TestDataArray::test_polyfit[False-False]\n  /testbed/xarray/core/missing.py:265: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n    if not index.is_monotonic:\n\nxarray/tests/test_dataarray.py::TestDataArray::test_polyfit[True-True]\nxarray/tests/test_dataarray.py::TestDataArray::test_polyfit[True-False]\nxarray/tests/test_dataarray.py::TestDataArray::test_polyfit[False-True]\nxarray/tests/test_dataarray.py::TestDataArray::test_polyfit[False-False]\n  /testbed/xarray/core/dataset.py:6258: RuntimeWarning: overflow encountered in multiply\n    scale = np.sqrt((lhs * lhs).sum(axis=0))\n\nxarray/tests/test_dataarray.py: 12 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n\nxarray/tests/test_dataarray.py::test_coarsen_keep_attrs\n  /testbed/xarray/tests/test_dataarray.py:6235: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n    coords={\"time\": pd.date_range(\"15/12/1999\", periods=364)},\n\nxarray/tests/test_dataarray.py::test_raise_no_warning_for_nan_in_binary_ops\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/_pytest/python.py:194: PytestRemovedIn8Warning: Passing None has been deprecated.\n  See https://docs.pytest.org/en/latest/how-to/capture-warnings.html#additional-use-cases-of-warnings-in-tests for alternatives in common use cases.\n    result = testfunction(**testargs)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n= 2 failed, 876 passed, 1 skipped, 5 xfailed, 1 xpassed, 259 warnings in 17.33s =\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN xarray/tests/test_dataarray.py` failed. (See above for error)",
          "test_files_run": [
            "xarray/tests/test_dataarray.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 877,
          "failed": 1,
          "errors": 0,
          "collected": 885,
          "duration": 29.48,
          "log_tail": "  /testbed/xarray/core/dataset.py:4861: FutureWarning: MultiIndex.is_lexsorted is deprecated as a public function, users should use MultiIndex.is_monotonic_increasing instead.\n    is_sorted = idx.is_lexsorted()\n\nxarray/tests/test_dataarray.py::TestDataArray::test_to_and_from_cdms2_classic\nxarray/tests/test_dataarray.py::TestIrisConversion::test_to_and_from_iris\nxarray/tests/test_dataarray.py::TestIrisConversion::test_to_and_from_iris\nxarray/tests/test_dataarray.py::TestIrisConversion::test_to_and_from_iris_dask\nxarray/tests/test_dataarray.py::TestIrisConversion::test_to_and_from_iris_dask\n  /testbed/xarray/coding/times.py:236: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n    if LooseVersion(pd.__version__) < \"0.25.0\":\n\nxarray/tests/test_dataarray.py::TestDataArray::test_to_and_from_cdms2_sgrid\nxarray/tests/test_dataarray.py::TestDataArray::test_to_and_from_cdms2_sgrid\nxarray/tests/test_dataarray.py::TestDataArray::test_to_and_from_cdms2_sgrid\nxarray/tests/test_dataarray.py::TestDataArray::test_to_and_from_cdms2_sgrid\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/numpy/ma/core.py:7939: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n    if not np.all(xinf == filled(np.isinf(y), False)):\n\nxarray/tests/test_dataarray.py::TestDataArray::test_polyfit[True-True]\nxarray/tests/test_dataarray.py::TestDataArray::test_polyfit[True-False]\nxarray/tests/test_dataarray.py::TestDataArray::test_polyfit[False-True]\nxarray/tests/test_dataarray.py::TestDataArray::test_polyfit[False-False]\n  /testbed/xarray/core/missing.py:265: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n    if not index.is_monotonic:\n\nxarray/tests/test_dataarray.py::TestDataArray::test_polyfit[True-True]\nxarray/tests/test_dataarray.py::TestDataArray::test_polyfit[True-False]\nxarray/tests/test_dataarray.py::TestDataArray::test_polyfit[False-True]\nxarray/tests/test_dataarray.py::TestDataArray::test_polyfit[False-False]\n  /testbed/xarray/core/dataset.py:6258: RuntimeWarning: overflow encountered in multiply\n    scale = np.sqrt((lhs * lhs).sum(axis=0))\n\nxarray/tests/test_dataarray.py: 12 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n\nxarray/tests/test_dataarray.py::test_coarsen_keep_attrs\n  /testbed/xarray/tests/test_dataarray.py:6235: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n    coords={\"time\": pd.date_range(\"15/12/1999\", periods=364)},\n\nxarray/tests/test_dataarray.py::test_raise_no_warning_for_nan_in_binary_ops\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/_pytest/python.py:194: PytestRemovedIn8Warning: Passing None has been deprecated.\n  See https://docs.pytest.org/en/latest/how-to/capture-warnings.html#additional-use-cases-of-warnings-in-tests for alternatives in common use cases.\n    result = testfunction(**testargs)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n= 1 failed, 877 passed, 1 skipped, 5 xfailed, 1 xpassed, 259 warnings in 25.47s =\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN xarray/tests/test_dataarray.py` failed. (See above for error)",
          "test_files_run": [
            "xarray/tests/test_dataarray.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "psf__requests-1142",
      "repo": "psf/requests",
      "valid": false,
      "worker": "http://34.70.1.155:8080",
      "duration": 6.270421743392944,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 5,
          "failed": 22,
          "errors": 0,
          "collected": 27,
          "duration": 2.69,
          "log_tail": "    return request('get', url, **kwargs)\nrequests/api.py:44: in request\n    return session.request(method=method, url=url, **kwargs)\nrequests/sessions.py:280: in request\n    resp = self.send(prep, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)\nrequests/sessions.py:373: in send\n    r = adapter.send(request, **kwargs)\nrequests/adapters.py:161: in send\n    resp = conn.urlopen(\nrequests/packages/urllib3/connectionpool.py:416: in urlopen\n    conn = self._get_conn(timeout=pool_timeout)\nrequests/packages/urllib3/connectionpool.py:231: in _get_conn\n    return conn or self._new_conn()\nrequests/packages/urllib3/connectionpool.py:196: in _new_conn\n    return HTTPConnection(host=self.host,\nE   TypeError: __init__() got an unexpected keyword argument 'strict'\n__________________ RequestsTestCase.test_user_agent_transfers __________________\ntest_requests.py:120: in test_user_agent_transfers\n    r = requests.get(httpbin('user-agent'), headers=heads)\nrequests/api.py:55: in get\n    return request('get', url, **kwargs)\nrequests/api.py:44: in request\n    return session.request(method=method, url=url, **kwargs)\nrequests/sessions.py:280: in request\n    resp = self.send(prep, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)\nrequests/sessions.py:373: in send\n    r = adapter.send(request, **kwargs)\nrequests/adapters.py:161: in send\n    resp = conn.urlopen(\nrequests/packages/urllib3/connectionpool.py:416: in urlopen\n    conn = self._get_conn(timeout=pool_timeout)\nrequests/packages/urllib3/connectionpool.py:231: in _get_conn\n    return conn or self._new_conn()\nrequests/packages/urllib3/connectionpool.py:196: in _new_conn\n    return HTTPConnection(host=self.host,\nE   TypeError: __init__() got an unexpected keyword argument 'strict'\n=============================== warnings summary ===============================\nrequests/packages/urllib3/_collections.py:7\n  /testbed/requests/packages/urllib3/_collections.py:7: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import MutableMapping\n\ntest_requests.py::RequestsTestCase::test_BASICAUTH_TUPLE_HTTP_200_OK_GET\n  /testbed/requests/models.py:140: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    if isinstance(hook, collections.Callable):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=================== 22 failed, 5 passed, 2 warnings in 0.53s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN test_requests.py` failed. (See above for error)",
          "test_files_run": [
            "test_requests.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 6,
          "failed": 21,
          "errors": 0,
          "collected": 27,
          "duration": 2.71,
          "log_tail": "    resp = conn.urlopen(\nrequests/packages/urllib3/connectionpool.py:416: in urlopen\n    conn = self._get_conn(timeout=pool_timeout)\nrequests/packages/urllib3/connectionpool.py:231: in _get_conn\n    return conn or self._new_conn()\nrequests/packages/urllib3/connectionpool.py:196: in _new_conn\n    return HTTPConnection(host=self.host,\nE   TypeError: __init__() got an unexpected keyword argument 'strict'\n__________________ RequestsTestCase.test_user_agent_transfers __________________\ntest_requests.py:120: in test_user_agent_transfers\n    r = requests.get(httpbin('user-agent'), headers=heads)\nrequests/api.py:55: in get\n    return request('get', url, **kwargs)\nrequests/api.py:44: in request\n    return session.request(method=method, url=url, **kwargs)\nrequests/sessions.py:280: in request\n    resp = self.send(prep, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)\nrequests/sessions.py:373: in send\n    r = adapter.send(request, **kwargs)\nrequests/adapters.py:161: in send\n    resp = conn.urlopen(\nrequests/packages/urllib3/connectionpool.py:416: in urlopen\n    conn = self._get_conn(timeout=pool_timeout)\nrequests/packages/urllib3/connectionpool.py:231: in _get_conn\n    return conn or self._new_conn()\nrequests/packages/urllib3/connectionpool.py:196: in _new_conn\n    return HTTPConnection(host=self.host,\nE   TypeError: __init__() got an unexpected keyword argument 'strict'\n=============================== warnings summary ===============================\nrequests/packages/urllib3/_collections.py:7\n  /testbed/requests/packages/urllib3/_collections.py:7: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import MutableMapping\n\nrequests/models.py:608\n  /testbed/requests/models.py:608: DeprecationWarning: invalid escape sequence \\*\n    \"\"\"Returns the json-encoded content of a response, if any.\n\nrequests/models.py:561\n  /testbed/requests/models.py:561: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n    if self.status_code is 0:\n\ntest_requests.py::RequestsTestCase::test_BASICAUTH_TUPLE_HTTP_200_OK_GET\n  /testbed/requests/models.py:140: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    if isinstance(hook, collections.Callable):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=================== 21 failed, 6 passed, 4 warnings in 0.52s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN test_requests.py` failed. (See above for error)",
          "test_files_run": [
            "test_requests.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "astropy__astropy-8872",
      "repo": "astropy/astropy",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10cfafe30>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 1
    },
    {
      "instance_id": "pydata__xarray-4687",
      "repo": "pydata/xarray",
      "valid": false,
      "worker": "http://34.44.241.183:8080",
      "duration": 112.62975573539734,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 1759,
          "failed": 2,
          "errors": 0,
          "collected": 2578,
          "duration": 57.8,
          "log_tail": "xarray/tests/test_computation.py::test_corr_lazycorr_consistency[time-da_a3-da_b3]\nxarray/tests/test_computation.py::test_corr_lazycorr_consistency[time-da_a5-da_b5]\nxarray/tests/test_computation.py::test_corr_lazycorr_consistency[time-da_a6-da_b6]\nxarray/tests/test_computation.py::test_corr_lazycorr_consistency[x-da_a3-da_b3]\nxarray/tests/test_computation.py::test_corr_lazycorr_consistency[x-da_a4-da_b4]\nxarray/tests/test_computation.py::test_corr_lazycorr_consistency[x-da_a5-da_b5]\nxarray/tests/test_computation.py::test_corr_lazycorr_consistency[x-da_a6-da_b6]\nxarray/tests/test_computation.py::test_corr_lazycorr_consistency[x-da_a7-da_b7]\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/dask/core.py:119: RuntimeWarning: invalid value encountered in divide\n    return func(*(_execute_task(a, cache) for a in args))\n\nxarray/tests/test_computation.py::test_corr_lazycorr_consistency[time-da_a4-da_b4]\nxarray/tests/test_computation.py::test_corr_lazycorr_consistency[time-da_a7-da_b7]\nxarray/tests/test_computation.py::test_corr_lazycorr_consistency[x-da_a1-da_b1]\nxarray/tests/test_computation.py::test_corr_lazycorr_consistency[x-da_a2-da_b2]\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/dask/array/numpy_compat.py:41: RuntimeWarning: invalid value encountered in divide\n    x = np.divide(x1, x2, out)\n\nxarray/tests/test_computation.py: 2 warnings\nxarray/tests/test_units.py: 8 warnings\n  /testbed/xarray/core/missing.py:269: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n    if not index.is_monotonic:\n\nxarray/tests/test_units.py: 128 warnings\n  /testbed/xarray/core/variable.py:2046: DeprecationWarning: the `interpolation=` argument to nanquantile was renamed to `method=`, which has additional options.\n  Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n    return np.moveaxis(_quantile_func(npa, **kwargs), 0, -1)\n\nxarray/tests/test_units.py: 44 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pint/facets/numpy/numpy_func.py:856: DeprecationWarning: the `interpolation=` argument to nanquantile was renamed to `method=`, which has additional options.\n  Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n    ret = func(*bound_args.args, **bound_args.kwargs)\n\nxarray/tests/test_units.py: 32 warnings\n  /testbed/xarray/core/missing.py:567: FutureWarning: Passing method to Int64Index.get_loc is deprecated and will raise in a future version. Use index.get_indexer([item], method=...) instead.\n    imin = index.get_loc(minval, method=\"nearest\")\n\nxarray/tests/test_units.py: 32 warnings\n  /testbed/xarray/core/missing.py:568: FutureWarning: Passing method to Int64Index.get_loc is deprecated and will raise in a future version. Use index.get_indexer([item], method=...) instead.\n    imax = index.get_loc(maxval, method=\"nearest\")\n\nxarray/tests/test_units.py: 12 warnings\n  /testbed/xarray/core/groupby.py:346: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n    if not index.is_monotonic:\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n= 2 failed, 1759 passed, 693 skipped, 112 xfailed, 12 xpassed, 365 warnings in 51.11s =\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN xarray/tests/test_computation.py xarray/tests/test_units.py` failed. (See above for error)",
          "test_files_run": [
            "xarray/tests/test_computation.py",
            "xarray/tests/test_units.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 1760,
          "failed": 1,
          "errors": 0,
          "collected": 2578,
          "duration": 53.89,
          "log_tail": "xarray/tests/test_computation.py::test_corr_lazycorr_consistency[time-da_a3-da_b3]\nxarray/tests/test_computation.py::test_corr_lazycorr_consistency[time-da_a5-da_b5]\nxarray/tests/test_computation.py::test_corr_lazycorr_consistency[time-da_a6-da_b6]\nxarray/tests/test_computation.py::test_corr_lazycorr_consistency[x-da_a3-da_b3]\nxarray/tests/test_computation.py::test_corr_lazycorr_consistency[x-da_a4-da_b4]\nxarray/tests/test_computation.py::test_corr_lazycorr_consistency[x-da_a5-da_b5]\nxarray/tests/test_computation.py::test_corr_lazycorr_consistency[x-da_a6-da_b6]\nxarray/tests/test_computation.py::test_corr_lazycorr_consistency[x-da_a7-da_b7]\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/dask/core.py:119: RuntimeWarning: invalid value encountered in divide\n    return func(*(_execute_task(a, cache) for a in args))\n\nxarray/tests/test_computation.py::test_corr_lazycorr_consistency[time-da_a4-da_b4]\nxarray/tests/test_computation.py::test_corr_lazycorr_consistency[time-da_a7-da_b7]\nxarray/tests/test_computation.py::test_corr_lazycorr_consistency[x-da_a1-da_b1]\nxarray/tests/test_computation.py::test_corr_lazycorr_consistency[x-da_a2-da_b2]\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/dask/array/numpy_compat.py:41: RuntimeWarning: invalid value encountered in divide\n    x = np.divide(x1, x2, out)\n\nxarray/tests/test_computation.py: 2 warnings\nxarray/tests/test_units.py: 8 warnings\n  /testbed/xarray/core/missing.py:269: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n    if not index.is_monotonic:\n\nxarray/tests/test_units.py: 128 warnings\n  /testbed/xarray/core/variable.py:2046: DeprecationWarning: the `interpolation=` argument to nanquantile was renamed to `method=`, which has additional options.\n  Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n    return np.moveaxis(_quantile_func(npa, **kwargs), 0, -1)\n\nxarray/tests/test_units.py: 44 warnings\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/pint/facets/numpy/numpy_func.py:856: DeprecationWarning: the `interpolation=` argument to nanquantile was renamed to `method=`, which has additional options.\n  Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n    ret = func(*bound_args.args, **bound_args.kwargs)\n\nxarray/tests/test_units.py: 32 warnings\n  /testbed/xarray/core/missing.py:567: FutureWarning: Passing method to Int64Index.get_loc is deprecated and will raise in a future version. Use index.get_indexer([item], method=...) instead.\n    imin = index.get_loc(minval, method=\"nearest\")\n\nxarray/tests/test_units.py: 32 warnings\n  /testbed/xarray/core/missing.py:568: FutureWarning: Passing method to Int64Index.get_loc is deprecated and will raise in a future version. Use index.get_indexer([item], method=...) instead.\n    imax = index.get_loc(maxval, method=\"nearest\")\n\nxarray/tests/test_units.py: 12 warnings\n  /testbed/xarray/core/groupby.py:346: FutureWarning: is_monotonic is deprecated and will be removed in a future version. Use is_monotonic_increasing instead.\n    if not index.is_monotonic:\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n= 1 failed, 1760 passed, 693 skipped, 112 xfailed, 12 xpassed, 365 warnings in 48.68s =\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN xarray/tests/test_computation.py xarray/tests/test_units.py` failed. (See above for error)",
          "test_files_run": [
            "xarray/tests/test_computation.py",
            "xarray/tests/test_units.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "psf__requests-1766",
      "repo": "psf/requests",
      "valid": false,
      "worker": "http://34.41.233.120:8080",
      "duration": 51.52511787414551,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 89,
          "failed": 2,
          "errors": 0,
          "collected": 91,
          "duration": 25.9,
          "log_tail": "test_requests.py::TestContentEncodingDetection::test_precedence PASSED   [ 76%]\ntest_requests.py::TestContentEncodingDetection::test_xhtml_pragma PASSED [ 78%]\ntest_requests.py::TestContentEncodingDetection::test_xml PASSED          [ 79%]\ntest_requests.py::TestCaseInsensitiveDict::test_contains PASSED          [ 80%]\ntest_requests.py::TestCaseInsensitiveDict::test_delitem PASSED           [ 81%]\ntest_requests.py::TestCaseInsensitiveDict::test_docstring_example PASSED [ 82%]\ntest_requests.py::TestCaseInsensitiveDict::test_equality PASSED          [ 83%]\ntest_requests.py::TestCaseInsensitiveDict::test_fixes_649 PASSED         [ 84%]\ntest_requests.py::TestCaseInsensitiveDict::test_get PASSED               [ 85%]\ntest_requests.py::TestCaseInsensitiveDict::test_getitem PASSED           [ 86%]\ntest_requests.py::TestCaseInsensitiveDict::test_iter PASSED              [ 87%]\ntest_requests.py::TestCaseInsensitiveDict::test_iterable_init PASSED     [ 89%]\ntest_requests.py::TestCaseInsensitiveDict::test_kwargs_init PASSED       [ 90%]\ntest_requests.py::TestCaseInsensitiveDict::test_len PASSED               [ 91%]\ntest_requests.py::TestCaseInsensitiveDict::test_lower_items PASSED       [ 92%]\ntest_requests.py::TestCaseInsensitiveDict::test_mapping_init PASSED      [ 93%]\ntest_requests.py::TestCaseInsensitiveDict::test_preserve_key_case PASSED [ 94%]\ntest_requests.py::TestCaseInsensitiveDict::test_preserve_last_key_case PASSED [ 95%]\ntest_requests.py::TestCaseInsensitiveDict::test_setdefault PASSED        [ 96%]\ntest_requests.py::TestCaseInsensitiveDict::test_update PASSED            [ 97%]\ntest_requests.py::TestCaseInsensitiveDict::test_update_retains_unchanged PASSED [ 98%]\ntest_requests.py::UtilsTestCase::test_super_len_io_streams PASSED        [100%]\n\n=================================== FAILURES ===================================\n______________ RequestsTestCase.test_DIGESTAUTH_QUOTES_QOP_VALUE _______________\ntest_requests.py:329: in test_DIGESTAUTH_QUOTES_QOP_VALUE\n    assert '\"auth\"' in r.request.headers['Authorization']\nE   assert '\"auth\"' in 'Digest username=\"user\", realm=\"me@kennethreitz.com\", nonce=\"b306969367906d573db485965fd4ec74\", uri=\"/digest-auth/auth/user/pass\", response=\"309fd91571ac3c49b6a33cd17598dc09\", opaque=\"317a4de75c70f6959acb991aa249fbe8\", algorithm=\"MD5\", qop=auth, nc=00000001, cnonce=\"4134589f2209ce83\"'\n________________ RequestsTestCase.test_conflicting_post_params _________________\ntest_requests.py:370: in test_conflicting_post_params\n    pytest.raises(ValueError, \"requests.post(url, data='[{\\\"some\\\": \\\"data\\\"}]', files={'some': f})\")\nE   TypeError: 'requests.post(url, data=\\'[{\"some\": \"data\"}]\\', files={\\'some\\': f})' object (type: <class 'str'>) must be callable\n=============================== warnings summary ===============================\nrequests/packages/urllib3/_collections.py:7\n  /testbed/requests/packages/urllib3/_collections.py:7: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import MutableMapping\n\nrequests/sessions.py:12\n  /testbed/requests/sessions.py:12: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping\n\ntest_requests.py::RequestsTestCase::test_BASICAUTH_TUPLE_HTTP_200_OK_GET\n  /testbed/requests/models.py:156: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    if isinstance(hook, collections.Callable):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================== 2 failed, 89 passed, 3 warnings in 23.03s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN test_requests.py` failed. (See above for error)",
          "test_files_run": [
            "test_requests.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 90,
          "failed": 1,
          "errors": 0,
          "collected": 91,
          "duration": 24.81,
          "log_tail": "test_requests.py::RequestsTestCase::test_user_agent_transfers PASSED     [ 72%]\ntest_requests.py::TestContentEncodingDetection::test_html4_pragma PASSED [ 73%]\ntest_requests.py::TestContentEncodingDetection::test_html_charset PASSED [ 74%]\ntest_requests.py::TestContentEncodingDetection::test_none PASSED         [ 75%]\ntest_requests.py::TestContentEncodingDetection::test_precedence PASSED   [ 76%]\ntest_requests.py::TestContentEncodingDetection::test_xhtml_pragma PASSED [ 78%]\ntest_requests.py::TestContentEncodingDetection::test_xml PASSED          [ 79%]\ntest_requests.py::TestCaseInsensitiveDict::test_contains PASSED          [ 80%]\ntest_requests.py::TestCaseInsensitiveDict::test_delitem PASSED           [ 81%]\ntest_requests.py::TestCaseInsensitiveDict::test_docstring_example PASSED [ 82%]\ntest_requests.py::TestCaseInsensitiveDict::test_equality PASSED          [ 83%]\ntest_requests.py::TestCaseInsensitiveDict::test_fixes_649 PASSED         [ 84%]\ntest_requests.py::TestCaseInsensitiveDict::test_get PASSED               [ 85%]\ntest_requests.py::TestCaseInsensitiveDict::test_getitem PASSED           [ 86%]\ntest_requests.py::TestCaseInsensitiveDict::test_iter PASSED              [ 87%]\ntest_requests.py::TestCaseInsensitiveDict::test_iterable_init PASSED     [ 89%]\ntest_requests.py::TestCaseInsensitiveDict::test_kwargs_init PASSED       [ 90%]\ntest_requests.py::TestCaseInsensitiveDict::test_len PASSED               [ 91%]\ntest_requests.py::TestCaseInsensitiveDict::test_lower_items PASSED       [ 92%]\ntest_requests.py::TestCaseInsensitiveDict::test_mapping_init PASSED      [ 93%]\ntest_requests.py::TestCaseInsensitiveDict::test_preserve_key_case PASSED [ 94%]\ntest_requests.py::TestCaseInsensitiveDict::test_preserve_last_key_case PASSED [ 95%]\ntest_requests.py::TestCaseInsensitiveDict::test_setdefault PASSED        [ 96%]\ntest_requests.py::TestCaseInsensitiveDict::test_update PASSED            [ 97%]\ntest_requests.py::TestCaseInsensitiveDict::test_update_retains_unchanged PASSED [ 98%]\ntest_requests.py::UtilsTestCase::test_super_len_io_streams PASSED        [100%]\n\n=================================== FAILURES ===================================\n________________ RequestsTestCase.test_conflicting_post_params _________________\ntest_requests.py:370: in test_conflicting_post_params\n    pytest.raises(ValueError, \"requests.post(url, data='[{\\\"some\\\": \\\"data\\\"}]', files={'some': f})\")\nE   TypeError: 'requests.post(url, data=\\'[{\"some\": \"data\"}]\\', files={\\'some\\': f})' object (type: <class 'str'>) must be callable\n=============================== warnings summary ===============================\nrequests/packages/urllib3/_collections.py:7\n  /testbed/requests/packages/urllib3/_collections.py:7: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import MutableMapping\n\nrequests/sessions.py:12\n  /testbed/requests/sessions.py:12: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping\n\ntest_requests.py::RequestsTestCase::test_BASICAUTH_TUPLE_HTTP_200_OK_GET\n  /testbed/requests/models.py:156: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    if isinstance(hook, collections.Callable):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================== 1 failed, 90 passed, 3 warnings in 22.70s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN test_requests.py` failed. (See above for error)",
          "test_files_run": [
            "test_requests.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "psf__requests-2931",
      "repo": "psf/requests",
      "valid": false,
      "worker": "http://35.239.238.137:8080",
      "duration": 6.83599591255188,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 85,
          "failed": 1,
          "errors": 81,
          "collected": 168,
          "duration": 3.29,
          "log_tail": "requests/api.py:137\n  /testbed/requests/api.py:137: DeprecationWarning: invalid escape sequence \\*\n    \"\"\"Sends a DELETE request.\n\nrequests/sessions.py:473\n  /testbed/requests/sessions.py:473: DeprecationWarning: invalid escape sequence \\*\n    \"\"\"Sends a GET request. Returns :class:`Response` object.\n\nrequests/sessions.py:483\n  /testbed/requests/sessions.py:483: DeprecationWarning: invalid escape sequence \\*\n    \"\"\"Sends a OPTIONS request. Returns :class:`Response` object.\n\nrequests/sessions.py:493\n  /testbed/requests/sessions.py:493: DeprecationWarning: invalid escape sequence \\*\n    \"\"\"Sends a HEAD request. Returns :class:`Response` object.\n\nrequests/sessions.py:503\n  /testbed/requests/sessions.py:503: DeprecationWarning: invalid escape sequence \\*\n    \"\"\"Sends a POST request. Returns :class:`Response` object.\n\nrequests/sessions.py:514\n  /testbed/requests/sessions.py:514: DeprecationWarning: invalid escape sequence \\*\n    \"\"\"Sends a PUT request. Returns :class:`Response` object.\n\nrequests/sessions.py:524\n  /testbed/requests/sessions.py:524: DeprecationWarning: invalid escape sequence \\*\n    \"\"\"Sends a PATCH request. Returns :class:`Response` object.\n\nrequests/sessions.py:534\n  /testbed/requests/sessions.py:534: DeprecationWarning: invalid escape sequence \\*\n    \"\"\"Sends a DELETE request. Returns :class:`Response` object.\n\ntest_requests.py::TestRequests::test_invalid_url\n  /testbed/requests/models.py:168: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    if isinstance(hook, collections.Callable):\n\ntest_requests.py::TestContentEncodingDetection::test_html4_pragma\ntest_requests.py::TestContentEncodingDetection::test_html_charset\ntest_requests.py::TestContentEncodingDetection::test_none\ntest_requests.py::TestContentEncodingDetection::test_precedence\ntest_requests.py::TestContentEncodingDetection::test_xhtml_pragma\ntest_requests.py::TestContentEncodingDetection::test_xml\n  /testbed/requests/utils.py:315: DeprecationWarning: In requests 3.0, get_encodings_from_content will be removed. For more information, please see the discussion on issue #2266. (This warning should only appear once.)\n    warnings.warn((\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n======= 1 failed, 85 passed, 1 xfailed, 28 warnings, 81 errors in 0.73s ========\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN test_requests.py` failed. (See above for error)",
          "test_files_run": [
            "test_requests.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 86,
          "failed": 0,
          "errors": 81,
          "collected": 168,
          "duration": 2.76,
          "log_tail": "requests/api.py:137\n  /testbed/requests/api.py:137: DeprecationWarning: invalid escape sequence \\*\n    \"\"\"Sends a DELETE request.\n\nrequests/sessions.py:473\n  /testbed/requests/sessions.py:473: DeprecationWarning: invalid escape sequence \\*\n    \"\"\"Sends a GET request. Returns :class:`Response` object.\n\nrequests/sessions.py:483\n  /testbed/requests/sessions.py:483: DeprecationWarning: invalid escape sequence \\*\n    \"\"\"Sends a OPTIONS request. Returns :class:`Response` object.\n\nrequests/sessions.py:493\n  /testbed/requests/sessions.py:493: DeprecationWarning: invalid escape sequence \\*\n    \"\"\"Sends a HEAD request. Returns :class:`Response` object.\n\nrequests/sessions.py:503\n  /testbed/requests/sessions.py:503: DeprecationWarning: invalid escape sequence \\*\n    \"\"\"Sends a POST request. Returns :class:`Response` object.\n\nrequests/sessions.py:514\n  /testbed/requests/sessions.py:514: DeprecationWarning: invalid escape sequence \\*\n    \"\"\"Sends a PUT request. Returns :class:`Response` object.\n\nrequests/sessions.py:524\n  /testbed/requests/sessions.py:524: DeprecationWarning: invalid escape sequence \\*\n    \"\"\"Sends a PATCH request. Returns :class:`Response` object.\n\nrequests/sessions.py:534\n  /testbed/requests/sessions.py:534: DeprecationWarning: invalid escape sequence \\*\n    \"\"\"Sends a DELETE request. Returns :class:`Response` object.\n\ntest_requests.py::TestRequests::test_invalid_url\n  /testbed/requests/models.py:168: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    if isinstance(hook, collections.Callable):\n\ntest_requests.py::TestContentEncodingDetection::test_html4_pragma\ntest_requests.py::TestContentEncodingDetection::test_html_charset\ntest_requests.py::TestContentEncodingDetection::test_none\ntest_requests.py::TestContentEncodingDetection::test_precedence\ntest_requests.py::TestContentEncodingDetection::test_xhtml_pragma\ntest_requests.py::TestContentEncodingDetection::test_xml\n  /testbed/requests/utils.py:315: DeprecationWarning: In requests 3.0, get_encodings_from_content will be removed. For more information, please see the discussion on issue #2266. (This warning should only appear once.)\n    warnings.warn((\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n============ 86 passed, 1 xfailed, 28 warnings, 81 errors in 0.63s =============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN test_requests.py` failed. (See above for error)",
          "test_files_run": [
            "test_requests.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "psf__requests-1921",
      "repo": "psf/requests",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "duration": 60.59525513648987,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 117,
          "failed": 2,
          "errors": 0,
          "collected": 119,
          "duration": 23.44,
          "log_tail": "test_requests.py::TestCaseInsensitiveDict::test_lower_items PASSED       [ 83%]\ntest_requests.py::TestCaseInsensitiveDict::test_mapping_init PASSED      [ 84%]\ntest_requests.py::TestCaseInsensitiveDict::test_preserve_key_case PASSED [ 84%]\ntest_requests.py::TestCaseInsensitiveDict::test_preserve_last_key_case PASSED [ 85%]\ntest_requests.py::TestCaseInsensitiveDict::test_setdefault PASSED        [ 86%]\ntest_requests.py::TestCaseInsensitiveDict::test_update PASSED            [ 87%]\ntest_requests.py::TestCaseInsensitiveDict::test_update_retains_unchanged PASSED [ 88%]\ntest_requests.py::UtilsTestCase::test_address_in_network PASSED          [ 89%]\ntest_requests.py::UtilsTestCase::test_dotted_netmask PASSED              [ 89%]\ntest_requests.py::UtilsTestCase::test_get_auth_from_url PASSED           [ 90%]\ntest_requests.py::UtilsTestCase::test_get_environ_proxies PASSED         [ 91%]\ntest_requests.py::UtilsTestCase::test_get_environ_proxies_ip_ranges PASSED [ 92%]\ntest_requests.py::UtilsTestCase::test_is_ipv4_address PASSED             [ 93%]\ntest_requests.py::UtilsTestCase::test_is_valid_cidr PASSED               [ 94%]\ntest_requests.py::UtilsTestCase::test_super_len_io_streams PASSED        [ 94%]\ntest_requests.py::TestMorselToCookieExpires::test_expires_invalid_int PASSED [ 95%]\ntest_requests.py::TestMorselToCookieExpires::test_expires_invalid_str PASSED [ 96%]\ntest_requests.py::TestMorselToCookieExpires::test_expires_none PASSED    [ 97%]\ntest_requests.py::TestMorselToCookieExpires::test_expires_valid_str PASSED [ 98%]\ntest_requests.py::TestMorselToCookieMaxAge::test_max_age_invalid_str PASSED [ 99%]\ntest_requests.py::TestMorselToCookieMaxAge::test_max_age_valid_int PASSED [100%]\n\n=================================== FAILURES ===================================\n________________ RequestsTestCase.test_conflicting_post_params _________________\ntest_requests.py:395: in test_conflicting_post_params\n    pytest.raises(ValueError, \"requests.post(url, data='[{\\\"some\\\": \\\"data\\\"}]', files={'some': f})\")\nE   TypeError: 'requests.post(url, data=\\'[{\"some\": \"data\"}]\\', files={\\'some\\': f})' object (type: <class 'str'>) must be callable\n_______ RequestsTestCase.test_headers_on_session_with_None_are_not_sent ________\ntest_requests.py:220: in test_headers_on_session_with_None_are_not_sent\n    assert 'Accept-Encoding' not in prep.headers\nE   AssertionError: assert 'Accept-Encoding' not in CaseInsensitiveDict({'User-Agent': 'python-requests/2.3.0 CPython/3.9.20 Linux/6.8.0-1033-gcp', 'Accept-Encoding': None, 'Accept': '*/*', 'Authorization': 'Basic dXNlcjpwYXNz'})\nE    +  where CaseInsensitiveDict({'User-Agent': 'python-requests/2.3.0 CPython/3.9.20 Linux/6.8.0-1033-gcp', 'Accept-Encoding': None, 'Accept': '*/*', 'Authorization': 'Basic dXNlcjpwYXNz'}) = <PreparedRequest [GET]>.headers\n=============================== warnings summary ===============================\nrequests/packages/urllib3/_collections.py:7\n  /testbed/requests/packages/urllib3/_collections.py:7: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import MutableMapping\n\nrequests/sessions.py:12\n  /testbed/requests/sessions.py:12: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping\n\ntest_requests.py::RequestsTestCase::test_BASICAUTH_TUPLE_HTTP_200_OK_GET\n  /testbed/requests/models.py:164: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    if isinstance(hook, collections.Callable):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================== 2 failed, 117 passed, 3 warnings in 19.61s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN test_requests.py` failed. (See above for error)",
          "test_files_run": [
            "test_requests.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 118,
          "failed": 1,
          "errors": 0,
          "collected": 119,
          "duration": 29.14,
          "log_tail": "________________ RequestsTestCase.test_conflicting_post_params _________________\ntest_requests.py:395: in test_conflicting_post_params\n    pytest.raises(ValueError, \"requests.post(url, data='[{\\\"some\\\": \\\"data\\\"}]', files={'some': f})\")\nE   TypeError: 'requests.post(url, data=\\'[{\"some\": \"data\"}]\\', files={\\'some\\': f})' object (type: <class 'str'>) must be callable\n=============================== warnings summary ===============================\nrequests/packages/urllib3/_collections.py:7\n  /testbed/requests/packages/urllib3/_collections.py:7: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import MutableMapping\n\nrequests/sessions.py:398\n  /testbed/requests/sessions.py:398: DeprecationWarning: invalid escape sequence \\*\n    \"\"\"Sends a GET request. Returns :class:`Response` object.\n\nrequests/sessions.py:408\n  /testbed/requests/sessions.py:408: DeprecationWarning: invalid escape sequence \\*\n    \"\"\"Sends a OPTIONS request. Returns :class:`Response` object.\n\nrequests/sessions.py:418\n  /testbed/requests/sessions.py:418: DeprecationWarning: invalid escape sequence \\*\n    \"\"\"Sends a HEAD request. Returns :class:`Response` object.\n\nrequests/sessions.py:428\n  /testbed/requests/sessions.py:428: DeprecationWarning: invalid escape sequence \\*\n    \"\"\"Sends a POST request. Returns :class:`Response` object.\n\nrequests/sessions.py:438\n  /testbed/requests/sessions.py:438: DeprecationWarning: invalid escape sequence \\*\n    \"\"\"Sends a PUT request. Returns :class:`Response` object.\n\nrequests/sessions.py:448\n  /testbed/requests/sessions.py:448: DeprecationWarning: invalid escape sequence \\*\n    \"\"\"Sends a PATCH request. Returns :class:`Response` object.\n\nrequests/sessions.py:458\n  /testbed/requests/sessions.py:458: DeprecationWarning: invalid escape sequence \\*\n    \"\"\"Sends a DELETE request. Returns :class:`Response` object.\n\nrequests/sessions.py:12\n  /testbed/requests/sessions.py:12: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    from collections import Mapping\n\ntest_requests.py::RequestsTestCase::test_BASICAUTH_TUPLE_HTTP_200_OK_GET\n  /testbed/requests/models.py:164: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n    if isinstance(hook, collections.Callable):\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n================= 1 failed, 118 passed, 10 warnings in 26.95s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN test_requests.py` failed. (See above for error)",
          "test_files_run": [
            "test_requests.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "pydata__xarray-6992",
      "repo": "pydata/xarray",
      "valid": true,
      "worker": "http://34.44.234.143:8080",
      "duration": 84.8315269947052,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 946,
          "failed": 12,
          "errors": 0,
          "collected": 969,
          "duration": 41.35,
          "log_tail": "E    +  where Frozen({'x': <xarray.IndexVariable 'x' (x: 4)>\\narray([('a', 1), ('a', 2), ('b', 1), ('b', 2)], dtype=object)}) = <[ValueError('__len__() should return >= 0') raised in repr()] Dataset object at 0x763fa34535a0>.variables\n_ TestDataset.test_reset_index_drop_convert[arg6-False-dropped6-converted6-renamed6] _\n/testbed/xarray/tests/test_dataset.py:3312: in test_reset_index_drop_convert\n    assert name not in reset.variables\nE   AssertionError: assert 'x' not in Frozen({'x': <xarray.IndexVariable 'x' (x: 4)>\\narray([('a', 1), ('a', 2), ('b', 1), ('b', 2)], dtype=object), 'foo': <xarray.IndexVariable 'x' (x: 4)>\\narray(['a', 'a', 'b', 'b'], dtype=object), 'bar': <xarray.IndexVariable 'x' (x: 4)>\\narray([1, 2, 1, 2])})\nE    +  where Frozen({'x': <xarray.IndexVariable 'x' (x: 4)>\\narray([('a', 1), ('a', 2), ('b', 1), ('b', 2)], dtype=object), 'foo': <xarray.IndexVariable 'x' (x: 4)>\\narray(['a', 'a', 'b', 'b'], dtype=object), 'bar': <xarray.IndexVariable 'x' (x: 4)>\\narray([1, 2, 1, 2])}) = <xarray.Dataset>\\nDimensions:  (x: 4)\\nCoordinates:\\n    x        (x) object MultiIndex\\n    foo      (x) object 'a' 'a' 'b' 'b'\\n  * bar      (x) int64 1 2 1 2\\nData variables:\\n    *empty*.variables\n_ TestDataset.test_reset_index_drop_convert[arg7-True-dropped7-converted7-renamed7] _\n/testbed/xarray/tests/test_dataset.py:3312: in test_reset_index_drop_convert\n    assert name not in reset.variables\nE   AssertionError: assert 'bar' not in Frozen({'bar': <xarray.IndexVariable 'x' (x: 4)>\\narray([1, 2, 1, 2])})\nE    +  where Frozen({'bar': <xarray.IndexVariable 'x' (x: 4)>\\narray([1, 2, 1, 2])}) = <[ValueError('__len__() should return >= 0') raised in repr()] Dataset object at 0x763fa34535a0>.variables\n___________________________ test_groupby_drops_nans ____________________________\n/testbed/xarray/tests/test_groupby.py:545: in test_groupby_drops_nans\n    assert_identical(actual2, expected2)\nE   AssertionError: Left and right Dataset objects are not identical\nE   \nE   Differing coordinates:\nE   L * id        (id) float64 1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0 10.0\nE   R * id        (id) float64 1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0 10.0\nE   Coordinates only on the right object:\nE       lon       (id) int64 1 2 0 1 2 0 1 2 1\nE       lat       (id) int64 0 0 1 1 1 2 2 2 3\nE   Differing data variables:\nE   L   variable  (time, id) float64 5.0 10.0 15.0 20.0 25.0 ... 34.0 39.0 44.0 54.0\nE   R   variable  (time, id) float64 5.0 10.0 15.0 20.0 25.0 ... 34.0 39.0 44.0 54.0\n=============================== warnings summary ===============================\nxarray/tests/test_dataarray.py::TestDataArray::test_to_and_from_cdms2_sgrid\nxarray/tests/test_dataarray.py::TestDataArray::test_to_and_from_cdms2_sgrid\nxarray/tests/test_dataarray.py::TestDataArray::test_to_and_from_cdms2_sgrid\nxarray/tests/test_dataarray.py::TestDataArray::test_to_and_from_cdms2_sgrid\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/numpy/ma/core.py:7939: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n    if not np.all(xinf == filled(np.isinf(y), False)):\n\nxarray/tests/test_dataset.py::TestDataset::test_rename_same_name\n  /testbed/xarray/tests/test_dataset.py:2842: UserWarning: rename 'dim2' to 'dim2' does not create an index anymore. Try using swap_dims instead or use set_index after rename to create an indexed coordinate.\n    renamed = data.rename(newnames)\n\nxarray/tests/test_dataset.py::TestDataset::test_rename_multiindex\n  /testbed/xarray/tests/test_dataset.py:2921: UserWarning: rename 'x' to 'a' does not create an index anymore. Try using swap_dims instead or use set_index after rename to create an indexed coordinate.\n    original.rename({\"x\": \"a\"})\n\nxarray/tests/test_dataset.py::TestDataset::test_rename_multiindex\n  /testbed/xarray/tests/test_dataset.py:2923: UserWarning: rename 'a' to 'x' does not create an index anymore. Try using swap_dims instead or use set_index after rename to create an indexed coordinate.\n    original.rename({\"a\": \"x\"})\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n= 12 failed, 946 passed, 2 skipped, 7 xfailed, 2 xpassed, 7 warnings in 33.56s =\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN xarray/tests/test_dataarray.py xarray/tests/test_dataset.py xarray/tests/test_groupby.py` failed. (See above for error)",
          "test_files_run": [
            "xarray/tests/test_dataarray.py",
            "xarray/tests/test_dataset.py",
            "xarray/tests/test_groupby.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 958,
          "failed": 0,
          "errors": 0,
          "collected": 969,
          "duration": 30.1,
          "log_tail": "xarray/tests/test_groupby.py::TestDataArrayResample::test_da_resample_func_args PASSED [ 97%]\nxarray/tests/test_groupby.py::TestDataArrayResample::test_resample_first PASSED [ 97%]\nxarray/tests/test_groupby.py::TestDataArrayResample::test_resample_bad_resample_dim PASSED [ 97%]\nxarray/tests/test_groupby.py::TestDataArrayResample::test_resample_drop_nondim_coords PASSED [ 97%]\nxarray/tests/test_groupby.py::TestDataArrayResample::test_resample_keep_attrs PASSED [ 97%]\nxarray/tests/test_groupby.py::TestDataArrayResample::test_resample_skipna PASSED [ 98%]\nxarray/tests/test_groupby.py::TestDataArrayResample::test_upsample PASSED [ 98%]\nxarray/tests/test_groupby.py::TestDataArrayResample::test_upsample_nd PASSED [ 98%]\nxarray/tests/test_groupby.py::TestDataArrayResample::test_upsample_tolerance PASSED [ 98%]\nxarray/tests/test_groupby.py::TestDataArrayResample::test_upsample_interpolate PASSED [ 98%]\nxarray/tests/test_groupby.py::TestDataArrayResample::test_upsample_interpolate_bug_2197 PASSED [ 98%]\nxarray/tests/test_groupby.py::TestDataArrayResample::test_upsample_interpolate_regression_1605 PASSED [ 98%]\nxarray/tests/test_groupby.py::TestDataArrayResample::test_upsample_interpolate_dask[True] PASSED [ 98%]\nxarray/tests/test_groupby.py::TestDataArrayResample::test_upsample_interpolate_dask[False] PASSED [ 98%]\nxarray/tests/test_groupby.py::TestDatasetResample::test_resample_and_first PASSED [ 98%]\nxarray/tests/test_groupby.py::TestDatasetResample::test_resample_min_count PASSED [ 99%]\nxarray/tests/test_groupby.py::TestDatasetResample::test_resample_by_mean_with_keep_attrs PASSED [ 99%]\nxarray/tests/test_groupby.py::TestDatasetResample::test_resample_loffset PASSED [ 99%]\nxarray/tests/test_groupby.py::TestDatasetResample::test_resample_by_mean_discarding_attrs PASSED [ 99%]\nxarray/tests/test_groupby.py::TestDatasetResample::test_resample_by_last_discarding_attrs PASSED [ 99%]\nxarray/tests/test_groupby.py::TestDatasetResample::test_resample_drop_nondim_coords PASSED [ 99%]\nxarray/tests/test_groupby.py::TestDatasetResample::test_resample_old_api PASSED [ 99%]\nxarray/tests/test_groupby.py::TestDatasetResample::test_resample_ds_da_are_the_same PASSED [ 99%]\nxarray/tests/test_groupby.py::TestDatasetResample::test_ds_resample_apply_func_args PASSED [ 99%]\nxarray/tests/test_groupby.py::test_groupby_cumsum PASSED                 [100%]\n\n=============================== warnings summary ===============================\nxarray/tests/test_dataarray.py::TestDataArray::test_to_and_from_cdms2_sgrid\nxarray/tests/test_dataarray.py::TestDataArray::test_to_and_from_cdms2_sgrid\nxarray/tests/test_dataarray.py::TestDataArray::test_to_and_from_cdms2_sgrid\nxarray/tests/test_dataarray.py::TestDataArray::test_to_and_from_cdms2_sgrid\n  /opt/miniconda3/envs/testbed/lib/python3.10/site-packages/numpy/ma/core.py:7939: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n    if not np.all(xinf == filled(np.isinf(y), False)):\n\nxarray/tests/test_dataset.py::TestDataset::test_rename_same_name\n  /testbed/xarray/tests/test_dataset.py:2842: UserWarning: rename 'dim2' to 'dim2' does not create an index anymore. Try using swap_dims instead or use set_index after rename to create an indexed coordinate.\n    renamed = data.rename(newnames)\n\nxarray/tests/test_dataset.py::TestDataset::test_rename_multiindex\n  /testbed/xarray/tests/test_dataset.py:2921: UserWarning: rename 'x' to 'a' does not create an index anymore. Try using swap_dims instead or use set_index after rename to create an indexed coordinate.\n    original.rename({\"x\": \"a\"})\n\nxarray/tests/test_dataset.py::TestDataset::test_rename_multiindex\n  /testbed/xarray/tests/test_dataset.py:2923: UserWarning: rename 'a' to 'x' does not create an index anymore. Try using swap_dims instead or use set_index after rename to create an indexed coordinate.\n    original.rename({\"a\": \"x\"})\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n====== 958 passed, 2 skipped, 7 xfailed, 2 xpassed, 7 warnings in 24.54s =======\n\n",
          "test_files_run": [
            "xarray/tests/test_dataarray.py",
            "xarray/tests/test_dataset.py",
            "xarray/tests/test_groupby.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "psf__requests-5414",
      "repo": "psf/requests",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "duration": 9.087538957595825,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 130,
          "failed": 1,
          "errors": 158,
          "collected": 290,
          "duration": 3.99,
          "log_tail": "  @pytest.fixture\n  def httpbin(httpbin):\nE       recursive dependency involving fixture 'httpbin' detected\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, httpbin, httpbin_secure, monkeypatch, nosan_server, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/testbed/tests/conftest.py:28\n=================================== FAILURES ===================================\n________ TestRequests.test_invalid_url[InvalidURL-http://.example.com] _________\ntests/test_requests.py:89: in test_invalid_url\n    requests.get(url)\nrequests/api.py:75: in get\n    return request('get', url, params=params, **kwargs)\nrequests/api.py:61: in request\n    return session.request(method=method, url=url, **kwargs)\nrequests/sessions.py:529: in request\n    resp = self.send(prep, **send_kwargs)\nrequests/sessions.py:645: in send\n    r = adapter.send(request, **kwargs)\nrequests/adapters.py:440: in send\n    resp = conn.urlopen(\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/urllib3/connectionpool.py:716: in urlopen\n    httplib_response = self._make_request(\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/urllib3/connectionpool.py:416: in _make_request\n    conn.request(method, url, **httplib_request_kw)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/urllib3/connection.py:244: in request\n    super(HTTPConnection, self).request(method, url, body=body, headers=headers)\n/opt/miniconda3/envs/testbed/lib/python3.9/http/client.py:1285: in request\n    self._send_request(method, url, body, headers, encode_chunked)\n/opt/miniconda3/envs/testbed/lib/python3.9/http/client.py:1331: in _send_request\n    self.endheaders(body, encode_chunked=encode_chunked)\n/opt/miniconda3/envs/testbed/lib/python3.9/http/client.py:1280: in endheaders\n    self._send_output(message_body, encode_chunked=encode_chunked)\n/opt/miniconda3/envs/testbed/lib/python3.9/http/client.py:1040: in _send_output\n    self.send(msg)\n/opt/miniconda3/envs/testbed/lib/python3.9/http/client.py:980: in send\n    self.connect()\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/urllib3/connection.py:205: in connect\n    conn = self._new_conn()\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/urllib3/connection.py:174: in _new_conn\n    conn = connection.create_connection(\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/urllib3/util/connection.py:68: in create_connection\n    return six.raise_from(\n<string>:3: in raise_from\n    ???\nE   urllib3.exceptions.LocationParseError: Failed to parse: '.example.com', label empty or too long\n============= 1 failed, 130 passed, 1 xfailed, 158 errors in 1.12s =============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_requests.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_requests.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 131,
          "failed": 0,
          "errors": 158,
          "collected": 290,
          "duration": 3.76,
          "log_tail": "  @pytest.fixture\n  def httpbin(httpbin):\nE       recursive dependency involving fixture 'httpbin' detected\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, httpbin, httpbin_secure, monkeypatch, nosan_server, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/testbed/tests/conftest.py:28\n_ ERROR at setup of TestPreparingURLs.test_redirecting_to_bad_url[http://localhost:-1-InvalidURL] _\nfile /testbed/tests/test_requests.py, line 2501\n      @pytest.mark.parametrize(\n          'url, exception',\n          (\n              ('http://localhost:-1', InvalidURL),\n          )\n      )\n      def test_redirecting_to_bad_url(self, httpbin, url, exception):\nfile /testbed/tests/conftest.py, line 28\n  @pytest.fixture\n  def httpbin(httpbin):\nE       recursive dependency involving fixture 'httpbin' detected\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, httpbin, httpbin_secure, monkeypatch, nosan_server, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/testbed/tests/conftest.py:28\n____________ ERROR at setup of TestPreparingURLs.test_post_json_nan ____________\nfile /testbed/tests/test_requests.py, line 2581\n      def test_post_json_nan(self, httpbin):\nfile /testbed/tests/conftest.py, line 28\n  @pytest.fixture\n  def httpbin(httpbin):\nE       recursive dependency involving fixture 'httpbin' detected\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, httpbin, httpbin_secure, monkeypatch, nosan_server, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/testbed/tests/conftest.py:28\n______ ERROR at setup of TestPreparingURLs.test_json_decode_compatibility ______\nfile /testbed/tests/test_requests.py, line 2586\n      def test_json_decode_compatibility(self, httpbin):\nfile /testbed/tests/conftest.py, line 28\n  @pytest.fixture\n  def httpbin(httpbin):\nE       recursive dependency involving fixture 'httpbin' detected\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, httpbin, httpbin_secure, monkeypatch, nosan_server, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/testbed/tests/conftest.py:28\n================== 131 passed, 1 xfailed, 158 errors in 0.99s ==================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_requests.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_requests.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "psf__requests-6028",
      "repo": "psf/requests",
      "valid": false,
      "worker": "http://34.44.241.183:8080",
      "duration": 6.85760498046875,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 193,
          "failed": 2,
          "errors": 8,
          "collected": 214,
          "duration": 3.54,
          "log_tail": "              ('http://user:pass@172.16.1.1:5000', '172.16.1.1'),\n              ('http://hostname/', 'hostname'),\n              ('http://hostname:5000/', 'hostname'),\n              ('http://user:pass@hostname', 'hostname'),\n              ('http://user:pass@hostname:5000', 'hostname'),\n      ))\n  def test_should_bypass_proxies_pass_only_hostname(url, expected, mocker):\nE       fixture 'mocker' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, httpbin, httpbin_secure, monkeypatch, nosan_server, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/testbed/tests/test_utils.py:663\n_ ERROR at setup of test_should_bypass_proxies_pass_only_hostname[http://user:pass@hostname:5000-hostname] _\nfile /testbed/tests/test_utils.py, line 663\n  @pytest.mark.parametrize(\n      'url, expected', (\n              ('http://172.16.1.1/', '172.16.1.1'),\n              ('http://172.16.1.1:5000/', '172.16.1.1'),\n              ('http://user:pass@172.16.1.1', '172.16.1.1'),\n              ('http://user:pass@172.16.1.1:5000', '172.16.1.1'),\n              ('http://hostname/', 'hostname'),\n              ('http://hostname:5000/', 'hostname'),\n              ('http://user:pass@hostname', 'hostname'),\n              ('http://user:pass@hostname:5000', 'hostname'),\n      ))\n  def test_should_bypass_proxies_pass_only_hostname(url, expected, mocker):\nE       fixture 'mocker' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, httpbin, httpbin_secure, monkeypatch, nosan_server, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/testbed/tests/test_utils.py:663\n=================================== FAILURES ===================================\n_ test_prepend_scheme_if_needed[http://user:pass@example.com/path?query-http://user:pass@example.com/path?query] _\ntests/test_utils.py:615: in test_prepend_scheme_if_needed\n    assert prepend_scheme_if_needed(value, 'http') == expected\nE   AssertionError: assert 'http://examp...om/path?query' == 'http://user:...om/path?query'\nE     - http://user:pass@example.com/path?query\nE     ?        ----------\nE     + http://example.com/path?query\n_ test_prepend_scheme_if_needed[http://user@example.com/path?query-http://user@example.com/path?query] _\ntests/test_utils.py:615: in test_prepend_scheme_if_needed\n    assert prepend_scheme_if_needed(value, 'http') == expected\nE   AssertionError: assert 'http://examp...om/path?query' == 'http://user@...om/path?query'\nE     - http://user@example.com/path?query\nE     ?        -----\nE     + http://example.com/path?query\n============= 2 failed, 193 passed, 11 skipped, 8 errors in 0.30s ==============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_utils.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_utils.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 195,
          "failed": 0,
          "errors": 8,
          "collected": 214,
          "duration": 2.52,
          "log_tail": "              ('http://user:pass@hostname:5000', 'hostname'),\n      ))\n  def test_should_bypass_proxies_pass_only_hostname(url, expected, mocker):\nE       fixture 'mocker' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, httpbin, httpbin_secure, monkeypatch, nosan_server, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/testbed/tests/test_utils.py:663\n_ ERROR at setup of test_should_bypass_proxies_pass_only_hostname[http://user:pass@hostname-hostname] _\nfile /testbed/tests/test_utils.py, line 663\n  @pytest.mark.parametrize(\n      'url, expected', (\n              ('http://172.16.1.1/', '172.16.1.1'),\n              ('http://172.16.1.1:5000/', '172.16.1.1'),\n              ('http://user:pass@172.16.1.1', '172.16.1.1'),\n              ('http://user:pass@172.16.1.1:5000', '172.16.1.1'),\n              ('http://hostname/', 'hostname'),\n              ('http://hostname:5000/', 'hostname'),\n              ('http://user:pass@hostname', 'hostname'),\n              ('http://user:pass@hostname:5000', 'hostname'),\n      ))\n  def test_should_bypass_proxies_pass_only_hostname(url, expected, mocker):\nE       fixture 'mocker' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, httpbin, httpbin_secure, monkeypatch, nosan_server, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/testbed/tests/test_utils.py:663\n_ ERROR at setup of test_should_bypass_proxies_pass_only_hostname[http://user:pass@hostname:5000-hostname] _\nfile /testbed/tests/test_utils.py, line 663\n  @pytest.mark.parametrize(\n      'url, expected', (\n              ('http://172.16.1.1/', '172.16.1.1'),\n              ('http://172.16.1.1:5000/', '172.16.1.1'),\n              ('http://user:pass@172.16.1.1', '172.16.1.1'),\n              ('http://user:pass@172.16.1.1:5000', '172.16.1.1'),\n              ('http://hostname/', 'hostname'),\n              ('http://hostname:5000/', 'hostname'),\n              ('http://user:pass@hostname', 'hostname'),\n              ('http://user:pass@hostname:5000', 'hostname'),\n      ))\n  def test_should_bypass_proxies_pass_only_hostname(url, expected, mocker):\nE       fixture 'mocker' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, httpbin, httpbin_secure, monkeypatch, nosan_server, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/testbed/tests/test_utils.py:663\n================== 195 passed, 11 skipped, 8 errors in 0.27s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_utils.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_utils.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "psf__requests-1724",
      "repo": "psf/requests",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10cfac6b0>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 1
    },
    {
      "instance_id": "pydata__xarray-3993",
      "repo": "pydata/xarray",
      "valid": false,
      "worker": "http://35.239.238.137:8080",
      "error": "HTTPConnectionPool(host='35.239.238.137', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 1
    },
    {
      "instance_id": "pytest-dev__pytest-5631",
      "repo": "pytest-dev/pytest",
      "valid": false,
      "worker": "http://34.41.233.120:8080",
      "duration": 5.0504021644592285,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 2.14,
          "log_tail": "\nERROR: usage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/tox.ini\n  rootdir: /testbed\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/python/integration.py` failed. (See above for error)",
          "test_files_run": [
            "testing/python/integration.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 2.13,
          "log_tail": "\nERROR: usage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/tox.ini\n  rootdir: /testbed\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/python/integration.py` failed. (See above for error)",
          "test_files_run": [
            "testing/python/integration.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "pytest-dev__pytest-5787",
      "repo": "pytest-dev/pytest",
      "valid": false,
      "worker": "http://34.44.241.183:8080",
      "duration": 10.905188083648682,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 7.7,
          "log_tail": "\nERROR: usage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/tox.ini\n  rootdir: /testbed\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/code/test_code.py testing/code/test_excinfo.py testing/conftest.py testing/test_reports.py` failed. (See above for error)",
          "test_files_run": [
            "testing/code/test_code.py",
            "testing/code/test_excinfo.py",
            "testing/conftest.py",
            "testing/test_reports.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 2.17,
          "log_tail": "\nERROR: usage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/tox.ini\n  rootdir: /testbed\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/code/test_code.py testing/code/test_excinfo.py testing/conftest.py testing/test_reports.py` failed. (See above for error)",
          "test_files_run": [
            "testing/code/test_code.py",
            "testing/code/test_excinfo.py",
            "testing/conftest.py",
            "testing/test_reports.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "pytest-dev__pytest-5809",
      "repo": "pytest-dev/pytest",
      "valid": false,
      "worker": "http://34.41.233.120:8080",
      "duration": 5.229780912399292,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 2.18,
          "log_tail": "\nERROR: usage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/tox.ini\n  rootdir: /testbed\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/test_pastebin.py` failed. (See above for error)",
          "test_files_run": [
            "testing/test_pastebin.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 2.25,
          "log_tail": "\nERROR: usage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/tox.ini\n  rootdir: /testbed\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/test_pastebin.py` failed. (See above for error)",
          "test_files_run": [
            "testing/test_pastebin.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "pytest-dev__pytest-5840",
      "repo": "pytest-dev/pytest",
      "valid": false,
      "worker": "http://34.41.233.120:8080",
      "duration": 5.599032163619995,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 2.66,
          "log_tail": "\nERROR: usage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/tox.ini\n  rootdir: /testbed\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/test_conftest.py` failed. (See above for error)",
          "test_files_run": [
            "testing/test_conftest.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 2.15,
          "log_tail": "\nERROR: usage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/tox.ini\n  rootdir: /testbed\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/test_conftest.py` failed. (See above for error)",
          "test_files_run": [
            "testing/test_conftest.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "pydata__xarray-6721",
      "repo": "pydata/xarray",
      "valid": true,
      "worker": "http://34.59.30.169:8080",
      "duration": 135.970205783844,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 1405,
          "failed": 1,
          "errors": 0,
          "collected": 1445,
          "duration": 71.34,
          "log_tail": "xarray/tests/test_dataset.py::TestDropDuplicates::test_drop_duplicates_1d[first] PASSED [ 99%]\nxarray/tests/test_dataset.py::TestDropDuplicates::test_drop_duplicates_1d[last] PASSED [ 99%]\nxarray/tests/test_dataset.py::TestDropDuplicates::test_drop_duplicates_1d[False] PASSED [ 99%]\nxarray/tests/test_dataset.py::TestNumpyCoercion::test_from_numpy PASSED  [ 99%]\nxarray/tests/test_dataset.py::TestNumpyCoercion::test_from_dask PASSED   [ 99%]\nxarray/tests/test_dataset.py::TestNumpyCoercion::test_from_pint PASSED   [ 99%]\nxarray/tests/test_dataset.py::TestNumpyCoercion::test_from_sparse PASSED [ 99%]\nxarray/tests/test_dataset.py::TestNumpyCoercion::test_from_cupy SKIPPED  [ 99%]\nxarray/tests/test_dataset.py::TestNumpyCoercion::test_from_pint_wrapping_dask PASSED [ 99%]\nxarray/tests/test_dataset.py::test_string_keys_typing PASSED             [100%]\n\n=================================== FAILURES ===================================\n__________________ TestDataset.test_chunks_does_not_load_data __________________\n/testbed/xarray/tests/test_dataset.py:1000: in test_chunks_does_not_load_data\n    assert ds.chunks == {}\n/testbed/xarray/core/dataset.py:2138: in chunks\n    return get_chunksizes(self.variables.values())\n/testbed/xarray/core/common.py:2026: in get_chunksizes\n    if hasattr(v.data, \"chunks\"):\n/testbed/xarray/core/variable.py:342: in data\n    return self.values\n/testbed/xarray/core/variable.py:515: in values\n    return _as_array_or_item(self._data)\n/testbed/xarray/core/variable.py:255: in _as_array_or_item\n    data = np.asarray(data)\n/testbed/xarray/core/indexing.py:646: in __array__\n    self._ensure_cached()\n/testbed/xarray/core/indexing.py:643: in _ensure_cached\n    self.array = NumpyIndexingAdapter(np.asarray(self.array))\n/testbed/xarray/core/indexing.py:616: in __array__\n    return np.asarray(self.array, dtype=dtype)\n/testbed/xarray/core/indexing.py:517: in __array__\n    return np.asarray(array[self.key], dtype=None)\n/testbed/xarray/tests/__init__.py:142: in __getitem__\n    raise UnexpectedDataAccess(\"Tried accessing data\")\nE   xarray.tests.UnexpectedDataAccess: Tried accessing data\n=============================== warnings summary ===============================\nxarray/tests/test_dataset.py::TestDataset::test_constructor_pandas_single\n  /testbed/xarray/core/merge.py:490: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n    obj = dict(obj.iteritems())\n\nxarray/tests/test_dataset.py: 12 warnings\n  /testbed/xarray/core/common.py:1371: PendingDeprecationWarning: dropping variables using `drop` will be deprecated; using drop_vars is encouraged.\n    cond_wdim = cond.drop(var for var in cond if dim not in cond[var].dims)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n= 1 failed, 1405 passed, 33 skipped, 1 xfailed, 5 xpassed, 13 warnings in 61.99s (0:01:01) =\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN xarray/tests/test_dataset.py` failed. (See above for error)",
          "test_files_run": [
            "xarray/tests/test_dataset.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 1406,
          "failed": 0,
          "errors": 0,
          "collected": 1445,
          "duration": 63.63,
          "log_tail": "xarray/tests/test_dataset.py::test_raise_no_warning_dask_rolling_assert_close[numpy-mean-2] XPASS [ 97%]\nxarray/tests/test_dataset.py::test_raise_no_warning_dask_rolling_assert_close[numpy-max-2] XPASS [ 97%]\nxarray/tests/test_dataset.py::test_raise_no_warning_dask_rolling_assert_close[dask-mean-2] XPASS [ 97%]\nxarray/tests/test_dataset.py::test_raise_no_warning_dask_rolling_assert_close[dask-max-2] XPASS [ 97%]\nxarray/tests/test_dataset.py::test_differentiate[1-True] PASSED          [ 97%]\nxarray/tests/test_dataset.py::test_differentiate[1-False] PASSED         [ 97%]\nxarray/tests/test_dataset.py::test_differentiate[2-True] PASSED          [ 97%]\nxarray/tests/test_dataset.py::test_differentiate[2-False] PASSED         [ 98%]\nxarray/tests/test_dataset.py::test_differentiate_datetime[True] PASSED   [ 98%]\nxarray/tests/test_dataset.py::test_differentiate_datetime[False] PASSED  [ 98%]\nxarray/tests/test_dataset.py::test_differentiate_cftime[True] PASSED     [ 98%]\nxarray/tests/test_dataset.py::test_differentiate_cftime[False] PASSED    [ 98%]\nxarray/tests/test_dataset.py::test_integrate[True] PASSED                [ 98%]\nxarray/tests/test_dataset.py::test_integrate[False] PASSED               [ 98%]\nxarray/tests/test_dataset.py::test_cumulative_integrate[True] PASSED     [ 98%]\nxarray/tests/test_dataset.py::test_cumulative_integrate[False] PASSED    [ 98%]\nxarray/tests/test_dataset.py::test_trapz_datetime[np-True] PASSED        [ 98%]\nxarray/tests/test_dataset.py::test_trapz_datetime[np-False] PASSED       [ 98%]\nxarray/tests/test_dataset.py::test_trapz_datetime[cftime-True] PASSED    [ 98%]\nxarray/tests/test_dataset.py::test_trapz_datetime[cftime-False] PASSED   [ 98%]\nxarray/tests/test_dataset.py::test_no_dict PASSED                        [ 98%]\nxarray/tests/test_dataset.py::test_subclass_slots PASSED                 [ 99%]\nxarray/tests/test_dataset.py::test_weakref PASSED                        [ 99%]\nxarray/tests/test_dataset.py::test_deepcopy_obj_array PASSED             [ 99%]\nxarray/tests/test_dataset.py::test_clip[1-numpy] PASSED                  [ 99%]\nxarray/tests/test_dataset.py::test_clip[1-dask] PASSED                   [ 99%]\nxarray/tests/test_dataset.py::TestDropDuplicates::test_drop_duplicates_1d[first] PASSED [ 99%]\nxarray/tests/test_dataset.py::TestDropDuplicates::test_drop_duplicates_1d[last] PASSED [ 99%]\nxarray/tests/test_dataset.py::TestDropDuplicates::test_drop_duplicates_1d[False] PASSED [ 99%]\nxarray/tests/test_dataset.py::TestNumpyCoercion::test_from_numpy PASSED  [ 99%]\nxarray/tests/test_dataset.py::TestNumpyCoercion::test_from_dask PASSED   [ 99%]\nxarray/tests/test_dataset.py::TestNumpyCoercion::test_from_pint PASSED   [ 99%]\nxarray/tests/test_dataset.py::TestNumpyCoercion::test_from_sparse PASSED [ 99%]\nxarray/tests/test_dataset.py::TestNumpyCoercion::test_from_cupy SKIPPED  [ 99%]\nxarray/tests/test_dataset.py::TestNumpyCoercion::test_from_pint_wrapping_dask PASSED [ 99%]\nxarray/tests/test_dataset.py::test_string_keys_typing PASSED             [100%]\n\n=============================== warnings summary ===============================\nxarray/tests/test_dataset.py::TestDataset::test_constructor_pandas_single\n  /testbed/xarray/core/merge.py:490: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n    obj = dict(obj.iteritems())\n\nxarray/tests/test_dataset.py: 12 warnings\n  /testbed/xarray/core/common.py:1371: PendingDeprecationWarning: dropping variables using `drop` will be deprecated; using drop_vars is encouraged.\n    cond_wdim = cond.drop(var for var in cond if dim not in cond[var].dims)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n===== 1406 passed, 33 skipped, 1 xfailed, 5 xpassed, 13 warnings in 57.43s =====\n\n",
          "test_files_run": [
            "xarray/tests/test_dataset.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "pytest-dev__pytest-6197",
      "repo": "pytest-dev/pytest",
      "valid": false,
      "worker": "http://34.123.9.23:8080",
      "duration": 5.639869928359985,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 2.7,
          "log_tail": "\nERROR: usage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/tox.ini\n  rootdir: /testbed\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/test_collection.py testing/test_skipping.py` failed. (See above for error)",
          "test_files_run": [
            "testing/test_collection.py",
            "testing/test_skipping.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 2.17,
          "log_tail": "\nERROR: usage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/tox.ini\n  rootdir: /testbed\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/test_collection.py testing/test_skipping.py` failed. (See above for error)",
          "test_files_run": [
            "testing/test_collection.py",
            "testing/test_skipping.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "pydata__xarray-6744",
      "repo": "pydata/xarray",
      "valid": true,
      "worker": "http://34.44.241.183:8080",
      "duration": 133.48189997673035,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 1812,
          "failed": 6,
          "errors": 0,
          "collected": 1854,
          "duration": 66.71,
          "log_tail": "    np.testing.assert_allclose(actual.values, expected.values)\nE   AssertionError: \nE   Not equal to tolerance rtol=1e-07, atol=0\nE   \nE   x and y nan location mismatch:\nE    x: array([[0.517327, 0.705974, 0.469443, 0.663984],\nE          [0.430073, 0.532862, 0.533503, 0.475727],\nE          [0.47008 , 0.515714, 0.609969, 0.262601]])\nE    y: array([[nan, nan, nan, nan],\nE          [nan, nan, nan, nan],\nE          [nan, nan, nan, nan]])\n____________ TestDataArrayRolling.test_rolling_iter[dask-3-True-1] _____________\n/testbed/xarray/tests/test_rolling.py:45: in test_rolling_iter\n    np.testing.assert_allclose(actual.values, expected.values)\nE   AssertionError: \nE   Not equal to tolerance rtol=1e-07, atol=0\nE   \nE   x and y nan location mismatch:\nE    x: array([[0.645377, 0.581508, 0.610692, 0.655184],\nE          [0.424782, 0.637004, 0.377074, 0.314847],\nE          [0.425113, 0.372744, 0.67305 , 0.103367]])\nE    y: array([[nan, nan, nan, nan],\nE          [nan, nan, nan, nan],\nE          [nan, nan, nan, nan]])\n____________ TestDataArrayRolling.test_rolling_iter[dask-3-True-2] _____________\n/testbed/xarray/tests/test_rolling.py:45: in test_rolling_iter\n    np.testing.assert_allclose(actual.values, expected.values)\nE   AssertionError: \nE   Not equal to tolerance rtol=1e-07, atol=0\nE   \nE   x and y nan location mismatch:\nE    x: array(4.)\nE    y: array(nan)\n____________ TestDataArrayRolling.test_rolling_iter[dask-7-True-1] _____________\n/testbed/xarray/tests/test_rolling.py:45: in test_rolling_iter\n    np.testing.assert_allclose(actual.values, expected.values)\nE   AssertionError: \nE   Not equal to tolerance rtol=1e-07, atol=0\nE   \nE   x and y nan location mismatch:\nE    x: array([[0.517327, 0.705974, 0.469443, 0.663984],\nE          [0.430073, 0.532862, 0.533503, 0.475727],\nE          [0.47008 , 0.515714, 0.609969, 0.262601]])\nE    y: array([[nan, nan, nan, nan],\nE          [nan, nan, nan, nan],\nE          [nan, nan, nan, nan]])\n======= 6 failed, 1812 passed, 32 skipped, 4 xpassed in 61.43s (0:01:01) =======\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN xarray/tests/test_rolling.py` failed. (See above for error)",
          "test_files_run": [
            "xarray/tests/test_rolling.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 1818,
          "failed": 0,
          "errors": 0,
          "collected": 1854,
          "duration": 65.9,
          "log_tail": "xarray/tests/test_rolling.py::TestDatasetRolling::test_ndrolling_reduce[numpy-True-max-None-True-2] PASSED [ 97%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_ndrolling_reduce[numpy-True-max-None-False-2] PASSED [ 97%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_ndrolling_reduce[numpy-True-max-1-True-2] PASSED [ 97%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_ndrolling_reduce[numpy-True-max-1-False-2] PASSED [ 97%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_ndrolling_reduce[numpy-False-sum-None-True-2] PASSED [ 97%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_ndrolling_reduce[numpy-False-sum-None-False-2] PASSED [ 97%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_ndrolling_reduce[numpy-False-sum-1-True-2] PASSED [ 97%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_ndrolling_reduce[numpy-False-sum-1-False-2] PASSED [ 97%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_ndrolling_reduce[numpy-False-max-None-True-2] PASSED [ 98%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_ndrolling_reduce[numpy-False-max-None-False-2] PASSED [ 98%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_ndrolling_reduce[numpy-False-max-1-True-2] PASSED [ 98%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_ndrolling_reduce[numpy-False-max-1-False-2] PASSED [ 98%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_ndrolling_reduce[dask-True-sum-None-True-2] PASSED [ 98%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_ndrolling_reduce[dask-True-sum-None-False-2] PASSED [ 98%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_ndrolling_reduce[dask-True-sum-1-True-2] PASSED [ 98%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_ndrolling_reduce[dask-True-sum-1-False-2] PASSED [ 98%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_ndrolling_reduce[dask-True-max-None-True-2] PASSED [ 98%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_ndrolling_reduce[dask-True-max-None-False-2] PASSED [ 98%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_ndrolling_reduce[dask-True-max-1-True-2] PASSED [ 98%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_ndrolling_reduce[dask-True-max-1-False-2] PASSED [ 98%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_ndrolling_reduce[dask-False-sum-None-True-2] PASSED [ 98%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_ndrolling_reduce[dask-False-sum-None-False-2] PASSED [ 98%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_ndrolling_reduce[dask-False-sum-1-True-2] PASSED [ 98%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_ndrolling_reduce[dask-False-sum-1-False-2] PASSED [ 98%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_ndrolling_reduce[dask-False-max-None-True-2] PASSED [ 98%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_ndrolling_reduce[dask-False-max-None-False-2] PASSED [ 98%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_ndrolling_reduce[dask-False-max-1-True-2] PASSED [ 98%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_ndrolling_reduce[dask-False-max-1-False-2] PASSED [ 99%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_ndrolling_construct[True-nan-True] PASSED [ 99%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_ndrolling_construct[True-nan-False] PASSED [ 99%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_ndrolling_construct[True-nan-center2] PASSED [ 99%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_ndrolling_construct[True-0.0-True] PASSED [ 99%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_ndrolling_construct[True-0.0-False] PASSED [ 99%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_ndrolling_construct[True-0.0-center2] PASSED [ 99%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_ndrolling_construct[False-nan-True] PASSED [ 99%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_ndrolling_construct[False-nan-False] PASSED [ 99%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_ndrolling_construct[False-nan-center2] PASSED [ 99%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_ndrolling_construct[False-0.0-True] PASSED [ 99%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_ndrolling_construct[False-0.0-False] PASSED [ 99%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_ndrolling_construct[False-0.0-center2] PASSED [ 99%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_raise_no_warning_dask_rolling_assert_close[numpy-mean-2] XPASS [ 99%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_raise_no_warning_dask_rolling_assert_close[numpy-max-2] XPASS [ 99%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_raise_no_warning_dask_rolling_assert_close[dask-mean-2] XPASS [ 99%]\nxarray/tests/test_rolling.py::TestDatasetRolling::test_raise_no_warning_dask_rolling_assert_close[dask-max-2] XPASS [ 99%]\nxarray/tests/test_rolling.py::TestDatasetRollingExp::test_rolling_exp[1-numpy] PASSED [ 99%]\nxarray/tests/test_rolling.py::TestDatasetRollingExp::test_rolling_exp_keep_attrs[1-numpy] PASSED [100%]\n\n============ 1818 passed, 32 skipped, 4 xpassed in 60.80s (0:01:00) ============\n\n",
          "test_files_run": [
            "xarray/tests/test_rolling.py"
          ]
        }
      },
      "error": null
    },
    {
      "instance_id": "pytest-dev__pytest-6202",
      "repo": "pytest-dev/pytest",
      "valid": false,
      "worker": "http://35.239.238.137:8080",
      "duration": 9.423105001449585,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 6.44,
          "log_tail": "\nERROR: usage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/tox.ini\n  rootdir: /testbed\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/test_collection.py` failed. (See above for error)",
          "test_files_run": [
            "testing/test_collection.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 2.21,
          "log_tail": "\nERROR: usage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/tox.ini\n  rootdir: /testbed\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/test_collection.py` failed. (See above for error)",
          "test_files_run": [
            "testing/test_collection.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "pytest-dev__pytest-7205",
      "repo": "pytest-dev/pytest",
      "valid": false,
      "worker": "http://34.59.30.169:8080",
      "duration": 10.311812162399292,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 7.22,
          "log_tail": "\nERROR: usage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/tox.ini\n  rootdir: /testbed\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/test_setuponly.py` failed. (See above for error)",
          "test_files_run": [
            "testing/test_setuponly.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 2.27,
          "log_tail": "\nERROR: usage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/tox.ini\n  rootdir: /testbed\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/test_setuponly.py` failed. (See above for error)",
          "test_files_run": [
            "testing/test_setuponly.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "pytest-dev__pytest-7324",
      "repo": "pytest-dev/pytest",
      "valid": false,
      "worker": "http://34.123.9.23:8080",
      "duration": 5.850636720657349,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 2.87,
          "log_tail": "\nWARNING: Unknown config ini key: rsyncdirs\nERROR: usage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/tox.ini\n  rootdir: /testbed\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/test_mark_expression.py` failed. (See above for error)",
          "test_files_run": [
            "testing/test_mark_expression.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 2.19,
          "log_tail": "\nWARNING: Unknown config ini key: rsyncdirs\nERROR: usage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --no-header\n  inifile: /testbed/tox.ini\n  rootdir: /testbed\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/test_mark_expression.py` failed. (See above for error)",
          "test_files_run": [
            "testing/test_mark_expression.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "pytest-dev__pytest-7432",
      "repo": "pytest-dev/pytest",
      "valid": false,
      "worker": "http://35.239.238.137:8080",
      "duration": 9.689178943634033,
      "test_only": {
        "passed": true,
        "stats": {
          "passed": 78,
          "failed": 0,
          "errors": 0,
          "collected": 79,
          "duration": 4.34,
          "log_tail": "testing/test_skipping.py::test_reportchars_error PASSED                  [ 78%]\ntesting/test_skipping.py::test_reportchars_all PASSED                    [ 79%]\ntesting/test_skipping.py::test_reportchars_all_error PASSED              [ 81%]\ntesting/test_skipping.py::test_errors_in_xfail_skip_expressions PASSED   [ 82%]\ntesting/test_skipping.py::test_xfail_skipif_with_globals PASSED          [ 83%]\ntesting/test_skipping.py::test_default_markers PASSED                    [ 84%]\ntesting/test_skipping.py::test_xfail_test_setup_exception PASSED         [ 86%]\ntesting/test_skipping.py::test_imperativeskip_on_xfail_test PASSED       [ 87%]\ntesting/test_skipping.py::TestBooleanCondition::test_skipif PASSED       [ 88%]\ntesting/test_skipping.py::TestBooleanCondition::test_skipif_noreason PASSED [ 89%]\ntesting/test_skipping.py::TestBooleanCondition::test_xfail PASSED        [ 91%]\ntesting/test_skipping.py::test_xfail_item PASSED                         [ 92%]\ntesting/test_skipping.py::test_module_level_skip_error PASSED            [ 93%]\ntesting/test_skipping.py::test_module_level_skip_with_allow_module_level PASSED [ 94%]\ntesting/test_skipping.py::test_invalid_skip_keyword_parameter PASSED     [ 96%]\ntesting/test_skipping.py::test_mark_xfail_item PASSED                    [ 97%]\ntesting/test_skipping.py::test_summary_list_after_errors PASSED          [ 98%]\ntesting/test_skipping.py::test_relpath_rootdir PASSED                    [100%]\n\n=================================== FAILURES ===================================\n________ TestXFail.test_xfail_run_with_skip_mark[test_input1-expected1] ________\n/testbed/testing/test_skipping.py:261: in test_xfail_run_with_skip_mark\n    result.stdout.fnmatch_lines(expected)\nE   Failed: nomatch: 'SKIPPED [1] test_sample.py:2: unconditional skip'\nE       and: '============================= test session starts =============================='\nE       and: 'platform linux -- Python 3.9.20, pytest-5.4.1.dev593+ge6e300e72, py-1.11.0, pluggy-0.13.1'\nE       and: 'rootdir: /tmp/pytest-of-root/pytest-0/test_xfail_run_with_skip_mark1'\nE       and: 'collected 1 item'\nE       and: ''\nE       and: 'test_sample.py s                                                         [100%]'\nE       and: ''\nE       and: '=========================== short test summary info ============================'\nE       and: 'SKIPPED [1] ../../../../testbed/src/_pytest/skipping.py:239: unconditional skip'\nE       and: '============================== 1 skipped in 0.00s =============================='\nE   remains unmatched: 'SKIPPED [1] test_sample.py:2: unconditional skip'\n----------------------------- Captured stdout call -----------------------------\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-5.4.1.dev593+ge6e300e72, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_xfail_run_with_skip_mark1\ncollected 1 item\n\ntest_sample.py s                                                         [100%]\n\n=========================== short test summary info ============================\nSKIPPED [1] ../../../../testbed/src/_pytest/skipping.py:239: unconditional skip\n============================== 1 skipped in 0.00s ==============================\n========================= 1 failed, 78 passed in 1.96s =========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/test_skipping.py` failed. (See above for error)",
          "test_files_run": [
            "testing/test_skipping.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 79,
          "failed": 0,
          "errors": 0,
          "collected": 79,
          "duration": 4.49,
          "log_tail": "testing/test_skipping.py::TestXFail::test_strict_xfail[True] PASSED      [ 43%]\ntesting/test_skipping.py::TestXFail::test_strict_xfail[False] PASSED     [ 44%]\ntesting/test_skipping.py::TestXFail::test_strict_xfail_condition[True] PASSED [ 45%]\ntesting/test_skipping.py::TestXFail::test_strict_xfail_condition[False] PASSED [ 46%]\ntesting/test_skipping.py::TestXFail::test_xfail_condition_keyword[True] PASSED [ 48%]\ntesting/test_skipping.py::TestXFail::test_xfail_condition_keyword[False] PASSED [ 49%]\ntesting/test_skipping.py::TestXFail::test_strict_xfail_default_from_file[true] PASSED [ 50%]\ntesting/test_skipping.py::TestXFail::test_strict_xfail_default_from_file[false] PASSED [ 51%]\ntesting/test_skipping.py::TestXFailwithSetupTeardown::test_failing_setup_issue9 PASSED [ 53%]\ntesting/test_skipping.py::TestXFailwithSetupTeardown::test_failing_teardown_issue9 PASSED [ 54%]\ntesting/test_skipping.py::TestSkip::test_skip_class PASSED               [ 55%]\ntesting/test_skipping.py::TestSkip::test_skips_on_false_string PASSED    [ 56%]\ntesting/test_skipping.py::TestSkip::test_arg_as_reason PASSED            [ 58%]\ntesting/test_skipping.py::TestSkip::test_skip_no_reason PASSED           [ 59%]\ntesting/test_skipping.py::TestSkip::test_skip_with_reason PASSED         [ 60%]\ntesting/test_skipping.py::TestSkip::test_only_skips_marked_test PASSED   [ 62%]\ntesting/test_skipping.py::TestSkip::test_strict_and_skip PASSED          [ 63%]\ntesting/test_skipping.py::TestSkipif::test_skipif_conditional PASSED     [ 64%]\ntesting/test_skipping.py::TestSkipif::test_skipif_reporting[\"hasattr(sys, 'platform')\"] PASSED [ 65%]\ntesting/test_skipping.py::TestSkipif::test_skipif_reporting[True, reason=\"invalid platform\"] PASSED [ 67%]\ntesting/test_skipping.py::TestSkipif::test_skipif_using_platform PASSED  [ 68%]\ntesting/test_skipping.py::TestSkipif::test_skipif_reporting_multiple[skipif-SKIP-skipped] PASSED [ 69%]\ntesting/test_skipping.py::TestSkipif::test_skipif_reporting_multiple[xfail-XPASS-xpassed] PASSED [ 70%]\ntesting/test_skipping.py::test_skip_not_report_default PASSED            [ 72%]\ntesting/test_skipping.py::test_skipif_class PASSED                       [ 73%]\ntesting/test_skipping.py::test_skipped_reasons_functional PASSED         [ 74%]\ntesting/test_skipping.py::test_skipped_folding PASSED                    [ 75%]\ntesting/test_skipping.py::test_reportchars PASSED                        [ 77%]\ntesting/test_skipping.py::test_reportchars_error PASSED                  [ 78%]\ntesting/test_skipping.py::test_reportchars_all PASSED                    [ 79%]\ntesting/test_skipping.py::test_reportchars_all_error PASSED              [ 81%]\ntesting/test_skipping.py::test_errors_in_xfail_skip_expressions PASSED   [ 82%]\ntesting/test_skipping.py::test_xfail_skipif_with_globals PASSED          [ 83%]\ntesting/test_skipping.py::test_default_markers PASSED                    [ 84%]\ntesting/test_skipping.py::test_xfail_test_setup_exception PASSED         [ 86%]\ntesting/test_skipping.py::test_imperativeskip_on_xfail_test PASSED       [ 87%]\ntesting/test_skipping.py::TestBooleanCondition::test_skipif PASSED       [ 88%]\ntesting/test_skipping.py::TestBooleanCondition::test_skipif_noreason PASSED [ 89%]\ntesting/test_skipping.py::TestBooleanCondition::test_xfail PASSED        [ 91%]\ntesting/test_skipping.py::test_xfail_item PASSED                         [ 92%]\ntesting/test_skipping.py::test_module_level_skip_error PASSED            [ 93%]\ntesting/test_skipping.py::test_module_level_skip_with_allow_module_level PASSED [ 94%]\ntesting/test_skipping.py::test_invalid_skip_keyword_parameter PASSED     [ 96%]\ntesting/test_skipping.py::test_mark_xfail_item PASSED                    [ 97%]\ntesting/test_skipping.py::test_summary_list_after_errors PASSED          [ 98%]\ntesting/test_skipping.py::test_relpath_rootdir PASSED                    [100%]\n\n============================== 79 passed in 1.97s ==============================\n\n",
          "test_files_run": [
            "testing/test_skipping.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got True\u2192True"
    },
    {
      "instance_id": "mwaskom__seaborn-3069",
      "repo": "mwaskom/seaborn",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10cfac650>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 1
    },
    {
      "instance_id": "pytest-dev__pytest-7521",
      "repo": "pytest-dev/pytest",
      "valid": false,
      "worker": "http://34.41.233.120:8080",
      "duration": 18.56899404525757,
      "test_only": {
        "passed": true,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "collected": 129,
          "duration": 9.1,
          "log_tail": "testing/test_capture.py::TestStdCaptureFDinvalidFD::test_fdcapture_invalid_fd_with_fd_reuse PASSED [ 75%]\ntesting/test_capture.py::TestStdCaptureFDinvalidFD::test_fdcapture_invalid_fd_without_fd_reuse PASSED [ 76%]\ntesting/test_capture.py::test_capturing_and_logging_fundamentals[SysCapture(2)] PASSED [ 77%]\ntesting/test_capture.py::test_capturing_and_logging_fundamentals[SysCapture(2, tee=True)] PASSED [ 78%]\ntesting/test_capture.py::test_capturing_and_logging_fundamentals[FDCapture(2)] PASSED [ 79%]\ntesting/test_capture.py::test_error_attribute_issue555 PASSED            [ 79%]\ntesting/test_capture.py::test_dontreadfrominput_has_encoding PASSED      [ 80%]\ntesting/test_capture.py::test_typeerror_encodedfile_write PASSED         [ 81%]\ntesting/test_capture.py::test_encodedfile_writelines PASSED              [ 82%]\ntesting/test_capture.py::TestLoggingInteraction::test_logging_stream_ownership PASSED [ 82%]\ntesting/test_capture.py::TestLoggingInteraction::test_logging_and_immediate_setupteardown PASSED [ 83%]\ntesting/test_capture.py::TestLoggingInteraction::test_logging_and_crossscope_fixtures PASSED [ 84%]\ntesting/test_capture.py::TestLoggingInteraction::test_conftestlogging_is_shown PASSED [ 85%]\ntesting/test_capture.py::TestLoggingInteraction::test_conftestlogging_and_test_logging PASSED [ 86%]\ntesting/test_capture.py::TestLoggingInteraction::test_logging_after_cap_stopped PASSED [ 86%]\ntesting/test_capture.py::TestCaptureFixture::test_keyboardinterrupt_disables_capturing PASSED [ 87%]\ntesting/test_capture.py::TestCaptureFixture::test_capture_and_logging PASSED [ 88%]\ntesting/test_capture.py::TestCaptureFixture::test_disabled_capture_fixture[True-capsys] PASSED [ 89%]\ntesting/test_capture.py::TestCaptureFixture::test_disabled_capture_fixture[True-capfd] PASSED [ 89%]\ntesting/test_capture.py::TestCaptureFixture::test_disabled_capture_fixture[False-capsys] PASSED [ 90%]\ntesting/test_capture.py::TestCaptureFixture::test_disabled_capture_fixture[False-capfd] PASSED [ 91%]\ntesting/test_capture.py::TestCaptureFixture::test_fixture_use_by_other_fixtures[capsys] PASSED [ 92%]\ntesting/test_capture.py::TestCaptureFixture::test_fixture_use_by_other_fixtures[capfd] PASSED [ 93%]\ntesting/test_capture.py::test_error_during_readouterr PASSED             [ 93%]\ntesting/test_capture.py::TestStdCaptureFD::test_simple_only_fd PASSED    [ 94%]\ntesting/test_capture.py::TestStdCaptureFDinvalidFD::test_stdcapture_fd_invalid_fd PASSED [ 95%]\ntesting/test_capture.py::test_close_and_capture_again PASSED             [ 96%]\ntesting/test_capture.py::test_crash_on_closing_tmpfile_py27 PASSED       [ 96%]\ntesting/test_capture.py::test_global_capture_with_live_logging PASSED    [ 97%]\ntesting/test_capture.py::test_capture_with_live_logging[capsys] PASSED   [ 98%]\ntesting/test_capture.py::test_capture_with_live_logging[capfd] PASSED    [ 99%]\ntesting/test_capture.py::test_logging_while_collecting PASSED            [100%]\n\n=================================== FAILURES ===================================\n____________ TestCaptureFixture.test_cafd_preserves_newlines[\\r\\n] _____________\ntesting/test_capture.py:521: in test_cafd_preserves_newlines\n    assert out.endswith(nl)\nE   AssertionError: assert False\nE    +  where False = <built-in method endswith of str object at 0x76381678acf0>('\\r\\n')\nE    +    where <built-in method endswith of str object at 0x76381678acf0> = 'test\\n'.endswith\n_____________ TestCaptureFixture.test_cafd_preserves_newlines[\\r] ______________\ntesting/test_capture.py:521: in test_cafd_preserves_newlines\n    assert out.endswith(nl)\nE   AssertionError: assert False\nE    +  where False = <built-in method endswith of str object at 0x7638167c2ef0>('\\r')\nE    +    where <built-in method endswith of str object at 0x7638167c2ef0> = 'test\\n'.endswith\n============= 2 failed, 123 passed, 3 skipped, 1 xfailed in 6.26s ==============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/test_capture.py` failed. (See above for error)",
          "test_files_run": [
            "testing/test_capture.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 125,
          "failed": 0,
          "errors": 0,
          "collected": 129,
          "duration": 8.58,
          "log_tail": "testing/test_capture.py::TestCaptureFixture::test_capsysbinary PASSED    [ 65%]\ntesting/test_capture.py::TestCaptureFixture::test_partial_setup_failure PASSED [ 65%]\ntesting/test_capture.py::TestCaptureFixture::test_fixture_use_by_other_fixtures_teardown[capsys] PASSED [ 66%]\ntesting/test_capture.py::TestCaptureFixture::test_fixture_use_by_other_fixtures_teardown[capfd] PASSED [ 67%]\ntesting/test_capture.py::test_setup_failure_does_not_kill_capturing PASSED [ 68%]\ntesting/test_capture.py::test_capture_conftest_runtest_setup PASSED      [ 68%]\ntesting/test_capture.py::test_capture_badoutput_issue412 PASSED          [ 69%]\ntesting/test_capture.py::test_capture_early_option_parsing PASSED        [ 70%]\ntesting/test_capture.py::test_capture_binary_output PASSED               [ 71%]\ntesting/test_capture.py::TestFDCapture::test_simple PASSED               [ 72%]\ntesting/test_capture.py::TestFDCapture::test_simple_many PASSED          [ 72%]\ntesting/test_capture.py::TestFDCapture::test_simple_many_check_open_files SKIPPED [ 73%]\ntesting/test_capture.py::TestFDCapture::test_simple_fail_second_start PASSED [ 74%]\ntesting/test_capture.py::TestFDCapture::test_writeorg PASSED             [ 75%]\ntesting/test_capture.py::TestStdCaptureFDinvalidFD::test_fdcapture_invalid_fd_with_fd_reuse PASSED [ 75%]\ntesting/test_capture.py::TestStdCaptureFDinvalidFD::test_fdcapture_invalid_fd_without_fd_reuse PASSED [ 76%]\ntesting/test_capture.py::test_capturing_and_logging_fundamentals[SysCapture(2)] PASSED [ 77%]\ntesting/test_capture.py::test_capturing_and_logging_fundamentals[SysCapture(2, tee=True)] PASSED [ 78%]\ntesting/test_capture.py::test_capturing_and_logging_fundamentals[FDCapture(2)] PASSED [ 79%]\ntesting/test_capture.py::test_error_attribute_issue555 PASSED            [ 79%]\ntesting/test_capture.py::test_dontreadfrominput_has_encoding PASSED      [ 80%]\ntesting/test_capture.py::test_typeerror_encodedfile_write PASSED         [ 81%]\ntesting/test_capture.py::test_encodedfile_writelines PASSED              [ 82%]\ntesting/test_capture.py::TestLoggingInteraction::test_logging_stream_ownership PASSED [ 82%]\ntesting/test_capture.py::TestLoggingInteraction::test_logging_and_immediate_setupteardown PASSED [ 83%]\ntesting/test_capture.py::TestLoggingInteraction::test_logging_and_crossscope_fixtures PASSED [ 84%]\ntesting/test_capture.py::TestLoggingInteraction::test_conftestlogging_is_shown PASSED [ 85%]\ntesting/test_capture.py::TestLoggingInteraction::test_conftestlogging_and_test_logging PASSED [ 86%]\ntesting/test_capture.py::TestLoggingInteraction::test_logging_after_cap_stopped PASSED [ 86%]\ntesting/test_capture.py::TestCaptureFixture::test_keyboardinterrupt_disables_capturing PASSED [ 87%]\ntesting/test_capture.py::TestCaptureFixture::test_capture_and_logging PASSED [ 88%]\ntesting/test_capture.py::TestCaptureFixture::test_disabled_capture_fixture[True-capsys] PASSED [ 89%]\ntesting/test_capture.py::TestCaptureFixture::test_disabled_capture_fixture[True-capfd] PASSED [ 89%]\ntesting/test_capture.py::TestCaptureFixture::test_disabled_capture_fixture[False-capsys] PASSED [ 90%]\ntesting/test_capture.py::TestCaptureFixture::test_disabled_capture_fixture[False-capfd] PASSED [ 91%]\ntesting/test_capture.py::TestCaptureFixture::test_fixture_use_by_other_fixtures[capsys] PASSED [ 92%]\ntesting/test_capture.py::TestCaptureFixture::test_fixture_use_by_other_fixtures[capfd] PASSED [ 93%]\ntesting/test_capture.py::test_error_during_readouterr PASSED             [ 93%]\ntesting/test_capture.py::TestStdCaptureFD::test_simple_only_fd PASSED    [ 94%]\ntesting/test_capture.py::TestStdCaptureFDinvalidFD::test_stdcapture_fd_invalid_fd PASSED [ 95%]\ntesting/test_capture.py::test_close_and_capture_again PASSED             [ 96%]\ntesting/test_capture.py::test_crash_on_closing_tmpfile_py27 PASSED       [ 96%]\ntesting/test_capture.py::test_global_capture_with_live_logging PASSED    [ 97%]\ntesting/test_capture.py::test_capture_with_live_logging[capsys] PASSED   [ 98%]\ntesting/test_capture.py::test_capture_with_live_logging[capfd] PASSED    [ 99%]\ntesting/test_capture.py::test_logging_while_collecting PASSED            [100%]\n\n================== 125 passed, 3 skipped, 1 xfailed in 6.23s ===================\n\n",
          "test_files_run": [
            "testing/test_capture.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got True\u2192True"
    },
    {
      "instance_id": "pytest-dev__pytest-7982",
      "repo": "pytest-dev/pytest",
      "valid": false,
      "worker": "http://34.41.233.120:8080",
      "duration": 11.6712167263031,
      "test_only": {
        "passed": true,
        "stats": {
          "passed": 1,
          "failed": 0,
          "errors": 0,
          "collected": 80,
          "duration": 5.68,
          "log_tail": "testing/test_collection.py::test_fixture_scope_sibling_conftests PASSED  [ 73%]\ntesting/test_collection.py::test_collect_init_tests PASSED               [ 75%]\ntesting/test_collection.py::test_collect_invalid_signature_message PASSED [ 76%]\ntesting/test_collection.py::test_collect_handles_raising_on_dunder_class PASSED [ 77%]\ntesting/test_collection.py::test_collect_with_chdir_during_import PASSED [ 78%]\ntesting/test_collection.py::test_collect_symlink_file_arg PASSED         [ 80%]\ntesting/test_collection.py::test_collect_symlink_out_of_tree PASSED      [ 81%]\ntesting/test_collection.py::test_collect_symlink_dir FAILED              [ 82%]\ntesting/test_collection.py::test_collectignore_via_conftest PASSED       [ 83%]\ntesting/test_collection.py::test_collect_pkg_init_and_file_in_args PASSED [ 85%]\ntesting/test_collection.py::test_collect_pkg_init_only PASSED            [ 86%]\ntesting/test_collection.py::test_collect_sub_with_symlinks[True] PASSED  [ 87%]\ntesting/test_collection.py::test_collect_sub_with_symlinks[False] PASSED [ 88%]\ntesting/test_collection.py::test_collector_respects_tbstyle PASSED       [ 90%]\ntesting/test_collection.py::test_does_not_eagerly_collect_packages PASSED [ 91%]\ntesting/test_collection.py::test_does_not_put_src_on_path PASSED         [ 92%]\ntesting/test_collection.py::TestImportModeImportlib::test_collect_duplicate_names PASSED [ 93%]\ntesting/test_collection.py::TestImportModeImportlib::test_conftest PASSED [ 95%]\ntesting/test_collection.py::TestImportModeImportlib::test_modules_importable_as_side_effect PASSED [ 96%]\ntesting/test_collection.py::TestImportModeImportlib::test_modules_not_importable_as_side_effect PASSED [ 97%]\ntesting/test_collection.py::test_does_not_crash_on_error_from_decorated_function PASSED [ 98%]\ntesting/test_collection.py::test_collect_pyargs_with_testpaths PASSED    [100%]\n\n=================================== FAILURES ===================================\n___________________________ test_collect_symlink_dir ___________________________\n/testbed/testing/test_collection.py:1188: in test_collect_symlink_dir\n    result.assert_outcomes(passed=2)\nE   AssertionError: assert {'errors': 0,...pped': 0, ...} == {'errors': 0,...pped': 0, ...}\nE     Omitting 5 identical items, use -vv to show\nE     Differing items:\nE     {'passed': 1} != {'passed': 2}\nE     Full diff:\nE       {\nE        'errors': 0,\nE        'failed': 0,...\nE     \nE     ...Full output truncated (9 lines hidden), use '-vv' to show\n----------------------------- Captured stdout call -----------------------------\n============================= test session starts ==============================\nplatform linux -- Python 3.9.20, pytest-6.2.0.dev154+ga7e38c5c6, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_collect_symlink_dir0\ncollected 1 item\n\ndir/test_it.py .                                                         [100%]\n\n============================== 1 passed in 0.00s ===============================\n=================== 1 failed, 78 passed, 1 xfailed in 2.84s ====================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/test_collection.py` failed. (See above for error)",
          "test_files_run": [
            "testing/test_collection.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 79,
          "failed": 0,
          "errors": 0,
          "collected": 80,
          "duration": 5.12,
          "log_tail": "testing/test_collection.py::TestCustomConftests::test_pytest_fs_collect_hooks_are_seen PASSED [ 43%]\ntesting/test_collection.py::TestCustomConftests::test_pytest_collect_file_from_sister_dir PASSED [ 45%]\ntesting/test_collection.py::TestSession::test_collect_topdir PASSED      [ 46%]\ntesting/test_collection.py::TestSession::test_collect_protocol_single_function PASSED [ 47%]\ntesting/test_collection.py::TestSession::test_collect_protocol_method PASSED [ 48%]\ntesting/test_collection.py::TestSession::test_collect_custom_nodes_multi_id PASSED [ 50%]\ntesting/test_collection.py::TestSession::test_collect_subdir_event_ordering PASSED [ 51%]\ntesting/test_collection.py::TestSession::test_collect_two_commandline_args PASSED [ 52%]\ntesting/test_collection.py::TestSession::test_serialization_byid PASSED  [ 53%]\ntesting/test_collection.py::TestSession::test_find_byid_without_instance_parents PASSED [ 55%]\ntesting/test_collection.py::Test_getinitialnodes::test_global_file PASSED [ 56%]\ntesting/test_collection.py::Test_getinitialnodes::test_pkgfile PASSED    [ 57%]\ntesting/test_collection.py::Test_genitems::test_check_collect_hashes PASSED [ 58%]\ntesting/test_collection.py::Test_genitems::test_example_items1 PASSED    [ 60%]\ntesting/test_collection.py::Test_genitems::test_class_and_functions_discovery_using_glob PASSED [ 61%]\ntesting/test_collection.py::test_matchnodes_two_collections_same_file PASSED [ 62%]\ntesting/test_collection.py::TestNodekeywords::test_no_under PASSED       [ 63%]\ntesting/test_collection.py::TestNodekeywords::test_issue345 PASSED       [ 65%]\ntesting/test_collection.py::TestNodekeywords::test_keyword_matching_is_case_insensitive_by_default PASSED [ 66%]\ntesting/test_collection.py::test_exit_on_collection_error PASSED         [ 67%]\ntesting/test_collection.py::test_exit_on_collection_with_maxfail_smaller_than_n_errors PASSED [ 68%]\ntesting/test_collection.py::test_exit_on_collection_with_maxfail_bigger_than_n_errors PASSED [ 70%]\ntesting/test_collection.py::test_continue_on_collection_errors PASSED    [ 71%]\ntesting/test_collection.py::test_continue_on_collection_errors_maxfail PASSED [ 72%]\ntesting/test_collection.py::test_fixture_scope_sibling_conftests PASSED  [ 73%]\ntesting/test_collection.py::test_collect_init_tests PASSED               [ 75%]\ntesting/test_collection.py::test_collect_invalid_signature_message PASSED [ 76%]\ntesting/test_collection.py::test_collect_handles_raising_on_dunder_class PASSED [ 77%]\ntesting/test_collection.py::test_collect_with_chdir_during_import PASSED [ 78%]\ntesting/test_collection.py::test_collect_symlink_file_arg PASSED         [ 80%]\ntesting/test_collection.py::test_collect_symlink_out_of_tree PASSED      [ 81%]\ntesting/test_collection.py::test_collect_symlink_dir PASSED              [ 82%]\ntesting/test_collection.py::test_collectignore_via_conftest PASSED       [ 83%]\ntesting/test_collection.py::test_collect_pkg_init_and_file_in_args PASSED [ 85%]\ntesting/test_collection.py::test_collect_pkg_init_only PASSED            [ 86%]\ntesting/test_collection.py::test_collect_sub_with_symlinks[True] PASSED  [ 87%]\ntesting/test_collection.py::test_collect_sub_with_symlinks[False] PASSED [ 88%]\ntesting/test_collection.py::test_collector_respects_tbstyle PASSED       [ 90%]\ntesting/test_collection.py::test_does_not_eagerly_collect_packages PASSED [ 91%]\ntesting/test_collection.py::test_does_not_put_src_on_path PASSED         [ 92%]\ntesting/test_collection.py::TestImportModeImportlib::test_collect_duplicate_names PASSED [ 93%]\ntesting/test_collection.py::TestImportModeImportlib::test_conftest PASSED [ 95%]\ntesting/test_collection.py::TestImportModeImportlib::test_modules_importable_as_side_effect PASSED [ 96%]\ntesting/test_collection.py::TestImportModeImportlib::test_modules_not_importable_as_side_effect PASSED [ 97%]\ntesting/test_collection.py::test_does_not_crash_on_error_from_decorated_function PASSED [ 98%]\ntesting/test_collection.py::test_collect_pyargs_with_testpaths PASSED    [100%]\n\n======================== 79 passed, 1 xfailed in 2.79s =========================\n\n",
          "test_files_run": [
            "testing/test_collection.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got True\u2192True"
    },
    {
      "instance_id": "pytest-dev__pytest-10081",
      "repo": "pytest-dev/pytest",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10cf2e5d0>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 1
    },
    {
      "instance_id": "pytest-dev__pytest-5262",
      "repo": "pytest-dev/pytest",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10cf2d1c0>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 1
    },
    {
      "instance_id": "pylint-dev__pylint-4661",
      "repo": "pylint-dev/pylint",
      "valid": false,
      "worker": "http://34.123.9.23:8080",
      "duration": 6.639693737030029,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 1,
          "collected": 0,
          "duration": 3.28,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 0 items / 1 error\n\n==================================== ERRORS ====================================\n_________________ ERROR collecting tests/lint/unittest_lint.py _________________\nImportError while importing test module '/testbed/tests/lint/unittest_lint.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/opt/miniconda3/envs/testbed/lib/python3.9/importlib/__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests/lint/unittest_lint.py:49: in <module>\n    import appdirs\nE   ModuleNotFoundError: No module named 'appdirs'\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/interpreter/_import/util.py:6\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/interpreter/_import/util.py:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    import pkg_resources\n\n-- Docs: https://docs.pytest.org/en/stable/warnings.html\n!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n========================= 1 warning, 1 error in 0.17s ==========================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/lint/unittest_lint.py` failed. (See above for error)",
          "test_files_run": [
            "tests/lint/unittest_lint.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "duration": 2.33,
          "log_tail": "\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/_pytest/config/__init__.py:318: PluggyTeardownRaisedWarning: A plugin raised an exception during an old-style hookwrapper teardown.\nPlugin: helpconfig, Hook: pytest_cmdline_parse\nConftestImportFailure: ModuleNotFoundError: No module named 'appdirs' (from /testbed/tests/conftest.py)\nFor more information see https://pluggy.readthedocs.io/en/stable/api_reference.html#pluggy.PluggyTeardownRaisedWarning\n  config = pluginmanager.hook.pytest_cmdline_parse(\nImportError while loading conftest '/testbed/tests/conftest.py'.\ntests/conftest.py:8: in <module>\n    from pylint import checkers\npylint/checkers/__init__.py:49: in <module>\n    from pylint.checkers.base_checker import BaseChecker, BaseTokenChecker\npylint/checkers/base_checker.py:22: in <module>\n    from pylint.config import OptionsProviderMixIn\npylint/config/__init__.py:39: in <module>\n    import appdirs\nE   ModuleNotFoundError: No module named 'appdirs'\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/lint/unittest_lint.py` failed. (See above for error)",
          "test_files_run": [
            "tests/lint/unittest_lint.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "pytest-dev__pytest-8399",
      "repo": "pytest-dev/pytest",
      "valid": false,
      "worker": "http://34.123.9.23:8080",
      "duration": 14.904447078704834,
      "test_only": {
        "passed": true,
        "stats": {
          "passed": 0,
          "failed": 0,
          "errors": 0,
          "collected": 90,
          "duration": 9.22,
          "log_tail": "    fixture has finished. The ``raising`` parameter determines if a KeyError\n    or AttributeError will be raised if the set/deletion operation has no target.\n\nrecwarn\n    Return a :class:`WarningsRecorder` instance that records all warnings emitted by test functions.\n    \n    See http://docs.python.org/library/warnings.html for information\n    on warning categories.\n\ntmpdir_factory [session scope]\n    Return a :class:`_pytest.tmpdir.TempdirFactory` instance for the test session.\n\ntmp_path_factory [session scope]\n    Return a :class:`_pytest.tmpdir.TempPathFactory` instance for the test session.\n\ntmpdir\n    Return a temporary directory path object which is unique to each test\n    function invocation, created as a sub directory of the base temporary\n    directory.\n    \n    By default, a new base temporary directory is created each test session,\n    and old bases are removed after 3 sessions, to aid in debugging. If\n    ``--basetemp`` is used then it is cleared each session. See :ref:`base\n    temporary directory`.\n    \n    The returned object is a `py.path.local`_ path object.\n    \n    .. _`py.path.local`: https://py.readthedocs.io/en/latest/path.html\n\ntmp_path\n    Return a temporary directory path object which is unique to each test\n    function invocation, created as a sub directory of the base temporary\n    directory.\n    \n    By default, a new base temporary directory is created each test session,\n    and old bases are removed after 3 sessions, to aid in debugging. If\n    ``--basetemp`` is used then it is cleared each session. See :ref:`base\n    temporary directory`.\n    \n    The returned object is a :class:`pathlib.Path` object.\n\nunittest_setUpClass_fixture_MyTestCase [class scope]\n    /testbed/src/_pytest/unittest.py:144: no docstring available\n\n\n============================ no tests ran in 0.01s =============================\n=================== 1 failed, 59 passed, 30 skipped in 2.31s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN testing/test_nose.py testing/test_unittest.py` failed. (See above for error)",
          "test_files_run": [
            "testing/test_nose.py",
            "testing/test_unittest.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 60,
          "failed": 0,
          "errors": 0,
          "collected": 90,
          "duration": 4.82,
          "log_tail": "testing/test_unittest.py::TestTrialUnittest::test_trial_exceptions_with_skips SKIPPED [ 50%]\ntesting/test_unittest.py::TestTrialUnittest::test_trial_error SKIPPED    [ 51%]\ntesting/test_unittest.py::TestTrialUnittest::test_trial_testcase_skip_property SKIPPED [ 52%]\ntesting/test_unittest.py::TestTrialUnittest::test_trial_testfunction_skip_property SKIPPED [ 53%]\ntesting/test_unittest.py::TestTrialUnittest::test_trial_testcase_todo_property SKIPPED [ 54%]\ntesting/test_unittest.py::TestTrialUnittest::test_trial_testfunction_todo_property SKIPPED [ 55%]\ntesting/test_unittest.py::test_djangolike_testcase PASSED                [ 56%]\ntesting/test_unittest.py::test_unittest_not_shown_in_traceback PASSED    [ 57%]\ntesting/test_unittest.py::test_unorderable_types PASSED                  [ 58%]\ntesting/test_unittest.py::test_unittest_typerror_traceback PASSED        [ 60%]\ntesting/test_unittest.py::test_unittest_expected_failure_for_failing_test_is_xfail[pytest] PASSED [ 61%]\ntesting/test_unittest.py::test_unittest_expected_failure_for_failing_test_is_xfail[unittest] PASSED [ 62%]\ntesting/test_unittest.py::test_unittest_expected_failure_for_passing_test_is_fail[pytest] PASSED [ 63%]\ntesting/test_unittest.py::test_unittest_expected_failure_for_passing_test_is_fail[unittest] PASSED [ 64%]\ntesting/test_unittest.py::test_unittest_setup_interaction[return] PASSED [ 65%]\ntesting/test_unittest.py::test_unittest_setup_interaction[yield] PASSED  [ 66%]\ntesting/test_unittest.py::test_non_unittest_no_setupclass_support PASSED [ 67%]\ntesting/test_unittest.py::test_no_teardown_if_setupclass_failed PASSED   [ 68%]\ntesting/test_unittest.py::test_cleanup_functions PASSED                  [ 70%]\ntesting/test_unittest.py::test_issue333_result_clearing PASSED           [ 71%]\ntesting/test_unittest.py::test_unittest_raise_skip_issue748 PASSED       [ 72%]\ntesting/test_unittest.py::test_unittest_skip_issue1169 PASSED            [ 73%]\ntesting/test_unittest.py::test_class_method_containing_test_issue1558 PASSED [ 74%]\ntesting/test_unittest.py::test_usefixtures_marker_on_unittest[builtins.object] PASSED [ 75%]\ntesting/test_unittest.py::test_usefixtures_marker_on_unittest[unittest.TestCase] PASSED [ 76%]\ntesting/test_unittest.py::test_testcase_handles_init_exceptions PASSED   [ 77%]\ntesting/test_unittest.py::test_error_message_with_parametrized_fixtures PASSED [ 78%]\ntesting/test_unittest.py::test_setup_inheritance_skipping[test_setup_skip.py-1 skipped] PASSED [ 80%]\ntesting/test_unittest.py::test_setup_inheritance_skipping[test_setup_skip_class.py-1 skipped] PASSED [ 81%]\ntesting/test_unittest.py::test_setup_inheritance_skipping[test_setup_skip_module.py-1 error] PASSED [ 82%]\ntesting/test_unittest.py::test_BdbQuit PASSED                            [ 83%]\ntesting/test_unittest.py::test_exit_outcome PASSED                       [ 84%]\ntesting/test_unittest.py::test_trace PASSED                              [ 85%]\ntesting/test_unittest.py::test_pdb_teardown_called PASSED                [ 86%]\ntesting/test_unittest.py::test_pdb_teardown_skipped[@unittest.skip] PASSED [ 87%]\ntesting/test_unittest.py::test_pdb_teardown_skipped[@pytest.mark.skip] PASSED [ 88%]\ntesting/test_unittest.py::test_async_support PASSED                      [ 90%]\ntesting/test_unittest.py::test_asynctest_support SKIPPED (could not ...) [ 91%]\ntesting/test_unittest.py::test_do_class_cleanups_on_success PASSED       [ 92%]\ntesting/test_unittest.py::test_do_class_cleanups_on_setupclass_failure PASSED [ 93%]\ntesting/test_unittest.py::test_do_class_cleanups_on_teardownclass_failure PASSED [ 94%]\ntesting/test_unittest.py::test_do_cleanups_on_success PASSED             [ 95%]\ntesting/test_unittest.py::test_do_cleanups_on_setup_failure PASSED       [ 96%]\ntesting/test_unittest.py::test_do_cleanups_on_teardown_failure PASSED    [ 97%]\ntesting/test_unittest.py::TestTrialUnittest::test_trial_pdb SKIPPED      [ 98%]\ntesting/test_unittest.py::test_plain_unittest_does_not_support_async PASSED [100%]\n\n======================== 60 passed, 30 skipped in 2.38s ========================\n\n",
          "test_files_run": [
            "testing/test_nose.py",
            "testing/test_unittest.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got True\u2192True"
    },
    {
      "instance_id": "pylint-dev__pylint-8898",
      "repo": "pylint-dev/pylint",
      "valid": false,
      "worker": "http://34.123.9.23:8080",
      "duration": 12.827670812606812,
      "test_only": {
        "passed": true,
        "stats": {
          "passed": 18,
          "failed": 0,
          "errors": 0,
          "collected": 20,
          "duration": 6.03,
          "log_tail": "tests/config/test_config.py::test_unknown_message_id PASSED              [ 10%]\ntests/config/test_config.py::test_unknown_option_name PASSED             [ 15%]\ntests/config/test_config.py::test_unknown_short_option_name PASSED       [ 20%]\ntests/config/test_config.py::test_unknown_confidence PASSED              [ 25%]\ntests/config/test_config.py::test_empty_confidence PASSED                [ 30%]\ntests/config/test_config.py::test_unknown_yes_no PASSED                  [ 35%]\ntests/config/test_config.py::test_unknown_py_version PASSED              [ 40%]\ntests/config/test_config.py::test_csv_regex_comma_in_quantifier[foo-expected0] PASSED [ 45%]\ntests/config/test_config.py::test_csv_regex_comma_in_quantifier[foo,bar-expected1] PASSED [ 50%]\ntests/config/test_config.py::test_csv_regex_comma_in_quantifier[foo, bar-expected2] PASSED [ 55%]\ntests/config/test_config.py::test_csv_regex_comma_in_quantifier[foo, bar{1,3}-expected3] FAILED [ 60%]\ntests/config/test_config.py::test_regex_error PASSED                     [ 65%]\ntests/config/test_config.py::test_csv_regex_error FAILED                 [ 70%]\ntests/config/test_config.py::test_short_verbose PASSED                   [ 75%]\ntests/config/test_config.py::test_argument_separator PASSED              [ 80%]\ntests/config/test_config.py::test_clear_cache_post_run PASSED            [ 85%]\ntests/config/test_config.py::test_enable_all_disable_all_mutually_exclusive PASSED [ 90%]\ntests/config/test_config.py::test_disable_before_enable_all_takes_effect PASSED [ 95%]\ntests/config/test_config.py::test_enable_before_disable_all_takes_effect PASSED [100%]\n\n=================================== FAILURES ===================================\n_________ test_csv_regex_comma_in_quantifier[foo, bar{1,3}-expected3] __________\ntests/config/test_config.py:142: in test_csv_regex_comma_in_quantifier\n    assert _template_run(in_string) == [re.compile(regex) for regex in expected]\nE   AssertionError: assert [re.compile('...compile('3}')] == [re.compile('...e('bar{1,3}')]\nE     At index 1 diff: re.compile('bar{1') != re.compile('bar{1,3}')\nE     Left contains one more item: re.compile('3}')\nE     Full diff:\nE     - [re.compile('foo'), re.compile('bar{1,3}')]\nE     + [re.compile('foo'), re.compile('bar{1'), re.compile('3}')]\nE     ?                                      ++ +++++++++++++\n_____________________________ test_csv_regex_error _____________________________\ntests/config/test_config.py:171: in test_csv_regex_error\n    assert (\nE   AssertionError: assert 'Error in provided regular expression: (foo{1,} beginning at index 0: missing ), unterminated subpattern' in 'usage: pylint [options]\\npylint: error: argument --bad-names-rgxs: Error in provided regular expression: (foo{1 beginning at index 0: missing ), unterminated subpattern\\n'\nE    +  where 'usage: pylint [options]\\npylint: error: argument --bad-names-rgxs: Error in provided regular expression: (foo{1 beginning at index 0: missing ), unterminated subpattern\\n' = CaptureResult(out='', err='usage: pylint [options]\\npylint: error: argument --bad-names-rgxs: Error in provided regular expression: (foo{1 beginning at index 0: missing ), unterminated subpattern\\n').err\n========================= 2 failed, 18 passed in 2.63s =========================\n\n\nError processing line 1 of /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/distutils-precedence.pth:\n\n  Traceback (most recent call last):\n    File \"/opt/miniconda3/envs/testbed/lib/python3.9/site.py\", line 177, in addpackage\n      exec(line)\n    File \"<string>\", line 1, in <module>\n  ModuleNotFoundError: No module named '_distutils_hack'\n\nRemainder of file ignored\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/config/test_config.py` failed. (See above for error)",
          "test_files_run": [
            "tests/config/test_config.py"
          ]
        }
      },
      "with_fix": {
        "passed": true,
        "stats": {
          "passed": 20,
          "failed": 0,
          "errors": 0,
          "collected": 20,
          "duration": 5.86,
          "log_tail": "============================= test session starts ==============================\ncollecting ... collected 20 items\n\ntests/config/test_config.py::test_can_read_toml_env_variable PASSED      [  5%]\ntests/config/test_config.py::test_unknown_message_id PASSED              [ 10%]\ntests/config/test_config.py::test_unknown_option_name PASSED             [ 15%]\ntests/config/test_config.py::test_unknown_short_option_name PASSED       [ 20%]\ntests/config/test_config.py::test_unknown_confidence PASSED              [ 25%]\ntests/config/test_config.py::test_empty_confidence PASSED                [ 30%]\ntests/config/test_config.py::test_unknown_yes_no PASSED                  [ 35%]\ntests/config/test_config.py::test_unknown_py_version PASSED              [ 40%]\ntests/config/test_config.py::test_csv_regex_comma_in_quantifier[foo-expected0] PASSED [ 45%]\ntests/config/test_config.py::test_csv_regex_comma_in_quantifier[foo,bar-expected1] PASSED [ 50%]\ntests/config/test_config.py::test_csv_regex_comma_in_quantifier[foo, bar-expected2] PASSED [ 55%]\ntests/config/test_config.py::test_csv_regex_comma_in_quantifier[foo, bar{1,3}-expected3] PASSED [ 60%]\ntests/config/test_config.py::test_regex_error PASSED                     [ 65%]\ntests/config/test_config.py::test_csv_regex_error PASSED                 [ 70%]\ntests/config/test_config.py::test_short_verbose PASSED                   [ 75%]\ntests/config/test_config.py::test_argument_separator PASSED              [ 80%]\ntests/config/test_config.py::test_clear_cache_post_run PASSED            [ 85%]\ntests/config/test_config.py::test_enable_all_disable_all_mutually_exclusive PASSED [ 90%]\ntests/config/test_config.py::test_disable_before_enable_all_takes_effect PASSED [ 95%]\ntests/config/test_config.py::test_enable_before_disable_all_takes_effect PASSED [100%]\n\n============================== 20 passed in 2.48s ==============================\n\n\nError processing line 1 of /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/distutils-precedence.pth:\n\n  Traceback (most recent call last):\n    File \"/opt/miniconda3/envs/testbed/lib/python3.9/site.py\", line 177, in addpackage\n      exec(line)\n    File \"<string>\", line 1, in <module>\n  ModuleNotFoundError: No module named '_distutils_hack'\n\nRemainder of file ignored\n",
          "test_files_run": [
            "tests/config/test_config.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got True\u2192True"
    },
    {
      "instance_id": "pylint-dev__pylint-7080",
      "repo": "pylint-dev/pylint",
      "valid": false,
      "worker": "http://34.123.9.23:8080",
      "duration": 45.07351493835449,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 121,
          "failed": 3,
          "errors": 0,
          "collected": 125,
          "duration": 23.07,
          "log_tail": "E     -----------------------------------\nE     Your code has been rated at 0.00/10\nE     \nE     \nE   assert 20 == 0\n________________ TestCallbackOptions.test_generate_toml_config _________________\ntests/test_self.py:1493: in test_generate_toml_config\n    assert \"[tool.pylint.main]\" in process.stdout\nE   assert '[tool.pylint.main]' in ''\nE    +  where '' = CompletedProcess(args=['/opt/miniconda3/envs/testbed/bin/python', '-m', 'pylint', '--rcfile=/testbed/pylint/testutils/testing_pylintrc', '--preferred-modules=a:b', '--generate-toml-config'], returncode=1, stdout='', stderr='Traceback (most recent call last):\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\\n    return _run_code(code, main_globals, None,\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/runpy.py\", line 87, in _run_code\\n    exec(code, run_globals)\\n  File \"/testbed/pylint/__main__.py\", line 10, in <module>\\n    pylint.run_pylint()\\n  File \"/testbed/pylint/__init__.py\", line 25, in run_pylint\\n    PylintRun(argv or sys.argv[1:])\\n  File \"/testbed/pylint/lint/run.py\", line 161, in __init__\\n    args = _config_initialization(\\n  File \"/testbed/pylint/config/config_initialization.py\", line 73, in _config_initialization\\n    parsed_args_list = linter._parse_command_line_configuration(args_list)\\n  File \"/testbed/pylint/config/arguments_manager.py\", line 271, in _parse_command_line_configuration\\n    self.config, parsed_args = self._arg_parser.parse_known_args(\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/argparse....in _parse_known_args\\n    start_index = consume_optional(start_index)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py\", line 2007, in consume_optional\\n    take_action(action, args, option_string)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py\", line 1935, in take_action\\n    action(self, namespace, argument_values, option_string)\\n  File \"/testbed/pylint/config/callback_actions.py\", line 281, in __call__\\n    print(self.run.linter._generate_config_file())\\n  File \"/testbed/pylint/config/arguments_manager.py\", line 681, in _generate_config_file\\n    toml_doc.add(tomlkit.key([\"tool\", \"pylint\"]), pylint_tool_table)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py\", line 116, in add\\n    return self.append(key, item)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py\", line 171, in append\\n    self._handle_dotted_key(key, item)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py\", line 120, in _handle_dotted_key\\n    raise TOMLKitError(\"Can\\'t add a table to a dotted key\")\\ntomlkit.exceptions.TOMLKitError: Can\\'t add a table to a dotted key\\n').stdout\n_____ TestCallbackOptions.test_generate_toml_config_disable_symbolic_names _____\ntests/test_self.py:1528: in test_generate_toml_config_disable_symbolic_names\n    Run([\"--generate-toml-config\"])\npylint/testutils/_run.py:45: in __init__\n    super().__init__(args, reporter, exit, do_exit)\npylint/lint/run.py:161: in __init__\n    args = _config_initialization(\npylint/config/config_initialization.py:73: in _config_initialization\n    parsed_args_list = linter._parse_command_line_configuration(args_list)\npylint/config/arguments_manager.py:271: in _parse_command_line_configuration\n    self.config, parsed_args = self._arg_parser.parse_known_args(\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:1858: in parse_known_args\n    namespace, args = self._parse_known_args(args, namespace)\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:2067: in _parse_known_args\n    start_index = consume_optional(start_index)\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:2007: in consume_optional\n    take_action(action, args, option_string)\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:1935: in take_action\n    action(self, namespace, argument_values, option_string)\npylint/config/callback_actions.py:281: in __call__\n    print(self.run.linter._generate_config_file())\npylint/config/arguments_manager.py:681: in _generate_config_file\n    toml_doc.add(tomlkit.key([\"tool\", \"pylint\"]), pylint_tool_table)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py:116: in add\n    return self.append(key, item)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py:171: in append\n    self._handle_dotted_key(key, item)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py:120: in _handle_dotted_key\n    raise TOMLKitError(\"Can't add a table to a dotted key\")\nE   tomlkit.exceptions.TOMLKitError: Can't add a table to a dotted key\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/interpreter/_import/util.py:6\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/interpreter/_import/util.py:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    import pkg_resources\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n============= 3 failed, 121 passed, 1 xfailed, 1 warning in 18.15s =============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_self.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_self.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 122,
          "failed": 2,
          "errors": 0,
          "collected": 125,
          "duration": 21.16,
          "log_tail": "tests/test_self.py::TestCallbackOptions::test_errors_only_functions_as_disable PASSED [ 98%]\ntests/test_self.py::TestCallbackOptions::test_verbose PASSED             [ 99%]\ntests/test_self.py::TestCallbackOptions::test_enable_all_extensions PASSED [100%]\n\n=================================== FAILURES ===================================\n________________ TestCallbackOptions.test_generate_toml_config _________________\ntests/test_self.py:1493: in test_generate_toml_config\n    assert \"[tool.pylint.main]\" in process.stdout\nE   assert '[tool.pylint.main]' in ''\nE    +  where '' = CompletedProcess(args=['/opt/miniconda3/envs/testbed/bin/python', '-m', 'pylint', '--rcfile=/testbed/pylint/testutils/testing_pylintrc', '--preferred-modules=a:b', '--generate-toml-config'], returncode=1, stdout='', stderr='Traceback (most recent call last):\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\\n    return _run_code(code, main_globals, None,\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/runpy.py\", line 87, in _run_code\\n    exec(code, run_globals)\\n  File \"/testbed/pylint/__main__.py\", line 10, in <module>\\n    pylint.run_pylint()\\n  File \"/testbed/pylint/__init__.py\", line 25, in run_pylint\\n    PylintRun(argv or sys.argv[1:])\\n  File \"/testbed/pylint/lint/run.py\", line 161, in __init__\\n    args = _config_initialization(\\n  File \"/testbed/pylint/config/config_initialization.py\", line 73, in _config_initialization\\n    parsed_args_list = linter._parse_command_line_configuration(args_list)\\n  File \"/testbed/pylint/config/arguments_manager.py\", line 271, in _parse_command_line_configuration\\n    self.config, parsed_args = self._arg_parser.parse_known_args(\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/argparse....in _parse_known_args\\n    start_index = consume_optional(start_index)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py\", line 2007, in consume_optional\\n    take_action(action, args, option_string)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py\", line 1935, in take_action\\n    action(self, namespace, argument_values, option_string)\\n  File \"/testbed/pylint/config/callback_actions.py\", line 281, in __call__\\n    print(self.run.linter._generate_config_file())\\n  File \"/testbed/pylint/config/arguments_manager.py\", line 681, in _generate_config_file\\n    toml_doc.add(tomlkit.key([\"tool\", \"pylint\"]), pylint_tool_table)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py\", line 116, in add\\n    return self.append(key, item)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py\", line 171, in append\\n    self._handle_dotted_key(key, item)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py\", line 120, in _handle_dotted_key\\n    raise TOMLKitError(\"Can\\'t add a table to a dotted key\")\\ntomlkit.exceptions.TOMLKitError: Can\\'t add a table to a dotted key\\n').stdout\n_____ TestCallbackOptions.test_generate_toml_config_disable_symbolic_names _____\ntests/test_self.py:1528: in test_generate_toml_config_disable_symbolic_names\n    Run([\"--generate-toml-config\"])\npylint/testutils/_run.py:45: in __init__\n    super().__init__(args, reporter, exit, do_exit)\npylint/lint/run.py:161: in __init__\n    args = _config_initialization(\npylint/config/config_initialization.py:73: in _config_initialization\n    parsed_args_list = linter._parse_command_line_configuration(args_list)\npylint/config/arguments_manager.py:271: in _parse_command_line_configuration\n    self.config, parsed_args = self._arg_parser.parse_known_args(\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:1858: in parse_known_args\n    namespace, args = self._parse_known_args(args, namespace)\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:2067: in _parse_known_args\n    start_index = consume_optional(start_index)\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:2007: in consume_optional\n    take_action(action, args, option_string)\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:1935: in take_action\n    action(self, namespace, argument_values, option_string)\npylint/config/callback_actions.py:281: in __call__\n    print(self.run.linter._generate_config_file())\npylint/config/arguments_manager.py:681: in _generate_config_file\n    toml_doc.add(tomlkit.key([\"tool\", \"pylint\"]), pylint_tool_table)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py:116: in add\n    return self.append(key, item)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py:171: in append\n    self._handle_dotted_key(key, item)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py:120: in _handle_dotted_key\n    raise TOMLKitError(\"Can't add a table to a dotted key\")\nE   tomlkit.exceptions.TOMLKitError: Can't add a table to a dotted key\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/interpreter/_import/util.py:6\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/interpreter/_import/util.py:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    import pkg_resources\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n============= 2 failed, 122 passed, 1 xfailed, 1 warning in 16.98s =============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_self.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_self.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "pytest-dev__pytest-7236",
      "repo": "pytest-dev/pytest",
      "valid": false,
      "worker": "http://34.171.248.213:8080",
      "error": "HTTPConnectionPool(host='34.171.248.213', port=8080): Max retries exceeded with url: /test (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x10cfafaa0>, 'Connection to 34.171.248.213 timed out. (connect timeout=150)'))",
      "retry_count": 1
    },
    {
      "instance_id": "psf__requests-2317",
      "repo": "psf/requests",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "error": "HTTPConnectionPool(host='34.44.234.143', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 1
    },
    {
      "instance_id": "pylint-dev__pylint-7277",
      "repo": "pylint-dev/pylint",
      "valid": false,
      "worker": "http://35.239.238.137:8080",
      "duration": 49.51335382461548,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 122,
          "failed": 3,
          "errors": 0,
          "collected": 126,
          "duration": 27.36,
          "log_tail": "    assert sys.path == paths\nE   AssertionError: assert ['/usr/local/...ite-packages'] == ['/do_not_rem...ite-packages']\nE     At index 0 diff: '/usr/local/lib/python39.zip' != '/do_not_remove'\nE     Right contains one more item: '/usr/local/lib/python3.9/site-packages'\nE     Full diff:\nE       [\nE     -  '/do_not_remove',\nE        '/usr/local/lib/python39.zip',\nE        '/usr/local/lib/python3.9',...\nE     \nE     ...Full output truncated (3 lines hidden), use '-vv' to show\n________________ TestCallbackOptions.test_generate_toml_config _________________\ntests/test_self.py:1312: in test_generate_toml_config\n    assert \"[tool.pylint.main]\" in process.stdout\nE   assert '[tool.pylint.main]' in ''\nE    +  where '' = CompletedProcess(args=['/opt/miniconda3/envs/testbed/bin/python', '-m', 'pylint', '--rcfile=/testbed/pylint/testutils/testing_pylintrc', '--preferred-modules=a:b', '--generate-toml-config'], returncode=1, stdout='', stderr='Traceback (most recent call last):\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\\n    return _run_code(code, main_globals, None,\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/runpy.py\", line 87, in _run_code\\n    exec(code, run_globals)\\n  File \"/testbed/pylint/__main__.py\", line 10, in <module>\\n    pylint.run_pylint()\\n  File \"/testbed/pylint/__init__.py\", line 35, in run_pylint\\n    PylintRun(argv or sys.argv[1:])\\n  File \"/testbed/pylint/lint/run.py\", line 161, in __init__\\n    args = _config_initialization(\\n  File \"/testbed/pylint/config/config_initialization.py\", line 73, in _config_initialization\\n    parsed_args_list = linter._parse_command_line_configuration(args_list)\\n  File \"/testbed/pylint/config/arguments_manager.py\", line 271, in _parse_command_line_configuration\\n    self.config, parsed_args = self._arg_parser.parse_known_args(\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/argparse....in _parse_known_args\\n    start_index = consume_optional(start_index)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py\", line 2007, in consume_optional\\n    take_action(action, args, option_string)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py\", line 1935, in take_action\\n    action(self, namespace, argument_values, option_string)\\n  File \"/testbed/pylint/config/callback_actions.py\", line 282, in __call__\\n    print(self.run.linter._generate_config_file())\\n  File \"/testbed/pylint/config/arguments_manager.py\", line 681, in _generate_config_file\\n    toml_doc.add(tomlkit.key([\"tool\", \"pylint\"]), pylint_tool_table)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py\", line 116, in add\\n    return self.append(key, item)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py\", line 171, in append\\n    self._handle_dotted_key(key, item)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py\", line 120, in _handle_dotted_key\\n    raise TOMLKitError(\"Can\\'t add a table to a dotted key\")\\ntomlkit.exceptions.TOMLKitError: Can\\'t add a table to a dotted key\\n').stdout\n_____ TestCallbackOptions.test_generate_toml_config_disable_symbolic_names _____\ntests/test_self.py:1348: in test_generate_toml_config_disable_symbolic_names\n    Run([\"--generate-toml-config\"])\npylint/testutils/_run.py:45: in __init__\n    super().__init__(args, reporter, exit, do_exit)\npylint/lint/run.py:161: in __init__\n    args = _config_initialization(\npylint/config/config_initialization.py:73: in _config_initialization\n    parsed_args_list = linter._parse_command_line_configuration(args_list)\npylint/config/arguments_manager.py:271: in _parse_command_line_configuration\n    self.config, parsed_args = self._arg_parser.parse_known_args(\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:1858: in parse_known_args\n    namespace, args = self._parse_known_args(args, namespace)\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:2067: in _parse_known_args\n    start_index = consume_optional(start_index)\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:2007: in consume_optional\n    take_action(action, args, option_string)\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:1935: in take_action\n    action(self, namespace, argument_values, option_string)\npylint/config/callback_actions.py:282: in __call__\n    print(self.run.linter._generate_config_file())\npylint/config/arguments_manager.py:681: in _generate_config_file\n    toml_doc.add(tomlkit.key([\"tool\", \"pylint\"]), pylint_tool_table)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py:116: in add\n    return self.append(key, item)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py:171: in append\n    self._handle_dotted_key(key, item)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py:120: in _handle_dotted_key\n    raise TOMLKitError(\"Can't add a table to a dotted key\")\nE   tomlkit.exceptions.TOMLKitError: Can't add a table to a dotted key\n================== 3 failed, 122 passed, 1 xfailed in 16.84s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_self.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_self.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 123,
          "failed": 2,
          "errors": 0,
          "collected": 126,
          "duration": 21.29,
          "log_tail": "tests/test_self.py::TestCallbackOptions::test_help_msg[args2---help-msg: expected at least one argumen-True] PASSED [ 93%]\ntests/test_self.py::TestCallbackOptions::test_generate_rcfile PASSED     [ 94%]\ntests/test_self.py::TestCallbackOptions::test_generate_config_disable_symbolic_names PASSED [ 95%]\ntests/test_self.py::TestCallbackOptions::test_generate_toml_config FAILED [ 96%]\ntests/test_self.py::TestCallbackOptions::test_generate_toml_config_disable_symbolic_names FAILED [ 96%]\ntests/test_self.py::TestCallbackOptions::test_errors_only PASSED         [ 97%]\ntests/test_self.py::TestCallbackOptions::test_errors_only_functions_as_disable PASSED [ 98%]\ntests/test_self.py::TestCallbackOptions::test_verbose PASSED             [ 99%]\ntests/test_self.py::TestCallbackOptions::test_enable_all_extensions PASSED [100%]\n\n=================================== FAILURES ===================================\n________________ TestCallbackOptions.test_generate_toml_config _________________\ntests/test_self.py:1312: in test_generate_toml_config\n    assert \"[tool.pylint.main]\" in process.stdout\nE   assert '[tool.pylint.main]' in ''\nE    +  where '' = CompletedProcess(args=['/opt/miniconda3/envs/testbed/bin/python', '-m', 'pylint', '--rcfile=/testbed/pylint/testutils/testing_pylintrc', '--preferred-modules=a:b', '--generate-toml-config'], returncode=1, stdout='', stderr='Traceback (most recent call last):\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\\n    return _run_code(code, main_globals, None,\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/runpy.py\", line 87, in _run_code\\n    exec(code, run_globals)\\n  File \"/testbed/pylint/__main__.py\", line 10, in <module>\\n    pylint.run_pylint()\\n  File \"/testbed/pylint/__init__.py\", line 35, in run_pylint\\n    PylintRun(argv or sys.argv[1:])\\n  File \"/testbed/pylint/lint/run.py\", line 161, in __init__\\n    args = _config_initialization(\\n  File \"/testbed/pylint/config/config_initialization.py\", line 73, in _config_initialization\\n    parsed_args_list = linter._parse_command_line_configuration(args_list)\\n  File \"/testbed/pylint/config/arguments_manager.py\", line 271, in _parse_command_line_configuration\\n    self.config, parsed_args = self._arg_parser.parse_known_args(\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/argparse....in _parse_known_args\\n    start_index = consume_optional(start_index)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py\", line 2007, in consume_optional\\n    take_action(action, args, option_string)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py\", line 1935, in take_action\\n    action(self, namespace, argument_values, option_string)\\n  File \"/testbed/pylint/config/callback_actions.py\", line 282, in __call__\\n    print(self.run.linter._generate_config_file())\\n  File \"/testbed/pylint/config/arguments_manager.py\", line 681, in _generate_config_file\\n    toml_doc.add(tomlkit.key([\"tool\", \"pylint\"]), pylint_tool_table)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py\", line 116, in add\\n    return self.append(key, item)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py\", line 171, in append\\n    self._handle_dotted_key(key, item)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py\", line 120, in _handle_dotted_key\\n    raise TOMLKitError(\"Can\\'t add a table to a dotted key\")\\ntomlkit.exceptions.TOMLKitError: Can\\'t add a table to a dotted key\\n').stdout\n_____ TestCallbackOptions.test_generate_toml_config_disable_symbolic_names _____\ntests/test_self.py:1348: in test_generate_toml_config_disable_symbolic_names\n    Run([\"--generate-toml-config\"])\npylint/testutils/_run.py:45: in __init__\n    super().__init__(args, reporter, exit, do_exit)\npylint/lint/run.py:161: in __init__\n    args = _config_initialization(\npylint/config/config_initialization.py:73: in _config_initialization\n    parsed_args_list = linter._parse_command_line_configuration(args_list)\npylint/config/arguments_manager.py:271: in _parse_command_line_configuration\n    self.config, parsed_args = self._arg_parser.parse_known_args(\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:1858: in parse_known_args\n    namespace, args = self._parse_known_args(args, namespace)\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:2067: in _parse_known_args\n    start_index = consume_optional(start_index)\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:2007: in consume_optional\n    take_action(action, args, option_string)\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:1935: in take_action\n    action(self, namespace, argument_values, option_string)\npylint/config/callback_actions.py:282: in __call__\n    print(self.run.linter._generate_config_file())\npylint/config/arguments_manager.py:681: in _generate_config_file\n    toml_doc.add(tomlkit.key([\"tool\", \"pylint\"]), pylint_tool_table)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py:116: in add\n    return self.append(key, item)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py:171: in append\n    self._handle_dotted_key(key, item)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py:120: in _handle_dotted_key\n    raise TOMLKitError(\"Can't add a table to a dotted key\")\nE   tomlkit.exceptions.TOMLKitError: Can't add a table to a dotted key\n================== 2 failed, 123 passed, 1 xfailed in 17.19s ===================\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/test_self.py` failed. (See above for error)",
          "test_files_run": [
            "tests/test_self.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "pylint-dev__pylint-6528",
      "repo": "pylint-dev/pylint",
      "valid": false,
      "worker": "http://34.44.234.143:8080",
      "duration": 53.87338185310364,
      "test_only": {
        "passed": false,
        "stats": {
          "passed": 171,
          "failed": 6,
          "errors": 0,
          "collected": 178,
          "duration": 30.38,
          "log_tail": "E     ------------------------------------------------------------------\nE     Your code has been rated at 0.00/10 (previous run: 0.00/10, +0.00)\nE     \nE     \nE   assert 20 == 0\n________________ TestCallbackOptions.test_generate_toml_config _________________\ntests/test_self.py:1459: in test_generate_toml_config\n    assert \"[tool.pylint.master]\" in process.stdout\nE   assert '[tool.pylint.master]' in ''\nE    +  where '' = CompletedProcess(args=['/opt/miniconda3/envs/testbed/bin/python', '-m', 'pylint', '--rcfile=/testbed/pylint/testutils/testing_pylintrc', '--preferred-modules=a:b', '--generate-toml-config'], returncode=1, stdout='', stderr='Traceback (most recent call last):\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\\n    return _run_code(code, main_globals, None,\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/runpy.py\", line 87, in _run_code\\n    exec(code, run_globals)\\n  File \"/testbed/pylint/__main__.py\", line 10, in <module>\\n    pylint.run_pylint()\\n  File \"/testbed/pylint/__init__.py\", line 25, in run_pylint\\n    PylintRun(argv or sys.argv[1:])\\n  File \"/testbed/pylint/lint/run.py\", line 135, in __init__\\n    args = _config_initialization(\\n  File \"/testbed/pylint/config/config_initialization.py\", line 73, in _config_initialization\\n    parsed_args_list = linter._parse_command_line_configuration(args_list)\\n  File \"/testbed/pylint/config/arguments_manager.py\", line 258, in _parse_command_line_configuration\\n    self.config, parsed_args = self._arg_parser.parse_known_args(\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/argparse.... 2067, in _parse_known_args\\n    start_index = consume_optional(start_index)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py\", line 2007, in consume_optional\\n    take_action(action, args, option_string)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py\", line 1935, in take_action\\n    action(self, namespace, argument_values, option_string)\\n  File \"/testbed/pylint/config/callback_actions.py\", line 281, in __call__\\n    self.run.linter._generate_config_file()\\n  File \"/testbed/pylint/config/arguments_manager.py\", line 661, in _generate_config_file\\n    toml_doc.add(tomlkit.key([\"tool\", \"pylint\"]), pylint_tool_table)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py\", line 116, in add\\n    return self.append(key, item)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py\", line 171, in append\\n    self._handle_dotted_key(key, item)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py\", line 120, in _handle_dotted_key\\n    raise TOMLKitError(\"Can\\'t add a table to a dotted key\")\\ntomlkit.exceptions.TOMLKitError: Can\\'t add a table to a dotted key\\n').stdout\n_____ TestCallbackOptions.test_generate_toml_config_disable_symbolic_names _____\ntests/test_self.py:1479: in test_generate_toml_config_disable_symbolic_names\n    Run([\"--generate-toml-config\"])\npylint/testutils/_run.py:45: in __init__\n    super().__init__(args, reporter, exit, do_exit)\npylint/lint/run.py:135: in __init__\n    args = _config_initialization(\npylint/config/config_initialization.py:73: in _config_initialization\n    parsed_args_list = linter._parse_command_line_configuration(args_list)\npylint/config/arguments_manager.py:258: in _parse_command_line_configuration\n    self.config, parsed_args = self._arg_parser.parse_known_args(\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:1858: in parse_known_args\n    namespace, args = self._parse_known_args(args, namespace)\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:2067: in _parse_known_args\n    start_index = consume_optional(start_index)\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:2007: in consume_optional\n    take_action(action, args, option_string)\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:1935: in take_action\n    action(self, namespace, argument_values, option_string)\npylint/config/callback_actions.py:281: in __call__\n    self.run.linter._generate_config_file()\npylint/config/arguments_manager.py:661: in _generate_config_file\n    toml_doc.add(tomlkit.key([\"tool\", \"pylint\"]), pylint_tool_table)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py:116: in add\n    return self.append(key, item)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py:171: in append\n    self._handle_dotted_key(key, item)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py:120: in _handle_dotted_key\n    raise TOMLKitError(\"Can't add a table to a dotted key\")\nE   tomlkit.exceptions.TOMLKitError: Can't add a table to a dotted key\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/interpreter/_import/util.py:6\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/interpreter/_import/util.py:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    import pkg_resources\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n============= 6 failed, 171 passed, 1 xfailed, 1 warning in 18.90s =============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/lint/unittest_lint.py tests/regrtest_data/directory/ignored_subdirectory/failing.py tests/test_self.py` failed. (See above for error)",
          "test_files_run": [
            "tests/lint/unittest_lint.py",
            "tests/regrtest_data/directory/ignored_subdirectory/failing.py",
            "tests/test_self.py"
          ]
        }
      },
      "with_fix": {
        "passed": false,
        "stats": {
          "passed": 175,
          "failed": 2,
          "errors": 0,
          "collected": 178,
          "duration": 22.67,
          "log_tail": "tests/test_self.py::TestCallbackOptions::test_errors_only PASSED         [ 98%]\ntests/test_self.py::TestCallbackOptions::test_verbose PASSED             [ 99%]\ntests/test_self.py::TestCallbackOptions::test_enable_all_extensions PASSED [100%]\n\n=================================== FAILURES ===================================\n________________ TestCallbackOptions.test_generate_toml_config _________________\ntests/test_self.py:1459: in test_generate_toml_config\n    assert \"[tool.pylint.master]\" in process.stdout\nE   assert '[tool.pylint.master]' in ''\nE    +  where '' = CompletedProcess(args=['/opt/miniconda3/envs/testbed/bin/python', '-m', 'pylint', '--rcfile=/testbed/pylint/testutils/testing_pylintrc', '--preferred-modules=a:b', '--generate-toml-config'], returncode=1, stdout='', stderr='Traceback (most recent call last):\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\\n    return _run_code(code, main_globals, None,\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/runpy.py\", line 87, in _run_code\\n    exec(code, run_globals)\\n  File \"/testbed/pylint/__main__.py\", line 10, in <module>\\n    pylint.run_pylint()\\n  File \"/testbed/pylint/__init__.py\", line 25, in run_pylint\\n    PylintRun(argv or sys.argv[1:])\\n  File \"/testbed/pylint/lint/run.py\", line 135, in __init__\\n    args = _config_initialization(\\n  File \"/testbed/pylint/config/config_initialization.py\", line 73, in _config_initialization\\n    parsed_args_list = linter._parse_command_line_configuration(args_list)\\n  File \"/testbed/pylint/config/arguments_manager.py\", line 258, in _parse_command_line_configuration\\n    self.config, parsed_args = self._arg_parser.parse_known_args(\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/argparse.... 2067, in _parse_known_args\\n    start_index = consume_optional(start_index)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py\", line 2007, in consume_optional\\n    take_action(action, args, option_string)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py\", line 1935, in take_action\\n    action(self, namespace, argument_values, option_string)\\n  File \"/testbed/pylint/config/callback_actions.py\", line 281, in __call__\\n    self.run.linter._generate_config_file()\\n  File \"/testbed/pylint/config/arguments_manager.py\", line 661, in _generate_config_file\\n    toml_doc.add(tomlkit.key([\"tool\", \"pylint\"]), pylint_tool_table)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py\", line 116, in add\\n    return self.append(key, item)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py\", line 171, in append\\n    self._handle_dotted_key(key, item)\\n  File \"/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py\", line 120, in _handle_dotted_key\\n    raise TOMLKitError(\"Can\\'t add a table to a dotted key\")\\ntomlkit.exceptions.TOMLKitError: Can\\'t add a table to a dotted key\\n').stdout\n_____ TestCallbackOptions.test_generate_toml_config_disable_symbolic_names _____\ntests/test_self.py:1479: in test_generate_toml_config_disable_symbolic_names\n    Run([\"--generate-toml-config\"])\npylint/testutils/_run.py:45: in __init__\n    super().__init__(args, reporter, exit, do_exit)\npylint/lint/run.py:135: in __init__\n    args = _config_initialization(\npylint/config/config_initialization.py:73: in _config_initialization\n    parsed_args_list = linter._parse_command_line_configuration(args_list)\npylint/config/arguments_manager.py:258: in _parse_command_line_configuration\n    self.config, parsed_args = self._arg_parser.parse_known_args(\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:1858: in parse_known_args\n    namespace, args = self._parse_known_args(args, namespace)\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:2067: in _parse_known_args\n    start_index = consume_optional(start_index)\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:2007: in consume_optional\n    take_action(action, args, option_string)\n/opt/miniconda3/envs/testbed/lib/python3.9/argparse.py:1935: in take_action\n    action(self, namespace, argument_values, option_string)\npylint/config/callback_actions.py:281: in __call__\n    self.run.linter._generate_config_file()\npylint/config/arguments_manager.py:661: in _generate_config_file\n    toml_doc.add(tomlkit.key([\"tool\", \"pylint\"]), pylint_tool_table)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py:116: in add\n    return self.append(key, item)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py:171: in append\n    self._handle_dotted_key(key, item)\n/opt/miniconda3/envs/testbed/lib/python3.9/site-packages/tomlkit/container.py:120: in _handle_dotted_key\n    raise TOMLKitError(\"Can't add a table to a dotted key\")\nE   tomlkit.exceptions.TOMLKitError: Can't add a table to a dotted key\n=============================== warnings summary ===============================\n../opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/interpreter/_import/util.py:6\n  /opt/miniconda3/envs/testbed/lib/python3.9/site-packages/astroid/interpreter/_import/util.py:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n    import pkg_resources\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n============= 2 failed, 175 passed, 1 xfailed, 1 warning in 18.40s =============\n\n\nERROR conda.cli.main_run:execute(124): `conda run pytest -v --tb=short --no-header -rN tests/lint/unittest_lint.py tests/regrtest_data/directory/ignored_subdirectory/failing.py tests/test_self.py` failed. (See above for error)",
          "test_files_run": [
            "tests/lint/unittest_lint.py",
            "tests/regrtest_data/directory/ignored_subdirectory/failing.py",
            "tests/test_self.py"
          ]
        }
      },
      "error": "Expected fail\u2192pass, got False\u2192False"
    },
    {
      "instance_id": "mwaskom__seaborn-3187",
      "repo": "mwaskom/seaborn",
      "valid": false,
      "worker": "http://34.59.30.169:8080",
      "error": "HTTPConnectionPool(host='34.59.30.169', port=8080): Read timed out. (read timeout=150)",
      "retry_count": 1
    }
  ]
}